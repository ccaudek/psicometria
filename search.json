[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science per Psicologi",
    "section": "",
    "text": "Benvenuti\nQuesto sito web √® dedicato al materiale didattico dell‚Äôinsegnamento di Psicometria (A.A. 2024/2025), rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell‚ÄôUniversit√† degli Studi di Firenze.\nIl corso √® strutturato per fornire agli studenti una formazione teorica e pratica approfondita nell‚Äôinferenza statistica, enfatizzando particolarmente le applicazioni pratiche attraverso la programmazione. Attraverso esercitazioni guidate, gli studenti impareranno a manipolare e analizzare dati psicologici utilizzando Python, acquisendo cos√¨ le competenze necessarie per prendere decisioni informate e realizzare interpretazioni precise nei loro progetti di modellazione.\nIl programma copre un ampio spettro di tecniche, partendo dall‚Äôanalisi descrittiva per arrivare fino ai modelli gerarchici avanzati. Si pone un forte accento sull‚Äôinferenza causale, approcciata da una prospettiva bayesiana, includendo l‚Äôuso di Grafi Aciclici Diretti (DAG) per esplorare in modo approfondito le relazioni causali. L‚Äôintento √® di andare oltre i limiti della modellazione lineare tradizionale, mostrando come integrare efficacemente i modelli psicologici avanzati nell‚Äôanalisi statistica.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#informazioni-sullinsegnamento",
    "href": "index.html#informazioni-sullinsegnamento",
    "title": "Data Science per Psicologi",
    "section": "Informazioni sull‚Äôinsegnamento",
    "text": "Informazioni sull‚Äôinsegnamento\n\n\nCodice: B000286 - PSICOMETRIA \n\nModulo: B000286 - PSICOMETRIA (Cognomi L-Z) \n\nCorso di laurea: Scienze e Tecniche Psicologiche \n\nAnno Accademico: 2024-2025 \n\nMateriali didattici: √à sufficiente disporre di un laptop/computer funzionante. Tutti i materiali didattici e il software necessario sono forniti gratuitamente a tutti gli studenti, senza richiedere alcun acquisto.\n\nCalendario: Il corso si terr√† dal 3 marzo al 31 maggio 2025.\n\nOrario delle lezioni: Le lezioni si svolgeranno il luned√¨ e il marted√¨ dalle 8:30 alle 10:30 e il gioved√¨ dalle 11:30 alle 13:30.\n\nLuogo: Le lezioni si terranno presso il Plesso didattico La Torretta.\n\nModalit√† di svolgimento della didattica: Le lezioni ed esercitazioni saranno svolte in modalit√† frontale.\n\n\n\n\n\n\n\nIl presente sito web costituisce l‚Äôunica fonte ufficiale da consultare per ottenere informazioni sul programma dell‚Äôinsegnamento B000286 - PSICOMETRIA (Cognomi L-Z) A.A. 2024-2025 e sulle modalit√† d‚Äôesame.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Data Science per Psicologi",
    "section": "Syllabus",
    "text": "Syllabus\nIl Syllabus pu√≤ essere scaricato utilizzando questo link.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "chapters/python/introduction_python.html",
    "href": "chapters/python/introduction_python.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa verranno presentati alcuni concetti fondamentali per l‚Äôanalisi dei dati utilizzando Python come linguaggio di programmazione e Jupyter come ambiente di sviluppo. Tuttavia, saranno trattati solo in modo conciso, poich√© esistono numerose risorse online che approfondiscono questo argomento. Per coloro che preferiscono una trattazione pi√π completa, si consiglia il libro A Beginners Guide to Python 3 Programming di John Hunt (disponibile gratuitamente alla comunit√† UniFi). Il tutorial ufficiale della documentazione Python, in italiano, √® fornito qui.\nPrima di procedere con il presente capitolo, √® indispensabile leggere l‚ÄôAppendice A ‚Äî Ambiente di lavoro, l‚ÄôAppendice C ‚Äî La Shell e l‚ÄôAppendice I ‚Äî Insiemi.",
    "crumbs": [
      "Python",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html",
    "href": "chapters/python/00_prelims.html",
    "title": "1¬† Preliminari",
    "section": "",
    "text": "1.1 Iniziare ad Usare Python üêç\nIn questo corso, utilizzeremo Python all‚Äôinterno di un ambiente Jupyter Notebook. L‚Äôappendice Appendice A fornisce le istruzioni per installare Jupyter Notebook sul vostro computer.\nIn alternativa, √® possibile scrivere uno script Python in un file con estensione .py, il quale pu√≤ essere eseguito tramite il comando python nome_file.py dalla linea di comando.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#jupyter-notebook",
    "href": "chapters/python/00_prelims.html#jupyter-notebook",
    "title": "1¬† Preliminari",
    "section": "1.2 Jupyter Notebook",
    "text": "1.2 Jupyter Notebook\nI Jupyter Notebook offrono un ambiente interattivo in cui √® possibile eseguire il codice suddiviso in celle. Sebbene sia possibile eseguire il codice nelle celle in qualsiasi ordine, √® considerata una pratica consigliata eseguirle in sequenza al fine di prevenire errori e garantire una corretta esecuzione del codice.\nI Jupyter Notebook supportano due tipi di celle:\n\nCelle di Testo: Queste celle consentono di scrivere testo formattato utilizzando la sintassi Markdown. Questo permette agli autori di inserire del testo descrittivo, comprese immagini, formule in formato \\(\\LaTeX\\), tabelle e altro ancora. Le celle di testo facilitano la documentazione del processo di analisi dei dati in modo chiaro e comprensibile.\nCelle di Codice: Le celle di codice consentono di scrivere e eseguire codice Python. Il codice pu√≤ essere eseguito facendo clic sul triangolo situato a sinistra di ogni cella. Diverse celle possono contenere istruzioni diverse e possono essere eseguite in sequenza. √à importante notare che una funzione definita in una cella precedente pu√≤ essere utilizzata solo se la cella precedente √® stata eseguita.\n\nQui sotto abbiamo una cella di codice.\n\n# Make plot\n%matplotlib inline\nimport math\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntheta = np.arange(0, 4 * math.pi, 0.1)\neight = plt.figure()\naxes = eight.add_axes([0, 0, 1, 1])\naxes.plot(0.5 * np.sin(theta), np.cos(theta / 2))\n\n\n\n\n\n\n\n\nQuando lavori con il notebook, puoi essere all‚Äôinterno di una cella, digitando i suoi contenuti, oppure al di fuori delle celle, muovendoti nel notebook.\nQuando sei all‚Äôinterno di una cella, premi Esc per uscirne. Quando ti muovi al di fuori delle celle, premi Invio per entrare.\n\nFuori da una cella:\n\nUsa i tasti freccia per muoverti.\nPremi Shift+Invio per eseguire il codice nel blocco.\n\nAll‚Äôinterno di una cella:\n\nPremi Tab per suggerire completamenti delle variabili.\n\n\nIl nome \"Jupyter\" deriva dalle tre principali lingue di programmazione supportate: Julia, Python e R. Tuttavia, √® possibile utilizzare i Jupyter Notebook con molte altre lingue di programmazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#esecuzione-locale-o-su-colab",
    "href": "chapters/python/00_prelims.html#esecuzione-locale-o-su-colab",
    "title": "1¬† Preliminari",
    "section": "1.3 Esecuzione Locale o su Colab",
    "text": "1.3 Esecuzione Locale o su Colab\nI Jupyter Notebook possono essere eseguiti sia in locale, sul vostro computer, che su un server remoto, come Google Colab. Questa flessibilit√† permette agli utenti di accedere ai propri notebook da qualsiasi dispositivo connesso a Internet e di condividere agevolmente il proprio lavoro con altri.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#kernel-nei-jupyter-notebook",
    "href": "chapters/python/00_prelims.html#kernel-nei-jupyter-notebook",
    "title": "1¬† Preliminari",
    "section": "1.4 Kernel nei Jupyter Notebook",
    "text": "1.4 Kernel nei Jupyter Notebook\nI Jupyter Notebook sono strumenti che agevolano la programmazione in Python grazie a un componente essenziale: il kernel. Quest‚Äôultimo funge da motore di esecuzione per il codice Python presente nelle celle dei notebook. Ogni volta che eseguite una cella, il suo contenuto viene processato dal kernel. La caratteristica pi√π significativa del kernel √® la sua capacit√† di preservare lo stato delle variabili e delle funzioni tra le diverse celle. In pratica, ci√≤ significa che potete definire variabili o funzioni in una cella e poi riutilizzarle in celle successive. Questa interattivit√† facilita l‚Äôesecuzione iterativa del codice e offre un modo dinamico per esplorare i dati.\nDurante l‚Äôinstallazione di Jupyter Notebook, di norma ricevete anche IPython, un kernel ottimizzato per Python.\nSi noti che il kernel Python deve essere installato all‚Äôinterno di un ambiente di sviluppo dedicato noto come ‚Äúambiente virtuale‚Äù (per ulteriori dettagli, si veda {ref}sec-virtual-environment). Questo ambiente svolge un ruolo fondamentale nel separare e isolare le librerie e le dipendenze necessarie per il kernel. Ci√≤ aiuta a evitare conflitti tra diverse configurazioni e garantisce il corretto funzionamento del codice nel contesto desiderato. L‚Äôutilizzo di ambienti specifici risulta particolarmente vantaggioso nei progetti che richiedono versioni particolari di librerie.\nIn questo insegnamento, faremo ampio uso della funzionalit√† conda, inclusa nell‚Äôinstallazione di Anaconda, per la gestione di questi ambienti. conda mette a disposizione funzioni utili per la creazione, la gestione e l‚Äôattivazione di ambienti separati, ciascuno con le sue configurazioni e dipendenze uniche. Questa capacit√† semplifica notevolmente la transizione tra diversi ambienti, garantendo che ogni progetto o kernel disponga delle risorse necessarie per operare in modo efficiente e senza interferenze.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#visual-studio-code",
    "href": "chapters/python/00_prelims.html#visual-studio-code",
    "title": "1¬† Preliminari",
    "section": "1.5 Visual Studio Code",
    "text": "1.5 Visual Studio Code\nIl modo pi√π semplice di usare un Jupyter Notebook √® all‚Äôinterno di Visual Studio Code. Dopo aver installato Visual Studio Code, √® necessario installare l‚Äôestensione Python per sfruttare le funzionalit√† specifiche per Python, inclusa la capacit√† di lavorare con Jupyter Notebook.\n\nIn Visual Studio Code, si clicca sull‚Äôicona delle estensioni (quadrati che si intersecano) nella barra laterale a sinistra.\nSi cerca ‚ÄúPython‚Äù nella barra di ricerca e si seleziona l‚Äôestensione ufficiale offerta da Microsoft.\nSi clicca su ‚ÄúInstall‚Äù.\n\nUna volta completate le installazioni, siete pronti per creare il vostro primo Jupyter Notebook in VS Code.\n\nSi apre Visual Studio Code.\nSi clicca su File &gt; New File.\nSi preme Ctrl+Shift+P per aprire la Palette dei Comandi.\nSi digita ‚ÄúJupyter‚Äù e si seleziona Jupyter: Create New Blank Notebook.\nSi aprir√† un nuovo notebook dove si pu√≤ iniziare a scrivere il codice Python nelle celle.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html",
    "href": "chapters/python/01_python_1.html",
    "title": "2¬† Python (1)",
    "section": "",
    "text": "2.1 Scrivere Codice con il Supporto dei LLM\nI Large Language Models (LLM), come GPT-4, stanno rivoluzionando non solo molte applicazioni legate alla creazione di testi in linguaggio naturale, ma stanno anche aprendo nuove e interessanti potenzialit√† nel campo della programmazione e dell‚Äôanalisi dei dati. La programmazione, con le sue regole esplicite e la sintassi strutturata, si adatta particolarmente bene alle capacit√† di riconoscimento dei pattern degli LLM. A differenza dei linguaggi umani, ricchi di significati ambigui ed espressioni idiomatiche, i linguaggi di programmazione sono rigorosi e precisi.\nNel contesto dell‚Äôanalisi dei dati, √® naturale unire le capacit√† degli LLM con la potenza computazionale dei linguaggi statistici come R o di programmazione come Python. Sono gi√† stati pubblicati libri su come integrare le capacit√† degli LLM con l‚Äôanalisi dei dati Matter (2025), e sta emergendo una nuova branca dell‚Äôingegneria dedicata allo sviluppo dei prompt pi√π efficaci per l‚Äôuso con gli LLM. Pertanto, il problema non √® se utilizzare gli LLM a supporto della programmazione, ma come farlo nel modo pi√π efficace.\nUn principio fondamentale √® che, maggiore √® la conoscenza delle regole sintattiche di un linguaggio di programmazione, maggiore sar√† l‚Äôefficacia dell‚Äôuso degli LLM per scopi di analisi dei dati. Quindi, anche se i problemi di programmazione richiesti in questo corso di analisi dei dati sono relativamente semplici rispetto alle capacit√† degli LLM, gli utenti che utilizzeranno gli LLM a supporto delle proprie attivit√† di programmazione trarranno certamente beneficio dalla conoscenza delle regole sintattiche del linguaggio di programmazione utilizzato, che nel nostro caso sar√† principalmente Python (esamineremo anche degli esempi in R).\nGli LLM si basano sul concetto di ‚Äúpredizione del prossimo token‚Äù. Questo significa che sono addestrati per prevedere la parola o il carattere successivo in una sequenza, basandosi su quelli precedenti. Questo principio √® fondamentale per la capacit√† degli LLM di generare codice e per il loro utilizzo nel migliorare i flussi di lavoro di analisi dei dati in Python o R. Oltre a miliardi di parole provenienti da testi comuni (siti web, libri, articoli di riviste), gli LLM di OpenAI, come GPT-4, sono stati addestrati su un vasto corpus di codice open-source e discussioni sul codice presenti su piattaforme come Stack Overflow. Questo consente loro di generare codice sintatticamente e semanticamente corretto in molte situazioni.\nGli LLM possono assistere in diversi compiti di programmazione in Python e R, tra cui l‚Äôidentificazione degli errori negli script, la scrittura di codice a partire da descrizioni in linguaggio naturale, l‚Äôottimizzazione del codice, la generazione di documentazione e la creazione di casi di test.\nAcquisire conoscenze sull‚Äôuso pratico dell‚ÄôAI/LLM nelle attivit√† di programmazione e analisi √® pi√π di una tendenza: √® una necessit√† nel mercato del lavoro attuale. I professionisti che possono utilizzare efficacemente l‚ÄôAI/LLM per migliorare le loro competenze di programmazione e integrare questi strumenti in Python e R avranno un vantaggio competitivo. Man mano che l‚ÄôAI e gli LLM diventano sempre pi√π diffusi nell‚Äôindustria e nel mondo accademico, la domanda per queste competenze continuer√† a crescere.\nL‚Äôobiettivo di questo capitolo √® fornire una panoramica della sintassi di Python e delle principali funzioni di pacchetti come Pandas, Numpy e Matplotlib, utili per la data science. Python √® un linguaggio di programmazione versatile e di facile lettura, adatto a numerosi usi. Anche se il suo nome √® un omaggio al gruppo comico Monty Python, apprendere Python richiede tempo, pratica e impegno.\nQuesta guida (e tutto il corso) si concentra sull‚Äôinsegnamento dei principi di base della programmazione, piuttosto che sui dettagli tecnici. Possiamo fare riferimento alla distinzione di Marr tra livello computazionale e livello algoritmico (Marr 2010). Una spiegazione a livello computazionale descrive la logica del problema. Se consideriamo un modello, una spiegazione a livello computazionale descrive i passaggi necessari per trasformare l‚Äôinput in output. Ad esempio, potrebbe essere necessario eseguire una certa trasformazione sui dati (come una trasformazione logaritmica) e poi effettuare altre operazioni sui dati trasformati.\nIl livello algoritmico, invece, descrive come eseguire specificamente le operazioni logiche delineate a livello computazionale. Nel caso del presente esempio, questo livello specifica la sintassi in Python per eseguire la trasformazione dei dati richiesta. √à importante notare che la stessa operazione logica descritta a livello computazionale pu√≤ essere implementata in moltissimi modi diversi a livello algoritmico, utilizzando vari pacchetti Python o diversi linguaggi di programmazione.\nIl focus di questo corso √® il livello computazionale (per la sintassi ci sono i LLM). Con questa conoscenza a livello computazionale, gli studenti saranno pi√π capaci di risolvere problemi specifici e di cercare autonomamente la sintassi appropriata per il problema da risolvere.\nNel mondo attuale, in cui l‚Äôintelligenza artificiale riveste un ruolo sempre pi√π centrale, √® fondamentale sviluppare la capacit√† di pensare in modo computazionale. Questa competenza va oltre la mera programmazione e offre un approccio strutturato per risolvere problemi complessi. Sebbene i modelli di linguaggio avanzati (LLM) siano in grado di risolvere molti dei problemi di programmazione che affronteremo in questo corso, una comprensione approfondita dei principi della programmazione rimane essenziale per interpretare, modificare o migliorare le soluzioni proposte da tali sistemi.\nIn conclusione, anche nell‚Äôera dell‚ÄôIA, una solida comprensione dei fondamenti della programmazione √® indispensabile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#espressioni-e-operatori",
    "href": "chapters/python/01_python_1.html#espressioni-e-operatori",
    "title": "2¬† Python (1)",
    "section": "2.2 Espressioni e Operatori",
    "text": "2.2 Espressioni e Operatori\nI programmi sono insiemi di espressioni che elaborano dati per fornire istruzioni specifiche al computer. Ad esempio, in Python, l‚Äôoperazione di moltiplicazione si esegue utilizzando l‚Äôasterisco (*) tra due numeri. Quando si incontra un‚Äôespressione come 3 * 4, il computer la valuta e produce il risultato, che pu√≤ essere visualizzato in una cella successiva di un notebook Jupyter.\nLe regole sintattiche in un linguaggio di programmazione come Python sono stringenti. Ad esempio, non √® consentito inserire due simboli asterisco in sequenza senza un operando intermedio. Qualora un‚Äôespressione violi queste norme sintattiche, il sistema ritorner√† un ‚ÄúSyntaxError‚Äù, un errore che indica la non conformit√† alle regole del linguaggio. Per esempio\n3 * * 4\nrestituisce:\n Cell In[3], line 1\n    3 * * 4\n        ^\nSyntaxError: invalid syntax\nAnche piccole modifiche in un‚Äôespressione possono cambiarne completamente il significato. Nell‚Äôesempio successivo, lo spazio tra i due asterischi * √® stato rimosso. Tuttavia, poich√© gli asterischi compaiono tra due espressioni numeriche, l‚Äôespressione √® corretta e indica l‚Äôelevamento a potenza del primo numero al secondo: 3 elevato alla quarta potenza (\\(3 \\times 3 \\times 3 \\times 3\\)). In programmazione, simboli come * e ** sono noti come ‚Äúoperatori‚Äù, mentre i valori su cui agiscono sono denominati ‚Äúoperandi‚Äù.\n\n3 ** 4\n\n81\n\n\nLa tabella seguente elenca i principali operatori binari utilizzati in Python, chiamati cos√¨ perch√© agiscono su due operandi.\n\n\n\nOperazione\nOperatore\n\n\n\n\naddizione\n+\n\n\nsottrazione\n-\n\n\nmoltiplicazione\n*\n\n\ndivisione (reale)\n/\n\n\ndivisione (intera; rimuove il resto)\n//\n\n\nresto (modulo)\n%\n\n\nelevamento a potenza\n**\n\n\n\nLe due operazioni che potrebbero essere meno familiari sono % (trova il resto di una divisione) e // (esegui una divisione scartando il resto).\nPer esempio, la divisione intera (scartando il resto) di 11/2 produce 5.\n\n11 // 2\n\n5\n\n\nIl resto di 11/2 √® 1.\n\n11 % 2\n\n1\n\n\nUsando gli operatori che abbiamo elencato in precedenza possiamo usare Python come un calcolatore.\n\nprint(\"4 + 2 √®\", 4 + 2)\nprint(\"4 - 2 √®\", 4 - 2)\nprint(\"4 * 2 √®\", 4 * 2)\nprint(\"4 / 2 √®\", 4 / 2)\nprint(\"4 ** 2 √®\", 4**2)\nprint(\"9 % 4 √®\", 9 % 4)\nprint(\"9 // 4 √®\", 9 // 4)\n\n4 + 2 √® 6\n4 - 2 √® 2\n4 * 2 √® 8\n4 / 2 √® 2.0\n4 ** 2 √® 16\n9 % 4 √® 1\n9 // 4 √® 2\n\n\nL‚Äôapplicazione degli operatori aritmetici in Python dipende dalle seguenti regole di precedenza degli operatori, che sono analoghe a quelle usate in algebra.\n\nLe espressioni tra parentesi vengono valutate per prime.\nSuccessivamente si valutano gli elevamenti a potenza.\nIn seguito, si valutano moltiplicazioni, divisioni e moduli.\nPer ultime vengono valutate somme e sottrazioni.\n\n\n1 + 2 * 3 * 4 * 5 / 6 ** 3 + 7 + 8 - 9 + 10\n\n17.555555555555557\n\n\n\n1 + 2 * (3 * 4 * 5 / 6) ** 3 + 7 + 8 - 9 + 10\n\n2017.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#variabili",
    "href": "chapters/python/01_python_1.html#variabili",
    "title": "2¬† Python (1)",
    "section": "2.3 Variabili",
    "text": "2.3 Variabili\nQuando generiamo un risultato, la risposta viene visualizzata ma non viene memorizzata da nessuna parte, come abbiamo visto negli esempi precedenti. Se vogliamo recuperare quel risultato, dobbiamo memorizzarlo. Lo mettiamo in un oggetto, e diamo un nome a quell‚Äôoggetto. Questa √® una variabile.\nPer creare una variabile facciamo uso di un‚Äôistruzione di assegnazione. In un‚Äôistruzione di assegnazione, si specifica un nome seguito dal simbolo di uguale (=) e dall‚Äôespressione che si desidera assegnare a tale nome. L‚Äôoperazione di assegnazione consiste nell‚Äôassociare il valore dell‚Äôespressione a destra del simbolo di uguale al nome a sinistra. Da quel momento in poi, ogni volta che il nome viene utilizzato in un‚Äôespressione, il valore associato durante l‚Äôassegnazione viene utilizzato al suo posto.\n\na = 10\nb = 20\na + b\n\n30\n\n\n\na = 1/4\nb = 2 * a\nb\n\n0.5\n\n\n\nmy_var = 100\nconst = 3\n\nmy_var * const\n\n300\n\n\nIn Python, ogni ‚Äúoggetto‚Äù √® un‚Äôarea di memoria nel computer. Una ‚Äúvariabile‚Äù funge da etichetta che fa riferimento a quest‚Äôarea. Se un oggetto non ha pi√π etichette (ovvero, non ci sono pi√π variabili che lo referenziano), i dati contenuti nell‚Äôoggetto diventano inaccessibili. Il Garbage Collector del linguaggio si occuper√† di rilevare questi oggetti non referenziati e liberare la memoria, permettendo che venga riutilizzata per nuovi dati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#nomi-delle-variabili",
    "href": "chapters/python/01_python_1.html#nomi-delle-variabili",
    "title": "2¬† Python (1)",
    "section": "2.4 Nomi delle Variabili",
    "text": "2.4 Nomi delle Variabili\nI nomi delle variabili in Python possono contenere caratteri alfanumerici da a-z, A-Z, 0-9 e alcuni caratteri speciali come _. I nomi delle variabili normali devono iniziare con una lettera. I nomi delle variabili non possono contenere uno spazio; invece, √® comune utilizzare il carattere _ per sostituire ogni spazio. Sta al programmatore scegliere nomi facili da interpretare.\nPer convenzione, i nomi delle variabili iniziano con una lettera minuscola, mentre i nomi delle classi iniziano con una lettera maiuscola.\nInoltre, ci sono una serie di parole chiave (keyword) in Python che non possono essere utilizzate come nomi di variabili. Queste parole chiave sono:\n\nimport keyword\nprint(*keyword.kwlist, sep=\"\\n\")\n\nFalse\nNone\nTrue\nand\nas\nassert\nasync\nawait\nbreak\nclass\ncontinue\ndef\ndel\nelif\nelse\nexcept\nfinally\nfor\nfrom\nglobal\nif\nimport\nin\nis\nlambda\nnonlocal\nnot\nor\npass\nraise\nreturn\ntry\nwhile\nwith\nyield\n\n\nSi presti attenzione alla parola chiave ‚Äúlambda‚Äù, che potrebbe facilmente essere un nome di variabile naturale in un programma scientifico. Tuttavia, essendo una parola chiave, non pu√≤ essere utilizzata come nome di variabile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#tipologie-di-dati-in-python",
    "href": "chapters/python/01_python_1.html#tipologie-di-dati-in-python",
    "title": "2¬† Python (1)",
    "section": "2.5 Tipologie di Dati in Python",
    "text": "2.5 Tipologie di Dati in Python\nIn Python, le variabili possono appartenere a diverse tipologie di dati, ciascuna con caratteristiche e utilizzi specifici.\n\n2.5.1 Stringhe (String)\nLe stringhe sono sequenze di caratteri, utilizzate per rappresentare testo. In Python, le stringhe possono essere create utilizzando apici singoli (' '), doppi (\" \") o tripli (''' ''' oppure \"\"\" \"\"\") per delimitare il testo. Esempi di stringhe sono:\n\"Hello, world!\"\n'Beyonce-Lemonade.txt'\n\"lemonade\"\nSi noti il risultato ottenuto quando si applica l‚Äôoperatore + a due stringhe.\n\n\"data\" + \"science\"\n\n'datascience'\n\n\n\n\"data\" + \" \" + \"science\"\n\n'data science'\n\n\nSia le virgolette singole che doppie possono essere utilizzate per creare le stringhe: ‚Äúciao‚Äù e ‚Äòciao‚Äô sono espressioni equivalenti. Tuttavia, le virgolette doppie sono spesso preferite poich√© consentono di includere virgolette singole all‚Äôinterno delle stringhe.\n\n\"Che cos'√® una parola?\"\n\n\"Che cos'√® una parola?\"\n\n\nL‚Äôespressione precedente avrebbe prodotto un SyntaxError se fosse stata racchiusa da virgolette singole.\n\n2.5.1.1 Parsing strings\nIn Python, una stringa √® concepita come una sequenza ordinata di caratteri. Grazie all‚Äôoperatore di indicizzazione, rappresentato dalle parentesi quadre [], √® possibile accedere a singoli elementi della stringa.\n√à importante ricordare che l‚Äôindicizzazione in Python parte da zero.\nL‚Äôindice del primo carattere √® [0], quello del secondo √® [1], del terzo [2], e cos√¨ via. Questa funzionalit√† consente di manipolare o consultare specifici segmenti della stringa, piuttosto che gestirla come un blocco unico.\nConsideriamo questo verso di Eugenio Montale:\n\nmy_string = \"Tendono alla chiarit√† le cose oscure\"\nprint(my_string)\n\nTendono alla chiarit√† le cose oscure\n\n\n\nmy_string[0]\n\n'T'\n\n\n\nmy_string[3]\n\n'd'\n\n\n\nlen(my_string)\n\n36\n\n\nLa stringa ‚Äúmy_string‚Äù conta 36 caratteri. Pertanto, gli indici validi per questa stringa vanno da 0 a 35. Per accedere all‚Äôultimo carattere, √® necessario utilizzare l‚Äôindice 35, che corrisponde a 36 meno 1.\n\nmy_string[35]\n\n'e'\n\n\nUn modo efficiente per ottenere l‚Äôultimo carattere √® ricorrere alla funzione len, sottraendo 1 al risultato:\n\nmy_string[len(my_string) - 1]\n\n'e'\n\n\nSi noti che len() √® una funzione. Una funzione √® un blocco di codice che esegue un‚Äôoperazione specifica. I programmatori chiamano anche gli input delle funzioni ‚Äúparametri‚Äù o ‚Äúargomenti‚Äù.\nLa funzione len prende un input e restituisce un output. L‚Äôoutput √® la lunghezza di ci√≤ che √® stato passato come input.\n\n\n2.5.1.2 Slicing strings\nOltre a estrarre caratteri individuali da una stringa, Python offre la possibilit√† di selezionare segmenti di testo attraverso la tecnica dello ‚Äúslicing‚Äù. Questo meccanismo √® simile all‚Äôindicizzazione, ma utilizza due indici separati da un carattere a due punti (:). Il primo indice indica la posizione di partenza dello ‚Äúslicing‚Äù nella stringa, mentre il secondo indice segnala il punto in cui terminare l‚Äôestrazione del segmento.\n\nmy_string[2:4]\n\n'nd'\n\n\nSe si omette il primo indice, Python utilizzer√† l‚Äôinizio della stringa; se si omette il secondo, utilizzer√† la fine della stringa.\n\nmy_string[:4]\n\n'Tend'\n\n\n\nmy_string[4:]\n\n'ono alla chiarit√† le cose oscure'\n\n\n\n\n2.5.1.3 Metodi\nA partire da una stringa esistente, si possono generare nuove stringhe mediante l‚Äôutilizzo di metodi specifici per le stringhe. Questi metodi sono essenzialmente funzioni che agiscono direttamente sull‚Äôoggetto stringa. Per invocare un metodo, basta posizionare un punto subito dopo la stringa e seguire con il nome del metodo desiderato. Ad esempio, il metodo successivo converte tutti i caratteri della stringa in maiuscole.\n\nmy_string.upper()\n\n'TENDONO ALLA CHIARIT√Ä LE COSE OSCURE'\n\n\nIl metodo my_string.title() √® utilizzato per convertire la prima lettera di ogni parola nella stringa my_string in maiuscolo, mentre rende tutte le altre lettere minuscole. In pratica, trasforma la stringa in una forma ‚Äúa titolo‚Äù, in cui ogni parola inizia con una lettera maiuscola.\n\nmy_string.title()\n\n'Tendono Alla Chiarit√† Le Cose Oscure'\n\n\n\n\n\n2.5.2 Numeri Interi (Integer)\nI numeri interi rappresentano numeri senza una componente decimale. In Python, possono essere creati assegnando un valore senza parte decimale a una variabile. Esempio di un numero intero √®:\n\nage = 20\n\n\n\n2.5.3 Numeri in Virgola Mobile (Float)\nI numeri in virgola mobile, o ‚Äúfloat‚Äù, rappresentano numeri che hanno una componente decimale. Sono creati assegnando un valore con una parte decimale a una variabile. Esempio di un numero float √®:\n\ntemperature = 36.4\n\nI numeri in virgola mobile, o ‚Äúfloat‚Äù, hanno una precisione limitata a circa 15-16 cifre decimali; oltre questo limite, la precisione viene persa. Nonostante questa limitazione, sono sufficienti per la maggior parte delle applicazioni.\nInoltre, √® possibile utilizzare la notazione scientifica per rappresentare numeri molto grandi o molto piccoli. In questa notazione, m * 10^n viene comunemente abbreviato come mEn, dove ‚ÄúE‚Äù rappresenta l‚Äôesponente dieci. Ad esempio, 1E9 equivale a un miliardo (\\(1 \\times 10^9\\)) e 1E-9 rappresenta un miliardesimo (\\(1 \\times 10^{-9}\\)).\n\n\n2.5.4 Valori Booleani (Boolean)\nI valori booleani possono assumere solo due stati: vero (True) o falso (False). Sono utilizzati per rappresentare le condizioni logiche e sono ottenuti attraverso espressioni di confronto. Esempio di un valore booleano √®:\n\nis_raining = False\n\nNel contesto delle operazioni aritmetiche, True √® equivalente al numero intero 1, mentre False corrisponde a 0. Questo permette di includere valori booleani in calcoli matematici. Per esempio:\n\nTrue + True + False\n\n2\n\n\nUn valore booleano viene ritornato quando si valuta un confronto. Per esempio:\n\n3 &gt; 1 + 1\n\nIl valore True indica che il confronto √® valido; Python ha confermato questo semplice fatto sulla relazione tra 3 e 1+1.\nSi noti la regola di precedenza: gli operatori &gt;, &lt;, &gt;=, &lt;=, ==, != hanno la precedenza pi√π bassa (vengono valutati per ultimi), il che significa che nell‚Äôespressione precedente viene prima valutato (1 + 1) e poi (3 &gt; 2).\n\n\n2.5.5 Operatori di confronto\nUn operatore di confronto √® un operatore che esegue un qualche tipo di confronto e restituisce un valore booleano (True oppure False). Per esempio, l‚Äôoperatore == confronta le espressioni su entrambi i lati e restituisce True se hanno gli stessi valori e False altrimenti. L‚Äôopposto di == √® !=, che si pu√≤ leggere come ‚Äònon uguale al valore di‚Äô. Gli operatori di confronto sono elencati qui sotto:\n\n\n\nConfronto\nOperatore\n\n\n\n\nMinore\n&lt;\n\n\nMaggiore\n&gt;\n\n\nMinore o uguale\n&lt;=\n\n\nMaggiore o uguale\n&gt;=\n\n\nUguale\n==\n\n\nNon uguale\n!=\n\n\n\nAd esempio:\n\na = 4\nb = 2\n\nprint(\"a &gt; b\", \"is\", a &gt; b)\nprint(\"a &lt; b\", \"is\", a &lt; b)\nprint(\"a == b\", \"is\", a == b)\nprint(\"a &gt;= b\", \"is\", a &gt;= b)\nprint(\"a &lt;= b\", \"is\", a &lt;= b)\n\nNella cella seguente si presti attenzione all‚Äôuso di = e di ==:\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nL‚Äôoperatore = √® un‚Äôistruzione di assegnazione. Ovvero, crea un nuovo oggetto. L‚Äôoperatore == valuta invece una condizione logica e ritorna un valore booleano.\nUn‚Äôespressione pu√≤ contenere pi√π confronti e tutti devono essere veri affinch√© l‚Äôintera espressione sia vera. Ad esempio:\n\n1 &lt; 1 + 1 &lt; 3\n\n\n\n2.5.6 Tipizzazione Dinamica in Python\nPython √® un linguaggio con tipizzazione dinamica, il che significa che il tipo di una variabile √® determinato dal valore che le viene assegnato durante l‚Äôesecuzione del programma e non necessita di essere dichiarato esplicitamente.\nPer identificare il tipo di una variabile o del risultato di un‚Äôespressione, Python mette a disposizione la funzione type(). Questa funzione, quando chiamata con una variabile o un‚Äôespressione come argomento, restituisce il tipo di dati corrispondente.\nNell‚Äôesempio seguente il programma stamper√† &lt;class 'str'&gt;, indicando che x √® una variabile di tipo ‚Äústringa‚Äù.\n\nx = \"hello\"\nprint(type(x))\n\n&lt;class 'str'&gt;\n\n\nApplichiamo la funzione type() alle altre variabili che abbiamo definito in precedenza.\n\nage = 20\nprint(type(age))\n\n&lt;class 'int'&gt;\n\n\n\ntemperature = 36.4\nprint(type(temperature))\n\n&lt;class 'float'&gt;\n\n\n\nis_raining = False\nprint(type(is_raining))\n\n&lt;class 'bool'&gt;\n\n\n\n\n2.5.7 Operatori Booleani\nGli operatori booleani (o operatori logici) confrontano espressioni (non valori) e ritornano un valore booleano. Python ha tre operatori logici:\n\nand ‚Äì Ritorna True solo se entrambi le espressioni sono vere, altrimenti ritorna False\nor ‚Äì Ritorna True se almeno una delle due espressioni √® vera, altrimenti ritorna False.\nnot ‚Äì Ritorna True se l‚Äôespressione √® falsa, altrimenti ritorna False.\n\nAd esempio:\n\na = 2\nb = 3\n\n(a + b &gt; a) and (a + b &gt; b)\n\nTrue\n\n\nNella cella sopra le parentesi tonde sono opzionali ma facilitano la lettura.\nL‚Äôoperatore and restituisce True solo se entrambe le condizioni booleane sono vere. Ad esempio, True and False restituir√† False perch√© una delle condizioni √® falsa:\n\nTrue and False\n\nFalse\n\n\nL‚Äôoperatore or restituisce True se almeno una delle due condizioni booleane √® vera. Ad esempio, True or False restituir√† True perch√© almeno una delle condizioni √® vera.\n\nTrue or False\n\nTrue\n\n\nL‚Äôoperatore not viene utilizzato per invertire il valore di verit√† di una condizione booleana. Ad esempio, not True restituir√† False e not False restituir√† True.\n\nnot True\n\nFalse\n\n\nAlcuni esempi sono i seguenti (si noti l‚Äôuso della funzione len()):\n\nprint(3 &gt; 2)  # True, because 3 is greater than 2\nprint(3 &gt;= 2)  # True, because 3 is greater than 2\nprint(3 &lt; 2)  # False,  because 3 is greater than 2\nprint(2 &lt; 3)  # True, because 2 is less than 3\nprint(2 &lt;= 3)  # True, because 2 is less than 3\nprint(3 == 2)  # False, because 3 is not equal to 2\nprint(3 != 2)  # True, because 3 is not equal to 2\nprint(len(\"mango\") == len(\"avocado\"))  # False\nprint(len(\"mango\") != len(\"avocado\"))  # True\nprint(len(\"mango\") &lt; len(\"avocado\"))  # True\nprint(len(\"milk\") != len(\"meat\"))  # False\nprint(len(\"milk\") == len(\"meat\"))  # True\nprint(len(\"tomato\") == len(\"potato\"))  # True\nprint(len(\"python\") &gt; len(\"dragon\"))  # False\n\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\nAltri esempi di come questi operatori possono essere utilizzati sono i seguenti:\n\nprint(3 &gt; 2 and 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 and 4 &lt; 3)  # False - because the second statement is false\nprint(3 &lt; 2 and 4 &lt; 3)  # False - because both statements are false\nprint(\"True and True: \", True and True)\nprint(3 &gt; 2 or 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 or 4 &lt; 3)  # True - because one of the statements is true\nprint(3 &lt; 2 or 4 &lt; 3)  # False - because both statements are false\nprint(\"True or False:\", True or False)\nprint(not 3 &gt; 2)  # False - because 3 &gt; 2 is true, then not True gives False\nprint(not True)  # False - Negation, the not operator turns true to false\nprint(not False)  # True\nprint(not not True)  # True\nprint(not not False)  # False\n\nTrue\nFalse\nFalse\nTrue and True:  True\nTrue\nTrue\nFalse\nTrue or False: True\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\nAbbiamo tralasciato alcuni operatori in Python. Due di quelli che abbiamo omesso sono gli operatori di appartenenza, in e not in. Gli altri operatori che abbiamo tralasciato sono gli operatori bitwise e gli operatori sugli insiemi, che verranno trattati in seguito.\n\n\n2.5.8 Valori Numerici di True e False\n√à fondamentale comprendere i valori numerici associati alle parole chiave True e False. Queste due parole chiave hanno i valori numerici di 1 e 0, rispettivamente.\n\nTrue == 1\n\nTrue\n\n\n\nFalse == 0\n\nTrue\n\n\n\nTrue + False\n\n1\n\n\n\ntype(True + False)\n\nint",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#sequenze",
    "href": "chapters/python/01_python_1.html#sequenze",
    "title": "2¬† Python (1)",
    "section": "2.6 Sequenze",
    "text": "2.6 Sequenze\nOltre ai numeri e ai valori booleani, Python supporta anche un insieme di ‚Äúcontenitori‚Äù, ovvero i seguenti tipi strutturati:\n\nle liste,\nle tuple,\ngli insiemi,\ni dizionari.\n\n\n2.6.1 Le tuple\nUna tupla √® una collezione di diversi tipi di dati che √® ordinata e immutabile (non modificabile). Le tuple sono scritte tra parentesi tonde, (). Una volta creata una tupla, non √® possibile modificarne i contenuti.\n\ncolors = (\"Rosso\", \"Nero\", \"Bianco\")\ncolors\n\n('Rosso', 'Nero', 'Bianco')\n\n\n\ntype(colors)\n\ntuple\n\n\nLe stringhe sono tuple di caratteri. Pertanto non sono modificabili.\n\n\n2.6.2 Le liste\nGli oggetti di tipo lista sono simili alle tuple, ma con alcune differenze. La lista √® un oggetto mutabile, il che significa che possiamo aggiungere o rimuovere elementi dalla lista anche dopo la sua creazione. Una lista viene creata separando i suoi elementi tramite virgola e racchiudendo il tutto tra parentesi quadre.\nSi noti che una lista √® una struttura dati eterogenea contentente una sequenza di elementi che possono essere di tipo diverso.\n\nmy_list = [\"Pippo\", 3, -2.953, [1, 2, 3]]\nmy_list\n\n['Pippo', 3, -2.953, [1, 2, 3]]\n\n\n\ntype(my_list)\n\nlist\n\n\nLa lista my_list √® composta da diversi elementi: una stringa (‚ÄúPippo‚Äù), un numero intero (3), un numero decimale (-2.953) e un‚Äôaltra lista ([1, 2, 3]).\nGli elementi nella lista sono ordinati in base all‚Äôindice, il quale rappresenta la loro posizione all‚Äôinterno della lista. Gli indici delle liste partono da 0 e aumentano di uno. Per accedere a un elemento della lista tramite il suo indice, si utilizza la notazione delle parentesi quadre: nome_lista[indice]. Ad esempio:\n\nmy_list[1]\n\n3\n\n\n\nmy_list[0]\n\n'Pippo'\n\n\nPython prevede alcune funzioni che elaborano liste, come per esempio len che restituisce il numero di elementi contenuti in una lista:\n\nlen(my_list)\n\n4\n\n\nBench√© questa lista contenga come elemento un‚Äôaltra lista, tale lista nidificata conta comunque come un singolo elemento. La lunghezza di di my_list √® quattro.\nUna lista vuota si crea nel modo seguente:\n\nempty_list = []\nlen(empty_list)\n\n0\n\n\nEcco alcuni esempi.\n\nfruits = [\"banana\", \"orange\", \"mango\", \"lemon\"]  # list of fruits\nvegetables = [\"Tomato\", \"Potato\", \"Cabbage\", \"Onion\", \"Carrot\"]  # list of vegetables\n\nprint(\"Fruits:\", fruits)\nprint(\"Number of fruits:\", len(fruits))\nprint(\"Vegetables:\", vegetables)\nprint(\"Number of vegetables:\", len(vegetables))\n\nFruits: ['banana', 'orange', 'mango', 'lemon']\nNumber of fruits: 4\nVegetables: ['Tomato', 'Potato', 'Cabbage', 'Onion', 'Carrot']\nNumber of vegetables: 5\n\n\nSupponiamo di voler ordinare in ordine alfabetico i nomi presenti nella lista. Per fare ci√≤, √® necessario utilizzare il metodo sort sulla lista utilizzando la notazione con il punto (dot notation):\n\nnames = [\"Carlo\", \"Giovanni\", \"Giacomo\"]\nnames.sort()\n\nTale metodo per√≤ non restituisce alcun valore, in quanto l‚Äôordinamento √® eseguito in place: dopo l‚Äôinvocazione, gli elementi della lista saranno stati riposizionati nell‚Äôordine richiesto. Visualizziamo la listra trasformata:\n\nnames\n\n['Carlo', 'Giacomo', 'Giovanni']\n\n\nL‚Äôinvocazione di metodi (e di funzioni) prevede anche la possibilit√† di specificare degli argomenti opzionali. Per esempio:\n\nnames.sort(reverse=True)\nnames\n\n['Giovanni', 'Giacomo', 'Carlo']\n\n\nIl metodo remove() pu√≤ essere usato per rimuovere elementi da una lista.\n\nprint(fruits)\nfruits.remove(\"banana\")\nprint(fruits)\n\n['banana', 'orange', 'mango', 'lemon']\n['orange', 'mango', 'lemon']\n\n\nIl metodo insert() pu√≤ essere usato per aggiungere elementi ad una lista.\n\nprint(fruits)\nfruits.insert(2, \"watermelon\")\nprint(fruits)\n\n['orange', 'mango', 'lemon']\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n√à possibile copiare una lista in una nuova variabile:\n\nprint(fruits)\nnew_fruits = fruits.copy()\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\nprint(new_fruits)\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\n\n2.6.3 Operazioni su liste\nL‚Äôoperatore + concatena liste:\n\na = [1, 2, 3]\nb = [4, 5, 6]\nc = a + b\nprint(c)\n\n[1, 2, 3, 4, 5, 6]\n\n\nIn maniera simile, l‚Äôoperatore * ripete una lista un certo numero di volte:\n\n[0] * 4\n\n[0, 0, 0, 0]\n\n\n\n[1, 2, 3] * 3\n\n[1, 2, 3, 1, 2, 3, 1, 2, 3]\n\n\nL‚Äôaspetto importante da considerare √® che, essendo una sequenza di elementi eterogenei, √® difficile eseguire operazioni algebriche sulle liste in Python puro. Ad esempio, consideriamo la seguente lista:\n\nx = [1, 2, 3]\nx\n\n[1, 2, 3]\n\n\nSe desideriamo calcolare una semplice operazione, come la media di x, √® necessario seguire una procedura abbastanza articolata. Ad esempio:\n\ntotal = 0\ncounter = 0\n\nfor num in x:\n    counter += 1\n    total += num\n\navg = total / counter\n\nprint(avg)\n\n2.0\n\n\nIndubbiamente, sarebbe preferibile ottenere questo risultato con un approccio pi√π semplice. In seguito, vedremo che se utilizziamo una sequenza di elementi omogenei, il problema pu√≤ essere risolto in modo molto pi√π agevole. Ad esempio,\n\nimport numpy as np\n\nx = np.array([1, 2, 3])\nnp.mean(x)\n\n2.0\n\n\nPossiamo contare il numero degli elementi specificati che sono contenuti in una lista usando count().\n\nages = [22, 19, 24, 25, 26, 24, 25, 24]\nprint(ages.count(24))         \n\n3\n\n\nPossiamo trovare l‚Äôindice di un elemento in una lista con index().\n\nages.index(24)  # index of the first occurrence\n\n2\n\n\n\n\n2.6.4 Operatore slice\nL‚Äôoperatore di slice (:) applicato alle liste in Python consente di estrarre una porzione specifica di elementi dalla lista. L‚Äôoperatore di slice ha la seguente sintassi: lista[inizio:fine:passo].\n\ninizio rappresenta l‚Äôindice di partenza dell‚Äôintervallo (inclusivo).\nfine rappresenta l‚Äôindice di fine dell‚Äôintervallo (esclusivo).\npasso rappresenta il passo o l‚Äôincremento tra gli indici degli elementi selezionati (facoltativo).\n\nEcco alcuni esempi per illustrare l‚Äôutilizzo dell‚Äôoperatore di slice:\n\nlista = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# Estrarre una porzione della lista\nporzione = lista[2:6]  # [3, 4, 5, 6]\n\n# Estrarre una porzione con un passo specifico\nporzione_passo = lista[1:9:2]  # [2, 4, 6, 8]\n\n# Estrarre una porzione dalla fine della lista\nporzione_fine = lista[6:]  # [7, 8, 9, 10]\n\n# Estrarre una porzione dall'inizio della lista\nporzione_inizio = lista[:5]  # [1, 2, 3, 4, 5]\n\n\n\n2.6.5 Gli insiemi\nGli insiemi sono collezioni finite di elementi distinti e non memorizzati in un ordine specifico. Un insieme non pu√≤ contenere pi√π di un‚Äôistanza dello stesso elemento. Per creare un insieme si utilizzano le parentesi graffe {}. Ad esempio:\n\nmy_set = {\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"}\nmy_set\n\n{'A', 'B', 'C', 'D', 'E', 'F'}\n\n\n\ntype(my_set)\n\nset\n\n\nGli oggetti di tipo ‚Äúset‚Äù sono utili per eseguire operazioni matematiche sugli insiemi.\nPer verificare se un elemento esiste in un insieme usiamo l‚Äôoperatore in.\n\nprint(\"Does set my_set contain D? \", \"D\" in my_set)\n\nDoes set my_set contain D?  True\n\n\nL‚Äôunione di due insieme si ottiene con union().\n\nfruits = {\"banana\", \"orange\", \"mango\", \"lemon\"}\nvegetables = {\"tomato\", \"potato\", \"cabbage\", \"onion\", \"carrot\"}\nprint(fruits.union(vegetables))\n\n{'carrot', 'onion', 'lemon', 'mango', 'tomato', 'potato', 'banana', 'cabbage', 'orange'}\n\n\nL‚Äôintersezione di due insieme si trova con intersection().\n\npython = {\"p\", \"y\", \"t\", \"h\", \"o\", \"n\"}\ndragon = {\"d\", \"r\", \"a\", \"g\", \"o\", \"n\"}\npython.intersection(dragon)\n\n{'n', 'o'}\n\n\nUn insieme pu√≤ essere un sottoinsieme o un sovrainsieme di altri insiemi.\nPer verificare se un insieme √® un sottoinsieme di un altro, si utilizza il metodo issubset(). Per verificare se un insieme √® un sovrainsieme di un altro, si utilizza il metodo issuperset().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.issubset(st1)\n\nTrue\n\n\n\nst1.issuperset(st2) \n\nTrue\n\n\nLa differenza tra due insiemi si ottiene con difference().\n\nwhole_numbers = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\neven_numbers = {0, 2, 4, 6, 8, 10}\nwhole_numbers.difference(even_numbers)\n\n{1, 3, 5, 7, 9}\n\n\nPossiamo verificare se due insiemi sono disgiunti, ovvero non hanno elementi in comune, utilizzando il metodo isdisjoint().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.isdisjoint(st1)\n\nFalse\n\n\n\n\n2.6.6 I dizionari\nGli oggetti di tipo ‚Äúdizionario‚Äù vengono utilizzati per creare coppie chiave-valore, dove ogni chiave √® unica. Un dizionario viene creato specificando ogni coppia come chiave : valore, separando le diverse coppie con una virgola e racchiudendo il tutto tra parentesi graffe. Ad esempio:\n\nmusic = {\n    \"blues\": \"Betty Smith\",\n    \"classical\": \"Gustav Mahler\",\n    \"pop\": \"David Bowie\",\n    \"jazz\": \"John Coltrane\",\n}\n\nL‚Äôaccesso agli elementi di un dizionario viene fatto specificando all‚Äôinterno di parentesi quadre la chiave per ottenere o modificare il valore corrispondente:\n\nmusic[\"pop\"]\n\n'David Bowie'\n\n\nPer trovare il numero di coppie key: value nel dizionario usiamo len().\n\nprint(len(music))\n\n4\n\n\n\nmusic[\"new music\"] = \"Missy Mazzoli\"\nprint(music)\n\n{'blues': 'Betty Smith', 'classical': 'Gustav Mahler', 'pop': 'David Bowie', 'jazz': 'John Coltrane', 'new music': 'Missy Mazzoli'}\n\n\n\n\n2.6.7 Contenitori vuoti\nA volte √® utile creare dei contenitori vuoti. I comandi per creare liste vuote, tuple vuote, dizionari vuoti e insiemi vuoti sono rispettivamente lst = [], tup=(), dic={} e st = set().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "2¬† Python (1)",
    "section": "2.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "2.7 Informazioni sull‚ÄôAmbiente di Sviluppo\nAlla fine di ogni capitolo e, in effetti, alla fine (o all‚Äôinizio) di qualsiasi notebook che creiamo, √® utile includere informazioni sull‚Äôambiente di calcolo, compresi i numeri di versione di tutti i pacchetti che utilizziamo. Il pacchetto watermark pu√≤ essere usato per questo scopo. Il pacchetto watermark contiene comandi speciali ed √® un‚Äôestensione di IPython. In generale, per utilizzare tali comandi speciali, li precediamo con il segno % o %% in una cella. Utilizziamo la funzione speciale built-in %load_ext per caricare watermark, e quindi utilizziamo %watermark per invocarlo.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 24 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\nEcco una spiegazione dettagliata delle opzioni che sono state utilizzate nell‚Äôistruzione precedente.\n\n-n o --datename: Aggiunge la data e l‚Äôora correnti al watermark. Questo pu√≤ essere utile per mantenere una cronologia delle modifiche o delle esecuzioni del notebook.\n-u o --updated: Mostra l‚Äôultima volta in cui il notebook √® stato salvato. √à utile per tenere traccia delle modifiche recenti apportate al notebook.\n-v o --python: Mostra la versione di Python utilizzata nel kernel del notebook. Questo √® importante per garantire la compatibilit√† del codice e replicare gli ambienti di lavoro.\n-iv o --iversions: Visualizza le versioni delle librerie importate nel notebook. √à fondamentale per la replicabilit√† degli esperimenti e degli analisi, dato che diverse versioni delle librerie possono comportare risultati diversi.\n-w o --watermark: Aggiunge il watermark stesso, che √® semplicemente il logo ‚Äúwatermark‚Äù. √à pi√π una questione estetica che funzionale.\n-m o --machine: Fornisce informazioni sulla macchina su cui viene eseguito il Jupyter Notebook, come il tipo di sistema operativo e l‚Äôarchitettura della macchina (ad esempio, x86_64). Questo pu√≤ essere utile per documentare l‚Äôambiente hardware in cui vengono eseguiti gli esperimenti.\n\nQueste opzioni forniscono un modo semplice e immediato per documentare e tracciare importanti metadati nei notebook Jupyter.\n\n\n\n\nMarr, David. 2010. Vision: A computational investigation into the human representation and processing of visual information. MIT press.\n\n\nMatter, Ulrich. 2025. Data Analysis with AI and R. 1st Edition. New York, NY: Manning Publications.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html",
    "href": "chapters/python/02_python_2.html",
    "title": "3¬† Python (2)",
    "section": "",
    "text": "3.1 Funzioni\nLo scopo delle funzioni √® raggruppare il codice in un formato organizzato, leggibile e riutilizzabile, contribuendo cos√¨ a ridurre la ridondanza del codice.\nUna regola generale per le funzioni √® che dovrebbero essere di piccole dimensioni e svolgere un‚Äôunica operazione.\nNella programmazione, una funzione accetta un input, esegue operazioni su di esso e pu√≤ restituire un output. Python mette a disposizione un‚Äôampia gamma di funzioni integrate, e si pu√≤ anche importare funzioni da pacchetti aggiuntivi o definirne di nuove.\nPer definire una nuova funzione in Python, si utilizza la parola chiave def, seguita dal nome della funzione e dai nomi simbolici dei suoi argomenti, separati da virgole e racchiusi tra parentesi. La definizione continua con i due punti (:) e il corpo della funzione, le cui istruzioni devono essere indentate. Il valore restituito dalla funzione viene specificato tramite la parola chiave return, generalmente nella riga finale del corpo della funzione.\ndef add_numbers(a, b):\n    \"\"\"\n    returns the sum of the two numeric arguments\n    \"\"\"\n    the_sum = a + b\n    return the_sum\nUna volta definita una funzione, √® possibile eseguirla chiamandola e passando gli argomenti appropriati. Ad esempio, possiamo chiamare la funzione add_numbers per sommare due numeri, come ad esempio 20 e 10:\nadd_numbers(20, 10)\n\n30\nConsideriamo la funzione roll_die():\nimport random\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return random.choice([1, 2, 3, 4, 5, 6])\nIl corpo della funzione √® composto da una singola riga di codice che utilizza la funzione choice() della libreria random, a cui viene passata una lista. Questo significa che una funzione pu√≤ utilizzare altre funzioni che sono gi√† state definite. In questo caso, la funzione si limita a specificare l‚Äôargomento da passare a choice(). La funzione choice() restituir√† un numero casuale tra quelli specificati in input. Pertanto, la funzione roll_die() simula il lancio di un dado:\nroll_die()\n\n6\nroll_die()\n\n5\nSi noti inoltre la docstring, cio√® una stringa (in genere racchiusa tra ‚Äú‚Äú‚Äú‚Ä¶‚Äù‚Äú‚Äú) che si trova come prima istruzione all‚Äôinterno di una funzione. La docstring contiene informazioni sullo scopo e sulle modalit√† d‚Äôuso della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#funzioni",
    "href": "chapters/python/02_python_2.html#funzioni",
    "title": "3¬† Python (2)",
    "section": "",
    "text": "3.1.1 Introspection\nUsando un punto interrogativo (?) prima o dopo una variabile √® possibile visualizzare alcune informazioni generale su quell‚Äôoggetto. Nel caso di una funzione viene stampata la doc string.\n\nroll_die?\n\nSignature: roll_die()\nDocstring: returns a random int between 1 and 6\nFile:      /var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_13125/63164766.py\nType:      function\n\n\n\n\n3.1.2 Metodi\nLe funzioni definite all‚Äôinterno di una classe, chiamate ‚Äúmetodi‚Äù, rappresentano operazioni specifiche che possono essere eseguite sugli oggetti di quella classe. Una classe √® una struttura concettuale che rappresenta un concetto o un oggetto nel contesto del problema che stiamo affrontando. Ad esempio, nel capitolo sull‚Äôintroduzione a Pandas, lavorando con dati organizzati in una tabella, utilizziamo un oggetto chiamato DataFrame, appartenente alla classe ‚Äúpandas.DataFrame‚Äù. Un DataFrame √® una struttura tabellare che contiene dati disposti in righe e colonne.\nI metodi specifici della classe DataFrame offrono funzionalit√† per manipolare e analizzare i dati in questa struttura. Per esempio, il metodo ‚Äúhist()‚Äù genera istogrammi dei valori presenti in una colonna specifica del DataFrame. Per invocare un metodo su un oggetto DataFrame, come ‚Äúdf‚Äù, utilizziamo la sintassi ‚Äúnome_oggetto.nome_metodo()‚Äù e possiamo passare eventuali parametri richiesti tra parentesi.\nD‚Äôaltra parte, gli attributi rappresentano le caratteristiche o le propriet√† degli oggetti di una classe. Gli attributi possono essere richiamati utilizzando la sintassi ‚Äúnome_oggetto.nome_attributo‚Äù e restituiscono un valore specifico associato a quell‚Äôoggetto. Per esempio, l‚Äôattributo ‚Äú.shape‚Äù applicato a un DataFrame come ‚Äúdf.shape‚Äù restituisce il numero di righe e colonne presenti nel DataFrame.\nIn sintesi, una classe definisce un tipo di oggetto che ha attributi che ne descrivono le caratteristiche e metodi che rappresentano le azioni eseguibili su di esso. Gli attributi forniscono informazioni specifiche sull‚Äôoggetto, mentre i metodi consentono di effettuare operazioni e manipolazioni sui dati contenuti nell‚Äôoggetto stesso.\n\n\n3.1.3 La funzione lambda\nPython offre una sintassi alternativa che consente di definire funzioni ‚Äúinline‚Äù, cio√® in una singola linea di codice. Queste funzioni, chiamate funzioni anonime, non richiedono una definizione esplicita poich√© vengono utilizzate solo nel punto in cui sono dichiarate. Per creare una funzione anonima, utilizziamo la parola chiave lambda, seguita da un elenco di argomenti separati da virgole, due punti ‚Äú:‚Äù e l‚Äôespressione che definisce il comportamento della funzione basandosi sugli argomenti forniti.\nlambda argomento1, argomento2, ... : espressione\nQuesta sintassi permette di creare funzioni semplici ed espressive in modo conciso.\nNell‚Äôesempio seguente, la funzione somma 1 al valore passato come input:\n\n(lambda x : x + 1)(2)\n\n3\n\n\nQuando eseguiamo (lambda x : x + 1)(2), avviene quanto segue:\n\nL‚Äôinterprete Python definisce la funzione lambda lambda x : x + 1.\nLa funzione lambda viene immediatamente chiamata con l‚Äôargomento 2.\nAll‚Äôinterno della funzione lambda, x viene sostituito da 2, quindi l‚Äôespressione x + 1 diventa 2 + 1.\nLa funzione lambda restituisce 3.\n\nQuindi, il risultato dell‚Äôespressione (lambda x : x + 1)(2) √® 3.\nIn sintesi, la funzione lambda (lambda x : x + 1) definisce una funzione che aggiunge 1 al suo argomento. Quando la chiamiamo con l‚Äôargomento 2, otteniamo 3 come risultato.\nIn questo secondo esempio sommiamo i due numeri in entrata:\n\n(lambda x, y: x + y)(2, 3)\n\n5\n\n\nLa sintassi seguente √® valida in quanto, per l‚Äôinterprete, il carattere _ corrisponde all‚Äôultima funzione che √® stata valutata:\n\nlambda x, y: x + y\n\n&lt;function __main__.&lt;lambda&gt;(x, y)&gt;\n\n\n\n_(20, 10)\n\n30\n\n\nSi noti che abbiamo valutato la funzione lambda x, y: x + y in una cella precedente a quella che contiene _(20, 10); inserendo le due espressioni in una singola cella si ottiene un SyntaxError.\n\n\n3.1.4 Le funzioni map() e filter()\nPer gli esercizi che svolgeremo in seguito, risultano utili le funzioni map() e filter().\nLa funzione map() prende come input una funzione e una lista, e restituisce il risultato dell‚Äôapplicazione della funzione a ciascun elemento della lista (√® anche possibile usare qualsiasi oggetto iterabile al posto della lista). La lista stessa rimane invariata. Ad esempio, la seguente linea di codice eleva al quadrato ciascuno degli elementi della lista a e salva il risultato nella lista b:\n\na = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nb = list(map(lambda x: x * x, a))\nb\n\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n\n\nUn‚Äôaltra funzione molto utile per manipolare gli oggetti iterabili √® la funzione filter(). Questa funzione filtra un oggetto iterabile selezionando solo gli elementi che rispondono ad un determinato predicato. (Il predicato √® una funzione che restituisce un booleano). Per esempio\n\nc = list(filter(lambda x: x &gt; 50, b))\nc\n\n[64, 81, 100]\n\n\nSia map() che filter() restituiscono risultati che non sono ancora stati calcolati.\n\nfilter(lambda x: x &gt; 50, b)\n\n&lt;filter at 0x171da9720&gt;\n\n\nPossiamo visualizzare il risultato convertendolo in una lista:\n\nlist(filter(lambda x: x &gt; 50, b))\n\n[64, 81, 100]\n\n\n\n\n3.1.5 La funzione zip()\nLa funzione zip() crea una lista di tuple dagli elementi di due contenitori. Come nel caso delle operazioni precedenti, gli elementi vengono calcolati solo quando viene richiesto. Per esempio:\n\na = list(range(4))\na\n\n[0, 1, 2, 3]\n\n\n\nb = list(range(4, 8))\nb\n\n[4, 5, 6, 7]\n\n\n\nb = zip(a, b)\nb\n\n&lt;zip at 0x172034f80&gt;\n\n\n\nlist(b)\n\n[(0, 4), (1, 5), (2, 6), (3, 7)]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#il-flusso-di-esecuzione",
    "href": "chapters/python/02_python_2.html#il-flusso-di-esecuzione",
    "title": "3¬† Python (2)",
    "section": "3.2 Il flusso di esecuzione",
    "text": "3.2 Il flusso di esecuzione\nIn Python il codice viene eseguito sequenzialmente, partendo dalla prima riga fino a quando non c‚Äô√® pi√π nulla da eseguire. L‚Äôordine di esecuzione delle varie istruzioni √® detto flusso di esecuzione.\nPer esempio la cella seguente prima memorizza la lista names, poi la lista born e infine la lista dead.\n\nnames = [\"Sigmund Freud\", \"Jean Piaget\", \"Burrhus Frederic Skinner\", \"Albert Bandura\"]\nborn = [1856, 1896, 1904, 1925]\ndead = [1939, 1980, 1990, None]\n\nHo usato il valore speciale None in quanto non risulta disponibile l‚Äôanno. In queste situazioni si parla di valori mancanti (missing values) che, di norma, vengono indicati con la sigla NA (not available).\nLa cella seguente include le istruzioni condizionali che specificano se e quando devono essere eseguiti determinati blocchi di codice. La pi√π semplice istruzione di controllo √® l‚Äôistruzione if. Per esempio:\n\nname = \"Maria\"\ngrade = 29\n\nif name == \"Maria\" and grade &gt; 28:\n    print(\"Maria, hai ottenuto un ottimo voto all'esame!\")\n\nif name == \"Giovanna\" or grade &gt; 28:\n    print(\n        \"Tu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\"\n    )\n\nif name != \"Giovanna\" and grade &gt; 28:\n    print(\"Tu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\")\n\nMaria, hai ottenuto un ottimo voto all'esame!\nTu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\nTu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\n\n\nTutte e tre le condizioni precedenti ritornano True, quindi vengono stampati tutti e tre i messaggi.\nSi noti che == e != confrontano valori, mentre is e not confrontano oggetti. Per esempio,\n\nname_list = [\"Maria\", \"Giovanna\"]\nname_list_two = [\"Marco\", \"Francesco\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nFalse\nFalse\n\n\nUna delle parole chiave condizionali pi√π utili √® in. Un esempio √® il seguente:\n\nname_list = [\"Maria\", \"Giovanna\", \"Marco\", \"Francesco\"]\n\nprint(\"Giovanna\" in name_list)\nprint(\"Luca\" in name_list)\n\nTrue\nFalse\n\n\nLa condizione opposta √® not in.\n\nprint(\"Luca\" not in name_list)\n\nTrue\n\n\nFacciamo un altro esempio.\n\nage = 26\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\n\nSei maggiorenne\n\n\nPython dispone di un‚Äôespressione ternaria che introduce la potenza dell‚Äôistruzione ‚Äòelse‚Äô in una sintassi concisa:\n\nage = 26\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei maggiorenne\n\n\n\nage = 16\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei minorenne\n\n\nUna struttura di selezione leggermente pi√π complessa √® ‚Äúif-else‚Äù. La sintassi di questa struttura √® la seguente:\nif &lt;condizione&gt;:\n    &lt;istruzione_se_condizione_vera&gt;\nelse:\n    &lt;istruzione_se_condizione_falsa&gt;\nLa semantica di ‚Äúif-else‚Äù √® quella che ci si aspetta: la condizione tra la parola chiave if e il carattere di due punti viene valutata: se risulta vera viene eseguita l‚Äôistruzione alla linea seguente, altrimenti viene eseguita l‚Äôistruzione dopo la parola chiave else. Anche in questo caso l‚Äôindentazione permette di identificare quali istruzioni devono essere eseguite nei due rami della selezione. Per esempio:\n\nage = 16\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\nelse:\n    print(\"Sei minorenne\")\n\nSei minorenne\n\n\nIn presenza di pi√π di due possibilit√† mutuamente esclusive ed esaustive possiamo usare l‚Äôistruzione elif. Per esempio:\n\ncfu = 36\nthesis_defense = False\n\nif cfu &gt;= 180 and thesis_defense == True:\n    print(\"Puoi andare a festeggiare!\")\nelif cfu &gt;= 180 and thesis_defense == False:\n    print(\"Devi ancora superare la prova finale!\")\nelse:\n    print(\"Ripassa tra qualche anno!\")\n\nRipassa tra qualche anno!\n\n\n\n3.2.1 Commenti\nIn Python √® possibile usare il carattere # per aggiungere commenti al codice. Ogni riga di commento deve essere preceduta da un #. I commenti non devono spiegare il metodo (cosa fa il codice: quello si vede), ma bens√¨ lo scopo: quello che noi intendiamo ottenere. I primi destinatari dei commenti siamo noi stessi tra un po‚Äô di tempo, ovvero quando ci saremo dimenticati cosa avevamo in mente quando abbiamo scritto il codice.\n\n# This is a comment and will not be executed.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#cicli",
    "href": "chapters/python/02_python_2.html#cicli",
    "title": "3¬† Python (2)",
    "section": "3.3 Cicli",
    "text": "3.3 Cicli\nUn ciclo √® un modo per eseguire una porzione di codice pi√π di una volta. I cicli sono fondamentali nei linguaggi di programmazione. Come molti altri linguaggi di programmazione, Python ha due tipi di cicli per gestire tutte le proprie necessit√† di iterazione: il ciclo ‚Äúwhile‚Äù e il ciclo ‚Äúfor‚Äù.\n\n3.3.1 Il ciclo while\nil ciclo while permette l‚Äôesecuzione di un blocco di codice finch√© una determinata condizione √® True. Per esempio:\n\ncounter = 0\n\nwhile counter &lt;= 10:\n    print(counter)\n    counter += 1\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nIl codice counter += 1 √® equivalente a counter = counter + 1 e, ogni qualvolta viene eseguito il ciclo, riassegna alla variabile counter il valore che aveva in precedenza + 1.\nL‚Äôistruzione while controlla se alla variabile counter √® associato un valore minore o uguale a 10. Nel primo passo del ciclo la condizione √® soddisfatta, avendo noi definito counter = 0, pertanto il programma entra nel loop, stampa il valore della variabile counter e incrementa counter di un‚Äôunit√†.\nQuesto comportamento si ripete finch√© la condizione counter &lt;= 10 risulta True. Quando il contatore counter assume il valore 11 il ciclo while si interrompe e il blocco di codice del ciclo non viene pi√π eseguito.\n\n\n3.3.2 Il ciclo for\nIl ciclo for √® un costrutto di controllo di flusso che viene utilizzato per iterare su una sequenza di valori, come ad esempio una lista, una tupla, una stringa o un dizionario.\nLa sintassi generale di un ciclo for in Python √® la seguente:\nfor element in sequence:\n    # codice da eseguire\nDove element √® una variabile temporanea che assume il valore di ciascun elemento della sequenza ad ogni iterazione del ciclo, e sequence √® la sequenza di valori su cui iterare.\nDurante l‚Äôesecuzione del ciclo, il blocco di codice indentato sotto la linea for viene eseguito una volta per ogni elemento della sequenza. Ad ogni iterazione, la variabile elemento assume il valore dell‚Äôelemento corrente della sequenza e il codice all‚Äôinterno del blocco viene eseguito con questo valore.\nIl ciclo for √® spesso utilizzato per eseguire operazioni su ciascun elemento di una sequenza, come ad esempio la somma degli elementi di una lista o la stampa di ciascun carattere di una stringa. Per esempio\n\nnumbers = [0, 1, 2, 3, 4, 5]\nfor number in numbers: # number is temporary name to refer to the list's items, valid only inside this loop\n    print(number)\n\n0\n1\n2\n3\n4\n5\n\n\n\nlanguage = \"Python\"\nfor letter in language:\n    print(letter)\n\nP\ny\nt\nh\no\nn\n\n\nLa funzione range() √® spesso usata nei cicli for e permette di impostare un intervallo di esecuzione tanto ampio quanto il numero che le passiamo come parametro meno uno.\nLa funzione range() prende tre parametri: start (default 0), stop e step (default 1), ovvero un punto di inizio dell‚Äôintervallo, un punto di fine e un passo di avanzamento. L‚Äôindicizzazione Python parte da 0; quindi range(0, 11, 1) una lista di 11 elementi, da 0 a 10 inclusi.\n\nprint(list(range(0, 11, 1)))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nAd esempio, impostiamo un punto di inizio a 3, il punto di fine a 11 e un passo di 2:\n\nprint(list(range(3, 12, 2)))\n\n[3, 5, 7, 9, 11]\n\n\nIn un ciclo for, l‚Äôintervallo di range() corrisponde al numero di iterazioni che verranno eseguite, ovvero al numero di volte che il ciclo verr√† processato. Nel caso seguente, l‚Äôindice del ciclo (qui chiamato number) assume il valore 0 la prima volta che il ciclo viene eseguito e il valore 10 nell‚Äôultima esecuzione del ciclo.\n\nfor number in range(11):\n    print(number)\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\nfor number in range(3, 12, 2):\n    print(number)\n\n3\n5\n7\n9\n11\n\n\n\n3.3.2.1 Cicli for annidati\nSono possibili i cicli for annidati, vale a dire un ciclo posto all‚Äôinterno del corpo di un altro (chiamato ciclo esterno). Al suo primo passo, il ciclo esterno mette in esecuzione quello interno che esegue il proprio blocco di codice fino alla conclusione. Quindi, al secondo passo, il ciclo esterno rimette in esecuzione quello interno. Questo si ripete finch√© il ciclo esterno non termina. Per esempio:\n\nfor i in range(4):\n    for j in range(4):\n        print((i, j))\n\n(0, 0)\n(0, 1)\n(0, 2)\n(0, 3)\n(1, 0)\n(1, 1)\n(1, 2)\n(1, 3)\n(2, 0)\n(2, 1)\n(2, 2)\n(2, 3)\n(3, 0)\n(3, 1)\n(3, 2)\n(3, 3)\n\n\n\n\n3.3.2.2 Modificare gli elementi di una lista\nIl ciclo for √® il modo pi√π comune per scorrere gli elementi di una lista, come abbiamo visto in precedenza.\n\nfor name in name_list:\n    print(name)\n\nMaria\nGiovanna\nMarco\nFrancesco\n\n\nQuesto approccio pu√≤ essere usato se abbiamo solo bisogno di leggere gli elementi della lista. Nel ciclo seguente, ad esempio, leggiamo gli elementi d una lista per incrementare una variabile cos√¨ da calcolare una somma.\n\nnumbers = [2, -4, 1, 6, 3]\n\ntotal = 0\nfor num in numbers:\n    total += num\n\nprint(total)\n\n8\n\n\nMa se vogliamo cambiare gli elementi di una lista l‚Äôapproccio precedente non funziona e dobbiamo usare gli indici. Nell‚Äôesempio seguente, questo risultato viene ottenuto utilizzando le funzioni range e len:\n\nnumbers = [2, -4, 1, 6, 3]\n\nfor i in range(len(numbers)):\n    numbers[i] = numbers[i] * 2\n\nprint(numbers)\n\n[4, -8, 2, 12, 6]\n\n\nNel codice seguente, la funzione len() ritorna 5.\n\nnumbers = [2, -4, 1, 6, 3]\nlen(numbers)\n\n5\n\n\nQuindi, range(5) produce la seguente sequenza iterabile:\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]\n\n\nQuesti sono gli indici che verranno usati nelle iterazioni del ciclo for.\n\nLa prima volta che il ciclo viene eseguito, l‚Äôindice i vale 0 e numbers[i] si riferisce al primo elemento della lista;\nla seconda volta che il ciclo viene eseguito, i vale 1 e numbers[i] si riferisce al secondo elemento della lista;\ne cos√¨ via.\n\nL‚Äôistruzione di assegnazione nel corpo del ciclo for usa i per leggere il valore i-esimo della lista originale (a destra dell‚Äôuguale) e per assegnargli un nuovo valore (a sinistra dell‚Äôuguale).\n\n\n\n3.3.3 List comprehension\nUna list comprehension √® un modo conciso di creare una lista. √à un modo compatto per creare una nuova lista. Accade speso di dover creare una lista dove ciascun elemento √® il risultato di un‚Äôoperazione condotta sugli elementi di un‚Äôaltra lista o di un iterabile; oppure, di dover estrarre gli elementi che soddisfano una certa condizione. Per esempio, supponiamo di volere sommare una costante ad una lista di numeri. Usando un ciclo for possiamo procedere nel modo seguente (si noti l‚Äôuso della funzione append):\n\nnew_list = []\nk = 10\nfor x in range(10):\n    new_list.append(x + k)\n\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nOppure, in maniera pi√π semplice, possiamo usare una list comprehension:\n\nnew_list = [x + k for x in range(10)]\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nUna list comprehension √® racchiusa tra parentesi quadre; contiene un‚Äôespressione, seguita da una clausola for, seguita da zero o pi√π clausole for o if. La sintassi √® la seguente:\n[ &lt;expression&gt; for item in iterable &lt;if optional_condition&gt; ]\nIl risultato √® una nuova lista costruita valutando l‚Äôespressione nel contesto delle clausole for e if che la seguono. Una list comprehension combina dunque un ciclo for e (se necessario) una o pi√π condizioni logiche in una singola riga di codice. Esaminiamo una variante dell‚Äôesempio precedente.\n\nlist1 = [1, 2, 3, 4, 5, 6]\nprint(\"list1:\", list1)\n\nlist1: [1, 2, 3, 4, 5, 6]\n\n\n\nlist2 = [item + 1 for item in list1]\nprint(\"list2:\", list2)\n\nlist2: [2, 3, 4, 5, 6, 7]\n\n\nSi noti che la parola item avrebbe potuto essere quasi qualsiasi stringa (in precedenza abbiamo usato x). La possiamo immaginare con la seguente definizione: ...per ogni elemento in .... Nel seguente esempio, sommiamo 1 agli elementi di list1 solo se sono pari:\n\nlist3 = [item + 1 for item in list1 if item % 2 == 0] \nprint('list3:', list3)\n\nlist3: [3, 5, 7]\n\n\nFacciamo un altro esempio usando range():\n\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n\nQui selezioniamo solo i numeri pari (oltre allo zero):\n\n[i for i in range(11) if i % 2 == 0]\n\n[0, 2, 4, 6, 8, 10]\n\n\nSpecificando una condizione, possiamo cambiare il segno solo dei numeri dispari nella lista:\n\n[-i if i % 2 else i for i in range(11)]\n\n[0, -1, 2, -3, 4, -5, 6, -7, 8, -9, 10]\n\n\nPossiamo anche eseguire pi√π iterazioni simultaneamente:\n\n[(i, j) for i in range(3) for j in range(4)]\n\n[(0, 0),\n (0, 1),\n (0, 2),\n (0, 3),\n (1, 0),\n (1, 1),\n (1, 2),\n (1, 3),\n (2, 0),\n (2, 1),\n (2, 2),\n (2, 3)]\n\n\nIn questo esempio vengono selezionati solo i nomi inclusi nella lista female_names:\n\nfirst_names = [\"Maria\", \"Marco\", \"Francesco\", \"Giovanna\"]\nfemale_names = [\"Alice\", \"Maria\", \"Giovanna\", \"Lisa\"]\nfemale_list = [name for name in first_names if name in female_names]\nprint(female_list)\n\n['Maria', 'Giovanna']\n\n\nNel seguente esempio vengono estratte le prime tre lettere di ciascuno dei nomi che compongono una lista:\n\nletters = [name[0:3] for name in first_names] \nletters\n\n['Mar', 'Mar', 'Fra', 'Gio']\n\n\nPer estrarre l‚Äôultimo carattere di una stringa usiamo [-1]:\n\nmy_string = \"barbabl√π\"\nmy_string[-1]\n\n'√π'\n\n\nPossiamo dunque usare seguente list comprehension estrae gli ultimi tre caratteri di ciascun elemento della lista first_names.\n\nletters = [name[-3:] for name in first_names] \nletters\n\n['ria', 'rco', 'sco', 'nna']\n\n\n√à possibile impiegare un‚Äôespressione ternaria all‚Äôinterno di una list comprehension per sfruttare la versatilit√† dell‚Äôistruzione ‚Äòelse‚Äô in modo sintatticamente efficace. Ad esempio, possiamo sostituire tutti i numeri dispari di una lista (un un NumPy array) con il valore 99.\n\nnum = np.array([4, 7, 2, 6, 3, 9])  # pu√≤ anche essere una lista Python\n[e if e % 2 == 0 else 99 for e in num]\n\n[4, 99, 2, 6, 99, 99]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#librerie-e-moduli",
    "href": "chapters/python/02_python_2.html#librerie-e-moduli",
    "title": "3¬† Python (2)",
    "section": "3.4 Librerie e moduli",
    "text": "3.4 Librerie e moduli\n\n3.4.1 Importare moduli\nI moduli (anche conosciuti come librerie in altri linguaggi) sono dei file usati per raggruppare funzioni e altri oggetti. Python include una lista estensiva di moduli standard (anche conosciuti come Standard Library), ma √® anche possibile scaricarne o definirne di nuovi. Prima di potere utilizzare le funzioni non presenti nella Standard Library all‚Äôinterno dei nostri programmi dobbiamo importare dei moduli aggiuntivi, e per fare ci√≤ usiamo il comando import.\nL‚Äôimportazione pu√≤ riguardare un intero modulo oppure solo uno (o pi√π) dei suoi elementi. Consideriamo per esempio la funzione mean. Essa √® disponibile nel modulo numpy. L‚Äôistruzione import numpy importa tutto il modulo numpy. Dopo che un modulo √® stato importato, √® possibile accedere a un suo generico elemento usando il nome del modulo, seguito da un punto e dal nome dell‚Äôelemento in questione. Ad esempio, numpy.mean().\nIndicare il nome di un modulo per poter accedere ai suoi elementi ha spesso l‚Äôeffetto di allungare il codice, diminuendone al contempo la leggibilit√†. √à per questo motivo che √® possibile importare un modulo specificando un nome alternativo, pi√π corto. √à quello che succede quando scriviamo l‚Äôistruzione import numpy as np. In questo caso, l‚Äôistruzione precedente diventa np.mean().\nI moduli pi√π complessi sono organizzati in strutture gerarchiche chiamate package. La seguente cella importa il modulo pyplot che √® contenuto nel package matplotlib (matplotlib √® la libreria di riferimento in Python per la creazione di grafici).\n\nimport matplotlib.pyplot as plt\n\nQui di seguito sono descritte tutte le possibilit√†:\n\n# import everything from library\nimport random\n# call function by\nrandom.random()\n\n0.16777284588756924\n\n\n\n#import everything, but change name\nimport random as rnd\n# call function by\nrnd.random()\n\n0.05690270000491682\n\n\n\n# select what to import from library\nfrom random import random\n#call function by\nrandom()\n\n0.037974565142151695\n\n\n\n# import everything from library\nfrom random import *\n# call function by\nrandom()\n\n0.20988431417194764\n\n\nNella cella seguente importiamo seaborn con il nome sns e usiamo le sue funzionalit√† per impostare uno stile e una palette di colori per la visualizzazione dei grafici.\n\nimport seaborn as sns\nsns.set_theme()\nsns.set_palette(\"colorblind\")\n\nNell‚Äôesempio seguente calcoliamo la somma degli elementi della lista numerica primes usando funzione sum() contenuta nella libreria NumPy che abbiamo importato con il nome di np:\n\nimport numpy as np\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nnp.sum(primes)\n\n42\n\n\nCalcolo la media di primes:\n\nnp.mean(primes)\n\n6.0\n\n\nScriviamo una nuova funzione per la media, \\(\\bar{x} = n^{-1}\\sum_{i=1}^n x_i\\):\n\ndef my_mean(x):\n    res = np.sum(x) / len(x)\n    return res\n\n\nmy_mean(primes)\n\n6.0\n\n\nSi noti che, nel corpo di una funzione, √® possibile usare altre funzioni: qui, np.sum() e len().\n√à sempre possibile usare la funzione di help su una funzione:\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n    \n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\nIn Visual Studio Code √® sufficiente posizionare il cursore sul nome della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#formattazione-del-codice",
    "href": "chapters/python/02_python_2.html#formattazione-del-codice",
    "title": "3¬† Python (2)",
    "section": "3.5 Formattazione del codice",
    "text": "3.5 Formattazione del codice\n\njwxhixq ../images/code_quality_2x.png :align: center",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "3¬† Python (2)",
    "section": "3.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "3.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.1.4\nnumpy     : 1.26.2\nseaborn   : 0.13.0\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html",
    "href": "chapters/python/03_numpy.html",
    "title": "4¬† NumPy",
    "section": "",
    "text": "4.1 Preparazione del Notebook\nimport numpy as np",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "href": "chapters/python/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "title": "4¬† NumPy",
    "section": "4.2 Utilizzo degli Array nel Modulo NumPy",
    "text": "4.2 Utilizzo degli Array nel Modulo NumPy\nIn Python standard, abbiamo a disposizione tipi di dati numerici (come numeri interi e decimali) e strutture come liste, dizionari e insiemi. NumPy, d‚Äôaltro canto, introduce un nuovo tipo di struttura dati: l‚Äôarray N-dimensionale, noto come ndarray. Questi array hanno alcune caratteristiche distintive:\n\nDimensioni: Gli ndarray possono variare nel numero di dimensioni, definite come ‚Äúassi‚Äù. Ad esempio, un array pu√≤ essere unidimensionale (simile a un vettore lineare), bidimensionale (come una matrice o una tabella), tridimensionale (simile a un cubo), e cos√¨ via.\nTipo di Dato: A differenza delle liste in Python standard che possono contenere diversi tipi di dati, ogni elemento all‚Äôinterno di un ndarray deve essere dello stesso tipo, come numeri interi, decimali, booleani o stringhe.\nForma: La ‚Äúforma‚Äù di un ndarray si riferisce alle sue dimensioni, ovvero quante righe, colonne o altri livelli di profondit√† ha. Per esempio, la forma (3, 4) indica un array con 3 righe e 4 colonne.\nIndicizzazione: Gli ndarray possono essere indicizzati in modo simile agli array standard di Python, ma offrono anche opzioni pi√π avanzate per l‚Äôindicizzazione.\n\nGli ndarray sono potenti per manipolare e analizzare i dati, grazie alle loro funzioni e metodi che includono operazioni matematiche e statistiche, trasformazioni e altre manipolazioni dei dati.\nTerminologia Importante: - Size: Indica il numero totale di elementi in un array. - Rank: Si riferisce al numero di dimensioni, o assi, di un array. - Shape: Denota le dimensioni specifiche dell‚Äôarray, ovvero una sequenza di numeri che rappresentano il conteggio degli elementi in ogni dimensione.\nCome Creare un ndarray: Il modo pi√π diretto per creare un ndarray √® attraverso la conversione di una lista Python. Ad esempio, √® possibile creare un array unidimensionale (1-D) a partire da una lista standard di Python.\n\nx = np.array([1, 2, 3, 4, 5, 6])\n\nL‚Äôistruzione precedente crea un array in NumPy, assegnandolo alla variabile x. Questo array √® un vettore unidimensionale contenente sei elementi, che sono i numeri interi specificati all‚Äôinterno delle parentesi quadre.\n\nprint(x)\n\n[1 2 3 4 5 6]\n\n\nIndicizzazione\nSe vogliamo estrarre un singolo elemento del vettore lo indicizziamo con la sua posizione (si ricordi che l‚Äôindice inizia da 0):\n\nx[0]\n\n1\n\n\n\nx[2]\n\n3\n\n\nUn array 2-D si crea nel modo seguente:\n\ny = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nEstraiamo un singolo elemento dall‚Äôarray:\n\ny[0, 2]\n\n3\n\n\nEstraiamo la seconda riga dall‚Äôarray:\n\ny[1]\n\narray([5, 6, 7, 8])\n\n\nEstraiamo la seconda colonna dall‚Äôarray:\n\ny[:, 1] \n\narray([ 2,  6, 10])\n\n\nLa sintassi con i due punti √® chiamata ‚Äúslicing‚Äù dell‚Äôarray.\n\n# Display the first row of the array\nprint(\"Displaying the first row:\")\nprint(y[0, :])\n\nDisplaying the first row:\n[1 2 3 4]\n\n\n\n# Show the last two elements in the first row\nprint(\"Showing the last two elements in the first row:\")\nprint(y[0, -2:])\n\nShowing the last two elements in the first row:\n[3 4]\n\n\n\n# Retrieve every second element in the first row\nprint(\"Retrieving every second element in the first row:\")\nprint(y[0, ::2])\n\nRetrieving every second element in the first row:\n[1 3]\n\n\n\n# Extract a submatrix from the original array\nprint(\"Extracting a submatrix:\")\nprint(y[:2, 1:3])\n\nExtracting a submatrix:\n[[2 3]\n [6 7]]\n\n\n\n4.2.1 Funzioni per ndarray\nNumpy offre varie funzioni per creare ndarray. Per esempio, √® possibile creare un array 1-D con la funzione .arange(start, stop, incr, dtype=..) che fornisce l‚Äôintervallo di numeri compreso fra start, stop, al passo incr:\n\nz = np.arange(2, 9, 2)\nprint(z)\n\n[2 4 6 8]\n\n\nSi usa spesso .arange per creare sequenze a incrementi unitari:\n\nw = np.arange(11)\nprint(w)\n\n[ 0  1  2  3  4  5  6  7  8  9 10]\n\n\nUn‚Äôaltra funzione molto utile √® .linspace:\n\nx = np.linspace(0, 10, num=20)\nprint(x)\n\n[ 0.          0.52631579  1.05263158  1.57894737  2.10526316  2.63157895\n  3.15789474  3.68421053  4.21052632  4.73684211  5.26315789  5.78947368\n  6.31578947  6.84210526  7.36842105  7.89473684  8.42105263  8.94736842\n  9.47368421 10.        ]\n\n\nFissati gli estremi (qui 0, 10) e il numero di elementi desiderati, .linspace determina in maniera automatica l‚Äôincremento.\nUna propriet√† molto utile dei ndarray √® la possibilit√† di filtrare gli elementi di un array che rispondono come True ad un criterio. Per esempio:\n\nprint(x[x &gt; 7])\n\n[ 7.36842105  7.89473684  8.42105263  8.94736842  9.47368421 10.        ]\n\n\nperch√© solo gli ultimi sei elementi di x rispondono True al criterio \\(x &gt; 7\\).\nLe dimensioni (‚Äúassi‚Äù) di un ndarray vengono ritornate dal metodo .dim. Per esempio:\n\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\ny.ndim\n\n2\n\n\n\nprint(y.max(axis=1))\n\n[ 4  8 12]\n\n\n\nprint(y.max(axis=0))\n\n[ 9 10 11 12]\n\n\nIl numero di elementi per ciascun asse viene ritornato dal metodo .shape:\n\ny.shape\n\n(3, 4)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#manipolazione-di-array-con-numpy",
    "href": "chapters/python/03_numpy.html#manipolazione-di-array-con-numpy",
    "title": "4¬† NumPy",
    "section": "4.3 Manipolazione di Array con NumPy",
    "text": "4.3 Manipolazione di Array con NumPy\nNumPy rende pi√π agevole lavorare con grandi quantit√† di dati. Un concetto fondamentale in NumPy sono gli array monodimensionali, spesso utilizzati per rappresentare vettori, ovvero sequenze di numeri che possono rappresentare, ad esempio, le misurazioni di una variabile specifica. Grazie a NumPy, possiamo eseguire operazioni aritmetiche su questi vettori in modo semplice, applicando la stessa operazione a tutti gli elementi dell‚Äôarray contemporaneamente.\n\n4.3.1 Cosa Significa Vettorizzare un‚ÄôOperazione\nLa vettorizzazione √® una delle funzionalit√† pi√π efficaci di NumPy. Quando diciamo che un‚Äôoperazione √® vettorizzata, significa che questa operazione viene applicata in un colpo solo a tutti gli elementi dell‚Äôarray, invece di dover agire su ciascun elemento individualmente. Questo approccio rende la manipolazione di grandi insiemi di dati non solo pi√π veloce ma anche pi√π intuitiva, poich√© consente di trattare l‚Äôintero insieme di dati come un‚Äôunica entit√† anzich√© come una serie di punti dati individuali.\nSupponiamo di avere raccolto i dati di 4 individui\n\nm = np.array([1.62, 1.75, 1.55, 1.74])\nkg = np.array([55.4, 73.6, 57.1, 59.5])\n\nprint(m)\nprint(kg)\n\n[1.62 1.75 1.55 1.74]\n[55.4 73.6 57.1 59.5]\n\n\ndove m √® l‚Äôarray che contiene i dati relativi all‚Äôaltezza in metri dei quattro individui e kg √® l‚Äôarray che contiene i dati relativi al peso in kg. I dati sono organizzati in modo tale che il primo elemento di entrambi i vettori si riferisce alle misure del primo individuo, il secondo elemento dei due vettori si riferisce alle misure del secondo individuo, ecc.\nSupponiamo di volere calcolare l‚Äôindice BMI:\n\\[\nBMI = \\frac{kg}{m^2}.\n\\]\nPer il primo individuo del campione, l‚Äôindice di massa corporea √®\n\n55.4 / 1.62**2\n\n21.109586953208346\n\n\nSi noti che non abbiamo bisogno di scrivere 55.4 / (1.62**2) in quanto, in Python, l‚Äôelevazione a potenza viene eseguita prima della somma e della divisione (come in tutti i linguaggi). Usando i dati immagazzinati nei due vettori, lo stesso risultato si ottiene nel modo seguente:\n\nkg[0] / m[0]**2\n\n21.109586953208346\n\n\nSe ora non specifichiamo l‚Äôindice (per esempio, [0]), le operazioni aritmetiche indicate verranno eseguite per ciascuna coppia di elementi corrispondenti nei due vettori:\n\nbmi = kg / m**2\n\nOtteniamo cos√¨, con una sola istruzione, l‚Äôindice BMI dei quattro individui:\n\nbmi.round(1)\n\narray([21.1, 24. , 23.8, 19.7])\n\n\nQuesto esempio illustra come le operazioni aritmetiche standard vengano eseguite elemento per elemento negli array, grazie al processo di vettorizzazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#broadcasting",
    "href": "chapters/python/03_numpy.html#broadcasting",
    "title": "4¬† NumPy",
    "section": "4.4 Broadcasting",
    "text": "4.4 Broadcasting\nIl broadcasting √® una caratteristica distintiva di NumPy che facilita l‚Äôesecuzione di operazioni tra array di dimensioni diverse o tra un array e uno scalare, anche se le loro dimensioni non sono direttamente compatibili. Grazie al broadcasting, NumPy √® in grado di ‚Äúespandere‚Äù automaticamente le dimensioni di uno degli operandi per rendere possibile l‚Äôoperazione.\nQuesto significa che possiamo, per esempio, eseguire un‚Äôoperazione tra un array e un numero singolo (un vettore e uno scalare) o tra due array di dimensioni differenti, senza la necessit√† di modificare manualmente le dimensioni di questi array. Il broadcasting si occupa di adattare le dimensioni in modo coerente per consentire l‚Äôoperazione desiderata. Ci√≤ rende il codice pi√π snello e leggibile, eliminando la necessit√† di espandere gli array manualmente.\nIn breve, il broadcasting in NumPy √® un potente strumento che semplifica l‚Äôesecuzione di operazioni su array di dimensioni diverse o tra array e scalari, automatizzando l‚Äôallineamento delle dimensioni.\n\n4.4.1 Esempio di Broadcasting\nImmaginiamo di avere un array A con dimensioni 3x3 e un numero scalare B. Senza broadcasting, dovremmo espandere B in un array 3x3 riempiendo ogni cella con il valore di B per eseguire un‚Äôoperazione come l‚Äôaddizione su ciascun elemento di A. Grazie al broadcasting, possiamo semplicemente scrivere A + B, e NumPy si occuper√† automaticamente di ‚Äúespandere‚Äù B durante l‚Äôoperazione, applicando il valore scalare a ogni elemento di A.\n\n# Creiamo un array 3x3\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Definiamo uno scalare\nB = 5\n\n# Applichiamo il broadcasting per aggiungere lo scalare a ogni elemento dell'array\nC = A + B\n\nprint(C)\n\n[[ 6  7  8]\n [ 9 10 11]\n [12 13 14]]\n\n\nIn questo esempio, C conterr√† l‚Äôarray originale A con ogni elemento incrementato di 5, dimostrando come il broadcasting semplifichi operazioni che altrimenti richiederebbero passaggi aggiuntivi.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#altre-operazioni-sugli-array",
    "href": "chapters/python/03_numpy.html#altre-operazioni-sugli-array",
    "title": "4¬† NumPy",
    "section": "4.5 Altre operazioni sugli array",
    "text": "4.5 Altre operazioni sugli array\nC‚Äô√® un numero enorme di funzioni predefinite in NumPy che calcolano automaticamente diverse quantit√† sugli ndarray. Ad esempio:\n\nmean(): calcola la media di un vettore o matrice;\nsum(): calcola la somma di un vettore o matrice;\nstd(): calcola la deviazione standard;\nmin(): trova il minimo nel vettore o matrice;\nmax(): trova il massimo;\nndim: dimensione del vettore o matrice;\nshape: restituisce una tupla con la ‚Äúforma‚Äù del vettore o matrice;\nsize: restituisce la dimensione totale del vettore (=ndim) o della matrice;\ndtype: scrive il tipo numpy del dato;\nzeros(num): scrive un vettore di num elementi inizializzati a zero;\narange(start,stop,step): genera un intervallo di valori (interi o reali, a seconda dei valori di start, ecc.) intervallati di step. Nota che i dati vengono generati nell‚Äôintervallo aperto [start,stop)!\nlinstep(start,stop,num): genera un intervallo di num valori interi o reali a partire da start fino a stop (incluso!);\nastype(tipo): converte l‚Äôndarray nel tipo specificato\n\nPer esempio:\n\nx = np.array([1, 2, 3])\nprint(x)\n\n[1 2 3]\n\n\n\n[x.min(), x.max(), x.sum(), x.mean(), x.std()]\n\n[1, 3, 6, 2.0, 0.816496580927726]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#lavorare-con-formule-matematiche",
    "href": "chapters/python/03_numpy.html#lavorare-con-formule-matematiche",
    "title": "4¬† NumPy",
    "section": "4.6 Lavorare con formule matematiche",
    "text": "4.6 Lavorare con formule matematiche\nL‚Äôimplementazione delle formule matematiche sugli array √® un processo molto semplice con Numpy. Possiamo prendere ad esempio la formula della deviazione standard che discuteremo nel capitolo {ref}loc-scale-notebook:\n\\[\ns = \\sqrt{\\sum_{i=1}^n\\frac{(x_i - \\bar{x})^2}{n}}\n\\]\nL‚Äôimplementazione su un array NumPy √® la seguente:\n\nprint(x)\n\n[1 2 3]\n\n\n\nnp.sqrt(np.sum((x - np.mean(x)) ** 2) / np.size(x))\n\n0.816496580927726\n\n\nQuesta implementazione funziona nello stesso modo sia che x contenga 3 elementi (come nel caso presente) sia che x contenga migliaia di elementi. √à importante notare l‚Äôutilizzo delle parentesi tonde per specificare l‚Äôordine di esecuzione delle operazioni. In particolare, nel codice fornito, si inizia calcolando la media degli elementi del vettore x per mezzo della funzione np.mean(x). Questa operazione produce uno scalare, ovvero un singolo valore numerico che rappresenta la media degli elementi del vettore. L‚Äôutilizzo delle parentesi tonde √® fondamentale per garantire l‚Äôordine corretto delle operazioni. In questo caso, la funzione np.mean() viene applicata al vettore x prima di qualsiasi altra operazione matematica. Senza le parentesi tonde, le operazioni verrebbero eseguite in un ordine diverso e il risultato potrebbe essere errato.\n\nnp.mean(x)\n\n2.0\n\n\nSuccessivamente, eseguiamo la sottrazione dei singoli elementi del vettore x per la media del vettore stesso, ovvero \\(x_i - \\bar{x}\\), utilizzando il meccanismo del broadcasting.\n\nx - np.mean(x)\n\narray([-1.,  0.,  1.])\n\n\nEleviamo poi al quadrato gli elementi del vettore che abbiamo ottenuto:\n\n(x - np.mean(x)) ** 2\n\narray([1., 0., 1.])\n\n\nSommiamo gli elementi del vettore:\n\nnp.sum((x - np.mean(x)) ** 2)\n\n2.0\n\n\nDividiamo il numero ottenuto per \\(n\\). Questa √® la varianza di \\(x\\):\n\nres = np.sum((x - np.mean(x)) ** 2) / np.size(x)\nres\n\n0.6666666666666666\n\n\nInfine, per ottenere la deviazione standard, prendiamo la radice quadrata:\n\nnp.sqrt(res)\n\n0.816496580927726\n\n\nIl risultato ottenuto coincide con quello che si trova applicando la funzione np.std():\n\nnp.std(x)\n\n0.816496580927726",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#slicing",
    "href": "chapters/python/03_numpy.html#slicing",
    "title": "4¬† NumPy",
    "section": "4.7 Slicing",
    "text": "4.7 Slicing\nPer concludere, spendiamo ancora alcune parole sull‚Äôindicizzazione degli ndarray.\nSlicing in Numpy √® un meccanismo che consente di selezionare una porzione di un array multidimensionale, ovvero una sotto-matrice o un sotto-vettore. Per selezionare una porzione di un array, si utilizza la sintassi [start:stop:step], dove start indica l‚Äôindice di partenza della porzione, stop indica l‚Äôindice di fine e step indica il passo da utilizzare per la selezione. Se uno o pi√π di questi valori vengono omessi, vengono utilizzati dei valori di default.\nAd esempio, se abbiamo un array arr di dimensione (3, 4) e vogliamo selezionare la seconda colonna, possiamo usare la sintassi arr[:, 1]. In questo caso, il simbolo : indica che vogliamo selezionare tutte le righe, mentre il numero 1 indica che vogliamo selezionare la seconda colonna.\nInoltre, possiamo utilizzare il meccanismo di slicing anche per selezionare porzioni di array multidimensionali. Ad esempio, se abbiamo un array arr di dimensione (3, 4, 5) e vogliamo selezionare la prima riga di ciascuna matrice 4x5, possiamo usare la sintassi arr[:, 0, :].\nPer esempio, creiamo l‚Äôarray x di rango 2 con shape (3, 4):\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nUtilizziamo il meccanismo di slicing per estrarre la sottomatrice composta dalle prime 2 righe e dalle colonne 1 e 2. y √® l‚Äôarray risultante di dimensione (2, 2):\n\ny = x[:2, 1:3]\nprint(y)\n\n[[2 3]\n [6 7]]\n\n\n√à importante sapere che uno slice di un array in Numpy √® una vista degli stessi dati, il che significa che modificarlo implica la modifica dell‚Äôarray originale. In pratica, quando si modifica uno slice di un array, si sta modificando direttamente l‚Äôarray originale e tutte le altre visualizzazioni dell‚Äôarray vedranno la stessa modifica. Questo avviene perch√© Numpy √® progettato per gestire enormi quantit√† di dati, pertanto cerca di evitare il pi√π possibile di effettuare copie dei dati.\nQuesto comportamento deve essere preso in considerazione durante la modifica degli array in Numpy, al fine di evitare modifiche accidentali o indesiderate. In alcuni casi, √® possibile utilizzare il metodo copy() per creare una copia indipendente di un array e lavorare sulla copia senza modificare l‚Äôoriginale. Vediamo un esempio.\n\nprint(x[0, 1])   \n\n2\n\n\n\ny[0, 0] = 77     \n\n\nprint(x)\n\n[[ 1 77  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nz = x.copy()\nprint(z)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nz[0, 1] = 33\nprint(z)\n\n[[ 1 33  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#copia-e-copia-profonda-in-python",
    "href": "chapters/python/03_numpy.html#copia-e-copia-profonda-in-python",
    "title": "4¬† NumPy",
    "section": "4.8 Copia e ‚ÄúCopia Profonda‚Äù in Python",
    "text": "4.8 Copia e ‚ÄúCopia Profonda‚Äù in Python\nIn Python, per ottimizzare le prestazioni, le assegnazioni di solito non copiano gli oggetti sottostanti. Questo √® particolarmente importante, ad esempio, quando gli oggetti vengono passati tra funzioni, per evitare una quantit√† eccessiva di copie in memoria quando non sono necessarie (questo approccio √® noto tecnicamente come ‚Äúpassaggio per riferimento‚Äù).\nConsideriamo il seguente esempio con un array A:\n\nA = np.array([[1, 2], [3, 4]])\n\nSe creiamo un nuovo riferimento B a A:\n\nB = A\n\nOra B si riferisce allo stesso insieme di dati di A. Se modifichiamo B, anche A viene modificato di conseguenza:\n\nB[0,0] = 10\n\nDopo questa modifica, sia B che A saranno:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nSe desideriamo evitare questo comportamento, in modo tale che B diventi un oggetto completamente indipendente da A, dobbiamo effettuare una cosiddetta ‚Äúcopia profonda‚Äù utilizzando la funzione copy:\n\nB = np.copy(A)\n\nOra, se modificassimo B, A non subirebbe alcuna modifica. Ad esempio:\n\nB[0,0] = -5\n\nA questo punto, B sar√†:\n\nprint(B)\n\n[[-5  2]\n [ 3  4]]\n\n\nMa A rimarr√† invariato:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nQuesto esempio mostra chiaramente la differenza tra una semplice assegnazione, che crea un riferimento all‚Äôoggetto originale, e una ‚Äúcopia profonda‚Äù, che crea un nuovo oggetto indipendente.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "title": "4¬† NumPy",
    "section": "4.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "4.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy: 1.26.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html",
    "href": "chapters/python/04_pandas.html",
    "title": "5¬† Pandas (1)",
    "section": "",
    "text": "5.1 Preparazione del NoteBook\nimport pandas as pd\nimport numpy as np\n\n# Di default, Pandas mostrer√† 60 righe e 20 colonne. \n# Modifichiamo qui le impostazioni di visualizzazione predefinite di Pandas per mostrare pi√π righe.\npd.options.display.max_rows = 100",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#series",
    "href": "chapters/python/04_pandas.html#series",
    "title": "5¬† Pandas (1)",
    "section": "5.2 Series",
    "text": "5.2 Series\nIn Pandas, una Series √® un array unidimensionale composto da una sequenza di valori omogenei, simile ad un ndarray, accompagnato da un array di etichette chiamato ‚Äúindex‚Äù. A differenza degli indici degli array Numpy, che sono sempre interi e partono da zero, gli oggetti Series supportano etichette personalizzate che possono essere, ad esempio, delle stringhe. Inoltre, gli oggetti Series possono contenere dati mancanti che vengono ignorati da molte delle operazioni della classe.\nIl modo pi√π semplice di creare un oggetto Series √® di convertire una lista. Per esempio:\n\ngrades = pd.Series([27, 30, 24, 18, 22, 20, 29])\n\n√à possibile ottenere la rappresentazione dell‚Äôarray dell‚Äôoggetto e dell‚Äôindice dell‚Äôoggetto Series tramite i suoi attributi array e index, rispettivamente.\n\ngrades.array\n\n&lt;NumpyExtensionArray&gt;\n[27, 30, 24, 18, 22, 20, 29]\nLength: 7, dtype: int64\n\n\n\ngrades.index\n\nRangeIndex(start=0, stop=7, step=1)\n\n\nOppure, possiamo semplicemente stampare i contenuti dell‚Äôoggetto Series direttamente:\n\nprint(grades)\n\n0    27\n1    30\n2    24\n3    18\n4    22\n5    20\n6    29\ndtype: int64\n\n\nPer accedere agli elementi di un oggetto Series si usano le parentesi quadre contenenti un indice:\n\ngrades[0]\n\n27\n\n\n\ngrades[0:3]\n\n0    27\n1    30\n2    24\ndtype: int64\n\n\n√à possibile filtrare gli elementi di un oggetto Series con un array booleano:\n\ngrades &gt; 24\n\n0     True\n1     True\n2    False\n3    False\n4    False\n5    False\n6     True\ndtype: bool\n\n\n\ngrades[grades &gt; 24]\n\n0    27\n1    30\n6    29\ndtype: int64\n\n\n√à possibile manipolare gli elementi di un oggetto Series con le normali operazioni aritmetiche mediante la vettorializzazione:\n\ngrades / 10\n\n0    2.7\n1    3.0\n2    2.4\n3    1.8\n4    2.2\n5    2.0\n6    2.9\ndtype: float64\n\n\n\nnp.sqrt(grades)\n\n0    5.196152\n1    5.477226\n2    4.898979\n3    4.242641\n4    4.690416\n5    4.472136\n6    5.385165\ndtype: float64\n\n\nGli oggetti Series hanno diversi metodi per svolgere varie operazioni, per esempio per ricavare alcune statistiche descrittive:\n\n[grades.count(), grades.mean(), grades.min(), grades.max(), grades.std(), grades.sum()]\n\n[7, 24.285714285714285, 18, 30, 4.572172558506722, 170]\n\n\nMolto utile √® il metodo .describe():\n\ngrades.describe()\n\ncount     7.000000\nmean     24.285714\nstd       4.572173\nmin      18.000000\n25%      21.000000\n50%      24.000000\n75%      28.000000\nmax      30.000000\ndtype: float64",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#dataframe",
    "href": "chapters/python/04_pandas.html#dataframe",
    "title": "5¬† Pandas (1)",
    "section": "5.3 DataFrame",
    "text": "5.3 DataFrame\nUn pandas.DataFrame √® composto da righe e colonne. Ogni colonna di un dataframe √® un oggetto pandas.Series: quindi, un dataframe √® una collezione di serie. A differenza di un array NumPy, un dataframe pu√≤ combinare pi√π tipi di dati, come numeri e testo, ma i dati in ogni colonna sono dello stesso tipo.\nEsistono molti modi per costruire un DataFrame. Un primo metodo √® quello di utilizzare un dizionario che include una o pi√π liste o array Numpy di uguale lunghezza. Per esempio:\n\ndata = {\n    \"name\": [\n        \"Maria\",\n        \"Anna\",\n        \"Francesco\",\n        \"Cristina\",\n        \"Gianni\",\n        \"Gabriella\",\n        \"Stefano\",\n    ],\n    \"sex\": [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"],\n    \"group\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"],\n    \"x\": [1, 2, 3, 4, 5, 6, 7],\n    \"y\": [8, 9, 10, 11, 12, 13, 14],\n    \"z\": [15, 16, 17, 18, 19, 20, 21],\n}\nframe = pd.DataFrame(data)\nframe\n\n\n\n\n\n\n\n\n\nname\nsex\ngroup\nx\ny\nz\n\n\n\n\n0\nMaria\nf\na\n1\n8\n15\n\n\n1\nAnna\nf\nb\n2\n9\n16\n\n\n2\nFrancesco\nm\na\n3\n10\n17\n\n\n3\nCristina\nf\nb\n4\n11\n18\n\n\n4\nGianni\nm\nb\n5\n12\n19\n\n\n5\nGabriella\nf\nc\n6\n13\n20\n\n\n6\nStefano\nm\na\n7\n14\n21\n\n\n\n\n\n\n\n\nOppure possiamo procedere nel modo seguente:\n\ndf = pd.DataFrame()\n\ndf[\"x\"] = [1, 2, 3, 4, 5, 6, 7]\ndf[\"y\"] = [8, 9, 10, 11, 12, 13, 14]\ndf[\"z\"] = [14.4, 15.1, 16.7, 17.3, 18.9, 19.3, 20.2]\ndf[\"group\"] = [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"]\ndf[\"sex\"] = [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"]\ndf[\"name\"] = [\n    \"Maria\",\n    \"Anna\",\n    \"Francesco\",\n    \"Cristina\",\n    \"Gianni\",\n    \"Gabriella\",\n    \"Stefano\",\n]\n\nprint(df)\n\n   x   y     z group sex       name\n0  1   8  14.4     a   f      Maria\n1  2   9  15.1     b   f       Anna\n2  3  10  16.7     a   m  Francesco\n3  4  11  17.3     b   f   Cristina\n4  5  12  18.9     b   m     Gianni\n5  6  13  19.3     c   f  Gabriella\n6  7  14  20.2     a   m    Stefano\n\n\nMolto spesso un DataFrame viene creato dal caricamento di dati da file.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#lettura-di-dati-da-file",
    "href": "chapters/python/04_pandas.html#lettura-di-dati-da-file",
    "title": "5¬† Pandas (1)",
    "section": "5.4 Lettura di dati da file",
    "text": "5.4 Lettura di dati da file\nDi solito la quantit√† di dati da analizzare √® tale che non √® pensabile di poterli immettere manualmente in una o pi√π liste. Normalmente i dati sono memorizzati su un file ed √® necessario importarli. La lettura (importazione) dei file √® il primo fondamentale passo nel processo pi√π generale di analisi dei dati.\nIn un primo esempio, importiamo i dati da un repository remoto.\n\nurl = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\ntitanic = pd.read_csv(url, index_col=\"Name\")\n\n√à possibile usare il metodo .head() per visualizzare le prime cinque righe.\n\ntitanic.head()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBraund, Mr. Owen Harris\n1\n0\n3\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\n2\n1\n1\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\nHeikkinen, Miss. Laina\n3\n1\n3\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n4\n1\n1\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\nAllen, Mr. William Henry\n5\n0\n3\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\n\nLe statistiche descrittive per ciascuna colonna si ottengono con il metodo describe.\n\ntitanic.describe()\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n891.000000\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.000000\n0.383838\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208\n\n\nstd\n257.353842\n0.486592\n0.836071\n14.526497\n1.102743\n0.806057\n49.693429\n\n\nmin\n1.000000\n0.000000\n1.000000\n0.420000\n0.000000\n0.000000\n0.000000\n\n\n25%\n223.500000\n0.000000\n2.000000\n20.125000\n0.000000\n0.000000\n7.910400\n\n\n50%\n446.000000\n0.000000\n3.000000\n28.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n668.500000\n1.000000\n3.000000\n38.000000\n1.000000\n0.000000\n31.000000\n\n\nmax\n891.000000\n1.000000\n3.000000\n80.000000\n8.000000\n6.000000\n512.329200\n\n\n\n\n\n\n\n\nIn questo modo possiamo ottenere informazioni sui nomi dei passeggeri, la sopravvivenza (0 o 1), l‚Äôet√†, il prezzo del biglietto, ecc. Con le statistiche riassuntive vediamo che l‚Äôet√† media √® di 29,7 anni, il prezzo massimo del biglietto √® di 512 USD, il 38% dei passeggeri √® sopravvissuto, ecc.\nPer fare un secondo esempio, importo i dati dal file penguins.csv situato nella directory ‚Äúdata‚Äù del mio computer. I dati relativi ai pinguini di Palmer sono resi disponibili da Kristen Gorman e dalla Palmer station, Antarctica LTER. La seguente cella legge il contenuto del file penguins.csv e lo inserisce nell‚Äôoggetto df utilizzando la funzione read_csv() di Pandas.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nPer il DataFrame df il significato delle colonne √® il seguente:\n\nspecies: a factor denoting penguin type (Ad√©lie, Chinstrap and Gentoo)\nisland: a factor denoting island in Palmer Archipelago, Antarctica (Biscoe, Dream or Torgersen)\nbill_length_mm: a number denoting bill length (millimeters)\nbill_depth_mm: a number denoting bill depth (millimeters)\nflipper_length_mm: an integer denoting flipper length (millimeters)\nbody_mass_g: an integer denoting body mass (grams)\nsex: a factor denoting sexuality (female, male)\nyear: the year of the study\n\nUsiamo il metodo .head() per visualizzare le prime cinque righe.\n\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\nA volte potrebbero esserci dati estranei alla fine del file, quindi √® importante anche controllare le ultime righe:\n\ndf.tail()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n\n\n\n\nUn breve tutorial in formato video √® disponibile tramite il seguente [collegamento](https://drive.google.com/file/d/12y7jZ0McvZBXThg6yjFgWx2ljQKrhoYR/view?usp=share_link), il quale illustra come effettuare la lettura dei dati da un file esterno in Visual Studio Code. \nL‚Äôattributo .dtypes restituisce il tipo dei dati:\n\ndf.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\nGli attributi pi√π comunemente usati sono elencati di seguito:\n\n\n\n\n\n\n\nAttributo\nRitorna\n\n\n\n\ndtypes\nIl tipo di dati in ogni colonna\n\n\nshape\nUna tupla con le dimensioni del DataFrame object (numero di righe, numero di colonne)\n\n\nindex\nL‚Äôoggetto Index lungo le righe del DataFrame\n\n\ncolumns\nIl nome delle colonne\n\n\nvalues\nI dati contenuti nel DataFrame\n\n\nempty\nCheck if the DataFrame object is empty\n\n\n\nPer esempio, l‚Äôistruzione della cella seguente restituisce l‚Äôelenco con i nomi delle colonne del DataFrame df:\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')\n\n\nLe dimensioni del Data Frame si ottengono con l‚Äôattributo .shape, che ritorna il numero di righe e di colonne. Nel caso presente, ci sono 344 righe e 8 colonne.\n\ndf.shape\n\n(344, 8)\n\n\nCome abbiamo gi√† visto in precedenza, un sommario dei dati si ottiene con il metodo .describe():\n\ndf.describe()\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\n\nUna descrizione del DataFrame si ottiene con il metodo .info().\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\nSi noti che, alle volte, abbiamo utilizzato la sintassi `df.word` e talvolta la sintassi `df.word()`. Tecnicamente, la classe Pandas Dataframe ha sia attributi che metodi. Gli attributi sono `.word`, mentre i metodi sono `.word()` o `.word(arg1, arg2, ecc.)`. Per sapere se qualcosa √® un metodo o un attributo √® necessario leggere la documentazione.\nAbbiamo visto in precedenza come possiamo leggere i dati in un dataframe utilizzando la funzione read_csv(). Pandas comprende anche molti altri formati, ad esempio utilizzando le funzioni read_excel(), read_hdf(), read_json(), ecc. (e i corrispondenti metodi per scrivere su file: to_csv(), to_excel(), to_hdf(), to_json(), ecc.).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#gestione-dei-dati-mancanti",
    "href": "chapters/python/04_pandas.html#gestione-dei-dati-mancanti",
    "title": "5¬† Pandas (1)",
    "section": "5.5 Gestione dei dati mancanti",
    "text": "5.5 Gestione dei dati mancanti\nNell‚Äôoutput di .info() troviamo la colonna ‚ÄúNon-Null Count‚Äù, ovvero il numero di dati non mancanti per ciascuna colonna del DataFrame. Da questo si nota che le colonne del DataFrame df contengono alcuni dati mancanti. La gestione dei dati mancanti √® un argomento complesso. Per ora ci limitiamo ad escludere tutte le righe che, in qualche colonna, contengono dei dati mancanti.\nOttengo il numero di dati per ciascuna colonna del DataFrame:\n\ndf.isnull().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\nyear                  0\ndtype: int64\n\n\nRimuovo i dati mancanti con il metodo .dropna(). L‚Äôargomento inplace=True specifica il DataFrame viene trasformato in maniera permanente.\n\ndf.dropna(inplace=True)\n\nVerifico che i dati mancanti siano stati rimossi.\n\ndf.shape\n\n(333, 8)\n\n\nIn alternativa, possiamo rimuovere solo le righe del DataFrame per le quali ci sono dei dati mancanti rispetto a specifiche colonne. Per esempio\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf0 = df.copy()\n\nmissing_data = df0.isnull()[[\"bill_length_mm\", \"body_mass_g\"]].any(axis=1)\n# Drop rows with any missing data\ndf0_cleaned = df0.loc[~missing_data]\ndf0_cleaned.shape\n\n(342, 8)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#rinominare-le-colonne",
    "href": "chapters/python/04_pandas.html#rinominare-le-colonne",
    "title": "5¬† Pandas (1)",
    "section": "5.6 Rinominare le colonne",
    "text": "5.6 Rinominare le colonne\n√à possibile rinominare tutte le colonne passando al metodo .rename() un dizionario che specifica quali colonne devono essere mappate a cosa. Nella cella seguente facciamo prima una copia del DataFrame con il metodo copy() e poi rinominiamo sex che diventa gender e year che diventa year_of_the_study:\n\ndf1 = df.copy()\n\n# rename(columns={\"OLD_NAME\": \"NEW_NAME\"})\ndf1.rename(columns={\n    \"sex\": \"gender\", \n    \"year\": \"year_of_the_study\"\n    }, \n           inplace=True)\ndf1.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\ngender\nyear_of_the_study\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\n\nSi noti che in Python valgono le seguenti regole.\n\n- Il nome di una variabile deve iniziare con una lettera o con il trattino basso (*underscore*) `_`.\n- Il nome di una variabile non pu√≤ iniziare con un numero.\n- Un nome di variabile pu√≤ contenere solo caratteri alfanumerici e il trattino basso (A-z, 0-9 e _).\n- I nomi delle variabili fanno distinzione tra maiuscole e minuscole (`age`, `Age` e `AGE` sono tre variabili diverse).\n\nGli spazi non sono consentiti nel nome delle variabili: come separatore usate il trattino basso.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "href": "chapters/python/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "title": "5¬† Pandas (1)",
    "section": "5.7 Estrarre i dati dal DataFrame",
    "text": "5.7 Estrarre i dati dal DataFrame\nUna parte cruciale del lavoro con i DataFrame √® l‚Äôestrazione di sottoinsiemi di dati: vogliamo trovare le righe che soddisfano un determinato insieme di criteri, vogliamo isolare le colonne/righe di interesse, ecc. Per rispondere alle domande di interesse dell‚Äôanalisi dei dati, molto spesso √® necessario selezionare un sottoinsieme del DataFrame.\n\n5.7.1 Colonne\n√à possibile estrarre una colonna da un DataFrame usando una notazione simile a quella che si usa per il dizionario (DataFrame['word']) o utilizzando la notazione DataFrame.word. Per esempio:\n\ndf[\"bill_length_mm\"]\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\n\ndf.bill_length_mm\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\nSe tra parentesi quadre indichiamo una lista di colonne, come nel caso di df[['bill_length_mm','species']], otteniamo un nuovo DataFrame costituito unicamente dalle colonne selezionate:\n\ndf[[\"bill_length_mm\", \"species\"]]\n\n\n\n\n\n\n\n\n\nbill_length_mm\nspecies\n\n\n\n\n0\n39.1\nAdelie\n\n\n1\n39.5\nAdelie\n\n\n2\n40.3\nAdelie\n\n\n4\n36.7\nAdelie\n\n\n5\n39.3\nAdelie\n\n\n...\n...\n...\n\n\n339\n55.8\nChinstrap\n\n\n340\n43.5\nChinstrap\n\n\n341\n49.6\nChinstrap\n\n\n342\n50.8\nChinstrap\n\n\n343\n50.2\nChinstrap\n\n\n\n\n333 rows √ó 2 columns\n\n\n\n\n\n\n5.7.2 Righe\nIn un pandas.DataFrame, anche le righe hanno un nome. I nomi delle righe sono chiamati index:\n\ndf.index\n\nInt64Index([  0,   1,   2,   4,   5,   6,   7,  12,  13,  14,\n            ...\n            334, 335, 336, 337, 338, 339, 340, 341, 342, 343],\n           dtype='int64', length=333)\n\n\nCi sono vari metodi per estrarre sottoinsimi di righe da un DataFrame. √à possibile fare riferimento ad un intervallo di righe mediante un indice di slice. Per esempio, possiamo ottenere le prime 3 righe del DataFrame df nel modo seguente:\n\ndf[0:3]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\nSi noti che in Python una sequenza √® determinata dal valore iniziale e quello finale ma si interrompe ad n-1. Pertanto, per selezionare una singola riga (per esempio, la prima) dobbiamo procedere nel modo seguente:\n\ndf[0:1]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n\n\n\n\n\n\n\n\n5.7.3 Indicizzazione, selezione e filtraggio\nPoich√© l‚Äôoggetto DataFrame √® bidimensionale, √® possibile selezionare un sottoinsieme di righe e colonne utilizzando le etichette degli assi (loc) o gli indici delle righe (iloc).\nPer esempio, usando l‚Äôattributo iloc posso selezionare la prima riga del DataFrame:\n\ndf.iloc[0]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            39.1\nbill_depth_mm             18.7\nflipper_length_mm        181.0\nbody_mass_g             3750.0\nsex                       male\nyear                      2007\nName: 0, dtype: object\n\n\nLa cella seguene seleziona le prime tre righe del DataFrame:\n\ndf.iloc[0:3]\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\n\nL‚Äôattributo loc consente di selezionare simultaneamente righe e colonne per ‚Äúnome‚Äù. Il ‚Äúnome‚Äù delle righe √® l‚Äôindice di riga. Per esempio, visualizzo il quinto valore della colonna body_mass_g:\n\ndf.loc[4, \"body_mass_g\"]\n\n3450.0\n\n\noppure, il quinto valore delle colonne bill_length_mm, bill_depth_mm, flipper_length_mm:\n\ndf.loc[4, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\nbill_length_mm        36.7\nbill_depth_mm         19.3\nflipper_length_mm    193.0\nName: 4, dtype: object\n\n\nVisualizzo ora le prime tre righe sulle tre colonne precedenti. Si noti l‚Äôuso di : per definire un intervallo di valori sull‚Äôindice di riga.\n\ndf.loc[0:2, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n39.1\n18.7\n181.0\n\n\n1\n39.5\n17.4\n186.0\n\n\n2\n40.3\n18.0\n195.0\n\n\n\n\n\n\n\n\nUna piccola variante della sintassi precedente si rivela molto utile. Qui, il segno di due punti (:) signfica ‚Äútutte le righe‚Äù:\n\nkeep_cols = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\nprint(df.loc[:, keep_cols])\n\n     bill_length_mm  bill_depth_mm  flipper_length_mm\n0              39.1           18.7              181.0\n1              39.5           17.4              186.0\n2              40.3           18.0              195.0\n4              36.7           19.3              193.0\n5              39.3           20.6              190.0\n..              ...            ...                ...\n339            55.8           19.8              207.0\n340            43.5           18.1              202.0\n341            49.6           18.2              193.0\n342            50.8           19.0              210.0\n343            50.2           18.7              198.0\n\n[333 rows x 3 columns]\n\n\n\n\n5.7.4 Filtrare righe in maniera condizionale\nIn precedenza abbiamo utilizzato la selezione delle righe in un DataFrame in base alla loro posizione. Tuttavia, √® pi√π comune selezionare le righe del DataFrame utilizzando una condizione logica, cio√® tramite l‚Äôindicizzazione booleana.\nIniziamo con un esempio relativo ad una condizione specificata sui valori di una sola colonna. Quando applichiamo un operatore logico come &gt;, &lt;, ==, != ai valori di una colonna del DataFrame, il risultato √® una sequenza di valori booleani (True, False), uno per ogni riga nel DataFrame, i quali indicano se, per quella riga, la condizione √® vera o falsa. Ad esempio:\n\ndf[\"island\"] == \"Torgersen\"\n\n0       True\n1       True\n2       True\n4       True\n5       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nName: island, Length: 333, dtype: bool\n\n\nUtilizzando i valori booleani che sono stati ottenuti in questo modo √® possibile filtrare le righe del DataFrame, ovvero, ottenere un nuovo DataFrame nel quale la condizione logica specificata √® vera su tutte le righe. Per esempio, nella cella seguente selezioniamo solo le osservazioni relative all‚Äôisola Torgersen, ovvero tutte le righe del DataFrame nelle quali la colonna island assume il valore Torgersen.\n\nonly_torgersen = df[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo scrivere:\n\nonly_torgersen = df.loc[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\n\n√à possibile combinare pi√π condizioni logiche usando gli operatori & (e), | (oppure). Si presti attenzione all‚Äôuso delle parentesi.\n\ndf.loc[(df[\"island\"] == \"Torgersen\") & (df[\"sex\"] == \"female\")].head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n12\nAdelie\nTorgersen\n41.1\n17.6\n182.0\n3200.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n\n5.7.5 Metodo .query\n√à anche possibile filtrare le righe del DataFrame usando il metodo query(). Ci sono diversi modi per generare sottoinsiemi con Pandas. I metodi loc e iloc consentono di recuperare sottoinsiemi in base alle etichette di riga e colonna o all‚Äôindice intero delle righe e delle colonne. E Pandas ha una notazione a parentesi quadre che consente di utilizzare condizioni logiche per recuperare righe di dati specifiche. Ma la sintassi di questi metodi non √® la pi√π trasparente. Inoltre, tali metodi sono difficili da usare insieme ad altri metodi di manipolazione dei dati in modo organico.\nIl metodo .query di Pandas cerca di risolve questi problemi. Il metodo .query consente di ‚Äúinterrogare‚Äù un DataFrame e recuperare sottoinsiemi basati su condizioni logiche. La sintassi √® un po‚Äô pi√π snella rispetto alla notazione a parentesi quadre di Pandas. Inoltre, il metodo .query pu√≤ essere utilizzato con altri metodi di Pandas in modo snello e semplice, rendendo la manipolazione dei dati maggiormente fluida e diretta.\nLa sintassi √® la seguente:\nyour_data_frame.query(expression, inplace = False)\nL‚Äôespressione utilizzata nella query √® una sorta di espressione logica che descrive quali righe restituire in output. Se l‚Äôespressione √® vera per una particolare riga, la riga verr√† inclusa nell‚Äôoutput. Se l‚Äôespressione √® falsa per una particolare riga, quella riga verr√† esclusa dall‚Äôoutput.\nIl parametro inplace consente di specificare se si desidera modificare direttamente il DataFrame con cui si sta lavorando.\nPer esempio:\n\neval_string = \"island == 'Torgersen' & sex == 'female' & year != 2009\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n6\n17.8\n181.0\n\n\n12\n17.6\n182.0\n\n\n15\n17.8\n185.0\n\n\n16\n19.0\n195.0\n\n\n18\n18.4\n184.0\n\n\n68\n16.6\n190.0\n\n\n70\n19.0\n190.0\n\n\n72\n17.2\n196.0\n\n\n74\n17.5\n190.0\n\n\n76\n16.8\n191.0\n\n\n78\n16.1\n187.0\n\n\n80\n17.2\n189.0\n\n\n82\n18.8\n187.0\n\n\n\n\n\n\n\n\nUn altro esempio usa la keyword in per selezionare solo le righe relative alle due isole specificate.\n\neval_string = \"island in ['Torgersen', 'Dream']\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n18.7\n181.0\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n5\n20.6\n190.0\n\n\n...\n...\n...\n\n\n339\n19.8\n207.0\n\n\n340\n18.1\n202.0\n\n\n341\n18.2\n193.0\n\n\n342\n19.0\n210.0\n\n\n343\n18.7\n198.0\n\n\n\n\n170 rows √ó 2 columns\n\n\n\n\nIl metodo query() pu√≤ anche essere utilizzato per selezionare le righe di un DataFrame in base alle relazioni tra le colonne. Ad esempio,\n\ndf.query(\"bill_length_mm &gt; 3*bill_depth_mm\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n152\n13.2\n211.0\n\n\n153\n16.3\n230.0\n\n\n154\n14.1\n210.0\n\n\n155\n15.2\n218.0\n\n\n156\n14.5\n215.0\n\n\n...\n...\n...\n\n\n272\n14.3\n215.0\n\n\n273\n15.7\n222.0\n\n\n274\n14.8\n212.0\n\n\n275\n16.1\n213.0\n\n\n293\n17.8\n181.0\n\n\n\n\n106 rows √ó 2 columns\n\n\n\n\n√à anche possibile fare riferimento a variabili non contenute nel DataFrame usando il carattere @.\n\noutside_var = 21\ndf.query(\"bill_depth_mm &gt; @outside_var\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n13\n21.2\n191.0\n\n\n14\n21.1\n198.0\n\n\n19\n21.5\n194.0\n\n\n35\n21.1\n196.0\n\n\n49\n21.2\n191.0\n\n\n61\n21.1\n195.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "href": "chapters/python/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "title": "5¬† Pandas (1)",
    "section": "5.8 Selezione casuale di un sottoinsieme di righe",
    "text": "5.8 Selezione casuale di un sottoinsieme di righe\nIl metodo sample() viene usato per ottenere un sottoinsieme casuale di righe del DataFrame. L‚Äôargomento replace=False indica l‚Äôestrazione senza rimessa (default); se specifichiamo replace=True otteniamo un‚Äôestrazione con rimessa. L‚Äôargomento n specifica il numero di righe che vogliamo ottenere. Ad esempio\n\ndf_sample = df.sample(4)\ndf_sample\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n204\nGentoo\nBiscoe\n45.1\n14.4\n210.0\n4400.0\nfemale\n2008\n\n\n69\nAdelie\nTorgersen\n41.8\n19.4\n198.0\n4450.0\nmale\n2008\n\n\n296\nChinstrap\nDream\n42.4\n17.3\n181.0\n3600.0\nfemale\n2007\n\n\n208\nGentoo\nBiscoe\n43.8\n13.9\n208.0\n4300.0\nfemale\n2008\n\n\n\n\n\n\n\n\n\ndf_sample = df[[\"bill_length_mm\", \"bill_depth_mm\"]].sample(4)\ndf_sample\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\n\n\n175\n46.3\n15.8\n\n\n133\n37.5\n18.5\n\n\n182\n47.3\n15.3\n\n\n251\n51.1\n16.5",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#selezione-di-colonne",
    "href": "chapters/python/04_pandas.html#selezione-di-colonne",
    "title": "5¬† Pandas (1)",
    "section": "5.9 Selezione di colonne",
    "text": "5.9 Selezione di colonne\nIl metodo drop() prende in input una lista con i nomi di colonne che vogliamo escludere dal DataFrame e pu√≤ essere usato per creare un nuovo DataFrame o per sovrascrivere quello di partenza. √à possibile usare le espressioni regolari (regex) per semplificare la ricerca dei nomi delle colonne.\nIn *regex* il simbolo `$` significa \"la stringa finisce con\"; il simbolo `^` significa \"la stringa inizia con\". L'espressione `regex` pu√≤ contenere (senza spazi) il simbolo `|` che significa \"oppure\". \nNel codice della cella seguente, alla funzione .columns.str.contains() viene passata l‚Äôespressione regolare mm$|year che significa: tutte le stringhe (in questo caso, nomi di colonne) che finiscono con mm oppure la stringa (nome di colonna) year.\n\nmask = df.columns.str.contains(\"mm$|year\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'year'], dtype='object')\n\n\n\ndf_new = df.drop(columns=columns_to_drop)\ndf_new.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n3750.0\nmale\n\n\n1\nAdelie\nTorgersen\n3800.0\nfemale\n\n\n2\nAdelie\nTorgersen\n3250.0\nfemale\n\n\n4\nAdelie\nTorgersen\n3450.0\nfemale\n\n\n5\nAdelie\nTorgersen\n3650.0\nmale\n\n\n\n\n\n\n\n\nIn un altro esempio, creaiamo l‚Äôelenco delle colonne che iniziano con la lettera ‚Äúb‚Äù, insieme a year e sex.\n\nmask = df.columns.str.contains(\"^b|year|sex\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'body_mass_g', 'sex', 'year'], dtype='object')\n\n\nOppure l‚Äôelenco delle colonne che contengono il patten ‚Äúlength‚Äù.\n\nmask = df.columns.str.contains(\"length\")\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'flipper_length_mm'], dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#creare-nuove-colonne",
    "href": "chapters/python/04_pandas.html#creare-nuove-colonne",
    "title": "5¬† Pandas (1)",
    "section": "5.10 Creare nuove colonne",
    "text": "5.10 Creare nuove colonne\nPer ciascuna riga, calcoliamo\n\nbill_length_mm - bill_depth_mm\nbill_length_mm / (body_mass_g / 1000)\n\nPer ottenere questo risultato possiamo usare una lambda function.\n\ndf = df.assign(\n    bill_difference=lambda x: x.bill_length_mm - x.bill_depth_mm,\n    bill_ratio=lambda x: x.bill_length_mm / (x.body_mass_g / 1000),\n)\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n\n\n\n\n\n\n\n\nIn maniera pi√π semplice possiamo procedere nel modo seguente:\n\ndf[\"bill_ratio2\"] = df[\"bill_length_mm\"] / (df[\"body_mass_g\"] / 1000)\ndf.head()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\nbill_ratio2\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n10.767123\n\n\n\n\n\n\n\n\nUn‚Äôutile funzionalit√† √® quella che consente di aggiungere una colonna ad un DataFrame (o di mofificare una colonna gi√† esistente) sulla base di una condizione True/False. Questo risultato pu√≤ essere raggiunto usando np.where(), con la seguente sintassi:\nnp.where(condition, value if condition is true, value if condition is false)\nSupponiamo di avere un DataFrame df con due colonne, A e B, e vogliamo creare una nuova colonna C che contenga il valore di A quando questo √® maggiore di 0, e il valore di B altrimenti. Possiamo utilizzare la funzione where() per ottenere ci√≤ come segue:\n\n# Creiamo un DataFrame di esempio\ndf = pd.DataFrame({\"A\": [-1, 2, 3, -4], \"B\": [5, 6, 0, 8]})\n\n# Creiamo una nuova colonna 'C' usando la funzione where()\ndf[\"C\"] = df[\"A\"].where(df[\"A\"] &gt; 0, df[\"B\"])\n\nprint(df)\n\n   A  B  C\n0 -1  5  5\n1  2  6  2\n2  3  0  3\n3 -4  8  8",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#formato-long-e-wide",
    "href": "chapters/python/04_pandas.html#formato-long-e-wide",
    "title": "5¬† Pandas (1)",
    "section": "5.11 Formato long e wide",
    "text": "5.11 Formato long e wide\nNella data analysis, i termini ‚Äúformato long‚Äù e ‚Äúformato wide‚Äù sono usati per descrivere la struttura di un set di dati. l formato wide (in inglese ‚Äúwide format‚Äù) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni variabile √® rappresentata da pi√π colonne. Un esempio √® il seguente, nel quale per ciascun partecipante, identificato da Name e ID abbiamo i punteggi di un ipotetico test per 6 anni consecutivi.\n\nscores = {\n    \"Name\": [\"Maria\", \"Carlo\", \"Giovanna\", \"Irene\"],\n    \"ID\": [1, 2, 3, 4],\n    \"2017\": [85, 87, 89, 91],\n    \"2018\": [96, 98, 100, 102],\n    \"2019\": [100, 102, 106, 106],\n    \"2020\": [89, 95, 98, 100],\n    \"2021\": [94, 96, 98, 100],\n    \"2022\": [100, 104, 104, 107],\n}\n\nwide_data = pd.DataFrame(scores)\nwide_data\n\n\n\n\n\n\n\n\n\nName\nID\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\n0\nMaria\n1\n85\n96\n100\n89\n94\n100\n\n\n1\nCarlo\n2\n87\n98\n102\n95\n96\n104\n\n\n2\nGiovanna\n3\n89\n100\n106\n98\n98\n104\n\n\n3\nIrene\n4\n91\n102\n106\n100\n100\n107\n\n\n\n\n\n\n\n\nIl formato long (in inglese ‚Äúlong format‚Äù) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni colonna rappresenta una singola variabile. Questo formato √® quello che viene richiesto per molte analisi statistiche. In Pandas √® possibile usare la funzione melt per trasformare i dati dal formato wide al formato long. Un esempio √® riportato qui sotto. Sono state mantenute le due colonne che identificano ciascun partecipante, ma i dati del test, che prima erano distribuiti su sei colonne, ora sono presenti in una singola colonna. Al DataFrame, inoltre, √® stata aggiunta una colonna che riporta l‚Äôanno.\n\nlong_data = wide_data.melt(id_vars=[\"Name\", \"ID\"], var_name=\"Year\", value_name=\"Score\")\nlong_data\n\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n1\nCarlo\n2\n2017\n87\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n3\nIrene\n4\n2017\n91\n\n\n4\nMaria\n1\n2018\n96\n\n\n5\nCarlo\n2\n2018\n98\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n7\nIrene\n4\n2018\n102\n\n\n8\nMaria\n1\n2019\n100\n\n\n9\nCarlo\n2\n2019\n102\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n11\nIrene\n4\n2019\n106\n\n\n12\nMaria\n1\n2020\n89\n\n\n13\nCarlo\n2\n2020\n95\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n15\nIrene\n4\n2020\n100\n\n\n16\nMaria\n1\n2021\n94\n\n\n17\nCarlo\n2\n2021\n96\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n19\nIrene\n4\n2021\n100\n\n\n20\nMaria\n1\n2022\n100\n\n\n21\nCarlo\n2\n2022\n104\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n23\nIrene\n4\n2022\n107\n\n\n\n\n\n\n\n\nPer migliorare la leggibilit√† dei dati, √® possibile riordinare le righe del set di dati utilizzando la funzione sort_values. In questo modo, le informazioni saranno presentate in un ordine specifico, che pu√≤ rendere pi√π facile la lettura dei dati.\n\nlong_data.sort_values(by=[\"ID\", \"Year\"])\n\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n4\nMaria\n1\n2018\n96\n\n\n8\nMaria\n1\n2019\n100\n\n\n12\nMaria\n1\n2020\n89\n\n\n16\nMaria\n1\n2021\n94\n\n\n20\nMaria\n1\n2022\n100\n\n\n1\nCarlo\n2\n2017\n87\n\n\n5\nCarlo\n2\n2018\n98\n\n\n9\nCarlo\n2\n2019\n102\n\n\n13\nCarlo\n2\n2020\n95\n\n\n17\nCarlo\n2\n2021\n96\n\n\n21\nCarlo\n2\n2022\n104\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n3\nIrene\n4\n2017\n91\n\n\n7\nIrene\n4\n2018\n102\n\n\n11\nIrene\n4\n2019\n106\n\n\n15\nIrene\n4\n2020\n100\n\n\n19\nIrene\n4\n2021\n100\n\n\n23\nIrene\n4\n2022\n107",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#copia-di-un-data-frame",
    "href": "chapters/python/04_pandas.html#copia-di-un-data-frame",
    "title": "5¬† Pandas (1)",
    "section": "5.12 Copia di un data frame",
    "text": "5.12 Copia di un data frame\nQuando in Python definiamo un nuovo data frame basandoci su un data frame esistente con l‚Äôistruzione new_df = old_df, √® importante essere consapevoli del fatto che non stiamo creando un nuovo data frame indipendente. In realt√†, new_df diventa solamente un riferimento all‚Äôoggetto originale old_df nell‚Äôambiente corrente. Questo significa che qualsiasi modifica apportata a new_df si rifletter√† automaticamente anche in old_df. In pratica, abbiamo un unico oggetto data frame accessibile attraverso due nomi diversi.\nPer creare effettivamente una copia indipendente di old_df, in modo che le modifiche apportate a questa copia non influiscano sull‚Äôoriginale, dobbiamo utilizzare il metodo .copy(). Questo metodo crea un nuovo oggetto data frame che √® una copia del data frame originale. L‚Äôistruzione corretta per fare ci√≤ in Python √® la seguente:\nnew_df = old_df.copy()\nUtilizzando old_df.copy(), otteniamo due data frame completamente indipendenti. Modifiche apportate a new_df non avranno alcun impatto su old_df, permettendoci di lavorare con i dati in modo sicuro e senza rischi di sovrascrittura o alterazione involontaria dei dati originali. Questa pratica √® fondamentale per mantenere l‚Äôintegrit√† dei dati e per gestire correttamente le variabili all‚Äôinterno di un programma Python.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "title": "5¬† Pandas (1)",
    "section": "5.13 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "5.13 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.2\npandas: 2.1.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html",
    "href": "chapters/python/05_pandas_aggregate.html",
    "title": "6¬† Pandas (2)",
    "section": "",
    "text": "6.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport arviz as az\nimport seaborn as sns\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nsns.set_theme(palette=\"colorblind\")\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = 'retina'",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "href": "chapters/python/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "title": "6¬† Pandas (2)",
    "section": "6.2 Calcolo delle statistiche descrittive",
    "text": "6.2 Calcolo delle statistiche descrittive\nAgli oggetti Pandas possono essere applicati vari metodi matematici e statistici. La maggior parte di questi rientra nella categoria della riduzione di dati o delle statistiche descrittive. Rispetto ai metodi degli array NumPy, i metodi Pandas consentono la gestione dei dati mancanti. Alcuni dei metodi disponibili per gli oggetti Pandas sono elencati di seguito.\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncount\nNumber of non-NA values\n\n\ndescribe\nCompute set of summary statistics\n\n\nmin, max\nCompute minimum and maximum values\n\n\nargmin, argmax\nCompute index locations (integers) at which minimum or maximum value is obtained, respectively; not available on DataFrame objects\n\n\nidxmin, idxmax\nCompute index labels at which minimum or maximum value is obtained, respectively\n\n\nquantile\nCompute sample quantile ranging from 0 to 1 (default: 0.5)\n\n\nsum\nSum of values\n\n\nmean\nMean of values\n\n\nmedian\nArithmetic median (50% quantile) of values\n\n\nmad\nMean absolute deviation from mean value\n\n\nprod\nProduct of all values\n\n\nvar\nSample variance of values\n\n\nstd\nSample standard deviation of values\n\n\nskew\nSample skewness (third moment) of values\n\n\nkurt\nSample kurtosis (fourth moment) of values\n\n\ncumsum\nCumulative sum of values\n\n\ncummin, cummax\nCumulative minimum or maximum of values, respectively\n\n\ncumprod\nCumulative product of values\n\n\ndiff\nCompute first arithmetic difference (useful for time series)\n\n\npct_change\nCompute percent changes\n\n\n\nTali metodi possono essere applicati a tutto il DataFrame, oppure soltanto ad una o pi√π colonne.\nPer fare un esempio, esamineremo nuovamente i dati penguins.csv. Come in precedenza, dopo avere caricato i dati, rimuoviamo i dati mancanti.\n\ndf = pd.read_csv(\"../../data/penguins.csv\")\ndf.dropna(inplace=True)\n\nUsiamo il metodo describe() su tutto il DataFrame:\n\ndf.describe(include=\"all\")\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\ncount\n333\n333\n333.000000\n333.000000\n333.000000\n333.000000\n333\n333.000000\n\n\nunique\n3\n3\nNaN\nNaN\nNaN\nNaN\n2\nNaN\n\n\ntop\nAdelie\nBiscoe\nNaN\nNaN\nNaN\nNaN\nmale\nNaN\n\n\nfreq\n146\n163\nNaN\nNaN\nNaN\nNaN\n168\nNaN\n\n\nmean\nNaN\nNaN\n43.992793\n17.164865\n200.966967\n4207.057057\nNaN\n2008.042042\n\n\nstd\nNaN\nNaN\n5.468668\n1.969235\n14.015765\n805.215802\nNaN\n0.812944\n\n\nmin\nNaN\nNaN\n32.100000\n13.100000\n172.000000\n2700.000000\nNaN\n2007.000000\n\n\n25%\nNaN\nNaN\n39.500000\n15.600000\n190.000000\n3550.000000\nNaN\n2007.000000\n\n\n50%\nNaN\nNaN\n44.500000\n17.300000\n197.000000\n4050.000000\nNaN\n2008.000000\n\n\n75%\nNaN\nNaN\n48.600000\n18.700000\n213.000000\n4775.000000\nNaN\n2009.000000\n\n\nmax\nNaN\nNaN\n59.600000\n21.500000\n231.000000\n6300.000000\nNaN\n2009.000000\n\n\n\n\n\n\n\n\nSe desideriamo solo le informazioni relative alle variabili qualitative, usiamo l‚Äôargomento include='object'.\n\ndf.describe(include=\"object\")\n\n\n\n\n\n\n\n\n\nspecies\nisland\nsex\n\n\n\n\ncount\n333\n333\n333\n\n\nunique\n3\n3\n2\n\n\ntop\nAdelie\nBiscoe\nmale\n\n\nfreq\n146\n163\n168\n\n\n\n\n\n\n\n\nI valori NaN indicano dati mancanti. Ad esempio, la colonna species contiene stringhe, quindi non esiste alcun valore per mean; allo stesso modo, bill_length_mm √® una variabile numerica, quindi non vengono calcolate le statistiche riassuntive per le variabili categoriali (unique, top, freq).\nEsaminimiamo le colonne singolarmente. Ad esempio, troviamo la media della colonna bill_depth_mm.\n\ndf[\"bill_depth_mm\"].mean()\n\n17.164864864864867\n\n\nPer la deviazione standard usiamo il metodo std(). Si noti l‚Äôargomento opzionale ddof:\n\ndf[\"bill_length_mm\"].std(ddof=1)\n\n5.46866834264756\n\n\nLa cella seguente fornisce l‚Äôindice della riga nella quale la colonna bill_length_mm assume il suo valore massimo:\n\ndf[\"bill_length_mm\"].idxmax()\n\n185\n\n\nLa colonna species nel DataFrame df √® una variabile a livello nominale. Elenchiamo le modalit√† di tale variabile.\n\ndf[\"species\"].unique()\n\narray(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n\nIl metodo value_counts ritorna la distribuzione di frequenza assoluta:\n\ndf[\"species\"].value_counts()\n\nspecies\nAdelie       146\nGentoo       119\nChinstrap     68\nName: count, dtype: int64\n\n\nPer le frequenze relative si imposta l‚Äôargomento normalize=True:\n\nprint(df[\"species\"].value_counts(normalize=True))\n\nspecies\nAdelie       0.438438\nGentoo       0.357357\nChinstrap    0.204204\nName: proportion, dtype: float64\n\n\nConsideriamo la lunghezza del becco dei pinguini suddivisa per ciascuna specie. Con l‚Äôistruzione seguente, possiamo generare gli istogrammi corrispondenti che rappresentano la distribuzione della lunghezza del becco in ciascun gruppo.\n\ncolor_fill = \"#b97c7c\"\n_ = df.hist(\n    column=\"bill_length_mm\",\n    by=[\"species\"],\n    bins=20,\n    figsize=(12, 4),\n    layout=(1, 3),\n    rwidth=0.9,\n    color=color_fill\n)\n\n\n\n\n\n\n\n\n\ndf\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n333 rows √ó 8 columns\n\n\n\n\n\n6.2.1 Aggregazione dei dati\nIl riepilogo di pi√π valori in un unico indice va sotto il nome di ‚Äúaggregazione‚Äù dei dati. Il metodo aggregate() pu√≤ essere applicato ai DataFrame e restituisce un nuovo DataFrame pi√π breve contenente solo i valori aggregati. Il primo argomento di aggregate() specifica quale funzione o quali funzioni devono essere utilizzate per aggregare i dati. Molte comuni funzioni di aggregazione sono disponibili nel modulo statistics. Ad esempio:\n\nmedian(): la mediana;\nmean(): la media;\nstdev(): la deviazione standard;\n\nSe vogliamo applicare pi√π funzioni di aggregazione, allora possiamo raccogliere prima le funzioni in una lista e poi passare la lista ad aggregate().\n\n# Lista delle funzioni statistiche di riepilogo come stringhe\nsummary_stats = [\"min\", \"median\", \"mean\", \"std\", \"max\"]\n\n# Calcola le statistiche di riepilogo per le colonne numeriche usando aggregate\nresult = df[\n    [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n].aggregate(summary_stats)\n\nprint(result)\n\n        bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\nmin          32.100000      13.100000         172.000000  2700.000000\nmedian       44.500000      17.300000         197.000000  4050.000000\nmean         43.992793      17.164865         200.966967  4207.057057\nstd           5.468668       1.969235          14.015765   805.215802\nmax          59.600000      21.500000         231.000000  6300.000000\n\n\nSi noti che Pandas ha applicato le funzioni di riepilogo a ogni colonna, ma, per alcune colonne, le statistiche riassuntive non si possono calcolare, ovvero tutte le colonne che contengono stringhe anzich√© numeri. Di conseguenza, vediamo che alcuni dei risultati per tali colonne sono contrassegnati con ‚ÄúNaN‚Äù. Questa √® un‚Äôabbreviazione di ‚ÄúNot a Number‚Äù, talvolta utilizzata nell‚Äôanalisi dei dati per rappresentare valori mancanti o non definiti.\nMolto spesso vogliamo calcolare le statistiche descrittive separatamente per ciascun gruppo di osservazioni ‚Äì per esempio, nel caso presente, potremmo volere distinguere le statistiche descrittive in base alla specie dei pinguini. Questo risultato si ottiene con il metodo .groupby().\nIl nome ‚Äúgroup by‚Äù deriva da un comando nel linguaggio del database SQL, ma forse √® pi√π semplice pensarlo nei termini coniati da Hadley Wickham: split, apply, combine. Un esempio canonico di questa operazione di split-apply-combine, in cui ‚Äúapply‚Äù √® un‚Äôaggregazione di sommatoria, √® illustrato nella figura seguente:\n\n\n\n\n\n\nFigura¬†6.1: Split, apply, combine.\n\n\n\nLa figura rende chiaro ci√≤ che si ottiene con groupby:\n\nla fase ‚Äúsplit‚Äù prevede la suddivisione e il raggruppamento di un DataFrame in base al valore della chiave specificata;\nla fase ‚Äúapply‚Äù implica il calcolo di alcune funzioni, solitamente un‚Äôaggregazione, una trasformazione o un filtro, all‚Äôinterno dei singoli gruppi;\nla fase ‚Äúcombine‚Äù unisce i risultati di queste operazioni in una matrice di output.\n\nPer esempio, ragruppiamo le osservazioni body_mass_g in funzione delle modalit√† della variabile species.\n\ngrouped = df[\"body_mass_g\"].groupby(df[\"species\"])\n\nCalcoliamo ora la media della variabile body_mass_g separatamente per ciascun gruppo di osservazioni.\n\ngrouped.mean()\n\nspecies\nAdelie       3706.164384\nChinstrap    3733.088235\nGentoo       5092.436975\nName: body_mass_g, dtype: float64\n\n\n√à possibile applicare criteri di classificazione multipli. Per fare un altro esempio, contiamo il numero di pinguini presenti sulle tre isole, distinguendoli per specie e genere.\n\ndf.groupby([\"island\", \"species\", \"sex\"]).size()\n\nisland     species    sex   \nBiscoe     Adelie     female    22\n                      male      22\n           Gentoo     female    58\n                      male      61\nDream      Adelie     female    27\n                      male      28\n           Chinstrap  female    34\n                      male      34\nTorgersen  Adelie     female    24\n                      male      23\ndtype: int64\n\n\nCon il metodo aggregate() possiamo applicare diverse funzioni di aggregazione alle osservazioni ragruppate. Ad esempio\n\nsummary_stats = [np.mean, np.std]\n# Group by \"species\" and calculate summary statistics for numeric columns\nresult = df.groupby(\"species\").agg(\n    {col: summary_stats for col in df.columns if pd.api.types.is_numeric_dtype(df[col])}\n)\n\nprint(result)\n\n          bill_length_mm           bill_depth_mm           flipper_length_mm  \\\n                    mean       std          mean       std              mean   \nspecies                                                                        \nAdelie         38.823973  2.662597     18.347260  1.219338        190.102740   \nChinstrap      48.833824  3.339256     18.420588  1.135395        195.823529   \nGentoo         47.568067  3.106116     14.996639  0.985998        217.235294   \n\n                     body_mass_g                     year            \n                std         mean         std         mean       std  \nspecies                                                              \nAdelie     6.521825  3706.164384  458.620135  2008.054795  0.811816  \nChinstrap  7.131894  3733.088235  384.335081  2007.970588  0.863360  \nGentoo     6.585431  5092.436975  501.476154  2008.067227  0.789025  \n\n\nNella cella seguente troviamo la media di body_mass_g e flipper_length_mm separatamente per ciascuna isola e ciascuna specie:\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].mean()\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n188.795455\n\n\nGentoo\n5092.436975\n217.235294\n\n\nDream\nAdelie\n3701.363636\n189.927273\n\n\nChinstrap\n3733.088235\n195.823529\n\n\nTorgersen\nAdelie\n3708.510638\n191.531915\n\n\n\n\n\n\n\n\nFacciamo la stessa cosa per la deviazione standard.\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].std(ddof=1)\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n487.733722\n6.729247\n\n\nGentoo\n501.476154\n6.585431\n\n\nDream\nAdelie\n448.774519\n6.480325\n\n\nChinstrap\n384.335081\n7.131894\n\n\nTorgersen\nAdelie\n451.846351\n6.220062\n\n\n\n\n\n\n\n\nPrestiamo attenzione alla seguente sintassi:\n\nsummary_stats = (\n    df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]\n    .groupby([\"island\", \"species\"])\n    .aggregate([\"mean\", \"std\", \"count\"])\n)\nsummary_stats\n\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\n\n\nmean\nstd\ncount\nmean\nstd\ncount\n\n\nisland\nspecies\n\n\n\n\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n487.733722\n44\n188.795455\n6.729247\n44\n\n\nGentoo\n5092.436975\n501.476154\n119\n217.235294\n6.585431\n119\n\n\nDream\nAdelie\n3701.363636\n448.774519\n55\n189.927273\n6.480325\n55\n\n\nChinstrap\n3733.088235\n384.335081\n68\n195.823529\n7.131894\n68\n\n\nTorgersen\nAdelie\n3708.510638\n451.846351\n47\n191.531915\n6.220062\n47\n\n\n\n\n\n\n\n\nNell‚Äôistruzione precedente selezioniamo tutte le righe (:) di tre colonne di interesse: df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]. L‚Äôistruzione .groupby([\"island\", \"species\"]) ragruppa le osservazioni (righe) secondo le modalit√† delle variabili island e species. Infine .aggregate([\"mean\", \"std\", \"count\"]) applica i metodi statistici specificati a ciascun gruppo di osservazioni. Con questa sintassi la sequenza delle operazioni da eseguire diventa molto intuitiva.\n√à possibile approfondire questo argomento consultanto il capitolo 10 del testo Python for Data Analysis di McKinney (2022).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "title": "6¬† Pandas (2)",
    "section": "6.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "6.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.11.4\nseaborn   : 0.13.0\nnumpy     : 1.26.2\npandas    : 2.1.4\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. \" O‚ÄôReilly Media, Inc.\".",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html",
    "href": "chapters/python/06_pandas_functions.html",
    "title": "7¬† Pandas (3)",
    "section": "",
    "text": "7.1 pd.read_csv, pd.read_excel\nLa prima funzione da menzionare √® read_csv o read_excel. Le funzioni vengono utilizzate per leggere un file CSV o un file Excel in formato DataFrame di Pandas. Qui stiamo utilizzando la funzione read_csv per leggere il dataset penguins. In precedenza abbiamo anche visto come la funzione dropna viene utilizzata per rimuovere tutte le righe del DataFrame che includono dati mancanti.\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\ndf.tail()\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#columns",
    "href": "chapters/python/06_pandas_functions.html#columns",
    "title": "7¬† Pandas (3)",
    "section": "7.2 .columns",
    "text": "7.2 .columns\nQuando si dispone di un grande dataset, pu√≤ essere difficile visualizzare tutte le colonne. Utilizzando la funzione columns, √® possibile stampare tutte le colonne del dataset.\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#drop",
    "href": "chapters/python/06_pandas_functions.html#drop",
    "title": "7¬† Pandas (3)",
    "section": "7.3 .drop()",
    "text": "7.3 .drop()\n√à possibile eliminare alcune colonne non necessarie utilizzando drop.\n\ndf = df.drop(columns=[\"year\"])\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#len",
    "href": "chapters/python/06_pandas_functions.html#len",
    "title": "7¬† Pandas (3)",
    "section": "7.4 len()",
    "text": "7.4 len()\nFornisce il numero di righe di un DataFrame.\n\nlen(df)\n\n333",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#query",
    "href": "chapters/python/06_pandas_functions.html#query",
    "title": "7¬† Pandas (3)",
    "section": "7.5 .query()",
    "text": "7.5 .query()\n√à possibile filtrare un DataFrame utilizzando un‚Äôespressione booleana.\n\ndf1 = df.query(\"species == 'Chinstrap' & island == 'Dream'\")\nlen(df1)\n\n68",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#iloc",
    "href": "chapters/python/06_pandas_functions.html#iloc",
    "title": "7¬† Pandas (3)",
    "section": "7.6 .iloc[]",
    "text": "7.6 .iloc[]\nQuesta funzione accetta come parametri gli indici delle righe e delle colonne, fornendo una selezione del DataFrame in base a questi. In questo caso, stiamo selezionando le prime 3 righe di dati e le colonne con indice 2, 3 e 5.\n\ndf2 = df.iloc[:3, [2, 3, 5]]\ndf2\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nbody_mass_g\n\n\n\n\n0\n39.1\n18.7\n3750.0\n\n\n1\n39.5\n17.4\n3800.0\n\n\n2\n40.3\n18.0\n3250.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#loc",
    "href": "chapters/python/06_pandas_functions.html#loc",
    "title": "7¬† Pandas (3)",
    "section": "7.7 .loc[]",
    "text": "7.7 .loc[]\nQuesta funzione compie un‚Äôoperazione molto simile a quella della funzione .iloc. Tuttavia, in questo caso, abbiamo la possibilit√† di specificare gli indici delle righe che desideriamo, insieme ai nomi delle colonne che vogliamo includere nella nostra selezione.\n\ndf3 = df.loc[[2, 4, 6], [\"island\", \"flipper_length_mm\", \"sex\"]]\ndf3\n\n\n\n\n\n\n\n\n\nisland\nflipper_length_mm\nsex\n\n\n\n\n2\nTorgersen\n195.0\nfemale\n\n\n4\nTorgersen\n193.0\nfemale\n\n\n6\nTorgersen\n181.0\nfemale",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "title": "7¬† Pandas (3)",
    "section": "7.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "7.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.0\nnumpy     : 1.26.2\narviz     : 0.17.0\npandas    : 2.1.4\nmatplotlib: 3.8.2\nscipy     : 1.11.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html",
    "href": "chapters/python/07_matplotlib.html",
    "title": "8¬† Matplotlib",
    "section": "",
    "text": "8.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\n# Questa istruzione consente di visualizzare i grafici generati dai comandi di \n# plot direttamente all'interno del notebook.\n%config InlineBackend.figure_format = 'retina'\n\n# Questo valore viene usato come seed per il random number generator.\nRANDOM_SEED = 42\n\n# In questa riga, stai utilizzando il generatore di numeri casuali di NumPy per \n# creare una nuova istanza denominata rng. La funzione np.random.default_rng() viene \n# utilizzata per inizializzare un generatore di numeri casuali con un seme specifico, \n# che in questo caso √® RANDOM_SEED.\nrng = np.random.default_rng(RANDOM_SEED)\n\n# Queste due righe di codice sono spesso utilizzate per personalizzare l'aspetto dei \n# grafici in Python utilizzando le librerie ArviZ e Seaborn.\n# Questa riga di codice utilizza il metodo use() della libreria ArviZ per impostare uno \n# stile specifico per i tuoi grafici. In particolare, sta impostando lo stile chiamato \n# \"arviz-darkgrid\". Gli stili in ArviZ determinano come saranno visualizzati i grafici, inclusi colori, linee di griglia e altri dettagli estetici.\naz.style.use(\"arviz-darkgrid\")\n\n# Questa riga di codice utilizza la libreria Seaborn per impostare il tema dei grafici. \n# In questo caso, il tema viene impostato utilizzando set_theme() con il parametro palette \n# impostato su \"colorblind\". Questo significa che i colori utilizzati nei grafici saranno \n# scelti in modo da essere adatti alle persone con deficit visivi dei colori, rendendo i \n# grafici pi√π accessibili.\nsns.set_theme(palette=\"colorblind\")",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "href": "chapters/python/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "title": "8¬† Matplotlib",
    "section": "8.2 L‚ÄôInterfaccia pyplot per Creare Grafici",
    "text": "8.2 L‚ÄôInterfaccia pyplot per Creare Grafici\nMatplotlib √® una libreria in Python famosa per la creazione di grafici, e la sua interfaccia pyplot √® particolarmente apprezzata per la sua semplicit√†. Vediamo in dettaglio come funzionano le sue funzioni principali. Per comprendere meglio come funzionano le sue funzioni principali, possiamo fare un parallelo con il disegno su un supporto fisico.\n\nPrepariamo la Tela: Iniziamo con plt.figure(), che √® analogo a ottenere una tela bianca pronta per essere dipinta. √à il punto di partenza, una superficie vuota su cui creeremo il nostro grafico.\nDefiniamo le Aree di Disegno: Successivamente, utilizzando plt.subplot() o plt.axes(), creiamo delle aree specifiche o ‚Äúassi‚Äù sulla nostra tela. Questi assi corrispondono a diverse sezioni in cui posizioneremo vari elementi del nostro grafico, come se suddividessimo la tela fisica in diverse parti.\nAggiungiamo Elementi al Grafico: Una volta definiti gli assi, entriamo nel processo di creazione. Usandando funzioni come plt.plot() per tracciare linee o plt.scatter() per punti, aggiungiamo elementi grafici alla nostra area di disegno. √à simile a disegnare direttamente sulla tela fisica.\nRendiamo il Grafico Comprensibile: Per garantire che il grafico sia chiaro e informativo, aggiungiamo etichette e titoli con plt.xlabel(), plt.ylabel() e plt.title().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "href": "chapters/python/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "title": "8¬† Matplotlib",
    "section": "8.3 Principi Fondamentali di Pyplot",
    "text": "8.3 Principi Fondamentali di Pyplot\nEsploriamo le funzionalit√† essenziali di pyplot di Matplotlib:\n\nCreazione di Grafici Lineari: Utilizzando plt.plot(x, y), √® possibile generare grafici lineari. Questa funzione necessita delle coordinate x e y per disegnare il grafico, semplificando cos√¨ la rappresentazione visiva dei dati.\nDenominazione degli Assi: √à fondamentale assegnare un‚Äôetichetta appropriata agli assi per migliorare la comprensione del grafico. Si possono denominare gli assi tramite plt.xlabel('Nome') per l‚Äôasse X e plt.ylabel('Nome') per l‚Äôasse Y, facilitando l‚Äôinterpretazione dei dati visualizzati.\nInserimento del Titolo: Un titolo descrittivo clarifica lo scopo o il contesto del grafico. Aggiungere un titolo √® semplice con plt.title('Titolo'), che aiuta a comunicare il messaggio principale del grafico in modo efficace.\nInserimento di Legende: Per grafici che includono pi√π serie di dati o elementi distinti, l‚Äôaggiunta di una legenda √® cruciale per la distinzione tra questi. La funzione plt.legend() permette di integrare una legenda, migliorando la leggibilit√† del grafico.\nEsposizione del Grafico: Una volta completata la composizione del grafico, il passo finale √® la sua visualizzazione. Attraverso plt.show(), √® possibile mostrare il grafico elaborato, offrendo una visione complessiva dei dati analizzati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "href": "chapters/python/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "title": "8¬† Matplotlib",
    "section": "8.4 Esempio 1: Grafico lineare semplice",
    "text": "8.4 Esempio 1: Grafico lineare semplice\n\nx = [1, 2, 3, 4]\ny = [10, 20, 30, 40]\n\nplt.plot(x, y)\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico Lineare Semplice\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "href": "chapters/python/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "title": "8¬† Matplotlib",
    "section": "8.5 Esempio 2: Grafico con legenda e stile",
    "text": "8.5 Esempio 2: Grafico con legenda e stile\n\nx = [1, 2, 3, 4]\ny1 = [10, 20, 30, 40]\ny2 = [5, 15, 25, 35]\n\nplt.plot(x, y1, label=\"Linea 1\", color=\"C0\", linestyle=\"--\")\nplt.plot(x, y2, label=\"Linea 2\", color=\"C3\", linestyle=\"-\")\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico con Legenda\")\nplt.legend();",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-3-istogramma",
    "href": "chapters/python/07_matplotlib.html#esempio-3-istogramma",
    "title": "8¬† Matplotlib",
    "section": "8.6 Esempio 3: Istogramma",
    "text": "8.6 Esempio 3: Istogramma\n\ndata = rng.normal(100, 15, 1000)\n\nplt.hist(data, bins=20)\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Istogramma\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-4-pannelli-multipli",
    "href": "chapters/python/07_matplotlib.html#esempio-4-pannelli-multipli",
    "title": "8¬† Matplotlib",
    "section": "8.7 Esempio 4: pannelli multipli",
    "text": "8.7 Esempio 4: pannelli multipli\nFacciamo un altro esempio usando i dati penguins.csv.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\n\n\nplt.figure(figsize=(9, 8))\n\nplt.subplot(2, 2, 1)\nplt.hist(df[\"bill_depth_mm\"], 10, density=True, color=\"C3\")\nplt.title(\"Bill depth (mm)\");\n\nplt.subplot(2, 2, 2)\nsns.kdeplot(df[\"bill_length_mm\"], fill=True)\nplt.title(\"KDE of Bill length (mm)\");\n\nplt.subplot(2, 2, 3)\nplt.scatter(x=df[\"bill_length_mm\"], y=df[\"bill_depth_mm\"], alpha=0.4)\nplt.title(\"Bill depth as a function of bill length\");\n\nplt.subplot(2, 2, 4)\nplt.boxplot(df[\"bill_length_mm\"])\nplt.title(\"Boxplot of Bill Length (mm)\")\n\nplt.tight_layout()\n\n/var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_55046/1324325854.py:19: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nGli indici in plt.subplot() sono utilizzati per specificare come dividere una figura in diverse aree di tracciamento, chiamate ‚Äúsubplots‚Äù. La funzione plt.subplot(nrows, ncols, index) prende tre argomenti principali:\n\nnrows: Numero di righe in cui la figura sar√† suddivisa.\nncols: Numero di colonne in cui la figura sar√† suddivisa.\nindex: Indice del subplot su cui operare, partendo dall‚Äôangolo in alto a sinistra e proseguendo da sinistra a destra e dall‚Äôalto in basso.\n\nNel codice precedente, plt.subplot(2, 2, 1) indica che la figura sar√† divisa in una griglia 2x2 (2 righe e 2 colonne) e che la funzione plt.hist() agir√† sul primo subplot, che si trover√† nell‚Äôangolo in alto a sinistra.\nGli altri indici (2, 3, 4) selezionano rispettivamente il secondo subplot (in alto a destra), il terzo subplot (in basso a sinistra) e il quarto subplot (in basso a destra) della griglia 2x2.\nEcco come i subplot sono organizzati sulla figura:\n+---------------------+----------------------+\n|  plt.subplot(2,2,1) |  plt.subplot(2,2,2)  |\n+---------------------+----------------------+\n|  plt.subplot(2,2,3) |  plt.subplot(2,2,4)  |\n+---------------------+----------------------+\nOgni volta che si chiama plt.subplot() con un nuovo indice, il ‚Äúcurrent axes‚Äù cambia per puntare al subplot specificato. Quindi, le funzioni di tracciamento come plt.hist(), sns.kdeplot(), plt.scatter() e plt.boxplot() saranno applicate al subplot attualmente selezionato.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "title": "8¬† Matplotlib",
    "section": "8.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "8.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Feb 03 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.2\narviz     : 0.17.0\nmatplotlib: 3.8.2\npandas    : 2.1.4\nseaborn   : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html",
    "href": "chapters/python/08_seaborn.html",
    "title": "9¬† Seaborn",
    "section": "",
    "text": "9.1 Elevare la Visualizzazione dei Dati con Seaborn\nNel capitolo precedente, abbiamo esaminato Matplotlib, una libreria estremamente versatile per la visualizzazione dei dati in Python. Ora esamineremo le funzionalit√† di Seabonrn. Seaborn, che si basa su Matplotlib, arricchisce l‚Äôesperienza di visualizzazione dei dati offrendo una gamma pi√π ampia e specializzata di opzioni grafiche, particolarmente utili nel campo della data science.\nIl vero punto di forza di Seaborn √® la sua capacit√† di migliorare non solo l‚Äôaspetto estetico dei grafici ma anche di facilitare la creazione di visualizzazioni pi√π complesse. Questo rende il processo pi√π diretto e intuitivo. La libreria √® dotata di un‚Äôampia variet√† di strumenti, dalle mappe di calore ai grafici a violino, permettendo agli utenti di esplorare e rappresentare i dati in modi innovativi e informativi.\nPer chi vuole approfondire ulteriormente, i tutorial presenti sul sito ufficiale di Seaborn sono una risorsa preziosa e facilmente accessibile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#preparazione-del-notebook",
    "href": "chapters/python/08_seaborn.html#preparazione-del-notebook",
    "title": "9¬† Seaborn",
    "section": "9.2 Preparazione del Notebook",
    "text": "9.2 Preparazione del Notebook\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport arviz as az\n\n\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"seaborn\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "href": "chapters/python/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "title": "9¬† Seaborn",
    "section": "9.3 Visualizzare la distribuzione dei dati",
    "text": "9.3 Visualizzare la distribuzione dei dati\nVediamo alcuni esempi pratici per scoprire come Seaborn possa trasformare il modo in cui visualizziamo i dati.\nConsideriamo nuovamente i dati Palmer penguin.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nUna delle forme di visualizzazione pi√π comuni e informative nel campo dell‚Äôanalisi dei dati √® l‚Äôistogramma, e la sua variante pi√π sofisticata, l‚Äôistogramma lisciato. Vediamo dunque come generare istogrammi che, per il DataFrame df, sono stratificati sia in base alla specie che al genere dei pinguini.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n);\n\nGeneriamo la stessa figura usando questa volta gli istogrammi lisciati.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    height=3, kind=\"kde\", facet_kws=dict(margin_titles=True),\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "href": "chapters/python/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "title": "9¬† Seaborn",
    "section": "9.4 Visualizzazione di dati categoriali",
    "text": "9.4 Visualizzazione di dati categoriali\nConsideriamo ora il caso in cui si vuole rappresentare la relazione tra una variabile numerica e una o pi√π variabili categoriali.\nConsideriamo, ad esempio, la massa corporea in relazione alla specie, differenziando le osservazioni per genere. Creiamo il grafico utilizzando i boxplot.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"box\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\n\n\n\n\nDai diagrammi risulta evidente che i pinguini maschi hanno un peso maggiore rispetto alle femmine in tutte le specie, e che i pinguini Gentoo hanno un peso superiore rispetto ad Adelie e Chinstrap.\nCome alternativa, possiamo utilizzare il violinplot per la rappresentazione grafica dei dati.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"violin\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#relazioni-tra-variabili",
    "href": "chapters/python/08_seaborn.html#relazioni-tra-variabili",
    "title": "9¬† Seaborn",
    "section": "9.5 Relazioni tra variabili",
    "text": "9.5 Relazioni tra variabili\nCalcoliamo la correlazione tra le variabili.\n\nvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\ncorr_matrix = df[vars].corr().round(2)\ncorr_matrix\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.00\n-0.24\n0.66\n0.60\n\n\nbill_depth_mm\n-0.24\n1.00\n-0.58\n-0.47\n\n\nflipper_length_mm\n0.66\n-0.58\n1.00\n0.87\n\n\nbody_mass_g\n0.60\n-0.47\n0.87\n1.00\n\n\n\n\n\n\n\n\nQueste informazioni possono essere comunicate in forma pi√π diretta se usiamo una rappresentazione grafica.\n\nsns.heatmap(corr_matrix, annot=True, linecolor=\"white\", linewidths=5);\n\n\n\n\n\n\n\n\nLa lunghezza della pinna e la massa corporea mostrano un forte legame, con una correlazione di 0.87. Ci√≤ indica che i pinguini con pinne pi√π lunghe tendono a pesare di pi√π.\nDi seguito √® riportato un esempio di diagramma a dispersione che illustra questa relazione.\n\nsns.scatterplot(df, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\");\n\n\n\n\n\n\n\n\nEvidentemente, le osservazioni delle tre specie formano cluster distinti. Per ciascuna specie, la lunghezza e la larghezza del becco presentano un intervallo specifico.\nSpesso √® vantaggioso creare grafici separati in base a diverse dimensioni dei dati; nell‚Äôesempio seguente, suddividiamo i dati in base all‚Äôisola di appartenenza.\n\ng = sns.relplot(\n    data=df,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\",\n    row=\"sex\",\n    col=\"island\",\n    height=3,\n    facet_kws=dict(margin_titles=True),\n)\ng.set_axis_labels(\n    \"Bill length (mm)\",\n    \"Bill depth (mm)\",\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "title": "9¬† Seaborn",
    "section": "9.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "9.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 08 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\narviz     : 0.18.0\npandas    : 2.2.2\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Introduzione",
    "section": "",
    "text": "La data science √® un campo che si sviluppa all‚Äôintersezione tra la statistica e l‚Äôinformatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l‚Äôinformatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell‚Äôanalisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html",
    "href": "chapters/key_notions/01_key_notions.html",
    "title": "10¬† Concetti chiave",
    "section": "",
    "text": "Introduzione\nL‚Äôanalisi dei dati si colloca all‚Äôintersezione tra statistica, teoria della probabilit√† e informatica. Questa disciplina multidisciplinare richiede una solida comprensione dei concetti fondamentali provenienti da ciascuna di queste tre aree.\nLa statistica fornisce gli strumenti e le tecniche per raccogliere, analizzare e interpretare i dati. Attraverso metodi descrittivi e inferenziali, permette di trarre conclusioni dai dati e di prendere decisioni informate.\nLa statistica fornisce gli strumenti e le tecniche per raccogliere, analizzare e interpretare i dati. Attraverso metodi descrittivi e inferenziali, la statistica permette di trarre conclusioni dai dati e di prendere decisioni informate.\nLa teoria della probabilit√† costituisce la base matematica della statistica, modellando l‚Äôincertezza e comprendendo i fenomeni aleatori, fornendo i fondamenti per sviluppare metodi statistici rigorosi.\nL‚Äôinformatica gioca un ruolo cruciale nell‚Äôanalisi dei dati, offrendo gli strumenti necessari per la gestione, l‚Äôelaborazione e la visualizzazione dei dati su larga scala. Conoscere i principi dell‚Äôinformatica √® essenziale per sfruttare appieno tecnologie moderne come il machine learning e l‚Äôintelligenza artificiale. L‚Äôuso di linguaggi di programmazione come Python e R, insieme a librerie specializzate, permette di eseguire analisi complesse e di visualizzare i dati in modo efficace.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#introduzione",
    "href": "chapters/key_notions/01_key_notions.html#introduzione",
    "title": "10¬† Concetti chiave",
    "section": "",
    "text": "Statistica\n\n\n\nIl termine ‚Äústatistica‚Äù pu√≤ assumere diversi significati, a seconda del contesto in cui viene utilizzato.\n\nNel primo senso, la statistica √® una scienza e una disciplina che si occupa dello studio e dell‚Äôapplicazione di metodi e tecniche per la raccolta, l‚Äôorganizzazione, l‚Äôanalisi, l‚Äôinterpretazione e la presentazione di dati.\nNel secondo senso, il termine ‚Äústatistica‚Äù si riferisce a una singola misura o un valore numerico che √® stato calcolato a partire da un campione di dati. Questo tipo di statistica rappresenta una caratteristica specifica del campione. Esempi comuni di statistiche in questo senso includono la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#popolazioni-e-campioni",
    "href": "chapters/key_notions/01_key_notions.html#popolazioni-e-campioni",
    "title": "10¬† Concetti chiave",
    "section": "10.1 Popolazioni e Campioni",
    "text": "10.1 Popolazioni e Campioni\nPer iniziare l‚Äôanalisi dei dati, √® fondamentale individuare le unit√† che contengono le informazioni rilevanti per il fenomeno di interesse. Questo insieme di unit√† costituisce la popolazione o universo, rappresentando l‚Äôinsieme completo di entit√† capaci di fornire informazioni per l‚Äôindagine statistica in questione. Le singole unit√† dell‚Äôinsieme sono chiamate unit√† statistiche.\nNella ricerca psicologica, sia nelle ricerche sperimentali che in quelle osservazionali, l‚Äôobiettivo principale √® studiare i fenomeni psicologici all‚Äôinterno di una specifica popolazione. √à essenziale definire con chiarezza la popolazione di interesse, ovvero l‚Äôinsieme di individui ai quali verranno applicati i risultati della ricerca. Tale popolazione pu√≤ essere reale, come tutte le persone sopravvissute per un anno dopo il bombardamento atomico di Hiroshima, o ipotetica, come tutte le persone depresse che potrebbero beneficiare di un intervento psicologico.\n\n10.1.1 Sotto-popolazioni e Campioni\nUna sotto-popolazione √® un sottoinsieme di individui che possiedono propriet√† specifiche ben definite. Ad esempio, potremmo essere interessati alla sotto-popolazione degli uomini di et√† inferiore ai 30 anni o dei pazienti depressi che hanno ricevuto uno specifico intervento psicologico. Il campione √® un sottoinsieme della popolazione composto da elementi che rappresentano unit√† statistiche (u.s.) portatrici delle informazioni rilevate tramite misurazione. Il campione viene utilizzato per ottenere informazioni sulla popolazione di riferimento.\n\n\n10.1.2 Metodi di Campionamento\nIl campionamento pu√≤ avvenire in diversi modi. Il campionamento casuale consente al ricercatore di trarre conclusioni sulla popolazione e di quantificare l‚Äôincertezza dei risultati, come avviene in un sondaggio. Tuttavia, esistono anche altre forme di campionamento, come il campione di convenienza o il campionamento stratificato.\nIl ricercatore deve sempre considerare la rappresentativit√† statistica del campione, ovvero se il campione scelto riflette accuratamente le caratteristiche di interesse della popolazione. In molti casi, soprattutto in psicologia, possono essere usati metodi di campionamento diversi dal casuale a seconda delle risorse disponibili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#i-bias-nella-raccolta-dati",
    "href": "chapters/key_notions/01_key_notions.html#i-bias-nella-raccolta-dati",
    "title": "10¬† Concetti chiave",
    "section": "10.2 I Bias nella Raccolta Dati",
    "text": "10.2 I Bias nella Raccolta Dati\n√à importante tenere presenti i bias che governano la raccolta dei dati. I dati non sono mai ‚Äúneutri‚Äù e il contenuto dei dati raccolti, insieme alle intenzioni che guidano la raccolta, spesso dettano i parametri della nostra comprensione (Nobles 2000).\nAd esempio, Johnson (2021) confronta due modalit√† di raccolta dati riguardanti le persone incarcerate negli Stati Uniti: quella statale e quella comunitaria. La raccolta dati statale si concentra su informazioni demografiche e statistiche di base, perpetuando una comprensione limitata e spesso distorta del sistema carcerario. Al contrario, la raccolta dati comunitaria include dettagli pi√π specifici sulle condizioni di vita e gli effetti della detenzione, offrendo una visione pi√π completa e umana della realt√† carceraria.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#variabili-e-costanti",
    "href": "chapters/key_notions/01_key_notions.html#variabili-e-costanti",
    "title": "10¬† Concetti chiave",
    "section": "10.3 Variabili e Costanti",
    "text": "10.3 Variabili e Costanti\nNell‚Äôanalisi statistica, le variabili denotano le caratteristiche che possono assumere diversi valori, sia numerici che categoriali. Le costanti, al contrario, sono valori che non variano tra le unit√† di osservazione. Le variabili indipendenti (o predittive) rappresentano i fattori che si ipotizza influenzino l‚Äôesito di interesse, mentre le variabili dipendenti rappresentano l‚Äôesito che si cerca di spiegare o prevedere.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#effetto",
    "href": "chapters/key_notions/01_key_notions.html#effetto",
    "title": "10¬† Concetti chiave",
    "section": "10.4 Effetto",
    "text": "10.4 Effetto\nIl concetto di ‚Äúeffetto‚Äù misura il cambiamento o l‚Äôinfluenza tra le variabili. Ad esempio, consideriamo uno studio che indaga l‚Äôeffetto delle mnemotecniche sul miglioramento della memoria. Se il gruppo che ha seguito un workshop mnemonico mostra un punteggio medio superiore, si pu√≤ affermare che le mnemotecniche hanno un effetto positivo sulla memoria. L‚Äôeffetto viene misurato attraverso diverse statistiche, come la differenza di medie o il rapporto di probabilit√† (Huntington-Klein 2021).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#variabili-casuali",
    "href": "chapters/key_notions/01_key_notions.html#variabili-casuali",
    "title": "10¬† Concetti chiave",
    "section": "10.5 Variabili Casuali",
    "text": "10.5 Variabili Casuali\nNel contesto della teoria delle probabilit√†, una variabile casuale rappresenta una quantit√† che pu√≤ assumere diversi valori con una certa probabilit√†. Dopo l‚Äôosservazione e la misurazione, una variabile casuale diventa una variabile statistica, trasformando un‚Äôincertezza teorica in una certezza empirica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#stima-e-inferenza",
    "href": "chapters/key_notions/01_key_notions.html#stima-e-inferenza",
    "title": "10¬† Concetti chiave",
    "section": "10.6 Stima e Inferenza",
    "text": "10.6 Stima e Inferenza\n\n10.6.1 Stima\nLa stima statistica permette di dedurre le caratteristiche di un‚Äôintera popolazione partendo dall‚Äôanalisi di un campione rappresentativo. Gli elementi chiave della stima statistica sono i seguenti.\n\nParametri della popolazione:\n\nsono le caratteristiche numeriche che descrivono la popolazione;\nesempi includono la media (Œº), la varianza (œÉ¬≤), la proporzione (p), ecc.;\ngeneralmente non sono noti e devono essere stimati.\n\nStatistiche campionarie:\n\nsono calcolate dai dati del campione;\nfungono da stimatori dei parametri della popolazione;\nesempi: media campionaria (xÃÑ), varianza campionaria (s¬≤), proporzione campionaria (pÃÇ).\n\nTipi di stime:\n\npuntuale: fornisce un singolo valore come miglior stima del parametro;\nintervallare: offre un range di valori plausibili per il parametro, con un certo livello di credibilit√† o confidenza.\n\nPropriet√† degli stimatori:\n\nconsistenza: la stima converge al vero valore del parametro all‚Äôaumentare della dimensione del campione;\nnon distorsione: il valore atteso dello stimatore √® uguale al vero valore del parametro;\nefficienza: lo stimatore ha la minor varianza possibile.\n\n\nL‚Äôaccuratezza della stima dipende da vari fattori, tra cui la dimensione e la rappresentativit√† del campione, la variabilit√† nella popolazione e il metodo di campionamento utilizzato.\n\n\n10.6.2 Inferenza Statistica\nDopo aver ottenuto queste stime, si passa al passaggio successivo: l‚Äôinferenza statistica. Questo processo va oltre la semplice stima e ci permette di trarre conclusioni pi√π ampie sulla popolazione. L‚Äôinferenza statistica riguarda la valutazione di specifiche ipotesi o risposte a domande di ricerca relative alla popolazione, utilizzando le stime ottenute dal campione.\nAd esempio, se abbiamo stimato la media dei redditi in un campione di famiglie, possiamo utilizzare l‚Äôinferenza statistica per testare se c‚Äô√® una differenza significativa nei redditi tra diverse regioni o gruppi demografici all‚Äôinterno della popolazione. In questo modo, l‚Äôinferenza statistica ci fornisce gli strumenti per fare previsioni e trarre conclusioni riguardanti la popolazione intera.\nEsistono vari approcci e metodologie per condurre l‚Äôinferenza statistica, tra cui due dei pi√π comuni sono l‚Äôinferenza bayesiana e l‚Äôapproccio frequentista.\nL‚Äôinferenza bayesiana:\n\nsi fonda sul teorema di Bayes;\nutilizza probabilit√† a priori, che rappresentano le conoscenze o le credenze iniziali su un fenomeno;\naggiorna queste probabilit√† con nuovi dati per ottenere probabilit√† a posteriori;\noffre una interpretazione diretta delle probabilit√† come gradi di credenza.\n\nL‚Äôapproccio frequentista:\n\nsi basa sulla frequenza relativa di eventi in esperimenti ripetuti;\nutilizza tecniche come il test dell‚Äôipotesi nulla e gli intervalli di confidenza;\nnon fa uso di probabilit√† a priori.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#le-tre-sfide-della-statistica",
    "href": "chapters/key_notions/01_key_notions.html#le-tre-sfide-della-statistica",
    "title": "10¬† Concetti chiave",
    "section": "10.7 Le tre sfide della statistica",
    "text": "10.7 Le tre sfide della statistica\nSecondo Gelman, Hill, e Vehtari (2020), le tre principali sfide dell‚Äôinferenza statistica sono:\n\nGeneralizzare dai campioni alla popolazione, un problema spesso associato al campionamento di comodo, comune nella psicologia, ma che si manifesta in quasi tutte le applicazioni dell‚Äôinferenza statistica;\nGeneralizzare dal gruppo trattato al gruppo di controllo, un problema legato all‚Äôinferenza causale, che √® una componente essenziale, sia implicita che esplicita, nell‚Äôinterpretazione della maggior parte degli studi sull‚Äôefficacia dei trattamenti psicologici; e\nGeneralizzare dalle misurazioni osservate ai costrutti sottostanti di interesse, poich√© i dati psicologici raramente riflettono esattamente ci√≤ che vorremmo studiare.\n\nTutte e tre queste sfide possono essere inquadrate come problemi di previsione: per nuove persone o nuovi item non inclusi nel campione, per risultati futuri sotto diversi trattamenti potenzialmente assegnati, e per i costrutti sottostanti di interesse, se potessero essere misurati con precisione.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "title": "10¬† Concetti chiave",
    "section": "10.8 Modelli Psicologici",
    "text": "10.8 Modelli Psicologici\nUn ‚Äúmodello‚Äù rappresenta una formulazione matematica semplificata di un fenomeno reale che si desidera studiare. Si tratta di un insieme di equazioni e ipotesi che delineano la struttura probabilistica e le relazioni tra le variabili, cercando di catturare gli aspetti essenziali del fenomeno senza rappresentarlo in ogni dettaglio. Poich√© spesso esistono diversi modelli che possono essere applicati allo stesso problema, la data science si occupa dell‚Äôidentificazione del modello che meglio si adatta ai dati e che soddisfa specifici criteri di validit√† e accuratezza.\nI modelli psicologici sono strumenti concettuali utilizzati per descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un modello psicologico robusto e valido deve soddisfare diverse caratteristiche essenziali:\n\nCoerenza descrittiva: Il modello deve fornire una rappresentazione logica e internamente coerente del fenomeno studiato. Deve catturare gli elementi essenziali del processo psicologico in esame, offrendo una struttura concettuale che organizzi le osservazioni in modo significativo e comprensibile.\nCapacit√† predittiva: Un aspetto cruciale di un modello psicologico efficace √® la sua abilit√† di formulare predizioni accurate sulle manifestazioni future del fenomeno. Questa caratteristica non solo aumenta l‚Äôutilit√† pratica del modello, ma fornisce anche un mezzo per testarne la validit√†.\nSupporto empirico: Il modello deve essere ancorato a solide prove empiriche. Ci√≤ implica che le sue assunzioni e previsioni devono essere confermate da dati osservabili raccolti attraverso ricerche sistematiche e metodologicamente rigorose.\nFalsificabilit√†: Forse la caratteristica pi√π critica, la falsificabilit√†, richiede che il modello sia costruito in modo da poter essere sottoposto a verifica o confutazione attraverso l‚Äôosservazione e l‚Äôesperimento. Questo principio, fondamentale per il metodo scientifico, assicura che il modello rimanga aperto al scrutinio critico e alla revisione basata su nuove evidenze.\nParsimonia: Un buon modello psicologico dovrebbe essere parsimonioso. Dovrebbe spiegare il fenomeno nel modo pi√π semplice possibile, evitando complessit√† non necessarie.\nGeneralizzabilit√†: Il modello dovrebbe essere applicabile a una vasta gamma di situazioni e contesti, non solo a specifici casi o condizioni sperimentali.\nUtilit√† pratica: Infine, un modello psicologico efficace dovrebbe avere implicazioni pratiche, fornendo insights utili per interventi, terapie o applicazioni nel mondo reale.\n\nLa modellazione in psicologia si trova spesso di fronte a sfide uniche dovute alla natura soggettiva e variabile dell‚Äôesperienza umana. I ricercatori devono bilanciare la necessit√† di precisione scientifica con la flessibilit√† richiesta per catturare la ricchezza e la complessit√† dei fenomeni psicologici. Inoltre, devono essere consapevoli dei limiti etici nella sperimentazione e delle potenziali implicazioni sociali dei loro modelli.\nLa creazione e l‚Äôutilizzo di modelli in psicologia √® un processo dinamico e iterativo. I modelli sono costantemente raffinati, testati e, se necessario, rivisti o sostituiti man mano che emergono nuove evidenze.\nL‚Äôanalisi dei dati, attraverso l‚Äôapplicazione di tecniche statistiche, √® il mezzo attraverso il quale un modello psicologico viene valutato. Oltre a determinare se il modello √® in grado di spiegare i dati osservati, l‚Äôanalisi pu√≤ anche verificare la capacit√† del modello di fare previsioni accurate su dati non ancora osservati. In questo modo, la modellazione diventa uno strumento potente non solo per comprendere i fenomeni psicologici ma anche per prevedere e, in alcuni casi, influenzare il comportamento e le dinamiche mentali.\nIn sintesi, un modello, sia in statistica che in psicologia, √® uno strumento teorico che cerca di rappresentare un fenomeno complesso in una forma semplificata ma informativa, guidando la comprensione, la previsione e, in ultima analisi, l‚Äôintervento efficace su quel fenomeno. La scelta e la valutazione del modello giusto sono fondamentali per garantire che le conclusioni derivanti dall‚Äôanalisi siano valide e utili nel contesto specifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/key_notions/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "title": "10¬† Concetti chiave",
    "section": "10.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "10.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nHuntington-Klein, Nick. 2021. The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nJohnson, Kaneesha R. 2021. ¬´Two regimes of prison data collection¬ª. Harvard Data Science Review 3 (3): 10‚Äì1162.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nNobles, Melissa. 2000. Shades of citizenship: Race and the census in modern politics. Stanford University Press.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html",
    "href": "chapters/key_notions/02_measurement.html",
    "title": "11¬† La misurazione in psicologia",
    "section": "",
    "text": "11.1 Introduzione\nIl primo passo in qualsiasi studio scientifico √® rappresentare numericamente oggetti del mondo reale e le loro relazioni in modo tale che possano essere analizzati attraverso metodi statistici. Esiste un‚Äôintera disciplina scientifica, chiamata teoria della misurazione, dedicata a questo argomento. La teoria della misurazione distingue tra una procedura di misurazione e il costrutto che si desidera misurare.\nAd esempio, la temperatura fisica √® un costrutto, mentre il termometro √® un dispositivo di misurazione. Analogamente, l‚Äôabilit√† matematica √® un costrutto, e un esame di matematica pu√≤ essere considerato una procedura per misurare tale costrutto. Sebbene oggi diamo per scontata l‚Äôaffidabilit√† della misurazione di certe grandezze fisiche, esistono ancora problemi di misurazione complessi in altri ambiti.\nLe complessit√† della misurazione emergono in modo particolarmente evidente quando le nostre variabili riguardano soggetti umani. I problemi psicologici legati agli esseri umani coinvolgono inevitabilmente variabili che mirano a quantificare tratti, inclinazioni, abilit√† e qualit√† di una persona. I ricercatori spesso tentano di accedere a questi costrutti progettando sondaggi, test o questionari. Tuttavia, molti dati relativi agli esseri umani vengono raccolti in modo estemporaneo, senza seguire principi di misurazione chiari.\nIn questo capitolo verranno introdotte alcune nozioni di base relative alla misurazione quantitativa delle caratteristiche psicologiche. Verr√† presentata la teoria delle scale di misura di Stevens (1946). Tuttavia, prima di procedere, √® indispensabile leggere la sezione sui numeri (vedi Appendice G).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#introduzione",
    "href": "chapters/key_notions/02_measurement.html#introduzione",
    "title": "11¬† La misurazione in psicologia",
    "section": "",
    "text": "11.1.1 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling pi√π noti √® lo ¬´Scaling di Guttman¬ª, che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell‚Äôansia, le domande possono essere disposte in ordine di intensit√† crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde ‚Äús√¨‚Äù a una domanda che riflette un sintomo pi√π intenso, ci si aspetta che abbia risposto ‚Äús√¨‚Äù anche a tutte le domande precedenti, che rappresentano sintomi di intensit√† minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravit√† dei sintomi.\nScaling Thurstoniano. Lo ¬´Scaling Thurstoniano¬ª √® un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a pi√π livelli, che va da ¬´fortemente in disaccordo¬ª a ¬´fortemente d‚Äôaccordo¬ª. I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell‚Äôindividuo rispetto all‚Äôoggetto di studio.\n\n\n11.1.2 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le propriet√† delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l‚Äôaffidabilit√† delle misure pu√≤ essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validit√† delle scale pu√≤ essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validit√† di costrutto √® particolarmente cruciale, poich√© riguarda la capacit√† della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n11.1.3 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si √® arricchito di nuove prospettive, grazie all‚Äôavvento di tecnologie avanzate e all‚Äôintegrazione di approcci interdisciplinari. Ecco alcune delle tendenze pi√π rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarit√† per la sua capacit√† di fornire stime pi√π precise delle abilit√† latenti rispetto ai modelli classici. La IRT considera la probabilit√† che un individuo risponda correttamente a un item in funzione della sua abilit√† e delle caratteristiche dell‚Äôitem stesso, offrendo una visione pi√π dettagliata delle propriet√† psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessit√† e l‚Äôincertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L‚Äôanalisi di rete √® un‚Äôaltra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio pu√≤ offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "title": "11¬† La misurazione in psicologia",
    "section": "11.2 Le scale di misurazione",
    "text": "11.2 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le propriet√† psicologiche. La teoria delle scale di Stevens Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poich√© ciascuna di esse √® in grado di ‚Äúcatturare‚Äù solo alcune delle propriet√† dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n11.2.1 Scala nominale\nILa scala nominale √® il livello di misurazione pi√π semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica √® uguale o diversa da un‚Äôaltra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unit√† di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL‚Äôunica operazione algebrica consentita dalla scala nominale √® quella di contare le unit√† di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale √® possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unit√† di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n11.2.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unit√† di misura all‚Äôinterno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) √® uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale √® quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed √® scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto √® considerato pi√π duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearit√† della scala di Mohs (Burchard, 2004).\n\n\n\n\n11.2.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le propriet√† della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unit√† statistiche in termini di un intervallo costante, chiamato ‚Äúunit√† di misura‚Äù, a cui viene attribuito il valore ‚Äú1‚Äù. L‚Äôorigine della scala, ovvero il punto zero, √® scelta arbitrariamente e non indica l‚Äôassenza della propriet√† che si sta misurando. Ci√≤ significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all‚Äôunit√† statistica in cui la propriet√† risulta assente.\nLa scala ad intervalli equivalenti consente l‚Äôesecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli √® che non consente di calcolare il rapporto tra coppie di misure. √à possibile affermare la differenza tra \\(a\\) e \\(b\\) come la met√† della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non √® possibile affermare che \\(a\\) abbia una propriet√† misurata in quantit√† doppia rispetto a \\(b\\). In altre parole, non √® possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalit√† permettono tutte le operazioni aritmetiche, come la somma, l‚Äôelevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l‚Äôunit√† di misura √® arbitraria e pu√≤ essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l‚Äôaggiunta di una costante a tutti i valori della scala, √® ammessa poich√© non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l‚Äôuguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli √® la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, √® possibile stabilire se due modalit√† sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale √® possibile mettere due modalit√† in una relazione d‚Äôordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, per√≤, √® possibile definire una unit√† di misura per cui √® possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c‚Äô√® una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l‚Äôintensit√† del fenomeno, godono della propriet√† che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli √® quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non √® il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione ‚Äúil doppio di‚Äù che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla propriet√† misurata (cio√® la temperatura). La decisione di che scala usare (Centigrada vs.¬†Fahrenheit) √® arbitraria. Ma questa arbitrariet√† non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realt√† empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l‚Äôaspetto invariante di una trasformazione lineare, ovvero l‚Äôuguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\n√à facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall‚Äôunit√† di misura che √® stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n11.2.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non √® arbitrario e rappresenta l‚Äôelemento che ha intensit√† nulla rispetto alla propriet√† misurata. Per costruire questa scala, si associa il numero 0 all‚Äôelemento con intensit√† nulla e si sceglie un‚Äôunit√† di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a=d/u\\), dove \\(d\\) rappresenta la distanza dall‚Äôorigine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensit√† della propriet√† misurata.\nIn questa scala, √® possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L‚Äôunica scelta arbitraria √® l‚Äôunit√† di misura, ma lo zero deve sempre rappresentare l‚Äôintensit√† nulla della propriet√† considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarit√† e sono del tipo \\(y' = by\\), dove \\(b&gt;0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "11¬† La misurazione in psicologia",
    "section": "11.3 Gerarchia dei livelli delle scale di misurazione",
    "text": "11.3 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati ‚Äúlivelli di scala‚Äù. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello pi√π basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello pi√π alto.\n\nLa scala nominale √® il livello pi√π elementare, in cui le categorie o le etichette vengono assegnate agli oggetti o agli individui senza alcuna valutazione di grandezza o ordine.\nAl livello successivo si trova la scala ordinale, in cui le categorie sono ordinate in base a una qualche qualit√† o caratteristica. Qui, √® possibile stabilire un ordine di preferenza o gerarchia tra le categorie, ma non √® possibile quantificare la differenza tra di esse in modo preciso.\nLa scala intervallo rappresenta un livello successivo, in cui le categorie sono ordinate e la differenza tra di esse √® quantificabile in modo preciso. In questa scala, √® possibile effettuare operazioni matematiche come l‚Äôaddizione e la sottrazione tra i valori, ma non √® possibile stabilire un vero e proprio punto zero significativo.\nInfine, la scala a rapporti equivalenti rappresenta il livello pi√π alto. In questa scala, le categorie sono ordinate, la differenza tra di esse √® quantificabile in modo preciso e esiste un punto zero assoluto che rappresenta l‚Äôassenza totale della grandezza misurata. Questo livello di scala permette di effettuare tutte le operazioni matematiche, compresa la moltiplicazione e la divisione.\n\nPassando da un livello di misurazione ad uno pi√π alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPer ci√≤ che riguarda le trasformazioni ammissibili, pi√π il livello di scala √® basso, pi√π le funzioni sono generali (sono minori cio√® i vincoli per passare da una rappresentazione numerica ad un‚Äôaltra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa pi√π restrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "href": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "title": "11¬† La misurazione in psicologia",
    "section": "11.4 Variabili discrete o continue",
    "text": "11.4 Variabili discrete o continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nLe variabili discrete assumono valori specifici ma non possono assumere valori intermedi. Una volta che l‚Äôelenco dei valori accettabili √® stato definito, non vi sono casi che si trovano tra questi valori. In genere, le variabili discrete assumono valori interi, come il numero di eventi, il numero di persone o il numero di oggetti.\nD‚Äôaltra parte, le variabili continue possono assumere qualsiasi valore all‚Äôinterno di un intervallo specificato. Teoricamente, ci√≤ significa che √® possibile utilizzare frazioni e decimali per ottenere qualsiasi grado di precisione.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "href": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "title": "11¬† La misurazione in psicologia",
    "section": "11.5 Comprendere gli errori nella misurazione",
    "text": "11.5 Comprendere gli errori nella misurazione\nGli errori di misurazione possono essere casuali o sistematici. Gli errori casuali sono fluttuazioni aleatorie, mentre gli errori sistematici sono costanti e derivano da problemi nel metodo di misurazione o negli strumenti.\n\n11.5.1 Precisione e Accuratezza\nLa precisione indica la coerenza tra misurazioni ripetute, mentre l‚Äôaccuratezza si riferisce alla vicinanza del valore misurato al valore reale. Entrambi i concetti sono cruciali per l‚Äôassessment psicometrico.\nUtilizzando l‚Äôanalogia del tiro al bersaglio, si pu√≤ avere una serie di colpi vicini tra loro ma lontani dal centro (precisione senza accuratezza) oppure colpi distribuiti in modo sparso ma in media vicini al centro (accuratezza senza precisione).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "href": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "title": "11¬† La misurazione in psicologia",
    "section": "11.6 Assessment psicometrico",
    "text": "11.6 Assessment psicometrico\nL‚Äôassessment psicometrico valuta la qualit√† delle misurazioni psicologiche, considerando la validit√† e l‚Äôaffidabilit√†.\n\n11.6.1 Validit√† nella Misurazione Psicologica\nLa validit√† √® una propriet√† psicometrica fondamentale dei test psicologici. Secondo gli Standards for Educational and Psychological Testing (2014), la validit√† si riferisce al grado in cui evidenza e teoria supportano le interpretazioni dei punteggi dei test per gli usi proposti. Questo concetto evidenzia che la validit√† riguarda sia il significato dei punteggi sia il loro utilizzo, rendendola ‚Äúla considerazione pi√π fondamentale nello sviluppo e nella valutazione dei test‚Äù.\n\n\n11.6.2 Evoluzione del Concetto di Validit√†\nTradizionalmente, la validit√† era suddivisa in tre categorie:\n\nValidit√† di Contenuto: Si riferisce alla corrispondenza tra il contenuto degli item di un test e il dominio dell‚Äôattributo psicologico che il test intende misurare. √à importante che gli item siano pertinenti e rappresentativi dell‚Äôattributo misurato.\nValidit√† di Criterio: Valuta il grado di concordanza tra i risultati ottenuti tramite lo strumento di misurazione e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto o da un criterio esterno. Include validit√† concorrente e predittiva.\nValidit√† di Costrutto: Riguarda il grado in cui un test misura effettivamente il costrutto che si intende misurare. Si suddivide in validit√† convergente (accordo con strumenti che misurano lo stesso costrutto) e validit√† divergente (capacit√† di discriminare tra costrutti diversi).\n\nLa moderna teoria della validit√† non adotta pi√π questa visione tripartita. Gli Standards del 2014 descrivono la validit√† come un concetto unitario, dove diverse forme di evidenza concorrono a supportare l‚Äôinterpretazione dei punteggi del test per il loro utilizzo previsto.\n\n\n11.6.3 Tipologie di Prove di Validit√†\nGli Standards del 2014 identificano cinque categorie principali di prove di validit√†:\n\nProve Basate sul Contenuto del Test: Valutano quanto il contenuto del test rappresenti adeguatamente il dominio del costrutto da misurare.\nProve Basate sui Processi di Risposta: Analizzano se i processi cognitivi e comportamentali degli esaminandi riflettono il costrutto valutato.\nProve Basate sulla Struttura Interna: Esaminano la coerenza tra gli elementi del test e la struttura teorica del costrutto. L‚Äôanalisi fattoriale √® uno strumento chiave in questo contesto.\nProve Basate sulle Relazioni con Altre Variabili: Studiano la correlazione tra i punteggi del test e altre variabili teoricamente correlate, utilizzando metodi come la validit√† convergente e divergente.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni e gli effetti dell‚Äôuso del test, sia intenzionali che non intenzionali.\n\n\n\n11.6.4 Minacce alla Validit√†\nLa validit√† pu√≤ essere compromessa quando un test non misura integralmente il costrutto di interesse (sotto-rappresentazione del costrutto) o quando include varianza estranea al costrutto. Inoltre, fattori esterni come l‚Äôansia o la bassa motivazione degli esaminandi, e deviazioni nelle procedure di amministrazione e valutazione, possono influenzare negativamente la validit√† delle interpretazioni dei risultati.\n\n\n11.6.5 Integrazione delle Prove di Validit√†\nLa validit√† di un test si costruisce attraverso l‚Äôintegrazione di diverse linee di evidenza. Ogni interpretazione o uso di un test deve essere validato specificamente, richiedendo una valutazione continua e accurata delle prove disponibili. Questo processo implica la costruzione di un argomento di validit√† che consideri attentamente la qualit√† tecnica del test e l‚Äôadeguatezza delle sue interpretazioni per gli scopi previsti.\nIn conclusione, la validit√† √® un concetto complesso e integrato che richiede un‚Äôanalisi continua e multidimensionale delle evidenze. La moderna teoria della validit√† enfatizza l‚Äôimportanza di considerare diverse forme di evidenza per supportare le interpretazioni dei punteggi dei test, garantendo che siano utilizzati in modo appropriato e significativo. Gli sviluppatori e gli utilizzatori di test devono impegnarsi a valutare costantemente la validit√† per assicurare misurazioni psicologiche accurate e affidabili.\n\n\n11.6.6 Affidabilit√†\nL‚Äôaffidabilit√† concerne la consistenza e stabilit√† delle misurazioni, verificata attraverso metodi come l‚Äôaffidabilit√† test-retest, inter-rater, intra-rater e l‚Äôaffidabilit√† interna.\n\nAffidabilit√† Test-Retest: Questa forma di affidabilit√† verifica la consistenza delle misurazioni nel tempo. Se un individuo viene testato in due momenti diversi, i risultati dovrebbero essere simili, assumendo che non ci siano stati cambiamenti significativi nel costrutto misurato.\nAffidabilit√† Inter-rater: In questo caso, l‚Äôaffidabilit√† √® determinata dalla concordanza tra le valutazioni di diversi esaminatori. Ad esempio, se pi√π psicologi dovessero valutare un individuo utilizzando lo stesso strumento, le loro valutazioni dovrebbero essere simili.\nAffidabilit√† Intra-rater: Questa misura dell‚Äôaffidabilit√† si riferisce alla consistenza delle valutazioni dello stesso esaminatore in momenti diversi.\nAffidabilit√† Interna: Si riferisce alla coerenza delle risposte all‚Äôinterno dello stesso test. Ad esempio, se un test misura un costrutto come l‚Äôansia, gli item che misurano l‚Äôansia dovrebbero correlare positivamente l‚Äôuno con l‚Äôaltro. Un modo comune per valutare l‚Äôaffidabilit√† interna √® utilizzare il coefficiente \\(\\omega\\) di McDonald.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "href": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "title": "11¬† La misurazione in psicologia",
    "section": "11.7 Commenti e considerazioni finali",
    "text": "11.7 Commenti e considerazioni finali\nLa teoria della misurazione √® fondamentale nella ricerca empirica per valutare l‚Äôattendibilit√† e la validit√† delle misurazioni. √à cruciale valutare l‚Äôerrore nella misurazione per garantire la precisione e l‚Äôaccuratezza delle misure. L‚Äôassessment psicometrico si occupa di valutare la qualit√† delle misurazioni psicologiche, considerando l‚Äôaffidabilit√† e la validit√† per garantire misure accurate dei costrutti teorici. Le moderne tecnologie e metodologie stanno continuamente arricchendo questo campo, offrendo strumenti sempre pi√π raffinati per la comprensione delle caratteristiche psicologiche.\n\n\n\n\nLilienfeld, Scott O, e Adele N Strother. 2020. ¬´Psychological measurement and the replication crisis: Four sacred cows.¬ª Canadian Psychology/Psychologie Canadienne 61 (4): 281‚Äì288.\n\n\nMaul, Andrew, David Torres Irribarra, e Mark Wilson. 2016. ¬´On the philosophical foundations of psychological measurement¬ª. Measurement 79: 311‚Äì20.\n\n\nStevens, Stanley Smith. 1946. ¬´On the theory of scales of measurement¬ª. Science 103 (2684): 677‚Äì80.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html",
    "href": "chapters/key_notions/03_data_analysis.html",
    "title": "12¬† L‚Äôanalisi dei dati psicologici",
    "section": "",
    "text": "Introduzione\nNel panorama contemporaneo delle scienze sociali e della psicologia, gli ultimi due decenni hanno visto l‚Äôemergere di una profonda trasformazione metodologica ed epistemologica. Questo movimento, caratterizzato da concetti chiave quali ‚ÄúCredibility Revolution‚Äù (Angrist e Pischke 2010), ‚ÄúCausal Revolution‚Äù (Pearl e Mackenzie 2018) e ‚ÄúReplication Crisis‚Äù (Collaboration 2015), ha determinato un cambiamento paradigmatico nelle pratiche delle scienze sociali e, in particolare, della psicologia (Korbmacher et al. 2023). Questa transizione verso quella che Munger (2023) definisce ‚ÄúScience versione 2‚Äù √® stata motivata dalle lacune metodologiche precedenti e ha catalizzato l‚Äôadozione di approcci pi√π rigorosi e replicabili.\nLa genesi di questa Riforma √® radicata nella constatazione di problematiche metodologiche pervasive, tra cui la proliferazione di falsi positivi (Simmons, Nelson, e Simonsohn 2011), l‚Äôabuso dei ‚Äúgradi di libert√† dei ricercatori‚Äù (Gelman e Loken 2013), e l‚Äôinadeguatezza delle pratiche statistiche tradizionali (Gelman e Loken 2014). Fenomeni come il p-hacking, l‚Äôuso di campioni sottodimensionati (Button et al. 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilit√† delle scoperte psicologiche (Ioannidis 2005; Meehl 1967), portando alla cosiddetta ‚ÄúReplication Crisis‚Äù (Baker 2016; Bishop 2019) ‚Äì si veda il Capitolo 94.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "title": "12¬† L‚Äôanalisi dei dati psicologici",
    "section": "12.1 L‚ÄôApproccio Bayesiano",
    "text": "12.1 L‚ÄôApproccio Bayesiano\nIn risposta a queste sfide, l‚Äôapproccio bayesiano √® emerso come un paradigma statistico fondamentale nella ‚ÄúCredibility Revolution‚Äù. Contrariamente all‚Äôinferenza frequentista basata sul Test dell‚ÄôIpotesi Nulla, la statistica bayesiana offre un framework pi√π flessibile e intuitivo per l‚Äôanalisi dei dati e l‚Äôinferenza causale. Il principio cardine dell‚Äôapproccio bayesiano, l‚Äôaggiornamento delle distribuzioni di probabilit√† a priori (priors) alla luce di nuove evidenze, si allinea perfettamente con l‚Äôobiettivo di una scienza cumulativa e auto-correttiva.\nL‚Äôadozione di metodi bayesiani in psicologia comporta diversi vantaggi significativi:\n\nQuantificazione dell‚Äôincertezza: L‚Äôinferenza bayesiana fornisce distribuzioni di probabilit√† posteriori complete per i parametri di interesse, offrendo una rappresentazione pi√π ricca e sfumata dell‚Äôincertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane consentono l‚Äôintegrazione formale di conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poich√© l‚Äôinferenza si basa sull‚Äôintera distribuzione posteriore piuttosto che su soglie arbitrarie di significativit√†.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano-nella-ricerca-clinica",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano-nella-ricerca-clinica",
    "title": "12¬† L‚Äôanalisi dei dati psicologici",
    "section": "12.2 L‚Äôapproccio bayesiano nella ricerca clinica",
    "text": "12.2 L‚Äôapproccio bayesiano nella ricerca clinica\nL‚Äôimpiego delle statistiche bayesiane nella ricerca clinica presenta notevoli vantaggi rispetto ad altri metodi statistici tradizionali, come il test di significativit√† dell‚Äôipotesi nulla. Un punto di forza importante risiede nella sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto per gli studi clinici che spesso si basano su campioni di dimensioni ridotte (Larson et al. 2023).\nLa ricerca clinica √® frequentemente caratterizzata da campioni limitati, dovuti a diversi fattori quali la bassa prevalenza di determinate condizioni, le difficolt√† nel reclutamento dei partecipanti e le complessit√† nelle procedure di valutazione. Questi campioni di piccole dimensioni sono intrinsecamente soggetti a una maggiore eterogeneit√†, che si manifesta nella variabilit√† del fenotipo comportamentale delle condizioni cliniche esaminate e nella discrepanza tra le stime degli effetti in diversi studi. Tale eterogeneit√† pu√≤ condurre a stime degli effetti distorte e scarsamente riproducibili.\nL‚Äôapproccio bayesiano offre una soluzione efficace a queste problematiche. In primo luogo, consente di valutare l‚Äôadeguatezza della dimensione del campione attraverso un‚Äôanalisi della sensibilit√† dei risultati rispetto alla specificazione delle distribuzioni a priori. In secondo luogo, permette di ottenere risultati precisi anche con campioni ridotti, a condizione che le conoscenze a priori siano accurate e ben definite.\nUn ulteriore vantaggio dell‚Äôapproccio bayesiano √® la sua capacit√† di ottimizzare l‚Äôuso dei campioni di partecipanti, favorendo un‚Äôinclusione equa delle popolazioni diversificate. Questo √® particolarmente rilevante per gruppi spesso sottorappresentati, come le minoranze etniche. Le statistiche bayesiane aiutano a superare questa sfida evitando di esercitare una pressione eccessiva su questi gruppi per aumentarne la partecipazione, permettendo cos√¨ una ricerca pi√π equa e rappresentativa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "href": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "title": "12¬† L‚Äôanalisi dei dati psicologici",
    "section": "12.3 Modellazione Formale",
    "text": "12.3 Modellazione Formale\nLa ‚ÄúCredibility Revolution‚Äù ha catalizzato l‚Äôintegrazione della Data Science nelle pratiche di ricerca psicologica. L‚Äôadozione di pipeline di analisi dei dati riproducibili, l‚Äôuso di controllo di versione, e la condivisione di dati e codice sono diventati standard de facto nella comunit√† scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilit√† della ricerca, ma facilitano anche la collaborazione e l‚Äôaccumulo di conoscenze nel campo.\nParallelamente, si √® osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer e Lewandowsky 2019; Van Dongen et al. 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, che era tipica della pratica dominante dell‚ÄôANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l‚Äôincorporazione di incertezza parametrica, e la valutazione dell‚Äôevidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l‚Äôanalisi di sensibilit√†, i ricercatori possono valutare rigorosamente la plausibilit√† relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "title": "12¬† L‚Äôanalisi dei dati psicologici",
    "section": "12.4 Riflessioni Epistemologiche",
    "text": "12.4 Riflessioni Epistemologiche\nL‚Äôadozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box\n\ntutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL‚Äôapproccio bayesiano, con la sua enfasi sull‚Äôaggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verit√† assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l‚Äôutilit√† euristica e predittiva (si veda la discussione nella Sezione 83.2).\nIn particolare, McElreath (2020) sottolinea l‚Äôimportanza di riconoscere la dualit√† tra il ‚Äúmondo del modello‚Äù e il mondo reale pi√π ampio che cerchiamo di comprendere. Questa consapevolezza √® cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#conclusione",
    "href": "chapters/key_notions/03_data_analysis.html#conclusione",
    "title": "12¬† L‚Äôanalisi dei dati psicologici",
    "section": "12.5 Conclusione",
    "text": "12.5 Conclusione\nL‚Äôintegrazione dell‚Äôapproccio bayesiano e della data science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla ‚ÄúReplication Crisis‚Äù. Offrendo un framework coerente per la modellazione formale, l‚Äôinferenza statistica e l‚Äôincorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilit√† della ricerca psicologica. Tuttavia, √® fondamentale che l‚Äôadozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica ‚Äì si veda, ad esempio, il Capitolo 69.\n\n\n\n\nAngrist, Joshua D, e J√∂rn-Steffen Pischke. 2010. ¬´The credibility revolution in empirical economics: How better research design is taking the con out of econometrics¬ª. Journal of economic perspectives 24 (2): 3‚Äì30.\n\n\nBaker, Monya. 2016. ¬´1,500 scientists lift the lid on reproducibility¬ª. Nature 533 (7604).\n\n\nBishop, Dorothy. 2019. ¬´The psychology of experimental psychologists: Overcoming cognitive constraints to improve research¬ª.\n\n\nButton, Katherine S, John PA Ioannidis, Claire Mokrysz, Brian A Nosek, Jonathan Flint, Emma SJ Robinson, e Marcus R Munaf√≤. 2013. ¬´Power failure: why small sample size undermines the reliability of neuroscience¬ª. Nature Reviews Neuroscience 14 (5): 365‚Äì76.\n\n\nCollaboration, Open Science. 2015. ¬´Estimating the reproducibility of psychological science¬ª. Science 349 (6251): aac4716.\n\n\nGelman, Andrew, e Eric Loken. 2013. ¬´The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ‚Äúfishing expedition‚Äù or ‚Äúp-hacking‚Äù and the research hypothesis was posited ahead of time¬ª. Department of Statistics, Columbia University 348 (1-17): 3.\n\n\n‚Äî‚Äî‚Äî. 2014. ¬´The statistical crisis in science¬ª. American scientist 102 (6): 460‚Äì65.\n\n\nIoannidis, John PA. 2005. ¬´Why most published research findings are false¬ª. PLoS medicine 2 (8): e124.\n\n\nKorbmacher, Max, Flavio Azevedo, Charlotte R Pennington, Helena Hartmann, Madeleine Pownall, Kathleen Schmidt, Mahmoud Elsherif, et al. 2023. ¬´The replication crisis has led to positive structural, procedural, and community changes¬ª. Communications Psychology 1 (1): 3.\n\n\nLabatut, Benjamƒ±ÃÅn. 2021. Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, Caroline, David Kaplan, Teresa Girolamo, Sara T Kover, e Inge-Marie Eigsti. 2023. ¬´A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples¬ª. Journal of Clinical Psychology 79 (11): 2602‚Äì24.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nMeehl, Paul E. 1967. ¬´Theory-testing in psychology and physics: A methodological paradox¬ª. Philosophy of science 34 (2): 103‚Äì15.\n\n\nMunger, Kevin. 2023. ¬´Temporal validity as meta-science¬ª. Research & Politics 10 (3): 20531680231187271.\n\n\nOberauer, Klaus, e Stephan Lewandowsky. 2019. ¬´Addressing the theory crisis in psychology¬ª. Psychonomic bulletin & review 26: 1596‚Äì1618.\n\n\nPearl, Judea, e Dana Mackenzie. 2018. The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, Joseph P, Leif D Nelson, e Uri Simonsohn. 2011. ¬´False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant¬ª. Psychological science 22 (11): 1359‚Äì66.\n\n\nVan Dongen, Noah, Riet van Bork, Adam Finnemann, Jonas Haslbeck, Han LJ van der Maas, Donald J Robinaugh, Jill de Ron, Jan Sprenger, e Denny Borsboom. 2024. ¬´Productive explanation: A framework for evaluating explanations in psychological science.¬ª Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "Introduzione",
    "section": "",
    "text": "L‚Äôanalisi esplorativa dei dati rappresenta la prima fase di un progetto di analisi dei dati. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica descrittiva. Oltre alle definizioni teoriche, verranno fornite istruzioni in Python per condurre analisi statistiche su dati reali. Il capitolo si concluder√† con alcune considerazioni sui limiti di un approccio epistemologico basato esclusivamente sull‚Äôanalisi delle associazioni tra variabili, sottolineando l‚Äôimportanza dello studio delle cause dei fenomeni.",
    "crumbs": [
      "EDA",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "13.1 Introduzione\nSecondo Yu e Barter (2024), ogni progetto di analisi dei dati segue una combinazione delle seguenti fasi:\nMentre quasi tutti i progetti di data science attraversano le fasi 1-2 e 4-5, non tutti includono la fase 3.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#introduzione",
    "href": "chapters/eda/01_project_structure.html#introduzione",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "Formulazione del problema e raccolta dei dati.\nPulizia dei dati, preprocessing e analisi esplorativa.\nAnalisi predittiva e/o inferenziale.\nValutazione dei risultati.\nComunicazione dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-1-formulazione-del-problema-e-raccolta-dei-dati",
    "href": "chapters/eda/01_project_structure.html#fase-1-formulazione-del-problema-e-raccolta-dei-dati",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "13.2 Fase 1: Formulazione del Problema e Raccolta dei Dati",
    "text": "13.2 Fase 1: Formulazione del Problema e Raccolta dei Dati\nLa prima fase del ciclo di vita di un progetto di data science (DSLC) implica la formulazione di una domanda di ricerca che possa essere risolta utilizzando i dati disponibili. Questo potrebbe sembrare semplice, ma spesso la domanda iniziale √® troppo vaga o non risolvibile. L‚Äôobiettivo √® riformulare la domanda in modo tale che possa trovare una risposta utilizzando i dati a disposizione.\n\n13.2.1 Raccolta dei Dati\nAlcuni progetti utilizzano dati esistenti (da repository pubblici, database interni o esperimenti passati), mentre altri richiedono la raccolta di nuovi dati. Ogni volta che √® possibile, √® necessario avere ben chiaro quali analisi statistiche verranno svolte prima di aver raccolto i dati. Se questo non viene fatto, pu√≤ succedere che i dati raccolti non siano adeguati per rispondere alle domande di interesse, in quanto mancano informazioni cruciali, o vengono violate assunzioni richieste dai modelli statistici che si vogliono impiegare.\n√à importante sviluppare una comprensione dettagliata di come i dati sono stati raccolti e cosa significano i valori al loro interno. √à altrettanto importante essere consapevoli degli strumenti e delle procedure utilizzate per la raccolta dei dati.\n\n\n13.2.2 Terminologia dei Dati\nOgni colonna di una tabella di dati (spesso chiamata semplicemente ‚Äúdati‚Äù o ‚Äúdataset‚Äù) corrisponde a un diverso tipo di misurazione e viene denominata variabile, caratteristica, attributo o covariata dei dati.\nOgni variabile in un dataset ha tipicamente uno dei seguenti tipi:\n\nNumerica: Un valore continuo (ad es. l‚Äôimporto di spesa), una durata (ad es. il numero di secondi che un paziente pu√≤ stare in equilibrio su un piede, o il tempo che un visitatore trascorre sul tuo sito web), un conteggio (ad es. il numero di visitatori del tuo sito web in un periodo specificato, il numero di animali osservati in una determinata localit√†), ecc.\nCategorica: Un insieme di gruppi o categorie finite/fisse con un insieme di opzioni predeterminate, come partito politico, dipartimento ospedaliero, paese, genere, ecc.\nDate e orari: Date e orari possono avere vari formati, come ‚Äú01/01/2020 23:00:05‚Äù o ‚Äú1 gen 2020‚Äù.\nTesto strutturato (breve): Testo con una struttura o lunghezza prestabilita, come il nome di una persona, un indirizzo postale, un indirizzo email, ecc.\nTesto non strutturato (lungo): Un corpo di testo pi√π ampio che non ha una struttura predefinita, come voci nei rapporti di patologia o note del medico, recensioni di film, tweet, post su Reddit, ecc.\n\nLa dimensione dei dati si riferisce al numero di variabili (colonne) che contiene (e talvolta anche al numero di righe che contiene). Pertanto, i ‚Äúdati ad alta dimensione‚Äù si riferiscono tipicamente a dati con molte variabili (generalmente pi√π di 100, anche se non esiste una soglia fissa oltre la quale i dati diventano ‚Äúad alta dimensione‚Äù).\nOgni riga corrisponde a una particolare osservazione, unit√† osservazionale, unit√† di dati o punto dati (usiamo questi termini in modo intercambiabile). Queste sono le entit√† per cui vengono raccolte le misurazioni.\nQuesto formato, in cui i dati sono disposti in colonne (caratteristiche/variabili) e righe (unit√† osservazionali), √® chiamato dati rettangolari o tabellari.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-2-pulizia-dei-dati-e-analisi-esplorativa",
    "href": "chapters/eda/01_project_structure.html#fase-2-pulizia-dei-dati-e-analisi-esplorativa",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "13.3 Fase 2: Pulizia dei Dati e Analisi Esplorativa",
    "text": "13.3 Fase 2: Pulizia dei Dati e Analisi Esplorativa\n\n13.3.1 Pulizia dei Dati\nDopo aver definito una domanda e raccolto alcuni dati rilevanti, √® il momento di pulire i dati. Un dataset pulito √® ordinato, formattato in modo appropriato e ha voci non ambigue. La fase iniziale di pulizia dei dati consiste nell‚Äôidentificare problemi con i dati (come formattazioni strane e valori non validi) e modificarli in modo che i valori siano validi e formattati in modo comprensibile sia per il computer che per noi. La pulizia dei dati √® una fase incredibilmente importante di un progetto di data science perch√© non solo aiuta a garantire che i dati siano interpretati correttamente dal computer, ma aiuta anche a sviluppare una comprensione dettagliata delle informazioni contenute nei dati e delle loro limitazioni.\nL‚Äôobiettivo della pulizia dei dati √® creare una versione dei dati che rifletta nella maniera pi√π fedele possibile la realt√† e che sia interpretata correttamente dal computer. Per garantire che il computer utilizzi fedelmente le informazioni contenute nei dati, √® necessario modificare i dati (scrivendo codice, non modificando il file dati grezzo stesso) in modo che siano in linea con ci√≤ che il computer ‚Äúsi aspetta‚Äù. Tuttavia, il processo di pulizia dei dati √® necessariamente soggettivo e comporta fare assunzioni sulle quantit√† reali sottostanti misurate e decisioni su quali modifiche siano le pi√π sensate.\n\n\n13.3.2 Preprocessing\nIl preprocessing si riferisce al processo di modifica dei dati puliti per soddisfare i requisiti di un algoritmo specifico che si desidera applicare. Ad esempio, se si utilizza un algoritmo che richiede che le variabili siano sulla stessa scala, potrebbe essere necessario trasformarle, oppure, se si utilizza un algoritmo che non consente valori mancanti, potrebbe essere necessario imputarli o rimuoverli. Durante il preprocessing, potrebbe essere utile anche definire nuove caratteristiche/variabili utilizzando le informazioni esistenti nei dati, se si ritiene che queste possano essere utili per l‚Äôanalisi.\nCome per la pulizia dei dati, non esiste un unico modo corretto per pre-elaborare un dataset, e la procedura finale comporta tipicamente una serie di decisioni che dovrebbero essere documentate nel codice e nei file di documentazione.\n\n\n13.3.3 Analisi Esplorativa dei Dati\nLa fase successiva prevede un esame pi√π approfondito dei dati mediante la creazione di tabelle informative, il calcolo di statistiche riassuntive come medie e mediane, e la produzione di visualizzazioni informative. Questa fase ha tipicamente due sottofasi. La prima sottofase, l‚Äôanalisi esplorativa dei dati (EDA), implica lo sviluppo di riassunti numerici e visivi dei dati per comprendere meglio i dati e i modelli che contengono. La seconda sottofase, l‚Äôanalisi esplicativa dei dati, consiste nel perfezionare le tabelle e i grafici esplorativi pi√π informativi per comunicarli a un pubblico esterno.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-3-analisi-predittiva-eo-inferenziale",
    "href": "chapters/eda/01_project_structure.html#fase-3-analisi-predittiva-eo-inferenziale",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "13.4 Fase 3: Analisi Predittiva e/o Inferenziale",
    "text": "13.4 Fase 3: Analisi Predittiva e/o Inferenziale\nMolte domande di data science sono formulate come problemi di previsione, dove l‚Äôobiettivo √® utilizzare dati osservabili passati o presenti per prevedere qualcosa su dati futuri non visti, solitamente per aiutare a prendere decisioni nel mondo reale.\n\n13.4.1 Inferenza Basata sui Dati\nUn altro tipo di problema basato sui dati che si pu√≤ incontrare √® quello dell‚Äôinferenza, che comporta l‚Äôapprendimento su una popolazione pi√π ampia quantificando l‚Äôincertezza associata a una stima del parametro (come la ‚Äúmedia del campione‚Äù, che √® una stima della ‚Äúmedia della popolazione‚Äù). Le tecniche tradizionali di inferenza statistica includono il test delle ipotesi e gli intervalli di confidenza.\nLa maggior parte di questo corso √® dedicata a fornire un‚Äôintroduzione a come il problema dell‚Äôinferenza possa essere affrontato usando una prospettiva bayesiana.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-4-valutazione-dei-risultati",
    "href": "chapters/eda/01_project_structure.html#fase-4-valutazione-dei-risultati",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "13.5 Fase 4: Valutazione dei Risultati",
    "text": "13.5 Fase 4: Valutazione dei Risultati\nL‚Äôinterpretazione dei risultati alla luce della domanda che ha motivato l‚Äôanalisi √® un passaggio cruciale. √à necessario valutare qualitativamente i risultati utilizzando il pensiero critico e quantitativamente utilizzando gli standard correnti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-5-comunicazione-dei-risultati",
    "href": "chapters/eda/01_project_structure.html#fase-5-comunicazione-dei-risultati",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "13.6 Fase 5: Comunicazione dei Risultati",
    "text": "13.6 Fase 5: Comunicazione dei Risultati\nL‚Äôultima fase del ciclo di un progetto di data science implica la comunicazione dei risultati affinch√© possano essere utilizzati per prendere decisioni nel mondo reale. Questo potrebbe implicare la scrittura di un articolo di ricerca, la creazione di un report per un gruppo di lavoro, o la preparazione di alcune diapositive. La capacit√† di comunicare efficacemente i risultati dell‚Äôanalisi alle persone che potrebbero utilizzarli √® cruciale. Dopotutto, se hai condotto un‚Äôanalisi approfondita ma non riesci a spiegare i risultati a nessuno, qual √® stato il senso di condurre l‚Äôanalisi in primo luogo?\nLa comunicazione deve essere personalizzata per il pubblico di riferimento. Piuttosto che presumere che il pubblico sia gi√† familiare con il progetto, √® necessario spiegare l‚Äôanalisi e le figure in modo molto accurato e chiaro. Anche se il messaggio principale di una figura o diapositiva pu√≤ essere ovvio per te, √® buona pratica spiegare esplicitamente al pubblico come interpretarlo (senza usare gergo complesso).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#lorganizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#lorganizzazione-del-progetto",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "13.7 L‚Äôorganizzazione del Progetto",
    "text": "13.7 L‚Äôorganizzazione del Progetto\nIl primo requisito di un progetto di analisi dei dati √® organizzare in maniera efficiente i vari file che verranno utilizzati: i file dei dati, i file di codice e la documentazione del progetto. Tutti i file relativi a un progetto di analisi dei dati devono essere contenuti in una singola cartella. Yu e Barter (2024) propongono il seguente template per la struttura di un progetto:\n\nLe due cartelle principali sono:\n\ndata/: contiene il dataset grezzo (ad esempio, data.csv) e una sottocartella con informazioni sulla documentazione dei dati (ad esempio, metainformazioni e definizioni dei dati sotto forma di codebook).\ndslc_documentation/: contiene file .qmd di Quarto (per R) o .ipynb di Jupyter Notebook (per Python) per condurre e documentare le esplorazioni e analisi basate su codice in ogni fase del progetto DSLC. Ogni nome di file ha un prefisso numerico per garantire che i file appaiano nell‚Äôordine corretto. C‚Äô√® anche una sottocartella functions/ con script .R (R) o .py (Python) che contengono funzioni utilizzate in vari file di analisi.\n\nIl file README.md riassume la struttura del progetto e descrive il contenuto di ogni file.\nUna struttura di progetto come quella proposta da Yu e Barter (2024), in cui tutti i file sono contenuti in una singola cartella, offre un vantaggio significativo: la specificazione di tutti i percorsi dei file, ad esempio quelli necessari per la lettura dei dati, pu√≤ essere fatta in maniera relativa, utilizzando come root la cartella del progetto. Questo assicura la portabilit√† del progetto tra diversi computer o utenti.\n\n13.7.1 I dati sulle aspettative negative nella depressione\nPer illustrare gli aspetti dell‚Äôarchiviazione dei dati sul computer e dell‚Äôimportazione dei dati in Python, consideriamo i dati raccolti da Zetsche, Buerkner, e Renneberg (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento della depressione. I ricercatori hanno confrontato 30 soggetti con episodi depressivi con un gruppo di controllo di 37 individui sani, utilizzando il Beck Depression Inventory (BDI-II) per misurare la depressione.\nQuesto file CSV, cos√¨ come tutti gli altri file di dati utilizzati in questa dispensa, √® contenuto nella cartella data all‚Äôinterno della cartella psicometria, che √® la directory principale dell‚Äôintero progetto.\nCon le seguenti istruzioni, specifico il percorso della directory principale del progetto in relazione alla mia directory personale:\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\nprint(project_directory)\n\n/Users/corradocaudek/_repositories/psicometria\n\n\nAvendo definito project_directory come root, diventa possibile specificare il percorso del file CSV che contiene i dati in relazione a project_directory.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"data.mood.csv\")\nprint(file_path)\n\n/Users/corradocaudek/_repositories/psicometria/data/data.mood.csv\n\n\nCon la seguente istruzione posso dunque leggere i dati del file data.mood.csv in un DataFrame pandas.\n\ndf = pd.read_csv(file_path)\n\n\n\n13.7.2 Esaminare i dati\nPer conoscere le dimensioni del DataFrame utilizziamo il metodo .shape.\n\ndf.shape\n\n(1188, 44)\n\n\nIl DataFrame ha 1188 righe e 44 colonne. Visualizziamo il nome delle colonne con il metodo .columns.\n\ndf.columns\n\nIndex(['Unnamed: 0', 'vpn_nr', 'esm_id', 'group', 'bildung', 'bdi',\n       'nr_of_episodes', 'nobs_mood', 'trigger_counter', 'form', 'traurig_re',\n       'niedergeschlagen_re', 'unsicher_re', 'nervos_re', 'glucklich_re',\n       'frohlich_re', 'mood_sad.5', 'mood_fearful.5', 'mood_neg.5',\n       'mood_happy.5', 'cesd_sum', 'rrs_sum', 'rrs_brood', 'rrs_reflect',\n       'forecast_sad', 'forecast_fear', 'forecast_neg', 'forecast_happy',\n       'recall_sad', 'recall_fear', 'recall_neg', 'recall_happy',\n       'diff_neg.fore.5', 'diff_sad.fore.5', 'diff_fear.fore.5',\n       'diff_happy.fore.5', 'diff_neg.retro.5', 'diff_sad.retro.5',\n       'diff_fear.retro.5', 'diff_happy.retro.5', 'mood_sad5_tm1',\n       'mood_neg5_tm1', 'mood_fearful5_tm1', 'mood_happy5_tm1'],\n      dtype='object')\n\n\nDato che il DataFrame √® troppo grande (1188 righe e 44 colonne), stampiamo sullo schermo le prime 5 righe.\n\ndf.head()\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nvpn_nr\nesm_id\ngroup\nbildung\nbdi\nnr_of_episodes\nnobs_mood\ntrigger_counter\nform\n...\ndiff_fear.fore.5\ndiff_happy.fore.5\ndiff_neg.retro.5\ndiff_sad.retro.5\ndiff_fear.retro.5\ndiff_happy.retro.5\nmood_sad5_tm1\nmood_neg5_tm1\nmood_fearful5_tm1\nmood_happy5_tm1\n\n\n\n\n0\n1\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n5\nForecasting\n...\n0.333333\n-1.000000\n0.250000\n0.166667\n0.333333\n-1.000000\nNaN\nNaN\nNaN\nNaN\n\n\n1\n2\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n6\nForecasting\n...\n-0.666667\n-0.333333\n-0.416667\n-0.166667\n-0.666667\n-0.333333\n3.333333\n3.000000\n2.666667\n3.000000\n\n\n2\n3\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n7\nForecasting\n...\n0.666667\n-0.666667\n1.250000\n1.833333\n0.666667\n-0.666667\n3.666667\n3.666667\n3.666667\n2.333333\n\n\n3\n4\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n8\nForecasting\n...\n-0.333333\n-0.666667\n0.083333\n0.500000\n-0.333333\n-0.666667\n1.666667\n2.000000\n2.333333\n2.666667\n\n\n4\n5\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n10\nForecasting\n...\n0.333333\n-1.000000\n0.416667\n0.500000\n0.333333\n-1.000000\n3.000000\n3.166667\n3.333333\n2.666667\n\n\n\n\n5 rows √ó 44 columns",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "13¬† Le fasi del progetto di analisi dei dati",
    "section": "13.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "13.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Aug 01 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nYu, Bin, e Rebecca L Barter. 2024. Veridical data science: The practice of responsible data analysis and decision making. MIT Press.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "14.1 Introduzione\nSebbene la parte pi√π interessante di un progetto di analisi dei dati sia quella in cui si trova la risposta alla domanda che ha motivato l‚Äôintera indagine, gran parte del tempo di un analista viene effettivamente dedicata a una fase precedente: la pulizia dei dati e il preprocessing, che avvengono persino prima dell‚Äôanalisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nAnche se l‚Äôordine di questi passaggi √® flessibile e pu√≤ essere modificato in base alle esigenze, c‚Äô√® un passaggio che non dovrebbe mai essere spostato: il passo n.¬†1, la revisione dei dati. Senza una revisione preliminare dei dati, l‚Äôanalista potrebbe sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto, o peggio, che sta lavorando con i dati sbagliati.\nEsamineremo questi passaggi seguendo il tutorial di Crystal Lewis.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (‚Äúw1_mathproj_stu_svy_raw.csv‚Äù) to a folder (called ‚Äúdata‚Äù) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#importare-i-dati",
    "href": "chapters/eda/02_data_cleaning.html#importare-i-dati",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.2 Importare i Dati",
    "text": "14.2 Importare i Dati\nUn aspetto fondamentale da considerare √® che i dati grezzi non devono mai essere modificati direttamente. √à una buona pratica organizzare i dati in una cartella chiamata data, all‚Äôinterno della quale ci saranno altre due cartelle: raw e processed. I dati grezzi devono essere salvati nella cartella raw e lasciati invariati. I dati ripuliti, invece, verranno salvati nella cartella processed.\nPer fare un esempio, importiamo i dati dal file w1_mathproj_stu_svy_raw.csv discussi da Crystal Lewis e iniziamo il processo di pulizia.\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\nprint(project_directory)\n\n/Users/corradocaudek/_repositories/psicometria\n\n\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"w1_mathproj_stu_svy_raw.csv\")\nprint(file_path)\n\n/Users/corradocaudek/_repositories/psicometria/data/w1_mathproj_stu_svy_raw.csv",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#esaminare-i-dati",
    "href": "chapters/eda/02_data_cleaning.html#esaminare-i-dati",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.3 (1) Esaminare i Dati",
    "text": "14.3 (1) Esaminare i Dati\n√à sempre necessario esaminare visivamente le prime (o ultime) righe del data frame, per essere sicuri che i dati siano stati importati correttamente.\n\nsvy = pd.read_csv(file_path)\nsvy\n\n\n\n\n\n\n\n\n\nstu_id\nsvy_date\ngrade_level\nmath1\nmath2\nmath3\nmath4\n\n\n\n\n0\n1347\n2023-02-13\n9\n2\n1\n3.0\n3.0\n\n\n1\n1368\n2023-02-13\n10\n3\n2\n2.0\n2.0\n\n\n2\n1377\n2023-02-13\n9\n4\n4\n4.0\n4.0\n\n\n3\n1387\n2023-02-13\n11\n3\n3\nNaN\nNaN\n\n\n4\n1347\n2023-02-14\n9\n2\n2\n4.0\n2.0\n\n\n5\n1399\n2023-02-14\n12\n4\n1\n3.0\n1.0",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#modifica-i-casi-secondo-necessit√†",
    "href": "chapters/eda/02_data_cleaning.html#modifica-i-casi-secondo-necessit√†",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.4 (2) Modifica i casi secondo necessit√†",
    "text": "14.4 (2) Modifica i casi secondo necessit√†\nIl secondo passo √® quello in cui vengono fatte delle semplici ma necessarie modifiche al data frame. Crystal Lewis descrive cos√¨ questo passo per i dati in esame:\n\nVerificare la presenza di duplicati - Il record 1347 √® duplicato.\nRimuovere i duplicati.\nOrdinare per svy_date in ordine crescente.\nEsaminare i dati dopo aver rimosso i duplicati.\n\n\n# Trova i duplicati basati su 'stu_id'\nduplicates = svy[svy.duplicated(\"stu_id\", keep=False)]\n\n# Ordina per 'svy_date' in ordine crescente e rimuovi i duplicati mantenendo il primo\nsvy = svy.sort_values(\"svy_date\").drop_duplicates(\"stu_id\", keep=\"first\")\n\n# Mostra il DataFrame finale\nsvy\n\n\n\n\n\n\n\n\n\nstu_id\nsvy_date\ngrade_level\nmath1\nmath2\nmath3\nmath4\n\n\n\n\n0\n1347\n2023-02-13\n9\n2\n1\n3.0\n3.0\n\n\n1\n1368\n2023-02-13\n10\n3\n2\n2.0\n2.0\n\n\n2\n1377\n2023-02-13\n9\n4\n4\n4.0\n4.0\n\n\n3\n1387\n2023-02-13\n11\n3\n3\nNaN\nNaN\n\n\n5\n1399\n2023-02-14\n12\n4\n1\n3.0\n1.0",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#de-identificazione-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#de-identificazione-dei-dati",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.5 (3) De-identificazione dei Dati",
    "text": "14.5 (3) De-identificazione dei Dati\n\n# Rimuovi la colonna 'svy_date'\nsvy = svy.drop(columns=[\"svy_date\"])\n\n# Mostra i nomi delle colonne rimaste\nsvy.columns\n\nIndex(['stu_id', 'grade_level', 'math1', 'math2', 'math3', 'math4'], dtype='object')",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#rimuovere-le-colonne-non-necessarie",
    "href": "chapters/eda/02_data_cleaning.html#rimuovere-le-colonne-non-necessarie",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.6 (4) Rimuovere le Colonne non Necessarie",
    "text": "14.6 (4) Rimuovere le Colonne non Necessarie\nNel caso presente, la rimozione di colonne non √® necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, √® comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l‚Äôanalisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l‚Äôanalisi. Rimuovere le colonne non necessarie non solo rende il dataset pi√π gestibile, ma aiuta anche a focalizzare l‚Äôanalisi sulle variabili che realmente importano per rispondere alle domande di ricerca.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dividere-le-colonne-secondo-necessit√†",
    "href": "chapters/eda/02_data_cleaning.html#dividere-le-colonne-secondo-necessit√†",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.7 (5) Dividere le colonne secondo necessit√†",
    "text": "14.7 (5) Dividere le colonne secondo necessit√†\nNel caso presente, questa operazione non √® necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata ‚ÄúNomeCompleto‚Äù, contenente sia il nome che il cognome di uno studente, √® buona pratica separare questa colonna in due colonne distinte, ‚ÄúNome‚Äù e ‚ÄúCognome‚Äù. Questa suddivisione facilita l‚Äôanalisi e la manipolazione dei dati, rendendoli pi√π organizzati e accessibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#rinominare-le-colonne",
    "href": "chapters/eda/02_data_cleaning.html#rinominare-le-colonne",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.8 (6) Rinominare le Colonne",
    "text": "14.8 (6) Rinominare le Colonne\nNel caso presente, non √® necessario, ma √® importante sottolineare l‚Äôimportanza di assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l‚Äôanalisi dei dati pi√π intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come ‚Äúx‚Äù o acronimi incomprensibili. Questi possono creare confusione durante l‚Äôanalisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di ‚Äúx1‚Äù o ‚ÄúVAR123‚Äù, un nome come ‚Äúansia_base‚Äù o ‚Äúliv_autoefficacia‚Äù √® molto pi√π comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate ‚Äútest_ansia_pre‚Äù e ‚Äútest_ansia_post‚Äù per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\nNome generico: TS, AE\n\nNome migliore: tempo_studio, auto_efficacia\n\nNome generico: S1, S2\n\nNome migliore: stress_situazione1, stress_situazione2\n\nNome generico: Q1, Q2\n\nNome migliore: qualit√†_sonno_sett1, qualit√†_sonno_sett2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#trasformare-le-variabili",
    "href": "chapters/eda/02_data_cleaning.html#trasformare-le-variabili",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.9 (7) Trasformare le Variabili",
    "text": "14.9 (7) Trasformare le Variabili\nNel caso presente non si applica, ma √® un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione pi√π simmetrica e migliorare l‚Äôinterpretabilit√† dei risultati.\nCodifica delle variabili categoriche: Se √® presente una variabile categorica come il ‚Äútipo di intervento‚Äù con valori come ‚Äúcognitivo‚Äù, ‚Äúcomportamentale‚Äù e ‚Äúfarmacologico‚Äù, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo √® utile quando si utilizzano tecniche di regressione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#standardizzare-normalizzare-le-variabili",
    "href": "chapters/eda/02_data_cleaning.html#standardizzare-normalizzare-le-variabili",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.10 (8) Standardizzare / Normalizzare le Variabili",
    "text": "14.10 (8) Standardizzare / Normalizzare le Variabili\nNel caso presente non si applica, ma √® un passo importante in molte analisi dei dati.\nEsempi di standardizzazione delle variabili:\n\nStandardizzazione dei punteggi: Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Se desideriamo confrontare i livelli di ansia tra diversi gruppi o includere questa variabile in un modello di regressione, potrebbe essere utile standardizzare i punteggi (cio√®, sottrarre la media e dividere per la deviazione standard) per ottenere una variabile con media 0 e deviazione standard 1. Questo processo rende i punteggi comparabili e facilita l‚Äôinterpretazione dei coefficienti in un modello di regressione.\nNormalizzazione delle variabili: Se hai dati su diverse variabili come ‚Äúore di sonno‚Äù, ‚Äúlivello di stress‚Äù e ‚Äúauto-efficacia‚Äù, e queste variabili hanno scale molto diverse, potrebbe essere utile normalizzarle (ad esempio, ridimensionarle tutte su una scala da 0 a 1) per garantire che abbiano lo stesso peso in un‚Äôanalisi multivariata.\n\nTrasformare e standardizzare le variabili sono passaggi cruciali in molte analisi psicologiche, specialmente quando si confrontano dati provenienti da diverse fonti o gruppi. Questi processi aiutano a garantire che le variabili siano trattate in modo appropriato e che i risultati dell‚Äôanalisi siano validi e interpretabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#aggiornare-i-tipi-delle-variabili",
    "href": "chapters/eda/02_data_cleaning.html#aggiornare-i-tipi-delle-variabili",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.11 (9) Aggiornare i Tipi delle Variabili",
    "text": "14.11 (9) Aggiornare i Tipi delle Variabili\nNel caso presente non √® necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sar√† necessario convertire questa colonna da stringa a numerico.\nIn Python, utilizzando pandas, potresti farlo con il seguente codice:\nimport pandas as pd\n\n# Supponiamo di avere un DataFrame chiamato 'df' con una colonna 'punteggio' che √® stata importata come stringa\ndf['punteggio'] = pd.to_numeric(df['punteggio'], errors='coerce')\n\n# Ora la colonna 'punteggio' √® stata convertita in un tipo numerico e puoi eseguire calcoli su di essa\nIn questo esempio, la funzione pd.to_numeric viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati. L‚Äôopzione errors='coerce' trasforma eventuali valori non convertibili in NaN, garantendo che i dati errati non compromettano le analisi.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all‚Äôinterno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o pi√π caratteri alfanumerici. Di conseguenza, l‚Äôintera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, √® fondamentale individuare la cella problematica, correggere il valore errato, e poi riconvertire l‚Äôintera colonna da alfanumerica a numerica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#ricodificare-le-variabili",
    "href": "chapters/eda/02_data_cleaning.html#ricodificare-le-variabili",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.12 (10) Ricodificare le Variabili",
    "text": "14.12 (10) Ricodificare le Variabili\nAnche se in questo caso non √® necessario, la ricodifica delle variabili √® una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalit√† descritte da stringhe poco comprensibili, che vengono ricodificate con nomi pi√π chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalit√† \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente ‚ÄúTerapia Cognitiva‚Äù, ‚ÄúTerapia Comportamentale‚Äù e ‚ÄúTerapia Mista‚Äù. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi pi√π espliciti. Ecco come farlo in Python utilizzando pandas:\n\n# Supponiamo di avere un DataFrame chiamato 'df' con una colonna 'tipo_intervento'\ndf = pd.DataFrame({\"tipo_intervento\": [\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"]})\n\n# Ricodifica delle modalit√† della variabile 'tipo_intervento' in nomi pi√π comprensibili\ndf[\"tipo_intervento_ricodificato\"] = df[\"tipo_intervento\"].replace(\n    {\"CT\": \"Terapia Cognitiva\", \n     \"BT\": \"Terapia Comportamentale\", \n     \"MT\": \"Terapia Mista\"\n    }\n)\n\n# Ora la colonna 'tipo_intervento_ricodificato' contiene i nomi ricodificati\nprint(df)\n\n  tipo_intervento tipo_intervento_ricodificato\n0              CT            Terapia Cognitiva\n1              BT      Terapia Comportamentale\n2              MT                Terapia Mista\n3              CT            Terapia Cognitiva\n4              BT      Terapia Comportamentale",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#aggiungere-nuove-variabili-nel-data-frame",
    "href": "chapters/eda/02_data_cleaning.html#aggiungere-nuove-variabili-nel-data-frame",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.13 (11) Aggiungere Nuove Variabili nel Data Frame",
    "text": "14.13 (11) Aggiungere Nuove Variabili nel Data Frame\nNel caso presente non √® richiesto, ma aggiungere nuove variabili a un DataFrame √® un‚Äôoperazione comune durante l‚Äôanalisi dei dati. Un esempio √® il calcolo dell‚Äôindice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un DataFrame chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf = pd.DataFrame({\"peso_kg\": [70, 85, 60, 95], \"altezza_m\": [1.75, 1.80, 1.65, 1.90]})\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf[\"BMI\"] = df[\"peso_kg\"] / (df[\"altezza_m\"] ** 2)\n\n# Mostra il DataFrame con la nuova variabile aggiunta\nprint(df)\n\n   peso_kg  altezza_m        BMI\n0       70       1.75  22.857143\n1       85       1.80  26.234568\n2       60       1.65  22.038567\n3       95       1.90  26.315789",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#affrontare-il-problema-dei-dati-mancanti",
    "href": "chapters/eda/02_data_cleaning.html#affrontare-il-problema-dei-dati-mancanti",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.14 (12) Affrontare il Problema dei Dati Mancanti",
    "text": "14.14 (12) Affrontare il Problema dei Dati Mancanti\nL‚Äôimputazione √® una tecnica utilizzata per gestire i dati mancanti in un dataset, un problema comune in molte analisi. Lasciare i valori mancanti nel DataFrame pu√≤ compromettere la qualit√† dell‚Äôanalisi, poich√© molti algoritmi statistici non sono in grado di gestire direttamente i dati incompleti, portando a risultati distorti o poco affidabili.\nI valori mancanti possono causare diversi problemi:\n\nBias dei risultati: I dati mancanti possono introdurre un bias nelle stime se i valori mancanti non sono distribuiti in modo casuale.\nRiduzione della potenza statistica: Quando si eliminano le righe con dati mancanti (rimozione listwise), si riduce la dimensione del campione, diminuendo la potenza dell‚Äôanalisi.\nImpossibilit√† di utilizzare alcuni algoritmi: Molti algoritmi di statistica richiedono che tutti i valori siano presenti per eseguire correttamente i calcoli.\n\nEsistono vari approcci per affrontare i dati mancanti:\n\nImputazione Semplice:\n\nMedia/Mediana: Un metodo comune e semplice √® sostituire i valori mancanti con la media o la mediana della colonna. Questo metodo √® facile da implementare, ma pu√≤ ridurre la variabilit√† dei dati e portare a una sottostima della varianza.\nMode (moda): Per le variabili categoriche, √® possibile sostituire i valori mancanti con la moda (il valore pi√π frequente). Tuttavia, questo pu√≤ portare a una distorsione se la distribuzione dei dati √® molto eterogenea.\n\nImputazione Multipla:\n\nRegressione Iterativa: L‚Äôimputazione multipla, come implementata con algoritmi come IterativeImputer, √® una procedura pi√π sofisticata che predice i valori mancanti in modo iterativo utilizzando un modello basato sulle altre variabili del dataset. Questa tecnica tiene conto delle relazioni tra le variabili, migliorando l‚Äôaccuratezza delle imputazioni rispetto ai metodi semplici.\nL‚Äôimputazione multipla conserva la variabilit√† nei dati e riduce il bias, fornendo stime pi√π accurate rispetto ai metodi di imputazione semplice.\n\n\nL‚Äôimputazione dei dati mancanti √® essenziale per garantire che l‚Äôanalisi statistica sia accurata e robusta. Sebbene i metodi semplici come la sostituzione con la media possano essere utili in alcuni casi, l‚Äôimputazione multipla offre un approccio pi√π completo e sofisticato, particolarmente utile quando si desidera preservare le relazioni tra le variabili e mantenere l‚Äôintegrit√† statistica del dataset.\nApplichiamo dunque la procedura dell‚Äôimputazione multipla al caso presente.\n\nd = svy.copy()\nd = pd.DataFrame(d)\n# Conserva l'indice originale\noriginal_index = d.index\nd\n\n\n\n\n\n\n\n\n\nstu_id\ngrade_level\nmath1\nmath2\nmath3\nmath4\n\n\n\n\n0\n1347\n9\n2\n1\n3.0\n3.0\n\n\n1\n1368\n10\n3\n2\n2.0\n2.0\n\n\n2\n1377\n9\n4\n4\n4.0\n4.0\n\n\n3\n1387\n11\n3\n3\nNaN\nNaN\n\n\n5\n1399\n12\n4\n1\n3.0\n1.0\n\n\n\n\n\n\n\n\n\n# Converti solo le colonne numeriche relative ai punteggi in float per l'imputazione\nnumeric_columns = [\"math1\", \"math2\", \"math3\", \"math4\"]\nd[numeric_columns] = d[numeric_columns].astype(float)\n\n# Applica IterativeImputer per l'imputazione multipla\nimputer = IterativeImputer(max_iter=10, random_state=0)\ndf_imputed = pd.DataFrame(\n    imputer.fit_transform(d[numeric_columns]),\n    columns=numeric_columns,\n    index=original_index,  # Mantieni l'indice originale\n)\n\n# Arrotonda i valori imputati ai numeri interi pi√π vicini\ndf_imputed = df_imputed.round()\n\n# Inserisci i valori imputati e arrotondati nel DataFrame originale\nd[numeric_columns] = df_imputed\n\n# Mostra il DataFrame dopo l'imputazione e l'arrotondamento\nprint(\"\\nDataFrame dopo l'imputazione e l'arrotondamento:\")\nprint(d)\n\n\nDataFrame dopo l'imputazione e l'arrotondamento:\n   stu_id  grade_level  math1  math2  math3  math4\n0    1347            9    2.0    1.0    3.0    3.0\n1    1368           10    3.0    2.0    2.0    2.0\n2    1377            9    4.0    4.0    4.0    4.0\n3    1387           11    3.0    3.0    3.0    4.0\n5    1399           12    4.0    1.0    3.0    1.0\n\n\nPer eseguire l‚Äôimputazione multipla in Python, utilizziamo il pacchetto sklearn con il modulo IterativeImputer, che √® uno degli algoritmi pi√π avanzati disponibili per l‚Äôimputazione dei valori mancanti. Questo algoritmo utilizza la regressione iterativa, in cui ogni valore mancante viene previsto utilizzando un modello che tiene conto di tutte le altre variabili presenti nel dataset.\n\nAbbiamo selezionato le colonne numeriche che vogliamo imputare.\nImputazione Multipla con IterativeImputer:\n\nIterativeImputer √® un algoritmo che prevede i valori mancanti iterativamente. Per ciascuna colonna con valori mancanti, l‚Äôalgoritmo usa una regressione basata sulle altre colonne per stimare i valori mancanti.\nIl processo viene ripetuto iterativamente fino a quando i valori imputati convergono a una soluzione stabile.\nmax_iter=10 significa che il processo verr√† ripetuto fino a un massimo di 10 volte per garantire la stabilit√† delle imputazioni.\n\nApplicazione dell‚ÄôImputazione: Dopo aver eseguito l‚Äôimputazione, i valori imputati vengono reinseriti nel DataFrame originale.\n\nIl DataFrame risultante non ha pi√π valori mancanti nelle colonne math3 e math4, poich√© questi sono stati imputati utilizzando le relazioni con le altre variabili del dataset.\nIn conclusione, l‚Äôimputazione multipla √® una tecnica potente che consente di gestire i valori mancanti nei dati senza dover eliminare intere righe o colonne. In questo caso, abbiamo utilizzato IterativeImputer per prevedere i valori mancanti basandoci sulle informazioni fornite dalle altre variabili. Questo approccio aumenta l‚Äôaccuratezza e la validit√† delle analisi successive.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#aggiungere-i-metadati",
    "href": "chapters/eda/02_data_cleaning.html#aggiungere-i-metadati",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.15 (13) Aggiungere i Metadati",
    "text": "14.15 (13) Aggiungere i Metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull‚Äôorigine dei dati, unit√† di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\nValori mancanti: In R, √® possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all‚Äôinterno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\nIn Python, la gestione dei metadati non √® cos√¨ strutturata come in R. pandas, che √® il pacchetto principale per la manipolazione dei dati in Python, non ha un supporto nativo per l‚Äôassegnazione di metadati direttamente alle colonne di un DataFrame, come etichette di variabili o etichette di valori. Tuttavia, ci sono alcuni approcci che si possono adottare:\n\nEtichette di variabili: Poich√© pandas non supporta nativamente le etichette di variabili, un modo comune per gestirle √® utilizzare il campo attrs di un DataFrame. attrs √® un dizionario che pu√≤ contenere metadati personalizzati, come le etichette delle variabili. Ad esempio, si possono aggiungere descrizioni per ciascuna variabile all‚Äôinterno di attrs['variable_labels'].\nEtichette di valori: Le variabili categoriali in pandas possono avere categorie ordinate o non ordinate con nomi significativi, ma queste non sono considerate come ‚Äúetichette di valori‚Äù nel senso in cui R le gestisce. Tuttavia, √® possibile simulare questo comportamento rinominando le categorie di una variabile categoriale.\nValori mancanti: pandas tratta i valori mancanti utilizzando NaN, ma non c‚Äô√® una funzionalit√† nativa per etichettare valori specifici come mancanti con una descrizione. Si pu√≤ gestire questo manualmente, utilizzando una combinazione di sostituzioni (replace()) e l‚Äôuso di valori speciali.\n\n\n14.15.1 Confronto R vs Python\n\nR ffre un supporto pi√π robusto e dettagliato per i metadati, con pacchetti specializzati che permettono di etichettare variabili, valori e gestire i dati mancanti in modo intuitivo e strutturato. I metadati possono essere direttamente integrati nei DataFrame e sono parte integrante del workflow di analisi in R.\nMentre pandas offre alcune capacit√† di manipolazione e annotazione dei dati, il supporto per i metadati √® meno strutturato e richiede soluzioni personalizzate. Python si basa pi√π su convenzioni e personalizzazioni tramite campi come attrs per conservare i metadati. Anche se Python √® estremamente flessibile, la gestione dei metadati richiede spesso soluzioni creative rispetto alla semplicit√† e alla coerenza offerte da R.\n\nIn sintesi, sebbene Python sia molto potente per l‚Äôelaborazione dei dati, l‚Äôecosistema R offre strumenti pi√π raffinati e specializzati per la gestione dei metadati all‚Äôinterno di un processo di data cleaning e analisi.\n\n# Creazione del DataFrame 'svy'\ndata = {\n    \"stu_id\": [1347, 1368, 1377, 1387, 1399],\n    \"grade_level\": [9, 10, 9, 11, 12],\n    \"math1\": [2, 3, 4, 3, 4],\n    \"math2\": [1, 2, 4, 3, 1],\n    \"math3\": [3.0, 2.0, 4.0, np.nan, 3.0],\n    \"math4\": [3.0, 2.0, 4.0, np.nan, 1.0],\n    \"int\": [1, 0, 1, 0, 1],\n}\n\nsvy = pd.DataFrame(data)\n\n# Aggiungi etichette di valore alle colonne math1:math4\nvalue_labels_math = {\n    1: \"strongly disagree\",\n    2: \"disagree\",\n    3: \"agree\",\n    4: \"strongly agree\",\n}\n\nfor col in [\"math1\", \"math2\", \"math3\", \"math4\"]:\n    svy[col] = svy[col].astype(\n        pd.CategoricalDtype(categories=value_labels_math.keys(), ordered=True)\n    )\n    svy[col] = svy[col].cat.rename_categories(value_labels_math)\n\n# Aggiungi etichette di valore alla colonna 'int'\nvalue_labels_int = {1: \"treatment\", 0: \"control\"}\nsvy[\"int\"] = svy[\"int\"].astype(\n    pd.CategoricalDtype(categories=value_labels_int.keys(), ordered=True)\n)\nsvy[\"int\"] = svy[\"int\"].cat.rename_categories(value_labels_int)\n\n# Verifica delle etichette di valore\nfor col in [\"math1\", \"math2\", \"math3\", \"math4\", \"int\"]:\n    print(f\"Value labels for {col}:\")\n    print(svy[col].cat.categories)\n    print()\n\n# Aggiungi etichette per valori mancanti\nna_value = -99\nsvy = svy.replace(np.nan, na_value)\n\n# Aggiungi etichette di variabili utilizzando un dizionario dati (esempio semplificato)\nvar_labels = {\n    \"stu_id\": \"Student ID\",\n    \"grade_level\": \"Grade Level\",\n    \"math1\": \"Math Response 1\",\n    \"math2\": \"Math Response 2\",\n    \"math3\": \"Math Response 3\",\n    \"math4\": \"Math Response 4\",\n    \"int\": \"Intervention Group\",\n}\n\n# Assegna etichette di variabili al DataFrame (non nativo in pandas, gestito come metadati)\nsvy.attrs[\"variable_labels\"] = var_labels\n\n# Verifica delle etichette di variabili\nprint(\"\\nVariable labels:\")\nfor var, label in svy.attrs[\"variable_labels\"].items():\n    print(f\"{var}: {label}\")\n\nValue labels for math1:\nIndex(['strongly disagree', 'disagree', 'agree', 'strongly agree'], dtype='object')\n\nValue labels for math2:\nIndex(['strongly disagree', 'disagree', 'agree', 'strongly agree'], dtype='object')\n\nValue labels for math3:\nIndex(['strongly disagree', 'disagree', 'agree', 'strongly agree'], dtype='object')\n\nValue labels for math4:\nIndex(['strongly disagree', 'disagree', 'agree', 'strongly agree'], dtype='object')\n\nValue labels for int:\nIndex(['treatment', 'control'], dtype='object')\n\n\nVariable labels:\nstu_id: Student ID\ngrade_level: Grade Level\nmath1: Math Response 1\nmath2: Math Response 2\nmath3: Math Response 3\nmath4: Math Response 4\nint: Intervention Group",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#validazione-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#validazione-dei-dati",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.16 (14) Validazione dei Dati",
    "text": "14.16 (14) Validazione dei Dati\nL‚Äôobiettivo √® creare un report che mostri se i dati soddisfano i criteri attesi. Utilizzando il dizionario dei dati come riferimento, si possono aggiungere diversi controlli:\n\nLe osservazioni (righe) sono tutti distinte? Ci sono ancora ID duplicati?\nGli ID sono tutti validi (rientrano nell‚Äôintervallo previsto)?\nLe variabili grade_level, int e math contengono tutti valori che rientrano nel set di valori atteso?\n\n\n# Funzione per controllare se le righe sono uniche per una specifica colonna\ndef check_rows_distinct(df, column):\n    duplicates = df[df.duplicated(column, keep=False)]\n    if len(duplicates) &gt; 0:\n        print(f\"Le righe duplicate trovate per la colonna {column}:\")\n        print(duplicates)\n    else:\n        print(f\"Tutte le righe sono uniche per la colonna {column}.\")\n\n\n# Funzione per controllare se i valori sono compresi in un intervallo\ndef check_col_vals_between(df, column, left, right):\n    outside_range = df[(df[column] &lt; left) | (df[column] &gt; right)]\n    if len(outside_range) &gt; 0:\n        print(f\"Valori fuori dall'intervallo trovati in {column}:\")\n        print(outside_range)\n    else:\n        print(f\"Tutti i valori in {column} sono compresi tra {left} e {right}.\")\n\n\n# Funzione per controllare se i valori appartengono a un insieme specifico\ndef check_col_vals_in_set(df, column, valid_set):\n    invalid_vals = df[~df[column].isin(valid_set)]\n    if len(invalid_vals) &gt; 0:\n        print(f\"Valori non validi trovati in {column}:\")\n        print(invalid_vals)\n    else:\n        print(f\"Tutti i valori in {column} appartengono all'insieme {valid_set}.\")\n\n\n# Esegui le verifiche\ncheck_rows_distinct(svy, \"stu_id\")\ncheck_col_vals_between(svy, \"stu_id\", 1300, 1400)\ncheck_col_vals_in_set(svy, \"grade_level\", {9, 10, 11, 12, pd.NA})\ncheck_col_vals_in_set(svy, \"math1\", {1, 2, 3, 4, pd.NA})\ncheck_col_vals_in_set(svy, \"math2\", {1, 2, 3, 4, pd.NA})\ncheck_col_vals_in_set(svy, \"math3\", {1, 2, 3, 4, pd.NA})\ncheck_col_vals_in_set(svy, \"math4\", {1, 2, 3, 4, pd.NA})\n\nprint(\"Validazione completata.\")\n\nTutte le righe sono uniche per la colonna stu_id.\nTutti i valori in stu_id sono compresi tra 1300 e 1400.\nTutti i valori in grade_level appartengono all'insieme {9, 10, 11, 12, &lt;NA&gt;}.\nTutti i valori in math1 appartengono all'insieme {1, 2, 3, 4, &lt;NA&gt;}.\nTutti i valori in math2 appartengono all'insieme {1, 2, 3, 4, &lt;NA&gt;}.\nValori non validi trovati in math3:\n   stu_id  grade_level  math1  math2  math3  math4\n3    1387           11      3      3    NaN    NaN\nValori non validi trovati in math4:\n   stu_id  grade_level  math1  math2  math3  math4\n3    1387           11      3      3    NaN    NaN\nValidazione completata.\n\n\nIn R, la procedura precedente pu√≤ essere gestita in modo pi√π semplice utilizzando il pacchetto pointblank, che offre strumenti dedicati per facilitare questo processo.\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\nAccurato: Sebbene non sia sempre possibile determinare l‚Äôaccuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore √® realmente corretto o meno), in alcuni casi √® possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto √® sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola √® sempre scritto in modo coerente in tutto il dataset.\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l‚Äôinterpretazione.\nAnalizzabile: Il dataset √® in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, √® possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#unire-eo-aggiungere-dati-se-necessario",
    "href": "chapters/eda/02_data_cleaning.html#unire-eo-aggiungere-dati-se-necessario",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.17 (15) Unire e/o aggiungere dati se necessario",
    "text": "14.17 (15) Unire e/o aggiungere dati se necessario\nIn questo passaggio, √® possibile unire o aggiungere colonne o righe presenti in file diversi. √à importante eseguire nuovamente i controlli di validazione dopo l‚Äôunione/aggiunta di nuovi dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#trasformare-i-dati-se-necessario",
    "href": "chapters/eda/02_data_cleaning.html#trasformare-i-dati-se-necessario",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.18 (16) Trasformare i dati se necessario",
    "text": "14.18 (16) Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, √® possibile ristrutturare i dati secondo le esigenze.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#salvare-il-dataset-pulito-finale",
    "href": "chapters/eda/02_data_cleaning.html#salvare-il-dataset-pulito-finale",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.19 (17) Salvare il dataset pulito finale",
    "text": "14.19 (17) Salvare il dataset pulito finale\nL‚Äôultimo passaggio del processo di pulizia consiste nell‚Äôesportare o salvare il dataset pulito. Come accennato in precedenza, pu√≤ essere utile esportare/salvare il dataset in pi√π di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.20 Organizzazione dei file e informazioni aggiuntive",
    "text": "14.20 Organizzazione dei file e informazioni aggiuntive\nInfine, √® essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perch√© e come i dati sono stati raccolti. √à utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, √® importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilit√† dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento √® fondamentale per chiunque voglia comprendere o analizzare i dati.\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README √® spesso il primo documento consultato e serve a orientare l‚Äôutente tra i vari file e risorse del progetto.\n\nQuesta documentazione non solo aiuta a mantenere il progetto organizzato, ma √® anche cruciale per facilitare la collaborazione e l‚Äôarchiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.21 Dizionario dei Dati",
    "text": "14.21 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati √® un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento √® essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n14.21.1 Passi per Creare un Dizionario dei Dati\n\nIdentificare le variabili: Elenca tutte le variabili nel dataset.\nDescrivere ogni variabile: Per ciascuna variabile, identifica il tipo (ad esempio, int, float, datetime, category), il range di valori accettabili e, se applicabile, le categorie.\nSalvare il dizionario dei dati: Il dizionario dei dati pu√≤ essere salvato in un file .csv o .xlsx per facilitarne la consultazione.\n\nPer fare un esempio, utilizzeremo il dataset del tutorial di Crystal Lewis. Il codice seguente creer√† due file:\n\ndata_dictionary.csv: Un file CSV contenente il dizionario dei dati.\ndata_dictionary.xlsx: Un file Excel contenente lo stesso dizionario dei dati.\n\n\n# Creazione del Dizionario dei Dati\ndata_dict = {\n    \"Variable Name\": [\n        \"stu_id\",\n        \"svy_date\",\n        \"grade_level\",\n        \"math1\",\n        \"math2\",\n        \"math3\",\n        \"math4\",\n    ],\n    \"Type\": [\"int\", \"datetime\", \"int\", \"int\", \"int\", \"float\", \"float\"],\n    \"Description\": [\n        \"Student ID\",\n        \"Survey Date\",\n        \"Grade Level\",\n        \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n        \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n        \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n        \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\",\n    ],\n    \"Range/Values\": [\n        \"1347-1399\",\n        \"2023-02-13 to 2023-02-14\",\n        \"9-12\",\n        \"1-4\",\n        \"1-4\",\n        \"1.0-4.0 (NaN allowed)\",\n        \"1.0-4.0 (NaN allowed)\",\n    ],\n}\n\ndata_dict_df = pd.DataFrame(data_dict)\n\nprint(data_dict_df)\n\n  Variable Name      Type                                        Description  \\\n0        stu_id       int                                         Student ID   \n1      svy_date  datetime                                        Survey Date   \n2   grade_level       int                                        Grade Level   \n3         math1       int  Math Response 1 (1: Strongly Disagree, 4: Stro...   \n4         math2       int  Math Response 2 (1: Strongly Disagree, 4: Stro...   \n5         math3     float  Math Response 3 (1: Strongly Disagree, 4: Stro...   \n6         math4     float  Math Response 4 (1: Strongly Disagree, 4: Stro...   \n\n               Range/Values  \n0                 1347-1399  \n1  2023-02-13 to 2023-02-14  \n2                      9-12  \n3                       1-4  \n4                       1-4  \n5     1.0-4.0 (NaN allowed)  \n6     1.0-4.0 (NaN allowed)  \n\n\nUna volta creato il Dizionario dei dati lo possiamo salvare in un file CSV o Excel:\n# Salva il Dizionario dei Dati in un file CSV\ndata_dict_df.to_csv(\"data_dictionary.csv\", index=False)\n\n# Opzionalmente, salva il Dizionario dei Dati in un file Excel\ndata_dict_df.to_excel(\"data_dictionary.xlsx\", index=False)\nQuesti file forniscono una documentazione chiara e strutturata del dataset, utile per qualsiasi analisi successiva o per la condivisione con altri.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#guide-di-stile",
    "href": "chapters/eda/02_data_cleaning.html#guide-di-stile",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.22 Guide di Stile",
    "text": "14.22 Guide di Stile\nLe guide di stile possono essere applicate a diversi aspetti di un progetto di analisi dei dati, non soltanto al dizionario dei dati. Un‚Äôottima introduzione alle regole di stile per un progetto di analisi dei dati √® fornita in questo capitolo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#python-e-r",
    "href": "chapters/eda/02_data_cleaning.html#python-e-r",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.23 Python e R",
    "text": "14.23 Python e R\nNella discussione precedente, abbiamo accennato alle differenze tra Python e R per quanto riguarda la fase di pulizia e pre-elaborazione dei dati. Sebbene Python, tramite la libreria Pandas, offra strumenti potenti e flessibili per la manipolazione dei dati, R si distingue per la sua capacit√† di semplificare e ottimizzare queste operazioni, specialmente quando si tratta di progetti complessi.\nR √® stato progettato specificamente per l‚Äôanalisi statistica, e molte delle sue funzioni native sono state sviluppate con un focus particolare sulla semplicit√† d‚Äôuso e l‚Äôefficienza nei processi di cleaning e preprocessing. Un esempio emblematico di questa facilit√† √® la creazione di un Dizionario dei Dati, un‚Äôoperazione essenziale per documentare e descrivere accuratamente il dataset utilizzato in un progetto di analisi. In R, questa operazione pu√≤ essere completata con una singola istruzione utilizzando pacchetti come datadictionary. Per esempio, il pacchetto datadictionary permette di generare un dizionario dei dati in modo rapido ed efficiente, come illustrato nel file README. Questo rende R particolarmente vantaggioso quando si lavora con dataset complessi che richiedono una documentazione dettagliata e strutturata.\nD‚Äôaltra parte, Python, con Pandas, √® estremamente flessibile e pu√≤ essere adattato a una vasta gamma di esigenze di pulizia e manipolazione dei dati. Tuttavia, la flessibilit√† di Pandas richiede spesso un approccio pi√π manuale e dettagliato per compiti che in R potrebbero essere gestiti con comandi pi√π concisi e specifici. Ad esempio, in Python, come abbiamo visto in precedenza, la creazione di un dizionario dei dati richiede una serie di passaggi personalizzati che possono includere la costruzione manuale di tabelle, la gestione delle categorie e dei metadati, e la documentazione. Questa flessibilit√† rende Python particolarmente adatto a progetti che richiedono un elevato grado di personalizzazione o l‚Äôintegrazione di dati provenienti da diverse fonti. Tuttavia, pu√≤ risultare pi√π laborioso e meno intuitivo rispetto a R per operazioni standardizzate di cleaning e preprocessing.\nIn definitiva, la scelta tra Python e R per la pulizia e pre-elaborazione dei dati dipende dalle specifiche esigenze del progetto e dalle competenze dell‚Äôanalista. R offre strumenti altamente ottimizzati per un‚Äôanalisi statistica rapida e strutturata, rendendolo ideale per progetti che richiedono una documentazione dettagliata e una gestione intuitiva dei dati. Python, con la sua flessibilit√† e potenza, √® preferibile per progetti che richiedono personalizzazioni complesse o integrazioni con altri strumenti di analisi dei dati e sviluppo software.\nQuando si tratta di progetti di analisi dei dati, √® importante considerare non solo la potenza degli strumenti disponibili, ma anche la loro capacit√† di semplificare e rendere efficienti le operazioni di pulizia e pre-elaborazione. Scegliere lo strumento giusto pu√≤ fare una grande differenza in termini di tempo, efficienza e qualit√† dei risultati ottenuti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#considerazioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#considerazioni-conclusive",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "14.24 Considerazioni Conclusive",
    "text": "14.24 Considerazioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione √® cruciale per garantire la qualit√† e l‚Äôintegrit√† dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all‚Äôanalisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, √® possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l‚Äôanalisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, √® fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "14¬† Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Sun Aug 18 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\npandas    : 2.2.2\nsklearn   : 1.5.1\n\n\n\n\n\n\n\nBuchanan, Erin M, Sarah E Crain, Ari L Cunningham, Hannah R Johnson, Hannah Stash, Marietta Papadatou-Pastou, Peder M Isager, Rickard Carlsson, e Balazs Aczel. 2021. ¬´Getting started creating data dictionaries: How to create a shareable data set¬ª. Advances in Methods and Practices in Psychological Science 4 (1): 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>14</span>¬† <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html",
    "href": "chapters/eda/03_freq_distr.html",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "",
    "text": "15.1 Introduzione\nUn aspetto cruciale del lavoro di un data scientist √® la capacit√† di presentare in modo chiaro ed efficace le intuizioni derivanti dall‚Äôanalisi dei dati. Questo √® fondamentale sia per la comprensione personale sia per la comunicazione con altri, in particolare con coloro che potrebbero utilizzare tali informazioni per prendere decisioni concrete nel mondo reale.\nLa comunicazione efficace dei dati e dei risultati derivati raramente avviene attraverso la semplice presentazione dei dati grezzi o degli output di codice. Questi formati non permettono di rilevare facilmente pattern significativi. Invece, i dati e i risultati vengono generalmente presentati in due modi principali:\nIn questo capitolo, esploreremo le strategie per sintetizzare grandi volumi di dati, concentrandoci su concetti chiave come le distribuzioni di frequenza, i quantili e le tecniche di visualizzazione. Esamineremo sia gli aspetti computazionali sia quelli interpretativi di queste misure, fornendo gli strumenti necessari per rappresentare graficamente le sintesi dei dati in modo efficace.\nIn particolare, ci focalizzeremo sull‚Äôuso della visualizzazione dei dati per condurre l‚Äôanalisi esplorativa dei dati (EDA). L‚ÄôEDA consiste nel riassumere visivamente e numericamente i pattern, le tendenze e le relazioni presenti in un dataset, nel contesto del problema di dominio che stiamo cercando di risolvere. L‚Äôobiettivo delle esplorazioni EDA √® comprendere le tendenze e i pattern che risponderanno alla domanda che motiva l‚Äôanalisi dei dati. In questo capitolo esamineremo tre metodi per rappresentare graficamente una distribuzione di frequenze:",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#introduzione",
    "href": "chapters/eda/03_freq_distr.html#introduzione",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "",
    "text": "Sintesi statistiche: Utilizzando medie o altri valori rappresentativi, spesso organizzati in tabelle concise.\nRappresentazioni visive: Attraverso grafici, dove elementi come forme, distanze, colori e dimensioni illustrano le grandezze e le relazioni tra i valori contenuti nei dati.\n\n\n\n\nl‚Äôistogramma,\nl‚Äôistogramma lisciato,\nil box-plot.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/03_freq_distr.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.2 I dati sulle aspettative negative nella depressione",
    "text": "15.2 I dati sulle aspettative negative nella depressione\nPer illustrare i principali strumenti dell‚ÄôEDA, analizzeremo i dati sulle aspettative negative come meccanismo chiave nel mantenimento della depressione (Zetsche, Buerkner, e Renneberg 2019). Come abbiamo visto nel cam√¨pitolo precedente, avendo definito project_directory come root\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\n\n√® possibile specificare il percorso del file CSV che contiene i dati in relazione a project_directory:\n\nfile_path = os.path.join(project_directory, \"data\", \"data.mood.csv\")\n\nLeggiamo i dati grezzi del file data.mood.csv in un DataFrame pandas:\n\ndf = pd.read_csv(file_path)\n\nPer questo esercizio, ci concentriamo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf = df[[\"esm_id\", \"group\", \"bdi\"]]\ndf.head()\n\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n1\n10\nmdd\n25.0\n\n\n2\n10\nmdd\n25.0\n\n\n3\n10\nmdd\n25.0\n\n\n4\n10\nmdd\n25.0\n\n\n\n\n\n\n\n\nUna delle prime cose da fare, quando esaminiamo un dataset, √® capire che tipo di variabili sono incluse.\n\ndf.dtypes\n\nesm_id      int64\ngroup      object\nbdi       float64\ndtype: object\n\n\nNel caso specifico, notiamo che la variabile group √® di tipo object, quindi √® una variabile qualitativa, mentre le altre variabili sono numeriche, rappresentate come numeri interi (int64) o a virgola mobile (bdi).\nSe elenchiamo le modalit√† presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf[\"group\"].unique()\n\narray(['mdd', 'ctl'], dtype=object)\n\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf = df.drop_duplicates(keep=\"first\")\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndf.shape\n\n(67, 3)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n14\n9\nmdd\n30.0\n\n\n29\n6\nmdd\n26.0\n\n\n45\n7\nmdd\n35.0\n\n\n64\n12\nmdd\n44.0\n\n\n\n\n\n\n\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il ‚Äúnome‚Äù delle righe (ovvero, l‚Äôindice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga √® 15. Questo non ha nessuna conseguenza perch√© non useremo l‚Äôindice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf = df[pd.notnull(df[\"bdi\"])]\n\nOtteniamo cos√¨ il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndf.shape\n\n(66, 3)\n\n\nStampiamo i valori BDI-II presentandoli ordinati dal pi√π piccolo al pi√π grande:\n\nprint(df[\"bdi\"].sort_values())\n\n682     0.0\n455     0.0\n465     0.0\n485     0.0\n540     0.0\n       ... \n190    39.0\n810    41.0\n150    43.0\n135    43.0\n64     44.0\nName: bdi, Length: 66, dtype: float64\n\n\nNella terminologia statistica, l‚Äôosservazione √® l‚Äôinformazione raccolta da un individuo o un‚Äôentit√† specifica che partecipa allo studio. Considerando il dataset di Zetsche, Buerkner, e Renneberg (2019), l‚Äôunit√† di osservazione √® costituita dai partecipanti allo studio. Pertanto, nel DataFrame denominato df, ogni riga simboleggia un individuo distinto coinvolto nell‚Äôindagine.\nLe variabili, d‚Äôaltro canto, sono espressioni delle diverse caratteristiche degli individui o delle entit√† analizzate. Nel contesto del progetto STAR, questo concetto si traduce in:\n\nOgni colonna di df rappresenta una variabile che incarna una particolare propriet√† condivisa dai partecipanti.\nLe variabili sono identificate attraverso etichette collegate alle colonne, come esa_id (il codice identificativo dei soggetti), mdd (il gruppo di appartenza), e bdi (il valore del test BDI-II).\n\nPer rappresentare un‚Äôosservazione singola della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l‚Äôindice dell‚Äôosservazione. Questo indice significa che abbiamo un valore differente di \\(X\\) per ogni valore distinto di \\(i\\). Ad esempio, nel caso di 67 osservazioni, \\(i\\) pu√≤ variare da 1 a 67. Pertanto, per simboleggiare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\). √à fondamentale tener presente che, mentre in Python gli indici iniziano da 0, nella notazione matematica tradizionale, come quella rappresentata da \\(X_i\\), l‚Äôindice ha inizio da 1.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#distribuzioni-di-frequenze",
    "href": "chapters/eda/03_freq_distr.html#distribuzioni-di-frequenze",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.3 Distribuzioni di frequenze",
    "text": "15.3 Distribuzioni di frequenze\n√à chiaro dall‚Äôoutput esaminato nella sezione precedente che i dati grezzi non sono molto informativi. Ci porremo ora l‚Äôobiettivo di creare una rappresentazione sintetica e comprensibile di questi dati.\nUna distribuzione di frequenze rappresenta il conteggio delle volte in cui i valori di una variabile si verificano all‚Äôinterno di un intervallo. Per i nostri dati BDI-II, categorizziamo i punteggi in quattro classi:\n\n0‚Äì13: depressione minima\n14‚Äì19: depressione lieve-moderata\n20‚Äì28: depressione moderata-severa\n29‚Äì63: depressione severa\n\nOgni classe \\(\\Delta_i\\) rappresenta un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\), con limiti inferiori e superiori \\(a_i\\) e \\(b_i\\), vengono associati un‚Äôampiezza \\(b_i - a_i\\) (che non √® necessariamente uguale per ogni classe) e un valore centrale \\(\\bar{x}_i\\). Poich√© ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), √® possibile calcolare le seguenti quantit√†.\n\nLa frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\n\nPropriet√†: \\(n_1 + n_2 + \\dots + n_m = n\\).\n\nLa frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe.\n\nPropriet√†: \\(f_1+f_2+\\dots+f_m =1\\).\n\nLa frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\)\nLa frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\)\n\n\n15.3.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, √® necessario prima aggiungere al DataFrame df una colonna che contenga una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravit√† della depressione. Questo risultato si ottiene con il metodo pandas.cut().\nIn pandas.cut(), il primo argomento x √® un array unidimensionale (lista python, numpy.ndarray o pandas.Series) che contiene i dati e il secondo argomento bins specifica gli intervalli delle classi. La funzione restituisce un array che specifica la classe di appartenenza di ogni elemento dell‚Äôarray x. L‚Äôargomento include_lowest=True specifica classi chiuse a destra (nel nostro caso √® irrilevante dato che nessuna osservazione coincide con il limite di una classe).\n\n15.3.1.1 Frequenze assolute\n\ndf[\"bdi_class\"] = pd.cut(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], include_lowest=True)\ndf[\"bdi_class\"].value_counts()\n\nbdi_class\n(-0.001, 13.5]    36\n(28.5, 63.0]      17\n(19.5, 28.5]      12\n(13.5, 19.5]       1\nName: count, dtype: int64\n\n\n\n\n15.3.1.2 Frequenze relative\n\nabs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=[\"Abs. freq.\"])\nrel_freq = abs_freq / abs_freq.sum()\nrel_freq = rel_freq.round(2)\nrel_freq\n\n\n\n\n\n\n\n\ncol_0\nAbs. freq.\n\n\nbdi_class\n\n\n\n\n\n(-0.001, 13.5]\n0.55\n\n\n(13.5, 19.5]\n0.02\n\n\n(19.5, 28.5]\n0.18\n\n\n(28.5, 63.0]\n0.26\n\n\n\n\n\n\n\n\nControlliamo\n\nrel_freq.sum()\n\ncol_0\nAbs. freq.    1.01\ndtype: float64\n\n\n\ngrp_freq = pd.crosstab(index=df[\"group\"], columns=[\"Abs. freq.\"], colnames=[\"\"])\ngrp_freq\n\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nctl\n36\n\n\nmdd\n30\n\n\n\n\n\n\n\n\nVolendo modificare tale ordine √® possibile accedere al DataFrame tramite loc e specificando come secondo argomento una lista dei valori nell‚Äôordine desiderato:\n\ngrp_freq.loc[[\"mdd\", \"ctl\"], :]\n\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nmdd\n30\n\n\nctl\n36\n\n\n\n\n\n\n\n\nIn Python, il simbolo : utilizzato all‚Äôinterno delle parentesi quadre permette di ottenere uno slicing corrispondente all‚Äôintera lista.\n\n\n\n15.3.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l‚Äôinsieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l‚Äôinsieme di variabili \\(V\\) √® composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali pu√≤ assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell‚Äôesempio precedente, la funzione pd.crosstab pu√≤ essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti index e columns.\n\nbdi_group_abs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"])\nbdi_group_abs_freq\n\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n36\n0\n\n\n(13.5, 19.5]\n0\n1\n\n\n(19.5, 28.5]\n0\n12\n\n\n(28.5, 63.0]\n0\n17\n\n\n\n\n\n\n\n\nOppure:\n\nbdi_group_rel_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"], normalize=True)\nbdi_group_rel_freq\n\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n0.545455\n0.000000\n\n\n(13.5, 19.5]\n0.000000\n0.015152\n\n\n(19.5, 28.5]\n0.000000\n0.181818\n\n\n(28.5, 63.0]\n0.000000\n0.257576\n\n\n\n\n\n\n\n\nInvocando il metodo plot.bar sulla tabella, otteniamo un grafico a barre nel quale le barre relative a uno stesso valore bdi_class risultino affiancate. Nel caso presente, le due distribuzioni sono completamente separate, quindi non abbiamo mai due barre affiancate:\n\nbdi_group_rel_freq.plot.bar();",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#istogramma",
    "href": "chapters/eda/03_freq_distr.html#istogramma",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.4 Istogramma",
    "text": "15.4 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densit√† della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densit√† della frequenza relativa √® misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) √® la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l‚Äôampiezza della classe. In questo modo, l‚Äôarea del rettangolo associato alla classe \\(\\Delta_i\\) sull‚Äôistogramma sar√† proporzionale alla frequenza relativa \\(f_i\\). √à importante notare che l‚Äôarea totale dell‚Äôistogramma delle frequenze relative √® uguale a 1.0, poich√© rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche, Buerkner, e Renneberg (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell‚Äôistogramma ‚Äì si notino le frequenze assolute sull‚Äôasse delle ordinate.\n\ncolor_fill = \"#b97c7c\"\nplt.hist(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], density=True, color=color_fill)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()\n\n\n\n\n\n\n\n\nAnche se nel caso presente √® sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un‚Äôampiezza uguale.\n\nplt.hist(df[\"bdi\"], density=True, color=color_fill)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#kernel-density-plot",
    "href": "chapters/eda/03_freq_distr.html#kernel-density-plot",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.5 Kernel density plot",
    "text": "15.5 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell‚Äôistogramma: la sua forma dipende dall‚Äôarbitrariet√† con cui vengono scelti il numero e l‚Äôampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficolt√†, possiamo utilizzare una tecnica alternativa chiamata stima della densit√† kernel (KDE) ‚Äì si veda l‚ÄôAppendice L. Mentre l‚Äôistogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione pi√π continua e meno dipendente dall‚Äôarbitrariet√† delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo √® ci√≤ che fa la KDE: smussa il profilo dell‚Äôistogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un‚Äôaltezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densit√† dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L‚Äôarea sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell‚Äôintervallo. Per esempio, se un intervallo ha un‚Äôarea maggiore sotto la curva rispetto ad altri, significa che in quell‚Äôintervallo c‚Äô√® una maggiore concentrazione di dati.\nLa curva di densit√† ottenuta tramite KDE fornisce dunque un‚Äôidea chiara di come i dati sono distribuiti senza dipendere dall‚Äôarbitrariet√† della scelta delle classi dell‚Äôistogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da {cite:t}zetsche_2019future.\n\nsns.kdeplot(data=df, x=\"bdi\", hue=\"group\", common_norm=False)\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI-II Scores\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "href": "chapters/eda/03_freq_distr.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.6 Consigli per Creare Visualizzazioni di Dati Efficaci",
    "text": "15.6 Consigli per Creare Visualizzazioni di Dati Efficaci\nEcco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualit√† adatta alle presentazioni:\n\nMessaggio chiaro: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, ‚ÄúIl livello di benessere psicologico dei partecipanti aumenta nel tempo‚Äù).\nUso del colore:\n\nUtilizza i colori in modo ponderato e con moderazione.\nNon eccedere nell‚Äôuso dei colori solo perch√© √® possibile farlo.\nLimita l‚Äôuso a non pi√π di cinque o sei colori in una singola figura.\nVerifica che le scelte cromatiche non distorcano le conclusioni della figura.\nEvita l‚Äôuso contemporaneo di rosso e verde nello stesso grafico, poich√© queste tonalit√† sono difficili da distinguere per le persone daltoniche.\n\nGuidare l‚Äôattenzione:\n\nUtilizza dimensioni, colori e testo per guidare l‚Äôattenzione del pubblico.\nEvidenzia elementi particolari del grafico per enfatizzare punti chiave.\n\nGestione del sovraccarico visivo:\n\nUtilizza la trasparenza per ridurre il ‚Äúsovrapplotting‚Äù (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).\nQuesta tecnica √® particolarmente utile quando si visualizza una grande quantit√† di dati.\nSe il dataset √® molto ampio e l‚Äôaggiunta di trasparenza non √® sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto senza sostituzione). Questa tecnica √® nota come sottocampionamento.\n\nElementi testuali:\n\nI titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.\nGli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#forma-di-una-distribuzione",
    "href": "chapters/eda/03_freq_distr.html#forma-di-una-distribuzione",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.7 Forma di una Distribuzione",
    "text": "15.7 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un‚Äôillustrazione grafica √® fornita nella figura seguente. Nel pannello 1, la distribuzione √® unimodale con asimmetria negativa; nel pannello 2, la distribuzione √® unimodale con asimmetria positiva; nel pannello 3, la distribuzione √® simmetrica e unimodale; nel pannello 4, la distribuzione √® bimodale.\n\n\n\nDistribuzioni\n\n\nIl grafico della densit√† di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche, Buerkner, e Renneberg (2019) √® bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l‚Äôaltro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche, Buerkner, e Renneberg (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#indici-di-posizione",
    "href": "chapters/eda/03_freq_distr.html#indici-di-posizione",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.8 Indici di posizione",
    "text": "15.8 Indici di posizione\n\n15.8.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche, Buerkner, e Renneberg (2019) pu√≤ essere sintetizzata attraverso l‚Äôuso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) √® la dimensione del campione e \\(p\\) √® l‚Äôordine del quantile. Se \\(np\\) non √® un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) √® un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) √® la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che √® molto popolare e pu√≤ essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche, Buerkner, e Renneberg (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non √® un intero. Pertanto, il valore del secondo quartile √® pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che √® un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo numpy per trovare la soluzione dell‚Äôesercizio precedente.\n\nx = [19, 26, 27, 28, 28, 33, 33, 41, 43]\nnp.quantile(x, 2 / 3)\n\n33.0",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#mostrare-i-dati",
    "href": "chapters/eda/03_freq_distr.html#mostrare-i-dati",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.9 Mostrare i dati",
    "text": "15.9 Mostrare i dati\n\n15.9.1 Diagramma a scatola\nIl box plot √® uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la ‚Äúscatola‚Äù) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) √® rappresentata da una linea all‚Äôinterno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti ‚Äúbaffi‚Äù, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore √® il valore pi√π basso tra le osservazioni che √® maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore √® il valore pi√π alto tra le osservazioni che √® minore o uguale al terzo quartile pi√π 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati ‚Äúvalori anomali‚Äù e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nsns.boxplot(x=\"group\", y=\"bdi\", data=df, color=color_fill)\nplt.xlabel(\"Group\")\nplt.ylabel(\"BDI-II\")\nplt.title(\"Boxplot of BDI-II Scores by Group\")\nplt.show()\n\n\n\n\n\n\n\n\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n\n15.9.2 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densit√† di kernel (KDE plot) per offrire una rappresentazione pi√π dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nsns.violinplot(x=\"group\", y=\"bdi\", data=df, color=\"lightgray\")\nsns.stripplot(x=\"group\", y=\"bdi\", data=df, color=\"black\", size=5, jitter=True, alpha=0.3)\nplt.ylabel(\"BDI-II\")\nplt.xlabel(\"Group\")\nplt.title(\"Violin Plot with Overlay of Individual Data Points of BDI-II Scores by Group\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/03_freq_distr.html#commenti-e-considerazioni-finali",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.10 Commenti e considerazioni finali",
    "text": "15.10 Commenti e considerazioni finali\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densit√†. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_freq_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/03_freq_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "15¬† Analisi esplorativa dei dati",
    "section": "15.11 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "15.11 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHealy, Kieran. 2018. Data visualization: a practical introduction. Princeton University Press.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, e Garrett Grolemund. 2023. R for data science. \" O‚ÄôReilly Media, Inc.\".\n\n\nWilke, Claus O. 2019. Fundamentals of data visualization: a primer on making informative and compelling figures. O‚ÄôReilly Media.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Analisi esplorativa dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_loc_scale.html",
    "href": "chapters/eda/04_loc_scale.html",
    "title": "16¬† Indici di posizione e di scala",
    "section": "",
    "text": "16.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, √® possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l‚Äôasimmetria, nonch√© la presenza di una o pi√π mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l‚Äôutilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/04_loc_scale.html#indici-di-tendenza-centrale",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.2 Indici di tendenza centrale",
    "text": "16.2 Indici di tendenza centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all‚Äôinterno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l‚Äôintero insieme. Gli indici di tendenza centrale sono fondamentali nell‚Äôanalisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\nMedia: La media √® la somma di tutti i valori divisa per il numero totale di valori. √à spesso utilizzata come misura generale di tendenza centrale, ma √® sensibile agli estremi (valori molto alti o molto bassi).\nMediana: La mediana √® il valore che divide l‚Äôinsieme di dati in due parti uguali. A differenza della media, non √® influenzata da valori estremi ed √® quindi pi√π robusta in presenza di outlier.\nModa: La moda √® il valore che appare pi√π frequentemente in un insieme di dati. In alcuni casi, pu√≤ non essere presente o esserci pi√π di una moda.\n\nLa scelta dell‚Äôindice di tendenza centrale appropriato dipende dalla natura dei dati e dall‚Äôobiettivo dell‚Äôanalisi. Ad esempio, la mediana potrebbe essere preferita alla media se l‚Äôinsieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l‚Äôapplicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.\n\n16.2.1 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. √à calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed √® espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{16.1}\\]\ndove \\(x_i\\) rappresenta i valori nell‚Äôinsieme, \\(n\\) √® il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n16.2.1.1 Propriet√† della media\nUna propriet√† fondamentale della media √® che la somma degli scarti di ciascun valore dalla media √® zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{16.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta propriet√† implica che i dati sono equamente distribuiti intorno alla media.\n\n\n16.2.1.2 La media come centro di gravit√† dell‚Äôistogramma\nLa media aritmetica pu√≤ essere interpretata come il centro di gravit√† o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravit√† √® il punto in cui la massa di un sistema √® equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati √® in equilibrio. Ogni valore dell‚Äôinsieme di dati pu√≤ essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori pi√π grandi a destra e pi√π piccoli a sinistra, la media corrisponder√† esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n16.2.1.3 Principio dei minimi quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come ‚Äúmetodo dei minimi quadrati‚Äù. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media √® minima. Questo principio √® alla base dell‚Äôanalisi statistica dei modelli di regressione e conferma l‚Äôinterpretazione della media come centro di gravit√† dell‚Äôistogramma.\n\n\n16.2.1.4 Calcolo della media con NumPy\nPer calcolare la media di un piccolo numero di valori in Python, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n\n32.6\n\n\novvero\n\nx = np.array([12, 44, 21, 62, 24])\nnp.mean(x)\n\n32.6\n\n\n\nnp.average(x)\n\n32.6\n\n\n\n\n16.2.1.5 Le proporzioni sono medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione √® il numero di uni in essa, e la media della collezione √® la proporzione di uni.\n\nzero_one = np.array([1, 1, 1, 0])\nresult = sum(zero_one)\nprint(result) \n\n3\n\n\n\nnp.mean(zero_one)\n\n0.75\n\n\n√à possibile sostituire 1 con il valore booleano True e 0 con False:\n\nnp.mean(np.array([(True, True, True, False)]))\n\n0.75\n\n\n\n\n16.2.1.6 Limiti della media aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre √® l‚Äôindice pi√π adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, √® pi√π indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).\n\n\n16.2.1.7 Medie per gruppi\nMolto spesso per√≤ i nostri dati sono contenuti in file e inserire i dati manualmente non √® fattibile. Per fare un esempio, considereremo i dati del Progetto STAR, contenuti nel file STAR.csv, che rappresentano un‚Äôimportante indagine sulle prestazioni degli studenti in relazione alla dimensione delle classi. Negli anni ‚Äô80, i legislatori del Tennessee considerarono la possibilit√† di ridurre le dimensioni delle classi per migliorare il rendimento degli studenti. Al fine di prendere decisioni informate, commissionarono lo studio multimilionario ‚ÄúProgetto Student-Teacher Achievement Ratio‚Äù (Project STAR). Lo studio coinvolgeva bambini della scuola materna assegnati casualmente a classi piccole, con 13-17 studenti, o classi di dimensioni regolari, con 22-25 studenti, fino alla fine della terza elementare. I ricercatori hanno seguito il progresso degli studenti nel tempo, concentrandosi su variabili di risultato, come i punteggi dei test standardizzati di lettura (reading) e matematica (math) alla terza elementare, oltre ai tassi di diploma di scuola superiore (graduated, con valore 1 per s√¨ e 0 per no).\nPoniamoci il problema di calcolare la media dei punteggi math calcolata separatamente per i due gruppi di studenti: coloro che hanno completato la scuola superiore e coloro che non l‚Äôhanno completata.\nProcediamo all‚Äôimportazione dei dati per iniziare l‚Äôanalisi.\n\ndf = pd.read_csv(\"../../data/STAR.csv\")\ndf.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nEsaminiamo la numerosit√† di ciascun gruppo.\n\ndf.groupby(\"graduated\").size()\n\ngraduated\n0     166\n1    1108\ndtype: int64\n\n\nOra procediamo al calcolo delle medie dei punteggi math all‚Äôinterno dei due gruppi. Per rendere la risposta pi√π concisa, useremo la funzione round() per stampare solo 2 valori decimali.\n\ndf.groupby(\"graduated\")[\"math\"].mean().round(2)\n\ngraduated\n0    606.64\n1    635.33\nName: math, dtype: float64\n\n\nIn alternativa, possiamo usare il metodo .describe():\n\ndf.groupby(\"graduated\")[\"math\"].describe().round(1)\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\ngraduated\n\n\n\n\n\n\n\n\n\n\n\n\n0\n166.0\n606.6\n34.1\n526.0\n580.5\n606.0\n629.0\n711.0\n\n\n1\n1108.0\n635.3\n38.1\n515.0\n609.5\n634.0\n659.0\n774.0\n\n\n\n\n\n\n\n\n\n\n\n16.2.2 Media spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, √® un metodo di calcolo della media che prevede l‚Äôeliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all‚Äôinizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l‚Äôultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata √® calcolata come la media aritmetica dei dati rimanenti. Questo approccio √® utile quando ci sono valori anomali o quando la distribuzione √® asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\nA titolo di esempio, procediamo al calcolo della media spuntata dei valori math per i due gruppi definiti dalla variabile graduated, escludendo il 10% dei valori pi√π estremi.\n\nnot_graduated = df[df[\"graduated\"] == 0].math\nstats.trim_mean(not_graduated, 0.10)\n\n605.6492537313433\n\n\n\ngraduated = df[df[\"graduated\"] == 1].math\nstats.trim_mean(graduated, 0.10)\n\n634.4403153153153\n\n\n\n\n16.2.3 Quantili\nIl quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\) rappresenta il valore che divide la distribuzione dei dati in modo tale che una frazione \\(p\\) dei dati si trovi al di sotto di esso.\nLa formula per calcolare il quantile non interpolato √® la seguente:\n\\[\n    q_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) √® l‚Äôelemento \\(k\\)-esimo nell‚Äôinsieme di dati ordinato in modo crescente, e \\(k\\) √® calcolato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) √® il numero totale di dati nel campione, e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all‚Äôintero successivo. In questa definizione, il quantile non interpolato corrisponde al valore effettivo nell‚Äôinsieme di dati, senza effettuare alcuna interpolazione tra i valori circostanti.\nAd esempio, consideriamo il seguente insieme di dati: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}\\). Supponiamo di voler calcolare il quantile non interpolato di ordine \\(p = 0.3\\) (cio√® il 30¬∞ percentile).\nOrdiniamo i dati in modo crescente: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\\) Calcoliamo \\(k\\) utilizzando la formula \\(k = \\lceil p \\cdot n \\rceil\\), dove \\(n\\) √® il numero totale di dati nel campione. Nel nostro caso, \\(n = 10\\) e \\(p = 0.3\\):\n\\[\nk = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n\\]\nIl quantile non interpolato corrisponde al valore \\(x_{(k)}\\), ovvero l‚Äôelemento \\(k\\)-esimo nell‚Äôinsieme ordinato: \\(q_{0.3} = x_{(3)} = 23.\\)\nOltre al quantile non interpolato, esiste anche il concetto di quantile interpolato. A differenza del quantile non interpolato, il quantile interpolato pu√≤ essere calcolato anche per percentili che non corrispondono esattamente a valori presenti nell‚Äôinsieme di dati. Per ottenere il valore del quantile interpolato, viene utilizzato un procedimento di interpolazione lineare tra i valori adiacenti. In genere, il calcolo del quantile interpolato viene eseguito mediante l‚Äôuso di software dedicati.\nOra, procediamo al calcolo dei quantili di ordine 0.10 e 0.90 per i valori math all‚Äôinterno dei due gruppi. I quantili sono dei valori che dividono la distribuzione dei dati in parti specifiche. Ad esempio, il quantile di ordine 0.10 corrisponde al valore al di sotto del quale si trova il 10% dei dati, mentre il quantile di ordine 0.90 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\nCalcoliamo i quantili di ordine 0.1 e 0.9 della distribuzione dei punteggi math nei due gruppi definiti dalla variabile graduated.\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.1), \n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.9)\n]\n\n[588.0, 684.0]\n\n\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che non hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.1),\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.9),\n]\n\n[564.5, 651.0]\n\n\n\n\n16.2.4 Moda e mediana\nIn precedenza abbiamo gi√† incontrato altri due popolari indici di tendenza centrale: la moda (Mo), che rappresenta il valore centrale della classe con la frequenza massima (in alcune distribuzioni pu√≤ esserci pi√π di una moda, rendendola multimodale e facendo perdere a questo indice il suo significato di indicatore di tendenza centrale); e la mediana (\\(\\tilde{x}\\)), che rappresenta il valore corrispondente al quantile di ordine 0.5 della distribuzione.\n\n\n16.2.5 Quando usare media, moda, mediana\nLa moda pu√≤ essere utilizzata per dati a livello nominale o ordinale ed √® l‚Äôunica tra le tre statistiche che pu√≤ essere calcolata in questi casi.\nLa media, d‚Äôaltra parte, √® una buona misura di tendenza centrale solo se la distribuzione dei dati √® simmetrica, ossia se i valori sono distribuiti uniformemente a sinistra e a destra della media. Tuttavia, se ci sono valori anomali o se la distribuzione √® asimmetrica, la media pu√≤ essere influenzata in modo significativo e, pertanto, potrebbe non essere la scelta migliore come misura di tendenza centrale.\nIn queste situazioni, la mediana pu√≤ fornire una misura migliore di tendenza centrale rispetto alla media poich√© √® meno influenzata dai valori anomali e si basa esclusivamente sul valore centrale dell‚Äôinsieme di dati. Di conseguenza, la scelta tra media e mediana dipende dal tipo di distribuzione dei dati e dagli obiettivi dell‚Äôanalisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_loc_scale.html#indici-di-dispersione",
    "href": "chapters/eda/04_loc_scale.html#indici-di-dispersione",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.3 Indici di dispersione",
    "text": "16.3 Indici di dispersione\nLe misure di posizione descritte in precedenza, come le medie e gli indici di posizione, offrono una sintesi dei dati mettendo in evidenza la tendenza centrale delle osservazioni. Tuttavia, trascurano un aspetto importante della distribuzione dei dati: la variabilit√† dei valori numerici della variabile statistica. Pertanto, √® essenziale completare la descrizione della distribuzione di una variabile statistica utilizzando anche indicatori che valutino la dispersione delle unit√† statistiche. In questo modo, otterremo una visione pi√π completa e approfondita delle caratteristiche del campione analizzato.\n\n16.3.1 Indici basati sull‚Äôordinamento dei dati\nPer valutare la variabilit√† dei dati, √® possibile utilizzare indici basati sull‚Äôordinamento dei dati. L‚Äôindice pi√π semplice √® l‚Äôintervallo di variazione, che corrisponde alla differenza tra il valore massimo e il valore minimo di una distribuzione di dati. Tuttavia, questo indice ha il limite di essere calcolato basandosi solo su due valori della distribuzione, e non tiene conto di tutte le informazioni disponibili. Inoltre, l‚Äôintervallo di variazione pu√≤ essere fortemente influenzato dalla presenza di valori anomali.\nUn altro indice basato sull‚Äôordinamento dei dati √® la differenza interquartile, gi√† incontrata in precedenza. Anche se questo indice utilizza pi√π informazioni rispetto all‚Äôintervallo di variazione, presenta comunque il limite di essere calcolato basandosi solo su due valori della distribuzione, ossia il primo quartile \\(Q_1\\) e il terzo quartile \\(Q_3\\).\nPer valutare la variabilit√† in modo pi√π completo, √® necessario utilizzare altri indici di variabilit√† che tengano conto di tutti i dati disponibili. In questo modo, si otterr√† una valutazione pi√π accurata della dispersione dei valori nella distribuzione e si potranno individuare eventuali pattern o tendenze nascoste.\n\n\n16.3.2 Varianza\nDate le limitazioni delle statistiche descritte in precedenza, √® pi√π comune utilizzare una misura di variabilit√† che tenga conto della dispersione dei dati rispetto a un indice di tendenza centrale. La varianza √® la misura di variabilit√† pi√π utilizzata per valutare la variabilit√† di una variabile statistica. Essa √® definita come la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione, come segue:\n\\[\n\\begin{equation}\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\end{equation}\n\\tag{16.3}\\]\nLa varianza √® una misura di dispersione pi√π completa rispetto a quelle descritte in precedenza. Tuttavia, √® appropriata solo nel caso di distribuzioni simmetriche ed √® fortemente influenzata dai valori anomali, come altre misure di dispersione. Inoltre, la varianza √® espressa in un‚Äôunit√† di misura che √® il quadrato dell‚Äôunit√† di misura dei dati originali, pertanto, potrebbe non essere facilmente interpretata in modo intuitivo.\nCalcoliamo la varianza dei valori math per i dati del progetto STAR. Applicando l‚Äôequazione della varianza, otteniamo:\n\nsum((df[\"math\"] - np.mean(df[\"math\"])) ** 2) / len(df[\"math\"])\n\n1507.2328523125227\n\n\nPi√π semplicemente, possiamo usare la funzione np.var():\n\nnp.var(df[\"math\"])\n\n1507.2328523125227\n\n\n\n16.3.2.1 Stima della varianza della popolazione\nSi noti il denominatore della formula della varianza. Nell‚ÄôEquazione¬†16.3, ho utilizzato \\(n\\) come denominatore (l‚Äôampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, √® possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{16.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si pu√≤ dimostrare che l‚ÄôEquazione¬†16.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l‚ÄôEquazione¬†16.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione √® illustrata nella figura seguente.\n\nx = np.arange(100 - 4 * 15, 100 + 4 * 15, 0.001)\n\nmu = 100\nsigma = 15\n\ncolor_edge = \"#8f2727\"\npdf = stats.norm.pdf(x, mu, sigma)\nplt.plot(x, pdf, color=color_edge)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()\n\n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza ‚Äì in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nx = rng.normal(loc=100, scale=15, size=4)\nprint(x)\n\n[ 96.66036673 119.88488115  91.43544977 110.02373805]\n\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza √® \\(15^2\\) = 225.\n\nnp.var(x)\n\n134.65656223872708\n\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nIl primo campione √®\n\nrandom_samples[0]\n\narray([133.75543403, 101.43900843,  94.59994101,  92.23138768])\n\n\nIl decimo campione √®\n\nrandom_samples[9]\n\narray([ 89.06126415, 109.72357033, 119.31191461, 125.38475089])\n\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs = np.array(random_samples)\nrs\n\narray([[133.75543403, 101.43900843,  94.59994101,  92.23138768],\n       [105.84924945, 124.12259109,  95.58010071,  76.35634967],\n       [ 80.23586783, 114.3021062 ,  98.54492676,  91.47149307],\n       [114.26794026,  86.66403178,  79.74954446, 102.23174837],\n       [110.22926012,  80.75554712, 100.93634803,  83.44336602],\n       [ 80.68461566, 122.39378237, 115.0707391 ,  85.53365763],\n       [ 82.42398628,  99.06628072,  95.40790879,  95.03682044],\n       [ 86.56471564,  97.82411638,  98.28650923,  99.23388255],\n       [120.24780337,  94.92211176,  87.6421954 ,  89.48037814],\n       [ 89.06126415, 109.72357033, 119.31191461, 125.38475089]])\n\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo cos√¨ 10 stime della varianza della popolazione del QI.\n\nx_var = np.var(rs, axis=1)  # applichiamo la funzione su ciascuna riga\nprint(x_var)\n\n[277.43209934 298.44010918 152.5955359  180.87367224 149.56472568\n 326.89426388  39.64935846  26.73631903 171.07120901 189.71979388]\n\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno √® noto con il nome di variabilit√† campionaria;\nin media le stime sembrano troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=0, axis=1)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(x_var, bins=10, color=color_fill, edgecolor=color_edge)\nplt.xlabel(\"Varianza\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Varianza del QI in campioni di n = 4\")\nplt.show()\n\n\n\n\n\n\n\n\nLa stima pi√π verosimile della varianza del QI √® dato dalla media di questa distribuzione.\n\nnp.mean(x_var)\n\n170.04960311858687\n\n\nSi noti che il nostro spospetto √® stato confermato: il valore medio della stima della varianza ottenuta con l‚ÄôEquazione¬†16.3 √® troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=1, axis=1)\n\nnp.mean(x_var)\n\n226.57872540048734\n\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima √® molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilit√† di un particolare campione di osservazioni. D‚Äôaltro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione √® stato estratto.\n\n\n\n16.3.3 Deviazione standard\nPer interpretare la varianza in modo pi√π intuitivo, si pu√≤ calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard √® espressa nell‚Äôunit√† di misura originaria dei dati, a differenza della varianza che √® espressa nel quadrato dell‚Äôunit√† di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo pi√π facile la comprensione della variabilit√† dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) √® definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{16.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation √® stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano ‚Äúdeviazione standard‚Äù ne √® la traduzione pi√π utilizzata nel linguaggio comune; il termine dell‚ÄôEnte Nazionale Italiano di Unificazione √® tuttavia ‚Äúscarto tipo‚Äù, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media √® una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, √® importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard pu√≤ risultare ingannevole e non rappresentare accuratamente la variabilit√† complessiva della distribuzione. Pertanto, √® fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere pi√π appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilit√† dei dati in modo pi√π accurato e affidabile.\nPer fare un esempio, calcoliamo la deviazione standard per i valori math del campione di dati del progetto STAR. Applicando l‚ÄôEquazione¬†16.5, per tutto il campione abbiamo\n\nnp.std(df.math)\n\n38.82309689234648\n\n\nPer ciascun gruppo, abbiamo:\n\ndf.groupby(\"graduated\")[\"math\"].std()\n\ngraduated\n0    34.105746\n1    38.130136\nName: math, dtype: float64\n\n\n\n16.3.3.1 Interpretazione\nLa deviazione standard pu√≤ essere interpretata in modo semplice: essa rappresenta la dispersione dei dati rispetto alla media aritmetica. √à simile allo scarto semplice medio campionario, cio√® alla media aritmetica dei valori assoluti degli scarti tra ciascuna osservazione e la media, anche se non √® identica. La deviazione standard ci fornisce un‚Äôindicazione di quanto, in media, le singole osservazioni si discostino dal centro della distribuzione.\nPer verificare l‚Äôinterpretazione della deviazione standard, utilizziamo i valori math del campione di dati del progetto STAR.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nLa deviazione standard calcolata per questi dati √® \\(\\approx 38.8\\). Questo valore ci indica che, in media, ogni osservazione si discosta di circa 38.8 punti dalla media aritmetica dei punteggi math. Maggiore √® il valore della deviazione standard, maggiore √® la dispersione dei dati attorno alla media, mentre un valore pi√π piccolo indica che i dati sono pi√π concentrati vicino alla media. La deviazione standard ci offre quindi una misura quantitativa della variabilit√† dei dati nella distribuzione.\nPer questi dati, lo scarto semplice medio campionario √®\n\nnp.mean(np.abs(df.math - np.mean(df.math)))\n\n30.9682664274501\n\n\nSi noti che i due valori sono simili, ma non identici.\n\n\n\n16.3.4 Deviazione mediana assoluta\nUna misura robusta della dispersione statistica di un campione √® la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana. Matematicamente, la formula per calcolare la MAD √®:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{16.6}\\]\nLa deviazione mediana assoluta √® particolarmente utile quando si affrontano distribuzioni con presenza di dati anomali o asimmetrie, poich√© √® meno influenzata da questi valori estremi rispetto alla deviazione standard.\nQuando i dati seguono una distribuzione gaussiana (normale), esiste una relazione specifica tra MAD e la deviazione standard (si veda il Capitolo {ref}cont-rv-distr-notebook). In una distribuzione normale, la MAD √® proporzionale alla deviazione standard. La costante di proporzionalit√† dipende dalla forma esatta della distribuzione normale, ma in generale, la relazione √® data da:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\\(\\sigma\\) √® la deviazione standard.\nMAD √® la Mediana della Deviazione Assoluta.\n\\(k\\) √® una costante che, per una distribuzione normale, √® tipicamente presa come circa 1.4826.\n\nQuesta costante di 1.4826 √® derivata dal fatto che, in una distribuzione normale, circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media. Quindi, per convertire la MAD (basata sulla mediana) nella deviazione standard (basata sulla media), si usa il reciproco di 0.6745, che √® approssimativamente 1.4826.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale √®:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione √® utile per stimare la deviazione standard in modo pi√π robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un‚Äôindicazione pi√π intuitiva della variabilit√† dei dati. Tuttavia, √® importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilit√† dei dati.\nPer verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori math del campione di dati del progetto STAR.\n\n1.4826 * np.median(np.abs(df[\"math\"] - np.median(df[\"math\"])))\n\n41.5128\n\n\nIn questo caso, la MAD per i punteggi di matematica √® simile alla deviazione standard.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nInfatti, la distribuzione dei punteggi math √® approssimativamente gaussiana.\n\nplt.hist(df[\"math\"], bins=10, color=color_fill, edgecolor=color_edge)\nplt.xlabel(\"math\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione dei Punteggi di Matematica\")\nplt.show()\n\n\n\n\n\n\n\n\nVerifichiamo nuovamente il principio usando un campione di dati estratto da una popolazione normale. Usiamo, ad esempio, la distribuzione \\(\\mathcal{N}(100, 15)\\):\n\nx = np.random.normal(loc=100, scale=15, size=10000)\n1.4826 * np.median(np.abs(x - np.median(x)))\n\n15.152283592574692\n\n\n\n\n16.3.5 Quando usare la deviazione standard e MAD\nLa deviazione standard e la MAD sono entrambe misure di dispersione che forniscono informazioni su quanto i dati in un insieme si discostano dalla tendenza centrale. Tuttavia, ci sono alcune differenze tra le due misure e situazioni in cui pu√≤ essere pi√π appropriato utilizzare una rispetto all‚Äôaltra.\n\nDeviazione standard: Questa misura √® particolarmente utile per descrivere la dispersione dei dati in una distribuzione normale. La deviazione standard √® una scelta appropriata se si vuole sapere quanto i dati sono distribuiti intorno alla media, o se si vuole confrontare la dispersione di due o pi√π set di dati. Tuttavia, la deviazione standard √® fortemente influenzata dalla presenza di dati anomali, e questo pu√≤ rappresentare una limitazione in casi in cui sono presenti valori estremi nell‚Äôinsieme di dati.\nDeviazione mediana assoluta (MAD): La MAD √® meno sensibile ai valori anomali rispetto alla deviazione standard, il che la rende una scelta migliore quando ci sono valori anomali nell‚Äôinsieme di dati. Inoltre, la MAD pu√≤ essere una buona scelta quando si lavora con dati non normalmente distribuiti, poich√© non assume una distribuzione specifica dei dati. La MAD √® calcolata utilizzando la mediana e i valori assoluti delle deviazioni dei dati dalla mediana, il che la rende una misura robusta di dispersione.\n\nIn sintesi, se si sta lavorando con dati normalmente distribuiti, la deviazione standard √® la misura di dispersione pi√π appropriata. Se si lavora con dati non normalmente distribuiti o si hanno valori anomali nell‚Äôinsieme di dati, la MAD pu√≤ essere una scelta migliore. In ogni caso, la scelta tra le due misure dipende dal tipo di dati che si sta analizzando e dall‚Äôobiettivo dell‚Äôanalisi.\n\n\n16.3.6 Indici di variabilit√† relativi\nA volte pu√≤ essere necessario confrontare la variabilit√† di grandezze incommensurabili, ovvero di caratteri misurati con differenti unit√† di misura. In queste situazioni, le misure di variabilit√† descritte in precedenza diventano inadeguate poich√© dipendono dall‚Äôunit√† di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilit√†.\nIl pi√π importante di questi indici √® il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{16.7}\\]\nIl coefficiente di variazione √® un numero puro e permette di confrontare la variabilit√† di distribuzioni con unit√† di misura diverse.\nUn altro indice relativo di variabilit√† √® la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice √® definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilit√† forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unit√† di misura e facilitando l‚Äôanalisi delle differenze di variabilit√† tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/eda/04_loc_scale.html#la-fallacia-ergodica",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.4 La fallacia ergodica",
    "text": "16.4 La fallacia ergodica\nSebbene il concetto di ‚Äúmedia‚Äù possa sembrare chiaro, ci√≤ non implica che il suo utilizzo non presenti delle problematiche nell‚Äôambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi √® ci√≤ che viene definito ‚Äúfallacia ergodica‚Äù.\nIl concetto di ‚Äúfallacia ergodica‚Äù (Speelman et al. 2024) si riferisce all‚Äôerrore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all‚Äôinterno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio √® che l‚Äôuso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo √® ingiustificato, poich√© le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull‚Äôassunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere cos√¨ simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all‚Äôinterno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di pi√π individui non descrivono accuratamente nessuno di quegli individui in un dato momento, n√© possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell‚Äôassumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_loc_scale.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/04_loc_scale.html#commenti-e-considerazioni-finali",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.5 Commenti e considerazioni finali",
    "text": "16.5 Commenti e considerazioni finali\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un‚Äôidea della variabilit√† dei dati. In sintesi, le statistiche descrittive ci offrono un quadro chiaro e sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilit√†.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "16¬† Indici di posizione e di scala",
    "section": "16.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "16.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nSpeelman, Craig P, Laura Parker, Benjamin J Rapley, e Marek McGann. 2024. ¬´Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals¬ª. Collabra: Psychology 10 (1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Indici di posizione e di scala</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html",
    "href": "chapters/eda/05_correlation.html",
    "title": "17¬† Le relazioni tra variabili",
    "section": "",
    "text": "Introduzione\nNonostante sia un‚Äôoperazione di base, l‚Äôanalisi delle associazioni tra variabili rappresenta uno degli aspetti pi√π controversi nell‚Äôambito dell‚Äôanalisi dei dati psicologici. Sebbene possa sembrare un passaggio naturale dopo l‚Äôanalisi univariata, questo processo solleva numerose questioni metodologiche e concettuali.\nTradizionalmente, in psicologia, l‚Äôanalisi delle associazioni tra variabili √® stata considerata come l‚Äôobiettivo finale del processo di ricerca. Questa visione si basa sull‚Äôidea che la descrizione delle relazioni tra variabili fornisca una spiegazione esaustiva dei fenomeni psicologici. Tale approccio trova le sue radici storiche nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate:\nSebbene sia indubbio che rispondere alla seconda domanda posta da Pearson sia relativamente semplice, √® altres√¨ evidente che la nostra comprensione di un fenomeno non pu√≤ dipendere unicamente dalle informazioni fornite dalle correlazioni.\nIn contrasto con questa visione tradizionale, la ‚ÄúCausal Revolution‚Äù propone un paradigma radicalmente diverso secondo il quale le associazioni tra variabili sono considerate come epifenomeni, mentre l‚Äôobiettivo principale della ricerca √® l‚Äôidentificazione e la comprensione delle relazioni causali: per comprendere veramente i fenomeni psicologici √® essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nLa discussione dei metodi utilizzati per individuare le relazioni causali sar√† trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. √à importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all‚Äôutilizzo di indici lineari.\nNel linguaggio comune, termini come ‚Äúdipendenza‚Äù, ‚Äúassociazione‚Äù e ‚Äúcorrelazione‚Äù vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, √® importante distinguere questi concetti:\n√à cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalit√†. Questa distinzione √® fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell‚Äôassociazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#introduzione",
    "href": "chapters/eda/05_correlation.html#introduzione",
    "title": "17¬† Le relazioni tra variabili",
    "section": "",
    "text": "Quanto spesso, quando √® stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‚Äòqual √® la sua causa?‚Äô. Questa √® una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, pu√≤ essere pi√π facile rispondere alla domanda: ‚Äòin che misura altri fenomeni sono associati con esso?‚Äô. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\n\n\n\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un‚Äôaltra.\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), √® probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l‚Äôintensit√† di una relazione lineare.\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#i-dati-grezzi",
    "href": "chapters/eda/05_correlation.html#i-dati-grezzi",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.1 I dati grezzi",
    "text": "17.1 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche, Buerkner, e Renneberg (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione √® stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II √® uno strumento di autovalutazione utilizzato per valutare la gravit√† della depressione in adulti e adolescenti. Il test √® stato sviluppato per identificare e misurare l‚Äôintensit√† dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado pi√π basso e 3 il grado pi√π elevato di sintomatologia depressiva.\nNell‚Äôesercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche, Buerkner, e Renneberg (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/eda/05_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.2 Definizione delle relazioni tra variabili",
    "text": "17.2 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o pi√π variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ci√≤, prendiamo ad esempio l‚Äôaltezza e l‚Äôet√† tra un gruppo di bambini. In generale, √® possibile notare che all‚Äôaumentare dell‚Äôet√† di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l‚Äôet√† di un bambino, ad esempio tredici anni, e l‚Äôet√† di un altro, sei anni, ci fornisce un‚Äôindicazione su quale dei due bambini sia pi√π alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e et√† come positiva, il che significa che all‚Äôaumentare dei valori di una delle variabili (in questo caso, l‚Äôet√†), ci aspettiamo di vedere valori pi√π elevati anche nell‚Äôaltra variabile (l‚Äôaltezza). Tuttavia, esistono anche relazioni negative, in cui l‚Äôaumento di una variabile √® associato a un diminuzione dell‚Äôaltra (ad esempio, pi√π et√† √® correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo cos√¨ una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili pu√≤ essere categorica, rendendo difficile parlare di ‚Äúmaggioranza‚Äù o ‚Äúminoranza‚Äù ma piuttosto di ‚Äúdifferente‚Äù (ad esempio, i bambini pi√π grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini pi√π piccoli, senza necessariamente essere ‚Äúmigliori‚Äù o ‚Äúpeggiori‚Äù).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#sec-scatter-plot",
    "href": "chapters/eda/05_correlation.html#sec-scatter-plot",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.3 Grafico a dispersione",
    "text": "17.3 Grafico a dispersione\nIl metodo pi√π diretto per visualizzare la relazione tra due variabili continue √® tramite un grafico a dispersione, comunemente noto come ‚Äúscatterplot‚Äù. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull‚Äôasse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l‚Äôidea pi√π chiara, consideriamo i dati dello studio condotto da Zetsche, Buerkner, e Renneberg (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II √® uno strumento di autovalutazione che valuta la presenza e l‚Äôintensit√† dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D √® una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poich√© entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf = pd.read_csv(\"../../data/data.mood.csv\", index_col=0)\n\n# Seleziona le colonne di interesse\ndf = df[[\"esm_id\", \"group\", \"bdi\", \"cesd_sum\"]]\n\n# Rimuovi le righe duplicate\ndf = df.drop_duplicates(keep=\"first\")\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf = df.dropna(subset=[\"bdi\"])\n\nPosizionando i valori del BDI-II sull‚Äôasse delle ascisse e quelli del CES-D sull‚Äôasse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. √à evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l‚Äôutilizzo di unit√† di misura arbitrarie per le due variabili. L‚Äôerrore di misurazione √® una componente inevitabile che influisce in parte su qualsiasi misurazione, ed √® particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione √® generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici √® che l‚Äôunit√† di misura della depressione √® una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all‚Äôuso di unit√† di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di ‚Äúassociazione lineare‚Äù, √® possibile esaminare i dati attraverso l‚Äôutilizzo di un diagramma a dispersione.\n\n# Crea uno scatterplot con colori diversi per i due gruppi\nplt.scatter(df[df[\"group\"] == \"mdd\"][\"bdi\"], df[df[\"group\"] == \"mdd\"][\"cesd_sum\"], label=\"Pazienti\", c=\"C0\")\nplt.scatter(df[df[\"group\"] == \"ctl\"][\"bdi\"], df[df[\"group\"] == \"ctl\"][\"cesd_sum\"], label=\"Controlli\", c=\"C2\")\n\n# Calcola i coefficienti della retta dei minimi quadrati\ncoeff_combined = np.polyfit(df[\"bdi\"], df[\"cesd_sum\"], 1)\n\n# Calcola la retta dei minimi quadrati\nline_combined = np.poly1d(coeff_combined)\n\n# Disegna la retta dei minimi quadrati\nx_values = np.linspace(df[\"bdi\"].min(), df[\"bdi\"].max(), 100)\nplt.plot(x_values, line_combined(x_values), linestyle='--', color='C3')\n\n# Etichette degli assi\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"CESD\")\n\n# Linee verticali ed orizzontali per le medie\nplt.axvline(np.mean(df[df[\"group\"] == \"mdd\"][\"bdi\"]), alpha=0.2, color=\"blue\")\nplt.axvline(np.mean(df[df[\"group\"] == \"ctl\"][\"bdi\"]), alpha=0.2, color=\"red\")\nplt.axhline(np.mean(df[df[\"group\"] == \"mdd\"][\"cesd_sum\"]), alpha=0.2, color=\"blue\")\nplt.axhline(np.mean(df[df[\"group\"] == \"ctl\"][\"cesd_sum\"]), alpha=0.2, color=\"red\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, √® evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ci√≤ suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, √® importante notare che la relazione lineare tra le due variabili √® lontana dall‚Äôessere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realt√†, la dispersione dei punti dal comportamento lineare ideale √® evidente.\nDi conseguenza, sorge la necessit√† di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#covarianza",
    "href": "chapters/eda/05_correlation.html#covarianza",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.4 Covarianza",
    "text": "17.4 Covarianza\nIniziamo a considerare il pi√π importante di tali indici, chiamato covarianza. In realt√† la definizione di questo indice non ci sorprender√† pi√π di tanto in quanto, in una forma solo apparentemente diversa, l‚Äôabbiamo gi√† incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) √® definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la ‚Äúcovarianza di una variabile con s√© stessa‚Äù. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) ‚Äúvariano insieme‚Äù (co-variano). √à facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{17.1}\\]\nL‚ÄôEquazione¬†17.1 ci fornisce la definizione della covarianza.\n\n17.4.1 Interpretazione\nPer capire il significato dell‚ÄôEquazione¬†17.1, supponiamo di dividere il grafico riportato nella Sezione 17.3 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avr√† un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avr√† segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avr√† un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avr√† segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l‚Äôassociazione lineare si dice positiva se la covarianza √® positiva, negativa se la covarianza √® negativa.\nEsercizio. Implemento l‚ÄôEquazione¬†17.1 in Python.\n\ndef cov_value(x, y):\n\n    mean_x = sum(x) / float(len(x))\n    mean_y = sum(y) / float(len(y))\n\n    sub_x = [i - mean_x for i in x]\n    sub_y = [i - mean_y for i in y]\n\n    sum_value = sum([sub_y[i] * sub_x[i] for i in range(len(x))])\n    denom = float(len(x))\n\n    cov = sum_value / denom\n    return cov\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD √® 207.4\n\nx = df[\"bdi\"]\ny = df[\"cesd_sum\"]\n\ncov_value(x, y)\n\n207.42653810835637\n\n\nOppure, in maniera pi√π semplice:\n\nnp.mean((x - np.mean(x)) * (y - np.mean(y)))\n\n207.42653810835628\n\n\nLo stesso risultato si ottiene con la funzione cov di NumPy.\n\nnp.cov(x, y, ddof=0)\n\narray([[236.23875115, 207.42653811],\n       [207.42653811, 222.83379247]])\n\n\nLa funzione np.cov(x, y, ddof=0) in Python, utilizzata tramite la libreria NumPy, calcola la covarianza tra due array, x e y. L‚Äôargomento ddof (Delta Degrees of Freedom) specifica il ‚Äúcorrettore‚Äù da applicare al denominatore della formula di covarianza.\nQuando si imposta ddof=0, la formula utilizzata per il calcolo della covarianza divide la somma dei prodotti delle deviazioni dalla media per n, dove n √® il numero totale degli elementi nel campione (ovvero, la dimensione del campione). Questo approccio assume che i dati forniti rappresentino l‚Äôintera popolazione da cui si vuole stimare la covarianza, producendo una stima non corretta (bias) se i dati sono effettivamente un campione di una popolazione pi√π ampia. Il ‚Äúbias‚Äù in questo contesto si riferisce al fatto che la stima tende sistematicamente a essere pi√π piccola rispetto alla vera covarianza della popolazione da cui il campione √® stato estratto.\nPer correggere questo errore sistematico e ottenere una stima non distorta (unbiased) della covarianza di una popolazione pi√π ampia basandosi su un campione, si utilizza ddof=1. Questo significa che al denominatore della formula si sottrae 1 a n, dividendo quindi per n-1. Il correttore n-1 √® noto come correttore di Bessel, e l‚Äôuso di ddof=1 rende la stima della covarianza non distorta nel contesto di un campione prelevato da una popolazione. La correzione √® importante in statistica perch√© fornisce una stima pi√π accurata delle propriet√† della popolazione, soprattutto quando la dimensione del campione √® piccola.\nIn sintesi: - Con ddof=0, si divide per n, assumendo che i dati rappresentino l‚Äôintera popolazione. Questo pu√≤ introdurre un bias nella stima della covarianza se i dati sono in realt√† un campione. - Con ddof=1, si divide per n-1, correggendo il bias e ottenendo una stima non distorta (unbiased) della covarianza se i dati rappresentano un campione di una popolazione pi√π grande. Questo approccio √® generalmente preferito per la stima delle propriet√† della popolazione basata su campioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#correlazione",
    "href": "chapters/eda/05_correlation.html#correlazione",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.5 Correlazione",
    "text": "17.5 Correlazione\nLa direzione della relazione tra le variabili √® indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poich√© dipende dall‚Äôunit√† di misura delle variabili. Ad esempio, considerando l‚Äôaltezza e il peso delle persone, la covarianza sar√† pi√π grande se l‚Äôaltezza √® misurata in millimetri e il peso in grammi, rispetto al caso in cui l‚Äôaltezza √® in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l‚Äôindice di correlazione.\nLa correlazione √® ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr_{XY} = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{17.2}\\]\nLa quantit√† che si ottiene dall‚ÄôEquazione¬†17.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l‚Äôuno dall‚Äôaltro, l‚Äôhanno introdotta).\n\n17.5.1 Propriet√†\nIl coefficiente di correlazione ha le seguenti propriet√†:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\n√® un numero puro, cio√® non dipende dall‚Äôunit√† di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n\n\n17.5.2 Interpretazione\nAll‚Äôindice di correlazione possiamo assegnare la seguente interpretazione:\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensit√† diversa;\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza √® 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c‚Äô√® un‚Äôassociazione lineare positiva. Per capire quale sia l‚Äôintensit√† della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore √® prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\nnp.corrcoef(x, y)\n\narray([[1.        , 0.90406202],\n       [0.90406202, 1.        ]])\n\n\nReplichiamo il risultato implementando l‚Äôeq. {eq}eq-cor-def:\n\ns_xy = np.mean((x - np.mean(x)) * (y - np.mean(y)))\ns_x = x.std(ddof=0)\ns_y = y.std(ddof=0)\nr_xy = s_xy / (s_x * s_y)\nprint(r_xy)\n\n0.9040620189474861\n\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD √® quello di standardizzare le due variabili per poi applicare la formula della covarianza:\n\nz_x = (x - np.mean(x)) / np.std(x, ddof=0)\nz_y = (y - np.mean(y)) / np.std(y, ddof=0)\nnp.mean(z_x * z_y)\n\n0.9040620189474862\n\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al.¬†(2024). Il concetto di ‚Äúgender bias‚Äù si riferisce alla tendenza sistematica di favorire un sesso rispetto all‚Äôaltro, spesso a scapito delle donne. Lo studio di Guilbeault et al.¬†(2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralit√† di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella societ√†. Il lavoro di Guilbeault et al.¬†(2024) evidenzia che il preconcetto di genere √® molto pi√π evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto pu√≤ essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al.¬†(2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura √® vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi √® alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralit√† di genere. In sostanza, questa misura di frequenza pu√≤ essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell‚Äôaltro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\n\nIl preconcetto di genere √® pi√π prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell‚Äôassociazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione √® stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al.¬†(2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/05_correlation.html#correlazione-di-spearman",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.6 Correlazione di Spearman",
    "text": "17.6 Correlazione di Spearman\nUn‚Äôalternativa per valutare la relazione lineare tra due variabili √® il coefficiente di correlazione di Spearman, che si basa esclusivamente sull‚Äôordine dei dati e non sugli specifici valori. Questo indice di associazione √® particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalit√† di risposta dei soggetti, ma non l‚Äôintensit√† della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come ‚Äúordinali‚Äù.\n\n\n\n\n\n\n√à importante ricordare che, nel caso di una variabile ordinale, non √® possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, √® possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalit√† di risposta. Come abbiamo appena visto, la direzione e l‚Äôintensit√† dell‚Äôassociazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\nstats.spearmanr([1, 2, 3, 4, 5], [5, 6, 7, 8, 7])\n\nSignificanceResult(statistic=0.8207826816681233, pvalue=0.08858700531354381)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#correlazione-nulla",
    "href": "chapters/eda/05_correlation.html#correlazione-nulla",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.7 Correlazione nulla",
    "text": "17.7 Correlazione nulla\nUn aspetto finale da sottolineare riguardo alla correlazione √® che essa descrive la direzione e l‚Äôintensit√† della relazione lineare tra due variabili. Tuttavia, la correlazione non cattura relazioni non lineari tra le variabili, anche se possono essere molto forti. √à fondamentale comprendere che una correlazione pari a zero non implica l‚Äôassenza di una relazione tra le due variabili, ma indica solamente l‚Äôassenza di una relazione lineare tra di esse.\nLa figura seguente fornisce tredici esempi di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili. In questi tredici insiemi di dati i coefficienti di correlazione di Pearson sono sempre uguali a 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili.\n\ndatasaurus_data = pd.read_csv(\"../../data/datasaurus.csv\")\ndatasaurus_data.groupby(\"dataset\").agg(\n    {\"x\": [\"count\", \"mean\", \"std\"], \"y\": [\"count\", \"mean\", \"std\"]}\n)\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\ncount\nmean\nstd\ncount\nmean\nstd\n\n\ndataset\n\n\n\n\n\n\n\n\n\n\naway\n142\n54.266100\n16.769825\n142\n47.834721\n26.939743\n\n\nbullseye\n142\n54.268730\n16.769239\n142\n47.830823\n26.935727\n\n\ncircle\n142\n54.267320\n16.760013\n142\n47.837717\n26.930036\n\n\ndino\n142\n54.263273\n16.765142\n142\n47.832253\n26.935403\n\n\ndots\n142\n54.260303\n16.767735\n142\n47.839829\n26.930192\n\n\nh_lines\n142\n54.261442\n16.765898\n142\n47.830252\n26.939876\n\n\nhigh_lines\n142\n54.268805\n16.766704\n142\n47.835450\n26.939998\n\n\nslant_down\n142\n54.267849\n16.766759\n142\n47.835896\n26.936105\n\n\nslant_up\n142\n54.265882\n16.768853\n142\n47.831496\n26.938608\n\n\nstar\n142\n54.267341\n16.768959\n142\n47.839545\n26.930275\n\n\nv_lines\n142\n54.269927\n16.769959\n142\n47.836988\n26.937684\n\n\nwide_lines\n142\n54.266916\n16.770000\n142\n47.831602\n26.937902\n\n\nx_shape\n142\n54.260150\n16.769958\n142\n47.839717\n26.930002\n\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(4, 4, figsize=(15, 15))\ndatasets = datasaurus_data[\"dataset\"].unique()\n\nfor i, dataset in enumerate(datasets):\n    row = i // 4\n    col = i % 4\n    ax = axs[row, col]\n    subset = datasaurus_data[datasaurus_data[\"dataset\"] == dataset]\n    ax.scatter(subset[\"x\"], subset[\"y\"], alpha=0.7)\n    ax.set_title(dataset)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_61607/188333220.py:14: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#due-paradossi-comuni",
    "href": "chapters/eda/05_correlation.html#due-paradossi-comuni",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.8 Due Paradossi Comuni",
    "text": "17.8 Due Paradossi Comuni\nEsistono due situazioni comuni in cui le associazioni tra variabili possono ingannarci, e che vale la pena esaminare esplicitamente: il paradosso di Simpson e il paradosso di Berkson.\n\n17.8.1 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando stimiamo una relazione per sottoinsiemi dei nostri dati, ma otteniamo una relazione diversa considerando l‚Äôintero dataset (Simpson 1951). √à un caso particolare della fallacia ecologica, che si verifica quando cerchiamo di fare affermazioni sugli individui basandoci sui loro gruppi. Ad esempio, potrebbe esserci una relazione positiva tra i voti universitari e la performance alla scuola di specializzazione in due dipartimenti considerati individualmente. Tuttavia, se i voti universitari tendono a essere pi√π alti in un dipartimento rispetto all‚Äôaltro, mentre la performance alla scuola di specializzazione tende a essere opposta, potremmo trovare una relazione negativa tra i voti universitari e la performance alla scuola di specializzazione.\n\n\n17.8.2 Paradosso di Berkson\nIl paradosso di Berkson si verifica quando stimiamo una relazione basandoci sul dataset che abbiamo, ma a causa della selezione del dataset, la relazione risulta diversa in un dataset pi√π generale (Berkson 1946). Ad esempio, se abbiamo un dataset di ciclisti professionisti, potremmo non trovare una relazione tra il loro VO2 max e la possibilit√† di vincere una gara di ciclismo (Coyle et al.¬†1988; Podlogar, Leo, and Spragg 2022). Tuttavia, se avessimo un dataset della popolazione generale, potremmo trovare una relazione tra queste due variabili. Il dataset professionale √® cos√¨ selezionato che la relazione scompare; non si pu√≤ diventare ciclisti professionisti senza avere un VO2 max adeguato, ma tra i ciclisti professionisti, tutti hanno un VO2 max sufficiente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#considerazioni-conclusive",
    "href": "chapters/eda/05_correlation.html#considerazioni-conclusive",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.9 Considerazioni conclusive",
    "text": "17.9 Considerazioni conclusive\nIn questo capitolo, abbiamo esplorato i concetti fondamentali di correlazione e covarianza, strumenti essenziali per quantificare le relazioni tra variabili nei fenomeni psicologici. Tuttavia, √® cruciale sottolineare che le associazioni osservate non sono necessariamente indicative dei meccanismi causali sottostanti.\nLe relazioni tra variabili possono manifestarsi in diversi scenari:\n\nCausalit√† Diretta: Quando una variabile \\(X\\) influenza causalmente una variabile \\(Y\\), si osserver√† un‚Äôassociazione tra le due. In un contesto ideale, con un effetto causale lineare e isolato, la correlazione rifletter√† direttamente l‚Äôentit√† e la direzione dell‚Äôeffetto causale.\nInterferenza di Altre Variabili: La realt√† √® spesso pi√π complessa. Anche in presenza di una relazione causale diretta tra \\(X\\) e \\(Y\\), l‚Äôintervento di altre variabili pu√≤ alterare significativamente l‚Äôassociazione osservata. Come vedremo nel capitolo successivo, a seconda della struttura delle relazioni causali, possiamo riscontrare associazioni positive, nulle o addirittura negative, pur in presenza di un effetto causale positivo.\nAssociazioni Spurie: √à possibile osservare associazioni tra variabili anche in assenza di qualsiasi relazione causale diretta. Questo fenomeno sottolinea l‚Äôimportanza di non confondere correlazione e causalit√†.\n\nQuesti scenari evidenziano un principio fondamentale: l‚Äôosservazione di un‚Äôassociazione tra due variabili, in assenza di ulteriori informazioni, non permette di trarre conclusioni definitive sulle relazioni causali sottostanti. Le associazioni, prese singolarmente, non forniscono informazioni utili sul fenomeno in esame.\nNonostante questi limiti, le associazioni tra variabili non perdono il loro valore. Quando integrate in un contesto pi√π ampio, che include:\n\nla misurazione di molteplici variabili,\nla conoscenza approfondita del dominio di studio,\nl‚Äôapplicazione di metodi statistici avanzati,\n\nle associazioni possono diventare strumenti preziosi per descrivere le caratteristiche dei meccanismi che governano i fenomeni psicologici di interesse.\nNel prossimo capitolo approfondiremo queste tematiche, esplorando metodi e approcci che ci permetteranno di andare oltre la semplice osservazione delle associazioni, verso una comprensione causale dei fenomeni psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "17¬† Le relazioni tra variabili",
    "section": "17.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "17.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 31 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\narviz     : 0.18.0\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.14.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Le relazioni tra variabili</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html",
    "href": "chapters/eda/06_causality.html",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "",
    "text": "Introduzione\nLa pura osservazione dei dati pu√≤ rivelare correlazioni e pattern nei dati, ma senza un‚Äôindagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro ‚ÄúStatistical Rethinking‚Äù (McElreath 2020), utilizza l‚Äôanalogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che √® stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull‚Äôanalisi delle associazioni statistiche tra variabili, trascurando considerazioni pi√π profonde sulla causalit√†.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti relazioni causali e i test statistici impiegati. Questa disconnessione √® evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\n√à importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica √® stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilit√† nella ricerca psicologica, come approfondito nel Capitolo 94. L‚Äôapproccio descritto, pur essendo potente nell‚Äôindividuare correlazioni, manca della ‚Äúsaggezza‚Äù necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) √® che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull‚Äôanalisi delle associazioni mediante il test dell‚Äôipotesi nulla non √® in grado di distinguere tra questi diversi scenari, come spiegato nel Capitolo 69.\nL‚Äôapproccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacit√† di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al. 2023). √à invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull‚Äôintroduzione dei concetti fondamentali dell‚Äôanalisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#introduzione",
    "href": "chapters/eda/06_causality.html#introduzione",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall‚Äôalto, l‚Äôutente risponde a una serie di domande riguardanti la misurazione e l‚Äôintento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#cos√®-la-causalit√†",
    "href": "chapters/eda/06_causality.html#cos√®-la-causalit√†",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.1 Cos‚Äô√® la causalit√†?",
    "text": "18.1 Cos‚Äô√® la causalit√†?\nHardt e Recht (2022) introducono il concetto di causalit√† distinguendo tra osservazione e azione. Ci√≤ che vediamo nell‚Äôosservazione passiva √® il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande pi√π importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attivit√† fisica soffrono meno d‚Äôansia; vogliamo capire se l‚Äôattivit√† fisica riduce effettivamente i livelli d‚Äôansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l‚Äôuso frequente dei social media √® associato a un calo del benessere mentale; vogliamo determinare se l‚Äôuso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale √® un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l‚Äôeffetto di un‚Äôazione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#effetto-causale",
    "href": "chapters/eda/06_causality.html#effetto-causale",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.2 Effetto Causale",
    "text": "18.2 Effetto Causale\nSebbene non esista una definizione univoca di causalit√†, possiamo concettualizzarla in modo pratico: diciamo che X causa Y se, intervenendo e modificando il valore di X (il trattamento), la distribuzione di Y cambia di conseguenza. Questa definizione sottolinea l‚Äôimportanza cruciale dell‚Äôazione o dell‚Äôintervento nel determinare una relazione causale.\nQuando X √® una variabile binaria, rappresentante la presenza o l‚Äôassenza del trattamento, la conseguenza dell‚Äôintervento su X √® denominata effetto medio del trattamento. Questo ci indica quanto il trattamento (azione X = 1) aumenta l‚Äôaspettativa di Y rispetto all‚Äôassenza di trattamento (azione X = 0).\n√à importante notare che gli effetti causali sono quantit√† relative alla popolazione. Si riferiscono a effetti mediati sull‚Äôintera popolazione in esame. Tuttavia, spesso l‚Äôeffetto del trattamento pu√≤ variare significativamente da un individuo all‚Äôaltro o tra gruppi di individui. In questi casi, parliamo di effetti di trattamento eterogenei.\nPer chiarire questo concetto, consideriamo un esempio concreto: supponiamo che la terapia cognitivo-comportamentale (CBT) riduca l‚Äôansia. Se un gruppo di persone ansiose non riceve alcun trattamento, i loro livelli d‚Äôansia rimarranno presumibilmente invariati. Se invece interveniamo introducendo la CBT (modificando cos√¨ il valore di X), i livelli d‚Äôansia nel gruppo tenderanno a diminuire (cambiando quindi il valore di Y). Questo esempio illustra la distinzione tra semplice correlazione, basata sull‚Äôosservazione passiva, e causalit√†, che implica un‚Äôazione o un intervento.\nLa definizione di causalit√† pu√≤ essere applicata anche per collegare variabili apparentemente distanti. Ad esempio, l‚Äôautoefficacia potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l‚Äôautoefficacia attraverso interventi mirati, √® probabile che osserviamo un miglioramento nell‚Äôimpegno allo studio. Questo aumento dell‚Äôimpegno, a sua volta, tende a migliorare le prestazioni accademiche. Di conseguenza, possiamo affermare che l‚Äôautoefficacia influisce indirettamente sulle prestazioni accademiche attraverso una catena causale.\n√à importante precisare che affermiamo l‚Äôesistenza di una relazione causale tra X e Y anche quando modificare X non porta necessariamente a un cambiamento immediato o deterministico in Y, ma altera la probabilit√† che Y si verifichi in un certo modo, modificando quindi la distribuzione di Y. Questa prospettiva probabilistica della causalit√† √® particolarmente rilevante in campi come la psicologia, dove le relazioni tra variabili sono spesso complesse e influenzate da molteplici fattori.\n\n18.2.1 I Limiti dell‚ÄôOsservazione\nPer comprendere i limiti dell‚Äôosservazione passiva, e quindi la necessit√† di comprendere le relazioni causali sottostanti, Hardt e Recht (2022) si riferiscono all‚Äôesempio storico delle ammissioni ai corsi di laurea dell‚ÄôUniversit√† della California, Berkeley, nel 1973. In quell‚Äôanno, 12,763 candidati furono considerati per l‚Äôammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test di significativit√† statistica indicano che questa differenza non √® attribuibile al caso, suggerendo una disparit√† nei tassi di ammissione tra i generi.\nUna tendenza simile si osserva quando si analizzano le decisioni aggregate di ammissione nei sei maggiori dipartimenti. Il tasso di ammissione complessivo per gli uomini era di circa il 44%, mentre per le donne era solo il 30%, un‚Äôaltra differenza significativa. Tuttavia, poich√© i dipartimenti hanno autonomia nelle loro decisioni di ammissione, √® utile esaminare il possibile bias di genere a livello di singolo dipartimento.\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall‚Äôosservazione di questi dati, emerge che quattro dei sei maggiori dipartimenti mostrano un tasso di ammissione pi√π elevato per le donne, mentre due mostrano un tasso pi√π elevato per gli uomini. Tuttavia, questi due dipartimenti non possono giustificare la sostanziale differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione pi√π alto per gli uomini sembra invertita quando i dati sono disaggregati per dipartimento.\nQuesto fenomeno √® noto come paradosso di Simpson, un paradosso statistico in cui una tendenza che appare in sottopopolazioni si inverte o scompare quando i dati vengono aggregati. Nel contesto attuale, il paradosso di Simpson si manifesta nel fatto che, mentre i dati aggregati sembrano indicare una discriminazione di genere contro le donne, l‚Äôanalisi dei dati disaggregati per dipartimento rivela che in alcuni casi le donne sono favorite in termini di ammissioni.\nLa domanda fondamentale √® se questi dati indicano effettivamente un problema di discriminazione di genere o se, come suggerito dallo studio originale, il bias di genere nelle ammissioni fosse principalmente dovuto al fatto che ‚Äúle donne sono indirizzate dalla loro socializzazione e istruzione verso campi di studio generalmente pi√π affollati, meno produttivi in termini di completamento dei diplomi, meno finanziati e che spesso offrono prospettive professionali peggiori.‚Äù In altre parole, il problema risiederebbe in differenze sistemiche e strutturali tra i campi di studio scelti dalle donne e quelli scelti dagli uomini.\nIl paradosso di Simpson crea disagio proprio perch√© l‚Äôintuizione suggerisce che una tendenza valida per tutte le sottopopolazioni dovrebbe esserlo anche a livello aggregato. Tuttavia, questo paradosso evidenzia un errore comune nell‚Äôinterpretazione delle probabilit√† condizionate: confondere l‚Äôosservazione passiva con l‚Äôanalisi causale. I dati che abbiamo rappresentano solo un‚Äôistantanea del comportamento normale di uomini e donne che si candidavano per l‚Äôammissione a UC Berkeley nel 1973.\nNon possiamo trarre conclusioni definitive da questi dati. Possiamo solo riconoscere che l‚Äôanalisi iniziale solleva ulteriori domande, come ad esempio la necessit√† di progettare nuovi studi per raccogliere dati pi√π completi, che potrebbero portare a conclusioni pi√π definitive. In alternativa, potremmo discutere su quale scenario sia pi√π verosimile in base alle nostre convinzioni e alle notre ipotesi sul mondo.\nL‚Äôinferenza causale pu√≤ essere utile in entrambi i casi. Da un lato, pu√≤ guidare la progettazione di nuovi studi, aiutandoci a scegliere quali variabili includere, quali escludere e quali mantenere costanti. Dall‚Äôaltro, i modelli causali possono fungere da meccanismo per incorporare le conoscenze scientifiche del dominio e passare da ipotesi plausibili a conclusioni plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#variabili-confondenti",
    "href": "chapters/eda/06_causality.html#variabili-confondenti",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.3 Variabili confondenti",
    "text": "18.3 Variabili confondenti\nSebbene gli esperimenti controllati offrano un elevato grado di certezza nell‚Äôidentificazione di queste relazioni, molte domande di ricerca non possono essere affrontate sperimentalmente a causa di limitazioni etiche o pratiche. In questi casi, i ricercatori ricorrono a disegni osservazionali, che offrono maggiore flessibilit√† e applicabilit√†. Tuttavia, l‚Äôuso di dati osservazionali comporta una sfida significativa: la difficolt√† di trarre conclusioni causali affidabili.\nAl centro di questa complessit√† si trovano le variabili confondenti. Possiamo dire che una variabile confondente √® presente quando l‚Äôassociazione osservata tra due variabili X e Y non riflette accuratamente la vera relazione causale tra di esse. In altre parole, la variabile confondente influenza sia X che Y, creando l‚Äôapparenza di una relazione diretta tra le due che potrebbe essere fuorviante o inesatta.\nNegli studi osservazionali, se le variabili confondenti non vengono misurate e controllate adeguatamente, possono distorcere le stime degli effetti causali, introducendo bias nei risultati e impedendo di riflettere il vero valore dell‚Äôeffetto. In pratica, la presenza di variabili confondenti pu√≤ portare a conclusioni errate quando si confrontano semplicemente i risultati osservati in diversi gruppi. Ci√≤ che si osserva nei dati potrebbe non corrispondere a ci√≤ che accadrebbe se si potesse manipolare direttamente la variabile di interesse in un esperimento controllato.\nUn approccio apparentemente semplice per affrontare questo problema potrebbe essere quello di controllare statisticamente tutte le variabili confondenti. In questo metodo, si stima l‚Äôeffetto di X su Y separatamente in ogni segmento della popolazione definito da una condizione Z = z per ogni possibile valore di z. Successivamente, si calcola la media di questi effetti stimati nelle sottopopolazioni, ponderandoli per la probabilit√† di Z = z nella popolazione. Tuttavia, questo metodo presenta due difficolt√† fondamentali: richiede la conoscenza di tutte le possibili variabili confondenti e la capacit√† di misurare ciascuna di esse, cosa che spesso non √® praticabile.\nIl controllo delle variabili confondenti √® cruciale per stabilire relazioni causali, poich√© permette di isolare gli effetti delle variabili indipendenti da quelli delle variabili confondenti che potrebbero influenzare le variabili dipendenti. Esistono due principali metodologie di controllo:\n\nIl controllo sperimentale, implementato attraverso il disegno sperimentale e basato principalmente sulla randomizzazione.\nIl controllo statistico, applicato durante l‚Äôanalisi dei dati, con l‚Äôobiettivo di neutralizzare o quantificare l‚Äôinfluenza delle variabili estranee.\n\nA causa di queste difficolt√†, l‚Äôinferenza causale basata su dati osservazionali √® spesso considerata problematica, dando origine al famoso detto ‚Äúla correlazione non implica causalit√†‚Äù. Tuttavia, √® importante notare che in alcune circostanze, √® possibile fare inferenze causali anche a partire da dati osservazionali.\nL‚Äôobiettivo dell‚Äôanalisi causale moderna √® proprio quello di fornire gli strumenti concettuali e metodologici per affrontare queste sfide. Attraverso l‚Äôuso di tecniche avanzate come i modelli causali strutturali, i grafi aciclici diretti (DAG) e i metodi di identificazione degli effetti causali, i ricercatori possono spesso superare le limitazioni dei dati osservazionali e trarre conclusioni causali pi√π robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/06_causality.html#modelli-causali-strutturali",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.4 Modelli Causali Strutturali",
    "text": "18.4 Modelli Causali Strutturali\nI modelli causali sono strumenti essenziali per l‚Äôanalisi dei dati osservazionali, poich√© consentono di rappresentare il processo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Questi modelli non solo permettono di anticipare le conseguenze di una causa, ma offrono anche la possibilit√† di esplorare scenari controfattuali, immaginando esiti alternativi che si sarebbero potuti verificare in presenza di decisioni diverse.\nUn modello causale strutturale (Structural Causal Model, SCM) √® un approccio che rappresenta le relazioni causali tra variabili. Esso si basa su una serie di assegnazioni che, partendo da variabili di rumore indipendenti (note anche come variabili esogene), generano una distribuzione di probabilit√† congiunta.\nLe variabili di rumore indipendenti svolgono un ruolo cruciale negli SCM. Esse rappresentano fonti di incertezza o variabilit√† all‚Äôinterno del sistema e non sono influenzate da altre variabili del modello. Queste variabili sono mutuamente indipendenti, il che significa che il loro valore non fornisce informazioni sul valore delle altre.\nLa costruzione di un SCM segue una sequenza specifica: si parte dalle variabili di rumore indipendenti, si applicano una serie di assegnazioni che descrivono gli effetti causali delle variabili esogene su altre variabili, e si genera progressivamente un insieme di variabili casuali che d√† origine a una distribuzione congiunta.\nIl principale vantaggio di un SCM risiede nella sua duplice natura: da un lato, fornisce una distribuzione di probabilit√† congiunta delle variabili, e dall‚Äôaltro, descrive il processo generativo che porta alla formazione di tale distribuzione, partendo dalle variabili di rumore elementari.\nQuesta struttura consente non solo di modellare le relazioni probabilistiche tra le variabili, ma anche di rappresentare in modo esplicito i meccanismi causali che le governano.\nI SCM possono essere rappresentati graficamente attraverso Grafi Aciclici Direzionati (Directed Acyclic Graphs, DAG). Questi DAG visualizzano le relazioni causali tra le variabili all‚Äôinterno di un SCM, facilitando l‚Äôidentificazione delle variabili confondenti e il loro impatto sull‚Äôanalisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/06_causality.html#bias-da-variabile-omessa",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.5 Bias da Variabile Omessa",
    "text": "18.5 Bias da Variabile Omessa\nPossiamo introdurre i DAG facendo riferiento al bias da variabile omessa (Omitted Variable Bias, o OVB; Wilms et al. (2021)). Come discusso da Byrnes e Dee (2024), l‚Äôomissione dall‚Äôanalisi statistica di variabili confondenti note ma non misurate, o sconosciute e non misurate, pu√≤ portare a stime errate della magnitudine degli effetti, errori nel segno delle stime (stimatori distorti), correlazioni spurie, e al mascheramento delle vere relazioni causali.\nUn illustrazione di questa situazione √® fornita nella Figura¬†18.1. La figura mostra tre DAG che illustrano diversi scenari in cui le variabili non osservate non influenzano i risultati del modello o potrebbero creare problemi a causa della confusione. Una variabile di risposta di interesse (Y) √® causata sia da una variabile misurata (X) che da una variabile non misurata (U). Nel pannello di sinistra, la variabile non osservata (U) non √® una variabile confondente. Nel pannello centrale, la variabile non osservata (U) √® una variabile confondente e causa il bias da variabile omessa. Nel pannello di destra la variabile non osservata (U) causa il bias da variabile omessa in maniera indiretta.\n\n\n\n\n\n\nFigura¬†18.1: Nel pannello di sinistra, X e U sono non correlate, quindi la mancata inclusione di U in un modello statistico aumenterebbe l‚Äôerrore standard della stima (riducendo la precisione del modello) ma non porterebbe a bias nella stima dell‚Äôeffetto di X su Y. Tuttavia, se U influenza anche X come nel pannello centrale, o se U e X sono influenzati da un fattore comune Z come nel pannello di destra, allora omettere U da un modello statistico causa il bias da variabile omessa nella stima dell‚Äôeffetto di X su Y. I casi illustrati dal pannello centrale e dal pannello di destra sono esempi di sistemi in cui le cause comuni di confusione (U e Z rispettivamente) devono essere controllate per effettuare inferenze causali non distorte (la figura √® ispirata da Byrnes e Dee (2024)).\n\n\n\nAffrontare i problemi creati dalle variabili confondenti non misurate rappresenta una sfida primaria nell‚Äôinferenza causale dai dati osservazionali. A differenza dell‚Äôerrore di misurazione nelle variabili predittive, che produce un bias costante verso lo zero e pu√≤ essere corretto o modellato (McElreath 2020; Schennach 2016), con l‚ÄôOVB non possiamo conoscere la grandezza o la direzione del bias senza conoscere tutte le possibili variabili confondenti e le loro relazioni nel sistema.\nNonostante queste sfide, non √® necessario abbandonare l‚Äôuso dei dati osservazionali per l‚Äôinferenza causale in psicologia. √à invece necessario ricorrere all‚Äôadozione delle tecniche dei SCM per potere comunque svolgere l‚Äôinferenza causale.\n√à evidente che questo approccio porter√† a conclusioni inevitabilmente parziali, destinate ad essere perfezionate da studi successivi. Tuttavia, tale metodologia offre il vantaggio di esplicitare il ‚Äúmodello generativo dei dati‚Äù, ovvero la struttura causale sottostante ai fenomeni psicologici oggetto di studio.\nI progressi nella ricerca empirica conducono a una maggiore comprensione e, di conseguenza, a modifiche nelle ipotesi sui meccanismi causali. Questo processo rappresenta un‚Äôevoluzione della conoscenza scientifica. Tale sviluppo √® reso possibile proprio perch√© le ipotesi causali sono formulate in termini di modelli formali, che descrivono in modo preciso i meccanismi ipotizzati.\nAl contrario, limitarsi alla mera descrizione delle associazioni tra variabili non consente questo tipo di avanzamento conoscitivo. La formulazione di modelli causali espliciti permette infatti di testare, raffinare e, se necessario, rivedere le ipotesi sui meccanismi sottostanti ai fenomeni osservati, portando a una comprensione pi√π profonda e dinamica dei processi psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/06_causality.html#grafi-aciclici-diretti",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.6 Grafi Aciclici Diretti",
    "text": "18.6 Grafi Aciclici Diretti\nI DAG sono uno strumento fondamentale per l‚Äôinferenza causale, offrendo una rappresentazione visiva delle relazioni causali ipotizzate tra variabili. Questi grafi sono definiti ‚Äúdiretti‚Äù perch√© le variabili, rappresentate da nodi, sono collegate da frecce orientate anzich√© da semplici linee. Sono inoltre chiamati ‚Äúaciclici‚Äù poich√© non √® possibile tornare a un nodo di partenza seguendo il percorso delle frecce.\nIn un DAG, una freccia che va da X a Y indica un‚Äôinfluenza probabilistica di X su Y. La terminologia delle relazioni all‚Äôinterno del grafo √® importante: il nodo di origine di una freccia √® chiamato ‚Äúgenitore‚Äù, mentre il nodo di destinazione √® detto ‚Äúfiglio‚Äù. Quando √® possibile raggiungere un nodo B partendo da un nodo A seguendo una successione di frecce, A √® definito ‚Äúantenato‚Äù di B, e B √® considerato ‚Äúdiscendente‚Äù di A.\nI DAG consentono di distinguere chiaramente tra cause dirette e indirette. Una causa diretta √® rappresentata da un nodo genitore, mentre una causa indiretta pu√≤ essere qualsiasi antenato di un nodo nel grafo causale. Questa struttura permette di differenziare efficacemente causa ed effetto basandosi sulla posizione relativa dei nodi all‚Äôinterno del grafo, ovvero se un nodo √® antenato o discendente di un altro.\nQuesti grafi sono particolarmente utili per identificare variabili confondenti, basandosi sulla teoria sviluppata da Judea Pearl (Pearl 2009). √à cruciale rappresentare in un DAG tutte le possibili relazioni causali, poich√© l‚Äôassenza di una freccia tra due nodi implica la certezza dell‚Äôassenza di una relazione causale diretta tra le variabili corrispondenti.\nNella teoria dei DAG, due concetti fondamentali sono la d-separazione e il criterio del back-door.\n\nLa d-separazione\nLa d-separazione ci aiuta a determinare quando due variabili in un grafo causale sono indipendenti condizionatamente a un insieme di altre variabili. Questo concetto √® cruciale per comprendere come l‚Äôinformazione o l‚Äôinfluenza si propaga tra le variabili in un modello causale.\nIn termini pi√π semplici, la d-separazione ci permette di identificare se esiste un ‚Äúblocco‚Äù nel flusso di informazioni tra due variabili, dato un certo insieme di altre variabili (che chiameremo Œõ). Quando due variabili sono d-separate da Œõ, significa che non c‚Äô√® flusso di informazioni tra di loro, condizionatamente a Œõ.\nPer comprendere meglio la d-separazione, consideriamo tre situazioni principali che possono verificarsi in un DAG:\n\nCatena (X ‚Üí Z ‚Üí Y): In questo caso, Z √® un mediatore tra X e Y. Se Z appartiene all‚Äôinsieme Œõ (cio√®, se controlliamo o condizioniamo su Z), blocchiamo il flusso di informazioni da X a Y attraverso questo percorso. Per esempio, se X √® ‚Äúesercizio fisico‚Äù, Z √® ‚Äúpressione sanguigna‚Äù e Y √® ‚Äúrischio di malattie cardiache‚Äù, controllando per la pressione sanguigna (Z) blocchiamo il percorso attraverso il quale l‚Äôesercizio fisico influenza il rischio di malattie cardiache.\nFork (X ‚Üê Z ‚Üí Y): Qui, Z √® una causa comune sia di X che di Y. Se Z appartiene a Œõ, blocchiamo la correlazione spuria tra X e Y che deriva dalla loro causa comune. Per esempio, se Z √® ‚Äústatus socioeconomico‚Äù, X √® ‚Äúlivello di istruzione‚Äù e Y √® ‚Äústato di salute‚Äù, controllando per lo status socioeconomico (Z) eliminiamo la correlazione apparente tra istruzione e salute che potrebbe derivare dal fatto che entrambe sono influenzate dallo status socioeconomico.\nCollider (X ‚Üí Z ‚Üê Y): In questa situazione, Z √® un effetto comune di X e Y. Sorprendentemente, se n√© Z n√© i suoi discendenti appartengono a Œõ, il percorso √® gi√† bloccato. Controllare per Z (o i suoi discendenti) in realt√† aprirebbe un percorso tra X e Y, creando una correlazione spuria. Per esempio, se X √® ‚Äúintelligenza‚Äù, Y √® ‚Äúbellezza‚Äù e Z √® ‚Äúsuccesso in una carriera di attore‚Äù, controllare per il successo nella carriera di attore (Z) creerebbe una correlazione apparente tra intelligenza e bellezza, anche se queste potrebbero essere indipendenti nella popolazione generale.\n\nIn sintesi, la d-separazione ci permette di determinare, dato un certo insieme di variabili Œõ, se due variabili X e Y sono indipendenti condizionatamente a Œõ. Questo ci aiuta a identificare quali variabili dobbiamo controllare (e quali non dobbiamo controllare) per ottenere stime causali non distorte, facilitando cos√¨ l‚Äôinferenza causale corretta. La d-separazione √® quindi uno strumento potente che ci permette di leggere le indipendenze condizionali direttamente dal grafo, senza dover fare calcoli probabilistici complessi.\n\n\nIl criterio del back-door\nIl criterio del back-door consente di identificare un insieme di variabili che, se controllate adeguatamente, permettono di stimare gli effetti causali in modo non distorto. L‚Äôobiettivo principale di questo criterio √® eliminare l‚Äôinfluenza di percorsi non causali tra la variabile di esposizione (causa potenziale) e l‚Äôoutcome (effetto), mantenendo aperto solo il percorso causale diretto di interesse.\nIn questo contesto, due variabili sono considerate ‚Äúconfuse‚Äù se esiste tra di esse un percorso di tipo back-door. Un back-door path da X a Y √® definito come qualsiasi percorso che inizia da X con una freccia entrante in X. Per esempio, consideriamo il seguente percorso:\nX ‚Üê A ‚Üí B ‚Üê C ‚Üí Y\nIn questo caso, il percorso rappresenta un flusso di informazioni da X a Y che non √® causale, ma potrebbe creare l‚Äôapparenza di una relazione causale.\nPer ‚Äúdeconfondere‚Äù una coppia di variabili, √® necessario selezionare un insieme di variabili (chiamato back-door set) che ‚Äúblocchi‚Äù tutti i back-door paths tra i due nodi di interesse. Il blocco di questi percorsi avviene in modi diversi a seconda della struttura del percorso:\n\nUn back-door path che coinvolge una catena di variabili (ad esempio, A ‚Üí B ‚Üí C) pu√≤ essere bloccato controllando per la variabile intermedia (in questo caso, B).\nUn percorso che coinvolge un ‚Äúcollider‚Äù (una variabile che riceve frecce da entrambe le direzioni, come in A ‚Üí B ‚Üê C) √® naturalmente bloccato e non permette il flusso di informazioni.\n\n√à importante notare che bisogna prestare attenzione a non aprire involontariamente un flusso di informazioni attraverso un collider. Questo pu√≤ accadere se si condiziona l‚Äôanalisi sul collider stesso o su un suo discendente, il che potrebbe erroneamente aprire il percorso e introdurre bias nell‚Äôanalisi.\n\nPunti chiave:\n\nIl criterio del back-door aiuta a identificare il set minimale di variabili da controllare.\nNon tutte le variabili associate sia all‚Äôesposizione che all‚Äôoutcome devono essere controllate; solo quelle che creano percorsi back-door.\nIn alcuni casi, potrebbe non essere necessario controllare alcuna variabile (se non ci sono percorsi back-door aperti).\nIn altri casi, potrebbe essere impossibile bloccare tutti i percorsi back-door con le variabili disponibili, indicando che l‚Äôeffetto causale non pu√≤ essere identificato con i dati a disposizione.\n\nUtilizzando il criterio del back-door in combinazione con i DAG, i ricercatori possono fare scelte pi√π informate su quali variabili includere nelle loro analisi, migliorando cos√¨ la validit√† delle loro inferenze causali.\n\n\n\n18.6.1 Applicazioni\nConsideriamo nuovamente la struttura causale illustrata nella Figura¬†18.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, √® possibile identificare le potenziali fonti di bias da variabili omesse, inclusi i confondenti non misurati (ad esempio, U). Non controllare per le variabili confondenti apre una ‚Äúback-door‚Äù permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl 2009). In altre parole, omettere una variabile confondente come U nella Figura¬†18.1 (pannello centrale) in un‚Äôanalisi statistica significa che questa viene incorporata nel termine di errore del modello statistico, insieme alle fonti di errore casuali. La Figura¬†18.2 illustra le conseguenze di un confondente U che ha un effetto positivo su X ma un effetto negativo su Y. Se adattiamo un modello come mostrato nella Figura¬†18.2 bi, l‚Äôeffetto stimato di X su Y √® positivo quando si controlla per U. Tuttavia, se non si controlla per U, come mostrato nella Figura¬†18.2 bii, U viene incorporato nel termine di errore, inducendo una correlazione tra l‚Äôerrore e X, come illustrato nella Figura¬†18.2 biii, portando a una stima errata. Pertanto, il termine di errore del modello e X risultano correlati, il che viola un‚Äôassunzione fondamentale dei modelli lineari (ovvero, il teorema di Gauss-Markov; Abdallah et al., 2015; Antonakis et al., 2010). Questo produce una stima errata, evidenziata in blu.\n\n\n\n\n\n\nFigura¬†18.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l‚Äôinferenza causale. (A) mostra un DAG di un sistema in cui X ha un effetto positivo su Y, e una variabile confondente U ha un effetto positivo su Y ma un effetto negativo su X. Le variabili non osservate (cio√® non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un‚Äôanalisi del percorso. Vedi Box 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e X, che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e √® la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realt√†, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realt√† sta adattando il modello in (Biii), dove il termine di errore non √® solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ci√≤, c‚Äô√® un percorso diretto dal termine di errore del modello a X (e quindi X √® endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra X e Y dai rispettivi modelli. La linea rossa √® la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poich√© non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes e Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/06_causality.html#commenti-e-considerazioni-finali",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.7 Commenti e Considerazioni Finali",
    "text": "18.7 Commenti e Considerazioni Finali\nI diagrammi causali sono uno dei primi strumenti per identificare il bias da variabili omesse (Pearl 1995; Pearl, Glymour, e Jewell 2016). I diagrammi causali, sotto forma di DAG, visualizzano la nostra comprensione delle relazioni causali e delle variabili confondenti all‚Äôinterno di un sistema. In questo modo, i DAG chiariscono in modo trasparente le assunzioni dietro le affermazioni causali derivate dai dati e mostrano le potenziali fonti di bias derivanti da variabili confondenti.\n√à fondamentale che i DAG includano tutte le cause comuni di un predittore e della risposta di interesse, comprendendo tutte le variabili confondenti misurate e non misurate. Questo significa che l‚Äôinferenza causale √® possibile solo quando il ricercatore dispone di adeguate conoscenze del dominio.\nDopo aver costruito un DAG, √® possibile determinare le potenziali fonti di bias da variabili omesse, incluse quelle derivanti da variabili confondenti non misurate (es., U nella figura fig-byrnes-dee-1, pannello centrale). Non controllare le variabili confondenti apre una ‚Äúback-door‚Äù per la variazione confondente, permettendo a quest‚Äôultima di fluire tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl 2009).\nPertanto, un diagramma causale √® un primo passo fondamentale per identificare potenziali bias da variabili omesse. I DAG giustificano anche la scelta delle variabili di controllo, rendendo trasparenti le assunzioni che un ricercatore fa su come funziona il sistema oggetto di studio.\n√à importante notare che i DAG possono essere incorretti o non includere variabili confondenti sconosciute. Infatti, un DAG rappresenta solo la comprensione attuale e le assunzioni del ricercatore riguardo alle relazioni causali all‚Äôinterno di un sistema.\nUn sommario ironico di questi concetti √® fornito nella vignetta di xkcd.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_causality.html#esercizi",
    "href": "chapters/eda/06_causality.html#esercizi",
    "title": "18¬† Causalit√† dai dati osservazionali",
    "section": "18.8 Esercizi",
    "text": "18.8 Esercizi\n\nEsercizio 18.1 Consideriamo il seguente DAG dove A influenza B e D, B influenza C, e D influenza B.\n\n\n\n\n\n\n\n\n\nSe vogliamo stimare l‚Äôeffetto causale di A su C, quale delle seguenti affermazioni √® corretta riguardo alla d-separazione e al controllo delle variabili?\n\nControllare per B √® sufficiente e necessario per ottenere una stima non distorta dell‚Äôeffetto di A su C.\nControllare per D √® necessario per bloccare il back-door path tra A e C.\nNon √® necessario controllare per alcuna variabile, poich√© non ci sono confondenti tra A e C.\nControllare sia per B che per D √® necessario per ottenere una stima non distorta dell‚Äôeffetto di A su C.\nControllare per B potrebbe introdurre un bias, poich√© B √® un collider nel percorso A ‚Üí B ‚Üê D.\n\n\n\nEsercizio 18.2 Consideriamo il seguente DAG dove X √® la variabile di esposizione, Y √® l‚Äôoutcome, e Z e W sono altre variabili nel sistema.\n\n\n\n\n\n\n\n\n\nSe vogliamo stimare l‚Äôeffetto causale di X su Y utilizzando il criterio del back-door, quale delle seguenti affermazioni √® corretta?\n\nNon √® necessario controllare per alcuna variabile, poich√© non ci sono back-door paths tra X e Y.\n√à necessario controllare solo per Z per bloccare tutti i back-door paths tra X e Y.\n√à necessario controllare solo per W per bloccare tutti i back-door paths tra X e Y.\n√à necessario controllare sia per Z che per W per bloccare tutti i back-door paths tra X e Y.\nNon √® possibile stimare l‚Äôeffetto causale di X su Y in questo DAG utilizzando il criterio del back-door.\n\n\n\nEsercizio 18.3 Consideriamo il seguente DAG dove A e B influenzano C indipendentemente, e C influenza D.\n\n\n\n\n\n\n\n\n\nSupponiamo di voler studiare la relazione tra A e B. Quale delle seguenti affermazioni √® corretta riguardo a questo DAG e al concetto di collider?\n\nA e B sono indipendenti, ma diventano dipendenti se controlliamo per C.\nA e B sono dipendenti, ma diventano indipendenti se controlliamo per C.\nA e B sono sempre dipendenti, indipendentemente dal fatto che controlliamo o meno per C.\nA e B sono sempre indipendenti, indipendentemente dal fatto che controlliamo o meno per C o D.\nControllare per D √® necessario per rendere A e B indipendenti.\n\n\n\nEsercizio 18.4 Consideriamo il seguente DAG dove X √® la variabile di esposizione, Y √® l‚Äôoutcome, U √® una variabile non osservata, e Z √® una variabile osservata.\n\n\n\n\n\n\n\n\n\nQuale delle seguenti affermazioni √® corretta riguardo all‚Äôapplicazione del criterio del back-door per stimare l‚Äôeffetto causale di X su Y in questo DAG?\n\nNon √® possibile applicare il criterio del back-door perch√© U non √® osservata.\nControllare per Z √® sufficiente per bloccare tutti i back-door paths tra X e Y.\nControllare per Z non √® necessario perch√© non ci sono back-door paths tra X e Y.\n√à necessario controllare sia per U che per Z per ottenere una stima non distorta dell‚Äôeffetto causale di X su Y.\nControllare per Z potrebbe introdurre un bias nella stima dell‚Äôeffetto causale di X su Y.\n\n\n\nEsercizio 18.5 Considera le relazioni tra le variabili:\n\n\\(A \\sim \\mathcal{N}(0, 1)\\).\n\\(M = A + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\),\n\\(B = M + \\epsilon_2\\), dove \\(\\epsilon_2 \\sim \\mathcal{N}(0, 1)\\).\n\n\nIdentifica la struttura causale risultante.\nCrea una simulazione in Python con le precedenti relazioni tra variabili (con \\(n\\) = 10,000) e crea un diagramma a dispersione per A e B.\nCalcola la correlazione tra A e B.\n\n\n\nEsercizio 18.6 Considera le seguenti relazioni tra le variabili:\n\n\\(C \\sim \\mathcal{N}(0, 1)\\),\n\\(A = C + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\),\n\\(B = C + \\epsilon_2\\), dove \\(\\epsilon_2 \\sim \\mathcal{N}(0, 1)\\).\n\n\nIdentifica la struttura causale risultante.\nCrea una simulazione in Python con le precedenti relazioni tra variabili (con \\(n\\) = 10,000) e crea un diagramma a dispersione per A e B.\nCalcola la correlazione tra A e B.\n\n\n\nEsercizio 18.7 Consideriamo la struttura causale del confondimento, in cui una variabile \\(C\\) influenza entrambe le variabili \\(A\\) e \\(B\\):\n\n\\(C \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(C\\) √® distribuita secondo una normale standard),\n\\(A = C + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(A\\) √® una funzione di \\(C\\) con un termine di errore additivo),\n\\(B = C + \\epsilon_2\\), dove \\(\\epsilon_2 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(B\\) √® una funzione di \\(C\\) con un altro termine di errore additivo).\n\nIn questa simulazione Python, si genericno 10,000 osservazioni secondo le relazioni sopra descritte. Successivamente, si calcolino i residui della regressione di \\(A\\) su \\(C\\) e di \\(B\\) su \\(C\\). Questi residui rappresentano le componenti di \\(A\\) e \\(B\\) indipendenti linearmente da \\(C\\). Infine, calcoli la correlazione tra i residui di \\(A\\) e \\(B\\), ovvero la correlazione tra \\(A\\) e \\(B\\) dopo aver controllato l‚Äôeffetto di \\(C\\). Si interpretino i risultati.\n\n\nEsercizio 18.8 Consideriamo la struttura causale della mediazione, in cui una variabile \\(A\\) influenza una variabile \\(M\\), che a sua volta influenza una variabile \\(B\\):\n\n\\(A \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(A\\) √® distribuita secondo una normale standard),\n\\(M = A + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(M\\) √® una funzione di \\(A\\) con un termine di errore additivo),\n\\(B = M + \\epsilon_2\\), dove \\(\\epsilon_2 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(B\\) √® una funzione di \\(M\\) con un altro termine di errore additivo).\n\nIn questa simulazione Python, genera 10.000 osservazioni secondo le relazioni sopra descritte. Successivamente, calcola i residui della regressione di \\(M\\) su \\(A\\) e di \\(B\\) su \\(M\\). Questi residui rappresentano le componenti di \\(M\\) e \\(B\\) indipendenti linearmente da \\(A\\) e \\(M\\), rispettivamente. Infine, calcoleremo la correlazione tra \\(A\\) e i residui di \\(B\\), ovvero la correlazione tra \\(A\\) e \\(B\\) dopo aver controllato per l‚Äôeffetto della mediazione attraverso \\(M\\).\n\n\nEsercizio 18.9 Consideriamo ora la struttura causale di un collider, in cui due variabili indipendenti \\(A\\) e \\(B\\) influenzano entrambe una variabile \\(M\\). In questa configurazione, \\(M\\) √® il collider. Un aspetto fondamentale di questa struttura √® che il controllo su \\(M\\) (il collider) pu√≤ indurre una correlazione spuria tra \\(A\\) e \\(B\\), anche se \\(A\\) e \\(B\\) non sono direttamente correlati.\nLe relazioni causali sono le seguenti:\n\n\\(A \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(A\\) √® distribuita secondo una normale standard),\n\\(B \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(B\\) √® distribuita secondo una normale standard),\n\\(C = A + B + \\epsilon_1\\), dove \\(\\epsilon_1 \\sim \\mathcal{N}(0, 1)\\) (cio√®, \\(C\\) √® una funzione di \\(A\\) e \\(B\\) con un termine di errore additivo).\n\nIn questa simulazione Python, genera 10,000 osservazioni secondo le relazioni sopra descritte. Successivamente, calcola i residui della regressione di \\(C\\) su \\(A\\) e \\(B\\). Infine, calcola la correlazione tra \\(A\\) e \\(B\\) dopo aver controllato per \\(C\\).\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, Jarrett EK, e Laura E Dee. 2024. ¬´Causal inference with observational data and unobserved confounding variables¬ª. bioRxiv, 2024‚Äì02.\n\n\nHardt, Moritz, e Benjamin Recht. 2022. Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton, NJ: Princeton University Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nPearl, Judea. 1995. ¬´Causal diagrams for empirical research¬ª. Biometrika 82 (4): 669‚Äì88.\n\n\n‚Äî‚Äî‚Äî. 2009. Causality. Cambridge University Press.\n\n\nPearl, Judea, Madelyn Glymour, e Nicholas P. Jewell. 2016. Causal inference in statistics: A primer. John Wiley & Sons.\n\n\nRiederer, Emily. 2021. ¬´Causal design patterns for data analysts¬ª, gennaio. https://emilyriederer.netlify.app/post/causal-design-patterns/.\n\n\nSchennach, Susanne M. 2016. ¬´Recent advances in the measurement error literature¬ª. Annual Review of Economics 8 (1): 341‚Äì77.\n\n\nWilms, Rafael, E M√§thner, Lothar Winnen, e Ralf Lanwehr. 2021. ¬´Omitted variable bias: A threat to estimating causal relationships¬ª. Methods in Psychology 5: 100075.\n\n\nZwet, Erik van, Andrew Gelman, Sander Greenland, Guido Imbens, Simon Schwab, e Steven N Goodman. 2023. ¬´A New Look at P Values for Randomized Clinical Trials¬ª. NEJM Evidence 3 (1): EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Causalit√† dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Introduzione",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilit√†, una componente essenziale per la ricerca scientifica. Nell‚Äôambito della scienza, l‚Äôinferenza induttiva √® di fondamentale importanza, e la probabilit√† svolge un ruolo cruciale in questo processo. Sebbene non possiamo ottenere una certezza assoluta riguardo alla veridicit√† di un‚Äôipotesi o teoria, possiamo assegnare loro un grado di certezza probabilistica. L‚Äôapproccio bayesiano utilizza la probabilit√† per quantificare il grado di fiducia che possiamo attribuire a una determinata proposizione.\nL‚Äôinferenza statistica bayesiana mira a quantificare la fiducia nell‚Äôipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(O\\). Per affrontare adeguatamente l‚Äôinferenza statistica bayesiana, √® quindi essenziale avere una solida comprensione della teoria delle probabilit√†, almeno nei suoi concetti fondamentali.\nIn questa sezione esamineremo le definizioni di probabilit√†, la probabilit√† condizionale e il teorema di Bayes. Approfondiremo inoltre le propriet√† delle variabili casuali e le principali distribuzioni di massa e densit√† di probabilit√†. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell‚Äôinferenza bayesiana sia nell‚Äôinferenza frequentista.",
    "crumbs": [
      "Probabilit√†",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "19¬† Interpretazione della probabilit√†",
    "section": "",
    "text": "Introduzione\nNel corso di questo capitolo, esploreremo varie concezioni della probabilit√†, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con Python per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell‚Äôambito della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#storia-e-definizioni-della-probabilit√†",
    "href": "chapters/probability/01_intro_prob.html#storia-e-definizioni-della-probabilit√†",
    "title": "19¬† Interpretazione della probabilit√†",
    "section": "19.1 Storia e definizioni della probabilit√†",
    "text": "19.1 Storia e definizioni della probabilit√†\nLa probabilit√† √® un modo formale di quantificare l‚Äôincertezza, assegnando plausibilit√† o credibilit√† a un insieme di possibilit√† mutuamente esclusive o risultati di un esperimento o osservazione.\n\n19.1.1 Che cos‚Äô√® la probabilit√†?\nCi sono due modi principali per interpretare la probabilit√†:\n\nFrequentista: Secondo il framework frequentista, la probabilit√† rappresenta il limite della frequenza relativa con cui un evento di interesse si verifica quando il numero di esperimenti condotti ripetutamente nelle stesse condizioni tende all‚Äôinfinito. In questa visione, chiamata ‚Äúontologica‚Äù, la probabilit√† √® considerata una propriet√† intrinseca del mondo, indipendente dalla nostra esperienza. La probabilit√† √® quindi vista come una caratteristica oggettiva della realt√†.\nBayesiana: Al contrario, il framework bayesiano interpreta la probabilit√† come una credenza soggettiva riguardo alla probabilit√† di accadimento di un evento. In questa prospettiva ‚Äúepistemica‚Äù, la probabilit√† √® una misura della nostra conoscenza del mondo piuttosto che una propriet√† oggettiva. Questa visione soggettiva della probabilit√† dipende dalle informazioni disponibili e dal punto di vista dell‚Äôosservatore.\n\n\n\n19.1.2 Storia della probabilit√†\nLa storia della probabilit√† √® lunga e complessa, come illustrato in varie opere (Tabak 2004, Stigler 1986, Weisberg 2014). L‚Äôorigine della probabilit√† moderna risale a una domanda posta da Antoine Gombaud (Chevalier de M√©r√©) a Blaise Pascal (1623‚Äì1662) su come dividere equamente le puntate di un gioco di carte interrotto.\n\n19.1.2.1 Problema dei punti\nIl problema pu√≤ essere formulato cos√¨:\n\nImmaginiamo due persone che partecipano a un gioco a pi√π round. In ogni round, entrambe le persone hanno la stessa probabilit√† di vincere. La prima persona che vince sei round consecutivi si aggiudicher√† un ricco premio in denaro. Supponiamo che A e B abbiano gi√† disputato sei round, con A che ha vinto cinque volte e B una volta. In quel momento, il gioco √® interrotto. Poich√© n√© A n√© B hanno raggiunto le sei vittorie, hanno deciso di dividere il premio. Ma qual √® il modo pi√π equo per farlo?\n\nLa discussione tra Pierre de Fermat (1607‚Äì1665) e Pascal ha portato alla formalizzazione dell‚Äôutilizzo della matematica per risolvere questo problema, proponendo di considerare le probabilit√† di vincita di ciascun giocatore. Ad esempio, se A ha una probabilit√† del 97% di vincere il premio e B ha una probabilit√† del 3%, sembrerebbe equo assegnare ad A il 97% del premio. L‚Äôinteresse pubblico per la loro corrispondenza √® sopravvissuto grazie al libro di Christian Huygens del 1657 ‚ÄúDe Ratiociniis in Ludo Aleae‚Äù (Sul Ragionamento nei Giochi di Dadi), che √® rimasto il riferimento per la probabilit√† per circa 50 anni.\n\n\n19.1.2.2 Sviluppi successivi\nIl libro postumo di Jacob Bernoulli, ‚ÄúL‚ÄôArte della Congettura‚Äù (1713), ha segnato una svolta nella storia della probabilit√†. Bernoulli ha definito la probabilit√† come un indice di incertezza compreso tra 0 e 1 e ha collegato il calcolo della probabilit√† ai dati e alla frequenza a lungo termine di un evento, noto come legge dei grandi numeri. Bernoulli ha applicato la probabilit√† anche a settori diversi dal gioco d‚Äôazzardo, come la mortalit√† umana e la giustizia penale, creando la cosiddetta ‚Äúprobabilit√† soggettiva‚Äù.\n\n\n\n19.1.3 Interpretazione ‚Äúclassica‚Äù\nStoricamente, la prima definizione di probabilit√† √® stata proposta da Pierre-Simon Laplace (1749-1827), che si √® avvalso del calcolo combinatorio. Secondo Laplace, la probabilit√†\\(P\\)di un evento √® definita come il rapporto tra il numero di casi in cui l‚Äôevento si verifica e il numero totale di casi possibili. In questa definizione, un evento √® qualcosa a cui √® possibile assegnare un valore di verit√†, ovvero qualcosa che pu√≤ essere vero o falso. Ad esempio, la probabilit√† di ottenere un 3 in un lancio di un singolo dado √® 1/6 ‚âÉ 0.17, poich√© c‚Äô√® un solo caso favorevole (il lancio ha prodotto un 3) su sei casi possibili (i numeri da 1 a 6). Tuttavia, questa definizione √® insoddisfacente in quanto si basa sull‚Äôassunzione che ogni evento sia equiprobabile, il che non √® sempre vero. Inoltre, questa definizione √® circolare poich√© per definire il concetto di probabilit√†, √® necessario prima definire cosa significa che gli eventi siano equiprobabili, e quindi si deve gi√† conoscere il concetto di probabilit√†.\n\n\n19.1.4 Interpretazione frequentista\nUn secondo tentativo di definire la probabilit√† (dopo quello ‚Äúclassico‚Äù di Laplace) si basa sull‚Äôapproccio frequentista, che pu√≤ essere attribuito a molti autori. In questo approccio, la probabilit√† √® definita sulla base delle frequenze osservate dell‚Äôoccorrenza di un evento. Questo approccio nasce dalla difficolt√† di assegnare una probabilit√† agli eventi assumendo il principio di equiprobabilit√†, come nel caso delle monete, dei dadi o delle carte di un mazzo. Sebbene la probabilit√† di ottenere testa come risultato del lancio di un dado sia 1/2 se crediamo che la moneta sia bilanciata, se cos√¨ non fosse non potremmo assegnare la stessa probabilit√† a tutti i risultati possibili. Tuttavia, possiamo stimare le probabilit√† come la frequenza\\(f_t\\), definita come il rapporto tra il numero di volte in cui un lancio ha prodotto ‚Äútesta‚Äù e il numero totale di lanci.\nSi osservi che l‚Äôosservazione della frequenza \\(f_t\\) √® solo un‚Äô approssimazione della probabilit√†, ma l‚Äôaccuratezza migliora all‚Äôaumentare del numero totale di lanci, \\(N\\). In linea di principio, la probabilit√† di ottenere ‚Äútesta‚Äù, \\(P(T)\\), √® il limite della frequenza \\(f_t\\) quando il numero totale di lanci \\(N\\) tende all‚Äôinfinito. Tuttavia, questa definizione richiede l‚Äôinfinita ripetizione di un esperimento, il che pu√≤ essere impraticabile o impossibile in molti casi. Inoltre, questa definizione assume che gli eventi futuri siano simili agli eventi passati, il che non √® sempre garantito.\n\ndef coin_flips(n, run_label):\n    # Genera un array di 0 e 1 dove 1 rappresenta 'testa' e 0 'croce'\n    # usando una distribuzione binomiale.\n    heads = np.random.binomial(1, 0.5, n)\n    \n    # Calcola la proporzione cumulativa di teste.\n    flips = np.arange(1, n + 1) \n    proportion_heads = np.cumsum(heads) / flips\n    \n    # Crea un DataFrame per un facile accesso e visualizzazione dei dati.\n    df = pd.DataFrame({'flips': flips, 'proportion_heads': proportion_heads, 'run': run_label})\n\n    return df\n\nn = 1000\n\ndf = pd.concat([coin_flips(n, f'run{i+1}') for i in range(4)], axis=0)\nax = sns.lineplot(data = df, x = 'flips', y = 'proportion_heads', hue = 'run')\n\n\n\n\n\n\n\n\n\n\n19.1.5 La Legge dei Grandi Numeri\nLa simulazione precedente fornisce un esempio della Legge dei grandi numeri. La Legge dei Grandi Numeri afferma che, man mano che il numero di esperimenti casuali ripetuti aumenta, la stima della probabilit√† di un evento \\(P(Y=y)\\) diventa sempre pi√π accurata.\nIl teorema sostiene che, con l‚Äôaumento del numero di ripetizioni di un esperimento casuale, la media dei risultati osservati tende a convergere al valore atteso teorico della variabile casuale. In altre parole, la media empirica dei risultati osservati si avvicina sempre di pi√π al valore medio teorico.\nQuesta legge √® cruciale perch√© garantisce che, con un numero sufficientemente grande di prove, la stima empirica della probabilit√† di un evento si avvicina al valore reale. Questo rende le stime probabilistiche pi√π precise e affidabili.\nDal punto di vista pratico, la Legge dei Grandi Numeri consente di utilizzare modelli probabilistici per interpretare fenomeni reali. Anche se le osservazioni singole possono variare in modo casuale, la media delle osservazioni su un ampio numero di ripetizioni rifletter√† fedelmente le probabilit√† teoriche.\nFormalmente, data una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), ciascuna con media \\(\\mu\\), la Legge dei Grandi Numeri √® espressa come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{X_1 + X_2 + \\ldots + X_n}{n} - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) √® un valore positivo arbitrariamente piccolo e \\(P(\\cdot)\\) indica la probabilit√†. Questo significa che, con un numero molto grande di ripetizioni, la media campionaria osservata sar√† vicina alla media teorica attesa, permettendo inferenze affidabili sulla probabilit√† degli eventi.\nIn sintesi, la Legge dei Grandi Numeri assicura che, aumentando il numero di prove, le stime empiriche delle probabilit√† diventano sempre pi√π precise, allineandosi con i valori teorici attesi.\n\n19.1.5.1 Problema del caso singolo\nNell‚Äôambito dell‚Äôapproccio frequentista alla probabilit√†, basato sulla concezione delle frequenze relative di eventi osservati su lunghe serie di ripetizioni, emerge un limite concettuale nel trattare la probabilit√† di eventi singolari e non ripetibili. Secondo questa prospettiva, infatti, non risulta rigorosamente appropriato discutere di probabilit√† relative a eventi unici e non replicabili nel tempo. Esempi emblematici di tali eventi includono la possibilit√† che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023 o che si verifichi pioggia a Firenze il giorno di Ferragosto del 2024. Questi scenari, essendo unici e circoscritti a un preciso momento storico, sfuggono alla logica frequentista che richiede, per definizione, la possibilit√† di osservazione ripetuta degli eventi per valutarne la probabilit√†. Nonostante ci√≤, nel linguaggio comune non specialistico, √® comune l‚Äôuso del termine ‚Äúprobabilit√†‚Äù per riferirsi anche a tali eventi specifici e non ripetibili, evidenziando cos√¨ una discrepanza tra l‚Äôuso tecnico e quello colloquiale del concetto di probabilit√†.\n\n\n\n19.1.6 Collegamento tra probabilit√† e statistica\nDurante gli anni ‚Äô20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l‚Äôinferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significativit√†, i metodi di campionamento, l‚Äôanalisi della varianza e il disegno sperimentale.\nNegli anni ‚Äô30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull‚Äôinterpretazione frequentista della probabilit√†. Definirono due tipologie di errori decisionali e utilizzarono il test di significativit√† di Fisher, interpretando i valori\\(p\\)come indicatori dei tassi di errore a lungo termine.\n\n\n19.1.7 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della ‚Äúprobabilit√† inversa‚Äù (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l‚Äôinferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell‚Äôutilizzo dell‚Äôinferenza basata sul metodo della probabilit√† inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato ‚ÄúTheory of Probability‚Äù rappresent√≤ una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ‚Äô80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell‚Äôapproccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n\n19.1.8 Interpretazione soggettivista\nUna visione alternativa della probabilit√† la considera come una credenza soggettiva. Finetti (1970) ha proposto un‚Äôinterpretazione in cui la probabilit√† non √® vista come una caratteristica oggettiva degli eventi, ma piuttosto come una misura della credenza soggettiva, suggerendo di trattare \\(p(¬∑)\\) come una probabilit√† soggettiva. √à interessante notare che de Finetti era un soggettivista radicale. Infatti, la frase di apertura del suo trattato in due volumi sulla probabilit√† afferma che ‚ÄúLa probabilit√† non esiste‚Äù, intendendo che la probabilit√† non ha uno status oggettivo, ma rappresenta piuttosto la quantificazione della nostra esperienza di incertezza. Riteneva che l‚Äôidea di una probabilit√† esterna all‚Äôindividuo, con uno status oggettivo, fosse pura superstizione, paragonabile al credere in ‚ÄúEtere cosmico, Spazio e Tempo assoluti, ‚Ä¶, o Fate e Streghe‚Ä¶‚Äù. Secondo de Finetti, ‚Äú‚Ä¶ esistono solo probabilit√† soggettive - cio√®, il grado di credenza nell‚Äôoccorrenza di un evento attribuito da una determinata persona in un dato momento con un dato insieme di informazioni.‚Äù\nCome sottolineato da Press (2009), la prima menzione della probabilit√† come grado di credenza soggettiva fu fatta da Ramsey (1926), ed √® questa nozione di probabilit√† come credenza soggettiva che ha portato a una notevole resistenza alle idee bayesiane. Una trattazione dettagliata degli assiomi della probabilit√† soggettiva si trova in Fishburn (1986).\nLa denominazione ‚Äúsoggettivo‚Äù legata alla probabilit√† potrebbe risultare infelice, poich√© potrebbe suggerire un ragionamento vago o non scientifico. Lindley (2013) condivide queste riserve, proponendo l‚Äôalternativa ‚Äúprobabilit√† personale‚Äù rispetto a ‚Äúprobabilit√† soggettiva‚Äù. Analogamente, Howson e Urbach (2006) preferiscono utilizzare l‚Äôespressione ‚Äúprobabilit√† epistemica‚Äù, che riflette il grado di incertezza di un individuo di fronte al problema trattato. In sostanza, la probabilit√† epistemica si riferisce all‚Äôincertezza personale riguardo a variabili sconosciute. Questa terminologia viene adottata anche nel testo di Kaplan (2023), fornendo un linguaggio pi√π neutro per discutere di questi concetti.\nVa inoltre notato che l‚Äôinterpretazione soggettiva si adatta bene a eventi singoli, permettendo di esprimere una convinzione su eventi specifici, come la probabilit√† di pioggia in un dato giorno o l‚Äôesito di una competizione sportiva.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli‚Äôs Fallacy (Clayton 2021) offre un‚Äôintroduzione molto leggibile alle tematiche della definizione della probabilit√† nella storia della scienza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "title": "19¬† Interpretazione della probabilit√†",
    "section": "19.2 Commenti e Considerazioni Finali",
    "text": "19.2 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato il significato filosofico della nozione di probabilit√† e introdotto la simulazione come metodo per approssimare le probabilit√† empiriche quando non √® possibile ottenere soluzioni analitiche.\nNel prossimo capitolo, esamineremo la probabilit√† dal punto di vista matematico.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "19¬† Interpretazione della probabilit√†",
    "section": "19.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "19.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.14.0\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nClayton, Aubrey. 2021. Bernoulli‚Äôs Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFinetti, Bruno de. 1970. Teoria delle probabilit√†. Torino: G. Einaudi.\n\n\nFishburn, Peter C. 1986. ¬´The axioms of subjective probability¬ª. Statistical Science 1 (3): 335‚Äì45.\n\n\nHowson, Colin, e Peter Urbach. 2006. Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, David. 2023. Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, Dennis V. 2013. Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S James. 2009. Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, Frank P. 1926. ¬´Truth and probability¬ª. In Readings in Formal Epistemology: Sourcebook, 21‚Äì45. Springer.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Interpretazione della probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html",
    "href": "chapters/probability/02_prob_spaces.html",
    "title": "20¬† Misura di Probabilit√†",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#introduzione",
    "href": "chapters/probability/02_prob_spaces.html#introduzione",
    "title": "20¬† Misura di Probabilit√†",
    "section": "",
    "text": "20.0.1 Introduzione alle Probabilit√†: Origine e Definizione\nDa dove derivano matematicamente i numeri che chiamiamo ‚Äúprobabilit√†‚Äù? Per rispondere, ci riferiamo alla trattazione di Michael Betancourt, che chiarisce il concetto di distribuzione di probabilit√†. Questo capitolo offre una versione semplificata del suo lavoro, mantenendo la notazione e le figure originali.\nBetancourt afferma che i principi della teoria della probabilit√† sono semplici; le difficolt√† matematiche emergono principalmente nell‚Äôapplicazione a insiemi complessi come i numeri reali. Per semplificare, Betancourt introduce i fondamenti della teoria della probabilit√† utilizzando uno spazio campionario composto da un numero finito di elementi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "href": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "title": "20¬† Misura di Probabilit√†",
    "section": "20.1 Insiemi Finiti",
    "text": "20.1 Insiemi Finiti\nUn insieme finito √® costituito da un numero finito di elementi distinti, \\[\nX = \\{x_1, ..., x_N\\}.\n\\] Qui, l‚Äôindice numerico serve a distinguere gli \\(N\\) elementi individuali, senza implicare necessariamente un ordine particolare tra di essi. Per evitare qualsiasi presunzione di ordine, Betancourt utilizza un insieme di cinque elementi come esempio: \\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\n\n\n\n\n\n\nFigura¬†20.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni pratiche della teoria della probabilit√†, gli elementi astratti \\(x_{n}\\) rappresentano oggetti concreti e significativi. Tuttavia, in questo capitolo, ci si concentrer√† esclusivamente sui concetti matematici, evitando qualsiasi interpretazione particolare. Quando \\(X\\) √® inteso a rappresentare tutti gli oggetti di interesse in una data applicazione, viene denominato spazio campionario.\nUna volta definito lo spazio campionario, possiamo organizzare e manipolare i suoi elementi in vari modi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "title": "20¬† Misura di Probabilit√†",
    "section": "20.2 Sottoinsiemi",
    "text": "20.2 Sottoinsiemi\nUn sottoinsieme di \\(X\\) √® qualsiasi collezione di elementi in \\(X\\). Per evitare ambiguit√†, user√≤ esclusivamente lettere romane minuscole \\(x\\) per indicare un elemento variabile nello spazio campionario \\(X\\) e lettere minuscole sans serif \\(\\mathsf{x}\\) per indicare un sottoinsieme variabile.\nAd esempio, \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) √® un sottoinsieme di \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\). Importante notare che nel concetto di sottoinsieme non esiste la nozione di molteplicit√†, solo di appartenenza: un sottoinsieme pu√≤ includere un elemento \\(x_{n}\\) ma non pu√≤ includerlo pi√π volte.\n\n\n\n\n\n\nFigura¬†20.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) √® qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in $X = {, , , , }.\n\n\n\nSe \\(\\mathsf{x}\\) √® un sottoinsieme dello spazio campionario \\(X\\) allora scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) potrebbe contenere tutti gli elementi di \\(X\\), nel qual caso \\(\\mathsf{x} = X\\), allora scriviamo \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente da quanti elementi un insieme finito \\(X\\) contiene, possiamo sempre costruire tre tipi speciali di sottoinsiemi. L‚Äôinsieme vuoto \\(\\emptyset = \\{\\}\\) non contiene alcun elemento. D‚Äôaltra parte, l‚Äôintero insieme stesso pu√≤ essere considerato un sottoinsieme contenente tutti gli elementi. Un sottoinsieme contenente un singolo elemento √® denotato \\(\\{ x_{n} \\}\\) e chiamato insieme atomico.\nCi sono \\[\n{N \\choose n} = \\frac{ N! }{ n! (N - n)!}\n\\] modi per selezionare \\(n\\) elementi da un insieme finito di \\(N\\) elementi totali, e quindi \\({N \\choose n}\\) sottoinsiemi totali di dimensione \\(n\\). Ad esempio, esiste un solo sottoinsieme che non contiene elementi, \\[\n{N \\choose 0} = \\frac{ N! }{ 0! (N - 0)!} = \\frac{ N! }{ N! } = 1,\n\\] che √® solo l‚Äôinsieme vuoto. Allo stesso modo, esiste un solo sottoinsieme che contiene tutti gli elementi, \\[\n{N \\choose N} = \\frac{ N! }{ N! (N - N)!} = \\frac{ N! }{ N! } = 1,\n\\] che √® solo l‚Äôinsieme completo stesso. D‚Äôaltra parte, ci sono \\[\n{N \\choose 1} = \\frac{ N! }{ 1! (N - 1)!} = N\n\\] insiemi atomici distinti che contengono un solo elemento, uno per ciascun elemento in \\(X\\).\nContando tutti i sottoinsiemi di tutte le dimensioni possibili si ottiene \\[\n\\sum_{n = 0}^{N} {N \\choose n} = 2^{N}\n\\] sottoinsiemi possibili che possiamo costruire da un insieme finito con \\(N\\) elementi.\nLa collezione di tutti i sottoinsiemi √® essa stessa un insieme finito con \\(2^{N}\\) elementi. Chiamiamo questo insieme insieme potenza di \\(X\\) e lo denotiamo \\(2^{X}\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "20¬† Misura di Probabilit√†",
    "section": "20.3 Operazioni sui Sottoinsiemi",
    "text": "20.3 Operazioni sui Sottoinsiemi\nPossiamo sempre costruire sottoinsiemi elemento per elemento, ma possiamo anche costruirli manipolando sottoinsiemi esistenti.\nAd esempio, dato un sottoinsieme \\(\\mathsf{x} \\subset X\\) possiamo costruire il suo complemento raccogliendo tutti gli elementi in \\(X\\) che non sono gi√† in \\(\\mathsf{x}\\). L‚Äôinsieme atomico \\(\\mathsf{x} = \\{ \\diamondsuit \\}\\) contiene l‚Äôunico elemento \\(\\diamondsuit\\) e il suo complemento contiene i rimanenti elementi \\[\n\\mathsf{x}^{c} = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\] Per costruzione, il complemento dell‚Äôinsieme vuoto √® l‚Äôintero insieme, \\(\\emptyset^{c} = X\\), e il complemento dell‚Äôinsieme completo √® l‚Äôinsieme vuoto, \\(X^{c} = \\emptyset\\).\n\n\n\n\n\n\nFigura¬†20.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) √® il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi nello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\nAd esempio, applicando l‚Äôoperatore di complemento al sottoinsieme \\(\\mathsf{x} = \\{ \\clubsuit, \\spadesuit \\}\\) otteniamo \\[\n\\mathsf{x}^{c}\n= \\{ \\clubsuit, \\spadesuit \\}^{c}\n= \\{ \\Box, \\diamondsuit, \\heartsuit \\}.\n\\]\nPossiamo anche costruire sottoinsiemi da pi√π di un sottoinsieme. Consideriamo, ad esempio, due sottoinsiemi \\(\\mathsf{x}_1 = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_2 = \\{ \\Box, \\spadesuit \\}\\). La collezione di tutti gli elementi che sono contenuti in uno qualsiasi dei due sottoinsiemi √® essa stessa un sottoinsieme, \\[\n\\{ \\Box, \\heartsuit, \\spadesuit \\} \\subset X,\n\\] cos√¨ come la collezione di tutti gli elementi che sono contenuti in entrambi i sottoinsiemi, \\[\n\\{ \\Box \\} \\subset X.\n\\] Questi sottoinsiemi derivati sono chiamati rispettivamente unione, \\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box, \\heartsuit, \\spadesuit \\},\n\\] e intersezione, \\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cap \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box \\}.\n\\]\n\n\n\n\n\n\nFigura¬†20.4: Possiamo manipolare due sottoinsiemi in vari modi per ottenere un nuovo sottoinsieme.\n\n\n\n\n\n\n\n\n\nFigura¬†20.5: L‚Äôunione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2\\), √® un sottoinsieme contenente tutti gli elementi di entrambi i sottoinsiemi in input. D‚Äôaltra parte, l‚Äôintersezione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2\\), √® un sottoinsieme contenente solo gli elementi che compaiono in entrambi i sottoinsiemi in input.\n\n\n\nDue sottoinsiemi sono disgiunti se non condividono alcun elemento; in questo caso la loro intersezione √® l‚Äôinsieme vuoto, \\[\n\\mathsf{x}_{1} \\cap \\mathsf{x}_{2} = \\emptyset.\n\\] L‚Äôunione e l‚Äôintersezione di un sottoinsieme con se stesso restituiscono quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\] Poich√© l‚Äôinsieme vuoto non contiene alcun elemento, la sua unione con qualsiasi sottoinsieme restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\] e la sua intersezione con qualsiasi sottoinsieme restituisce l‚Äôinsieme vuoto, \\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\] Allo stesso modo, l‚Äôunione di un sottoinsieme con l‚Äôinsieme completo restituisce l‚Äôinsieme completo, \\[\n\\mathsf{x} \\cup X = X \\cup \\mathsf{x} = X,\n\\] e l‚Äôintersezione di un sottoinsieme con l‚Äôinsieme completo restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cap X = X \\cap \\mathsf{x} = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sugli-elementi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sugli-elementi",
    "title": "20¬† Misura di Probabilit√†",
    "section": "20.4 Misura e Probabilit√† sugli Elementi",
    "text": "20.4 Misura e Probabilit√† sugli Elementi\nDa un punto di vista matematico, la teoria della misura riguarda l‚Äôallocazione coerente di una qualche quantit√† astratta attraverso lo spazio campionario. Consideriamo un serbatoio (il termine standard in questo contesto sarebbe ‚Äúmisura totale‚Äù o ‚Äúmassa totale‚Äù) di una qualche quantit√† positiva, continua e conservata, \\(M \\in [0, \\infty]\\). Poich√© \\(M\\) √® conservato, qualsiasi quantit√† \\(m_{n}\\) che viene allocata all‚Äôelemento \\(x_{n} \\in X\\) deve essere detratta dal serbatoio, lasciando meno da allocare agli altri elementi.\nUn caso particolare si verifica quando il contenuto totale del serbatoio \\(M\\) √® infinito. In questo scenario, possiamo allocare una quantit√† infinita dal serbatoio pur avendo ancora una quantit√† infinita rimanente. Allo stesso tempo, allocare una quantit√† infinita pu√≤ esaurire completamente il serbatoio o lasciare qualsiasi quantit√† finita residua. L‚Äôinfinito √® un concetto matematicamente complesso da trattare.\n\n\n\n\n\n\nFigura¬†20.6: La teoria della misura riguarda l‚Äôallocazione di una qualche quantit√† continua e positiva \\(M\\) sugli elementi individuali dello spazio campionario.\n\n\n\nUn‚Äôallocazione esaustiva di \\(M\\) su tutto lo spazio campionario assicura che il serbatoio sia completamente svuotato. In altre parole, l‚Äôintero valore di \\(M\\) deve essere distribuito tra gli elementi \\(x_{n} \\in X\\).\nPer illustrare questo concetto, consideriamo il nostro spazio campionario dimostrativo \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit \\}\\). Il processo di allocazione pu√≤ essere descritto come segue:\n\nAllocchiamo \\(m_\\Box\\) a \\(\\Box\\), lasciando \\(M - m_\\Box\\) nel serbatoio.\nAssegniamo \\(m_\\clubsuit\\) a \\(\\clubsuit\\), riducendo ulteriormente il contenuto del serbatoio a \\(M - m_\\Box - m_\\clubsuit\\).\nContinuiamo questo processo per \\(\\diamondsuit\\) e \\(\\heartsuit\\).\nInfine, per svuotare completamente il serbatoio, dobbiamo allocare tutto ci√≤ che rimane a \\(\\spadesuit\\).\n\nMatematicamente, l‚Äôammontare finale allocato a \\(\\spadesuit\\) sar√†:\n\\[\nM - m_{\\Box} - m_{\\clubsuit} - m_{\\diamondsuit} - m_{\\heartsuit}.\n\\]\nQuesta allocazione finale assicura che la somma di tutte le quantit√† distribuite sia esattamente uguale a \\(M\\), svuotando cos√¨ completamente il serbatoio.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n¬†\n\n\n\n\nFigura¬†20.7: Poich√© la quantit√† totale \\(M\\) √® conservata, ogni allocazione \\(m_{n}\\) a un elemento \\(x_{n} \\in X\\) riduce la quantit√† disponibile per l‚Äôallocazione agli altri elementi. Un‚Äôallocazione esaustiva non lascia nulla nel serbatoio iniziale dopo che ciascun elemento ha ricevuto la sua allocazione.\n\n\n\nUna misura √® qualsiasi allocazione coerente della quantit√† \\(M\\) agli elementi di uno spazio campionario. Matematicamente, qualsiasi misura su un insieme finito pu√≤ essere caratterizzata da \\(N\\) numeri \\[\n\\mu = \\{ m_{1}, \\ldots, m_{N} \\}\n\\] che soddisfano \\[\n0 \\le m_{n}\n\\] e \\[\n\\sum_{n = 1}^{N} m_{n} = M.\n\\] Ad esempio, qualsiasi misura sui cinque elementi dell‚Äôinsieme \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\) √® specificata da cinque numeri positivi \\(\\{ m_\\Box, m_\\clubsuit, m_\\diamondsuit, m_\\heartsuit, m_\\spadesuit \\}\\) che soddisfano \\[\nm_\\Box + m_\\clubsuit + m_\\diamondsuit + m_\\heartsuit + m_\\spadesuit = M.\n\\]\n\n\n\n\n\n\nFigura¬†20.8: Una misura \\(\\mu\\) su un insieme finito \\(X\\) √® qualsiasi allocazione coerente di \\(M\\) agli elementi $x_{n} X. Ogni misura pu√≤ essere caratterizzata da \\(N\\) numeri \\(m_{n}\\) che sommano a \\(M\\), o equivalentemente una funzione che mappa ogni elemento \\(x_{n}\\) alla sua misura allocata \\(m_{n}\\).\n\n\n\nPi√π grande √® \\(m_{n}\\), pi√π di \\(M\\) viene allocato all‚Äôelemento \\(x_{n}\\). Seguendo questa terminologia, chiameremo anche \\(M\\) come la misura totale e \\(m_{n}\\) come la misura allocata a \\(x_{n}\\).\nIn questa discussione, ci occuperemo solo di misure finite, dove la misura totale \\(M\\) √® un numero positivo e finito (\\(0 \\leq M \\leq \\infty\\)). Non tratteremo il caso di misure infinite (\\(M = \\infty\\)), poich√© richiede considerazioni pi√π complesse che vanno oltre lo scopo di questa trattazione.\nUna misura \\(\\mu\\) su uno spazio campionario \\(X\\) pu√≤ essere vista come una funzione che assegna un valore numerico non negativo (la misura) a ogni elemento dello spazio:\n\\[\n\\begin{alignat*}{6}\n\\mu :\\; & X & &\\rightarrow& \\; & [0, \\infty] &\n\\\\\n& x_{n} & &\\mapsto& & m_{n} = \\mu(x_{n}) &,\n\\end{alignat*}\n\\] dove:\n\n\\(X\\) √® lo spazio campionario,\n\\(x_n\\) √® un elemento di \\(X\\),\n\\(m_n\\) √® la misura assegnata a \\(x_n\\).\n\nQuesto approccio funzionale ci permette di considerare ogni elemento dello spazio campionario separatamente, valutando \\(\\mu(x_{n})\\) per ciascun \\(x_{n}\\), invece di dover gestire tutte le allocazioni contemporaneamente.\n√à importante notare che esistono molti modi diversi per distribuire una misura totale \\(M\\) tra gli elementi di un insieme finito. L‚Äôinsieme di tutte le possibili misure su \\(X\\) si indica con \\(\\mathcal{M}(X)\\).\nAll‚Äôinterno di questa collezione ci sono alcuni esempi notevoli. Ad esempio, una misura singolare alloca la misura totale \\(M\\) a un singolo elemento, lasciando il resto con niente. D‚Äôaltra parte, una misura uniforme alloca la stessa misura \\(M / N\\) a ciascun elemento. Su insiemi finiti ci sono \\(N\\) misure singolari distinte, una per ciascun elemento distinto, e una misura uniforme unica.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura¬†20.9: Una misura singolare (a) alloca la misura totale a un singolo elemento, mentre la misura uniforme (b) distribuisce la misura totale uniformemente a ciascun elemento.\n\n\n\nLe misure finite sono una categoria particolarmente importante nel campo della teoria della misura. Una misura si definisce finita quando la sua misura totale \\(M\\) √® un numero positivo e limitato, ovvero \\(0 &lt; M &lt; \\infty\\).\nL‚Äôimportanza delle misure finite risiede nella possibilit√† di esprimere le allocazioni in termini relativi anzich√© assoluti. Questo significa che possiamo rappresentare la misura di ciascun elemento come una frazione o una percentuale della misura totale, invece di usare il valore assoluto. Invece di considerare la misura assoluta allocata a ciascun elemento \\(m_{n}\\), possiamo considerare la proporzione della misura totale allocata a ciascun elemento \\[\np_{n} = m_{n} / M.\n\\] Per costruzione, le proporzioni sono confinate all‚Äôintervallo unitario \\([0, 1]\\). Come per qualsiasi quantit√† che assume valori in \\([0, 1]\\), possiamo rappresentare le proporzioni altrettanto bene con decimali, ad esempio \\(p_{n} = 0.2\\), e percentuali, \\(p_{n} = 20\\%\\).\nQuesto approccio relativo offre diversi vantaggi: permette di confrontare facilmente l‚Äôimportanza relativa di diversi elementi, facilita la comprensione della distribuzione della misura sull‚Äôintero spazio campionario e consente di normalizzare misure diverse, rendendo pi√π semplice il confronto tra sistemi diversi. In sintesi, le misure finite ci permettono di passare da una visione ‚Äúassoluta‚Äù a una ‚Äúrelativa‚Äù della distribuzione della misura, offrendo una prospettiva pi√π intuitiva e utile per l‚Äôanalisi.\n\n\n\n\n\n\nFigura¬†20.10: Ogni misura finita pu√≤ essere caratterizzata da un‚Äôallocazione proporzionale.\n\n\n\nIn altre parole, una misura proporzionale definisce la funzione \\[\n\\begin{alignat*}{6}\n\\pi :\\; & X & &\\rightarrow& \\; & [0, 1] &\n\\\\\n& x_{n} & &\\mapsto& & p_{n} = \\pi(x_{n}) &\n\\end{alignat*}\n\\] con \\[\n0 \\le p_{n} \\le 1\n\\] e \\[\n\\sum_{n = 1}^{N} p_{n} = 1.\n\\] Una collezione di variabili \\(\\{ p_{1}, \\ldots, p_{N} \\}\\) che soddisfano queste propriet√† √® chiamata simplex.\n\n\n\n\n\n\nFigura¬†20.11: Un‚Äôallocazione proporzionale √® anche conosciuta come distribuzione di probabilit√†.\n\n\n\nPi√π importante, una misura proporzionale \\(\\pi\\) √® anche conosciuta come distribuzione di probabilit√†, e le allocazioni proporzionali \\(p_{n}\\) sono chiamate probabilit√†. Sebbene il termine ‚Äúprobabilit√†‚Äù sia spesso carico di significati interpretativi e filosofici, la sua struttura matematica √® piuttosto semplice: su un insieme finito, una probabilit√† rappresenta semplicemente la proporzione di una quantit√† finita assegnata a ciascun elemento individuale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilit√†-sui-sottoinsiemi",
    "title": "20¬† Misura di Probabilit√†",
    "section": "20.5 Misura e Probabilit√† sui Sottoinsiemi",
    "text": "20.5 Misura e Probabilit√† sui Sottoinsiemi\nSugli insiemi finiti, qualsiasi allocazione, sia assoluta che proporzionale, agli elementi individuali \\(x \\in X\\) determina anche un‚Äôallocazione per i sottoinsiemi \\(\\mathsf{x} \\in 2^{X}\\). La misura assegnata a un sottoinsieme √® semplicemente la somma delle misure assegnate agli elementi che lo compongono. Ad esempio, la misura assegnata al sottoinsieme \\(\\mathsf{x} = \\{ \\Box, \\clubsuit, \\heartsuit \\}\\) √® \\(m_{\\Box} + m_{\\clubsuit} + m_{\\heartsuit}\\).\n\n\n\n\n\n\nFigura¬†20.12: Su un insieme finito, un‚Äôallocazione sugli elementi individuali definisce anche un‚Äôallocazione su qualsiasi sottoinsieme.\n\n\n\nPer costruzione, qualsiasi misura sui sottoinsiemi e distribuzione di probabilit√† soddisfano una serie di propriet√† utili. Ad esempio, per qualsiasi misura \\[\n\\mu( \\emptyset ) = 0\n\\] e \\[\n\\mu( X ) = \\sum_{n = 1}^{N} \\mu(x_{n}) = M,\n\\] mentre per qualsiasi distribuzione di probabilit√† abbiamo \\(\\pi( \\emptyset ) = 0\\) e \\(\\pi( X ) = 1\\).\nLe allocazioni sui sottoinsiemi si combinano in modo naturale con le operazioni sui sottoinsiemi. Consideriamo, ad esempio, i due sottoinsiemi disgiunti \\(\\mathsf{x}_{1} = \\{ \\Box, \\diamondsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\clubsuit, \\spadesuit \\}\\). Poich√© i due sottoinsiemi sono disgiunti, la loro unione include semplicemente tutti i loro elementi:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2}\n=\n\\{ \\Box, \\diamondsuit \\} \\cup \\{ \\clubsuit, \\spadesuit \\}\n=\n\\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\},\n\\]\ne la misura di questa unione √® solo la somma delle misure dei due sottoinsiemi:\n\\[\n\\begin{align*}\n\\mu ( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} )\n&=\n\\mu ( \\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\} )\n\\\\\n&=\nm_{\\Box} + m_{\\clubsuit} + m_{\\diamondsuit} + m_{\\spadesuit}\n\\\\\n&=\n( m_{\\Box} + m_{\\diamondsuit} ) + ( m_{\\clubsuit} + m_{\\spadesuit} )\n\\\\\n&=\n\\mu( \\mathsf{x}_{1} ) + \\mu( \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nPi√π in generale, per qualsiasi collezione di sottoinsiemi\n\\[\n\\mathsf{x}_{1}, \\ldots, \\mathsf{x}_{K}\n\\]\nche sono reciprocamente disgiunti,\n\\[\n\\mathsf{x}_{k} \\cap \\mathsf{x}_{k'} = \\emptyset \\quad \\text{per} \\quad k \\ne k',\n\\]\nabbiamo\n\\[\n\\mu ( \\cup_{k = 1}^{K} \\mathsf{x}_{k} )\n=\n\\sum_{k = 1}^{K} \\mu ( \\mathsf{x}_{k} ).\n\\]\nIn altre parole, se possiamo scomporre un sottoinsieme in una collezione di sottoinsiemi pi√π piccoli e disgiunti, possiamo anche scomporre la misura allocata a quel sottoinsieme iniziale nelle misure allocate ai sottoinsiemi componenti. Questa propriet√† di coerenza √® chiamata additivit√†.\nUn sottoinsieme \\(\\mathsf{x}\\) e il suo complemento \\(\\mathsf{x}^{c}\\) sono sempre disgiunti, ovvero \\(\\mathsf{x} \\cap \\mathsf{x}^{c} = \\emptyset\\). Allo stesso tempo, la loro unione copre l‚Äôintero insieme: \\(\\mathsf{x} \\cup \\mathsf{x}^{c} = X\\). Di conseguenza, l‚Äôadditivit√† implica che:\n\\[\n\\begin{align*}\nM &= \\mu (X) \\\\\n  &= \\mu ( \\mathsf{x} \\cup \\mathsf{x}^{c} ) \\\\\n  &= \\mu ( \\mathsf{x} ) + \\mu ( \\mathsf{x}^{c} ),\n\\end{align*}\n\\]\nda cui segue che:\n\\[\n\\mu ( \\mathsf{x}^{c} ) = M - \\mu ( \\mathsf{x} ).\n\\]\nIn altre parole, la misura assegnata al complemento di un sottoinsieme √® la misura totale meno la misura assegnata a quel sottoinsieme. Per le distribuzioni di probabilit√†, questo concetto √® ancora pi√π evidente:\n\\[\n\\pi ( \\mathsf{x}^{c} ) = 1 - \\pi ( \\mathsf{x} ).\n\\]\nQuando due sottoinsiemi si sovrappongono, dobbiamo considerare che la somma delle loro misure \\(\\mu (\\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} )\\) conta due volte la misura degli elementi condivisi tra di essi. Ad esempio, se \\(\\mathsf{x}_{1} = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\Box, \\spadesuit \\}\\), allora l‚Äôunione include l‚Äôelemento sovrapposto \\(\\Box\\) solo una volta:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2} = \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\} = \\{ \\Box, \\heartsuit, \\spadesuit \\}.\n\\]\nDi conseguenza:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) &= \\mu( \\{ \\Box, \\heartsuit, \\spadesuit \\} ) \\\\\n&= m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit}.\n\\end{align*}\n\\]\nSommando le misure allocate ai due sottoinsiemi individualmente, tuttavia, otteniamo:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) &= (m_{\\Box} + m_{\\heartsuit} ) + ( m_{\\Box} + m_{\\spadesuit} ) \\\\\n&= m_{\\Box} + m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit} \\\\\n&= m_{\\Box} + \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nL‚Äôelemento che viene contato due volte √® esattamente l‚Äôunico elemento nell‚Äôintersezione dei due sottoinsiemi:\n\\[\nm_{\\Box} = \\mu( \\{ \\Box \\} ) = \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nIn altre parole, possiamo scrivere:\n\\[\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) = \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) + \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nQuesta relazione vale per qualsiasi due sottoinsiemi, indipendentemente dalla loro sovrapposizione.\n\n\n\n\n\n\nFigura¬†20.13: Quando due sottoinsiemi si sovrappongono, la misura allocata a ciascuno conta doppio la misura allocata a qualsiasi elemento sovrapposto, qui \\(\\Box\\), ma la misura allocata alla loro unione no. Questo risulta in una relazione importante tra le misure allocate ai due sottoinsiemi, la misura allocata alla loro unione e la misura allocata alla loro intersezione.\n\n\n\nQueste propriet√† dei sottoinsiemi ci permettono di costruire una misura in molti modi diversi, ciascuno dei quali pu√≤ essere utile in circostanze diverse. Questa flessibilit√† √® molto comoda quando si applica la teoria della misura e la teoria della probabilit√† nella pratica.\nAd esempio, possiamo specificare una misura in due modi principali:\n\nAllocazione globale: possiamo assegnare le misure a tutti gli elementi individuali contemporaneamente. Questo metodo considera l‚Äôintero insieme fin dall‚Äôinizio e assegna una misura a ciascun elemento.\n\n\n\n\n\n\n\nFigura¬†20.14: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nAllocazione locale: possiamo assegnare la misura a ciascun elemento uno alla volta. Questo metodo permette di concentrarsi su un elemento alla volta, aggiungendo gradualmente le misure agli altri elementi.\n\n\n\n\n\n\n\nFigura¬†20.15: Allo stesso tempo, le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\nInoltre, non √® sempre necessario partire dalle allocazioni individuali. Un altro metodo consiste nel:\n\nAllocazione iterativa: possiamo iniziare allocando la misura totale a sottoinsiemi disgiunti e poi affinare iterativamente questa allocazione suddividendo i sottoinsiemi in parti sempre pi√π piccole fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura¬†20.16: Le misure possono anche essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre pi√π piccoli.\n\n\n\nQuesta flessibilit√† nelle modalit√† di costruzione delle misure √® particolarmente utile perch√© permette di adattare l‚Äôapproccio alle specifiche necessit√† del problema in questione. Ad esempio, nella pratica, potremmo trovare pi√π semplice allocare inizialmente misure a grandi gruppi di elementi e poi suddividere questi gruppi, oppure potremmo voler assegnare le misure a ciascun elemento uno per uno a seconda delle esigenze del contesto.\nInfine, la definizione di misura sui sottoinsiemi \\(\\mu : 2^{X} \\rightarrow [0, \\infty]\\) √® cruciale per estendere la teoria della misura oltre gli insiemi finiti. Questa estensione √® necessaria per definire misure in modo coerente su insiemi matematicamente pi√π complessi, come la retta reale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/02_prob_spaces.html#commenti-e-considerazioni-finali",
    "title": "20¬† Misura di Probabilit√†",
    "section": "20.6 Commenti e considerazioni finali",
    "text": "20.6 Commenti e considerazioni finali\nIl significato applicativo delle nozioni di misura e distribuzione di probabilit√† √® centrale per comprendere come utilizzare questi concetti nella pratica, in particolare nella statistica bayesiana. Il punto cruciale √® capire cosa rappresenta \\(M\\), la ‚Äúmisura totale‚Äù. Nelle applicazioni bayesiane, \\(M\\) rappresenta la nostra certezza complessiva.\nQuando si lavora con distribuzioni di probabilit√†, stiamo effettivamente allocando questa certezza complessiva tra diversi eventi possibili. Una distribuzione (di massa) di probabilit√† √® quindi l‚Äôallocazione relativa della nostra certezza tra un insieme di eventi disgiunti. Ogni probabilit√† individuale, \\(p_n\\), rappresenta la proporzione della nostra certezza totale che assegniamo a un particolare evento.\nNella teoria bayesiana, la ‚Äúmisura totale‚Äù \\(M\\) √® interpretata come la somma totale delle probabilit√†, che √® sempre uguale a 1. Questo riflette il fatto che la somma delle nostre certezze relative per tutti gli eventi possibili deve essere completa: siamo completamente certi che uno degli eventi nel nostro spazio campionario si verificher√†.\nQuando creiamo una distribuzione di probabilit√†, stiamo dividendo questa certezza totale tra i vari eventi possibili nel nostro spazio campionario. Ad esempio, se stiamo analizzando un problema con cinque possibili esiti distinti, dobbiamo allocare l‚Äôintera certezza (pari a 1) tra questi esiti. Ogni valore di probabilit√† \\(p_n\\) rappresenta la frazione della nostra certezza totale che attribuiamo a un particolare esito.\nLe nozioni di misura e distribuzione di probabilit√† trovano numerose applicazioni pratiche. Ad esempio:\n\nInferenza bayesiana: Utilizziamo distribuzioni di probabilit√† per rappresentare le nostre incertezze sui parametri di interesse. Dopo aver osservato i dati, aggiorniamo queste distribuzioni tramite il teorema di Bayes.\nModellizzazione probabilistica: Costruiamo modelli che descrivono il comportamento di sistemi complessi assegnando probabilit√† agli eventi possibili. Questo ci permette di fare previsioni e prendere decisioni informate basate sulle probabilit√† assegnate.\n\nIn conclusione, le nozioni di misura e distribuzione di probabilit√† sono strumenti potenti per allocare e manipolare la nostra certezza tra diversi eventi possibili. Comprendere questi concetti √® fondamentale per comprendere le applicazioni della teoria della probabilit√† e della statistica bayesiana. La ‚Äúmisura totale‚Äù \\(M\\) rappresenta la nostra certezza complessiva, e le distribuzioni di probabilit√† ci permettono di distribuire questa certezza in modo coerente e informato tra gli eventi possibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Misura di Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html",
    "href": "chapters/probability/03_prob_on_general_spaces.html",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "",
    "text": "Introduzione\nNel Capitolo 20 abbiamo introdotto la teoria della misura e della probabilit√† su insiemi con un numero finito di elementi. Tuttavia, molti degli spazi matematici che incontriamo nelle applicazioni pratiche, come gli interi e la retta reale, non hanno un numero finito di elementi, ma piuttosto un numero numerabile infinito o addirittura non numerabile infinito di elementi. Sfortunatamente, estendere la teoria della misura e della probabilit√† a spazi pi√π generali come questi non √® sempre semplice.\nSenza entrare nei dettagli, √® stato dimostrato che la forma pi√π generale della teoria della misura e della probabilit√† applicabile a qualsiasi spazio matematico √® chiamata \\(\\sigma\\)-algebra. In questo capitolo, forniremo un‚Äôintroduzione intuitiva ai vincoli delle \\(\\sigma\\)-algebre ed esamineremo alcune notevoli applicazioni. In particolare, introdurremo i concetti di variabile casuale, funzioni di massa di probabilit√† e funzioni di ripartizione.\nQuesti concetti sono fondamentali per comprendere come la probabilit√† e la misura possono essere utilizzate in contesti pi√π complessi, permettendo di estendere le nostre analisi a insiemi infiniti e spazi continui, che sono comuni nelle applicazioni psicologiche.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.1 \\(\\sigma\\)-Algebra",
    "text": "21.1 \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra √® una struttura matematica che permette di definire in modo coerente quali sottoinsiemi di un insieme sono ‚Äúmisurabili‚Äù.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.2 Definizione di \\(\\sigma\\)-Algebra",
    "text": "21.2 Definizione di \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra √® una collezione di sottoinsiemi di uno spazio \\(X\\) che soddisfa le seguenti propriet√†:\n\nChiusura rispetto al complemento: Se un sottoinsieme \\(A\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche il suo complemento \\(A^c\\) appartiene a \\(\\mathcal{F}\\). Questo significa che se \\(\\mathcal{F}\\) contiene un certo sottoinsieme, deve contenere anche tutti gli elementi che non sono in quel sottoinsieme.\nChiusura rispetto alle unioni numerabili: Se una sequenza numerabile di sottoinsiemi \\(A_1, A_2, A_3, \\ldots\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche l‚Äôunione di tutti questi sottoinsiemi appartiene a \\(\\mathcal{F}\\). Questo implica che se \\(\\mathcal{F}\\) contiene una serie di sottoinsiemi, deve contenere anche il loro insieme unito.\nInclusione dello spazio campionario: Lo spazio campionario \\(X\\) stesso deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). In altre parole, l‚Äôintero insieme \\(X\\) √® considerato un sottoinsieme misurabile.\n\nLa chiusura in questo contesto significa che la collezione \\(\\mathcal{F}\\) √® stabile rispetto a determinate operazioni insiemistiche. In particolare, se si applicano le operazioni di complemento o di unione numerabile a elementi della \\(\\sigma\\)-algebra, i risultati di queste operazioni rimarranno all‚Äôinterno della stessa \\(\\sigma\\)-algebra. Questo garantisce che la \\(\\sigma\\)-algebra non ‚Äúperda‚Äù elementi a causa di queste operazioni, mantenendo cos√¨ la coerenza e la completezza della collezione di sottoinsiemi.\n\n21.2.1 Spazio Misurabile\nUn insieme dotato di una \\(\\sigma\\)-algebra, \\((X, \\mathcal{X})\\), √® detto spazio misurabile. Gli elementi di una \\(\\sigma\\)-algebra sono noti come sottoinsiemi misurabili, mentre i sottoinsiemi non appartenenti alla \\(\\sigma\\)-algebra sono detti non misurabili. La distinzione tra sottoinsiemi misurabili e non misurabili √® cruciale per evitare comportamenti anomali e controintuitivi nella teoria della misura e della probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.3 Gli Assiomi di Kolmogorov",
    "text": "21.3 Gli Assiomi di Kolmogorov\nI tre assiomi di Kolmogorov definiscono le propriet√† fondamentali di una misura di probabilit√† e richiedono l‚Äôesistenza di una \\(\\sigma\\)-algebra.\n\nNon negativit√†: Per qualsiasi evento \\(A\\) nello spazio campionario \\(\\Omega\\), la probabilit√† di \\(A\\) √® non negativa. \\[\nP(A) \\geq 0.\n\\]\nNormalizzazione: La probabilit√† dell‚Äôintero spazio campionario \\(\\Omega\\) √® 1. \\[\nP(\\Omega) = 1.\n\\]\nAdditivit√† numerabile: Per qualsiasi sequenza numerabile di eventi mutuamente esclusivi \\(A_1, A_2, A_3, \\ldots\\), la probabilit√† della loro unione √® la somma delle loro probabilit√†. \\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\n21.3.1 Connessione tra gli Assiomi di Kolmogorov e le \\(\\sigma\\)-Algebre\nGli assiomi di Kolmogorov sono definiti rispetto a una misura di probabilit√† \\(P\\) su uno spazio campionario \\(\\Omega\\) e implicano l‚Äôesistenza di una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). La \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) √® la collezione di eventi (sottoinsiemi di \\(\\Omega\\)) per i quali la misura di probabilit√† \\(P\\) √® definita.\n\nNon negativit√† garantisce che \\(P\\) assegni un valore non negativo a ogni evento nella \\(\\sigma\\)-algebra.\nNormalizzazione garantisce che \\(P(\\Omega) = 1\\), assicurando che \\(\\Omega\\) sia un elemento della \\(\\sigma\\)-algebra.\nAdditivit√† numerabile garantisce che la \\(\\sigma\\)-algebra sia chiusa rispetto alle unioni numerabili di insiemi disgiunti.\n\nIn sintesi, gli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra come struttura all‚Äôinterno della quale queste propriet√† valgono. La \\(\\sigma\\)-algebra √® quindi la collezione di eventi per i quali la misura di probabilit√† √® ben definita e coerente con gli assiomi di Kolmogorov.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.4 Probabilit√†",
    "text": "21.4 Probabilit√†\nUna volta definiti gli assiomi di Kolmogorov, √® possibile introdurre la definizione di probabilit√†.\nLa probabilit√† di un evento √® una misura numerica che indica la possibilit√† che tale evento si verifichi, in accordo con gli assiomi di Kolmogorov.\n\nSe \\(P(A) = 0\\), l‚Äôevento \\(A\\) √® impossibile.\nSe \\(P(A) = 1\\), l‚Äôevento \\(A\\) √® certo.\n\nPer denotare la probabilit√† che un evento \\(A\\) non si verifichi, si usa la notazione \\(P(A^c)\\), dove: \\[\nP(A^c) = 1 - P(A).\n\\]\n\n21.4.1 Propriet√† Derivate dagli Assiomi di Kolmogorov\nAlcune propriet√† importanti derivate dagli assiomi includono:\n\n\\(P(\\varnothing) = 0\\),\nSe \\(A \\subset B\\), allora \\(P(A) \\leq P(B)\\),\n\\(0 \\leq P(A) \\leq 1\\),\n\\(P(A^c) = 1 - P(A)\\),\nSe \\(A \\cap B = \\varnothing\\), allora \\(P(A \\cup B) = P(A) + P(B)\\).\n\n\n\n21.4.2 Regole di Addizione per Eventi\nPer eventi non mutuamente esclusivi, la probabilit√† della loro unione √® data da: \\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\]\nUtilizzando il terzo assioma della probabilit√†, si ottiene: \\[\nP(A \\cup B) = P(A \\cap B^c) + P(B \\cap A^c) + P(A \\cap B).\n\\]\nQuando \\(A\\) e \\(B\\) sono mutuamente esclusivi, \\(P(A \\cap B) = 0\\), e quindi: \\[\nP(A \\cup B) = P(A) + P(B).\n\\]\nLa legge della probabilit√† totale permette di scrivere: \\[\nP(A) = P(A \\cap B) + P(A \\cap B^c),\n\\] e analogamente per \\(B\\): \\[\nP(B) = P(B \\cap A) + P(B \\cap A^c).\n\\]\nIn conclusione, gli assiomi di Kolmogorov forniscono la base per definire la probabilit√† su una \\(\\sigma\\)-algebra, garantendo che le propriet√† fondamentali della probabilit√† siano rispettate e che la probabilit√† sia ben definita per una collezione coerente di sottoinsiemi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†-e-calcolo-combinatorio",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilit√†-e-calcolo-combinatorio",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.5 Probabilit√† e Calcolo Combinatorio",
    "text": "21.5 Probabilit√† e Calcolo Combinatorio\nI problemi scolastici pi√π comuni sulle probabilit√† richiedono l‚Äôuso del calcolo combinatorio. La struttura generale di questi problemi √® sempre la stessa: dobbiamo contare il numero di modi in cui un evento compatibile con l‚Äôevento di ‚Äúsuccesso‚Äù definito dal problema si realizza e poi trovare la proporzione di tali eventi rispetto a tutti gli eventi possibili (inclusi quelli di ‚Äúinsuccesso‚Äù) che possono verificarsi nello spazio campionario. Questi problemi presentano due difficolt√† principali:\n\nTrasformare la descrizione verbale del problema in una formulazione matematica chiara, suddividendo gli eventi possibili nello spazio campionario in base alle condizioni di successo e insuccesso definite dal problema.\nContare il numero di successi e il numero totale di eventi.\n\nPer risolvere questi problemi, dobbiamo utilizzare tecniche del calcolo combinatorio, come le permutazioni e le combinazioni, che ci permettono di contare in modo preciso il numero di possibilit√†.\nConsideriamo un esempio semplice e intuitivo per chiarire il concetto. Supponiamo di avere una scatola con 10 palline numerate da 1 a 10. Vogliamo calcolare la probabilit√† di estrarre una pallina con un numero pari.\n\nDefinizione degli eventi: In questo caso, l‚Äôevento di ‚Äúsuccesso‚Äù √® l‚Äôestrazione di una pallina con un numero pari.\n\nEventi di successo: {2, 4, 6, 8, 10}\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\nConteggio delle possibilit√†:\n\nNumero di eventi di successo: 5\nNumero totale di eventi: 10\n\nCalcolo della probabilit√†: \\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5.\n\\]\n\nPer problemi pi√π complessi, come il calcolo della probabilit√† di ottenere una determinata combinazione di carte da un mazzo o di formare un particolare gruppo di persone da una popolazione pi√π grande, utilizziamo strumenti del calcolo combinatorio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "href": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.6 Il Problema dei Fratelli Bernoulli",
    "text": "21.6 Il Problema dei Fratelli Bernoulli\nLa soluzione dei problemi di probabilit√† non √® sempre semplice e nella storia della matematica ci sono molti esempi di celebri matematici che hanno commesso errori. Uno di questi aneddoti riguarda Jakob Bernoulli, uno dei pionieri della teoria della probabilit√†.\nJakob Bernoulli si interess√≤ al calcolo delle probabilit√† mentre cercava di formalizzare le leggi del caso nel suo libro ‚ÄúArs Conjectandi‚Äù, pubblicato postumo nel 1713. Uno dei problemi che affront√≤ riguardava il calcolo della probabilit√† di ottenere almeno una testa in 8 lanci di una moneta equa. Nonostante il suo approccio iniziale fosse corretto, Bernoulli commise un errore nel calcolo combinatorio durante il processo.\nPer risolvere il problema di calcolare la probabilit√† di ottenere almeno una testa in 8 lanci, bisogna considerare la probabilit√† complementare, ovvero la probabilit√† di non ottenere alcuna testa (ottenere solo croci) in 8 lanci, e poi sottrarla da 1:\n\nCalcolo della probabilit√† complementare: La probabilit√† di ottenere solo croci in un singolo lancio √® \\(\\frac{1}{2}\\). La probabilit√† di ottenere solo croci in 8 lanci consecutivi √®: \\[\n\\left(\\frac{1}{2}\\right)^8 = \\frac{1}{256}.\n\\]\nCalcolo della probabilit√† di ottenere almeno una testa: \\[\nP(\\text{almeno una testa}) = 1 - P(\\text{nessuna testa}) = 1 - \\frac{1}{256} = \\frac{255}{256}.\n\\]\n\nJakob Bernoulli commise un errore nel calcolo combinatorio che lo port√≤ a una soluzione errata. Egli sottostim√≤ la probabilit√† di ottenere almeno una testa, probabilmente a causa di un errore nel conteggio delle possibili combinazioni di successi e insuccessi.\nQuesto errore fu successivamente corretto da altri matematici, tra cui suo nipote Daniel Bernoulli, che dimostrarono il metodo corretto per risolvere tali problemi utilizzando il calcolo combinatorio in modo appropriato.\nLa storia del calcolo combinatorio e della probabilit√† √® ricca di aneddoti, come quello di Jakob Bernoulli, che mettono in luce quanto i problemi di probabilit√† possano essere estremamente controintuitivi, persino per i grandi matematici. Oggi, grazie al lavoro e alle correzioni apportate dai matematici del passato, siamo in grado di risolvere molti di questi problemi con maggiore facilit√†. La teoria della probabilit√†, come molte altre discipline scientifiche, √® il risultato di un lungo processo di sviluppo e comprensione, che ha richiesto tempo e sforzi considerevoli.\nUna delle sfide della probabilit√† √® che spesso i problemi non si prestano a soluzioni immediate o intuitive. Tuttavia, esistono due approcci fondamentali per affrontarli. Il primo consiste nell‚Äôapplicare i teoremi della teoria della probabilit√†, un metodo che, come abbiamo visto, pu√≤ risultare controintuitivo. Il secondo approccio √® quello della simulazione Monte Carlo, che consente di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura pi√π intuitiva. Il nome di questo metodo deriva dal famoso Casin√≤ di Monte Carlo a Monaco, ma possiamo semplicemente riferirci ad esso come metodo di simulazione.\nLa simulazione Monte Carlo √® una classe generale di metodi stocastici, in contrasto con i metodi deterministici, utilizzati per risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantit√† di interesse. Tra i metodi comunemente utilizzati troviamo il campionamento con reinserimento, in cui la stessa unit√† pu√≤ essere selezionata pi√π volte, e il campionamento senza reinserimento, in cui ogni unit√† pu√≤ essere selezionata una sola volta. Questi strumenti offrono un potente mezzo per affrontare problemi complessi in modo pratico e accessibile.\n\nEsempio 21.1 Consideriamo il seguente esercizio che presenta un ‚Äúclassico‚Äù problema di calcolo delle probabilit√†.\n‚ÄúUn‚Äôurna contiene 10 palline rosse, 10 palline blu e 20 palline verdi. Se si estraggono 5 palline a caso senza reinserimento, qual √® la probabilit√† che venga selezionata almeno una pallina di ciascun colore?‚Äù\nLa soluzione al problema consiste nel contare il numero di modi in cui possono verificarsi gli eventi incompatibili con la condizione richiesta, dividere per il numero totale di modi in cui 5 palline possono essere estratte da un‚Äôurna con 40 palline, e sottrarre tale risultato da 1.\nIniziamo dal denominatore (‚Äúin quanti modi possono essere estratte 5 palline da un‚Äôurna che ne contiene 40‚Äù). La soluzione √® data dal coefficiente binomiale: \\(\\binom{40}{5}\\).\nDobbiamo poi enumerare tutti i casi incompatibili con la condizione espressa dal problema; al numeratore avremo quindi: (modi di ottenere nessuna pallina rossa) + (modi di ottenere nessuna pallina blu) + (modi di ottenere nessuna pallina verde) - (modi di ottenere nessuna pallina rossa o blu) - (modi di ottenere nessuna pallina rossa o verde) - (modi di ottenere nessuna pallina blu o verde).\nLa soluzione √® dunque:\n\\[\nP(\\text{almeno una rossa, blu e verde}) = \\frac{\n\\binom{30}{5} + \\binom{30}{5} + \\binom{20}{5} - \\binom{20}{5} - \\binom{10}{5} - \\binom{10}{5}\n}{\\binom{40}{5}}.\n\\]\nSvolgiamo i calcoli usando Python.\n\n# Funzione per calcolare il coefficiente binomiale\ndef choose(n, k):\n    return math.comb(n, k)\n\n\n# Calcoli\nno_red = choose(30, 5)\nno_blue = choose(30, 5)\nno_green = choose(20, 5)\n\n# Modi per estrarre 5 palline senza ottenere due colori specifici\nno_red_blue = choose(20, 5)\nno_red_green = choose(10, 5)\nno_blue_green = choose(10, 5)\n\n# Modi totali per estrarre 5 palline in generale\ntotal_ways = choose(40, 5)\n\n# Probabilit√† di estrarre almeno 1 pallina di ciascun colore\nprob_real = (\n    1\n    - (no_red + no_blue + no_green - no_red_blue - no_red_green - no_blue_green)\n    / total_ways\n)\nprob_real\n\n0.567622278148594\n\n\nLo stesso risultato si ottiene con una simulazione.\n\nrandom.seed(12345)\n\n# Creare un'urna con le palline\nurn = [\"red\"] * 10 + [\"blue\"] * 10 + [\"green\"] * 20\n\n# Numero di simulazioni\nsimulations = 100000\n\ncount = 0\nfor _ in range(simulations):\n    # Estrarre 5 palline dall'urna\n    draw = random.sample(urn, 5)\n\n    # Verificare se c'√® almeno una pallina di ogni colore (red, blue, green)\n    if \"red\" in draw and \"blue\" in draw and \"green\" in draw:\n        count += 1\n\n# Calcolare la probabilit√† simulata\nprob_simulated = count / simulations\nprob_simulated\n\n0.56767\n\n\n\nIl metodo di simulazione consente di risolvere problemi che implicano il calcolo delle probabilit√† relative a vari eventi generati dal lancio dei dadi.\n\nEsempio 21.2 Nel caso del lancio di un dado, √® facile calcolare la probabilit√† di ottenere un 1 o un 5. Questa probabilit√† √® \\(\\frac{2}{6}\\). Tuttavia, quando lanciamo due dadi, la situazione si complica perch√© ci interessa ottenere almeno un 1 o un 5, e c‚Äô√® la possibilit√† di ottenere entrambi. Invece di calcolare direttamente questa probabilit√†, possiamo considerare la probabilit√† di non ottenere n√© un 1 n√© un 5 e sottrarla da 1. Con 2 dadi, la probabilit√† di non ottenere n√© un 1 n√© un 5 √® \\(\\frac{4}{6}\\) o \\(\\frac{2}{3}\\) per ogni dado. Per calcolare la probabilit√† congiunta, possiamo moltiplicare la probabilit√† per ciascun dado: \\(1 - (\\frac{2}{3} \\times \\frac{2}{3}) = 0.555\\). Questo significa che c‚Äô√® il 55% di probabilit√† di ottenere almeno un 1 o un 5 quando si lanciano 2 dadi.\nInvece di calcolare matematicamente la probabilit√† di ottenere almeno un 1 o un 5, possiamo utilizzare il metodo Monte Carlo, simulando un grande numero di lanci di dadi e ottenendo la risposta attraverso un approccio di forza bruta. Ecco il procedimento generale:\n\nLancia 2 dadi per 100.000 volte (o per il numero di volte che preferisci).\nConta quante volte appare almeno un 1 o un 5 in ciascun lancio.\nDividi questo conteggio per 100.000. Questa sar√† la probabilit√†.\n\n\n# Numero di simulazioni\nsimulations = 100_000\nsuccess_count = 0\n\n# Simulazione dei lanci\nfor _ in range(simulations):\n    # Lancia due dadi\n    dice_rolls = [random.randint(1, 6) for _ in range(2)]\n\n    # Verifica se c'√® almeno un 1 o un 5\n    if 1 in dice_rolls or 5 in dice_rolls:\n        success_count += 1\n\n# Calcola la probabilit√† simulata\nprobability = success_count / simulations\nprint(f\"La probabilit√† di ottenere almeno un 1 o un 5 √®: {probability:.3f}\")\n\nLa probabilit√† di ottenere almeno un 1 o un 5 √®: 0.555\n\n\n\nUsiamo un ciclo for per simulare i lanci. In ogni iterazione, generiamo due numeri casuali tra 1 e 6, che rappresentano i risultati dei due dadi.\nControlliamo se in ciascun lancio appare almeno un 1 o un 5. Se √® cos√¨, incrementiamo il contatore success_count.\nAlla fine, la probabilit√† viene calcolata dividendo success_count per il numero totale di simulazioni, e poi stampiamo il risultato.\n\nQuesto approccio, basato sulla simulazione, permette di ottenere un‚Äôottima approssimazione della probabilit√† in modo intuitivo, senza dover ricorrere a calcoli matematici complessi.\n√à facile cambiare la simulazione per consdierare il caso di un numero maggiore di dadi. Per esempio, per il caso del lancio di tre dadi, basta modificare il codice in modo che vengano lanciati tre dadi invece di due. Questo si ottiene cambiando range(2) in range(3) nel ciclo che genera i lanci dei dadi. Questa modifica consente di calcolare la probabilit√† di ottenere almeno un 1 o un 5 con tre dadi, utilizzando lo stesso approccio basato sulla simulazione.\nQuesto approccio basato sulla simulazione √® anche al centro della statistica bayesiana moderna. Poich√© il calcolo degli integrali complessi necessari per determinare le distribuzioni posteriori √® estremamente difficile, possiamo impiegare processi di Markov Chain Monte Carlo (MCMC) per esplorare lo spazio plausibile della distribuzione posteriore, fino a raggiungere una convergenza su un valore stabile.\n\n\nEsempio 21.3 Il problema dei compleanni, generalmente attribuito a Richard von Mises, √® un noto esempio controintuitivo di calcolo delle probabilit√† che utilizza il calcolo combinatorio, in particolare le permutazioni. Il problema chiede quanti individui sono necessari affinch√© la probabilit√† che almeno due persone abbiano lo stesso compleanno superi il 50%, assumendo che ogni giorno dell‚Äôanno sia ugualmente probabile come compleanno. Sorprendentemente, la risposta √® solo 23 persone, molto meno di quanto la maggior parte delle persone immagina.\nPer risolvere il problema dei compleanni utilizzando le permutazioni, consideriamo la seguente relazione:\n\\[\n\\begin{align*}\nP(\\text{almeno due persone hanno lo stesso compleanno}) &= \\\\\n1 - P(\\text{nessuno ha lo stesso compleanno}).\n\\end{align*}\n\\]\nQuesta uguaglianza √® valida perch√© l‚Äôevento ‚Äúnessuno ha lo stesso compleanno‚Äù √® il complemento dell‚Äôevento ‚Äúalmeno due persone hanno lo stesso compleanno‚Äù. Pertanto, dobbiamo calcolare la probabilit√† che nessuno abbia lo stesso compleanno.\nSia \\(k\\) il numero di persone. Per calcolare la probabilit√† che nessuno abbia lo stesso compleanno, dobbiamo contare il numero di modi in cui \\(k\\) persone possono avere compleanni diversi. Poich√© ogni compleanno √® ugualmente probabile, possiamo usare le permutazioni per contare il numero di modi in cui \\(k\\) compleanni unici possono essere disposti su 365 giorni:\n\\[\n365P_k = \\frac{365!}{(365 - k)!}.\n\\]\nDividiamo questo numero per il numero totale di elementi nello spazio campionario, che √® il numero totale di modi in cui \\(k\\) compleanni possono essere disposti su 365 giorni:\n\\[\n365^k.\n\\]\nQuindi, la probabilit√† che nessuno abbia lo stesso compleanno √®:\n\\[\nP(\\text{nessuno ha lo stesso compleanno}) = \\frac{365P_k}{365^k} = \\frac{365!}{365^k (365 - k)!}.\n\\]\nUsando questa formula, la probabilit√† che almeno due persone abbiano lo stesso compleanno √®:\n\\[\nP(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - \\frac{365!}{365^k (365 - k)!}.\n\\]\nIn sintesi, calcolando questa probabilit√†, si scopre che bastano solo 23 persone affinch√© la probabilit√† che almeno due di loro abbiano lo stesso compleanno superi il 50%, un risultato sorprendente rispetto all‚Äôintuizione comune.\n\ndef birthday(k):\n    logdenom = k * math.log(365) + math.lgamma(365 - k + 1) # log denominatore\n    lognumer = math.lgamma(366) # log numeratore\n    pr = 1 - np.exp(lognumer - logdenom) # trasformazione inversa\n    return pr\n\nk = np.arange(1, 51)\nbday = [birthday(i) for i in k]\n\nplt.plot(k, bday, marker=\"o\", alpha=0.5)\nplt.xlabel('Numero di persone')\nplt.ylabel('Probabilit√† che almeno due persone\\nabbiano lo stesso compleanno')\nplt.axhline(\n    y=0.5,\n    linestyle=\"--\",\n    color=\"gray\"\n)\nplt.xlim(0, 50)\nplt.ylim(0, 1)\nplt.title('Probabilit√† del Problema dei Compleanni')\nplt.show()\n\nprint(\"Probabilit√† per 20-25 persone:\", bday[19:25])\n\n\n\n\n\n\n\n\nProbabilit√† per 20-25 persone: [0.41143838358049944, 0.44368833516523465, 0.47569530766240553, 0.507297234324024, 0.5383442579144757, 0.5686997039694264]\n\n\nOsserviamo che quando il numero di persone √® 23, la probabilit√† che almeno due persone abbiano lo stesso compleanno supera 0.5. Quando il numero di persone √® pi√π di 50, questa probabilit√† √® quasi 1.\n\n\nEsempio 21.4 In precedenza, abbiamo derivato la soluzione analitica esatta per il problema dei compleanni, ma possiamo ottenere una soluzione approssimata in modo pi√π intuitivo utilizzando il metodo della simulazione Monte Carlo.\nPer affrontare il problema dei compleanni, campioniamo \\(k\\) compleanni, che potrebbero non essere unici, tra i 365 giorni dell‚Äôanno e verifichiamo se i \\(k\\) compleanni campionati sono tutti diversi. Utilizziamo il campionamento con reinserimento, poich√© ogni giorno dei 365 ha la stessa probabilit√† di essere scelto, indipendentemente dai giorni estratti in precedenza. In altre parole, il fatto che una persona sia nata in un determinato giorno dell‚Äôanno non esclude che qualcun altro possa essere nato nello stesso giorno.\nDopo aver ripetuto questa procedura di campionamento molte volte, calcoliamo la frazione di simulazioni in cui almeno due compleanni coincidono. Questa frazione serve come stima della probabilit√† cercata. Questa procedura di simulazione √® intuitiva perch√© riproduce il processo di generazione dei dati descritto nel problema dei compleanni.\nPer implementare il campionamento con o senza reinserimento in Python, utilizziamo la funzione numpy.random.choice. Nel caso del campionamento con reinserimento, impostiamo l‚Äôargomento replace su True. Il campionamento senza reinserimento significa che, una volta campionato un elemento, questo non sar√† disponibile per estrazioni successive.\n\nk = 23  # numero di persone\nsims = 1000  # numero di simulazioni\nevent = 0  # contatore eventi\n\nfor _ in range(sims):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event += 1\n\n# frazione di prove in cui almeno due compleanni sono uguali\nanswer = event / sims\nprint(f\"Stima della probabilit√†: {answer}\")\n\n# Aumentare il numero di simulazioni a un milione per maggiore accuratezza\nsims_large = 1000000\nevent_large = 0\n\nfor _ in range(sims_large):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event_large += 1\n\nanswer_large = event_large / sims_large\nprint(f\"Stima con un milione di simulazioni: {answer_large}\")\n\nStima della probabilit√†: 0.507\nStima con un milione di simulazioni: 0.507865\n\n\nNel codice sopra, abbiamo impostato il numero di simulazioni a un milione. Osserviamo che quando il numero di persone √® 23, la probabilit√† che almeno due persone abbiano lo stesso compleanno √® superiore a 0.5. Quando il numero di persone supera 50, questa probabilit√† √® vicina a 1.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#le-assunzioni-nella-soluzione-dei-problemi",
    "href": "chapters/probability/03_prob_on_general_spaces.html#le-assunzioni-nella-soluzione-dei-problemi",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.7 Le Assunzioni nella Soluzione dei Problemi",
    "text": "21.7 Le Assunzioni nella Soluzione dei Problemi\nNella realt√†, i compleanni non seguono una distribuzione uniforme. Una soluzione migliore al problema dei compleanni sarebbe quella di estrarre i compleanni dalla distribuzione effettiva piuttosto che da una distribuzione uniforme in cui ogni giorno ha la stessa probabilit√†. Non esiste un metodo matematico standard per calcolare questa probabilit√†; l‚Äôunico modo per farlo √® attraverso la simulazione.\nNegli Stati Uniti, il CDC e la Social Security Administration monitorano il numero di nascite giornaliere. Nel 2016, FiveThirtyEight ha pubblicato un articolo sulle frequenze giornaliere di nascita e ha reso disponibili i dati in un file CSV su GitHub. Utilizzando il codice fornito da Andrew Heiss, possiamo caricare quei dati e calcolare le probabilit√† giornaliere dei compleanni negli Stati Uniti.\n\n# Leggi i dati\nbirths_1994_1999 = pd.read_csv(\n    \"https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_1994-2003_CDC_NCHS.csv\"\n)\nbirths_1994_1999 = births_1994_1999[births_1994_1999[\"year\"] &lt; 2000]\n\nbirths_2000_2014 = pd.read_csv(\n    \"https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_2000-2014_SSA.csv\"\n)\n\n# Unisci i dataset\nbirths_combined = pd.concat([births_1994_1999, births_2000_2014])\n\n# Crea la colonna 'full_date' con un anno fittizio 2024 per mantenere la corretta relazione giorno/mese\nbirths_combined[\"full_date\"] = pd.to_datetime(\n    {\n        \"year\": 2024,\n        \"month\": births_combined[\"month\"],\n        \"day\": births_combined[\"date_of_month\"],\n    }\n)\n\n# Aggiungi la colonna 'day_of_year' per la verifica (non necessaria per la visualizzazione)\nbirths_combined[\"day_of_year\"] = births_combined[\"full_date\"].dt.dayofyear\n\n# Crea la colonna 'month_categorical' per avere il nome completo del mese\nbirths_combined[\"month_categorical\"] = births_combined[\"full_date\"].dt.month_name()\n\n# Calcola la media delle nascite per ciascun giorno del mese per ogni mese\navg_births_month_day = (\n    births_combined.groupby([\"month_categorical\", \"date_of_month\"])\n    .agg(avg_births=(\"births\", \"mean\"))\n    .reset_index()\n)\n\n# Correggi l'ordine dei mesi per l'asse Y\navg_births_month_day[\"month_categorical\"] = pd.Categorical(\n    avg_births_month_day[\"month_categorical\"],\n    categories=list(calendar.month_name)[1:],\n    ordered=True,\n)\n\n# Visualizza i dati con un heatmap\nplt.figure(figsize=(12, 10))\navg_births_pivot = avg_births_month_day.pivot(\n    index=\"month_categorical\", columns=\"date_of_month\", values=\"avg_births\"\n)\n\nsns.heatmap(\n    avg_births_pivot,\n    cmap=\"rocket\",\n    cbar_kws={\"orientation\": \"horizontal\", \"shrink\": 0.5, \"label\": \"Average births\"},\n)\n\n# Configura l'asse delle y per mostrare i mesi in ordine corretto\nplt.yticks(rotation=0)\nplt.title(\"Average births per day\", fontsize=16)\nplt.suptitle(\"1994‚Äì2014\", fontsize=12)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nSi noti che i dati rivelano alcuni pattern evidenti:\n\nNessuno sembra voler avere figli durante le festivit√† di Natale o Capodanno. Il giorno di Natale, la vigilia di Natale e il giorno di Capodanno presentano il numero medio di nascite pi√π basso.\nAnche la vigilia di Capodanno, Halloween, il 4 luglio, il 1¬∞ aprile e l‚Äôintera settimana del Ringraziamento mostrano medie particolarmente basse.\nIl 13 di ogni mese registra leggermente meno nascite rispetto alla media‚Äîla colonna relativa al giorno 13 √® particolarmente evidente in questo contesto.\nI giorni con il numero medio di nascite pi√π alto si trovano a met√† settembre, dal 9 al 20, ad eccezione dell‚Äô11 settembre.\n\nImmagino che in Italia i pattern siano, almeno in parte, diversi.\nNon √® l‚Äôobiettivo qui riformulare la soluzione del problema dei compleanni utilizzando la distribuzione effettiva delle nascite piuttosto che quella uniforme, ma piuttosto sottolineare che le procedure di risoluzione dei problemi si basano su assunzioni‚Äînel caso del problema dei compleanni, l‚Äôassunzione che la distribuzione dei compleanni sia uniforme, quando in realt√† non lo √®. Le soluzioni che otteniamo nei problemi probabilistici descrivono le regolarit√† osservabili nel mondo empirico tanto meglio quanto pi√π sono ragionevoli le assunzioni formulate.\nIn tutti i modelli probabilistici (e quindi, in tutti i modelli scientifici, dato che esistono solo modelli probabilistici) √® fondamentale prestare particolare attenzione alla plausibilit√† delle assunzioni su cui tali modelli si basano.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.8 Commenti e considerazioni finali",
    "text": "21.8 Commenti e considerazioni finali\nLa teoria delle probabilit√† √® un pilastro fondamentale della statistica, con applicazioni pratiche in numerosi campi, tra cui la psicologia. Comprendere le probabilit√† ci consente di prendere decisioni informate in situazioni di incertezza e di formulare previsioni affidabili. Una solida conoscenza delle basi della probabilit√† ci permette di affrontare una vasta gamma di problemi e di fare scelte ponderate basate sulla probabilit√† dei vari esiti possibili. Tuttavia, √® importante ricordare che i modelli probabilistici sono solo approssimazioni della realt√† e possono essere influenzati da semplificazioni o dalle limitazioni dei dati disponibili. Pertanto, √® fondamentale interpretare i risultati con cautela e avere piena consapevolezza delle assunzioni che sottendono le analisi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#esercizi",
    "href": "chapters/probability/03_prob_on_general_spaces.html#esercizi",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.9 Esercizi",
    "text": "21.9 Esercizi\n\nEsercizio 21.1 Supponiamo di dover formare una commissione di 5 psicologi su un gruppo di 20 persone (10 psicologi clinici e 10 psicologi del lavoro). Qual √® la probabilit√† che almeno 2 psicologi clinici siano nella commissione? Risolvi il problema usando una simulazione Monte Carlo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "title": "21¬† Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra",
    "section": "21.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "21.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\narviz     : 0.18.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nscipy     : 1.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>21</span>¬† <span class='chapter-title'>Fondamenti della probabilit√†: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "22¬† Probabilit√† condizionata",
    "section": "",
    "text": "Introduzione\nUn principio fondamentale nel campo della probabilit√† √® il concetto di condizionamento. Il condizionamento si verifica quando, all‚Äôinterno di un esperimento aleatorio, le probabilit√† vengono calcolate focalizzandosi esclusivamente su un sottoinsieme specifico dei risultati possibili. In pratica, questo significa che la probabilit√† viene determinata tenendo conto solo di quei risultati che rientrano in un certo criterio o condizione predefinita.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "22¬† Probabilit√† condizionata",
    "section": "22.1 Indipendenza Stocastica",
    "text": "22.1 Indipendenza Stocastica\nNel contesto della probabilit√† condizionata, il concetto di indipendenza gioca un ruolo fondamentale. Questa caratteristica permette di semplificare notevolmente il calcolo delle probabilit√† in molti problemi, evidenziando come la conoscenza di un evento non fornisca alcuna informazione aggiuntiva sull‚Äôaltro.\n\n22.1.1 Indipendenza di Due Eventi\nDue eventi \\(A\\) e \\(B\\) sono detti indipendenti se il verificarsi di uno non influenza la probabilit√† di verificarsi dell‚Äôaltro. Formalmente, questa condizione √® espressa come:\n\\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B),\\]\ndove \\(\\mathbb{P}(A \\cap B)\\) rappresenta la probabilit√† che entrambi gli eventi \\(A\\) e \\(B\\) si verifichino simultaneamente.\nSe questa condizione √® soddisfatta, scriviamo \\(A \\text{ ‚´´ } B\\), il che significa ‚ÄúA √® indipendente da B‚Äù.\n\n\n22.1.2 Indipendenza di un Insieme di Eventi\nL‚Äôindipendenza stocastica √® un concetto fondamentale nell‚Äôapplicazione della probabilit√† in campo statistico. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) √® detto indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilit√† dell‚Äôintersezione degli eventi nel sottoinsieme \\(J\\) √® uguale al prodotto delle loro singole probabilit√†. Formalmente:\n\\[\\mathbb{P} \\left( \\cap_{i \\in J} A_i \\right) = \\prod_{i \\in J} \\mathbb{P}(A_i).\\]\nQuesto significa che ogni combinazione finita di eventi nell‚Äôinsieme √® indipendente.\nL‚Äôindipendenza pu√≤ essere assunta o derivata a seconda del contesto. In alcuni modelli o situazioni, assumiamo che certi eventi siano indipendenti perch√© questa assunzione semplifica i calcoli o riflette una conoscenza previa. In altri casi, l‚Äôindipendenza pu√≤ essere derivata dai dati o da altre propriet√† del modello.\n\n\n22.1.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti (o mutuamente esclusivi) sono quelli che non possono verificarsi simultaneamente, cio√® \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno una probabilit√† positiva di verificarsi, allora non possono essere indipendenti. Questo perch√© per eventi disgiunti con \\(\\mathbb{P}(A) &gt; 0\\) e \\(\\mathbb{P}(B) &gt; 0\\), l‚Äôequazione di indipendenza \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\) non pu√≤ essere soddisfatta, dato che \\(\\mathbb{P}(A \\cap B) = 0\\) e \\(\\mathbb{P}(A) \\mathbb{P}(B) &gt; 0\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#sec-v",
    "href": "chapters/probability/04_conditional_prob.html#sec-v",
    "title": "22¬† Probabilit√† condizionata",
    "section": "22.2 Probabilit√† condizionata su altri eventi",
    "text": "22.2 Probabilit√† condizionata su altri eventi\nLa probabilit√† di un evento √® intrinsecamente condizionata dal nostro stato di informazione. In presenza di un determinato insieme di informazioni, attribuiamo a un evento una probabilit√† specifica di occorrenza. Tuttavia, qualora il nostro stato informativo subisca una modifica, anche la probabilit√† associata all‚Äôevento verr√† corrispondentemente aggiornata.\nIn realt√†, tutte le probabilit√† possono essere intese come probabilit√† condizionate, anche quando la variabile o l‚Äôevento condizionante non √® esplicitamente specificato. Ci√≤ implica che le probabilit√† sono sempre contestualizzate e dipendono dal set informativo disponibile in un dato scenario.\nQuesto quadro concettuale ci induce a considerare le probabilit√† come una ‚Äòmisura di plausibilit√†‚Äô che riflette la nostra conoscenza corrente del sistema o del fenomeno sotto indagine. A seguito dell‚Äôacquisizione di nuove informazioni o di cambiamenti nel contesto, la nostra misura di plausibilit√†, e quindi la probabilit√† attribuita agli eventi, pu√≤ essere rivista.\n\nTeorema 22.1 Siano \\(A\\) e \\(B\\) due eventi definiti su uno spazio campionario \\(S\\). Supponendo che l‚Äôevento \\(B\\) si verifichi, la probabilit√† condizionata di \\(A\\) dato \\(B\\) √® data da\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{per}\\, P(B) &gt; 0,\n\\tag{22.1}\\]\ndove \\(P(A \\cap B)\\) rappresenta la probabilit√† congiunta dei due eventi, ovvero la probabilit√† che entrambi si verifichino.\n\nNell‚ÄôEquazione¬†22.1, \\(P(A \\cap B)\\) √® la probabilit√† congiunta che entrambi gli eventi si verifichino, mentre \\(P(B)\\) √® la probabilit√† marginale dell‚Äôevento \\(B\\). Riorganizzando i termini, otteniamo la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nUtilizzando questa regola, possiamo derivare una forma alternativa della legge della probabilit√† totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c).\n\\]\nDove \\(B^c\\) rappresenta il complemento dell‚Äôevento \\(B\\).\n√à importante notare che \\(P(A \\mid B)\\) non √® definita se \\(P(B) = 0\\).\nLa probabilit√† condizionata pu√≤ essere interpretata come una ricalibrazione dello spazio campionario da \\(S\\) a \\(B\\). Per spazi campionari discreti, la probabilit√† condizionata √® espressa come\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\n\nEsempio 22.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilit√† che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilit√† in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poich√© ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilit√† di ottenere una somma minore di 8 √® 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma √® minore di 8. Quindi, la probabilit√† di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l‚Äôinformazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in Python.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nsample\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (2, 6),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (4, 6),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\n\nevent = [roll for roll in sample if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample)}\")\n\n21 / 36\n\n\n\nsample_odd = [roll for roll in sample if (sum(roll) % 2) != 0]\nsample_odd\n\n[(1, 2),\n (1, 4),\n (1, 6),\n (2, 1),\n (2, 3),\n (2, 5),\n (3, 2),\n (3, 4),\n (3, 6),\n (4, 1),\n (4, 3),\n (4, 5),\n (5, 2),\n (5, 4),\n (5, 6),\n (6, 1),\n (6, 3),\n (6, 5)]\n\n\n\nevent = [roll for roll in sample_odd if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample_odd)}\")\n\n12 / 18\n\n\nSe applichiamo l‚ÄôEquazione¬†22.1, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilit√† di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l‚Äôinformazione che la somma √® dispari, la probabilit√† di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 22.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilit√† del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificit√† del test: 90%. Ci√≤ indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo √® il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne √® affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual √® la probabilit√† che una donna scelta a caso ottenga una mammografia positiva? Poich√© il 1% delle donne ha il cancro al seno, la probabilit√† di ottenere una mammografia positiva (test positivo) √® pari alla sensibilit√† del test, ovvero 0.90 (cio√® 90%).\nSe la mammografia √® positiva, qual √® la probabilit√† che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test dar√† un risultato positivo (vera positivit√†) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test dar√† un risultato positivo (falsa positivit√†) in 99 casi (10%).\n\nQuesta situazione pu√≤ essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\n\nFigura¬†22.1: Esiti della mammografia per 1000 donne.\n\n\n\nCombinando i due risultati precedenti, vediamo che il test d√† un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilit√† di ottenere un risultato positivo al test √® \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilit√† di avere il cancro al seno, dato un risultato positivo al test, √® pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all‚Äô8.3%.\nIn questo esempio, la probabilit√† dell‚Äôevento ‚Äúottenere un risultato positivo al test‚Äù √® una probabilit√† non condizionata, poich√© calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D‚Äôaltra parte, la probabilit√† dell‚Äôevento ‚Äúavere il cancro al seno, dato che il test ha prodotto un risultato positivo‚Äù √® una probabilit√† condizionata, poich√© calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) pu√≤ influenzare la probabilit√† di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilit√† condizionate e non condizionate.\n\n\nEsempio 22.3 Il paradosso di Monty Hall rappresenta un curioso esempio di come l‚Äôintroduzione di nuove informazioni possa influenzare l‚Äôesito di una situazione probabilistica. Questo famoso problema trae origine dal popolare programma televisivo americano ‚ÄúLet‚Äôs Make a Deal‚Äù e deve la sua notoriet√† al conduttore Monty Hall.\nNel gioco ci sono tre porte chiuse: dietro una si nasconde un‚Äôautomobile, mentre dietro le altre due ci sono delle capre. Inizialmente, il concorrente sceglie una delle tre porte senza aprirla. Successivamente, Monty Hall apre una delle due porte rimaste, rivelando una capra. A questo punto, offre al concorrente la possibilit√† di cambiare la sua scelta iniziale e optare per l‚Äôaltra porta ancora chiusa. Il paradosso si presenta quando si scopre che cambiando la scelta in questa fase, il concorrente aumenta le sue probabilit√† di vincere l‚Äôautomobile, passando da 1/3 a 2/3.\nPer confermare questo risultato inaspettato, √® possibile eseguire una simulazione in Python. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilit√† del concorrente di vincere l‚Äôautomobile.\nDi seguito √® riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nporte = [\n    \"capra1\",\n    \"capra2\",\n    \"macchina\",\n]  # definisco il gioco, scelgo una porta a caso per n volte\ncounter = 0\ncontatore_cambio = 0\nn = 10000\nporta_vincente = \"macchina\"\nfor i in range(n):\n    scelta_casuale = random.choice(porte)\n    porte_rimaste = [x for x in porte if x != scelta_casuale]\n    porta_rivelata = random.choice([x for x in porte_rimaste if x != porta_vincente])\n    porta_alternativa = [\n        x for x in porte if x != scelta_casuale and x != porta_rivelata\n    ]\n    if \"macchina\" in porta_alternativa:\n        contatore_cambio += 1\n    if scelta_casuale == \"macchina\":\n        counter += 1\n\nprint(counter / n)  # quante volte vinco non cambiando porta\nprint(contatore_cambio / n)  # quante volte vinco cambiando porta\n\nQuesto script Python √® stato creato da un gruppo di studenti di Psicometria nell‚ÄôAA 2023-2023. La simulazione mostra che, effettivamente, la probabilit√† di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\nEcco una spiegazione del paradosso:\n\nFase Iniziale: Nel gioco, il concorrente deve scegliere una delle tre porte (A, B, C), dietro una delle quali si trova una macchina. Inizialmente, la probabilit√† che la macchina si trovi dietro la porta scelta √® \\(1/3\\), dato che esistono tre possibilit√† ugualmente probabili e solo una contiene la macchina.\nAggiunta di Informazioni: Dopo la scelta iniziale, Monty Hall, che conosce il contenuto dietro ogni porta, apre una delle due porte non scelte, rivelando sempre una capra. Questo passaggio √® fondamentale: non cambia la probabilit√† \\(1/3\\) che la macchina sia dietro la porta originariamente scelta dal concorrente, ma la probabilit√† che la macchina si trovi dietro l‚Äôaltra porta non scelta aumenta ora a \\(2/3\\). Questo aumento di probabilit√† deriva dal fatto che Monty ha scelto deliberatamente una porta con una capra, basando la sua scelta sulla posizione della macchina.\n\nConsideriamo i tre possibili scenari dopo che il concorrente ha scelto la porta A:\n\nLa macchina √® dietro la porta A: La probabilit√† di questo scenario √® \\(1/3\\). Monty pu√≤ aprire sia la porta B che la porta C, poich√© entrambe nascondono una capra. Se il concorrente cambia la sua scelta, perder√†.\nLa macchina √® dietro la porta B: La probabilit√† di questo scenario √® \\(1/3\\). Monty aprir√† la porta C, perch√© sa che la macchina √® dietro la porta B e non pu√≤ rivelarla. Se il concorrente cambia la sua scelta da A a B, vincer√†.\nLa macchina √® dietro la porta C: La probabilit√† di questo scenario √® \\(1/3\\). Monty aprir√† la porta B. Se il concorrente cambia la sua scelta da A a C, vincer√†.\n\nIn conclusione, cambiare la scelta originale porta alla vittoria in due dei tre scenari possibili. Pertanto, la probabilit√† complessiva di vincere cambiando la scelta √® \\(2/3\\).\nQuesto paradosso evidenzia come, in presenza di informazioni aggiuntive, le probabilit√† iniziali possano essere riviste significativamente. √à un classico esempio di come l‚Äôintuizione umana spesso si scontri con i principi della teoria delle probabilit√†, sottolineando l‚Äôimportanza della revisione bayesiana delle probabilit√† alla luce di nuove informazioni.\n\n\n22.2.1 Il paradosso di Simpson\nNel campo della probabilit√† condizionata, uno dei fenomeni pi√π interessanti e, nel contempo, pi√π controintuitivi, √® rappresentato dal paradosso di Simpson. Il paradosso di Simpson √® un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l‚Äôimportanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 22.4 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d‚Äôansia e coaching per migliorare le prestazioni lavorative. Ogni terapia pu√≤ avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d‚Äôansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d‚Äôansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi √® efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno √® un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere pi√π precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\nRossi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\nBianchi\n\nTasso di successo in terapia per disturbi d‚Äôansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\nQuello che sta succedendo √® che Rossi, presumibilmente a causa della sua reputazione come terapeuta pi√π esperto, sta effettuando un numero maggiore di terapie per disturbi d‚Äôansia, che sono intrinsecamente pi√π complesse e con una probabilit√† di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale √® inferiore non a causa di una minore abilit√† in un particolare tipo di terapia, ma perch√© una frazione maggiore delle sue terapie riguarda casi pi√π complessi.\nL‚Äôaggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilit√† dei terapeuti perch√© perdiamo l‚Äôinformazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, √® fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilit√†-composta",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilit√†-composta",
    "title": "22¬† Probabilit√† condizionata",
    "section": "22.3 Teorema della probabilit√† composta",
    "text": "22.3 Teorema della probabilit√† composta\n√à possibile scrivere l‚ÄôEquazione¬†22.1 nella forma:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{22.2}\\]\nQuesto secondo modo di scrivere l‚ÄôEquazione¬†22.1 √® chiamato teorema della probabilit√† composta (o regola moltiplicativa, o regola della catena). La legge della probabilit√† composta ci dice che la probabilit√† che si verifichino contemporaneamente due eventi \\(A\\) e \\(B\\) √® pari alla probabilit√† di uno dei due eventi moltiplicata per la probabilit√† dell‚Äôaltro evento condizionata al verificarsi del primo.\nL‚Äôl‚ÄôEquazione¬†22.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{22.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(&A_1 \\cap A_2 \\cap A_3 \\cap A_4) =  \\\\\n& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 22.5 Per fare un esempio, consideriamo il problema seguente. Da un‚Äôurna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell‚Äôurna. Indichiamo con \\(B_i\\) l‚Äôevento: ‚Äúesce una pallina bianca alla \\(i\\)-esima estrazione‚Äù e con \\(N_i\\) l‚Äôestrazione di una pallina nera. L‚Äôevento: ‚Äúescono due palline bianche nelle prime due estrazioni‚Äù √® rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l‚ÄôEquazione¬†22.2, la sua probabilit√† vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perch√© nella prima estrazione \\(\\Omega\\) √® costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilit√† condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perch√© nella seconda estrazione, se √® verificato l‚Äôevento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l‚Äôesperimento consiste nell‚Äôestrazione successiva di 3 palline, la probabilit√† che queste siano tutte bianche, per l‚ÄôEquazione¬†22.3, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilit√† dell‚Äôestrazione di tre palline nere √® invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "href": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "title": "22¬† Probabilit√† condizionata",
    "section": "22.4 Il teorema della probabilit√† totale",
    "text": "22.4 Il teorema della probabilit√† totale\nIl teorema della probabilit√† totale (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario \\(\\Omega\\) in \\(n\\) eventi mutualmente esclusivi e tali che la loro unione formi \\(\\Omega\\), allora la probabilit√† di un qualsiasi evento in \\(\\Omega\\) pu√≤ essere calcolata sommando la probabilit√† dell‚Äôevento su ciascun sottoinsieme della partizione, pesata in base alla probabilit√† del sottoinsieme.\nIn altre parole, se \\(H_1, H_2, \\dots, H_n\\) sono eventi mutualmente esclusivi e tali che \\(\\bigcup_{i=1}^n H_i = \\Omega\\), allora per ogni evento \\(E \\subseteq \\Omega\\), la probabilit√† di \\(E\\) √® data dalla formula:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{22.4}\\]\ndove \\(P(E \\mid H_i)\\) rappresenta la probabilit√† condizionata di \\(E\\) dato che si √® verificato l‚Äôevento \\(H_i\\), e \\(P(H_i)\\) √® la probabilit√† dell‚Äôevento \\(H_i\\).\nIl teorema della probabilit√† totale riveste un ruolo fondamentale in quanto fornisce il denominatore nel teorema di Bayes, svolgendo la funzione di costante di normalizzazione. Questa costante di normalizzazione √® di vitale importanza per assicurare che la distribuzione a posteriori sia una distribuzione di probabilit√† valida. Per ulteriori dettagli e approfondimenti, √® possibile fare riferimento al Capitolo 34.\nNell‚Äôambito della probabilit√† discreta, questo teorema viene usato quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilit√† di un evento, sfruttando le probabilit√† dei singoli eventi della partizione. Il caso pi√π semplice √® quello di una partizione dello spazio campione in due sottoinsiemi: \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\).\n\n\n\n\n\n\nFigura¬†22.2: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nIn tali circostanza abbiamo che\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nL‚ÄôEquazione¬†22.4 √® utile per calcolare \\(P(E)\\), se \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono facili da trovare.\n\nEsempio 22.6 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un‚Äôurna anch‚Äôessa scelta a caso. Qual √® la probabilit√† che la pallina estratta sia di colore rosso?\nSia \\(R\\) l‚Äôevento ‚Äúla pallina estratta √® rossa‚Äù e sia \\(U_i\\) l‚Äôevento che corrisponde alla scelta dell‚Äô\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilit√† totale, la probabilit√† di estrarre una pallina rossa √® dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]\n\n\n22.4.1 Indipendenza e probabilit√† condizionata\nL‚Äôindipendenza tra due eventi \\(A\\) e \\(B\\) pu√≤ essere espressa in modo intuitivo utilizzando la probabilit√† condizionata. Se \\(A\\) e \\(B\\) sono indipendenti, il verificarsi di uno degli eventi non influisce sulla probabilit√† del verificarsi dell‚Äôaltro. In altre parole, la probabilit√† che \\(A\\) accada non cambia se sappiamo che \\(B\\) √® avvenuto, e viceversa.\nPossiamo esprimere questa idea con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nQuindi, due eventi \\(A\\) e \\(B\\) sono indipendenti se soddisfano le condizioni:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQuesto significa che la probabilit√† di \\(A\\) rimane invariata indipendentemente dal fatto che \\(B\\) sia accaduto o meno, e lo stesso vale per \\(B\\).\n\n22.4.1.1 Indipendenza di Tre Eventi\nTre eventi \\(A\\), \\(B\\) e \\(C\\) sono indipendenti se soddisfano le seguenti condizioni:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C), \\\\\nP(A \\cap B \\cap C) &= P(A) P(B) P(C).\n\\end{align}\n\\]\nLe prime tre condizioni verificano l‚Äôindipendenza a due a due, ovvero l‚Äôindipendenza di ciascuna coppia di eventi. Tuttavia, per essere completamente indipendenti, deve essere soddisfatta anche l‚Äôultima condizione, che riguarda l‚Äôintersezione di tutti e tre gli eventi. Solo se tutte queste condizioni sono soddisfatte possiamo dire che \\(A\\), \\(B\\) e \\(C\\) sono completamente indipendenti.\nIn sintesi, l‚Äôindipendenza tra eventi implica che la conoscenza del verificarsi di uno non fornisce alcuna informazione sulla probabilit√† del verificarsi degli altri.\n\nEsempio 22.7 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilit√† con un mazzo completo\nIn un mazzo completo, la probabilit√† di pescare una carta di picche (\\(P(A)\\)) √® \\(\\frac{13}{52} = \\frac{1}{4}\\), poich√© ci sono 13 picche su 52 carte totali. La probabilit√† di pescare una regina (\\(P(B)\\)) √® \\(\\frac{4}{52} = \\frac{1}{13}\\), poich√© ci sono 4 regine su 52 carte.\nOra consideriamo la probabilit√† congiunta di pescare la regina di picche (\\(P(AB)\\)). Poich√© esiste solo una regina di picche nel mazzo, la probabilit√† di pescare questa specifica carta √® \\(\\frac{1}{52}\\).\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoich√© \\(P(AB) = \\frac{1}{52}\\) √® uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilit√† dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilit√† con questo mazzo ridotto:\nLa probabilit√† di pescare la regina di picche (\\(P(AB)\\)) √® ora \\(\\frac{1}{51}\\), poich√© ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\\(P(A)\\) diventa \\(\\frac{13}{51}\\), poich√© ci sono ancora 13 picche, ma su 51 carte.\n\\(P(B)\\) diventa \\(\\frac{4}{51}\\), poich√© ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilit√†:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoich√© \\(\\frac{1}{51} \\neq \\frac{52}{2601}\\), gli eventi \\(A\\) e \\(B\\) non sono pi√π indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l‚Äôindipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilit√† cambiano e gli eventi non sono pi√π indipendenti. Questo evidenzia l‚Äôimportanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilit√† e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilit√†, influenzando le relazioni di indipendenza tra eventi specifici.\nIn generale, l‚Äôindipendenza tra due eventi significa che la probabilit√† di uno non √® influenzata dal verificarsi dell‚Äôaltro. Questo concetto √® cruciale per analisi probabilistiche e modelli statistici pi√π complessi.\n\n\nEsempio 22.8 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = ‚Äúesce un 1 o un 2 nel primo lancio‚Äù e \\(B\\) = ‚Äúil punteggio totale √® 8‚Äù. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nCalcoliamo \\(P(A)\\):\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nA = [roll for roll in sample if roll[0] == 1 or roll[0] == 2]\nprint(A)\nprint(f\"{len(A)} / {len(sample)}\")\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]\n12 / 36\n\n\nCalcoliamo \\(P(B)\\):\n\nB = [roll for roll in sample if roll[0] + roll[1] == 8]\nprint(B)\nprint(f\"{len(B)} / {len(sample)}\")\n\n[(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)]\n5 / 36\n\n\nCalcoliamo \\(P(A \\cap B)\\):\n\nI = [\n    roll\n    for roll in sample\n    if (roll[0] == 1 or roll[0] == 2) and (roll[0] + roll[1] == 8)\n]\nprint(I)\nprint(f\"{len(I)} / {len(sample)}\")\n\n[(2, 6)]\n1 / 36\n\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti dato che \\(P(A \\cap B) \\neq P(A)P(B)\\):\n\n12/36 * 5/36 == 1/36\n\nFalse",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/04_conditional_prob.html#commenti-e-considerazioni-finali",
    "title": "22¬† Probabilit√† condizionata",
    "section": "22.5 Commenti e considerazioni finali",
    "text": "22.5 Commenti e considerazioni finali\nLa probabilit√† condizionata riveste un ruolo fondamentale poich√© ci permette di definire in modo preciso il concetto di indipendenza statistica. Uno degli aspetti cruciali dell‚Äôanalisi statistica riguarda la valutazione dell‚Äôassociazione tra due variabili. Nel capitolo attuale, ci siamo concentrati sul concetto di indipendenza, che indica l‚Äôassenza di relazione tra le variabili. Tuttavia, in futuro, esploreremo come fare inferenze sulla correlazione tra variabili, ovvero come determinare se le variabili sono associate tra loro o se esiste una relazione statistica credibile tra di esse.\nNell‚Äôambito dell‚Äôinferenza bayesiana, il condizionamento emerge come uno strumento essenziale. L‚Äôinferenza bayesiana √® un approccio statistico che sfrutta proprio il condizionamento per rivedere e aggiornare le credenze o le incertezze relative a determinate ipotesi, basandosi sull‚Äôintroduzione di nuove informazioni.\nIl processo inizia stabilendo una probabilit√† iniziale, denominata probabilit√† a priori, \\(P(A)\\)), che esprime la nostra convinzione o supposizione iniziale riguardo all‚Äôipotesi \\(A\\), prima di ricevere qualsiasi dato aggiuntivo. Questa probabilit√† a priori si fonda su conoscenze gi√† acquisite o su supposizioni precedentemente formulate.\nIl cuore dell‚Äôinferenza bayesiana si trova nell‚Äôaggiornamento di questa credenza iniziale in risposta all‚Äôacquisizione di nuove informazioni, rappresentate dalla variabile \\(E\\). L‚Äôaggiornamento avviene mediante il condizionamento, culminando nella determinazione di una probabilit√† a posteriori \\(P(A | E)\\). Questa nuova probabilit√† rappresenta la nostra credenza aggiornata sull‚Äôipotesi \\(A\\) dopo aver preso in esame l‚Äôevidenza \\(E\\) appena acquisita. In questo modo, l‚Äôinferenza bayesiana permette di affinare le nostre supposizioni e le nostre previsioni su determinati fenomeni, incorporando sistematicamente nuove prove nel nostro quadro di conoscenza.\nLa formula di Bayes governa questo processo di aggiornamento:\n\\[\nP(A | E) = \\frac{P(E | A) \\times P(A)}{P(E)}\n\\]\nIn questa formula, troviamo:\n\n\\(P(A | E)\\): la probabilit√† a posteriori, che √® la probabilit√† dell‚Äôipotesi \\(A\\) date le nuove prove \\(E\\).\n\\(P(E | A)\\): la verosimiglianza, ovvero la probabilit√† di osservare le prove \\(E\\) se l‚Äôipotesi \\(A\\) fosse vera.\n\\(P(A)\\): la probabilit√† a priori, che indica il nostro livello di convinzione iniziale nell‚Äôipotesi \\(A\\).\n\\(P(E)\\): la probabilit√† di osservare le prove \\(E\\), tenendo conto di tutte le ipotesi possibili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "22¬† Probabilit√† condizionata",
    "section": "22.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "22.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Feb 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas: 2.2.0\nnumpy : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>22</span>¬† <span class='chapter-title'>Probabilit√† condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html",
    "href": "chapters/probability/05_bayes_theorem.html",
    "title": "23¬† Il teorema di Bayes",
    "section": "",
    "text": "Introduzione\nIl teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall‚Äôidentificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati, all‚Äôinferenza dei pensieri altrui a partire dal loro comportamento. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.\nNonostante ci√≤, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l‚Äôuniverso fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.\nLa vita reale non √® paragonabile a una partita di scacchi, un gioco con informazioni perfette che pu√≤ essere ‚Äúrisolto‚Äù in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori. Questo capitolo si concentra sull‚Äôequazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un‚Äôipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.\nQuesto processo √® noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall‚Äôincertezza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#spiegazione-del-teorema-di-bayes",
    "href": "chapters/probability/05_bayes_theorem.html#spiegazione-del-teorema-di-bayes",
    "title": "23¬† Il teorema di Bayes",
    "section": "24.1 Spiegazione del Teorema di Bayes",
    "text": "24.1 Spiegazione del Teorema di Bayes\nPrima di approfondire gli aspetti matematici del teorema di Bayes, consideriamone il significato. Sebbene il teorema di Bayes sia un risultato apparentemente semplice della teoria della probabilit√† (la sua derivazione sar√† trattata nella sezione successiva), l‚Äôinterpretazione soggettiva della probabilit√† proposta da Bayes e Price eleva questa semplice formula di probabilit√† condizionata a un potente metodo per descrivere come un agente razionale aggiorni le proprie convinzioni su un‚Äôipotesi alla luce di nuovi dati.\nConsideriamo un‚Äôipotesi \\(H_i\\) all‚Äôinterno di un insieme di ipotesi \\(\\mathcal{H}\\). Il grado di convinzione attribuito all‚Äôipotesi prima di osservare qualsiasi dato √® indicato come \\(P(H_i)\\), noto come probabilit√† a priori. Dopo aver osservato i dati \\(O\\), il grado di convinzione aggiornato √® \\(P(H_i \\mid O)\\), chiamato probabilit√† a posteriori, che rappresenta la probabilit√† di \\(H_i\\) tenendo conto delle informazioni fornite da \\(O\\). Il teorema di Bayes applica la definizione di probabilit√† condizionata per fornire:\n\\[\nP(H_i \\mid O) = \\frac{P(O \\mid H_i)P(H_i)}{\\sum_{j=1}^{\\infty}P(O \\mid H_j)P(H_j)},\n\\]\ndove \\(P(O \\mid H_i)\\) √® la probabilit√† di osservare \\(O\\) se \\(H_i\\) fosse vera, nota come verosimiglianza. La somma al denominatore aggrega lo stesso prodotto (la probabilit√† a priori e la verosimiglianza) su tutte le ipotesi in \\(\\mathcal{H}\\), garantendo che la probabilit√† a posteriori \\(P(H_i \\mid O)\\) sommi a 1 su tutte le ipotesi. Il numeratore √® cruciale nel teorema di Bayes, indicando che la nostra convinzione in un‚Äôipotesi dopo aver osservato i dati dovrebbe riflettere il prodotto della probabilit√† a priori di quell‚Äôipotesi e della probabilit√† dei dati se quell‚Äôipotesi fosse vera.\nIntuitivamente, il teorema di Bayes afferma che le nostre convinzioni sulle ipotesi dovrebbero basarsi su due fattori: la plausibilit√† delle ipotesi (rappresentata dalla probabilit√† a priori) e la loro compatibilit√† con i dati osservati (rappresentata dalla verosimiglianza). Questi due fattori contribuiscono in modo uguale e moltiplicativo: se uno dei due √® molto piccolo, l‚Äôaltro deve essere molto grande per compensare.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#derivazione",
    "href": "chapters/probability/05_bayes_theorem.html#derivazione",
    "title": "23¬† Il teorema di Bayes",
    "section": "24.2 Derivazione",
    "text": "24.2 Derivazione\nDeriviamo il teorema di Bayes nella situazione pi√π semplice, ovvero quella in cui lo spazio di tutte le ipotesi possibili \\(\\mathcal{H}\\) √® costituito da sole due ipotesi, che possiamo concepire come eventi distinti e mutualmente esclusivi che costituiscono una partizione di \\(\\mathcal{H}\\), denominate ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo di avere gi√† una certa comprensione di queste ipotesi, espressa attraverso le loro probabilit√† a priori \\(P(H_1)\\) e \\(P(H_2)\\). A questo punto, introduciamo un nuovo evento, l‚Äôosservazione \\(O\\), la cui occorrenza √® accompagnata da una probabilit√† non nulla e per il quale conosciamo le probabilit√† condizionate \\(P(O \\mid H_1)\\) e \\(P(O \\mid H_2)\\), che indicano quanto sia probabile osservare \\(O\\) assumendo che una delle due ipotesi sia vera. Se \\(O\\) si verifica, siamo interessati a determinare le probabilit√† a posteriori \\(P(H_1 \\mid O)\\) e \\(P(H_2 \\mid O)\\) delle nostre ipotesi alla luce di questa nuova evidenza.\nLa seguente illustrazione rappresenta la suddivisione dello spazio totale delle ipotesi \\(\\mathcal{H}\\) nelle ipotesi \\(H_1\\) e \\(H_2\\), con l‚Äôevento corrispondente all‚Äôosservazione \\(O\\) posizionata all‚Äôinterno di questo spazio.\n\n\n\n\n\n\n\n\n\nPer calcolare la probabilit√† a posteriori dell‚Äôipotesi \\(H_1\\) data l‚Äôosservazione di \\(O\\), utilizziamo la formula:\n\\[\nP(H_1 \\mid O) = \\frac{P(O \\cap H_1)}{P(O)}.\n\\]\nQuesto calcolo pu√≤ essere semplificato sfruttando la definizione di probabilit√† condizionata, che ci permette di sostituire \\(P(O \\cap H_1)\\) con \\(P(O \\mid H_1)P(H_1)\\). Applicando questa sostituzione, otteniamo:\n\\[\nP(H_1 \\mid O) = \\frac{P(O \\mid H_1) P(H_1)}{P(O)}.\n\\]\nDato che \\(H_1\\) e \\(H_2\\) si escludono a vicenda, la probabilit√† totale di \\(O\\) pu√≤ essere espressa come la somma delle probabilit√† di \\(O\\) occorrente in concomitanza con ciascuna ipotesi, utilizzando il teorema della probabilit√† totale:\n\\[\nP(O) = P(O \\mid H_1)P(H_1) + P(O \\mid H_2)P(H_2).\n\\]\nIncorporando questi valori nella formula di Bayes, giungiamo a:\n\\[\nP(H_1 \\mid O) = \\frac{P(O \\mid H_1)P(H_1)}{P(O \\mid H_1)P(H_1) + P(O \\mid H_2)P(H_2)}.\n\\tag{24.1}\\]\nQuesta espressione costituisce l‚Äôessenza della formula di Bayes per il caso semplificato in cui le ipotesi si limitano a due eventi mutualmente esclusivi, \\(H_1\\) e \\(H_2\\).\nLa stessa derivazione pu√≤ essere presentata in forma visiva nel modo seguente.\n\n\n\nDerivazione visiva del teorema di Bayes (immagine ricavata da X).\n\n\nNel quadro delle probabilit√† discrete, questa formula pu√≤ essere generalizzata per accogliere un insieme pi√π ampio di ipotesi che formano una partizione completa dello spazio degli eventi \\(\\mathcal{H}\\), dove ogni \\(O\\) rappresenta un evento con probabilit√† maggiore di zero. Per ogni ipotesi \\(H_i\\) all‚Äôinterno di un insieme numerabile, la formula di Bayes si estende come segue:\n\\[\nP(H_i \\mid O) = \\frac{P(O \\mid H_i)P(H_i)}{\\sum_{j=1}^{\\infty}P(O \\mid H_j)P(H_j)}.\n\\tag{24.2}\\]\nQui, il denominatore agisce come un fattore di normalizzazione che integra i prodotti delle probabilit√† a priori e delle verosimiglianze associate a ogni ipotesi considerata.\nPer variabili continue, la formula di Bayes assume una forma integrale, adattandosi a situazioni in cui le ipotesi \\(H_i\\) rappresentano valori in un continuum. In questo contesto, la formula diventa\n\\[\nP(H_i \\mid O) = \\frac{P(O \\mid H_i) \\cdot P(H_i)}{\\int P(O \\mid H) \\cdot P(H) \\, dH}\n\\tag{24.3}\\]\ne consente di aggiornare le probabilit√† a posteriori di ipotesi continue basate su nuove evidenze.\nIn sintesi, la formula di Bayes si articola in tre elementi fondamentali:\n\nProbabilit√† a Priori, \\(P(H_i)\\): Questa componente riflette la nostra valutazione preliminare riguardo la verosimiglianza dell‚Äôipotesi \\(H_i\\) prima di prendere in esame nuove evidenze \\(O\\). Essa incarna il livello di credibilit√† o fiducia attribuita all‚Äôipotesi, basandosi su conoscenze preesistenti. In sostanza, la probabilit√† a priori quantifica le nostre convinzioni pregresse o le aspettative iniziali su quanto sia probabile che l‚Äôipotesi \\(H_i\\) sia vera.\nProbabilit√† a Posteriori, \\(P(H_i \\mid O)\\): Questo valore aggiorna la nostra fiducia nell‚Äôipotesi \\(H_i\\) in seguito all‚Äôosservazione dell‚Äôevidenza \\(O\\). Rappresenta il livello di convinzione ricalibrato in \\(H_i\\) dopo aver considerato l‚Äôevidenza \\(O\\). La formula di Bayes ci offre un metodo per modulare questa probabilit√† alla luce delle nuove informazioni ricevute.\nVerosimiglianza, \\(P(O \\mid H_i)\\): La verosimiglianza esprime la probabilit√† di rilevare l‚Äôevidenza \\(O\\) dato che l‚Äôipotesi \\(H_i\\) sia vera. √à un indice di quanto l‚Äôevidenza supporti o confermi l‚Äôipotesi \\(H_i\\). Un valore elevato di verosimiglianza indica che l‚Äôevidenza √® fortemente in linea o prevista dalla veridicit√† dell‚Äôipotesi.\n\nGrazie alla formula di Bayes, possiamo adottare un processo di aggiornamento continuo delle nostre credenze in base a nuove informazioni, promuovendo un metodo dinamico per navigare tra conoscenza e incertezza. Questa metodologia ci fornisce un approccio strutturato per rivedere e adattare le nostre convinzioni riguardo l‚Äôipotesi \\(H_i\\) di fronte a nuove evidenze \\(O\\). La capacit√† di rielaborare costantemente le nostre aspettative in funzione di informazioni aggiuntive ci consente di prendere decisioni pi√π informate, di interpretare con maggiore precisione i dati disponibili e di affinare le nostre previsioni e comprensioni del mondo circostante.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#alcuni-esempi",
    "href": "chapters/probability/05_bayes_theorem.html#alcuni-esempi",
    "title": "23¬† Il teorema di Bayes",
    "section": "24.3 Alcuni esempi",
    "text": "24.3 Alcuni esempi\n\nEsempio 24.1 Il modo pi√π comune per spiegare il teorema di Bayes √® attraverso i test medici. Prendiamo come esempio la mammografia e la diagnosi del cancro al seno.\nSupponiamo di avere un test di mammografia con una sensibilit√† del 90% e una specificit√† del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilit√† che il test lo rilevi correttamente √® del 90%.\nIn assenza di cancro al seno, la probabilit√† che il test confermi correttamente l‚Äôassenza della malattia √® del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch‚Äôesso del 10%.\nDefiniamo due ipotesi:\n\n\\(M^+\\): presenza della malattia\n\\(M^-\\): assenza della malattia\n\nL‚Äôevidenza √® rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilit√† di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) √® la probabilit√† di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilit√† del test, ovvero la probabilit√† che il test risulti positivo in presenza effettiva del cancro. In questo caso, √® pari a 0.90.\n\\(P(M^+)\\) √® la probabilit√† a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\\(P(T^+ \\mid M^-)\\) indica la probabilit√† di un falso positivo, cio√® la probabilit√† che il test risulti positivo in assenza di cancro. Con una specificit√† del 90%, questa probabilit√† si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificit√†} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c‚Äô√® una probabilit√† del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\\(P(M^-)\\) √® la probabilit√† a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilit√† effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilit√† e specificit√† del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nQuesto calcolo dimostra che, considerando una mammografia con risultato positivo ottenuto tramite un test con una sensibilit√† del 90% e una specificit√† del 90%, la probabilit√† che il paziente sia effettivamente affetto da cancro al seno √® solo dell‚Äô8.3%.\n\n\n24.3.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicit√†, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ci√≤ che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi √® fondamentale per questo calcolo: la prevalenza della malattia, la sensibilit√† e la specificit√† del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\nSensibilit√†: Indica la capacit√† del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilit√† (\\(Sens\\)) √® la seguente:\n\\[ \\text{Sensibilit√†} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilit√† misura la probabilit√† che il test risulti positivo se la malattia √® effettivamente presente.\nSpecificit√†: Misura la capacit√† del test di riconoscere gli individui sani, producendo un risultato negativo per chi non √® affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificit√† (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificit√†} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Cos√¨, la specificit√† rappresenta la probabilit√† che il test risulti negativo in assenza della malattia.\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\n\\(M^+\\)\n\\(P(T^+ \\cap M^+)\\)  (Sensibilit√†)\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilit√†)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificit√†)\n\\(P(T^- \\cap M^-)\\)  (Specificit√†)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilit√† totale di avere la malattia (\\(P(M^+)\\)) e la probabilit√† totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna riga.\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilit√† totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilit√† totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilit√† all‚Äôinterno di ciascuna colonna.\nTotale generale (angolo in basso a destra): La somma di tutte le probabilit√†, che per definizione √® 1, rappresentando l‚Äôintera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilit√† post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cio√® la probabilit√† post-test che un individuo sia malato dato un risultato positivo del test, √® calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilit√†} \\times \\text{Prevalenza})}{(\\text{Sensibilit√†} \\times \\text{Prevalenza}) + (1 - \\text{Specificit√†}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che √® la probabilit√† che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificit√†} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificit√†} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilit√†}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 24.2 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in Python e usiamo gli stessi dati dell‚Äôesercizio precedente.\n\ndef positive_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n\n\ndef negative_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilit√†\nspec = 0.9  # specificit√†\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo √®:\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.083\n\n\nIl valore predittivo del test negativo √®:\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\n\n\nEsempio 24.3 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test pu√≤ essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L‚ÄôIstituto Superiore di Sanit√†, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilit√† varia tra il 70% e l‚Äô86%, mentre la specificit√† si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus √® stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n\n0.002349135593220339\n\n\nL‚Äôobiettivo √® determinare la probabilit√† di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\nsens = (0.7 + 0.86) / 2  # sensibilit√†\nspec = (0.95 + 0.97) / 2 # specificit√†\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.044\n\n\nPertanto, se il risultato del tampone √® positivo, la probabilit√† di essere effettivamente affetti da Covid-19 √® solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cio√®, pari al 23.5%), la probabilit√† di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l‚Äô86%.\n\nprev = 138599 / 59000000 * 100\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.857\n\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilit√† di non essere infetto sarebbe del 99.9%.\n\nsens = (0.7 + 0.86) / 2  # sensibilit√†\nspec = (0.95 + 0.97) / 2  # specificit√†\nprev = 138599 / 59000000  # prevalenza\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\nTuttavia, un‚Äôesito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia √® molto bassa; in altre parole, il risultato negativo conferma una situazione gi√† presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell‚Äôasserire l‚Äôassenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 24.4 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell‚Äôinterpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un‚Äôaccuratezza del 99%, la sua affidabilit√† varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\nSensibilit√†:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\nSpecificit√†: circa 99.9% per tutte le condizioni citate\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\nNonostante l‚Äôalta sensibilit√† e specificit√†, il VPP pu√≤ essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni pi√π rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilit√†} \\times \\text{Prevalenza})}{(\\text{Sensibilit√†} \\times \\text{Prevalenza}) + (1 - \\text{Specificit√†}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilit√† che un risultato positivo sia effettivamente corretto dipende non solo dall‚Äôaccuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta pi√π affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT √® uno strumento prezioso per lo screening prenatale, √® fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.\n\n\nEsempio 24.5 Il teorema di Bayes non √® rilevante solo in medicina. In ambito legale √® presente un fenomeno noto come la Fallacia del Procuratore. La ‚Äúfallacia del procuratore‚Äù √® un errore logico che si verifica quando si confonde la probabilit√† di un evento dato un certo risultato con la probabilit√† di quel risultato dato l‚Äôevento. In ambito legale, si tratta spesso di confondere la probabilit√† di ottenere un risultato di un test (ad esempio, una corrispondenza del DNA) se una persona √® innocente, con la probabilit√† che una persona sia innocente dato che il test ha mostrato una corrispondenza.\nSupponiamo di avere i seguenti parametri per un test del DNA:\n\nSensibilit√†: 99% (probabilit√† di identificare correttamente il colpevole).\nSpecificit√†: 99.99997% (probabilit√† di identificare correttamente un innocente).\nPrevalenza: 1 su 65 milioni (probabilit√† a priori che una persona qualsiasi sia il colpevole, data una popolazione di 65 milioni).\n\nImmaginiamo che ci sia stato un crimine e che un campione di DNA sia stato trovato sulla scena del crimine. Il campione √® confrontato con il DNA di una persona nel database.\nSvolgiamo i calcoli:\n\nProbabilit√† a Priori (Prevalenza):\n\nLa prevalenza \\(P(C)\\) che una persona casuale sia il colpevole √® \\(\\frac{1}{65.000.000}\\).\n\nSensibilit√† e Specificit√†:\n\nSensibilit√† \\(P(T+|C) = 0.99\\).\nSpecificit√† \\(P(T-|I) = 0.9999997\\).\n\nProbabilit√† del Test Positivo:\n\nProbabilit√† di ottenere un test positivo \\(P(T+)\\) √® la somma della probabilit√† di ottenere un positivo dai veri colpevoli e dai falsi positivi:\n\n\n\\[ P(T+) = P(T+|C) \\cdot P(C) + P(T+|I) \\cdot P(I), \\]\n\ndove \\(P(T+|I)\\) √® \\(1 - \\text{Specificit√†}\\) e \\(P(I)\\) √® la probabilit√† di essere innocente (\\(1 - P(C)\\)).\n\n\\[ P(T+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000} \\]\n\\[ P(T+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999 \\]\n\\[ P(T+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7} \\]\n\\[ P(T+) \\approx 3.1523 \\times 10^{-7} \\]\n\nProbabilit√† Condizionale che il Sospetto sia Colpevole Dato un Test Positivo:\n\nUtilizzando il teorema di Bayes:\n\n\n\\[ P(C|T+) = \\frac{P(T+|C) \\cdot P(C)}{P(T+)} \\]\n\\[ P(C|T+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) = \\frac{0.99 \\times 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) \\approx 0.0483 \\]\nQuindi, la probabilit√† che il sospetto sia effettivamente il colpevole, dato che il test del DNA √® positivo, √® circa 4.83%, nonostante l‚Äôalta specificit√† del test.\nIn sintesi, quando si afferma che c‚Äô√® solo una probabilit√† su 3 milioni che il sospetto sia innocente (ovvero la specificit√†), si commette la fallacia del procuratore. In realt√†, la probabilit√† che il sospetto sia colpevole, data una corrispondenza del DNA, √® molto inferiore, come dimostrato nell‚Äôesempio numerico (circa 4.83%).\nQuesta fallacia pu√≤ portare a errori giudiziari perch√© non si considera la bassa prevalenza del colpevole nella popolazione generale e si confonde la specificit√† del test con la probabilit√† condizionale di colpevolezza. In altre parole, non si riconosce che le due domande ‚ÄòQuanto √® probabile che il DNA di una persona corrisponda al campione, se √® innocente?‚Äô e ‚ÄòQuanto √® probabile che qualcuno sia innocente, dato che il suo DNA corrisponde al campione?‚Äô non sono equivalenti. √à come confondere ‚ÄòQuanto √® probabile che un determinato essere umano sia il papa?‚Äô con ‚ÄòQuanto √® probabile che il papa sia un essere umano?‚Äô.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#probabilit√†-inversa",
    "href": "chapters/probability/05_bayes_theorem.html#probabilit√†-inversa",
    "title": "23¬† Il teorema di Bayes",
    "section": "24.4 Probabilit√† Inversa",
    "text": "24.4 Probabilit√† Inversa\nGli esempi precedenti mettono in luce che possiamo distinguere due domande diverse. La prima domanda √®: ‚ÄúQual √® la probabilit√† dell‚Äôevidenza, data l‚Äôipotesi?‚Äù La seconda domanda √®: ‚ÄúQual √® la probabilit√† che l‚Äôipotesi sia vera, data l‚Äôevidenza?‚Äù\nUn esempio per rispondere alla prima domanda √® il seguente: Supponiamo che la probabilit√† di ottenere testa nel lancio di una moneta sia 0.5 (questa √® l‚Äôipotesi). Qual √® la probabilit√† di ottenere 0 volte testa in cinque lanci?\nUn esempio per rispondere alla seconda domanda √® il seguente: Supponiamo di avere ottenuto 0 volte testa in 5 lanci di una moneta (questa √® l‚Äôevidenza). Ci chiediamo: qual √® la probabilit√† che la moneta sia bilanciata, alla luce delle nostre osservazioni?\nPer molto tempo, la storia della probabilit√† si √® concentrata sulla prima domanda. Ma dopo che il reverendo Thomas Bayes ha iniziato a porsi la seconda domanda nel XVIII secolo, questa √® diventata nota come probabilit√† inversa.\nQuesto modo di pensare ha suscitato molte controversie nel corso della storia della statistica, forse perch√© influisce su tutto. In particolare, ci si pu√≤ chiedere la seguente domanda: quanto √® probabile che un‚Äôipotesi scientifica sia vera, dato il risultato di uno studio? Per stimare questa probabilit√†, e un numero crescente di scienziati sostiene che √® esattamente ci√≤ che dovrebbero fare le statistiche, abbiamo bisogno di Bayes e delle probabilit√† a priori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/05_bayes_theorem.html#commenti-e-considerazioni-finali",
    "title": "23¬† Il teorema di Bayes",
    "section": "24.5 Commenti e Considerazioni Finali",
    "text": "24.5 Commenti e Considerazioni Finali\nIn questo capitolo abbiamo analizzato vari esempi nel campo medico e forense, dimostrando come il teorema di Bayes consenta di combinare le informazioni provenienti dalle osservazioni con le nostre conoscenze precedenti (priori) per aggiornare il nostro grado di convinzione rispetto a un‚Äôipotesi. Il teorema di Bayes offre un meccanismo razionale, noto come ‚Äúaggiornamento bayesiano‚Äù, per ricalibrare le nostre convinzioni iniziali in risposta a nuove evidenze.\nIl teorema di Bayes ci insegna che, nella ricerca scientifica come nella vita quotidiana, non siamo tanto interessati a conoscere la probabilit√† che qualcosa accada assumendo vera un‚Äôipotesi. Siamo invece interessati alla domanda opposta: qual √® la probabilit√† che un‚Äôipotesi sia vera, dato che abbiamo osservato una certa evidenza?\nIn questo capitolo, ci siamo concentrati sull‚Äôanalisi del teorema di Bayes utilizzando probabilit√† puntuali. Tuttavia, vedremo in seguito che il teorema di Bayes esprime pienamente il suo potenziale esplicativo quando l‚Äôevidenza e i gradi di certezza a priori delle ipotesi sono rappresentati in termini di distribuzioni di probabilit√† continue. Questo sar√† l‚Äôargomento del Capitolo 33.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "23¬† Il teorema di Bayes",
    "section": "24.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "24.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\narviz     : 0.17.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nChivers, Tom. 2024. Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>23</span>¬† <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html",
    "href": "chapters/probability/06_random_var.html",
    "title": "24¬† Variabili casuali",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, introdurremo il concetto di variabili casuali e delle loro distribuzioni di probabilit√†, ampliando ulteriormente l‚Äôambito delle analisi matematiche degli eventi considerati finora.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#definizione",
    "href": "chapters/probability/06_random_var.html#definizione",
    "title": "24¬† Variabili casuali",
    "section": "24.1 Definizione",
    "text": "24.1 Definizione\nLe variabili aleatorie sono uno strumento fondamentale nella teoria della probabilit√†. Esse ci permettono di passare da risultati qualitativi (come \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\)) a valori numerici, facilitando l‚Äôanalisi matematica.\nIn termini formali, una variabile casuale √® definita come una funzione che mappa ogni elemento di uno spazio campionario \\(S\\) a un valore in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione permette di esprimere numericamente gli esiti di un fenomeno aleatorio, associando un valore specifico a ciascun possibile risultato dell‚Äôesperimento.\n\nEsempio 24.1 Un esempio √® la variabile casuale \\(X\\) che rappresenta il risultato di un lancio di dado. Se definiamo \\(X = 1\\) per indicare che il risultato del lancio √® un numero dispari (1, 3 o 5) e \\(X = 0\\) per indicare che il risultato del lancio √® un numero pari (2, 4 o 6), abbiamo trasformato un‚Äôosservazione fisica (il lancio del dado) in un valore numerico che rappresenta un certo tipo di evento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/06_random_var.html#tipologie-di-variabili-casuali",
    "title": "24¬† Variabili casuali",
    "section": "24.2 Tipologie di Variabili Casuali",
    "text": "24.2 Tipologie di Variabili Casuali\nLe variabili casuali possono essere suddivise in due categorie principali: discrete e continue. Una variabile casuale discreta assume valori all‚Äôinterno di un insieme finito o al massimo numerabile, il che significa che i suoi possibili esiti possono essere contati, anche se l‚Äôinsieme √® infinito. Al contrario, una variabile casuale continua pu√≤ assumere un‚Äôinfinit√† di valori all‚Äôinterno di un intervallo, essendo in grado di coprire ogni punto di quell‚Äôintervallo senza interruzioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#convenzioni-notazionali",
    "href": "chapters/probability/06_random_var.html#convenzioni-notazionali",
    "title": "24¬† Variabili casuali",
    "section": "24.3 Convenzioni Notazionali",
    "text": "24.3 Convenzioni Notazionali\nNella teoria della probabilit√†, √® usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come \\(X\\), per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D‚Äôaltro canto, la corrispondente lettera minuscola, \\(x\\) nel nostro esempio, √® impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale pu√≤ assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (\\(X\\)) o di un suo specifico valore (\\(x\\)).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/06_random_var.html#variabili-casuali-multiple",
    "title": "24¬† Variabili casuali",
    "section": "24.4 Variabili casuali multiple",
    "text": "24.4 Variabili casuali multiple\nNella teoria della probabilit√†, le variabili casuali spesso interagiscono o si combinano tra loro. Consideriamo l‚Äôesempio di tre lanci di una moneta bilanciata, rappresentati da variabili casuali indipendenti \\(X_1\\), \\(X_2\\), e \\(X_3\\). Per ogni lancio:\n\n\\(P(X_n = 1)\\) (testa) = 0.5,\n\\(P(X_n = 0)\\) (croce) = 0.5,\n\ndove \\(n = 1, 2, 3\\).\nCombinando queste variabili, possiamo creare nuove variabili casuali. Ad esempio, definiamo \\(Z\\) come la somma dei risultati:\n\\[\nZ = X_1 + X_2 + X_3.\n\\]\n\\(Z\\) √® una variabile casuale discreta che rappresenta il numero totale di teste ottenute nei tre lanci. I suoi possibili valori sono 0, 1, 2, e 3.\nQuesto esempio illustra come variabili casuali indipendenti possano essere combinate per creare nuove variabili casuali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#sec-fun-mass-prob",
    "href": "chapters/probability/06_random_var.html#sec-fun-mass-prob",
    "title": "24¬† Variabili casuali",
    "section": "24.5 Distribuzione di Probabilit√†",
    "text": "24.5 Distribuzione di Probabilit√†\nLa distribuzione di probabilit√† √® un concetto fondamentale nella teoria della probabilit√†, che descrive come le probabilit√† si distribuiscono tra i possibili esiti di una variabile casuale. La sua rappresentazione varia a seconda che si tratti di variabili casuali discrete o continue.\n\n24.5.1 Variabili Casuali Discrete\nPer le variabili casuali discrete, che assumono valori specifici e contabili, la distribuzione di probabilit√† √® rappresentata dalla funzione di massa di probabilit√†, indicata come \\(P(\\cdot)\\).\n\n24.5.1.1 Funzione di Massa di Probabilit√†\nLa funzione di massa di probabilit√† assegna una probabilit√† precisa a ciascun possibile esito della variabile casuale discreta. Ad esempio, per il lancio di un dado equilibrato:\n\\(P(Y = 1) = \\frac{1}{6}\\).\nQuesto significa che la probabilit√† di ottenere ‚Äú1‚Äù in un singolo lancio √® 1/6.\n\n\n24.5.1.2 Istogrammi per Variabili Discrete\nGli istogrammi sono strumenti visivi efficaci per rappresentare la distribuzione di probabilit√† delle variabili casuali discrete. Per queste variabili, possiamo impostare ciascun bin dell‚Äôistogramma in modo che copra un singolo valore della variabile casuale. L‚Äôaltezza di ogni bin corrisponde alla probabilit√† di quel valore specifico.\nGli istogrammi ci permettono di identificare rapidamente caratteristiche importanti della distribuzione, come:\n\nunimodalit√†: concentrazione attorno a un singolo punto;\nmultimodalit√†: concentrazione attorno a pi√π punti;\nsimmetria o asimmetria della distribuzione;\ndispersione dei valori.\n\n\n\n\n24.5.2 Variabili Casuali Continue\nPer le variabili casuali continue, che possono assumere un‚Äôinfinit√† di valori in un intervallo, si utilizza la funzione di densit√† di probabilit√†, indicata come \\(p(\\cdot)\\).\n\n24.5.2.1 Funzione di Densit√† di Probabilit√†\nLa funzione di densit√† di probabilit√† non assegna probabilit√† a singoli valori (che sarebbe zero per una variabile continua), ma determina la probabilit√† che la variabile si trovi all‚Äôinterno di un intervallo specifico.\n\n\n24.5.2.2 Istogrammi per Variabili Continue\nAnche per le variabili continue possiamo usare istogrammi, ma in questo caso i bin devono sempre coprire intervalli di valori. Riducendo progressivamente la larghezza dei bin, il profilo dell‚Äôistogramma tende a coincidere con la funzione di densit√† di probabilit√† della variabile casuale.\n\n\n\n24.5.3 Supporto della Variabile Casuale\nIl supporto di una variabile casuale √® l‚Äôinsieme di tutti i valori che la variabile pu√≤ effettivamente assumere. Ad esempio:\n\nper un dado a sei facce: {1, 2, 3, 4, 5, 6};\nper una distribuzione gaussiana: l‚Äôintero insieme dei numeri reali.\n\n\n\n24.5.4 Assegnazione di Probabilit√†\n\nPer variabili discrete: si specifica la probabilit√† di ogni possibile valore.\nPer variabili continue: si utilizza la densit√† di probabilit√† per calcolare la probabilit√† di intervalli di valori.\n\nLa distribuzione di probabilit√†, sia per variabili discrete che continue, fornisce una descrizione completa del comportamento probabilistico della variabile casuale, permettendo analisi e previsioni accurate in vari campi di applicazione.\n\nEsempio 24.2 Consideriamo l‚Äôesperimento casuale costituito dal lancio di due dadi equilibrati. Definiamo la variabile casuale \\(X\\) come la somma dei punti ottenuti dai due dadi.\nLo spazio campionario \\(S\\) √® l‚Äôinsieme di tutte le possibili coppie ordinate \\((a,b)\\), dove \\(a\\) e \\(b\\) rappresentano i risultati del primo e del secondo dado rispettivamente:\n\\[\nS = {(1,1), (1,2), ..., (1,6), (2,1), (2,2), ..., (2,6), ..., (6,1), (6,2), ..., (6,6)}.\n\\]\nIn totale, ci sono 6 √ó 6 = 36 possibili esiti.\nLa variabile casuale \\(X\\) √® definita come la somma dei punti dei due dadi. Quindi:\n\\[\nX = a + b, \\quad \\text{dove } (a,b) \\in S.\n\\]\n\\(X\\) pu√≤ assumere valori interi da 2 (1+1) a 12 (6+6).\nLa distribuzione della variabile casuale \\(X\\) √® una funzione che associa a ogni possibile valore di \\(X\\) la sua probabilit√†. In questo caso, poich√© \\(X\\) √® discreta, usiamo una funzione di massa di probabilit√†.\nPer calcolare la probabilit√† di ogni valore di \\(X\\), contiamo il numero di casi favorevoli e lo dividiamo per il numero totale di casi possibili (36).\n\n\n\n\n\n\n\n\n\nX\nCasi favorevoli\nNumero di casi\nProbabilit√† P(X = x)\n\n\n\n\n2\n(1,1)\n1\n1/36\n\n\n3\n(1,2), (2,1)\n2\n2/36 = 1/18\n\n\n4\n(1,3), (2,2), (3,1)\n3\n3/36 = 1/12\n\n\n5\n(1,4), (2,3), (3,2), (4,1)\n4\n4/36 = 1/9\n\n\n6\n(1,5), (2,4), (3,3), (4,2), (5,1)\n5\n5/36\n\n\n7\n(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\n6\n6/36 = 1/6\n\n\n8\n(2,6), (3,5), (4,4), (5,3), (6,2)\n5\n5/36\n\n\n9\n(3,6), (4,5), (5,4), (6,3)\n4\n4/36 = 1/9\n\n\n10\n(4,6), (5,5), (6,4)\n3\n3/36 = 1/12\n\n\n11\n(5,6), (6,5)\n2\n2/36 = 1/18\n\n\n12\n(6,6)\n1\n1/36\n\n\n\nQuesta tabella rappresenta la distribuzione completa della variabile casuale \\(X\\).\nIn conclusione, la distribuzione di una variabile casuale discreta, come nell‚Äôesempio della somma dei punti di due dadi, fornisce una descrizione completa delle propriet√† probabilistiche della variabile. Essa associa a ogni possibile valore della variabile la sua probabilit√† di verificarsi.\nIn questo caso, la distribuzione ci dice, per esempio, che la probabilit√† di ottenere una somma di 7 √® 1/6, la pi√π alta tra tutti i possibili risultati. Questo √® dovuto al fatto che ci sono pi√π combinazioni che producono una somma di 7 rispetto a qualsiasi altro risultato.\nLa distribuzione ci permette di rispondere a domande come:\n\nQual √® la probabilit√† di ottenere una somma pari? (Sommando le probabilit√† di 2, 4, 6, 8, 10, 12).\nQual √® la probabilit√† di ottenere una somma maggiore o uguale a 10? (Sommando le probabilit√† di 10, 11, 12).\n\nLa distribuzione di massa di probabilit√† della variabile casuale \\(X\\) pu√≤ essere rappresentata visivamente utilizzando un istogramma. Un istogramma permette di vedere immediatamente la probabilit√† associata a ciascun valore di \\(X\\), rendendo chiaro quali risultati sono pi√π probabili e quali lo sono meno.\nLe istruzioni Python necessarie per generare questo istogramma sono fornite di seguito.\n\n\n# Valori possibili della variabile casuale X\nvalori_X = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n\n# Probabilit√† associate a ciascun valore di X\nprobabilita_X = [\n    1 / 36,\n    2 / 36,\n    3 / 36,\n    4 / 36,\n    5 / 36,\n    6 / 36,\n    5 / 36,\n    4 / 36,\n    3 / 36,\n    2 / 36,\n    1 / 36,\n]\n\n# Creazione dell'istogramma\nplt.bar(valori_X, probabilita_X, alpha = 0.5, edgecolor=\"black\")\nplt.xlabel(\"Valore della variabile casuale X\")\nplt.ylabel(\"Probabilit√† P(X = x)\")\nplt.title(\"Distribuzione di Massa di Probabilit√† della Variabile Casuale X\")\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "href": "chapters/probability/06_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "title": "24¬† Variabili casuali",
    "section": "24.6 Funzione di Distribuzione Cumulativa (CDF)",
    "text": "24.6 Funzione di Distribuzione Cumulativa (CDF)\nLa Funzione di Distribuzione Cumulativa (CDF) √® uno strumento fondamentale nella teoria della probabilit√† per descrivere la distribuzione di una variabile casuale.\n\n24.6.1 Definizione\nPer una variabile casuale \\(X\\), la funzione di distribuzione cumulativa \\(F(x)\\) √® definita come:\n\\[\nF(x) = P(X \\leq x),\n\\]\ndove:\n\n\\(X\\) √® la variabile casuale.\n\\(P(X \\leq x)\\) rappresenta la probabilit√† che \\(X\\) assuma un valore minore o uguale a \\(x\\).\n\nIn altre parole, \\(F(x)\\) quantifica la probabilit√† cumulativa dall‚Äôestremo inferiore dello spazio di probabilit√† fino al punto \\(x\\).\n\n\n24.6.2 Propriet√† della CDF\n\nMonotonia non decrescente:\n\nPer \\(x_1 &lt; x_2\\), \\(F(x_1) \\leq F(x_2)\\).\nLa CDF non diminuisce mai quando ci si sposta da sinistra a destra lungo l‚Äôasse \\(x\\).\n\nNormalizzazione:\n\n\\(\\lim_{{x \\to -\\infty}} F(x) = 0 \\quad \\text{e} \\quad \\lim_{{x \\to +\\infty}} F(x) = 1\\).\nLa CDF parte da 0 quando \\(x\\) tende a \\(-\\infty\\) e raggiunge 1 quando \\(x\\) tende a \\(+\\infty\\).\n\nContinuit√† a destra:\n\n\\(F(x) = \\lim_{{y \\to x^+}} F(y)\\).\nLa CDF √® continua da destra, il che significa che non presenta salti improvvisi quando ci si avvicina a un punto da destra.\n\n\n\n\n24.6.3 CDF per Variabili Casuali Discrete\nPer una variabile casuale discreta \\(X\\), la CDF (anche chiamata funzione di ripartizione cumulativa) √® definita come:\n\\[\nF(x) = P(X \\leq x) = \\sum_{x_i \\leq x} P(X = x_i),\n\\]\ndove la somma √® calcolata su tutti i valori \\(x_i\\) minori o uguali a \\(x\\).\n\n\n24.6.4 Importanza e Applicazioni\n\nLa CDF offre una rappresentazione visiva di come le probabilit√† si accumulano lungo l‚Äôintero intervallo dei possibili valori della variabile casuale.\nLa CDF permette di calcolare facilmente la probabilit√† che \\(X\\) cada in un intervallo specifico:\n\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\nLa CDF √® utilizzata in vari metodi di generazione di variabili casuali, come il metodo della trasformazione inversa.\nLe CDF facilitano il confronto tra diverse distribuzioni di probabilit√†, consentendo di valutare differenze nelle loro caratteristiche cumulative.\n\nIn conclusione, la CDF √® uno strumento versatile e potente che fornisce una descrizione completa della distribuzione di probabilit√† di una variabile casuale, sia essa discreta o continua.\n\nEsempio 24.3 Nel caso del lancio di due dadi, con la variabile casuale \\(Z\\) definita come la somma dei loro valori, la funzione di distribuzione cumulativa \\(F(z)\\) pu√≤ essere illustrata come segue:\n\n\n\n\\(z\\)\n\\(P(Z = z)\\)\n\\(F(z)\\)\n\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(\\frac{36}{36}\\)\n\n\n\nIn questa tabella:\n\n\\(P(Z = z)\\) rappresenta la probabilit√† che la somma dei due dadi sia esattamente \\(z\\).\n\\(F(z)\\) √® la funzione di distribuzione cumulativa, che fornisce la probabilit√† che la somma \\(Z\\) sia minore o uguale a \\(z\\).\n\nQuesta tabella mostra come le probabilit√† cumulative si accumulano per la variabile casuale \\(Z\\), evidenziando la distribuzione delle somme possibili quando si lanciano due dadi. Ad esempio, \\(F(7) = \\frac{21}{36}\\) indica che la probabilit√† che la somma sia 7 o inferiore √® \\(\\frac{21}{36}\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#trovare-la-distribuzione-di-probabilit√†-attraverso-una-simulazione",
    "href": "chapters/probability/06_random_var.html#trovare-la-distribuzione-di-probabilit√†-attraverso-una-simulazione",
    "title": "24¬† Variabili casuali",
    "section": "24.7 Trovare la Distribuzione di Probabilit√† attraverso una Simulazione",
    "text": "24.7 Trovare la Distribuzione di Probabilit√† attraverso una Simulazione\nLa distribuzione di probabilit√† che abbiamo calcolato in precedenza per il lancio di due dadi √® corretta, ma esiste un‚Äôalternativa per ottenere un risultato simile: la simulazione. Questo metodo consiste nel ripetere l‚Äôesperimento casuale un numero elevato di volte e analizzare le frequenze relative dei risultati ottenuti. In altre parole, simulando l‚Äôesperimento migliaia o milioni di volte, possiamo approssimare una distribuzione di probabilit√† empirica. Questa distribuzione empirica diventa sempre pi√π vicina a quella teorica man mano che aumentiamo il numero di ripetizioni.\nLa simulazione √® una tecnica ampiamente utilizzata in statistica, soprattutto quando la distribuzione di probabilit√† teorica √® difficile da calcolare o troppo complessa per essere trattata analiticamente. Attraverso la simulazione, possiamo esplorare le propriet√† di sistemi aleatori complessi e ottenere stime accurate delle probabilit√†, anche in situazioni in cui un approccio teorico diretto sarebbe impraticabile.\n\nEsempio 24.4 Nel Capitolo 2 abbiamo visto come creare una funzione che ritorna il risultato del lancio di un dado:\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return rng.choice([1, 2, 3, 4, 5, 6])\n\nPossiamo ora definire una funzione che ritorna la somma dei punti prodotti dal lancio di due dadi. La funzione ha come argomento il numero di ripetizioni di questo esperimento casuale.\n\ndef roll_two_dice(n):\n    \"\"\"\n    returns a random int between 2 and 12\n    \"\"\"\n    rolls = []\n    for i in range(n):\n        two_dice = roll_die() + roll_die()\n        rolls.append(two_dice)\n    \n    return rolls\n\nEseguiamo 100,000 ripetizioni dell‚Äôesperimento casuale e memorizzo i risultati ottenuti.\n\nnrolls = 100000\nres = roll_two_dice(nrolls)\nprint(*res[1:20])\n\n12 10 7 10 7 9 8 7 5 9 8 7 4 9 7 2 10 10 5\n\n\nCreiamo un DataFrame che contiene la variabile y corrispondente ai risultati delle 10,000 ripetizioni dell‚Äôesperimento casuale.\n\ndf = pd.DataFrame()\ndf[\"y\"] = res \n\nUtilizziamo dunque il metodo value_counts(), che pu√≤ essere applicato a un DataFrame, come abbiamo visto nel Capitolo 15, per trovare le frequenze assolute di ciascuno dei possibili risultati dell‚Äôesperimento casuale (cio√®, 2, 3, ‚Ä¶, 12). Dividendo per il numero totale delle ripetizioni, otterremo una stima empirica della probabilit√†. Si noti che i risultati saranno simili a quelli teorici ottenuti in precedenza.\n\nabs_freqs = df[\"y\"].value_counts().sort_index()\npx = abs_freqs / nrolls\nlist(zip(list(range(2, 13)), px))\n\n[(2, 0.02775),\n (3, 0.05625),\n (4, 0.08331),\n (5, 0.11109),\n (6, 0.13915),\n (7, 0.16824),\n (8, 0.13751),\n (9, 0.11167),\n (10, 0.08238),\n (11, 0.05567),\n (12, 0.02698)]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "24¬† Variabili casuali",
    "section": "24.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "24.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>24</span>¬† <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html",
    "href": "chapters/probability/07_expval_var.html",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "",
    "text": "Introduzione\nSintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici √® spesso molto utile. Questi indicatori consentono di cogliere le principali propriet√† della distribuzione, come la posizione centrale (ovvero il ‚Äúbaricentro‚Äù) e la variabilit√† (ossia la dispersione attorno al centro). In questo modo, √® possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilit√† della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le propriet√† di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#valore-atteso",
    "href": "chapters/probability/07_expval_var.html#valore-atteso",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "25.1 Valore Atteso",
    "text": "25.1 Valore Atteso\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo ‚Äúvalore tipico‚Äù. Tuttavia, questa nozione pu√≤ essere interpretata in diversi modi:\n\nMedia: La somma dei valori divisa per il numero dei valori.\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media √® \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana √® 3, e la moda √® 1. Tuttavia, quando ci occupiamo di variabili casuali, anzich√© di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per ‚Äúvalore tipico‚Äù in questo contesto. Questo ci porta alla definizione formale del valore atteso.\n\nDefinizione 25.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilit√† \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), √® definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale √® la somma di tutti i valori che la variabile pu√≤ assumere, ciascuno ponderato dalla probabilit√† con cui esso si verifica.\n\nEsempio 25.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 25.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nCome abbiamo visto nel Capitolo 24, \\(X\\) pu√≤ assumere i valori [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] con una distribuzione di massa di probabilit√† pari a [1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36]. Applicando la formula del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{11} x_i \\cdot P(x_i) = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + \\dots + 12 \\cdot \\frac{1}{36} = 7.0.\n\\]\n\n\nEsempio 25.3 Vediamo ora come eseguire i calcoli del valore atteso utilizzando Python. Per prima cosa, definiamo i valori della variabile casuale e li trasformiamo in un array NumPy:\n\nx = np.array(list(range(2, 13)))\nx\n\narray([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n\n\nSuccessivamente, calcoliamo la distribuzione di massa della variabile casuale \\(X\\), come visto nel Capitolo 19.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\n\npx = []\n\nfor i in range(2, 13):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n\npx = np.array(px)\npx\n\narray([0.02777778, 0.05555556, 0.08333333, 0.11111111, 0.13888889,\n       0.16666667, 0.13888889, 0.11111111, 0.08333333, 0.05555556,\n       0.02777778])\n\n\nOra, possiamo calcolare il valore atteso di \\(X\\) utilizzando la formula del valore atteso per variabili casuali discrete:\n\nex = np.sum(x * px)\nex.round(3)\n\n7.0\n\n\nIn alternativa, possiamo utilizzare le funzioni del modulo rv_discrete della libreria scipy.stats per ottenere il valore atteso:\n\nx = np.arange(2, 13)\npx = np.array([1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36])\nX = stats.rv_discrete(values=(x, px))\n\nUna volta definito l‚Äôoggetto \\(X\\) con rv_discrete(), possiamo calcolare il valore atteso utilizzando la funzione expect():\n\nx_ev = X.expect()\nround(x_ev, 3)\n\n7.0\n\n\nQuesti metodi dimostrano come sia possibile calcolare il valore atteso di una variabile casuale sia attraverso un approccio diretto con NumPy, sia utilizzando gli strumenti avanzati di scipy.stats.\n\n\n25.1.1 Interpretazione\nIl valore atteso di una variabile casuale corrisponde alla media aritmetica di un ampio numero di realizzazioni indipendenti della variabile stessa.\nPer chiarire questo concetto, consideriamo nuovamente l‚Äôesempio del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la ‚Äúsomma dei due dadi‚Äù. Per interpretare il valore atteso, possiamo simulare un grande numero di realizzazioni indipendenti di \\(X\\) utilizzando la funzione np.random.choice() della libreria NumPy. Questa funzione permette di generare campioni casuali basati sui valori della variabile casuale, sul numero di ripetizioni indipendenti (qui 1.000.000) e sulla distribuzione di massa di probabilit√† associata:\nx_samples = np.random.choice(x, size=1000000, p=px)\nL‚Äôistruzione np.random.choice(x, size=1000000, p=px) utilizza NumPy per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall‚Äôarray x secondo le probabilit√† specificate nell‚Äôarray px. In questo contesto, x √® l‚Äôarray contenente i possibili valori di \\(X\\), mentre px √® un array che rappresenta le probabilit√† associate a ciascun valore di \\(x\\).\nCome ci si aspetterebbe, quando il numero di realizzazioni indipendenti √® sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nnp.mean(x_samples).round(3)\n\n7.002\n\n\nQuesto risultato conferma che, con un numero elevato di simulazioni, la media aritmetica dei valori ottenuti fornisce una buona approssimazione del valore atteso teorico di \\(X\\).\n\n\n25.1.2 Propriet√† del Valore Atteso\nUna delle propriet√† pi√π importanti del valore atteso √® la sua linearit√†: il valore atteso della somma di due variabili casuali √® uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{25.1}\\]\nQuesta propriet√†, espressa dalla formula sopra, √® intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma √® valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto √® uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{25.2}\\]\nQuesta propriet√† ci dice che una costante pu√≤ essere ‚Äúestratta‚Äù dall‚Äôoperatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn‚Äôaltra propriet√† significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto √® uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{25.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica √®:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l‚Äôanalisi statistica e probabilistica.\n\nEsempio 25.4 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell‚Äôesperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado √® indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avr√† la stessa probabilit√† di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) √® dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l‚ÄôEquazione¬†25.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 25.5 Svolgiamo ora l‚Äôesercizio in Python.\n\ncoin = range(0, 2)\ndie = range(1, 7)\n\nsample = [(c, d) for c in coin for d in die]\nlist(sample)\n\n[(0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (0, 5),\n (0, 6),\n (1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6)]\n\n\n\npx = []\nfor i in range(1, 8):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n    print(f\"P(X + Y = {i}) = {len(event)} / {len(sample)}\")\n\nP(X + Y = 1) = 1 / 12\nP(X + Y = 2) = 2 / 12\nP(X + Y = 3) = 2 / 12\nP(X + Y = 4) = 2 / 12\nP(X + Y = 5) = 2 / 12\nP(X + Y = 6) = 2 / 12\nP(X + Y = 7) = 1 / 12\n\n\n\nx = np.arange(1, 8)\nsum(x * px)\n\n4.0\n\n\n\n\nEsempio 25.6 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilit√† congiunta \\(P(X, Y)\\) √® fornita nella tabella seguente.\n\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l‚ÄôEquazione¬†25.3. Infatti, il valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerci√≤\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n\n25.1.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso √® definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) √® ponderato in base alla densit√† di probabilit√† \\(p(x)\\).\nL‚Äôintegrale pu√≤ essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l‚Äôaltezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l‚Äôintero asse reale.\nQuesta interpretazione rende chiaro come l‚Äôintegrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell‚Äôintegrale, si veda l‚ÄôAppendice K.\n\n25.1.3.1 Moda\nUn‚Äôaltra misura di tendenza centrale delle variabili casuali continue √® la moda. La moda di \\(Y\\) individua il valore \\(y\\) pi√π plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densit√† \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{25.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#varianza",
    "href": "chapters/probability/07_expval_var.html#varianza",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "25.2 Varianza",
    "text": "25.2 Varianza\nDopo il valore atteso, la seconda propriet√† pi√π importante di una variabile casuale √® la varianza.\n\nDefinizione 25.2 Se \\(X\\) √® una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), √® definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{25.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n25.2.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della ‚Äúdispersione‚Äù dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le ‚Äúdistanze‚Äù tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poich√© lo scarto pu√≤ essere positivo o negativo, la media dello scarto √® sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza √® quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto √® fondamentale per comprendere la variabilit√† di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 25.7 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilit√†:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\nEsempio 25.8 Svolgiamo l‚Äôesercizio in Python.\n\nx = np.arange(2, 13)\npx = np.array(\n    [\n        1 / 36,\n        2 / 36,\n        3 / 36,\n        4 / 36,\n        5 / 36,\n        6 / 36,\n        5 / 36,\n        4 / 36,\n        3 / 36,\n        2 / 36,\n        1 / 36,\n    ]\n)\nX = stats.rv_discrete(values=(x, px))\nex = X.expect()\nex\n\n6.999999999999998\n\n\nApplichiamo l‚ÄôEquazione¬†25.5:\n\n((x - ex) ** 2 * px).sum()\n\n5.833333333333333\n\n\nUsiamo la funzione var() di rv_discrete:\n\nX.var()\n\n5.833333333333364\n\n\n\n\n\n25.2.2 Formula Alternativa per la Varianza\nEsiste un metodo pi√π semplice e diretto per calcolare la varianza di una variabile casuale \\(X\\):\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big] &= \\mathbb{E}\\big(X^2 - 2Y\\mathbb{E}(X) + \\mathbb{E}(X)^2\\big) \\notag\\\\\n&= \\mathbb{E}(X^2) - 2\\mathbb{E}(Y)\\mathbb{E}(X) + \\mathbb{E}(X)^2,\n\\end{align}\n\\]\ndove \\(\\mathbb{E}(X)\\) √® una costante. Semplificando ulteriormente, otteniamo:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(X)\\big)^2.\n\\tag{25.6}\\]\nIn altre parole, la varianza √® data dalla differenza tra la media dei quadrati dei valori di \\(X\\) e il quadrato della media di \\(X\\).\nQuesta formula √® utile perch√© permette di calcolare la varianza senza dover prima determinare lo scarto quadratico medio per ciascun valore di \\(X\\). Invece, si pu√≤ calcolare direttamente la media dei quadrati e sottrarre il quadrato della media, il che spesso semplifica i calcoli e riduce il rischio di errori.\n\nEsempio 25.9 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilit√† di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) √®\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 25.10 Svolgiamo l‚Äôesercizio in Python:\n\nx = np.array([0, 1])\npx = np.array([0.2, 0.8])\n\nsum(x**2 * px) - (sum(x * px)) ** 2\n\n0.15999999999999992\n\n\n\n\n\n25.2.3 Propriet√†\nSegno della varianza. La varianza di una variabile aleatoria non √® mai negativa, ed √® zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza √® invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\nx = np.array([2, 1, 4, 7])\ny = 100 + 2 * x\n\nnp.var(y) == 2**2 * np.var(x)\n\nTrue\n\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti √® pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio √® fornita sotto.\n\nx = np.array([2, 1, 4, 7])\ny = np.array([1, 3, 5, 11])\n\nnp.var(x + y, ddof=0)\n\n35.25\n\n\n\nnp.var(x, ddof=0) + np.var(y, ddof=0) + 2 * np.cov(x, y, ddof=0)[0, 1]\n\n35.25\n\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente √® illustrato dalla seguente simulazione.\n\n# Set up the population distribution\npopulation = np.random.normal(loc=50, scale=10, size=10000)\n\n# Set up the sample size and number of samples\nsample_size = 30\nnum_samples = 100000\n\n# Create an array to hold the sample means\nsample_means = np.zeros(num_samples)\n\n# Generate the samples and compute their means\nfor i in range(num_samples):\n    sample = np.random.choice(population, size=sample_size)\n    sample_means[i] = np.mean(sample)\n\n# Calculate the variance of the sample means\nsampling_dist_mean_var = np.var(sample_means)\nsampling_dist_mean_var\n\n3.4103710835201433\n\n\nIl valore teorico della varianza della distribuzione campionaria della media √®\n\n10**2 / 30\n\n3.3333333333333335\n\n\n\n\n25.2.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza √® definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{25.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la ‚Äúdistanza‚Äù media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#deviazione-standard",
    "href": "chapters/probability/07_expval_var.html#deviazione-standard",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "25.3 Deviazione Standard",
    "text": "25.3 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che pu√≤ rendere i numeri significativamente pi√π grandi (o pi√π piccoli) rispetto ai dati originali. Per riportare questi valori all‚Äôunit√† di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto √® chiamato deviazione standard ed √® comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 25.3 La deviazione standard, o scarto quadratico medio, √® definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la ‚Äúdistanza‚Äù tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 25.11 Per i dadi equilibrati dell‚Äôesempio precedente, la deviazione standard della variabile casuale \\(S\\) √® pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#standardizzazione",
    "href": "chapters/probability/07_expval_var.html#standardizzazione",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "25.4 Standardizzazione",
    "text": "25.4 Standardizzazione\n\nDefinizione 25.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l‚Äôespressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{25.8}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/07_expval_var.html#momenti-di-variabili-casuali",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "25.5 Momenti di variabili casuali",
    "text": "25.5 Momenti di variabili casuali\n\nDefinizione 25.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densit√† \\(p(x)\\), la quantit√†\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{25.9}\\]\nSe \\(X\\) √® una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i).\n\\tag{25.10}\\]\n\nI momenti sono importanti parametri indicatori di certe propriet√† di \\(X\\). I pi√π noti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x ‚àí \\mathbb{E}(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#alcuni-esempi-in-python",
    "href": "chapters/probability/07_expval_var.html#alcuni-esempi-in-python",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "25.6 Alcuni esempi in Python",
    "text": "25.6 Alcuni esempi in Python\nUtilizzando il modulo stats di scipy, √® possibile semplificare i calcoli del valore atteso e della varianza di variabili casuali discrete.\nConsideriamo ad esempio una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilit√†: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx = np.arange(7)\nprint(x)\n\n[0 1 2 3 4 5 6]\n\n\nIl vettore px conterr√† le probabilit√† associate ai valori x:\n\npx = [0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\nprint(px)\n\n[0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\n\n\nControlliamo che la somma sia 1:\n\nnp.sum(px)\n\n1.0\n\n\nUsiamo ora la funzione rv_discrete() che √® una funzione della libreria stats di Python. Tale funzione viene utilizzata per creare una distribuzione discreta personalizzata. La funzione richiede che vengano forniti dei valori discreti (ossia interi) e le rispettive probabilit√† di occorrenza.\nUna volta definita la distribuzione discreta, rv_discrete() permette di eseguire operazioni come la generazione di numeri casuali dalla distribuzione, il calcolo della funzione di probabilit√† cumulativa (CDF) e della funzione di densit√† di probabilit√† (PDF), e la valutazione della media, della varianza e di altre statistiche della distribuzione.\nLa sintassi di base della funzione rv_discrete() √® la seguente:\nrv = stats.rv_discrete(name='rv', values=(xk, pk))\ndove name √® il nome della distribuzione discreta, xk sono i valori discreti e pk sono le rispettive probabilit√† di occorrenza. Ad esempio, creiamo la variabile casuale X:\n\nX = stats.rv_discrete(name='rv', values=(x, px))\n\n\n# Distribuzione di massa di probabilit√† di X.\nprint(X.pmf(x))\n\n[0.1 0.2 0.3 0.1 0.1 0.  0.2]\n\n\n\n# Distribuzione comulativa di probabilit√† di X.\nprint(X.cdf(x))\n\n[0.1 0.3 0.6 0.7 0.8 0.8 1. ]\n\n\nGeneriamo un grafico che rappresenta la distribuzione di massa con Matplotlib.\n\ncolor_fill = \"#B17F7D\"\ncolor_edge = \"#832F2B\"\nplt.plot(x, X.pmf(x), \"o\", ms=6, color=color_fill, markeredgecolor=color_edge)\nplt.vlines(x, 0, X.pmf(x), lw=2, colors=color_edge)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso, ovvero utilizzando i vettori x e px.\n\nx_ev = (x * px).sum()\nx_ev\n\n2.7\n\n\nLo stesso risultato si ottience applicando il metodo .expect() all‚Äôoggetto X.\n\nx_ev = X.expect()\nx_ev\n\n2.7\n\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px.\n\nx_var = ((x - x_ev)**2 * X.pmf(x)).sum()\nx_var\n\n3.8100000000000005\n\n\nOtteniamo lo stesso risultato applicando il metodo .var() all‚Äôoggetto X.\n\nX.var()\n\n3.8099999999999987\n\n\nCalcoliamo la deviazione standard di \\(X\\) prendento la radice quadrata della varianza.\n\nnp.sqrt(x_var)\n\n1.9519221295943137\n\n\nOppure, in maniera equivalente, applicando il metodo .std() all‚Äôoggetto X.\n\nX.std()\n\n1.9519221295943132",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#considerazioni-conclusive",
    "href": "chapters/probability/07_expval_var.html#considerazioni-conclusive",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "25.7 Considerazioni Conclusive",
    "text": "25.7 Considerazioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il ‚Äúvalore tipico‚Äù che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione pi√π completa della distribuzione. Questi strumenti sono essenziali per l‚Äôanalisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilit√† nei fenomeni aleatori.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "25¬† Propriet√† delle variabili casuali",
    "section": "25.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "25.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nscipy     : 1.14.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>25</span>¬† <span class='chapter-title'>Propriet√† delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html",
    "href": "chapters/probability/08_sampling_distr.html",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† verranno utilizzate per costruire gli strumenti fondamentali dell‚Äôinferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "26.1 Popolazione e campioni",
    "text": "26.1 Popolazione e campioni\nNell‚Äôanalisi dei dati, l‚Äôobiettivo spesso √® comprendere una quantit√† specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantit√† sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta √® chiamata stima, e la formula che utilizziamo per ottenerla √® conosciuta come stimatore. In termini formali, uno stimatore √® una funzione dei dati osservati, utilizzata per fornire un‚Äôapprossimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo √® inferire determinate propriet√† della popolazione intera dalla quale il campione √® stato tratto. Il parametro √® l‚Äôindicatore numerico di queste propriet√†, ma poich√© spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore √® la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\n√à importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "href": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "26.2 La relazione tra stime e parametri",
    "text": "26.2 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo √® capire e caratterizzare l‚Äôincertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l‚Äôapproccio frequentista, facendo uso di un importante strumento statistico chiamato distribuzione campionaria.\n\n26.2.1 Distribuzione campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, √® fondamentale notare che le propriet√† e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci d√† una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all‚Äôintera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornir√† una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell‚Äôincertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL‚Äôistogramma seguente descrive la distribuzione di frequenza della popolazione.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nconteggi, intervalli, _ = plt.hist(\n    x,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nStampiamo gli intervalli utilizzati per l‚Äôistogramma.\n\nprint(\"Intervalli utilizzati per l'istogramma:\", intervalli)\nprint(\"Frequenze relative utilizzate per l'istogramma:\", conteggi)\n\nIntervalli utilizzati per l'istogramma: [2.  2.7 3.4 4.1 4.8 5.5]\nFrequenze relative utilizzate per l'istogramma: [0.35714286 0.         0.         0.35714286 0.71428571]\n\n\nLe frequenze assolute si ottengono usando l‚Äôargomento density=False.\n\nconteggi, intervalli, _ = plt.hist(\n    x,\n    bins=5,\n    density=False,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\nprint(\"Frequenze assolute utilizzate per l'istogramma:\", conteggi)\n\n\n\n\n\n\n\n\nFrequenze assolute utilizzate per l'istogramma: [1. 0. 0. 1. 2.]\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nSupponiamo ora di voler considerare l‚Äôestrazione di tutti i possibili campioni di dimensione \\(n\\) = 2 da una popolazione rappresentata dall‚Äôarray x. Per fare ci√≤, possiamo fare uso di uno strumento di programmazione, come la funzione product del modulo itertools in Python.\nSpecificamente, possiamo utilizzare product con l‚Äôargomento repeat impostato a 2, che indica che vogliamo formare tutte le possibili coppie di valori. In altre parole, stiamo cercando tutte le combinazioni in cui ogni valore nell‚Äôarray x pu√≤ essere abbinato a se stesso o a un altro valore nell‚Äôarray.\nDopo aver utilizzato la funzione product, otteniamo una lista di tuple, che rappresenta tutte le possibili coppie di valori. Possiamo convertire questa lista in un array NumPy pi√π maneggevole utilizzando la funzione np.array. Stampando il risultato, otteniamo un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie che possono essere formate dall‚Äôarray x.\nQuesta rappresentazione di tutte le possibili coppie √® coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento pu√≤ essere scelto pi√π di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sar√† $4^2 = 16 $. Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di \\(4 \\times 4 = 16\\) possibili coppie.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nConvertiamo l‚Äôoutput di itertools.product in un array NumPy per sfruttare le funzionalit√† di questa libreria. L‚Äôarray risultante, samples, √® un array 2D, dove ogni riga rappresenta una coppia di valori.\n\nsamples.shape\n\n(16, 2)\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), possiamo utilizzare la funzione mean del modulo NumPy e applicarla lungo l‚Äôasse delle colonne dell‚Äôarray di coppie di valori. In questo modo otterremo un array unidimensionale contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nLa funzione np.mean(samples, axis=1) calcola la media lungo l‚Äôasse specificato, che in questo caso √® l‚Äôasse 1. In NumPy, l‚Äôasse 0 rappresenta le righe (verticale) e l‚Äôasse 1 rappresenta le colonne (orizzontale).\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\nplt.hist(\n    means,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\n_ = plt.show()\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x.\n\n\n26.2.2 Valore atteso della media campionaria\nSupponiamo che $ X_1, X_2, , X_n $ siano variabili aleatorie iid con valore atteso $ $ e varianza $ ^2 $. Vogliamo trovare il valore atteso della media campionaria:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nEcco la dimostrazione:\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu \\\\\n& = \\mu\n\\end{align*}\n\\]\nQuindi, il valore atteso della media campionaria di $ n $ variabili iid √® uguale al valore atteso di ciascuna variabile singola, che in questo caso √® $ $.\nVerifichiamo che ci√≤ sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\n\n\n26.2.3 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid √® uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso √® \\(\\sigma^2/n\\).\nPer l‚Äôesempio in discussione, il valore della varianza delle medie dei campioni √® dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione √® diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione √® diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, possiamo sottolineare due risultati centrali che emergono dall‚Äôanalisi delle medie campionarie:\n\nMedia delle medie campionarie e media della popolazione: La media della distribuzione delle medie campionarie √® identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media $ $ √®:\n\n\\[\n   \\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\n\nVarianza delle medie campionarie e varianza della popolazione: La varianza della distribuzione delle medie campionarie √® inferiore alla varianza della popolazione e, precisamente, √® pari alla varianza della popolazione divisa per la dimensione del campione:\n\n\\[\n   \\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\nQuesti risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.\nInoltre, √® importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:\n\nSe la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sar√† anch‚Äôessa normale.\nSe la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.\n\nQuesti principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "26.3 Errore standard e rappresentazione dell‚Äôincertezza inferenziale",
    "text": "26.3 Errore standard e rappresentazione dell‚Äôincertezza inferenziale\nNella statistica inferenziale, l‚Äôerrore standard √® una misura frequentemente utilizzata per rappresentare l‚Äôincertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L‚Äôerrore standard quantifica quanto possa variare la stima di una statistica da un campione all‚Äôaltro; un errore standard minore indica una stima pi√π precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di ‚Äúmedia pi√π o meno uno (o due) errori standard.‚Äù Questa espressione fornisce una gamma di valori entro cui √® plausibile che ricada il valore vero del parametro della popolazione.\nL‚Äôuso dell‚Äôerrore standard nei grafici non √® soltanto una convenzione; esso √® uno strumento per quantificare e visualizzare l‚Äôincertezza inferenziale. Contribuisce alla comprensione dell‚Äôaffidabilit√† delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, √® importante notare che questo utilizzo dell‚Äôerrore standard pu√≤ essere problematico (Ward e Mann 2022).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "26.4 Legge dei Grandi Numeri",
    "text": "26.4 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) √® un principio fondamentale della teoria delle probabilit√† che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione ‚Äúforte‚Äù e quella ‚Äúdebole‚Äù, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n26.4.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilit√† 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell‚Äôinsieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilit√† √® zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) ‚Äúquasi certamente‚Äù.\n\n\n26.4.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantit√† maggiore di \\(\\epsilon\\) tende a zero all‚Äôaumentare di \\(n\\). Questo fenomeno √® definito come convergenza in probabilit√† verso la media teorica \\(\\mu\\).\n\n\n26.4.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, pi√π in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l‚Äôutilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l‚Äôaffidabilit√† delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 26.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di ‚ÄúTesta‚Äù in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di ‚ÄúTesta‚Äù dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilit√† 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) converger√† a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di ‚ÄúTesta‚Äù (HHHHHH‚Ä¶) o sequenze irregolari come HHTHHTHHTHHT‚Ä¶, ma queste hanno una probabilit√† collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilit√† che \\(\\bar{X}_n\\) sia distante pi√π di \\(\\epsilon\\) da \\(1/2\\) pu√≤ essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realt√† non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All‚Äôinizio, notiamo una certa variazione nella proporzione cumulativa di ‚ÄúTesta‚Äù. Tuttavia, con l‚Äôaumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Number of sequences\nnum_sequences = 6\n# Number of tosses\nnum_tosses = 300\n# Initialize a figure\nplt.figure()\n\n# Loop through each sequence\nfor i in range(num_sequences):\n    \n    # Generate a sequence of fair coin tosses (Heads=1, Tails=0)\n    coin_tosses = np.random.choice([0, 1], num_tosses)\n    \n    # Calculate the running proportion of Heads\n    running_proportion = np.cumsum(coin_tosses) / np.arange(1, num_tosses + 1)\n    \n    # Plot the running proportion as a function of the number of tosses\n    plt.plot(np.arange(1, num_tosses + 1), running_proportion, label=f'Sequence {i+1}')\n\n# Plotting the true mean (1/2)\nplt.axhline(y=0.5, color='r', linestyle='--', label='True Mean (1/2)')\n\n# Adding labels and title\nplt.xlabel('Number of Tosses')\nplt.ylabel('Running Proportion of Heads')\nplt.title('Running Proportion of Heads in Six Sequences of Fair Coin Tosses')\nplt.legend()\nplt.legend(fontsize='small')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "26.5 Teorema del Limite Centrale",
    "text": "26.5 Teorema del Limite Centrale\nIl teorema del limite centrale √® un risultato fondamentale in statistica che √® stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare cos√¨ frequentemente nei fenomeni naturali. Ecco la formulazione essenziale:\n\n26.5.1 Enunciato\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all‚Äôinfinito, la distribuzione di \\(Z\\) converger√† a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n\n26.5.2 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma pu√≤ essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacit√† di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l‚Äôaltezza degli esseri umani adulti pu√≤ essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalit√† rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 26.2 Per visualizzare il TLC in azione, si pu√≤ condurre una simulazione. Immaginiamo una popolazione iniziale con una distribuzione asimmetrica, come una Beta(2, 1). Estraiamo 50.000 campioni di dimensione \\(n\\) da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornir√† un‚Äôillustrazione concreta dell‚Äôefficacia del TLC nell‚Äôapprossimare distribuzioni reali.\n\n# parameters of the beta distribution\na=2\nb=1\n\ndef plot_samples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n            v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together\n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(\n        sample_means,\n        color=color_fill,\n        edgecolor=color_edge,\n    )\n    ax2 = ax.twinx()\n    sns.lineplot(x=x, y=y, ax=ax2, color=color_edge)\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l‚Äôampiezza campionaria √® 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non √® certamente Normale, inizia ad avvicinarsi alla gaussianit√†.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c‚Äô√® ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l‚Äôapprossimazione migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, √® possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ci√≤ avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed √® espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "26.6 Distribuzioni campionarie di altre statistiche",
    "text": "26.6 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente √® possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l‚Äôapprossimazione empirica della distribuzione campionaria del valore massimo del campione. √à chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sar√† maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax, color=color_fill)\nax2 = ax.twinx()\nsns.lineplot(x=x, y=y, ax=ax2, color=color_edge);\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni √® particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l‚Äôapprossimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione √® uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto √® stato interessante: in media, l‚Äôutilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard\n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find\n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax, color=color_fill)\n\nnp.mean(sample_vars)\n\n177.69769879129643\n\n\n\n\n\n\n\n\n\nAbbiamo gi√† visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax, color=color_fill)\n\nnp.mean(sample_vars)\n\n226.51417694562372\n\n\n\n\n\n\n\n\n\nLa differenza tra la stima di un parametro e il valore vero del parametro √® chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici √® uguale al valore del parametro che si vuole stimare. In altre parole, l‚Äôerrore medio di stima √® zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) √® uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) √® uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#considerazioni-conclusive",
    "href": "chapters/probability/08_sampling_distr.html#considerazioni-conclusive",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "26.7 Considerazioni conclusive",
    "text": "26.7 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#watermark",
    "href": "chapters/probability/08_sampling_distr.html#watermark",
    "title": "26¬† Stime, stimatori e parametri",
    "section": "26.8 Watermark",
    "text": "26.8 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nWard, Andrew, e Traci Mann. 2022. ¬´Control yourself: Broad implications of narrowed attention¬ª. Perspectives on Psychological Science 17 (6): 1692‚Äì1703.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>26</span>¬† <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html",
    "href": "chapters/probability/09_joint_prob.html",
    "title": "27¬† Probabilit√† congiunta",
    "section": "",
    "text": "Introduzione\nLa probabilit√† congiunta √® la probabilit√† che due o pi√π eventi si verifichino contemporaneamente. In questo capitolo verr√† esaminato il caso discreto.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#sec-fun-join-prob",
    "href": "chapters/probability/09_joint_prob.html#sec-fun-join-prob",
    "title": "27¬† Probabilit√† congiunta",
    "section": "27.1 Funzione di Probabilit√† Congiunta",
    "text": "27.1 Funzione di Probabilit√† Congiunta\nDopo aver esplorato la distribuzione di probabilit√† di singole variabili casuali, che associa un unico numero reale ad ogni possibile risultato di un esperimento, si procede naturalmente all‚Äôestensione di questo concetto al caso di due o pi√π variabili casuali.\n\n27.1.1 Esempio: Lancio di Tre Monete Equilibrate\nConsideriamo l‚Äôesperimento del lancio di tre monete equilibrate. Lo spazio campione \\(\\Omega\\) √® dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove T rappresenta ‚Äútesta‚Äù e C rappresenta ‚Äúcroce‚Äù. Assumendo che i lanci siano indipendenti, ogni risultato nell‚Äôinsieme \\(\\Omega\\) ha la stessa probabilit√† di occorrenza, ovvero \\(1/8\\).\nDefiniamo le seguenti variabili casuali sullo spazio campione \\(\\Omega\\):\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il ‚Äúnumero di teste ottenute nei tre lanci‚Äù.\n\\(Y \\in \\{0, 1\\}\\) indica se ‚Äúla testa √® stata ottenuta nel primo lancio‚Äù (1) o no (0).\n\nLa tabella seguente illustra lo spazio campione e le variabili casuali \\(X\\) e \\(Y\\), insieme alle rispettive probabilit√†:\n\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nPer ogni coppia \\((x, y)\\) definita su \\(\\Omega\\), associamo una probabilit√† come segue:\n\n\\(P(X=0, Y=0) = P(\\text{CCC}) = 1/8\\),\n\ne similmente per le altre coppie.\nLe probabilit√† calcolate per tutte le possibili coppie \\((X, Y)\\) sono:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= 1/8, \\\\\nP(X = 2, Y = 0) &= 1/8, \\\\\nP(X = 2, Y = 1) &= 1/4, \\\\\nP(X = 3, Y = 1) &= 1/8.\n\\end{aligned}\n\\]\nQueste probabilit√† compongono la distribuzione di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\).\n\n\n27.1.2 Definizione: Funzione di Probabilit√† Congiunta\nLa funzione di probabilit√† congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilit√† \\(P(X = x, Y = y)\\).\n\n\n27.1.3 Propriet√†\nUna distribuzione di probabilit√† congiunta deve soddisfare:\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilit√† su tutte le coppie deve essere 1.\n\n\n\n27.1.4 Calcolo della Probabilit√† di Eventi Specifici\nData la distribuzione di probabilit√† congiunta, possiamo determinare la probabilit√† di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilit√† che \\(X + Y \\leq 1\\), sommiamo le probabilit√† di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).\n\n\n27.1.5 Funzioni di Probabilit√† Marginali\nLa distribuzione marginale di un insieme di variabili casuali descrive la distribuzione di probabilit√† di queste variabili considerate singolarmente, indipendentemente dalle altre. La ‚Äúmarginalizzazione‚Äù √® un processo che permette di ottenere la distribuzione di probabilit√† di una o pi√π variabili casuali marginali sommando o integrando la distribuzione congiunta su tutte le possibili realizzazioni delle altre variabili casuali, ovvero quelle non considerate (e quindi ‚Äúmarginalizzate‚Äù).\nPer esempio, data la distribuzione congiunta di due variabili casuali discrete \\(X\\) e \\(Y\\), la distribuzione marginale di \\(X\\), indicata come \\(P(X=x)\\), si calcola come:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilit√† congiunta di \\(X\\) e \\(Y\\). Le distribuzioni marginali e congiunte di variabili casuali discrete sono frequentemente rappresentate in tabelle di contingenza. Si garantisce che le distribuzioni marginali siano normalizzate:\n\\[\n\\sum_x P(X=x) = 1, \\quad \\sum_y P(Y=y) = 1.\n\\]\nPer variabili casuali continue, la somma √® sostituita dall‚Äôintegrazione.\n\nEsempio 27.1 Prendiamo come riferimento l‚Äôesperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilit√† marginali di \\(X\\) e \\(Y\\), sommiamo le probabilit√† congiunte su una dimensione. La probabilit√† marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilit√† lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilit√† marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilit√† lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilit√† congiunta \\(P(X, Y)\\) e le probabilit√† marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n27.1.6 Marginalizzazione per Variabili Casuali Continue\nNell‚Äôambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo √®:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l‚Äôestensione dell‚Äôapproccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "27¬† Probabilit√† congiunta",
    "section": "27.2 Indipendenza tra Variabili Casuali",
    "text": "27.2 Indipendenza tra Variabili Casuali\nL‚Äôindipendenza tra variabili casuali √® un concetto fondamentale in statistica e probabilit√†, parallelo all‚Äôidea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l‚Äôinformazione su una non altera in alcun modo la distribuzione di probabilit√† dell‚Äôaltra. Questa sezione offre una formalizzazione dell‚Äôindipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilit√† congiunta.\n\n27.2.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ci√≤ significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilit√† congiunta √® il prodotto delle rispettive distribuzioni di probabilit√† marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l‚Äôindipendenza si verifica quando la funzione di densit√† congiunta √® il prodotto delle funzioni di densit√† marginali.\n\n\n27.2.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, √® utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile √® associata alla variazione dell‚Äôaltra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l‚Äôindipendenza tra variabili casuali √® un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate √® fondamentale per l‚Äôanalisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#covarianza",
    "href": "chapters/probability/09_joint_prob.html#covarianza",
    "title": "27¬† Probabilit√† congiunta",
    "section": "27.3 Covarianza",
    "text": "27.3 Covarianza\nLa covarianza √® un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell‚Äôaltra. Per esempio, considerando l‚Äôaltezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando cos√¨ una covarianza positiva. La covarianza √® denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n27.3.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) √® definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini pi√π espliciti, la covarianza pu√≤ essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) √® la funzione di probabilit√† congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che √® la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza pu√≤ essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n\n27.3.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n\n27.3.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si pu√≤ ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) √®:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 27.2 Per fare un esempio con Python, consideriamo l‚Äôesempio precedente nel quale \\(X\\) √® il numero che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) √® il numero di teste al primo lancio. Troviamo \\(Cov(X, Y)\\).\nCreiamo il prodotto cartesiano che si ottiene per tutti i possibili valori \\(X\\) e i possibili valori \\(Y\\).\n\nc3 = np.arange(0, 4)\nc1 = np.arange(0, 2)\nsample = [(i, j) for i in c1 for j in c3]\nsample\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo numero √® il valore di \\(X\\). Come abbiamo visto in precedenza, per√≤, quete coppie di valori \\(X, Y\\) non hanno tutte la stessa probabilit√† di verificarsi. Infatti, la probabilit√† che ciascuna coppia \\(X, Y\\) si osservi √® data, in sequenza, dai valori 1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8. Questi valori rappresentano la distribuzione di massa di probabilit√† congiunta delle variabili casuali \\(X\\) e \\(Y\\). Possiamo quindi applicare l‚Äôeq. {eq}eq-cov-def-rv:\n\nres = []\n\npmf = np.array([1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8])\n\nfor i in range(8):\n    res.append((sample[i][0] - 0.5) * (sample[i][1] - 1.5) * pmf[i])\n\nsum(res)\n\nLa covarianza tra \\(X\\) e \\(Y\\) √® dunque uguale a 0.25.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#correlazione",
    "href": "chapters/probability/09_joint_prob.html#correlazione",
    "title": "27¬† Probabilit√† congiunta",
    "section": "27.4 Correlazione",
    "text": "27.4 Correlazione\nMentre la covarianza fornisce un‚Äôindicazione della tendenza di due variabili casuali a variare insieme, essa √® influenzata dalle unit√† di misura delle variabili, rendendo difficile valutare l‚Äôintensit√† della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo cos√¨ una misura standardizzata dell‚Äôassociazione lineare tra di esse.\n\nDefinizione 27.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), √® definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) √® un valore adimensionale, ovvero non dipende dalle unit√† di misura delle variabili, e varia nell‚Äôintervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#propriet√†-1",
    "href": "chapters/probability/09_joint_prob.html#propriet√†-1",
    "title": "27¬† Probabilit√† congiunta",
    "section": "27.5 Propriet√†",
    "text": "27.5 Propriet√†\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) √® sempre nulla: \\(Cov(c, X) = 0\\).\nSimmetria: La covarianza √® simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\nIndipendenza dalle Unit√† di Misura: La correlazione √® indipendente dalle unit√† di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) √® una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, √® \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n27.5.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza √® nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza pi√π debole rispetto all‚Äôindipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 27.3 Consideriamo una distribuzione di probabilit√† congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilit√† uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilit√† congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilit√† congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) √® zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ci√≤ non implica la loro indipendenza. L‚Äôindipendenza richiede che la funzione di probabilit√† congiunta si possa esprimere come il prodotto delle funzioni di probabilit√† marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l‚Äôassenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l‚Äôincorrelazione non garantisce l‚Äôindipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#variabili-continue",
    "href": "chapters/probability/09_joint_prob.html#variabili-continue",
    "title": "27¬† Probabilit√† congiunta",
    "section": "27.6 Variabili continue",
    "text": "27.6 Variabili continue\nConsideriamo ora le distribuzioni di densit√†. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilit√† congiunta \\(p(A,B)\\), le probabilit√† marginali \\(p(A)\\) e \\(p(B)\\), e le probabilit√† condizionali \\(p(A \\mid B)\\).\n\n\n\nDistribuzioni di densit√† (figura tratta da Martin (2024)).\n\n\n\nProbabilit√† congiunta \\(p(A,B)\\): rappresenta la probabilit√† che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa √® data dall‚Äôintegrazione della funzione di densit√† congiunta su un‚Äôarea o volume di interesse.\nProbabilit√† marginale \\(p(A)\\) e \\(p(B)\\): √® la probabilit√† di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densit√† congiunta sull‚Äôintero intervallo di valori dell‚Äôaltra variabile.\nProbabilit√† condizionale \\(p(A \\mid B)\\): esprime la probabilit√† di A dato B. Si calcola dividendo la probabilit√† congiunta per la probabilit√† marginale di B, applicando la definizione di probabilit√† condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilit√† congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/09_joint_prob.html#commenti-e-considerazioni-finali",
    "title": "27¬† Probabilit√† congiunta",
    "section": "27.7 Commenti e considerazioni finali",
    "text": "27.7 Commenti e considerazioni finali\nIn alcune situazioni, ogni singolo elemento di una popolazione pu√≤ essere associato a diverse variabili casuali. Ad esempio, consideriamo l‚Äôelenco di tutti gli studenti iscritti a un‚Äôuniversit√† e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione √® associato a due variabili casuali, l‚Äôaltezza e il peso. Quando si hanno due o pi√π variabili casuali associate ad ogni elemento di una popolazione, √® possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilit√† congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "27¬† Probabilit√† congiunta",
    "section": "27.8 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "27.8 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMartin, Osvaldo. 2024. Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>27</span>¬† <span class='chapter-title'>Probabilit√† congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html",
    "href": "chapters/probability/10_density_func.html",
    "title": "28¬† La funzione di densit√† di probabilit√†",
    "section": "",
    "text": "Introduction\nIn precedenza abbiamo trattato solo variabili casuali discrete, ossia variabili che assumono solo valori interi. Tuttavia, se vogliamo rappresentare grandezze come lunghezze, volumi, distanze o qualsiasi altra propriet√† continua del mondo fisico o psicologico, √® necessario generalizzare l‚Äôapproccio utilizzato finora.\nLe variabili casuali continue assumono valori reali, e l‚Äôinsieme dei numeri reali √® non numerabile in quanto √® pi√π grande dell‚Äôinsieme degli interi.1 Le leggi della probabilit√† valgono sia per le variabili casuali discrete che per quelle continue. Tuttavia, la nozione di funzione di massa di probabilit√† deve essere sostituita dal suo equivalente continuo, la funzione di densit√† di probabilit√†. In questo capitolo, il nostro obiettivo √® chiarire il significato di questa nozione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "28¬† La funzione di densit√† di probabilit√†",
    "section": "28.1 Spinner e variabili casuali continue uniformi",
    "text": "28.1 Spinner e variabili casuali continue uniformi\nConsideriamo l‚Äôesperimento casuale in cui facciamo ruotare ad alta velocit√† uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma, identificata dall‚Äôangolo acuto con segno tra il suo asse e l‚Äôasse orizzontale del goniometro. Denotiamo con \\(\\Theta\\) la variabile casuale corrispondente alla ‚Äúpendenza dello spinner‚Äù. In questo contesto, l‚Äôassunzione che lo spinner sia simmetrico implica che, in ogni prova, la rotazione produce un angolo qualunque da 0 a 360 gradi con la stessa probabilit√†. In altre parole, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilit√† di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, dal momento che 36 gradi corrisponde a un decimo del percorso intorno al cerchio, la probabilit√† di ottenere un qualsiasi intervallo di 36 gradi sar√† sempre uguale al 10%. Pi√π precisamente, si ha \\(P(0 \\leq \\Theta \\leq 36) = \\frac{1}{10}\\) e \\(P(200 \\leq \\Theta \\leq 236) = \\frac{1}{10}\\).\n√à importante sottolineare che le probabilit√† sopra menzionate non si riferiscono al fatto che la variabile casuale \\(\\Theta\\) assuma un valore specifico, ma piuttosto all‚Äôevento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilit√† che la pendenza \\(\\Theta\\) cada in un intervallo specificato √® data dalla frazione del cerchio rappresentata dall‚Äôintervallo, cio√® \\(P(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}\\), per ogni intervallo \\([\\theta_1, \\theta_2]\\) tale che \\(0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360\\).\nNel caso di una variabile casuale continua, come l‚Äôangolo dello spinner, dunque, √® facile capire come assegnare una probabilit√† all‚Äôevento in cui la variabile casuale assuma un valore compreso in un intervallo.\n\n28.1.1 Distribuzione uniforme\nL‚Äôesempio dello spinner rappresenta il ‚Äúmeccanismo generatore dei dati‚Äù della variabile casuale continua pi√π semplice, ovvero la distribuzione continua uniforme. In teoria della probabilit√†, la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna la stessa probabilit√† a tutti i punti appartenenti ad un intervallo [a, b] contenuto in un certo insieme.\nLa distribuzione uniforme continua definita sull‚Äôintervallo \\({\\displaystyle S=[a,b]\\subset \\mathbb {R}}\\) viene denotata con \\({\\displaystyle {\\mathcal {U}}(a,b)={\\mathcal {U}}([a,b])}\\). La sua densit√† di probabilit√† √®\n\\[\nf(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n\\]\ne 0 altrimenti. La distribuzione uniforme continua √® caratterizzata dalla sua propriet√† di equidistribuzione: tutti gli intervalli di pari lunghezza all‚Äôinterno dell‚Äôintervallo [a, b] hanno la stessa probabilit√†. In altre parole, se \\({\\displaystyle [c,d]}\\) √® un sottointervallo di \\({\\displaystyle [a,b]}\\), allora la probabilit√† che una variabile casuale continua con distribuzione uniforme in \\({\\displaystyle [a,b]}\\) cada in \\({\\displaystyle [c,d]}\\) √® \\({\\displaystyle (d-c)/(b-a)}\\).\nSvolgiamo un esercizio con Python in cui, per continuare il nostro esempio dello spinner, consideriamo una \\(\\mathcal {U}(0, 360)\\).\n\na = 0\nb = 360\nsize = 101\nx = np.linspace(a, b, size)\ny = st.uniform.pdf(x, loc=a, scale=b)\n\nplt.figure()\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.ylabel(\"Densit√†\");\n\n\n\n\n\n\n\n\nGeneriamo 100,000 valori casuali di una v.c. \\(\\Theta \\sim \\mathcal {U}(0, 360)\\).\n\ndata = rng.uniform(0, 360, size=100000)\n\nL‚Äôistogramma delle 100,000 realizzazioni di \\(\\Theta\\) √® il seguente.\n\nplt.figure()\nplt.hist(data, density=True, alpha=0.5)\nplt.xlabel(\"Theta ~ U[0, 360]\")\nplt.ylabel(\"Densit√†\")\nplt.title(\"Distribuzione uniforme\")\nplt.show()\n\n\n\n\n\n\n\n\n√à chiaro che, all‚Äôaumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell‚Äôistogramma tender√† a diventare una linea retta. Ci√≤ significa che la funzione di densit√† di una variabile casuale uniforme continua √® una costante: \\(f(\\Theta) = c\\).\nDalla figura precedente vediamo che l‚Äôarea sottesa alla funzione di densit√† √® \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densit√† di una variabile casuale uniforme continua non dipende da \\(\\theta\\) ‚Äì √® costante e identica per ogni possibile valore \\(\\theta\\).\nIl valore atteso di \\(X \\sim \\mathcal {U}(a,b)\\) √® dato da\n\\[\n\\mathbb{E} = \\frac{b - a}{2}.\n\\]\nNel caso della presente simulazione otteniamo\n\ndata.mean()\n\n180.44171561785456\n\n\nSvolgiamo un altro semplice esercizio. Consideriamo una variabile casuale uniforme \\(X\\) definita sull‚Äôintervallo [0, 100]. Poniamoci il problema di trovare la probabilit√† \\(P(20 &lt; X &lt; 60)\\).\nPer trovare la soluzione √® sufficiente calcolare l‚Äôarea di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilit√† cercata √® dunque \\(P(20 &lt; X &lt; 60) = 40 \\cdot 0.01 = 0.4\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "28¬† La funzione di densit√† di probabilit√†",
    "section": "28.2 Il paradosso delle variabili casuali continue",
    "text": "28.2 Il paradosso delle variabili casuali continue\nConsideriamo ora la probabilit√† che la variabile casuale continua assuma un valore specifico, come ad esempio una pendenza dello spinner esattamente uguale a 36 gradi. Sorprendentemente, la risposta √® zero:\n\\[\nP(\\Theta = 36) = 0.\n\\]\nCi√≤ √® dovuto al fatto che se la probabilit√† di un valore specifico fosse maggiore di zero, allora ogni altro possibile valore dovrebbe avere la stessa probabilit√†, poich√© abbiamo assunto che tutti i valori \\(\\Theta\\) sono egualmente probabili. Ma se sommiamo tutte queste probabilit√†, il totale sarebbe maggiore di uno, il che √® impossibile.\nNel caso delle variabili casuali continue, dobbiamo quindi rinunciare all‚Äôidea che ogni singolo valore della variabile casuale possa avere una massa di probabilit√† maggiore di zero. Invece, una massa di probabilit√† viene assegnata alla realizzazione della variabile casuale in un intervallo di valori. Questo √® ci√≤ che differenzia le variabili casuali continue dalle variabili casuali discrete, dove ogni singolo valore ha una probabilit√† di massa non nulla. In sintesi, le variabili casuali continue non hanno una massa di probabilit√†, ma una densit√† di probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densit√†",
    "href": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densit√†",
    "title": "28¬† La funzione di densit√† di probabilit√†",
    "section": "28.3 Dagli istogrammi alle densit√†",
    "text": "28.3 Dagli istogrammi alle densit√†\nLe considerazioni precedenti ci fanno comprendere che, a differenza delle variabili casuali discrete, non esiste l‚Äôequivalente di una funzione di massa di probabilit√† per le variabili casuali continue. Invece, esiste una funzione di densit√† di probabilit√† che pu√≤ essere definita in termini di una simulazione. Considerando un numero enorme di casi e facendo tendere l‚Äôampiezza \\(\\Delta\\) di ciascuna classe a 0, il profilo dell‚Äôistogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) √® detta funzione di densit√† di probabilit√†.\nIn un istogramma, l‚Äôarea di ogni barra √® proporzionale alla frequenza relativa delle osservazioni nell‚Äôintervallo considerato. Dato che tutti gli intervalli hanno la stessa ampiezza, l‚Äôaltezza di ogni barra sar√† proporzionale alla frequenza relativa delle osservazioni nell‚Äôintervallo. Nella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore nell‚Äôintervallo considerato. Con l‚Äôaumentare del numero di osservazioni \\(M\\), le probabilit√† stimate si avvicinano sempre di pi√π ai valori effettivi della probabilit√†. Inoltre, all‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo tende a 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® appunto la funzione di densit√† di probabilit√† della variabile casuale.\nIn precedenza, nella statistica descrittiva, abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico utilizzato per stimare la funzione di densit√† di probabilit√† di una variabile casuale.\nPer fare un esempio, generiamo 50 valori dalla distribuzione del quoziente di intelligenza. Stampiamo i primi 5 valori.\n\nmu, sigma = 100, 15\nsize = 50\nx = rng.normal(loc=mu, scale=sigma, size=size)\nx[:5]\n\narray([ 91.33354594, 104.82329102, 112.23027301, 123.44901535,\n        98.12903873])\n\n\nCreiamo ora un istogramma a cui sovrapponiamo la funzione di densit√† Normale con parametri corrispondenti alla media e deviazione standard del campione. Con poche osservazioni, non c‚Äô√® una buona corrispondenza tra l‚Äôistogramma e la curva continua che abbiamo chiamato ‚Äúfunzione di densit√†‚Äù.\n\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=25, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 103.58 e 13.34')\n\n\n\n\n\n\n\n\n\nOra aumentiamo il numero di osservazioni. In questo caso consideriamo 20,000 valori del QI. Generiamo dunque una figura simile alla precedente, solo considerando un campione di dati pi√π grande.\n\nsize = 10000\nx = rng.normal(loc=mu, scale=sigma, size=size)\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=50, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 103.39 e 15.05')\n\n\n\n\n\n\n\n\n\nOra vediamo che c‚Äô√® una corrispondenza molto buona tra il profilo dell‚Äôistogramma e la curva continua. Questo ci consente la seguente interpretazione: la funzione di densit√† √® una curva che approssima il profilo di un istogramma, quando consideriamo un grande numero di osservazioni. In altre parole, una funzione di densit√† non √® altro che un (profilo di un) istogramma nel caso di un numero infinito di osservazioni e intervalli di ampiezza \\(\\Delta\\) infinitamente piccoli.\nIn un istogramma, l‚Äôarea di ciascuna barra √® proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo. Perch√© tutti gli intervalli hanno la stessa ampiezza, anche l‚Äôaltezza di ciascuna barra sar√† proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo.\nNella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore compreso nell‚Äôintervallo considerato. All‚Äôaumentare del numero \\(M\\) di osservazioni, le probabilit√† stimate si avvicinano sempre di pi√π ai veri valori della probabilit√†. All‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo \\(\\rightarrow\\) 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® la funzione di densit√† di probabilit√† della variabile casuale.\nNella statistica descrittiva abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico per stimare la funzione di densit√† di probabilit√† di una variabile casuale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "href": "chapters/probability/10_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "title": "28¬† La funzione di densit√† di probabilit√†",
    "section": "28.4 Funzione di densit√† di probabilit√†",
    "text": "28.4 Funzione di densit√† di probabilit√†\nDa un punto di vista matematico, l‚Äôintuizione precedente si pu√≤ esprimere nel modo seguente.\nPer descrivere le probabilit√† che possono essere associate ad una variabile casuale continua \\(X\\) √® necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due propriet√†:\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l‚Äôordinata della funzione di densit√† √® 0 o positiva;\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l‚Äôarea sottesa dalla \\(p(x)\\) √® unitaria2;\n\\(p(a &lt; x &lt; b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l‚Äôarea sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilit√† che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. √à possibile che \\(p(x) &gt; 1\\), quindi una densit√† di probabilit√† non pu√≤ essere interpretata come una probabilit√†. Piuttosto, la densit√† \\(p(x)\\) pu√≤ essere utilizzata per confrontare la credibilit√† relativa che pu√≤ essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui √® disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) &gt; p(x_l)\\), allora possiamo concludere che √® pi√π credibile, in termini relativi, osservare realizzazioni \\(X\\) nell‚Äôintorno di \\(x_k\\) piuttosto che nell‚Äôintorno di \\(x_l\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "28¬† La funzione di densit√† di probabilit√†",
    "section": "28.5 La funzione di ripartizione per una variabile casuale continua",
    "text": "28.5 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) √® definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCio√®, √® la probabilit√† che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua pu√≤ essere utilizzata per calcolare la probabilit√† che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "title": "28¬† La funzione di densit√† di probabilit√†",
    "section": "28.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "28.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.8.3\nscipy     : 1.12.0\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#footnotes",
    "href": "chapters/probability/10_density_func.html#footnotes",
    "title": "28¬† La funzione di densit√† di probabilit√†",
    "section": "",
    "text": "Georg Cantor dimostr√≤ che era impossibile mappare uno a uno i reali negli interi, dimostrando cos√¨ che l‚Äôinsieme dei reali √® non numerabile.‚Ü©Ô∏é\nPer quel che riguarda la notazione dell‚Äôintegrale, ovvero \\(\\int_x \\,\\operatorname {d}\\!x\\), rimando alla discussione di S.P. Thompson: https://calculusmadeeasy.org/1.html‚Ü©Ô∏é",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>28</span>¬† <span class='chapter-title'>La funzione di densit√† di probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html",
    "href": "chapters/probability/11_discr_rv_distr.html",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Introduzione\nLa previsione √® un processo che ci permette di formulare ipotesi su eventi incerti, sfruttando le regolarit√† osservate nei processi naturali, sociali e psicologici. Uno degli obiettivi principali della data science √® proprio quello di prevedere fenomeni di cui non abbiamo ancora certezza, inclusi, ma non limitati a, eventi futuri.\nLa capacit√† di fare previsioni senza considerare ogni possibile risultato dipende dalla conoscenza della popolazione di riferimento. Gli esseri umani organizzano e rappresentano questa conoscenza in vari modi. In questo capitolo, esploreremo le implicazioni di un approccio specifico alla rappresentazione delle popolazioni: le distribuzioni di probabilit√†.\nSupponiamo di avere una distribuzione di probabilit√† \\(p(x)\\) associata a una variabile casuale \\(X\\). Consideriamo che questa distribuzione rappresenti la variabilit√† osservata all‚Äôinterno di una popolazione. Se selezionassimo un‚Äôistanza in modo uniforme e casuale dalla popolazione, quale valore della variabile \\(X\\) dovremmo aspettarci? Ci aspettiamo che un campione estratto casualmente dalla popolazione segua la distribuzione \\(p(x)\\). In altre parole, questa distribuzione √® ci√≤ che definiamo un modello statistico, o pi√π semplicemente, un modello della popolazione. Il termine ‚Äúmodello‚Äù sottolinea che la distribuzione non √® la popolazione stessa, ma una rappresentazione astratta che utilizziamo per fare previsioni.\nIn particolare, ci concentreremo sulle distribuzioni di probabilit√† discrete, essenziali per comprendere i fenomeni aleatori che presentano un numero finito o numerabile di esiti. Queste distribuzioni sono cruciali nella modellazione e nell‚Äôanalisi di eventi che si verificano in contesti discreti, fornendo le basi per una comprensione pi√π profonda delle dinamiche probabilistiche che governano tali fenomeni.\nOgni distribuzione di probabilit√† √® caratterizzata da uno o pi√π parametri, che consentono di controllare specifici aspetti della distribuzione stessa. Esploreremo diverse distribuzioni discrete, ciascuna con le sue caratteristiche e applicazioni:\nIn sintesi, attraverso lo studio di queste distribuzioni, acquisiremo gli strumenti necessari per analizzare e prevedere una vasta gamma di situazioni reali.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Distribuzione di Bernoulli\n\nRappresenta esperimenti con due possibili esiti: ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù\nCostituisce il nucleo dei processi Bernoulliani\nParametro chiave: probabilit√† di successo in ciascuna prova\n\nDistribuzione Binomiale\n\nDescrive il numero totale di successi in un numero fisso di prove Bernoulliane\nNasce dalla somma di prove Bernoulliane indipendenti\nParametri: probabilit√† di successo in ciascuna prova e numero totale di prove\n\nDistribuzione di Poisson\n\nModella eventi rari o che si verificano su intervalli di tempo o spazio variabili\nAdatta quando il numero di prove √® una variabile casuale\nParametro: tasso medio di successo per unit√† di tempo o spazio\n\nDistribuzione Beta-Binomiale\n\nUtilizzata quando la probabilit√† di successo in una serie di prove Bernoulliane non √® costante\nOffre una rappresentazione pi√π flessibile rispetto alla distribuzione binomiale\nParametri: derivati dalla distribuzione Beta sottostante\n\nDistribuzione Uniforme Discreta\n\nOgni evento all‚Äôinterno di un determinato intervallo finito ha la stessa probabilit√†\nUtile quando non ci sono motivi per privilegiare un risultato rispetto a un altro\nNon dipende da parametri una volta stabilito il supporto della distribuzione",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.1 Distribuzione di Bernoulli",
    "text": "29.1 Distribuzione di Bernoulli\nIn statistica, un esperimento che presenta soltanto due esiti possibili viene modellato attraverso ci√≤ che √® noto come ‚Äúprova Bernoulliana‚Äù. Un esempio classico √® il lancio di una moneta, che pu√≤ risultare in testa o croce.\n\nDefinizione 29.1 Una variabile casuale \\(Y\\) che assume valori in \\(\\{0, 1\\}\\) √® definita come variabile di Bernoulli. La sua distribuzione di probabilit√† √® descritta come segue:\n\\[\nP(Y \\mid \\theta) =\n  \\begin{cases}\n    \\theta     & \\text{se $Y = 1$ (successo)}, \\\\\n    1 - \\theta & \\text{se $Y = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq \\theta \\leq 1\\). Il parametro \\(\\theta\\) rappresenta la probabilit√† dell‚Äôevento ‚Äúsuccesso‚Äù (\\(Y = 1\\)), mentre \\(1 - \\theta\\) quella dell‚Äôevento ‚Äúinsuccesso‚Äù (\\(Y = 0\\)).\n\nNella distribuzione Bernoulliana, la probabilit√† di osservare l‚Äôesito 1 √® \\(\\theta\\), mentre quella di osservare 0 √® \\(1 - \\theta\\). Questa distribuzione viene utilizzata per modellare situazioni in cui esistono due sole possibili risposte, come un ‚Äús√¨‚Äù o un ‚Äúno‚Äù, un ‚Äúsuccesso‚Äù o un ‚Äúinsuccesso‚Äù.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = \\theta, \\\\\n\\mathbb{V}(Y) &= (0 - \\theta)^2 \\cdot P(Y=0) + (1 - \\theta)^2 \\cdot P(Y=1) = \\theta(1-\\theta).\n\\end{align}\n\\tag{29.1}\\]\nEsplicitando ulteriormente la formula della varianza con \\(P(Y=0) = 1 - \\theta\\) e \\(P(Y=1) = \\theta\\), abbiamo:\n\\[ \\mathbb{V}(Y) = (0 - \\theta)^2 \\cdot (1 - \\theta) + (1 - \\theta)^2 \\cdot \\theta \\]\nCalcoliamo ora le singole parti dell‚Äôespressione: 1. $ (0 - )^2 = ^2 $ 2. $ (1 - )^2 = 1 - 2+ ^2 $\nSostituendo queste espressioni nell‚Äôequazione della varianza, otteniamo:\n\\[ \\mathbb{V}(Y) = \\theta^2 \\cdot (1 - \\theta) + (1 - 2\\theta + \\theta^2) \\cdot \\theta \\]\n\\[ \\mathbb{V}(Y) = \\theta^2 - \\theta^3 + \\theta - 2\\theta^2 + \\theta^3 \\]\nSemplificando:\n\\[ \\mathbb{V}(Y) = \\theta - \\theta^2 \\]\n\\[ \\mathbb{V}(Y) = \\theta(1-\\theta) \\]\nQuindi, l‚Äôequazione iniziale mostra come la varianza di una variabile casuale binaria \\(Y\\), che segue una distribuzione di Bernoulli con parametro \\(\\theta\\), sia espressa come \\(\\theta(1-\\theta)\\). Questo rispecchia il fatto che la varianza di una distribuzione di Bernoulli raggiunge il suo massimo quando \\(\\theta = 0.5\\), indicando la massima incertezza (o variabilit√†) quando la probabilit√† di successo √® uguale a quella di fallimento.\n\n# Define theta values between 0 and 1\ntheta = np.linspace(0, 1, 100)\n\n# Variance of a Bernoulli distribution is theta(1-theta)\nvariance = theta * (1 - theta)\n\nplt.plot(theta, variance, label='Varianza', color='blue')\nplt.title('Varianza di una variabile Bernoulliana in funzione di $\\\\theta$')\nplt.xlabel('$\\\\theta$')\nplt.ylabel('Varianza')\nplt.show()\n\n\n\n\n\n\n\n\nUtilizziamo la notazione \\(Y \\sim Bernoulli(\\theta)\\) per indicare che la variabile casuale \\(Y\\) segue una distribuzione Bernoulliana di parametro \\(\\theta\\).\nAd esempio, nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilit√† di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilit√† assegna una probabilit√† di \\(\\frac{1}{2}\\) sia per \\(Y = 0\\) che per \\(Y = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(Y = 0\\) e \\(1\\) per \\(Y = 1\\).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.2 Distribuzione Binomiale",
    "text": "29.2 Distribuzione Binomiale\nLa distribuzione binomiale √® una distribuzione di probabilit√† discreta fondamentale, che si concentra sul conteggio del numero di successi in una serie di prove Bernoulliane indipendenti. Queste prove sono caratterizzate dal fatto che ogni evento ha solo due possibili esiti: ‚Äúsuccesso‚Äù o ‚Äúinsuccesso‚Äù, con una probabilit√† di successo costante denotata da \\(\\theta\\).\n\nDefinizione 29.2 La distribuzione binomiale quantifica la probabilit√† di osservare esattamente \\(y\\) successi in \\(n\\) tentativi indipendenti di Bernoulli:\n\\[\nP(Y=y) = \\binom{n}{y} \\theta^{y} (1-\\theta)^{n-y} = \\frac{n!}{y!(n-y)!} \\theta^{y} (1-\\theta)^{n-y},\n\\] (eq-binomialdistribution)\nQui, \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di combinazioni possibili per ottenere \\(y\\) successi in \\(n\\) prove, mentre \\(\\theta\\) √® la probabilit√† costante di successo per ogni prova.\n\nLa distribuzione binomiale √® spesso illustrata con esempi come il lancio di una moneta o l‚Äôestrazione da un‚Äôurna. Ad esempio, nel caso del lancio ripetuto di una moneta, questa distribuzione descrive la probabilit√† di ottenere un numero specifico di teste in un certo numero di lanci, con ciascun lancio che segue una distribuzione di Bernoulli con probabilit√† di successo \\(\\theta\\).\nUn aspetto interessante della distribuzione binomiale √® la sua propriet√† di riproducibilit√†: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono distribuzioni binomiali con lo stesso parametro \\(\\theta\\), ma con diversi numeri di prove (\\(N_1\\) e \\(N_2\\)), allora la loro somma, \\(y = y_1 + y_2\\), sar√† anch‚Äôessa distribuita binomialmente, con parametri \\(N_1 + N_2\\) e \\(\\theta\\).\n\n29.2.1 Calcolo delle Probabilit√†\nPer approfondire il calcolo delle probabilit√† in questa distribuzione, esaminiamo una serie di prove Bernoulliane. Consideriamo una serie di \\(n\\) prove che risultano in \\(y\\) successi:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ volte} \\overbrace{II\\dots I}^\\text{$n-y$ volte}\n\\]\nOgni sequenza con \\(y\\) successi specifici ha una probabilit√† di \\(\\theta^y \\cdot (1-\\theta)^{n-y}\\). Tuttavia, siamo interessati alla probabilit√† complessiva di osservare qualsiasi sequenza con \\(y\\) successi, che si ottiene moltiplicando la probabilit√† di una sequenza singola per il numero totale di sequenze possibili, dato dal coefficiente binomiale \\(\\binom{n}{y}\\).\nIn questo modo, la distribuzione binomiale diventa uno strumento statistico per analizzare fenomeni che presentano esiti binari, con prove che sono indipendenti e identicamente distribuite. Questa distribuzione trova applicazione in una moltitudine di scenari, dalla valutazione del numero di successi in una serie di tentativi, come i lanci di moneta, fino a sondaggi di opinione e altro ancora.\n\n\n29.2.2 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l‚Äôapplicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilit√† di successo in ogni prova √® \\(\\theta = 0.2\\). La probabilit√† di ottenere questo risultato specifico √® calcolata utilizzando l‚Äôeq. {eq}eq-binomialdistribution:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo pu√≤ essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\nn = 4\ntheta = 0.2\ny = 2\n\nprob = math.comb(n, y) * theta**y * (1 - theta) ** (n - y)\nprint(prob)\n\n0.15360000000000007\n\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\nstats.binom.pmf(y, n, theta)\n\n0.15359999999999993\n\n\nUtilizzando scipy.stats.binom.pmf(y, n, p), possiamo trovare le probabilit√† per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\ny = np.arange(0, n + 1)\nprint(y)\n\n[0 1 2 3 4]\n\n\n\nprobabilities = stats.binom.pmf(y, n, theta)\nprint(*probabilities)\n\n0.40959999999999985 0.4096 0.15359999999999993 0.02559999999999999 0.0016000000000000003\n\n\nVisualizziamo la distribuzione di massa di probabilit√†:\n\nplt.figure()\nplt.plot(y, probabilities, \"o\", ms=8)\nplt.vlines(y, 0, probabilities, linestyles=\"-\", lw=1)\nplt.title(f\"Distribuzione binomiale: $n$={n}, $\\\\theta$={theta}\")\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilit√†\")\nplt.xlim(-0.5, n + 0.5)\nplt.ylim(0, max(probabilities) + 0.05)\nplt.show()\n\n\n\n\n\n\n\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilit√† di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\nplt.figure()\n\nfor theta in np.arange(0.3, 1.0, 0.3):\n    y = np.arange(0, 25)\n    binom_dist = stats.binom.pmf(y, 20, theta)\n    plt.plot(y, binom_dist, \"-o\", label=f\"theta = {theta:.1f}\")\n\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilit√†\")\nplt.title(\"Distribuzione binomiale al variare di $\\\\theta$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nUn‚Äôaltra propriet√† interessante della distribuzione binomiale √® la sua riproducibilit√†. Se abbiamo due variabili casuali indipendenti che seguono distribuzioni binomiali con lo stesso parametro \\(\\theta\\) ma con diversi numeri di prove, la loro somma seguir√† anch‚Äôessa una distribuzione binomiale. Questo pu√≤ essere dimostrato analiticamente o sperimentato empiricamente.\n\n# Parameters\nn1, n2 = 10, 15  # Number of trials\ntheta = 0.5  # Success probability\n\n# Analytical binomial distributions\nx1 = np.arange(0, n1+1)\ny1 = stats.binom.pmf(x1, n1, theta)\nx2 = np.arange(0, n2+1)\ny2 = stats.binom.pmf(x2, n2, theta)\n\n# Combined analytical distribution\nx_combined = np.arange(0, n1+n2+1)\ny_combined = stats.binom.pmf(x_combined, n1+n2, theta)\n\n# Simulated distributions\nsimulated1 = rng.binomial(n1, theta, 10000)\nsimulated2 = rng.binomial(n2, theta, 10000)\nsimulated_combined = simulated1 + simulated2\n\n# Plotting\nplt.figure(figsize=(18, 6))\n\n# Plot 1: Binomial 1\nplt.subplot(1, 3, 1)\nplt.bar(x1, y1, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated1, bins=range(n1+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Binomial Distribution n={n1}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.ylabel('Probability')\nplt.legend()\n\n# Plot 2: Binomial 2\nplt.subplot(1, 3, 2)\nplt.bar(x2, y2, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated2, bins=range(n2+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Binomial Distribution n={n2}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.legend()\n\n# Plot 3: Combined Binomial\nplt.subplot(1, 3, 3)\nplt.bar(x_combined, y_combined, color='blue', alpha=0.7, label='Analytical')\nplt.hist(simulated_combined, bins=range(n1+n2+2), density=True, alpha=0.5, color='red', label='Simulated')\nplt.title(f'Combined Binomial Distribution n={n1+n2}, $\\\\theta$={theta}')\nplt.xlabel('Successes')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual √® la probabilit√† che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\nstats.binom.pmf(2, n=5, p=0.5) + stats.binom.pmf(3, n=5, p=0.5) + stats.binom.pmf(4, n=5, p=0.5) +  stats.binom.pmf(5, n=5, p=0.5)\n\n0.8125\n\n\n\nnp.sum([stats.binom.pmf(k, n=5, p=0.5) for k in range(2, 6)])\n\n0.8125\n\n\nPi√π facilmente, si trova la risposta usando la funzione di ripartizione stats.binom.cdf.\n\n1 - stats.binom.cdf(1, n=5, p=0.5) \n\n0.8125\n\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\nn = 5\ntheta = 0.5\ny = np.arange(0, n+1)\n\nplt.figure()\nplt.plot(y, stats.binom.cdf(y, n=n, p=theta))\nplt.scatter(y, stats.binom.cdf(y, n=n, p=theta))\nplt.axhline(1, color=\"k\", alpha=0.7, linestyle=\"--\", lw=1)\nplt.title(f\"Funzione di ripartizione binomiale: $n$={n}, $\\\\theta$={theta}\", loc=\"left\")\nplt.xlabel(\"y\")\n_ = plt.ylabel(\"Probabilit√†\")\n\n\n\n\n\n\n\n\nUn‚Äôaltra funzione utile √® quella che trova il numero di successi in una distribuzione binomiale che corrisponde ad una data probabilit√† (nella coda sinistra della funzione ripartizione). Per l‚Äôesempio presente:\n\ntarget_probability = 1 - 0.8125\nstats.binom.ppf(target_probability, n, theta)\n\n1.0\n\n\nUtilizzando la funzione punto percentuale (PPF), che √® l‚Äôinverso della funzione di distribuzione cumulativa (CDF), possiamo trovare il numero di successi corrispondente alla probabilit√† target di \\(1 - 0.8125 = 0.1875\\) in una distribuzione binomiale con parametri \\(n = 5\\) e \\(\\theta = 0.5\\). Il risultato mostra che il numero di successi cercato per questa probabilit√† target √® 1.\nFacciamo un altro esempio. Consideriamo la probabilit√† cumulativa \\(P(Y \\leq 4)\\) per una variabile casuale \\(Y\\) che segue una distribuzione binomiale con numero di prove \\(n = 10\\) e probabilit√† di successo \\(\\theta = 0.2\\). La funzione stats.binom.cdf(4, n=10, p=0.2) calcola la probabilit√† che ci siano al massimo 4 successi in 10 tentativi, dove la probabilit√† di successo in ogni tentativo √® del 20%.\n\ntarget_probability = stats.binom.cdf(4, n=10, p=0.2)\ntarget_probability\n\n0.9672065024\n\n\nDi conseguenza, la funzione inversa √®:\n\nstats.binom.ppf(target_probability, n=10, p=0.2)\n\n4.0\n\n\nPer generare una sequenza di valori casuali seguendo una distribuzione binomiale possiamo utilizzare la funzione random() di NumPy. Dopo aver inizializzato rng = np.random.default_rng(RANDOM_SEED), per esempio,\n\nrng = np.random.default_rng(42)\n\npossiamo impiegare rng per generare valori casuali da una distribuzione binomiale:\n\nx = rng.binomial(p=.5, n=5, size=30)\nprint(*x)\n\n3 5 1 2 3 2 3 3 3 1 2 4 2 3 0 2 2 2 3 3 4 4 2 0 4 2 2 1 3 2\n\n\nPer una discussione sulla generazione di numeri pseudo-casuali in Python, si veda il capitolo {ref}appendix-rng.\n\n\n29.2.3 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si trovano nel modo seguente:\n\\[\n\\begin{align}\n\\mu    &= n\\theta,  \\notag \\\\\n\\sigma &= \\sqrt{n\\theta(1-\\theta)}.\n\\end{align}\n\\tag{29.2}\\]\nDimostrazione. Essendo \\(Y\\) la somma di \\(n\\) prove Bernoulliane indipendenti \\(Y_i\\), √® facile vedere che\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = n\\theta, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = n \\theta (1-\\theta).\n\\end{align}\n\\]\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilit√† di ottenere testa (successo) pari a \\(\\theta = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo √® dato da \\(\\mu = n \\theta\\), dove \\(n\\) √® il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(\\theta = 0.2\\), abbiamo:\n\\[\n\\mu = n \\theta = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale √® calcolata come \\(n \\theta (1-\\theta)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n \\theta (1-\\theta) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nx = rng.binomial(p=.2, n=4, size=1000000)\n\n\nnp.mean(x)\n\n0.79956\n\n\n\nnp.var(x, ddof=0)\n\n0.6397598064000003\n\n\n\n\n29.2.4 Funzioni Python associate alle distribuzioni di probabilit√†\n\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (y | n, Œ∏)\nEsempio: Normale (y | Œº, œÉ)\n\n\n\n\nFunzione di verosimiglianza\nbinom.pmf(y, n, Œ∏)\nnorm.pdf(y, Œº, œÉ)\n\n\nProb Y=y\nbinom.pmf(y, n, Œ∏)\nsempre 0\n\n\nProb Y ‚â• y, Y ‚â§ y, y1 &lt; Y &lt; y2\nbinom.cdf(y, n, Œ∏) o binom.sf(y, n, Œ∏)\nnorm.cdf(y, Œº, œÉ) o norm.sf(y, Œº, œÉ)\n\n\nInversa della CDF\nbinom.ppf(q, n, Œ∏)\nnorm.ppf(q, Œº, œÉ)\n\n\nGenerazione di dati simulati\nrng.binomial(p, n, size)\nrng.normal(Œº, œÉ, size\n\n\n\nIn seguito, utilizzeremo altre distribuzioni, come Uniforme, Beta, ecc., e ognuna di queste ha il proprio insieme di funzioni in Python trovate in scipy.stats. √à possibile consultare queste diverse distribuzioni in opere di riferimento o documentazione online.\nSi noti che pmf (funzione di massa di probabilit√†) √® usato per le distribuzioni discrete come la binomiale, mentre pdf (funzione di densit√† di probabilit√†) √® usata per le distribuzioni continue come la normale. cdf (funzione di distribuzione cumulativa) e sf (funzione di sopravvivenza, che √® 1 - cdf) sono utilizzate per calcolare le probabilit√† cumulative. ppf (percent point function) √® l‚Äôinverso della cdf e viene utilizzata per determinare il valore di variabile al di sotto del quale cade una certa percentuale delle osservazioni. rvs (random variates) √® usata per generare dati simulati.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.3 Distribuzione Discreta Uniforme",
    "text": "29.3 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme √® un tipo particolare di distribuzione di probabilit√†, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilit√† \\(p\\) di verificarsi. Questa distribuzione √® caratterizzata dalla sua semplicit√† e dalla sua propriet√† fondamentale di equiprobabilit√†.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che pu√≤ assumere valori nell‚Äôinsieme \\(\\{1, 2, \\dots, N\\}\\). Un‚Äôistanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilit√† di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilit√† che \\(X\\) assuma un valore specifico \\(x\\) √® uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilit√† di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci d√† un‚Äôidea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che √® la somma dei primi \\(N\\) numeri naturali. Questa somma √® data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) √® \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo √® calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilit√† (che √® \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l‚Äôidentit√† per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo gi√† stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l‚Äôespressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) √® \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-poisson",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-poisson",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.4 Distribuzione di Poisson",
    "text": "29.4 Distribuzione di Poisson\nCome riportato da Del Moral e Penev (2017), il giovane e talentuoso pescatore Sim√©on Denis Poisson stava scrivendo una serie di saggi sulle tecniche di pesca nel fiume Loiret nella primavera del 1823. Non esistevano potenti software per il controllo ortografico all‚Äôepoca, e Poisson era molto preoccupato di correggere tutti gli errori di stampa e ortografia. Leggendo le prime due pagine, trov√≤ gi√† quattro errori:\n\nA bab day of fishing is still better than a good day at the office‚Ä¶ If people concentrated on the really importants things in life, there would be a shortage of fishing poles‚Ä¶ Anyway, a woman who has never sen her husband fishing, doesn‚Äôt known what a patient man she married.\n\nSupponeva che tutti questi banali errori fossero stati fatti a un tasso unitario per ogni mezza pagina durante la digitazione. Dopo aver letto quattro pagine, riusc√¨ a fare alcune previsioni rigorose sulla probabilit√† di 0, 1, 2, ‚Ä¶ errori per pagina.\nInoltre, dimostr√≤ che, per un dato numero di errori su un dato numero di pagine, questi sarebbero stati distribuiti uniformemente nel testo. Corresse i primi errori e, dopo aver letto attentamente pi√π volte le prime 300 pagine, non trov√≤ altri errori. Era molto sorpreso e si sentiva un po‚Äô fortunato, poich√© si aspettava di trovare molti errori pi√π avanti nel testo. Dopo alcuni calcoli, vide che le probabilit√† di trovare errori nelle successive quattro pagine erano le stesse di quelle calcolate per le prime pagine. Questa intrigante propriet√† di assenza di memoria lo spinsero a passare dalla pesca alla creazione di una nuova teoria del conteggio degli eventi casuali.\nSim√©on Denis Poisson era un famoso matematico e fisico francese. Svilupp√≤ la sua teoria della probabilit√† nel 1837 nel suo lavoro ‚ÄúResearch on the Probability of Judgments in Criminal and Civil Matters‚Äù. Introdusse una distribuzione di probabilit√† discreta per il conteggio degli eventi casuali che si verificano indipendentemente l‚Äôuno dall‚Äôaltro in un dato intervallo di tempo o spazio. Questa distribuzione √® nota come distribuzione di Poisson, e il processo di conteggio √® chiamato processo di Poisson.\nLa distribuzione di Poisson √® utilizzata per modellare il numero di eventi indipendenti che si verificano in un intervallo di tempo o spazio prefissato. La variabile casuale discreta \\(Y\\) denota il numero di tali eventi, mentre il parametro \\(\\lambda\\) rappresenta il tasso medio di occorrenza di questi eventi in un intervallo specifico.\nLa funzione di massa di probabilit√† associata alla distribuzione di Poisson, che indica la probabilit√† che si verifichino esattamente \\(y\\) eventi, √® definita come segue:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\]\nQuesta equazione illustra:\n\n\\(P(Y = y \\mid \\lambda)\\), la probabilit√† che esattamente \\(y\\) eventi si verifichino.\n\\(\\lambda\\), il tasso medio di occorrenza degli eventi per l‚Äôintervallo considerato.\n\\(y\\), il numero di eventi, che √® limitato ai valori interi non negativi.\n\nUna peculiarit√† della distribuzione di Poisson √® che sia il valore atteso (\\(E[Y]\\)) sia la varianza (\\(Var[Y]\\)) sono equivalenti a \\(\\lambda\\). Questo significa che con l‚Äôaumentare del valore di \\(\\lambda\\), aumenta anche la dispersione dei dati attorno al valore medio, evidenziando un incremento della variabilit√† degli eventi.\nQuale esempio, presentiamo qui sotto un grafico con la distribuzione di Poisson di parametro \\(\\lambda\\) = 2.\n\n# Tasso medio di occorrenza di eventi\nlambda_value = 2\n\n# Creazione della distribuzione di Poisson con il tasso medio specificato\npoisson_dist = stats.poisson(mu=lambda_value)\n\n# Calcolo della probabilit√† di avere un certo numero di eventi\nk_values = range(0, 11)  # Consideriamo valori da 0 a 10\n\n# Calcolo delle probabilit√† corrispondenti\nprobabilities = poisson_dist.pmf(k_values)\n\nplt.figure()\n\n# Plot della distribuzione di massa di probabilit√†\nplt.bar(k_values, probabilities, alpha=0.5)\nplt.xlabel('Numero di Eventi (k)')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione di Massa di Probabilit√† di Poisson')\nplt.show()\n\n\n\n\n\n\n\n\nLa probabilit√† di ottenere un singolo valore \\(y\\) si calcola utilizzando la funzione di massa di probabilit√† (pmf), dove l‚Äôargomento k rappresenta il numero di eventi (\\(y\\)) e mu √® uguale a \\(\\lambda\\). Ad esempio, per determinare la probabilit√† di osservare esattamente tre eventi (\\(y = 3\\)) con un tasso di occorrenza \\(\\lambda\\) = 2, indicata come \\(P(Y = 3)\\), si utilizza la seguente istruzione:\n\nstats.poisson.pmf(k=3, mu=2)\n\n0.18044704431548356\n\n\nLa probabilit√† di non pi√π di 3 eventi, indicata come \\(P(Y \\leq 3)\\), si ottiene nel modo seguente:\n\np = stats.poisson.pmf(k=0, mu=2) + stats.poisson.pmf(k=1, mu=2) + stats.poisson.pmf(k=2, mu=2) + stats.poisson.pmf(k=3, mu=2)\np\n\n0.857123460498547\n\n\nLa funzione ppf, con la probabilit√† e \\(\\lambda\\) come argomenti, restituisce il quantile della distribuzione di Poisson. Ad esempio, nel caso precedente, abbiamo:\n\nstats.poisson.ppf(p, mu=2)\n\n3.0\n\n\nLa funzione di distribuzione cumulativa si calcola utilizzando cdf. Ad esempio, per calcolare \\(P(Y \\leq 3)\\) si utilizza:\n\nstats.poisson.cdf(3, mu=2)\n\n0.857123460498547\n\n\nLa generazione di numeri casuali dalla distribuzione di Poisson pu√≤ essere ottenuta utilizzando rng. Ad esempio:\n\nmu = 2\nx = rng.poisson(mu, 1000000)\n\nVerifichiamo:\n\nnp.mean(x)\n\n1.998219\n\n\n\nnp.var(x, ddof=0)\n\n1.996941828039\n\n\nEsempio. I dati provenienti dal reparto di maternit√† di un certo ospedale mostrano che c‚Äô√® una media storica di 4.5 bambini nati in questo ospedale ogni giorno. Qual √® la probabilit√† che domani nascano 6 bambini in questo ospedale?\nPer prima cosa, calcoliamo la probabilit√† teorica di questo evento utilizzando dpois(). Il numero di successi che stiamo considerando √® 6, quindi imposteremo x = 6. Inoltre, questa media storica di 4,5 nascite al giorno √® il nostro valore per lambda, quindi imposteremo lambda = 6.\n\np = stats.poisson.pmf(k=6, mu=4.5)\nprint(f\"La probabilit√† che domani in questo ospedale nasceranno 6 bambini √®: {p:.4f}\")\n\nLa probabilit√† che domani in questo ospedale nasceranno 6 bambini √®: 0.1281\n\n\nSimuliamo le nascite in questo ospedale per un anno (n = 365) utilizzando la funzione np.random.poisson e confrontiamo la proporzione di giorni in cui ci sono stati 6 nascite con la probabilit√† teorica che abbiamo calcolato in precedenza.\n\n# Simuliamo le nascite in un anno (365 giorni) con una media storica di 4.5 nascite al giorno\nn_days = 365\nmean_births_per_day = 4.5\nsimulated_births = rng.poisson(mean_births_per_day, n_days)\n\n# Calcoliamo la proporzione di giorni in cui sono nati esattamente 6 bambini nella simulazione\nproportion_six_births = np.mean(simulated_births == 6)\n\n# Stampiamo la proporzione calcolata\nprint(f\"La proporzione di giorni in cui, nella simulazione, sono nati 6 bambini √®: {proportion_six_births:.4f}\")\n\nLa proporzione di giorni in cui, nella simulazione, sono nati 6 bambini √®: 0.1342\n\n\nVisualizziamo i risultati della simulazione.\n\n# Visualizziamo l'istogramma delle nascite simulate\nplt.hist(simulated_births, bins=np.arange(12) - 0.5, density=True, alpha=0.5)\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\nplt.xticks(np.arange(11));\n\n\n\n\n\n\n\n\nCalcoliamo la probabilit√† teorica della nascita di pi√π di 6 bambini in un giorno.\n\nprob_more_than_six = 1 - stats.poisson.cdf(6, mean_births_per_day)\nprint(f\"La probabilit√† teorica di pi√π di 6 bambini nati √®: {prob_more_than_six:.4f}\")\n\nLa probabilit√† teorica di pi√π di 6 bambini nati √®: 0.1689\n\n\nCalcoliamo la proporzione corrispondente nella simulazione\n\nproportion_more_than_six = np.mean(simulated_births &gt; 6)\nprint(f\"La proporzione di giorni con pi√π di 6 bambini nati nella simulazione √®: {proportion_more_than_six:.4f}\")\n\nLa proporzione di giorni con pi√π di 6 bambini nati nella simulazione √®: 0.1808\n\n\n\nbins = np.arange(12) - 0.5\nhist, edges = np.histogram(simulated_births, bins=bins, density=True)\n\n# Disegna l'istogramma\nfor i in range(len(hist)):\n    if edges[i] &gt;= 6:\n        color = 'red'  # Colore per x &gt; 6\n    else:\n        color = 'blue'  # Colore per x &lt;= 6\n    plt.bar(edges[i], hist[i], width=1, align='edge', color=color, alpha=0.5)\n\n# Imposta etichette e titolo\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\n_ = plt.xticks(np.arange(11))",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.5 Distribuzione Beta-Binomiale",
    "text": "29.5 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilit√† nella probabilit√† di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilit√† per la distribuzione beta-binomiale √® data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{29.3}\\]\ndove:\n\n\\(y\\) indica il numero di successi osservati.\n\\(N\\) rappresenta il numero totale di tentativi.\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilit√† nella probabilit√† di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, √® definita tramite l‚Äôuso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL‚Äôimportanza della distribuzione beta-binomiale deriva dalla sua capacit√† di modellare situazioni in cui la probabilit√† di successo non √® fissa, ma segue una distribuzione di probabilit√†, specificatamente una distribuzione beta. Ci√≤ la rende particolarmente adatta per applicazioni in cui le probabilit√† di successo cambiano in maniera incerta da un tentativo all‚Äôaltro, come pu√≤ avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilit√† di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione pi√π realistica e flessibile per dati empirici che presentano variabilit√† nelle probabilit√† di successo.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-categorica",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-categorica",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.6 Distribuzione Categorica",
    "text": "29.6 Distribuzione Categorica\nLa distribuzione categorica √® una distribuzione di probabilit√† discreta che si applica a variabili aleatorie con pi√π di due possibili esiti. √à una generalizzazione della distribuzione Bernoulliana, che si limita a due esiti (successo e fallimento). Come vedremo in seguito, in Stan, la distribuzione categorica √® chiamata categorical ed √® utilizzata per modellare situazioni in cui un evento pu√≤ avere uno tra molti esiti mutuamente esclusivi, ognuno con una propria probabilit√† associata.\nLa distribuzione categorica descrive una variabile aleatoria discreta \\(X\\) che pu√≤ assumere uno dei \\(K\\) possibili valori, etichettati come \\(1, 2, \\ldots, K\\). Ogni valore ha una probabilit√† associata \\(p_k\\), dove \\(k\\) varia da 1 a \\(K\\), e la somma di tutte le probabilit√† √® pari a 1:\n\\[\np_1 + p_2 + \\ldots + p_K = 1.\n\\]\nLa probabilit√† che la variabile aleatoria \\(X\\) assuma il valore \\(k\\) √® data da \\(P(X = k) = p_k\\).\n\n29.6.1 Propriet√†\n\nEsiti Multipli: La distribuzione categorica pu√≤ modellare eventi con pi√π di due esiti. Ad esempio, se stiamo osservando il lancio di un dado a sei facce, la variabile aleatoria pu√≤ assumere uno dei sei valori, ognuno con la probabilit√† di $ $ in caso di un dado equo.\nGeneralizzazione della Distribuzione Bernoulliana: La distribuzione Bernoulliana √® un caso particolare della distribuzione categorical con due sole categorie. Per esempio, una variabile aleatoria che rappresenta il risultato di un lancio di una moneta (testa o croce) pu√≤ essere modellata con una distribuzione Bernoulliana, che √® semplicemente una distribuzione categorica con \\(K = 2\\).\nProbabilit√† Semplici e Semplici: Ogni categoria o esito ha una probabilit√† associata. Nella distribuzione categorica , queste probabilit√† sono rappresentate da un vettore simplex, che √® un vettore di probabilit√† non negative che sommano a 1.\n\n\n\n29.6.2 Utilizzo della Distribuzione Categorical in Stan\nNel contesto di Stan, la distribuzione categorica viene utilizzata per modellare la probabilit√† di un singolo esito tra molti. In termini pratici, se abbiamo una matrice di transizione \\(P\\) di una catena di Markov, dove ogni riga di \\(P\\) rappresenta la distribuzione categorical delle probabilit√† di transizione da uno stato corrente a uno degli stati possibili, possiamo usare la distribuzione categorical per definire la probabilit√† di osservare una transizione specifica.\nAd esempio, se uno studente si trova nello stato \\(A\\) al tempo \\(t\\) e le probabilit√† di transizione agli stati \\(A\\), \\(B\\) e \\(C\\) sono rispettivamente \\(0.7\\), \\(0.2\\), e \\(0.1\\), possiamo modellare la probabilit√† che l‚Äôevento successivo sia una transizione a uno di questi stati utilizzando la distribuzione categorical:\n\\[\nX \\sim \\text{categorical}(0.7, 0.2, 0.1)\n\\]\nQuesta sintassi dice che la variabile aleatoria \\(X\\) ha una distribuzione categorical con probabilit√† corrispondenti ai possibili esiti (stati \\(A\\), \\(B\\), \\(C\\)).\nLa distribuzione categorical √® particolarmente utile nei modelli di catene di Markov, come quello presentato in precedenza, dove rappresenta la probabilit√† di transizione tra stati in un sistema dinamico. Ogni transizione da uno stato a un altro √® trattata come un evento categorical, il che permette di modellare in modo flessibile sistemi con molti stati e transizioni complesse.\nDi seguito, esaminiamo come simulare una distribuzione categorica utilizzando numpy e come creare un istogramma per visualizzare la distribuzione di massa:\n\n# Definire le probabilit√† della distribuzione categorica\nprobabilities = [0.6, 0.3, 0.1]  # Le probabilit√† per ciascun esito\n\n# Definire le categorie\ncategories = [\"A\", \"B\", \"C\"]\n\n# Numero di campioni da generare\nn_samples = 1000\n\n# Simulare la distribuzione categorica\nsamples = np.random.choice(categories, size=n_samples, p=probabilities)\n\n# Creare un istogramma dei risultati\nplt.hist(samples, bins=np.arange(len(categories) + 1) - 0.5, edgecolor=\"black\")\nplt.xticks(range(len(categories)), categories)\nplt.xlabel(\"Categorie\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Istogramma della Distribuzione Categorica Simulata\")\nplt.show()\n\n\n\n\n\n\n\n\nConcludiamo chiarendo la relazione tra la distribuzione categoriale e quella multinomiale.\nDistribuzione Categoriale:\nLa distribuzione categoriale √® una distribuzione di probabilit√† discreta che descrive l‚Äôesito di una singola prova in cui ci sono \\(K\\) possibili categorie, ognuna con una propria probabilit√† associata. √à una generalizzazione della distribuzione Bernoulliana (che ha solo due esiti: successo o fallimento).\nEsempio: Lanciare un dado a sei facce una sola volta e osservare quale faccia viene visualizzata. Ogni faccia ha una probabilit√† associata di comparire.\nDistribuzione Multinomiale:\nLa distribuzione multinomiale √® una generalizzazione della distribuzione binomiale per pi√π di due categorie. Descrive l‚Äôesito di un numero fisso di prove, ognuna delle quali √® un‚Äôosservazione indipendente con una distribuzione categoriale identica.\nEsempio: Lanciare un dado a sei facce dieci volte e contare quante volte √® apparso ciascun numero.\nRelazione tra le Due Distribuzioni\n\nLa distribuzione categoriale pu√≤ essere vista come un caso speciale della distribuzione multinomiale quando si effettua una sola prova (\\(n = 1\\)). In altre parole, campionare da una distribuzione categoriale √® equivalente a campionare da una distribuzione multinomiale con una singola prova.\nNella distribuzione categoriale, otteniamo una singola categoria (esito), mentre nella distribuzione multinomiale, otteniamo un conteggio di esiti su pi√π prove.\n\nImplementazioni in NumPy\n\nnumpy.random.choice √® la funzione specifica di NumPy per campionare da una distribuzione categoriale. Consente di specificare un array di categorie e un array di probabilit√† corrispondenti, restituendo uno o pi√π campioni secondo la distribuzione specificata.\nnumpy.random.multinomial √® utilizzata per campionare da una distribuzione multinomiale, ma pu√≤ anche essere usata per simulare la distribuzione categoriale impostando il numero di prove (\\(n\\)) a 1. Quando si usa numpy.random.multinomial con \\(n = 1\\), si ottiene un risultato che rappresenta il conteggio degli esiti per quella singola prova, che √® effettivamente una distribuzione categoriale.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#considerazioni-conclusive",
    "href": "chapters/probability/11_discr_rv_distr.html#considerazioni-conclusive",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.7 Considerazioni Conclusive",
    "text": "29.7 Considerazioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarit√†. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilit√† nella probabilit√† di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilit√† a ogni evento in un insieme finito e discreto. Questa distribuzione √® particolarmente utile quando non abbiamo ragioni per assegnare probabilit√† diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell‚Äôanalisi statistica discreta e trovano applicazione in un‚Äôampia gamma di settori. In particolare, nel contesto dell‚Äôanalisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale √® cruciale, poich√© queste distribuzioni forniscono le basi per l‚Äôaggiornamento bayesiano, un concetto chiave che sar√† esplorato nei capitoli successivi.\nPer coloro interessati a tecniche pi√π avanzate, la generazione di valori casuali a partire da queste distribuzioni √® trattata nell‚Äôappendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l‚Äôapplicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni √® cruciale per chiunque desideri esplorare il vasto campo della probabilit√† e della statistica.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.8 Esercizi",
    "text": "29.8 Esercizi\n\nEsercizio 29.1 Per ciascuna delle distribuzioni di massa di probabilit√† discusse, utilizza Python per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l‚Äôintervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media pi√π una deviazione standard, calcolare la probabilit√† che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "29¬† Distribuzioni di v.c. discrete",
    "section": "29.9 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "29.9 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.13.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nDel Moral, Pierre, e Spiridon Penev. 2017. Stochastic Processes: From Applications to Theory. Chapman; Hall/CRC.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>29</span>¬† <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html",
    "href": "chapters/probability/12_cont_rv_distr.html",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "Introduzione\nAnalogamente a quanto avviene per le variabili casuali discrete, anche per le variabili casuali continue possiamo rappresentare la variabilit√† all‚Äôinterno di una popolazione attraverso un modello statistico, ma in questo caso utilizziamo le densit√† di probabilit√† ‚Äì si veda il Capitolo 28. Mentre le distribuzioni di probabilit√† discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le densit√† di probabilit√† sono fondamentali per descrivere variabili che possono assumere un continuum di valori.\nLa funzione di densit√† di probabilit√† \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilit√† all‚Äôinterno della popolazione. Questa funzione non fornisce la probabilit√† esatta di un singolo valore, ma piuttosto la probabilit√† di osservare valori di \\(X\\) all‚Äôinterno di un intervallo specifico. Cos√¨ come per le distribuzioni discrete, anche le densit√† di probabilit√† costituiscono un modello della popolazione, una rappresentazione matematica che ci consente di fare previsioni e di comprendere meglio i fenomeni aleatori continui.\nIniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-uniforme",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-uniforme",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.1 Distribuzione uniforme",
    "text": "30.1 Distribuzione uniforme\nLa distribuzione uniforme √® la pi√π sempilce funzione di densit√† di probabilit√†. Consideriamo nuovamente l‚Äôesperimento con lo spinner che abbiamo introdotto nel Capitolo 28. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\ny = rng.uniform(low=0, high=360, size=20)\nprint(y)\n\n[272.91158643 127.62934853 349.45128878 321.52360368 280.21805895\n  70.06993483 168.01956134  15.76935568  55.54421714 245.89762317\n 268.11437613 348.30350368 117.29712893 133.36549417 169.04009206\n  68.20968927  46.77174192 171.25377344  81.68736566 241.13303809]\n\n\n\nplt.figure()\ncount, bins, ignored = plt.hist(y, bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\nplt.ylabel(\"Frequenza relativa\");\n\n\n\n\n\n\n\n\nSebbene possiamo pensare che sia ugualmente probabile che si verifichi qualsiasi risultato tra 0 e 360, l‚Äôistogramma non sembra suggerire questo. Ma lo spinner √® stato fatto ruotare solo 20 volte. Proviamo con 100,000 ripetizioni.\n\nplt.figure()\ncount, bins, ignored = plt.hist(rng.uniform(0, 360, 100000), bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\n_ = plt.ylabel(\"Frequenza relativa\")\n\n\n\n\n\n\n\n\nIn questo caso, anche se c‚Äô√® una variazione nelle altezze delle barre (con \\(\\Delta\\) = 10), la forma generale dell‚Äôistogramma sembra essere piuttosto piatta, ovvero uniforme, nell‚Äôintero intervallo dei valori possibili di \\(X\\), ovvero \\(0 &lt;= X &lt;= 360\\). Se potessimo ottenere un numero enorme di risultati dello spinner, il profilo dell‚Äôistogramma assumerebbe la forma della funzione di densit√† uniforme mostratra nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 100)\nplt.plot(x, stats.uniform.pdf(x, 0, 360), lw=2, label=\"uniform pdf\")\nplt.xlabel(\"x\")\nplt.ylabel(\"p(x)\");\n\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) √® continua, come nel caso del risultato della rotazione dello spinner, allora per rappresentare le probabilit√† usiamo una curva chiamata funzione di densit√† di probabilit√†. Poich√© la scala dello spinner va da 0 a 360, sappiamo che tutti i risultati possibili devono cadere in questo intervallo, quindi la probabilit√† che \\(X\\) assuma un valore nell‚Äôintervallo [0, 360] √® 1.0. Questa probabilit√† √® rappresentata dall‚Äôarea totale sotto la funzione di densit√† della figura precedente tra 0 e 360. Poich√© l‚Äôarea di questo rettangolo √® data dall‚Äôaltezza per la base e la base √® uguale a 360, l‚Äôaltezza di questa curva di densit√† deve essere 1/360 = 0.00278. L‚Äôordinata della funzione di densit√† (qui 0.00278 nell‚Äôintervallo [0, 360] e 0 altrove) √® chiamata densit√†.\nLe probabilit√† corrispondono alle aree sottese alla curva di densit√† nell‚Äôintervallo di valori \\(X\\) specificato. Per esempio, nell‚Äôesperimento dello spinner possiamo chiederci quale sia la probabilit√† di ottenere un numero compreso tra 150 e 250, ovvero \\(P(150 &lt; X &lt; 250)\\). Per trovare la risposta dobbiamo calcolare l‚Äôarea di un rettangolo. La base √® 250 - 150 = 100. L‚Äôaltezza √® 0.00278. Dunque, la probabilit√† √®\n\n100*1/360\n\n0.2777777777777778\n\n\nPer svolgere questo calcolo i software utilizzano la funzione di ripartizione, \\(P(X &lt; x)\\). Per trovare l‚Äôarea in un intervallo √® necessario sottrarre due aree. Nel caso presente abbiamo \\(P(x &lt; 250) - P(x &lt; 150)\\), ovvero:\n\nstats.uniform.cdf(250, 0, 360) - stats.uniform.cdf(150, 0, 360)\n\n0.27777777777777773\n\n\nLa probabilit√† cercata √® rappresentata dal rettangolo indicato nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 1000)\nfx = stats.uniform.pdf(x, 0, 360)\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 150) & (x &lt;= 250), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera pi√π formale possiamo dire che la distribuzione continua uniforme √® una distribuzione di probabilit√† continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l‚Äôintervallo unitario \\(I=[0,1]\\).\nLa densit√† di probabilit√† di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) √®\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto √®\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza √®\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn Python √® possibile manipolare la distribuzione uniforme mediante la funzione uniform del modulo scipy.stats. Di default, la funzione scipy.stats.uniform() √® un‚Äôistanziazione di \\({\\mathcal{U}}(0,1)\\). Se utilizziamo la funzione pdf() (probability density function) otteniamo l‚Äôordinata della funzione di densit√† \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei valori \\(x\\) passati in input. Per esempio, esaminiamo la funzione di densit√† \\({\\mathcal{U}}(0,1)\\) in corrispondenza di 0.5, 0.8 e 1.2. Per i primi due valori ci aspettiamo di ottenere 1; in corrispondenza di 1.2 ci aspettiamo di ottenere 0, poich√© questo valore √® al di fuori dell‚Äôintervallo \\([ 0, 1]\\).\n\nstats.uniform.pdf([0.5, 0.8, 1.2])\n\narray([1., 1., 0.])\n\n\nCon la funzione cdf() (cumulative density function) otteniamo la funzione di ripartizione. Per esempio, per \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei punti 0.5 e 0.8 otteniamo\n\nstats.uniform.cdf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nUsando la funzione di ripartizione √® possibile calcolare la probabilit√† che la variabile casuale continua assuma un valore nell‚Äôintervallo specificato. Per esempio, per \\({\\mathcal{U}}(0,1)\\) troviamo \\(P(0.5 &lt; x &lt; 0.8)\\)\n\nstats.uniform.cdf(0.8) - stats.uniform.cdf(0.5)\n\n0.30000000000000004\n\n\nI quantili di una funzione di densit√† (ovvero, il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input) si ottengono con la funzione ppf() (probability point function). Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di una \\({\\mathcal  {U}}(0,1)\\).\n\nstats.uniform.ppf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nInfine, √® possibile simulare dei valori casuali della distribuzione \\({\\mathcal{U}}(0,1)\\) usando la funzione stats.uniform(). Se vogliamo 5 valori da una \\({\\mathcal{U}}(0,1)\\), scriviamo:\n\nrng.uniform(0, 1, 5)\n\narray([0.51383373, 0.32883263, 0.16402071, 0.13786892, 0.15572435])\n\n\nVerifico il valore atteso di 100,000 realizzazioni di \\({\\mathcal {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).mean()\n\n0.4993283752250098\n\n\nVerifico la varianza di 100,000 realizzazioni di \\({\\mathcal  {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).var()\n\n0.0832097723457758\n\n\n\n1 / 12\n\n0.08333333333333333",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.2 Distribuzione esponenziale",
    "text": "30.2 Distribuzione esponenziale\nUn‚Äôaltra distribuzione di densit√† molto semplice √® la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale √® l‚Äôunica distribuzione di probabilit√† continua che possiede la propriet√† di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinch√© un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si √® rotto dopo 3 anni dal primo utilizzo. L‚Äôassenza di memoria significa che la probabilit√† che questo bicchiere da vino non si rompa nel prossimo anno √® la stessa della probabilit√† che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densit√† esponenziale √®\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{30.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale √®\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale √®\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard √® dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\nPer disegnare un grafico della funzione esponenziale possiamo usare la funzione stats.expon(). La densit√† √® data da pdf(x, loc, scale), laddove il parametro loc √® 0 e scale √® la deviazione standard. Nel caso presente abbiamo:\n\nx = np.arange(0, 20, 0.01)\nmu = 4\nlam = 1 / mu\nstdev = 1 / lam\npdf = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\");\n\n\n\n\n\n\n\n\nChiediamoci, ad esempio, quale sia la probabilit√† di dovere aspettare non pi√π di un giorno e mezzo per conoscere il voto dell‚Äôesame. La risposta a questa domanda √® data dalla funzione di ripartizione in corrispondenza di 1.5, ovvero \\(F(1.5) = P(X \\leq 1.5)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 0) & (x &lt;= 1.5), color=\"0.75\");\n\n\n\n\n\n\n\n\nPossiamo trovare la risposta usando la funzione cdf():\n\nstats.expon.cdf(1.5, loc=0, scale=stdev) \n\n0.3127107212090278\n\n\nChiediamoci, ad esempio quale sia la probabilit√† di conoscere il voto in un tempo compreso tra 1 e 6 giorni. Dobbiamo trovare l‚Äôarea sottesa alla funzione di densit√† nell‚Äôintervallo [1, 6]. Usando la fuzione di ripartizione, calcoliamo \\(F(6) - F(1) = P(X &lt;= 6) - P(X &lt;= 1)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1) & (x &lt;= 6), color=\"0.75\");\n\n\n\n\n\n\n\n\n\nstats.expon.cdf(6, loc=0, scale=stdev) - stats.expon.cdf(1, loc=0, scale=stdev)\n\n0.5556706229229751\n\n\nTroviamo la probabilit√† di dovere aspettare almeno 5 giorni e mezzo.\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 5.5) & (x &lt;= 21), color=\"0.75\");\n\n\n\n\n\n\n\n\nLa probabilit√† cercata √® data dalla probabilit√† dell‚Äôevento complementare di quello fornito dalla funzione di ripartizione.\n\n1 - stats.expon.cdf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\n\nstats.expon.sf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\nSe la media del tempo di attesa nel Corso di Laurea fosse di 4 giorni, allora circa una volta su 4 lo studente dovr√† aspettare almeno 5.5 giorni per conoscere il voto dello scritto.\nLa figura seguente mostra un istogramma di 1000000 valori casuali estratti dalla distribuzione esponenziale di parametro \\(\\lambda = 1/4\\). All‚Äôistogramma √® sovrapposta la funzione di densit√†.\n\nsamps = rng.exponential(stdev, 100000)\n\nplt.figure()\ncount, bins, ignored = plt.hist(samps, bins=100, density=True, alpha=0.5)\nplt.plot(x, fx)\nplt.xlim([0, 20])\nplt.ylabel(\"Frequenza relativa\")\nplt.xlabel(\"Tempo di attesa\");",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.3 Distribuzione Gaussiana",
    "text": "30.3 Distribuzione Gaussiana\nLa pi√π importante distribuzione di densit√† √® la Gaussiana. Non c‚Äô√® un‚Äôunica distribuzione gaussiana (o Normale): la distribuzione gaussiana √® una famiglia di distribuzioni. Tali distribuzioni sono dette ‚Äúgaussiane‚Äù in onore di Carl Friedrich Gauss (uno dei pi√π grandi matematici della storia il quale, tra le altre cose, scopr√¨ l‚Äôutilit√† di tale funzione di densit√† per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densit√† alle misurazioni dell‚Äôuomo. Karl Pearson us√≤ per primo il termine ‚Äúdistribuzione normale‚Äù anche se ammise che questa espressione ‚Äúha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell‚Äôaltro, non siano normali.‚Äù\n\n30.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre not√≤ che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilit√† di successo di 0.9, la distribuzione √® chiaramente asimmetrica.\n\nn = 10\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist);\n\n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilit√† di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densit√† di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilit√† binomiale.\n\nn = 1000\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist)\nplt.xlim(850, 950);\n\n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.4 La Normale prodotta con una simulazione",
    "text": "30.4 La Normale prodotta con una simulazione\nIl libro ‚ÄúRethinking Statistics‚Äù di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo pu√≤ variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall‚Äôorigine, che √® il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non √® possibile determinare la posizione esatta di ogni individuo, ma √® possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall‚Äôorigine.\nAd esempio, √® possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall‚Äôorigine. Queste previsioni sono fattibili perch√© la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sar√† usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando cos√¨ il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps √® un elenco di numeri di passi in cui il codice traccer√† linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array √® riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verr√† utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri della simulazione\nnumero_passi = 16  # Numero di passi per passeggiata\nripetizioni = 1000  # Numero di passeggiate da generare\npunti_da_evidenziare = [4, 8, 16]  # Punti da evidenziare sul grafico\n\n# Inizializza l'array per registrare le passeggiate casuali\nx = np.zeros((numero_passi + 1, ripetizioni))\n\n# Genera le passeggiate casuali\nfor i in range(ripetizioni):\n    passi = rng.uniform(-1, 1, numero_passi)  # Genera passi casuali\n    x[1:, i] = np.cumsum(passi)  # Calcola la posizione cumulativa\n\n# Prepara il grafico\nfig, ax = plt.subplots()\nplt.plot(x, color=\"blue\", alpha=0.05)  # Disegna tutte le passeggiate\nplt.plot(x[:, 0], color=\"black\")  # Evidenzia la prima passeggiata\n\n# Evidenzia i punti specifici\nfor punto in punti_da_evidenziare:\n    plt.axvline(punto, linestyle=\"--\", color=\"black\", alpha=0.5)\n\n# Imposta etichette e aspetti del grafico\nplt.xlabel(\"Numero di passi\")\nplt.ylabel(\"Distanza dall'origine\")\nax.set_xticks(punti_da_evidenziare)\nplt.xlim(0, numero_passi + 0.1)\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota √® che, man mano che procediamo nel numero di passi, le densit√† iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\n# Crea una figura con 3 subplots in orizzontale, condividendo l'asse X\nfig, axs = plt.subplots(1, 3, figsize=(9, 3), sharex=True)\n\n# Itera sui punti da evidenziare e sugli assi corrispondenti\nfor step, ax in zip(punti_da_evidenziare, axs):\n    # Estrae le posizioni al passo specificato per tutte le ripetizioni\n    posizioni_al_passo = x[step, :]\n    \n    az.plot_kde(posizioni_al_passo, bw=0.01, ax=ax)\n    \n    ax.set_title(f\"{step} passi\")\n    ax.set_ylabel(\"Densit√†\")\n    ax.set_xlabel(\"Posizioni\")\n    ax.set_xlim(-6, 6)\n    ax.set_xticks([-6, -3, 0, 3, 6])\n\nplt.tight_layout() \nplt.show()\n\n\n\n\n\n\n\n\nLa chiarezza dell‚Äôinformazione presentata nei grafici precedenti pu√≤ essere migliorata utilizzando un KDE plot.\n\n# Genera la distribuzione uniforme e calcola la somma come prima\npos = rng.uniform(-1, 1, size=(16, 1000)).sum(0)\n\n# Calcola media e deviazione standard dei dati generati\nmedia, dev_std = np.mean(pos), np.std(pos)\n\n# Spazio dei valori per la distribuzione normale\nvalori = np.linspace(np.min(pos), np.max(pos), 1000)\n\n# Calcola la distribuzione normale con la stessa media e deviazione standard\ndistribuzione_normale = stats.norm.pdf(valori, media, dev_std)\n\n# Disegna la stima della densit√† kernel dei dati\naz.plot_kde(pos, label='Distribuzione KDE')\n\n# Sovrappone la distribuzione normale\nplt.plot(valori, distribuzione_normale, label='Distribuzione Normale', color = \"C1\", linestyle='--')\n\nplt.xlabel(\"Posizione\")\nplt.ylabel(\"Densit√†\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilit√†: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che pu√≤ essere uniforme, come nell‚Äôesempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocit√† con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocit√† di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno √® rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana √® quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa pu√≤ essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ci√≤, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni pi√π lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densit√† di probabilit√† √® distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{30.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densit√† normale √® unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densit√† in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell‚Äôeq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densit√† Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 √® fornita nella figura seguente.\n\nx = np.arange(-5, 6, 0.001)\n\nmus = [-1.0, -0.5, 0.0, 1.0]\nsigmas = [0.25, 0.5, 1, 2]\n\nplt.figure()\n\nfor mu, sigma in zip(mus, sigmas):\n    pdf = stats.norm.pdf(x, mu, sigma)\n    plt.plot(x, pdf, label=r\"$\\mu$ = {}, $\\sigma$ = {}\".format(mu, sigma))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n30.4.1 Concentrazione\n√à istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media √® superiore a 3 volte la deviazione standard presenti un carattere di eccezionalit√† perch√© meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n\n30.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) √® l‚Äôarea sottesa alla curva di densit√† \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilit√† \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEsaminiamo le funzioni per la densit√† Normale. Il metodo rng.normal(loc, scale, size) produce size valori casuali estratti dalla distribuzione Normale specificata. Per esempio, un singolo valore casuale dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\) √®:\n\nrng.normal(loc=100, scale=15, size=1)\n\narray([77.8271813])\n\n\nEstraiamo ora 10 valori a caso dalla \\(\\mathcal{N}(100, 15)\\):\n\nqi = rng.normal(loc=100, scale=15, size=10)\nprint(qi)\n\n[107.37134121  74.33288092  70.05953321 100.16099998  67.01041676\n 102.19573565 114.68076458  58.88627549  69.38274746 112.14401099]\n\n\nPer trovare la probabilit√† che un‚Äôosservazione estratta a caso dalla \\(\\mathcal{N}(100, 15)\\) abbia un valore minore o uguale a, diciamo, 115, troviamo il valore della funzione di ripartizione (o funzione cumulativa di densit√†) nel punto 115.\n\nstats.norm.cdf(115, 100, 15)\n\n0.8413447460685429\n\n\nQuesta √® l‚Äôarea sottesa alla funzione di densit√† nell‚Äôintervallo \\([-\\infty, 115]\\), come indicato nella figura seguente.\n\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\n\nplt.figure()\nplt.plot(x, fx)\n_ = plt.fill_between(x, fx, where=x &lt;= 115, color=\"0.75\")\n\n\n\n\n\n\n\n\nSolo per fare un esempio, qui di seguito fornisco il codice Python per calcolare l‚Äôintegrale che stiamo discutendo per mezzo della funzione quad della libreria SciPy:\n\ndef gaussian(x, mu, sig):\n    return (\n        1.0 / (np.sqrt(2.0 * np.pi) * sig) * np.exp(-np.power((x - mu) / sig, 2.0) / 2)\n    )\n\nmu = 100\nsigma = 15\nresult, error = quad(gaussian, -1000, 115, args=(mu, sigma))\nprint(\"Il risultato √®\", result, \"con errore\", error)\n\nIl risultato √® 0.8413447460685429 con errore 4.0191197364560644e-10\n\n\nIl risultato replica quello prodotto da .norm.cdf().\nPer trovare la proporzione di persone nella popolazione che hanno un QI maggiore di 2 deviazioni standard dalla media consideriamo l‚Äôevento complementare:\n\n1 - stats.norm.cdf(130, 100, 15)\n\n0.02275013194817921\n\n\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=x &gt;= 130, color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo usare la Survival Function:\n\nstats.norm.sf(130, 100, 15)\n\n0.022750131948179198\n\n\nLa funzione ppf restituisce il quantile della Normale. Ad esempio:\n\nstats.norm.ppf(1 - 0.022750131948179195, 100, 15)\n\n130.0\n\n\n\n\n30.4.3 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale √® l‚Äôinsieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL‚Äôarea sottesa alla curva di densit√† di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) √® uguale all‚Äôarea sottesa alla densit√† Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) √® il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l‚Äôarea sottesa nella semiretta \\([1, \\infty)\\) √® uguale all‚Äôarea sottesa nella semiretta \\((-\\infty, 1]\\) e quest‚Äôultima coincide con \\(F(-1)\\). Analogamente, l‚Äôarea sottesa nell‚Äôintervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), √® pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema √® quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato √® detto quantile di ordine \\(p\\) della Normale standard e pu√≤ essere trovato mediante un software.\nSupponiamo che l‚Äôaltezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un‚Äôaltezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l‚Äôarea sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell‚Äôintervallo \\([1.7, 1.8]\\):\n\nstats.norm.cdf(1.8, 1.7, 0.1) - stats.norm.cdf(1.7, 1.7, 0.1)\n\n0.34134474606854315\n\n\n\nmu = 1.7\nsigma = 0.1\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1.7) & (x &lt;= 1.8), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l‚Äôintervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell‚Äôintervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\nstats.norm.cdf(1.0, 0, 1) - stats.norm.cdf(0, 0, 1)\n\n0.3413447460685429\n\n\nIl modo pi√π semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilit√† richiesta non √® altro che la met√† dell‚Äôarea sottesa dalle distribuzioni Normali nell‚Äôintervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l‚Äôinverso della CDF della distribuzione normale.\n\n# Definisco i parametri della distribuzione\nmu = 100\nsigma = 15\n\n# Creo un range di valori su cui calcolare le funzioni\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 1000)\n\n# Calcolo la PDF, CDF, e l'inverso della CDF\npdf = stats.norm.pdf(x, mu, sigma)\ncdf = stats.norm.cdf(x, mu, sigma)\nppf = stats.norm.ppf(np.linspace(0.01, 0.99, 100), mu, sigma)  # Evitiamo 0 e 1 per l'inverso\n\n# Creo i grafici in una sola riga\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\n# Grafico della PDF\naxs[0].plot(x, pdf, label='PDF')\naxs[0].set_title('PDF')\naxs[0].set_xlabel('Valori')\naxs[0].set_ylabel('Probabilit√†')\naxs[0].legend()\n\n# Grafico della CDF\naxs[1].plot(x, cdf, label='CDF', color='orange')\naxs[1].set_title('CDF')\naxs[1].set_xlabel('Valori')\naxs[1].set_ylabel('Cumulativa')\naxs[1].legend()\n\n# Grafico dell'inverso della CDF\naxs[2].plot(np.linspace(0.01, 0.99, 100), ppf, label='Inverse CDF', color='green')\naxs[2].set_title('Inverse CDF')\naxs[2].set_xlabel('Probabilit√†')\naxs[2].set_ylabel('Valori')\naxs[2].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalit√† di osservare la stessa informazione.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.5 Distribuzione Chi-quadrato",
    "text": "30.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libert√† descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libert√†. La densit√† di probabilit√† di \\(\\chi^2_{~\\nu}\\) √®\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) √® una costante positiva.\nLa figura seguente mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\).\n\nx = np.arange(0, 40, 0.1)\n\nnus = [2, 4, 8, 16]\nplt.figure()\nfor nu in nus:\n    pdf = stats.chi2.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n30.5.1 Propriet√†\n\nLa distribuzione di densit√† \\(\\chi^2_{~\\nu}\\) √® asimmetrica.\nIl valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(\\nu\\).\nLa varianza di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(2\\nu\\).\nPer \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).\nSe \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libert√†, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti.\n\nPer fare un esempio, consideriamo la v.c. \\(\\chi^2_5\\).\n\n# Set the degrees of freedom\ndf = 5\n\n# Create a chi-square distribution object\nchi2_dist = stats.chi2(df)\n\n# Generate x values for the plot\nx = np.linspace(0, 20, 200)\n\n# Calculate the probability density function (PDF) of the chi-square distribution for x values\npdf = chi2_dist.pdf(x)\n\n# Plot the PDF\nplt.figure()\nplt.plot(x, pdf)\nplt.title('Chi-Square Distribution (df=5)')\nplt.xlabel('x')\nplt.ylabel('PDF');\n\n\n\n\n\n\n\n\nGeneriamo 1000000 valori da questa distribuzione.\n\nx = rng.chisquare(5, 1000000)\nx[0:20]\n\narray([3.66284512, 2.96353593, 4.93609572, 4.67151242, 4.10927523,\n       4.16530706, 3.36823832, 9.92342755, 7.02541475, 3.23262943,\n       2.73771833, 3.01973299, 4.83304038, 3.16952063, 5.98040985,\n       6.26951139, 8.73351727, 7.28411818, 7.75225854, 5.77346535])\n\n\nCalcoliamo la media di questi valori.\n\nnp.mean(x)\n\n5.0050584059950385\n\n\nCalcolo la varianza.\n\nnp.var(x, ddof=0)\n\n10.013703149640937",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.6 Distribuzione \\(t\\) di Student",
    "text": "30.6 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un‚Äôaltra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\tag{30.3}\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libert√†. Si usa scrivere \\(T \\sim t_{\\nu}\\). L‚Äôandamento della distribuzione \\(t\\) di Student √® simile a quello della distribuzione Normale, ma ha una dispersione maggiore (ha le code pi√π pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa seguente mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\nx = np.arange(-5, 5, 0.1)\n\nnus = [1, 2, 5, 30]\n\nplt.figure()\nfor nu in nus:\n    pdf = stats.t.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.plot(x, stats.norm.pdf(x, 0, 1), label=\"N(Œº = 0, œÉ = 1)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n30.6.1 Propriet√†\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti propriet√†:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densit√† della \\(t_{\\nu}\\) √® una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu &gt; 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\); pertanto √® sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\).\n\nPer esempio, calcoliamo il valore della funzione di ripartizione di ordine 0.025 nel caso di una \\(t_{30}\\).\n\nstats.t.ppf(0.025, 30)\n\n-2.042272456301238\n\n\nAumentiamo i gradi di libert√†: \\(\\nu\\) = 1000.\n\nstats.t.ppf(0.025, 1000)\n\n-1.9623390808264078\n\n\nQuesto valore √® quasi identico a quello della Normale stanardizzata.\n\nstats.norm.ppf(0.025, 0, 1)\n\n-1.9599639845400545\n\n\nLa ragione per cui il quantile della distribuzione \\(t\\) con \\(\\nu=30\\) √® maggiore (in valore assoluto) del quantile omotetico della distribuzione Normale Standard √® che la distribuzione \\(t\\) ha una varianza maggiore rispetto alla distribuzione Normale Standard.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.7 Funzione Beta di Eulero",
    "text": "30.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero √® una funzione matematica, non una densit√† di probabilit√†. La menzioniamo qui perch√© viene utilizzata nella densit√† di probabilit√† Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si pu√≤ scrivere in molti modi diversi; per i nostri scopi la presentiamo cos√¨:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{30.4}\\]\ndove \\(\\Gamma(x)\\) √® la funzione Gamma, ovvero il fattoriale discendente, cio√®\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore\n\nalpha = 3\nbeta = 9\nsc.beta(alpha, beta)\n\n0.00202020202020202\n\n\nSi noti che abbiamo usato la funzione beta della libreria scipy.special. Lo stesso risultato si ottiene svolgendo i calcoli in maniera esplicita:\n\n((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n\n0.00202020202020202\n\n\n\n(math.factorial(alpha-1)*math.factorial(beta-1)) / math.factorial(alpha+beta-1)\n\n0.00202020202020202\n\n\noppure usando la funzione gamma di scipy.special:\n\nsc.gamma(alpha) * sc.gamma(beta) / sc.gamma(alpha + beta)\n\n0.00202020202020202",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.8 Distribuzione Beta",
    "text": "30.8 Distribuzione Beta\nLa distribuzione di probabilit√† Beta, denotata comunemente come \\(Beta(\\alpha, \\beta)\\), √® utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione √® la sua definizione esclusiva nell‚Äôintervallo \\((0, 1)\\). In pratica, ci√≤ significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l‚Äô1 come estremi.\n\n30.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale pu√≤ assumere qualunque valore nell‚Äôintervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densit√† √® descritta dalla seguente formula:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) √® la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n\n30.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. √à essenziale che entrambi questi parametri siano positivi.\n\n\n30.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta pu√≤ essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilit√† di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilit√† di successo √® un parametro fisso; nella distribuzione Beta, questa probabilit√† diventa una variabile aleatoria.\n\n\n30.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione √® analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall‚Äôaspettativa iniziale della probabilit√† di successo: - Se si presume un‚Äôalta probabilit√† di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa pi√π stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali √® dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un‚Äôillustrazione √® fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\nx = np.linspace(0, 1, 200)\nalphas = [0.5, 5.0, 1.0, 2.0, 2.0]\nbetas = [0.5, 1.0, 3.0, 2.0, 5.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.beta.pdf(x, a, b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.ylim(0, 4.5)\nplt.legend(loc=9);\n\n\n\n\n\n\n\n\n\n\n30.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densit√† di probabilit√† che si estende sull‚Äôintervallo \\([0,1]\\), con l‚Äôarea sottesa dalla curva (l‚Äôintegrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamo\n\ndef integrand(p, a, b):\n    return p ** (a - 1) * (1 - p) ** (b - 1)\n\na = 3\nb = 9\nresult, error = quad(integrand, 0, 1, args=(a, b))\nprint(result)\n\n0.00202020202020202\n\n\novvero\n\nresult = (math.gamma(a) * math.gamma(b)) / math.gamma(a + b)\nprint(result)\n\n0.00202020202020202\n\n\novvero, usando la funzione beta di Eulero di scipy.special\n\nsc.beta(a, b)\n\n0.00202020202020202\n\n\n\n\n30.8.6 Propriet√†\nIl valore atteso, la moda e la varianza di una densit√† di probabilit√† Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire la funzione beta_mean_mode_variance() in Python per calcolare la media, la moda e la varianza di una distribuzione di probabilit√† Beta:\n\ndef beta_mean_mode_variance(alpha, beta):\n    mean = alpha / (alpha + beta)\n    mode = (alpha - 1) / (alpha + beta - 2)\n    variance = alpha * beta / ((alpha + beta) ** 2 * (alpha + beta + 1))\n    return mean, mode, variance\n\nPer esempio\n\nalpha = 7\nbeta = 3\nmean, mode, variance = beta_mean_mode_variance(alpha, beta)\nprint(f\"Mean: {mean}, Mode: {mode}, Variance: {variance}\")\n\nMean: 0.7, Mode: 0.75, Variance: 0.019090909090909092\n\n\n\n\n30.8.7 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell‚Äôambito dell‚Äôinferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poich√© permette di bypassare onerose computazioni numeriche tipicamente associate all‚Äôinferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(Œ±, Œ≤), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterr√† la forma funzionale della distribuzione Beta. Ci√≤ significa che, una volta raccolti i dati, l‚Äôaggiornamento a posteriori pu√≤ essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri Œ± e Œ≤ del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (Œ±+x, Œ≤+n-x), senza la necessit√† di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\n√à importante prestare attenzione all‚Äôuso del termine ‚ÄúBeta‚Äù in questo contesto, poich√© assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilit√† continua. - La funzione Beta, una funzione matematica speciale. - Il parametro Œ≤, che insieme ad Œ±, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.9 Distribuzione di Cauchy",
    "text": "30.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy √® un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libert√†. √à definita da una densit√† di probabilit√† che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{30.5}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\nx = np.linspace(-5, 5, 500)\nalphas = [0.0, 0.0, 0.0, -2.0]\nbetas = [0.5, 1.0, 2.0, 1.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.cauchy.pdf(x, loc=a, scale=b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.legend(loc=1);",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.10 Distribuzione Gamma",
    "text": "30.10 Distribuzione Gamma\nLa distribuzione Gamma √® ampiamente utilizzata nella statistica bayesiana come distribuzione a priori per parametri che sono strettamente positivi. La densit√† di probabilit√† Gamma √® una distribuzione di probabilit√† continua che gioca un ruolo chiave nella modellazione del tempo di attesa per l‚Äôoccorrenza di un certo numero di eventi indipendenti e rari. Essa √® caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti come parametro di forma e parametro di scala, rispettivamente.\nParametro di forma. Il parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione gamma si riduce a una distribuzione esponenziale.\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco attorno a \\((\\alpha - 1) \\cdot \\beta\\).\nSe \\(\\alpha &lt; 1\\), la distribuzione √® inclinata verso destra, mostrando una coda lunga che si estende verso valori pi√π bassi.\n\n\\(\\alpha\\) rappresenta il numero di eventi che si stanno aspettando. Determina la forma generale della curva di distribuzione. Con un valore basso di \\(\\alpha\\), la distribuzione √® fortemente inclinata verso valori bassi di \\(x\\) con una coda lunga che si estende verso i valori pi√π alti. Man mano che \\(\\alpha\\) aumenta, la curva si sposta verso destra e diventa pi√π simmetrica. Ad esempio, \\(\\alpha\\) potrebbe rappresentare il numero di ricordi vividi che ci si aspetta di esperire in un certo periodo di tempo.\nParametro di scala. Il parametro di scala, \\(\\beta\\), controlla la ‚Äúlarghezza‚Äù della distribuzione:\n\nUn valore pi√π grande di \\(\\beta\\) produce una curva pi√π piatta, indicando una maggiore variabilit√† nel tempo di attesa.\nUn valore pi√π piccolo di \\(\\beta\\) rende la curva pi√π appuntita, indicando una minore variabilit√†.\n\nNel contesto del tempo di attesa, \\(\\beta\\) agisce come una scala temporale, con un valore pi√π grande che indica un periodo di tempo pi√π lungo tra gli eventi, e un valore pi√π piccolo che indica un periodo di tempo pi√π breve.\n\n30.10.1 Formula della funzione di densit√† di probabilit√†\nLa formula matematica per la funzione di densit√† di probabilit√† (PDF) della distribuzione gamma √®:\n\\[\nf(x|\\alpha, \\theta) = \\frac{x^{\\alpha-1}e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove,\n\n\\(x\\) √® la variabile casuale continua, con \\(x &gt; 0\\).\n\\(\\theta = \\frac{1}{\\beta}\\).\n\\(\\Gamma(\\alpha)\\) √® la funzione Gamma di Eulero, che estende la nozione di fattoriale ai numeri reali e complessi. Per numeri interi \\(n\\), si ha che \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma √® definita come \\(\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1}e^{-x}dx\\).\n\nLe espressioni per media e varianza della distribuzione Gamma sono le seguenti:\n\nLa media (\\(\\mu\\)) della distribuzione Gamma √® \\(\\mu = \\alpha / \\beta\\), o equivalentemente \\(\\mu = \\alpha \\theta\\), usando il parametro di scala.\nLa varianza (\\(\\sigma^2\\)) della distribuzione Gamma √® \\(\\sigma^2 = \\alpha / \\beta^2\\), o equivalentemente \\(\\sigma^2 = \\alpha \\theta^2\\), adottando il parametro di scala.\n\nQuesto chiarisce la relazione tra i parametri \\(\\alpha\\) (forma) e \\(\\beta\\) (tasso) o \\(\\theta\\) (scala), e come influenzano la distribuzione Gamma.\nPer esempio, qui √® riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\nalpha = 3\nbeta = 5/3\n\nmean = alpha / beta\nprint(mean)\n\n1.7999999999999998\n\n\n\n# Standard deviation = sqrt(alpha / beta^2)\n\nsigma = np.sqrt(alpha / beta**2)\nprint(sigma)\n\n1.0392304845413263\n\n\n\n# Generazione di dati dalla distribuzione Gamma\ndata = rng.gamma(shape=alpha, scale=1/beta, size=100000)\n\n# Plot dell'istogramma dei dati generati\nplt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n\n# Plot della PDF (Probability Density Function) della distribuzione Gamma\nx = np.linspace(0, 10, 1000)\nplt.plot(x, stats.gamma.pdf(x, a=alpha, scale=1/beta), 'r-', lw=2, label='PDF')\n\nplt.xlabel('Valore')\nplt.ylabel('Densit√† di probabilit√†')\nplt.title('Distribuzione Gamma con alpha=3 e beta=5/3')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.11 Distribuzione Esponenziale",
    "text": "30.11 Distribuzione Esponenziale\nLa distribuzione esponenziale √® una distribuzione di probabilit√† continua che descrive la ‚Äúdurata di vita‚Äù di un fenomeno che non invecchia (ossia la distribuzione esponenziale √® priva di memoria).\nLa distribuzione esponenziale (o di Laplace) pu√≤ anche essere ricavata come la distribuzione di probabilit√† di una variabile aleatoria definita come somma dei quadrati di due variabili aleatorie normali standardizzate (ossia con valore atteso zero e varianza unitaria); dunque √® riconducibile a un caso particolare di distribuzione del chi-quadro, essendo, quest‚Äôultima, la distribuzione di probabilit√† della variabile aleatoria costruita come la somma dei quadrati di \\(n\\) variabili aleatorie indipendenti normali e standardizzate.\nLa distribuzione esponenziale con parametro \\({\\displaystyle \\lambda &gt;0}\\), ha funzione di densit√† di probabilit√†:\n\\[\n{\\displaystyle f(x;\\lambda )={\\begin{cases}\\lambda e^{-\\lambda x}&x&gt;0,\\\\0&x\\leq 0.\\end{cases}}}.\n\\]\nUna variabile aleatoria con distribuzione esponenziale di parametro \\({\\displaystyle \\lambda }\\) ha\n\nvalore atteso \\({\\displaystyle E[X]=1/\\lambda }\\),\nvarianza \\({\\displaystyle {\\text{Var}}(X)=1/\\lambda ^{2}}.\\)\n\nPer fare un esempio, consideriamo il punteggio totale della scala psicologica di Kessler (K6), una misura standardizzata utilizzata dal NHIS per lo screening del disagio psicologico. La K6 include sei item relativi alla sintomatologia depressiva e ansiosa e valuta il disagio psicologico aspecifico degli ultimi 30 giorni. Gli item sono valutati su una scala Likert a 5 punti, che va da ‚Äúmai‚Äù (=0) a ‚Äúsempre‚Äù (=4). I punteggi totali variano da 0 a 24. Secondo Tomitaka et al. (2019), il punteggio totale della K6 segue una distribuzione esponenziale, con punteggi di cut-off per disagio psicologico moderato e grave corrispondenti a punteggi di 5 e 13, rispettivamente. Dallo studio emerge che il punteggio medio del totale della K6 nella popolazione americana √® di 2.5. La corrispondente distribuzione esponenziale √® rappresentata di seguito.\n\nmean = 2.5\nx = np.linspace(0.001, 22, 100)\nplt.figure()\npdf = stats.expon.pdf(x, scale=mean)\nplt.plot(x, pdf, label=r\"$\\lambda$ = {}\".format(lam))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/12_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.12 Commenti e considerazioni finali",
    "text": "30.12 Commenti e considerazioni finali\nLa statistica bayesiana impiega le distribuzioni di probabilit√† come motore inferenziale per la stima dei parametri e dell‚Äôincertezza. Immaginiamo che le distribuzioni di probabilit√† siano piccoli pezzi di ‚ÄúLego‚Äù con cui possiamo costruire qualsiasi cosa desideriamo. Questo principio si applica analogamente ai modelli statistici bayesiani. Possiamo costruire modelli che vanno dai pi√π semplici ai pi√π complessi, utilizzando le distribuzioni di probabilit√† e le loro interrelazioni.\nPython, oltre al modulo stats, offre la capacit√† di generare campioni casuali da varie distribuzioni di probabilit√† attraverso il generatore di numeri casuali disponibile in NumPy. Dopo aver importato NumPy con il comando:\nimport numpy as np\n√® possibile inizializzare il generatore di numeri casuali (rng) con un valore di seme (seed) specifico, garantendo cos√¨ la riproducibilit√† degli esperimenti:\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nA questo punto, si possono generare campioni da diverse distribuzioni di probabilit√†. Ad esempio, per generare un campione dalla distribuzione normale (gaussiana), si pu√≤ procedere nel seguente modo:\nmedia, deviazione_standard = 0, 1  # Valori per media e deviazione standard\ncampione_normale = rng.normal(media, deviazione_standard, size=100)\nIn questo esempio, size=100 indica che vogliamo generare un campione di 100 valori dalla distribuzione. Analogamente, si possono generare campioni da altre distribuzioni di probabilit√† specificando i relativi parametri:\nDistribuzione Uniforme: Per generare valori da una distribuzione uniforme, definita in un intervallo da a a b, si pu√≤ usare:\na, b = 0, 10  # Estremi dell'intervallo\ncampione_uniforme = rng.uniform(a, b, size=100)  # Aggiunta del parametro 'size'\nDistribuzione t di Student: Per ottenere valori dalla distribuzione t di Student, con un dato numero di gradi di libert√†:\ngradi_libert√† = 10  # Gradi di libert√†\ncampione_t = rng.standard_t(gradi_libert√†, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Beta: Per la distribuzione Beta, specificando i parametri alpha e beta:\nalpha, beta = 2, 5  # Parametri alpha e beta\ncampione_beta = rng.beta(alpha, beta, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Gamma: Infine, per generare un campione dalla distribuzione Gamma, con i parametri di forma e scala:\nforma, scala = 2, 1  # Parametri di forma e scala\ncampione_gamma = rng.gamma(forma, scala, size=100)  # Aggiunta del parametro 'size'\nIn tutti i casi, l‚Äôaggiunta del parametro size consente di specificare la dimensione del campione desiderato.\nPer analizzare le propriet√† statistiche di diverse distribuzioni di probabilit√†, oltre alla generazione di campioni casuali, si utilizzano le funzioni di densit√† di probabilit√† (PDF), le funzioni di ripartizione cumulativa (CDF) e le funzioni quantili. Queste operazioni possono essere effettuate efficacemente utilizzando la libreria SciPy in Python.\nPer determinare la funzione densit√† di probabilit√† (PDF), la quale rappresenta la probabilit√† relativa di osservare un valore all‚Äôinterno di un intervallo continuo, il procedimento √® il seguente. Per la distribuzione normale, ad esempio:\nimport numpy as np\nfrom scipy.stats import norm, uniform, t, beta, gamma\n\nmedia, deviazione_standard = 0, 1\nx = np.linspace(media - 4*deviazione_standard, media + 4*deviazione_standard, 100)\npdf_normale = norm.pdf(x, loc=media, scale=deviazione_standard)\nSimili operazioni possono essere effettuate per altre distribuzioni, come mostrato di seguito:\nDistribuzione Uniforme:\na, b = 0, 10\nx = np.linspace(a, b, 100)\npdf_uniforme = uniform.pdf(x, loc=a, scale=b-a)\nDistribuzione t di Student:\ngradi_libert√† = 10\nx = np.linspace(-5, 5, 100)\npdf_t = t.pdf(x, df=gradi_libert√†)\nDistribuzione Beta:\nalpha, beta_param = 2, 5\nx = np.linspace(0, 1, 100)\npdf_beta = beta.pdf(x, alpha, beta_param)\nDistribuzione Gamma:\nforma, scala = 2, 1\nx = np.linspace(0, 10, 100)\npdf_gamma = gamma.pdf(x, a=forma, scale=scala)\nPer determinare i quantili, ovvero i valori corrispondenti a specifiche probabilit√† cumulate nella funzione di distribuzione, si utilizza la funzione ppf (Percent Point Function). Ad esempio, per la distribuzione normale:\nprobabilit√† = 0.5\nquantile_normale = norm.ppf(probabilit√†, loc=media, scale=deviazione_standard)\nE per le altre distribuzioni:\nDistribuzione Uniforme:\nquantile_uniforme = uniform.ppf(probabilit√†, loc=a, scale=b-a)\nDistribuzione t di Student:\nquantile_t = t.ppf(probabilit√†, df=gradi_libert√†)\nDistribuzione Beta:\nquantile_beta = beta.ppf(probabilit√†, alpha, beta_param)\nDistribuzione Gamma:\nquantile_gamma = gamma.ppf(probabilit√†, a=forma, scale=scala)\nInfine, per calcolare la probabilit√† cumulativa associata a un dato quantile (ovvero la probabilit√† che una variabile casuale sia minore o uguale a quel quantile), si utilizza la funzione cdf (Cumulative Distribution Function). Questo permette di determinare la probabilit√† che si verifichi un evento entro un certo intervallo di valori per la distribuzione considerata. Ad esempio, per la distribuzione normale:\nquantile = 0\nprobabilit√†_normale = norm.cdf(quantile, loc=media, scale=deviazione_standard)\nE analogamente per le altre distribuzioni:\nDistribuzione Uniforme:\nprobabilit√†_uniforme = uniform.cdf(quantile, loc=a, scale=b-a)\nDistribuzione t di Student:\nprobabilit√†_t = t.cdf(quantile, df=gradi_libert√†)\nDistribuzione Beta:\nprobabilit√†_beta = beta.cdf(quantile, alpha, beta_param)\nDistribuzione Gamma:\nprobabilit√†_gamma = gamma.cdf(quantile, a=forma, scale=scala)",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "30.13 Esercizi",
    "text": "30.13 Esercizi\n\nEsercizio 30.1 Per ciascuna delle distribuzioni di massa di probabilit√† discusse, utilizza Python per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l‚Äôintervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media pi√π una deviazione standard, calcolare la probabilit√† che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "30¬† Distribuzioni di v.c. continue",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\npandas    : 2.2.1\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nTomitaka, Shinichiro, Yohei Kawasaki, Kazuki Ide, Maiko Akutagawa, Yutaka Ono, e Toshi A Furukawa. 2019. ¬´Distribution of psychological distress is stable in recent decades and follows an exponential pattern in the US population¬ª. Scientific reports 9 (1): 11982.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>30</span>¬† <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html",
    "href": "chapters/probability/13_likelihood.html",
    "title": "31¬† La verosimiglianza",
    "section": "",
    "text": "Introduzione\nOltre agli approcci frequentisti e bayesiani, esiste un terzo metodo fondamentale nell‚Äôinferenza statistica: la metodologia basata sulla verosimiglianza. Questo approccio consente ai ricercatori di valutare l‚Äôevidenza relativa tra due modelli o ipotesi, in modo simile alla metodologia bayesiana, ma con una differenza cruciale: evita l‚Äôinclusione di informazioni a priori nelle analisi statistiche.\nQuesto capitolo si concentra sulla funzione di verosimiglianza, un concetto centrale che permea tutti e tre gli approcci statistici e che stabilisce un legame diretto tra i dati osservati e i parametri di un modello statistico specifico. La funzione di verosimiglianza √® fondamentale perch√© fornisce una misura di quanto bene i dati si adattino ai modelli teorici, partendo dall‚Äôassunzione di un modello generativo e variando i valori dei parametri.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/13_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "31¬† La verosimiglianza",
    "section": "31.1 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "31.1 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza e la funzione di densit√† (o massa) di probabilit√† sono due concetti fondamentali in statistica che, nonostante condividano la stessa espressione matematica, rivestono ruoli e interpretazioni distinti a seconda del contesto in cui vengono applicati. La chiave per distinguere tra i due concetti risiede nel modo in cui trattiamo i dati e i parametri del modello.\nNel caso della funzione di densit√† (o massa) di probabilit√†, i parametri del modello sono fissati e l‚Äôobiettivo √® valutare la probabilit√† di osservare un certo insieme di dati. Qui, i dati sono variabili, mentre i parametri sono considerati costanti. Per esempio, in un esperimento in cui lanciamo una moneta diverse volte, potremmo usare una distribuzione binomiale per calcolare la probabilit√† di ottenere un certo numero di teste, assumendo un valore noto e fisso per la probabilit√† di ottenere testa in un singolo lancio.\nAl contrario, nella funzione di verosimiglianza, manteniamo i dati osservati come fissi e variamo i parametri del modello per valutare quanto bene questi ultimi si adattino ai dati osservati. Questo processo ci permette di esplorare la plausibilit√† di diversi valori dei parametri dati gli stessi dati. L‚Äôobiettivo √® identificare il set di parametri che meglio spiega i dati osservati.\nFormalmente, la relazione tra la funzione di verosimiglianza e la funzione di densit√† di probabilit√† √® espressa come segue:\n\\[\nL(\\theta | y) \\propto p(y | \\theta),\n\\]\ndove \\(L(\\theta | y)\\) rappresenta la funzione di verosimiglianza per i parametri \\(\\theta\\) dati gli osservazioni \\(y\\), e \\(p(y | \\theta)\\) indica la probabilit√† (o densit√†) di osservare i dati \\(y\\) dato un certo set di parametri \\(\\theta\\).\nPrendiamo l‚Äôesempio del lancio di una moneta. Se osserviamo 7 teste su 10 lanci, la funzione di massa di probabilit√† della distribuzione binomiale ci permette di calcolare la probabilit√† di questo esito per un dato valore di \\(p\\) (la probabilit√† di testa). In questo contesto, \\(p\\) √® fisso e i dati (\\(y = 7\\) teste in \\(n = 10\\) lanci) sono variabili.\nDall‚Äôaltro lato, se consideriamo \\(p\\) variabile, la funzione di verosimiglianza ci permette di valutare come diversi valori di \\(p\\) si adattano all‚Äôesito osservato di 7 teste su 10 lanci, mantenendo i dati osservati fissi.\n√à importante sottolineare che, bench√© le due funzioni condividano la stessa forma matematica, il loro utilizzo e interpretazione sono profondamente diversi. La funzione di densit√† di probabilit√† si concentra sulla probabilit√† degli esiti dati i parametri, mentre la funzione di verosimiglianza valuta la plausibilit√† dei parametri dati gli esiti. Questa distinzione √® cruciale per l‚Äôinferenza statistica, permettendoci di stimare i parametri del modello che meglio si adattano ai dati osservati e di comprendere in modo pi√π approfondito la struttura e le caratteristiche del fenomeno studiato.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/13_likelihood.html#verosimiglianza-binomiale",
    "title": "31¬† La verosimiglianza",
    "section": "31.2 Verosimiglianza Binomiale",
    "text": "31.2 Verosimiglianza Binomiale\nProseguendo con l‚Äôesempio della distribuzione binomiale, approfondiamo la rilevanza della funzione di verosimiglianza nell‚Äôanalisi statistica attraverso uno scenario pratico. Supponiamo di condurre un esperimento con un numero definito di prove \\(n\\), ognuna delle quali pu√≤ terminare con un successo o un fallimento, come nel caso dei lanci di una moneta. Se registriamo \\(y\\) successi e \\(n - y\\) fallimenti, la probabilit√† di osservare esattamente \\(y\\) successi segue la funzione di massa di probabilit√† (FMP) binomiale, che √® definita come:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\theta\\) √® la probabilit√† di successo in una singola prova di Bernoulli.\nNell‚Äôutilizzo della funzione di verosimiglianza, ci concentriamo su come i diversi valori di \\(\\theta\\) possono spiegare i dati osservati \\(y\\). La verosimiglianza √® espressa come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y},\n\\]\ndato che il coefficiente binomiale \\(\\binom{n}{y}\\), non dipendendo da \\(\\theta\\), pu√≤ essere omesso per la semplicit√† della formulazione.\n\nEsempio 31.1 Per esemplificare, immaginiamo uno studio su un gruppo di 30 individui, di cui 23 presentano un atteggiamento negativo verso il futuro, un indicatore comune in pazienti con depressione (Zetsche, Buerkner, e Renneberg 2019). Qui, i nostri dati \\(y\\) e \\(n\\) sono fissi, e la funzione di verosimiglianza per \\(\\theta\\) sconosciuto diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} \\theta^{23} (1 - \\theta)^7.\n\\]\nValutando questa funzione per una serie di valori di \\(\\theta\\) possiamo determinare quale valore di \\(\\theta\\) rende i dati osservati pi√π verosimili. Procediamo simulando 100 valori equidistanti di \\(\\theta\\) nell‚Äôintervallo [0, 1] e calcoliamo la verosimiglianza per ciascuno di questi valori.\n\nn = 30\ny = 23\n\nCreiamo i possibili valori del parametro \\(\\theta\\) per i quali calcoleremo la verosimiglianza.\n\ntheta = np.linspace(0.0, 1.0, num=100)\nprint(theta)\n\n[0.         0.01010101 0.02020202 0.03030303 0.04040404 0.05050505\n 0.06060606 0.07070707 0.08080808 0.09090909 0.1010101  0.11111111\n 0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717\n 0.18181818 0.19191919 0.2020202  0.21212121 0.22222222 0.23232323\n 0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929\n 0.3030303  0.31313131 0.32323232 0.33333333 0.34343434 0.35353535\n 0.36363636 0.37373737 0.38383838 0.39393939 0.4040404  0.41414141\n 0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747\n 0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354\n 0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.5959596\n 0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566\n 0.66666667 0.67676768 0.68686869 0.6969697  0.70707071 0.71717172\n 0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778\n 0.78787879 0.7979798  0.80808081 0.81818182 0.82828283 0.83838384\n 0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.8989899\n 0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596\n 0.96969697 0.97979798 0.98989899 1.        ]\n\n\nPer esempio, ponendo \\(\\theta = 0.1\\) otteniamo il seguente valore dell‚Äôordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.1)\n\n9.7371682902e-18\n\n\nPonendo \\(\\theta = 0.2\\) otteniamo il seguente valore dell‚Äôordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.2)\n\n3.58141723492221e-11\n\n\nSe ripetiamo questo processo 100 volte, una volta per ciascuno dei valori \\(\\theta\\) che abbiamo elencato sopra, otteniamo 100 coppie di punti \\(\\theta\\) e \\(f(\\theta)\\). A tale fine, definiamo la seguente funzione.\n\ndef like(r, n, theta):\n    return math.comb(n, r) * theta**r * (1 - theta) ** (n - r)\n\nLa curva che interpola i punti ottenuti √® la funzione di verosimiglianza, come indicato dalla figura seguente.\n\nplt.figure()\nplt.plot(theta, like(r=y, n=n, theta=theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");\n\n\n\n\n\n\n\n\n\n\n31.2.1 Interpretazione della Funzione di Verosimiglianza\nL‚Äôinterpretazione della funzione di verosimiglianza ci permette di misurare l‚Äôadattamento dei vari valori di \\(\\theta\\) ai dati. Il valore che massimizza la funzione indica la stima pi√π plausibile di \\(\\theta\\) dati i dati osservati. In termini pratici, se per esempio il valore che massimizza la verosimiglianza √® \\(\\theta = 0.767\\), ci√≤ suggerisce che la probabilit√† pi√π plausibile di successo (o atteggiamento negativo) nella nostra popolazione di studio √® del 76.7%.\nLa determinazione numerica di questo valore ottimale pu√≤ avvenire attraverso tecniche computazionali, come l‚Äôidentificazione del punto di massimo della funzione di verosimiglianza tramite metodi di ottimizzazione. L‚Äôuso di librerie statistiche e matematiche in linguaggi di programmazione come Python consente di effettuare queste analisi con precisione e efficienza, offrendo una stima accurata del parametro \\(\\theta\\) che meglio si adatta ai dati osservati.\nQuesta metodologia, basata sull‚Äôuso della funzione di verosimiglianza, √® cruciale per l‚Äôinferenza statistica, permettendo agli scienziati di stimare i parametri dei modelli statistici in modo informato e di valutare l‚Äôadeguatezza di tali modelli in rappresentanza dei dati reali.\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si pu√≤ localizzare l‚Äôindice nel vettore dei valori di verosimiglianza dove questa raggiunge il suo picco. Metodi computazionali, come l‚Äôuso della funzione argmax in NumPy, possono automatizzare questo processo. Una volta individuato l‚Äôindice che massimizza la verosimiglianza, si pu√≤ risalire al valore corrispondente di \\(\\theta\\) nel vettore dei parametri, ottenendo cos√¨ la stima di \\(\\theta\\) che rende i dati osservati pi√π plausibili.\n\nl = like(r=y, n=n, theta=theta)\nl.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\n√à importante notare che, invece di utilizzare la funzione like() che abbiamo definito precedentemente per motivi didattici, √® possibile ottenere lo stesso risultato utilizzando in modo equivalente la funzione binom.pmf().\n\nplt.figure()\nplt.plot(theta, stats.binom.pmf(y, n, theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#massima-verosimiglianza",
    "href": "chapters/probability/13_likelihood.html#massima-verosimiglianza",
    "title": "31¬† La verosimiglianza",
    "section": "31.3 Massima verosimiglianza",
    "text": "31.3 Massima verosimiglianza\nTra tutti i possibili valori \\(\\theta\\) cerchiao il valore che massimizzi la probabilit√† dei dati osservati, ovvero, cerchiamo il valore \\(\\theta\\) che corrisponde al massimo della funzione di verosimiglianza.\nParliamo di ‚Äúminimizzazione‚Äù quando l ‚Äôobiettivo √® trovare il punto pi√π basso in una valle (minimizzare) o di ‚Äúmassimizzazione‚Äù, quando l‚Äôobiettivo √® quello di trovare il punto pi√π alto su una collina, a seconda della funzione. Nel caso della funzione di verosimiglianza, cerchiamo il punto in cui questa funzione raggiunge il suo valore massimo, ma poich√© molti algoritmi sono progettati per trovare minimi, possiamo cercare il minimo del negativo della funzione di verosimiglianza, che corrisponde al massimo della funzione stessa.\nLa Strategia di Base\n\nPunto di Partenza: L‚Äôalgoritmo inizia da un punto di partenza, che pu√≤ essere scelto casualmente o basato su una qualche ipotesi ragionevole.\nEsplorazione: L‚Äôalgoritmo esplora la ‚Äúsuperficie‚Äù della funzione, muovendosi in direzioni che sembrano portare verso il punto pi√π basso (o pi√π alto, se stiamo massimizzando). Questo √® simile a sentire la pendenza del terreno intorno a noi per decidere in quale direzione camminare.\nAggiustamento: Man mano che procede, l‚Äôalgoritmo aggiusta la sua traiettoria basandosi su ci√≤ che ha ‚Äúsentito‚Äù durante l‚Äôesplorazione. Se trova una discesa, continua in quella direzione; se incontra una salita, prova una direzione differente.\nConvergenza: Il processo continua finch√© l‚Äôalgoritmo non trova un punto in cui non ci sono pi√π discese significative in nessuna direzione, suggerendo che ha trovato il punto pi√π basso (o il punto pi√π alto, se stiamo massimizzando) raggiungibile da quel percorso.\n\nEsistono diversi metodi che l‚Äôalgoritmo pu√≤ utilizzare per decidere come muoversi. Alcuni esempi includono:\n\nDiscesa pi√π ripida (Gradient Descent): Utilizza il gradiente (la direzione e la pendenza della collina) per decidere in quale direzione muoversi.\nNewton-Raphson: Utilizza sia il gradiente sia la ‚Äúcurvatura‚Äù della funzione per fare passi pi√π informati verso il minimo.\nAlgoritmi Genetici: Ispirati dall‚Äôevoluzione biologica, questi algoritmi ‚Äúevolvono‚Äù una soluzione attraverso iterazioni che simulano la selezione naturale.\n\nIn termini intuitivi, dunque, l‚Äôottimizzazione √® un processo metodico di esplorazione e aggiustamento basato su feedback immediato dalla funzione che stiamo cercando di ottimizzare, con l‚Äôobiettivo di trovare il punto di massimo o minimo valore.\nDefiniamo dunque il negativo della funzione di verosimiglianza per l‚Äôottimizzazione (trovare il massimo della funzione):\n\ndef negative_likelihood(theta, n, y):\n    # Calcolo del negativo della funzione di verosimiglianza\n    return - (math.comb(n, y) * theta**y * (1 - theta) ** (n - y))\n\nUtilizziamo ora scipy.optimize.minimize per trovare il valore di theta che massimizza la verosimiglianza. Bisogna specificare un valore iniziale per theta, qui assumiamo 0.5 come punto di partenza. I vincoli su theta sono che deve essere compreso tra 0 e 1.\n\nresult = minimize(negative_likelihood, x0=0.5, args=(n, y), bounds=[(0, 1)])\nresult.x\n\narray([0.76666666])\n\n\n\n31.3.1 La Funzione di Log-Verosimiglianza\nProseguendo con il nostro approfondimento sull‚Äôanalisi statistica mediante la funzione di verosimiglianza, ci spostiamo verso una sua trasformazione matematica spesso preferita dagli statistici: la funzione di log-verosimiglianza. Il passaggio alla log-verosimiglianza, definita come il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y),\n\\tag{31.1}\\]\nnon altera la posizione del massimo della funzione originale grazie alla propriet√† di monotonicit√† del logaritmo. In termini pratici, ci√≤ significa che il valore di \\(\\theta\\) che massimizza la log-verosimiglianza, \\(\\hat{\\theta}\\), √® lo stesso che massimizza la verosimiglianza originale:\n\\[\n\\hat{\\theta} = \\arg \\max_{\\theta \\in \\Theta} \\ell(\\theta) = \\arg \\max_{\\theta \\in \\Theta} \\mathcal{L}(\\theta).\n\\]\nNell‚Äôanalisi di un campione di osservazioni, l‚Äôuso della log-verosimiglianza semplifica il processo di massimizzazione, che pu√≤ risultare complicato con la verosimiglianza tradizionale, soprattutto quando si gestiscono numeri molto piccoli. Questa semplificazione avviene perch√© la log-verosimiglianza trasforma il prodotto delle probabilit√† in una somma di logaritmi, rendendo il problema pi√π semplice e numericamente stabile. L‚Äôespressione della log-verosimiglianza per un modello binomiale, ad esempio, si presenta come segue:\n\\[\n\\ell(\\theta \\mid y) = \\log(\\theta^y (1 - \\theta)^{n - y}) = y \\log(\\theta) + (n - y) \\log(1 - \\theta).\n\\]\nQuesta formulazione trasforma il prodotto delle probabilit√† di osservazioni indipendenti in una somma, facilitando notevolmente i calcoli, specialmente per dataset di grandi dimensioni o in presenza di calcoli complessi. La forma logaritmica √® pi√π gestibile e si presta meglio all‚Äôapplicazione di tecniche di ottimizzazione numerica, grazie alla sua maggiore stabilit√† e alla riduzione di problemi come l‚Äôunderflow, comuni quando si lavora con probabilit√† molto piccole.\nRitornando all‚Äôesempio della distribuzione binomiale, l‚Äôapplicazione della log-verosimiglianza per il calcolo del parametro \\(\\theta\\) che meglio si adatta ai dati osservati pu√≤ essere eseguita con efficienza attraverso metodi computazionali. Per esempio, l‚Äôutilizzo di funzioni specifiche disponibili in pacchetti statistici, come binom.logpmf() in Python, permette di calcolare direttamente la log-verosimiglianza di un dato set di osservazioni per diversi valori di \\(\\theta\\). Questo approccio facilita la ricerca del valore di \\(\\theta\\) che massimizza la log-verosimiglianza, fornendo una stima accurata e computazionalmente efficiente del parametro.\nL‚Äôadozione della funzione di log-verosimiglianza, quindi, non solo consente di affrontare i limiti pratici legati alla manipolazione di piccole probabilit√†, ma offre anche un quadro concettuale chiaro per l‚Äôinterpretazione della plausibilit√† dei parametri del modello alla luce dei dati osservati. Questa trasformazione logaritmica rappresenta un passaggio cruciale nell‚Äôanalisi inferenziale, consentendo di stimare i parametri dei modelli statistici con maggiore precisione e affidabilit√†.\nPer illustrare questo concetto, riprendiamo l‚Äôesempio precedente e applichiamo la funzione di log-verosimiglianza per identificare il valore di $ $ che massimizza questa funzione. La rappresentazione grafica della funzione di log-verosimiglianza fornisce ulteriori intuizioni sul comportamento di questa funzione.\n\nn = 30\nr = 23\nplt.figure()\nplt.plot(theta, stats.binom.logpmf(y, n, theta), \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Log-verosimiglianza\");\n\n\n\n\n\n\n\n\nIl risultato replica quello trovato in precedenza con la funzione di verosimiglianza.\n\nll = stats.binom.logpmf(y, n, theta)\nll.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\nDefinizione della funzione del negativo della log-verosimiglianza con correzioni per evitare errori di dominio:\n\ndef corrected_negative_log_likelihood(theta, n, y):\n    # Assicurarsi che theta sia all'interno di un intervallo valido per evitare errori di logaritmo\n    theta = np.clip(theta, 1e-10, 1-1e-10)\n    return - (y * np.log(theta) + (n - y) * np.log(1 - theta))\n\nUtilizzo di scipy.optimize.minimize per trovare il valore di theta che massimizza la log-verosimiglianza:\n\nresult_log_likelihood_corrected = minimize(\n    corrected_negative_log_likelihood, x0=[0.5], args=(n, y), bounds=[(0, 1)]\n)\n\n\n# Il risultato ottimizzato per theta utilizzando la log-verosimiglianza corretta\noptimized_theta = result_log_likelihood_corrected.x\noptimized_theta\n\narray([0.76666666])\n\n\n\n\n31.3.2 Verosimiglianza Congiunta\nProseguendo nella nostra esplorazione dell‚Äôinferenza statistica attraverso la funzione di verosimiglianza, ci concentriamo ora sul caso in cui abbiamo pi√π osservazioni, tutte provenienti dalla stessa distribuzione binomiale e considerate indipendenti ed identicamente distribuite (IID). Tale scenario si presenta frequentemente nelle applicazioni pratiche, dove un insieme di \\(n\\) osservazioni \\(Y = [y_1, y_2, \\ldots, y_n]\\) viene raccolto sotto le stesse condizioni sperimentali.\nLa chiave per analizzare queste osservazioni congiuntamente risiede nel calcolo della probabilit√† congiunta di \\(y_1, y_2, \\ldots, y_n\\) data un‚Äôunica probabilit√† di successo \\(\\theta\\) comune a tutte le prove. L‚Äôindipendenza delle osservazioni ci consente di esprimere questa probabilit√† congiunta come il prodotto delle probabilit√† individuali di ciascuna osservazione:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nLa bellezza di questo approccio sta nel fatto che la verosimiglianza congiunta, che rappresenta la plausibilit√† complessiva di \\(\\theta\\) data l‚Äôintera sequenza di osservazioni \\(Y\\), √® semplicemente il prodotto delle verosimiglianze individuali di ogni osservazione \\(y_i\\) rispetto a \\(\\theta\\):\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta formulazione della verosimiglianza congiunta non solo evidenzia quanto bene il parametro \\(\\theta\\) si adatta all‚Äôintero set di dati \\(Y\\), ma offre anche una base metodologica solida per stimare \\(\\theta\\). Il parametro che massimizza la verosimiglianza congiunta, noto come stimatore di massima verosimiglianza (MLE) di \\(\\theta\\), √® quello che si ritiene essere il pi√π plausibile data l‚Äôosservazione dei dati.\nQuando abbiamo pi√π gruppi di osservazioni bernoulliane indipendenti ed identicamente distribuite (iid), la funzione di log-verosimiglianza congiunta per tutti i gruppi pu√≤ essere espressa come la somma delle log-verosimiglianze di ciascun gruppo. Ci√≤ √® dovuto alla propriet√† che il logaritmo del prodotto √® la somma dei logaritmi.\nSupponiamo di avere i seguenti dati per 4 gruppi di osservazioni:\n\nGruppo 1: 30 prove con 23 successi\nGruppo 2: 28 prove con 21 successi\nGruppo 3: 40 prove con 31 successi\nGruppo 4: 36 prove con 29 successi\n\nLa funzione di log-verosimiglianza congiunta per questi dati, assumendo una singola probabilit√† di successo \\(\\theta\\) per tutti i gruppi, √® data da:\n\\[\n\\log L(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove \\(n_i\\) e \\(y_i\\) sono rispettivamente il numero di prove e il numero di successi nel \\(i\\)-esimo gruppo.\nPer trovare il valore di \\(\\theta\\) che massimizza questa funzione di log-verosimiglianza, possiamo usare il metodo di ottimizzazione scipy.optimize.minimize, come abbiamo fatto in precedenza. Definiamo prima la funzione di log-verosimiglianza congiunta (usiamo np.clip per evitare errori):\n\ndef log_verosimiglianza_congiunta(theta, dati):\n    theta = np.clip(theta, 1e-10, 1-1e-10)  # Evita valori esattamente 0 o 1\n    log_likelihood = 0\n    for n, y in dati:\n        log_likelihood += y * np.log(theta) + (n - y) * np.log(1 - theta)\n    return -log_likelihood  # Restituisce il negativo per l'ottimizzazione\n\n\n# Dati dei gruppi: (prove, successi)\ndati_gruppi = [(30, 23), (28, 20), (40, 29), (36, 29)]\nprint(dati_gruppi)\n\n[(30, 23), (28, 20), (40, 29), (36, 29)]\n\n\nOttimizzazione con la funzione log_verosimiglianza_congiunta\n\nresult = minimize(\n    log_verosimiglianza_congiunta, x0=[0.5], args=(dati_gruppi,), bounds=[(0, 1)]\n)\n\n# Il risultato ottimizzato per theta con la funzione corretta\nresult.x\n\narray([0.75373134])\n\n\n\n# Intervallo di valori di theta da esplorare\ntheta_values = np.linspace(0.01, 0.99, 100)\n\n# Calcolo dei valori di log-verosimiglianza per ogni theta\nlog_likelihood_values = [log_verosimiglianza_congiunta(theta, dati_gruppi) for theta in theta_values]\n\n# Creazione del grafico\nplt.figure(figsize=(10, 6))\nplt.plot(theta_values, log_likelihood_values, label='Log-verosimiglianza')\nplt.xlabel('Theta')\nplt.ylabel('Log-verosimiglianza negativa')\nplt.title('Funzione di Log-verosimiglianza')\nplt.legend()\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/13_likelihood.html#la-verosimiglianza-marginale",
    "title": "31¬† La verosimiglianza",
    "section": "31.4 La Verosimiglianza Marginale",
    "text": "31.4 La Verosimiglianza Marginale\nAvanzando nella nostra discussione sulla verosimiglianza, approfondiamo ora un passaggio cruciale nell‚Äôapplicazione della teoria bayesiana: il concetto di verosimiglianza marginale. Questo approccio si rivela essenziale quando affrontiamo situazioni in cui il parametro di interesse, \\(\\theta\\), non √® definito da un valore singolo e fisso, ma √® invece descritto da una distribuzione di probabilit√† che riflette la nostra incertezza o variabilit√† su di esso.\nIn contesti pratici, non √® raro incontrare scenari in cui \\(\\theta\\) pu√≤ assumere una gamma di valori, ciascuno con una probabilit√† associata, piuttosto che un valore deterministico. L‚Äôintegrazione del parametro \\(\\theta\\) permette di calcolare la probabilit√† complessiva (o verosimiglianza) di osservare un determinato risultato dati tutti i possibili valori di \\(\\theta\\), piuttosto che appoggiarsi a un‚Äôanalisi basata su un singolo valore di \\(\\theta\\).\nConsideriamo, per esempio, una situazione in cui stiamo osservando una sequenza di prove binomiali, con un risultato specifico di interesse (ad esempio, \\(k=7\\) successi su \\(n=10\\) prove). Se \\(\\theta\\) rappresenta la probabilit√† di successo in ciascuna prova e pu√≤ assumere un insieme discreto di valori (per esempio, 0.1, 0.5, e 0.9) con probabilit√† uniforme, la verosimiglianza di osservare il nostro risultato specifico pu√≤ essere espressa come:\n\\[p(k=7, n=10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1-\\theta)^3 p(\\theta),\\]\ndove \\(p(\\theta)\\) rappresenta la probabilit√† associata a ciascun possibile valore di \\(\\theta\\).\nTuttavia, in molte applicazioni reali, \\(\\theta\\) pu√≤ variare continuamente all‚Äôinterno di un intervallo, come tra 0 e 1 per una distribuzione binomiale. In questi casi, il calcolo della verosimiglianza marginale richiede l‚Äôutilizzo dell‚Äôintegrazione su tutto lo spazio dei valori possibili di \\(\\theta\\), riflettendo la gamma continua di possibili probabilit√† di successo. La formula si estende quindi a:\n\\[p(k=7, n=10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1-\\theta)^3 p(\\theta) d\\theta,\\]\ndove \\(p(\\theta) d\\theta\\) rappresenta la densit√† di probabilit√† di \\(\\theta\\) su un intervallo infinitesimale, e l‚Äôintegrale copre tutti i possibili valori di \\(\\theta\\) da 0 a 1. Implementare questo calcolo nell‚Äôambito di uno spazio continuo richiede l‚Äôutilizzo di tecniche di integrazione.\nVediamo come sia possibile eseguire questo calcolo in Python, utilizzando la libreria scipy per l‚Äôintegrazione su uno spazio continuo:\n\n# Definire la funzione di verosimiglianza\ndef likelihood(theta):\n    return stats.binom.pmf(k=7, n=10, p=theta)\n\n# Calcolare la verosimiglianza marginale integrando su Œ∏\nmarginal_likelihood, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(\"La verosimiglianza marginale √®:\", marginal_likelihood)\n\nLa verosimiglianza marginale √®: 0.09090909090909094\n\n\nQuesto codice esegue l‚Äôintegrazione della funzione di verosimiglianza binomiale su tutti i possibili valori di Œ∏ (da 0 a 1), fornendo cos√¨ la verosimiglianza marginale per il nostro esempio. Questo processo ci permette di considerare l‚Äôincertezza su Œ∏, offrendo una visione completa della verosimiglianza dell‚Äôevento osservato senza fissare Œ∏ a un singolo valore.\nNumericamente, nell‚Äôesempio della verosimiglianza basata su una distribuzione binomiale precedente, la verosimiglianza marginale √® effettivamente interpretata come l‚Äôarea sottesa dalla funzione di verosimiglianza, calcolata integrandola su tutto l‚Äôintervallo dei possibili valori di \\(\\theta\\) (da 0 a 1, nel contesto di probabilit√†). Questa operazione di integrazione fornisce un valore che quantifica l‚Äôarea sotto la curva della funzione di verosimiglianza. Importante sottolineare, questo valore non corrisponde alla probabilit√† dei dati dati i parametri, dato che la verosimiglianza non √® una densit√† di probabilit√† sui parametri. Piuttosto, esso misura in che misura l‚Äôintero modello, considerando tutti i possibili valori del parametro, √® in grado di spiegare i dati osservati.\nLa vera importanza della verosimiglianza marginale emerge nel contesto dell‚Äôinferenza bayesiana: essa agisce come fattore di normalizzazione nella formula di Bayes. Nello specifico, la verosimiglianza marginale normalizza la funzione risultante dal prodotto tra la verosimiglianza e la distribuzione a priori dei parametri (il numeratore nella formula di Bayes), garantendo che il risultato sia una distribuzione di probabilit√† valida sullo spazio dei parametri. In altre parole, la verosimiglianza marginale assicura che l‚Äôarea sotto la curva della distribuzione posteriore sia esattamente 1, rendendola cos√¨ una vera distribuzione di probabilit√†.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/13_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "31¬† La verosimiglianza",
    "section": "31.5 Modello Gaussiano e Verosimiglianza",
    "text": "31.5 Modello Gaussiano e Verosimiglianza\nAmpliamo ora la nostra analisi al caso della distribuzione gaussiana. Inizieremo con la verosimiglianza associata a una singola osservazione $ Y $, per poi estendere la discussione a un insieme di osservazioni gaussiane indipendenti e identicamente distribuite (IID).\n\n31.5.1 Caso di una Singola Osservazione\nIniziamo esaminiamo il caso di una singola osservazione. Quale esempio, prendiamo in considerazione la situazione in cui una variabile casuale rappresenta il Quoziente d‚ÄôIntelligenza (QI) di un individuo. Se consideriamo la distribuzione del QI come gaussiana, possiamo esprimere la funzione di verosimiglianza per un singolo valore osservato di QI tramite la formula della distribuzione gaussiana, che misura la probabilit√† di osservare quel particolare valore di QI dato un insieme di parametri specifici, \\(\\mu\\) (la media) e \\(\\sigma\\) (la deviazione standard). La verosimiglianza offre quindi un modo per quantificare quanto bene i parametri \\(\\mu\\) e \\(\\sigma\\) si accordano con il valore osservato di QI.\nSupponiamo che il QI osservato sia 114 e, per semplicit√†, assumiamo che la deviazione standard \\(\\sigma\\) sia conosciuta e pari a 15. Vogliamo esaminare un‚Äôampia gamma di possibili valori per la media \\(\\mu\\), diciamo tra 70 e 160, e valutare quale di questi valori rende pi√π plausibile l‚Äôosservazione fatta Definiamo quindi un insieme di 1000 valori per \\(\\mu\\) da esplorare:\n\nmu = np.linspace(70.0, 160.0, num=1000)\ny = 114\n\nLa nostra analisi consiste nell‚Äôapplicare la funzione di densit√† di probabilit√† gaussiana a ciascuno di questi 1000 valori di \\(\\mu\\), mantenendo fisso il valore osservato di QI, \\(y=114\\), e la deviazione standard, \\(\\sigma=15\\). In questo modo, possiamo costruire la funzione di verosimiglianza che esprime la plausibilit√† di ciascun valore di \\(\\mu\\) alla luce del QI osservato.\nIl calcolo specifico della densit√† di probabilit√† per ogni valore di \\(\\mu\\) pu√≤ essere eseguito con la funzione norm.pdf di scipy.stats, che accetta il valore osservato \\(y\\), un array di medie (i nostri valori di \\(\\mu\\)) e la deviazione standard \\(\\sigma\\). Per un singolo valore mu = 70, otteniamo\n\nstats.norm.pdf(y, loc=70, scale=15)\n\n0.00036007041207962535\n\n\nPer il valore mu = 70.05 otteniamo\n\nstats.norm.pdf(y, loc=70.05, scale=15)\n\n0.00036360634900376967\n\n\ne cos√¨ via. Se usiamo utti i 1000 valori possibili di mu, otteniamo un vettore di 1000 risultati:\n\nf_mu = stats.norm.pdf(y, loc=mu, scale=15)\n\nQuesto passaggio ci fornisce un array di valori che rappresentano la verosimiglianza di ciascun valore di \\(\\mu\\) data l‚Äôosservazione \\(y\\). Tracciando questi valori f_mu in funzione di \\(\\mu\\), otteniamo una curva di verosimiglianza che illustra visivamente quanto bene ciascun valore di \\(\\mu\\) si adatta al dato osservato y = 114:\n\nplt.figure()\nplt.plot(mu, f_mu, \"-\")\nplt.title(\"Funzione di verosimiglianza per QI = 114\")\nplt.xlabel(\"Valore di mu [70, 160]\")\nplt.ylabel(\"Verosimiglianza\")\nplt.xlim([70, 160])\nplt.show()\n\n\n\n\n\n\n\n\nAbbiamo dunque proceduto come nel caso della distribuzione binomiale esaminata in precedenza. Abbiamo utilizzato la formula\n\\[\nf(x | \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ntenendo costante il valore \\(x\\) = 114 e considerando noto \\(\\sigma\\) = 15, e abbiamo applicato la formula 1000 volte facendo variare mu ogni volta utilizziando ciascuno dei valori definiti con np.linspace(70.0, 160.0, num=1000).\nLa moda della distribuzione, si trova con\n\noptimal_mu = mu[f_mu.argmax()]\nprint(optimal_mu)\n\n113.96396396396396\n\n\nIn questo esempio, otteniamo il valore \\(\\mu\\) = 113.96 che massimizza la verosimiglianza.\nPer calcolare il massimo della log-verosimiglianza per una distribuzione Gaussiana usando la funzione optimize() di SciPy, possiamo seguire questi passi. Partiamo dalla formula della densit√† di probabilit√† della distribuzione gaussiana per una singola osservazione \\(y\\), con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La formula √®:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\n\\]\nPoich√© abbiamo una singola osservazione \\(y\\), la funzione di verosimiglianza coincide con la funzione di densit√† di probabilit√†. Quindi, prendiamo il logaritmo naturale di entrambi i lati della equazione della densit√† di probabilit√† gaussiana per ottenere la log-verosimiglianza:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log \\left( \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right) \\right)\n\\]\nApplichiamo le propriet√† dei logaritmi. Ricordiamo che:\n\n\\(\\log(ab) = \\log(a) + \\log(b)\\)\n\\(\\log\\left(\\frac{1}{a}\\right) = -\\log(a)\\)\n\\(\\log(e^x) = x\\)\n\nQuindi, possiamo scrivere:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log\\left(\\frac{1}{\\sigma \\sqrt{2\\pi}}\\right) + \\log\\left(\\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\\right)\n\\]\n\\[\n= -\\log(\\sigma \\sqrt{2\\pi}) -\\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nRicordando che \\(\\log(ab) = \\log(a) + \\log(b)\\), possiamo scrivere \\(\\log(\\sigma \\sqrt{2\\pi})\\) come la somma di due logaritmi:\n\\[\n-\\log(\\sigma \\sqrt{2\\pi}) = -\\log(\\sigma) - \\log(\\sqrt{2\\pi}).\n\\]\nE dato che \\(\\log(\\sqrt{2\\pi}) = \\frac{1}{2}\\log(2\\pi)\\), possiamo sostituire per ottenere:\n\\[\n-\\log(\\sigma) - \\frac{1}{2}\\log(2\\pi).\n\\]\nCombinando tutto, otteniamo:\n\\[\n\\log L(\\mu; y, \\sigma) = -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2 \\sigma^2}.\n\\]\nQuesta √® la trasformata logaritmica della funzione di densit√† di probabilit√† gaussiana per una singola osservazione, che rappresenta la log-verosimiglianza di osservare \\(y\\) dato \\(\\mu\\) e \\(\\sigma\\).\nVogliamo trovare il valore di \\(\\mu\\) che massimizza questa funzione di log-verosimiglianza. Siccome optimize() di SciPy minimizza una funzione, possiamo passare il negativo della log-verosimiglianza per trovare il massimo.\n\n# Dati osservati\ny_obs = 114\nsigma = 15\n\n# Definizione della funzione negativa della log-verosimiglianza\ndef negative_log_likelihood(mu, y, sigma):\n    return 0.5 * np.log(2 * np.pi) + np.log(sigma) + ((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza\nresult = minimize(negative_log_likelihood, x0=0, args=(y_obs, sigma))\n\n# Il risultato ottimizzato per mu\nresult.x\n\narray([113.99997648])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per una distribuzione Gaussiana con \\(y = 114\\) e \\(\\sigma = 15\\) √® circa \\(114\\). Questo risultato dimostra che, nel caso di una distribuzione Gaussiana con una singola osservazione e deviazione standard nota, il massimo della log-verosimiglianza si ottiene quando la media stimata \\(\\mu\\) √® molto vicina al valore osservato \\(y\\).\n\n\n31.5.2 Campione indipendente di osservazioni da una distribuzione gaussiana\nPassiamo ora all‚Äôesame di un contesto pi√π complesso: quello di un campione composto da \\(n\\) osservazioni indipendenti, tutte provenienti da una distribuzione gaussiana. Consideriamo questo insieme di osservazioni come realizzazioni indipendenti ed identicamente distribuite (i.i.d.) di una variabile casuale \\(X\\), che segue una distribuzione normale con media $ $ e deviazione standard \\(\\sigma\\), entrambi parametri sconosciuti. Denotiamo questa situazione con la notazione \\(X \\sim N(\\mu, \\sigma^2)\\).\nIn presenza di osservazioni i.i.d., la densit√† di probabilit√† congiunta del campione √® il prodotto delle funzioni di densit√† per ogni singola osservazione. Matematicamente, ci√≤ si esprime attraverso l‚Äôequazione:\n\\[ p(y_1, y_2, \\ldots, y_n | \\mu, \\sigma) = \\prod_{i=1}^{n} p(y_i | \\mu, \\sigma), \\]\ndove \\(p(y_i | \\mu, \\sigma)\\) indica la funzione di densit√† gaussiana per l‚Äôosservazione \\(y_i\\), parametrizzata da \\(\\mu\\) e \\(\\sigma\\).\nSe manteniamo i dati osservati come costanti, ci√≤ che cambia in questa equazione quando variamo $ $ e \\(\\sigma\\) sono le probabilit√† associate ad ogni configurazione dei parametri, portandoci cos√¨ alla funzione di verosimiglianza congiunta per il campione.\n\nEsempio 31.2 Consideriamo, per illustrare questa dinamica, il caso di uno studio clinico che misura i punteggi del Beck Depression Inventory II (BDI-II) su trenta partecipanti. Supponiamo che questi punteggi seguano una distribuzione normale. Dati i punteggi BDI-II per i trenta partecipanti, il nostro obiettivo √® costruire una funzione di verosimiglianza per questi dati, assumendo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria di 6.50.\nPer la totalit√† del campione, la densit√† di probabilit√† congiunta diventa quindi il prodotto delle densit√† per ogni osservazione. Di conseguenza, la funzione di verosimiglianza per il campione intero √® rappresentata dal prodotto delle densit√† di probabilit√† di tutte le osservazioni.\nIn questo contesto, ogni possibile valore di \\(\\mu\\) viene valutato in termini di verosimiglianza. Per esemplificare, consideriamo un range di 1000 valori per \\(\\mu\\) e calcoliamo la funzione di verosimiglianza per ognuno di questi. Per rendere pi√π gestibili i calcoli, utilizziamo il logaritmo della funzione di verosimiglianza.\nDefinendo una funzione log_likelihood in Python che accetta i punteggi BDI-II \\(y\\), un valore medio \\(\\mu\\), e imposta \\(\\sigma\\) al valore noto, possiamo calcolare la log-verosimiglianza per un‚Äôampia gamma di valori di \\(\\mu\\) entro un intervallo specifico. Ci√≤ ci permette di visualizzare la credibilit√† relativa di ciascun valore di \\(\\mu\\) alla luce dei dati osservati.\nInfine, il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza corrisponde alla stima di massima verosimiglianza di \\(\\mu\\) data la distribuzione dei punteggi BDI-II nel campione. Questo valore, nel nostro esempio, coincide con la media campionaria dei punteggi BDI-II, offrendo una stima concorde con l‚Äôintuizione che la media del campione sia un buon rappresentante del parametro \\(\\mu\\) in una distribuzione normale.\nI dati sono:\n\ny = [\n    26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25,\n    28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n]\n\nIl nostro scopo √® sviluppare una funzione di verosimiglianza utilizzando le 30 osservazioni indicate sopra. Basandoci su studi precedenti, ipotizziamo che questi punteggi seguano una distribuzione normale. Assumiamo inoltre che la deviazione standard \\(\\sigma\\) sia nota e corrisponda a quella osservata nel campione, ossia 6.50.\nPer la prima osservazione del campione, dove \\(y_1 = 26\\), la funzione di densit√† di probabilit√† si esprime come:\n\\[\nf(26 \\,|\\, \\mu, \\sigma = 6.50) = \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(26 - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\]\nEstendendo questo calcolo all‚Äôintero campione, la funzione di densit√† di probabilit√† congiunta si ottiene come il prodotto delle densit√† di tutte le osservazioni individuali:\n\\[\nf(y \\,|\\, \\mu, \\sigma = 6.50) = \\prod_{i=1}^{n} f(y_i \\,|\\, \\mu, \\sigma = 6.50).\n\\]\nDi conseguenza, la funzione di verosimiglianza, indicata con \\(\\mathcal{L}(\\mu, \\sigma = 6.50 \\,|\\, y)\\), si determina moltiplicando insieme le densit√† di probabilit√† di tutte le osservazioni nel campione:\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\mu, \\sigma=6.50 \\,|\\, y) &= \\prod_{i=1}^{30} \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right) \\\\\n&= \\left( \\frac{1}{6.50\\sqrt{2\\pi}} \\right)^{30} \\exp\\left( -\\sum_{i=1}^{30} \\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\end{aligned}\n\\]\nIn questa formula, \\(\\mu\\) rappresenta il parametro di interesse, la media della distribuzione, la cui stima massimizza la funzione di verosimiglianza. Se si considerano 1000 valori differenti per \\(\\mu\\), dovremmo calcolare la funzione di verosimiglianza per ciascuno di questi valori.\nPer rendere i calcoli pi√π gestibili, √® consigliabile utilizzare il logaritmo della funzione di verosimiglianza. In Python, possiamo definire una funzione log_likelihood() che accetta come argomenti y, mu e sigma = true_sigma. Per semplificare, impostiamo true_sigma uguale alla deviazione standard osservata nel campione.\n\ntrue_sigma = np.std(y)\nprint(true_sigma)\n\n6.495810615739622\n\n\n\ndef log_likelihood(y, mu, sigma=true_sigma):\n    return np.sum(stats.norm.logpdf(y, loc=mu, scale=true_sigma))\n\nConsideriamo, ad esempio, il valore \\(\\mu_0 = \\bar{y}\\), ovvero\n\nbar_y = np.mean(y)\nprint(bar_y)\n\n30.933333333333334\n\n\nL‚Äôordinata della funzione di log-verosimiglianza in corrispondenza di \\(\\mu = 30.93\\) √®\n\nlog_likelihood(y, 30.93, sigma=true_sigma)\n\n-98.70288339960591\n\n\nTroviamo ora i valori della log-verosimiglianza per ciascuno dei 1000 valori \\(\\mu\\) nell‚Äôintervallo \\([\\bar{y} - 2 \\sigma, \\bar{y} + 2 \\sigma]\\). Iniziamo a definire il vettore mu.\n\nmu = np.linspace(np.mean(y) - 2 * np.std(y), np.mean(y) + 2 * np.std(y), num=1000)\n\nTroviamo il valore dell‚Äôordinata della funzione di log-verosimiglianza in corrispondenza di ciascuno dei 1000 valori mu che abbiamo definito.\n\nll = [log_likelihood(y, mu_val, true_sigma) for mu_val in mu]\n\nNel caso di un solo parametro sconosciuto (nel caso presente, \\(\\mu\\)) √® possibile rappresentare la log-verosimiglianza con una curva che interpola i punti (mu, ll). Tale funzione descrive la credibilit√† relativa che pu√≤ essere attribuita ai valori del parametro \\(\\mu\\) alla luce dei dati osservati.\n\nplt.figure()\nplt.plot(mu, ll, \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale mu\")\nplt.ylabel(\"Log-verosimiglianza\")\nplt.axvline(x=np.mean(y), alpha=0.4, ls=\"--\");\n\n\n\n\n\n\n\n\nIl valore \\(\\mu\\) pi√π credibile corrisponde al massimo della funzione di log-verosimiglinza e viene detto stima di massima verosimiglianza.\nIl massimo della funzione di log-verosimiglianza, ovvero 30.93 per l‚Äôesempio in discussione, √® identico alla media dei dati campionari.\nPer applicare lo stesso approccio usato precedentemente con optimize ad un campione di dati, anzich√© a una singola osservazione, possiamo modificare la funzione di log-verosimiglianza per prendere in considerazione tutte le osservazioni nel campione. La log-verosimiglianza per un campione da una distribuzione Gaussiana, dove ogni osservazione \\(y_i\\) ha la stessa media \\(\\mu\\) e deviazione standard \\(\\sigma\\), √® la somma delle log-verosimiglianze di ogni osservazione individuale.\nLa formula modificata per il campione sar√†:\n\\[\n\\log L(\\mu; y, \\sigma) = \\sum_{i=1}^{n} \\left[ -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y_i - \\mu)^2}{2 \\sigma^2} \\right],\n\\]\ndove \\(y\\) √® l‚Äôarray delle osservazioni e \\(n\\) √® il numero di osservazioni nel campione.\nPoich√©, per semplicit√†, assumiamo \\(\\sigma\\) come la deviazione standard del campione, prima calcoleremo \\(\\sigma\\) dal campione fornito e poi useremo quel valore per l‚Äôottimizzazione della log-verosimiglianza, cercando il valore di \\(\\mu\\) che la massimizza.\n\n# Calcolo della deviazione standard del campione\nsigma_sample = np.std(y, ddof=1)\n\n# Definizione della funzione negativa della log-verosimiglianza per il campione\ndef negative_log_likelihood_sample(mu, y, sigma):\n    n = len(y)\n    return n * 0.5 * np.log(2 * np.pi) + n * np.log(sigma) + np.sum((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza per il campione\nresult_sample = minimize(negative_log_likelihood_sample, x0=np.mean(y), args=(y, sigma_sample))\n\n# Il risultato ottimizzato per mu\nresult_sample.x\n\narray([30.93333333])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per il campione di dati fornito, assumendo noto il valore di \\(\\sigma\\) (la deviazione standard del campione), √® circa \\(30.93\\). Questo rappresenta la stima ottimale per la media della distribuzione Gaussiana che meglio si adatta al campione di dati dato.\n\n\n\n31.5.3 La Stima di Massima Verosimiglianza per \\(\\mu\\)\nPer determinare il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza, procediamo calcolando la sua derivata parziale rispetto a \\(\\mu\\) e impostando il risultato uguale a zero:\n\nPartiamo dalla funzione di log-verosimiglianza, che √® data da:\n\\[\n\\ell = -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\nCalcoliamo la derivata parziale di $ $ rispetto a $ $:\n\\[\n\\frac{\\partial \\ell}{\\partial \\mu} = \\sum_{i=1}^n \\frac{(y_i - \\mu)}{\\sigma^2}.\n\\]\nImpostiamo la derivata uguale a zero per trovare il punto di massimo:\n\\[\n\\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\mu) = 0.\n\\]\n\nRisolvendo questa equazione per $ $, otteniamo la stima di massima verosimiglianza:\n\\[\n\\hat{\\mu}_{MLE} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\bar{y}.\n\\]\nQuesta formula ci mostra che la stima di massima verosimiglianza per \\(\\mu\\) corrisponde semplicemente alla media aritmetica delle osservazioni.\nQuesto processo pu√≤ essere analogamente applicato per stimare \\(\\sigma^2\\), la varianza, e si trova che la stima di massima verosimiglianza per \\(\\sigma^2\\) √® pari alla varianza campionaria.\nIn conclusione, all‚Äôinterno di una distribuzione gaussiana, le stime di massima verosimiglianza per \\(\\mu\\) (la media) e \\(\\sigma^2\\) (la varianza) coincidono con la media campionaria e la varianza campionaria, rispettivamente.\n\nEsempio 31.3 Consideriamo un esempio relativo all‚Äôapprendimento per rinforzo. Lo scopo degli studi sull‚Äôapprendimento per rinforzo √® quello di comprendere come le persone imparano a massimizzare le loro ricompense in situazioni in cui la scelta migliore √® inizialmente sconosciuta. In modo pi√π specifico, consideriamo il seguente problema di apprendimento. Un partecipante deve effettuare ripetutamente delle scelte tra diverse opzioni o azioni, e dopo ogni scelta riceve una ricompensa numerica estratta da una distribuzione di probabilit√† che dipende dall‚Äôazione selezionata. L‚Äôobiettivo del partecipante √® massimizzare la ricompensa totale attesa durante un certo periodo di tempo, ad esempio, durante 100 scelte. Per descrivere questa situazione, viene spesso utilizzata la metafora di un giocatore che deve fare una serie di \\(T\\) scelte tra \\(K\\) slot machine (conosciute anche come ‚Äúmulti-armed bandits‚Äù) al fine di massimizzare le sue vincite. Se nella scelta \\(t\\) viene selezionata la slot machine \\(k\\), viene ottenuta una ricompensa \\(r_t\\) che ha valore 1 con una probabilit√† di successo \\(\\mu^k_t\\), altrimenti ha valore 0. Le probabilit√† di successo sono diverse per ogni slot machine e inizialmente sono sconosciute al partecipante. Nella versione pi√π semplice di questo compito, le probabilit√† di successo rimangono costanti nel tempo.\nIl modello di Rescorla-Wagner √® un modello di apprendimento associativo che descrive come gli animali o gli umani aggiornano le loro aspettative di rinforzo in risposta a stimoli. Il modello pu√≤ essere descritto con la seguente formula di aggiornamento:\n\\[ V_{t+1} = V_t + \\alpha (\\lambda - V_t), \\]\ndove:\n\n\\(V_t\\) √® il valore predetto del rinforzo al tempo \\(t\\),\n\\(\\alpha\\) √® il tasso di apprendimento, un parametro che vogliamo stimare,\n\\(\\lambda\\) √® l‚Äôintensit√† del rinforzo,\n\\(V_{t+1}\\) √® il valore aggiornato dopo aver sperimentato il rinforzo.\n\nPer semplificare, consideriamo un caso in cui gli stimoli si presentano in maniera binaria (rinforzo presente o assente), e \\(\\lambda\\) √® noto. L‚Äôobiettivo √® stimare il valore di \\(\\alpha\\) che massimizza la verosimiglianza dei dati osservati sotto il modello.\nLa funzione di verosimiglianza per questo modello dipende dalla differenza tra i valori predetti e gli effettivi rinforzi ricevuti. Tuttavia, la formulazione esatta della funzione di verosimiglianza pu√≤ variare a seconda della specifica formulazione del problema e dei dati disponibili. Per mantenere le cose semplici, consideriamo una versione semplificata in cui la ‚Äúverosimiglianza‚Äù √® basata sulla somma dei quadrati degli errori (SSE) tra i rinforzi previsti e quelli osservati (anche se tecnicamente questo non √® un approccio basato sulla verosimiglianza nel senso statistico classico).\nPer questo esempio, assumiamo di avere un semplice set di dati di rinforzi osservati e vogliamo trovare il valore di \\(\\alpha\\) che minimizza l‚ÄôSSE:\n\\[ SSE = \\sum_{t=1}^{n} (\\lambda - V_t)^2. \\]\nEcco un esempio di implementazione in Python che utilizza scipy.optimize.minimize per stimare \\(\\alpha\\):\n\n# Dati di esempio: rinforzi osservati (lambda)\n# In questo esempio, assumiamo lambda = 1 per rinforzo presente e lambda = 0 per rinforzo assente\n# per semplicit√†. In pratica, lambda potrebbe essere diverso a seconda degli esperimenti.\nrinforzi_osservati = [1, 0, 1, 1, 0, 1]  # Esempio di sequenza di rinforzi\n\n\n# Funzione che calcola l'SSE per un dato valore di alpha\ndef sse(alpha, rinforzi, V0=0):\n    V = V0\n    sse = 0\n    for lambda_ in rinforzi:\n        sse += (lambda_ - V)**2\n        V += alpha * (lambda_ - V)  # Aggiornamento del valore secondo il modello Rescorla-Wagner\n    return sse\n\n# Ottimizzazione per trovare il valore di alpha che minimizza l'SSE\nresult_alpha = minimize(sse, x0=0.5, args=(rinforzi_osservati,))\n\n# Il risultato ottimizzato per alpha\nresult_alpha.x\n\narray([0.29739989])\n\n\nIl valore di \\(\\alpha\\) (tasso di apprendimento) che minimizza la somma dei quadrati degli errori (SSE) per il modello di Rescorla-Wagner, dato il campione di rinforzi osservati, √® circa \\(0.297\\). Questo suggerisce che il tasso di apprendimento ottimale per adattare il modello ai dati osservati in questo esempio semplificato √® di circa 0.297, secondo l‚Äôapproccio di minimizzazione dell‚Äôerrore utilizzato qui.\n\n\nEsempio 31.4 Consideriamo ora un esempio relativo alla distribuzione esponenziale. Supponiamo che i seguenti siano i tempi di attesa per un certo evento:\n\ndata = np.array([27, 64, 3, 18, 8])\n\nDefiniamo la funzione di log-verosimiglianza negativa. Per iniziare, ricordiamo che la funzione di densit√† di probabilit√† (PDF) per una distribuzione esponenziale, dato un tasso \\(\\lambda\\), √® definita come:\n\\[\nf(x; \\lambda) = \\lambda e^{-\\lambda x} \\quad \\text{per } x \\geq 0.\n\\]\nLa verosimiglianza (\\(L\\)) di osservare un insieme di dati \\(\\{x_1, x_2, ..., x_n\\}\\) dato un parametro \\(\\lambda\\) √® il prodotto delle funzioni di densit√† di probabilit√† per ogni punto dati, assumendo che ciascun dato sia indipendente dagli altri. Quindi, per \\(n\\) dati osservati, la funzione di verosimiglianza √®:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} f(x_i; \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\n\\]\nLa log-verosimiglianza (\\(\\log(L(\\lambda))\\)) √® il logaritmo naturale di \\(L(\\lambda)\\). Utilizziamo il logaritmo per semplificare la moltiplicazione in una somma, il che rende pi√π semplici sia il calcolo che la differenziazione. Pertanto, la log-verosimiglianza diventa:\n\\[\n\\log(L(\\lambda)) = \\log\\left(\\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\\right) = \\sum_{i=1}^{n} \\log(\\lambda e^{-\\lambda x_i}) = \\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nIl motivo per utilizzare il negativo della log-verosimiglianza, cio√® \\(-\\log(L(\\lambda))\\), nelle tecniche di ottimizzazione, √® perch√© molte librerie e funzioni di ottimizzazione sono progettate per minimizzare una funzione obiettivo piuttosto che massimizzarla. Dato che vogliamo trovare il valore di \\(\\lambda\\) che massimizza la log-verosimiglianza (e quindi la verosimiglianza), possiamo invece minimizzare il suo negativo. Di conseguenza, la funzione obiettivo che passiamo all‚Äôalgoritmo di minimizzazione √®:\n\\[\n-\\log(L(\\lambda)) = -\\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nScriviamo la funzione in Python:\n\ndef neg_log_likelihood(lambda_, data, eps=1e-8):\n    lambda_ = np.clip(lambda_, eps, None)  # Assicura che lambda_ sia almeno eps\n    return -np.sum(np.log(lambda_) - lambda_ * data)\n\nMinimizzaziamo la funzione di log-verosimiglianza negativa:\n\nresult = minimize(neg_log_likelihood, x0=0.1, args=(data,), bounds=[(0, None)])\nprint(f\"Il valore di lambda che massimizza la log-verosimiglianza √®: {result.x[0]}\")\n\nIl valore di lambda che massimizza la log-verosimiglianza √®: 0.04166666292998713\n\n\nAvendo trovato il tasso \\(\\lambda\\), la stima di massima verosimiglianza del tempo di attesa medio diventa:\n\n1 / result.x\n\narray([24.00000215])\n\n\nVisualizzazione.\n\nlambda_opt = result.x[0]\nlambda_array = np.geomspace(0.01, 0.1, 100)\nLL = [-neg_log_likelihood(L, data) for L in lambda_array]\n\nplt.plot(lambda_array, LL, label='Log-likelihood')\nplt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\nplt.xlabel('$\\lambda$')\nplt.ylabel('Log-likelihood')\nplt.title('Log-likelihood over a range of $\\lambda$ values')\nplt.legend()\nplt.show()\n\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:6: SyntaxWarning: invalid escape sequence '\\l'\n  plt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:7: SyntaxWarning: invalid escape sequence '\\l'\n  plt.xlabel('$\\lambda$')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:9: SyntaxWarning: invalid escape sequence '\\l'\n  plt.title('Log-likelihood over a range of $\\lambda$ values')",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#conclusione-e-riflessioni-finali",
    "href": "chapters/probability/13_likelihood.html#conclusione-e-riflessioni-finali",
    "title": "31¬† La verosimiglianza",
    "section": "31.6 Conclusione e Riflessioni Finali",
    "text": "31.6 Conclusione e Riflessioni Finali\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilit√† dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l‚Äôinsieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza √® centrale nella pratica dell‚Äôinferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo √® fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto √® indispensabile per un‚Äôanalisi dati rigorosa e per un‚Äôinterpretazione accurata dei risultati.\nUn‚Äôapplicazione pratica e illustrativa dei principi esposti in questo capitolo √® fornita nella sezione sul modello Rescorla-Wagner, che √® un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l‚Äôapplicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi √® impegnato nella ricerca empirica e nell‚Äôinterpretazione di dati complessi.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#esercizi",
    "href": "chapters/probability/13_likelihood.html#esercizi",
    "title": "31¬† La verosimiglianza",
    "section": "31.7 Esercizi",
    "text": "31.7 Esercizi\n\nEsercizio 31.1 Spiega ciascuno dei concetti seguenti con una frase:\n\nprobabilit√†.\nfunzione di massa di probabilit√†.\nfunzione di densit√† di probabilit√†.\ndistribuzione di probabilit√†.\ndistribuzione di probabilit√† discreta.\ndistribuzione di probabilit√† continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\nAll‚Äôesame ti verr√† chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "31¬† La verosimiglianza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nSyntaxError: invalid syntax (2307612016.py, line 1)\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>31</span>¬† <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html",
    "href": "chapters/probability/14_simulation.html",
    "title": "32¬† Simulazioni",
    "section": "",
    "text": "32.1 Introduzione\nIn questo capitolo discuteremo alcuni degli esercizi di simulazione presentati da Gelman, Hill, e Vehtari (2021) nel quinto capitolo del loro libro. Gli autori introducono la pratica della simulazione affermando che simulare variabili casuali √® fondamentale nelle statistiche applicate per vari motivi.\nIn primo luogo, utilizziamo modelli di probabilit√† per imitare la variazione nel mondo reale, e gli strumenti di simulazione ci aiutano a comprendere meglio come questa variazione si manifesti. I modelli di casualit√† spesso contraddicono il pensiero umano comune: i nostri cervelli faticano a comprendere che le oscillazioni casuali sono presenti nel breve termine ma si livellano nel lungo termine. In molti casi, la simulazione √® di grande aiuto per allenare le nostre intuizioni riguardo agli andamenti medi e alla variazione.\nIn secondo luogo, possiamo utilizzare la simulazione per approssimare la distribuzione campionaria dei dati e trasferire questa approssimazione alla distribuzione campionaria delle stime e delle procedure statistiche.\nInfine, i modelli di regressione non sono deterministici, ma producono previsioni probabilistiche. La simulazione √® il metodo pi√π conveniente e generale per rappresentare le incertezze nelle previsioni.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#simulazione-di-modelli-di-probabilit√†-discreti",
    "href": "chapters/probability/14_simulation.html#simulazione-di-modelli-di-probabilit√†-discreti",
    "title": "32¬† Simulazioni",
    "section": "32.2 Simulazione di Modelli di Probabilit√† Discreti",
    "text": "32.2 Simulazione di Modelli di Probabilit√† Discreti\nIl primo esercizio discusso da Gelman, Hill, e Vehtari (2021) cerca di rispondere alla seguente domanda: Quante bambine su 400 nascite?\nLa probabilit√† che un neonato sia una bambina o un bambino √® approssimativamente del 48.8% o 51.2%, rispettivamente, e queste percentuali non variano molto in tutto il mondo. Supponiamo che in un anno nascano 400 bambini in un ospedale. Quante saranno bambine?\nGelman, Hill, e Vehtari (2021) mostrano come possiamo rispondere a questa domanda simulando le 400 nascite utilizzando la distribuzione binomiale e ripetendo la simulazione 10,000 volte.\n\n# Numero di simulazioni\nn_sims = 10_000\n\n# Probabilit√† di avere una bambina\np_girl = 0.488\n\n# Simulazione delle nascite\nn_girls = np.random.binomial(n=400, p=p_girl, size=n_sims)\n\n# Visualizzazione dell'istogramma\nplt.hist(n_girls, bins=30, edgecolor=\"black\", alpha=0.5)\nplt.title('Distribuzione del Numero di Bambine su 400 Nascite')\nplt.xlabel('Numero di Bambine')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nPossiamo complicare il modello in diversi modi. Ad esempio, c‚Äô√® una probabilit√† di 1 su 125 che un evento di nascita risulti in gemelli dizigoti, ciascuno dei quali ha una probabilit√† approssimativa del 49.5% di essere una bambina, e una probabilit√† di 1 su 300 di gemelli monozigoti, che hanno una probabilit√† approssimativa del 49.5% di essere entrambe bambine. Possiamo simulare 400 eventi di nascita nel modo seguente:\n\n# Probabilit√† per i tipi di nascita\nprobabilities = [1/125, 1/300, 1 - 1/125 - 1/300]\n\n# Tipi di nascita\nbirth_types = [\"fraternal twin\", \"identical twin\", \"single birth\"]\n\n# Simulazione dei tipi di nascita per 400 eventi\nbirth_type = np.random.choice(birth_types, size=400, p=probabilities)\n\n# Array per memorizzare il numero di bambine\ngirls = np.empty(400)\n\n# Ciclo per determinare il numero di bambine in base al tipo di nascita\nfor i in range(400):\n    if birth_type[i] == \"single birth\":\n        girls[i] = np.random.binomial(1, 0.488)\n    elif birth_type[i] == \"identical twin\":\n        girls[i] = 2 * np.random.binomial(1, 0.495)\n    elif birth_type[i] == \"fraternal twin\":\n        girls[i] = np.random.binomial(2, 0.495)\n\n# Somma totale delle bambine\nn_girls = np.sum(girls)\n\nprint(n_girls)\n\n194.0\n\n\nNel codice, identifichiamo tre categorie di nascita: gemelli dizigoti, gemelli monozigoti e nascite singole, e assegnamo le probabilit√† specificate dal problema a ciascun tipo di nascita. Campioniamo in maniera casuale da tale distribuzione di probabilit√† discreta ottenendo il vettore birth_type di 400 elementi. Nel ciclo for, esaminiamo ciascuno dei 400 elementi di birth_type. Se il tipo di nascita √® single birth, generiamo un valore casuale dalla distribuzione binomiale con probabilit√† di successo \\(p\\) pari a 0,488. Se il tipo di nascita √® identical twin, generiamo un valore casuale dalla distribuzione binomiale con \\(p\\) pari a 0,495 e moltiplichiamo per 2 per rappresentare entrambe le gemelle. Se il tipo di nascita √® fraternal twin, generiamo un valore casuale dalla distribuzione binomiale con \\(p\\) pari a 0,495 per due nascite.\nUsciti dal ciclo, sommiamo il numero di 1 nel vettore girls per ottenere una stima del numero di bambine nate.\nInvece di utilizzare un ciclo for per 400 iterazioni, √® possibile generare 400 eventi dalla distribuzione binomiale con una singola istruzione, come mostrato nel codice seguente.\n\n# Determinazione del numero di bambine per ogni tipo di nascita\ngirls = np.where(birth_type == \"single birth\", \n                 np.random.binomial(1, 0.488, 400),\n                 np.where(birth_type == \"identical twin\", \n                          2 * np.random.binomial(1, 0.495, 400),\n                          np.random.binomial(2, 0.495, 400)))\n\n# Somma totale delle bambine\nn_girls = np.sum(girls)\n\nprint(n_girls)\n\n199\n\n\nAnche in questo secondo caso otteniamo un risultato simile al precedente. Poich√© si tratta di una simulazione basata su numeri casuali, il risultato numerico esatto varia ad ogni esecuzione della simulazione. Per comprendere l‚Äôincertezza associata alla simulazione, possiamo ripetere l‚Äôintero processo un gran numero di volte (in questo caso, 10,000 volte).\n\nn_sims = 10_000\n\n# Array per memorizzare il numero di bambine per ogni simulazione\nn_girls = np.zeros(n_sims)\n\n# Eseguiamo 10.000 simulazioni\nfor s in range(n_sims):\n    # Simulazione dei tipi di nascita per 400 eventi\n    birth_type = np.random.choice(birth_types, size=400, p=probabilities)\n\n    # Array per memorizzare il numero di bambine per ogni evento di nascita\n    girls = np.zeros(400)\n\n    # Determiniamo il numero di bambine in base al tipo di nascita\n    for i in range(400):\n        if birth_type[i] == \"single birth\":\n            girls[i] = np.random.binomial(1, 0.488)\n        elif birth_type[i] == \"identical twin\":\n            girls[i] = 2 * np.random.binomial(1, 0.495)\n        elif birth_type[i] == \"fraternal twin\":\n            girls[i] = np.random.binomial(2, 0.495)\n\n    # Sommiamo il numero di bambine per questa simulazione\n    n_girls[s] = np.sum(girls)\n\n# Visualizzazione dell'istogramma\nplt.hist(n_girls, bins=30, edgecolor=\"black\", alpha=0.5)\nplt.title(\"Distribuzione del Numero di Bambine su 400 Nascite\")\nplt.xlabel(\"Numero di Bambine\")\nplt.ylabel(\"Frequenza\")\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#simulazione-di-probabilit√†-continue",
    "href": "chapters/probability/14_simulation.html#simulazione-di-probabilit√†-continue",
    "title": "32¬† Simulazioni",
    "section": "32.3 Simulazione di probabilit√† continue",
    "text": "32.3 Simulazione di probabilit√† continue\nGelman, Hill, e Vehtari (2021) dimostrano come sia possibile incorporare anche distribuzioni di probabilit√† continue nei tipi di simulazioni discusse nella sezione precedente. Forniscono il seguente esempio di un modello misto discreto/continuo: il 52% degli adulti negli Stati Uniti sono donne e il 48% sono uomini. L‚Äôaltezza degli uomini segue approssimativamente una distribuzione normale con una media di 69.1 pollici e una deviazione standard di 2.9 pollici; per le donne, la media √® 63.7 pollici e la deviazione standard √® 2.7 pollici. Ecco il codice per generare l‚Äôaltezza di un adulto scelto casualmente:\n\n# Funzione per simulare l'altezza media\ndef height_sim(N):\n    male = np.random.binomial(1, 0.48, N)\n    height = np.where(male == 1, np.random.normal(69.1, 2.9, N), np.random.normal(63.7, 2.7, N))\n    return np.mean(height)\n\nSupponiamo di selezionare 10 adulti a caso. Cosa possiamo dire della loro altezza media?\n\n# Numero di simulazioni\nn_sims = 10_000\n\n# Array per memorizzare le altezze medie\navg_height = np.empty(n_sims)\nmax_height = np.empty(n_sims)\n\n# Eseguiamo 10000 simulazioni\nfor s in range(n_sims):\n    N = 10\n    male = np.random.binomial(1, 0.48, N)\n    height = np.where(male == 1, np.random.normal(69.1, 2.9, N), np.random.normal(63.7, 2.7, N))\n    avg_height[s] = np.mean(height)\n    max_height[s] = np.max(height)\n\n# Istogramma delle altezze medie\nplt.hist(avg_height, bins=30, edgecolor='black', alpha=0.5)\nplt.title('Distribuzione dell\\'altezza media di 10 adulti')\nplt.xlabel('Altezza media')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nCosa possiamo dire dell‚Äôaltezza massima delle 10 persone?\n\n# Istogramma delle altezze massime\nplt.hist(max_height, bins=30, edgecolor='black', alpha=0.5)\nplt.title('Distribuzione dell\\'altezza massima di 10 adulti')\nplt.xlabel('Altezza massima')\nplt.ylabel('Frequenza')\nplt.show()",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "href": "chapters/probability/14_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "title": "32¬† Simulazioni",
    "section": "32.4 Sommario di una simulazione con media e mediana",
    "text": "32.4 Sommario di una simulazione con media e mediana\nQuando le nostre distribuzioni sono costruite come simulazioni al computer, pu√≤ essere conveniente riassumerle in qualche modo. Tipicamente, riassumiamo la posizione di una distribuzione con la sua media o mediana, che possiamo calcolare direttamente in Python utilizzando numpy.\nLa variazione nella distribuzione √® tipicamente riassunta dalla deviazione standard (in Python, calcolata utilizzando numpy.std), ma spesso preferiamo usare la deviazione mediana assoluta. Se la mediana di un insieme di simulazioni \\(z_1, \\ldots, z_n\\) √® \\(M\\), allora la deviazione mediana assoluta √®:\n\\[ \\text{mad} = \\text{mediana}_{n} |z_i - M| \\]\nTuttavia, poich√© siamo abituati a lavorare con le deviazioni standard, quando calcoliamo la deviazione mediana assoluta, la riscaliamo moltiplicandola per 1.483, il che riproduce la deviazione standard nel caso speciale della distribuzione normale. Chiamiamo questa la ‚Äúmad sd‚Äù e pu√≤ essere calcolata in Python come:\n\\[ 1.483 * \\text{median}(|y - \\text{median}(z)|) \\]\nPreferiamo tipicamente i riassunti basati sulla mediana perch√© sono pi√π stabili computazionalmente, e riscaliamo il riassunto basato sulla mediana della variazione come descritto sopra in modo da essere comparabile alla deviazione standard, che sappiamo gi√† interpretare nella pratica statistica usuale.\n\n32.4.1 Codice in Python\nEcco come implementare quanto sopra in Python per i dati relativi all‚Äôaltezza media di 10 adulti.\n\n# Funzione per calcolare la media e la mediana\ndef summarize_location(data):\n    mean_value = np.mean(data)\n    median_value = np.median(data)\n    return mean_value, median_value\n\n# Funzione per calcolare la deviazione standard\ndef calculate_sd(data):\n    return np.std(data, ddof=1)\n\n# Funzione per calcolare la deviazione mediana assoluta (mad)\ndef calculate_mad(data):\n    median_value = np.median(data)\n    mad = np.median(np.abs(data - median_value))\n    mad_sd = 1.483 * mad\n    return mad, mad_sd\n\n# Esempio di utilizzo\ndata = avg_height\n\n# Calcolo della media e della mediana\nmean_value, median_value = summarize_location(data)\nprint(\"Mean:\", mean_value)\nprint(\"Median:\", median_value)\n\n# Calcolo della deviazione standard\nsd_value = calculate_sd(data)\nprint(\"Standard Deviation:\", sd_value)\n\n# Calcolo della deviazione mediana assoluta e mad sd\nmad_value, mad_sd_value = calculate_mad(data)\nprint(\"MAD:\", mad_value)\nprint(\"MAD SD:\", mad_sd_value)\n\nMean: 66.26638365143874\nMedian: 66.26529661442922\nStandard Deviation: 1.2304485051822338\nMAD: 0.835064693740172\nMAD SD: 1.2384009408166752\n\n\nInfine, possiamo riassumere qualsiasi distribuzione tramite intervalli di incertezza; ad esempio, quantile(z, 0.25, 0.75) restituisce un intervallo centrale del 50% e quantile(z, 0.025, 0.975) restituisce un intervallo centrale del 95%.\nIn Python, possiamo usare numpy per calcolare i quantili e quindi ottenere gli intervalli di incertezza desiderati. Ecco come fare:\n\n# Funzione per calcolare gli intervalli di incertezza\ndef uncertainty_intervals(data, lower_quantile, upper_quantile):\n    lower = np.quantile(data, lower_quantile)\n    upper = np.quantile(data, upper_quantile)\n    return lower, upper\n\n# Esempio di utilizzo\ndata = avg_height\n\n# Calcolo dell'intervallo centrale del 50%\nlower_50, upper_50 = uncertainty_intervals(data, 0.25, 0.75)\nprint(\"Central 50% interval:\", lower_50, \"-\", upper_50)\n\n# Calcolo dell'intervallo centrale del 95%\nlower_95, upper_95 = uncertainty_intervals(data, 0.025, 0.975)\nprint(\"Central 95% interval:\", lower_95, \"-\", upper_95)\n\nCentral 50% interval: 65.42660984223639 - 67.0950850704999\nCentral 95% interval: 63.88592362666574 - 68.7170467946227",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/14_simulation.html#commenti-e-considerazioni-finali",
    "title": "32¬† Simulazioni",
    "section": "32.5 Commenti e Considerazioni Finali",
    "text": "32.5 Commenti e Considerazioni Finali\nLo scopo della simulazione di dati fittizi non √® fornire intuizioni sui dati o sul problema reale in esame, ma piuttosto valutare le propriet√† dei metodi statistici utilizzati, partendo da un modello generativo ipotizzato. Le simulazioni sono cruciali nella pratica della ricerca. Molti autori suggeriscono che dovrebbero essere eseguite prima di raccogliere i dati di uno studio, per valutare, tra le altre cose, se la dimensione campionaria prevista fornisce un potere statistico sufficiente per rispondere alla domanda della ricerca (Gelman e Brown 2024).",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#esercizi",
    "href": "chapters/probability/14_simulation.html#esercizi",
    "title": "32¬† Simulazioni",
    "section": "32.6 Esercizi",
    "text": "32.6 Esercizi\n\nEsercizio 32.1 Immagina il caso di 220 studenti che devono sostenere tre prove in itinere in un corso. Il voto finale √® la media dei voti ottenuti in queste tre prove. Le distribuzioni dei voti per le prove sono descritte come segue:\n\nPrima prova: I voti sono distribuiti secondo una gaussiana con media 24. Il 15% degli studenti ottiene un voto inferiore a 18.\nSeconda prova: I voti sono distribuiti secondo una gaussiana con media 25. Il 10% degli studenti ottiene un voto inferiore a 18.\nTerza prova: I voti sono distribuiti secondo una gaussiana con media 26. Solo il 5% degli studenti ottiene un voto inferiore a 18.\n\nDei 220 studenti iniziali:\n\nIl 10% non partecipa alla prima prova.\nUn ulteriore 5% non partecipa alla seconda prova.\n\nPer ottenere il voto finale, uno studente deve partecipare a tutte e tre le prove.\nUtilizzando una simulazione, trova la media finale dei voti e calcola l‚Äôintervallo di incertezza al 90% per la stima della media.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_simulation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_simulation.html#informazioni-sullambiente-di-sviluppo",
    "title": "32¬† Simulazioni",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Aug 08 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, Andrew, e Nicholas JL Brown. 2024. ¬´How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology¬ª.\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2021. Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Probabilit√†",
      "<span class='chapter-number'>32</span>¬† <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esamineremo l‚Äôinferenza bayesiana applicata a modelli statistici in cui si stima un unico parametro scalare, cio√® quando l‚Äôestimando \\(\\theta\\) √® unidimensionale. In questo capitolo, consideriamo quattro modelli unidimensionali fondamentali e ampiamente utilizzati: il modello binomiale, il modello normale, il modello di Poisson e il modello esponenziale. Approfondiremo il processo di aggiornamento bayesiano, analizzando due metodi principali per derivare la distribuzione a posteriori: l‚Äôapprossimazione numerica attraverso il metodo basato su griglia e l‚Äôutilizzo delle distribuzioni coniugate, in cui una specifica combinazione di distribuzione a priori e verosimiglianza consente una derivazione analitica della distribuzione a posteriori. Inoltre, considereremo l‚Äôinfluenza della scelta della distribuzione a priori sulla distribuzione a posteriori e discuteremo le tecniche utili per sintetizzare e interpretare quest‚Äôultima in modo efficace.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html",
    "href": "chapters/bayesian_inference/01_intro_bayes.html",
    "title": "33¬† Modellazione bayesiana",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo capitolo √® introdurre il quadro concettuale della modellizzazione bayesiana. L‚Äôapproccio bayesiano alla statistica si distingue non solo per l‚Äôuso del Teorema di Bayes, ma anche per il modo in cui gestisce l‚Äôincertezza e valuta l‚Äôintero spettro di possibili esiti attraverso le distribuzioni di probabilit√†. La modellazione bayesiana segue un approccio metodologico strutturato in diverse fasi: progettazione del modello, applicazione del teorema di Bayes e valutazione critica del modello. Questo flusso di lavoro bayesiano (Baribault e Collins 2023) costituisce un ciclo di apprendimento e miglioramento continuo, in cui l‚Äôobiettivo non √® trovare una ‚Äúverit√† ultima‚Äù fissa e immutabile, ma aggiornare continuamente in modo razionale il grado di certezza attribuito alle ipotesi, sulla base delle nuove evidenze disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#notazione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#notazione",
    "title": "33¬† Modellazione bayesiana",
    "section": "33.1 Notazione",
    "text": "33.1 Notazione\nIn seguito, utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo \\(x\\) per denotare le quantit√† note, come i predittori di un modello lineare.\n\n33.1.1 Distribuito come, \\(\\sim\\)\n√à comune scrivere modelli statistici utilizzando la seguente notazione:\n\\[\n\\begin{aligned}\ny & \\sim \\mathrm{normal}(\\mu, \\sigma) \\\\\n\\mu & \\sim \\mathrm{normal}(0, 10) \\\\\n\\sigma & \\sim \\mathrm{normal}^+(\\sigma |  0, 1),\n\\end{aligned}\n\\]\ndove il simbolo \\(\\sim\\) √® chiamato tilde (\\sim in LaTeX).\nIn generale, possiamo leggere \\(\\sim\\) come ‚Äú√® distribuito come‚Äù, e questa notazione √® usata come una scorciatoia per definire distribuzioni. L‚Äôesempio sopra pu√≤ essere scritto anche come:\n\\[\n\\begin{aligned}\n   p(y| \\mu, \\sigma) & = \\mathrm{normal}(y |  \\mu, \\sigma)\\\\\n   p(\\mu) & = \\mathrm{normal}(\\mu |  0, 10)\\\\\n   p(\\sigma) & = \\mathrm{normal}^+(\\sigma |  0, 1).\n\\end{aligned}\n\\]\nUna collezione di affermazioni sulle distribuzioni definisce una distribuzione congiunta come il prodotto delle distribuzioni componenti:\n\\[\np(y,\\mu,\\sigma) = p(y| \\mu, \\sigma )p(\\mu) p(\\sigma).\n\\]\n\n\n33.1.2 Proporzionale a, \\(\\propto\\)\nIl simbolo \\(\\propto\\) significa proporzionale a, il che implica che il termine a sinistra √® uguale al termine a destra, salvo un moltiplicatore costante. Ad esempio, se \\(y=2x\\), allora \\(y \\propto x\\). √à \\propto in LaTeX.\nPer eventi discreti osservabili, il teorema di Bayes si esprime come:\n\\[\nP(H_i \\mid O) = \\frac{P(O \\mid H_i) \\cdot P(H_i)}{P(O)}\n\\]\ndove:\n\n\\(P(H_i \\mid O)\\) √® la probabilit√† dell‚Äôipotesi \\(H_i\\) data l‚Äôosservazione \\(O\\),\n\\(P(O \\mid H_i)\\) √® la probabilit√† dell‚Äôosservazione \\(O\\) data l‚Äôipotesi \\(H_i\\),\n\\(P(H_i)\\) √® la probabilit√† a priori dell‚Äôipotesi \\(H_i\\),\n\\(P(O)\\) √® la probabilit√† marginale dell‚Äôosservazione \\(O\\), calcolata come somma delle probabilit√† congiunte di tutte le ipotesi.\n\nIn molte applicazioni statistiche, siamo interessati a stimare parametri continui basandoci su dati osservati. In questo contesto, passiamo dalla notazione per probabilit√† discrete a quella per distribuzioni di densit√† di probabilit√†. Considerando un dato osservato \\(y\\) e un parametro \\(\\theta\\), il teorema di Bayes pu√≤ essere riformulato come:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) \\cdot p(\\theta)}{p(y)}.\n\\tag{33.1}\\]\nNell‚ÄôEquazione¬†33.1, dividere per \\(p(y)\\) fa s√¨ che \\(\\int p(\\theta | y) d\\theta = 1\\). Tuttavia, spesso \\(p(y)\\) √® difficile da calcolare, ma per fortuna spesso non √® necessario conoscerlo, e in tal caso possiamo scrivere la regola di Bayes come:\n\\[\np(\\theta | y) \\propto p(y | \\theta)p(\\theta),\n\\]\ndove \\(p(\\theta)\\) rappresenta la distribuzione a priori del parametro \\(\\theta\\), ossia la nostra valutazione della plausibilit√† dei vari valori di \\(\\theta\\) prima di osservare i dati. \\(p(\\theta | y)\\), invece, √® la distribuzione a posteriori, che descrive l‚Äôaggiornamento delle nostre credenze su \\(\\theta\\) dopo aver osservato i dati.\n\n\n33.1.3 Modello e Verosimiglianza\nIl termine \\(p(y|\\theta,M)\\) ha due nomi diversi a seconda della situazione, e la notazione abbreviata utilizzata pu√≤ causare confusione.\n\nIl termine \\(p(y|\\theta,M)\\) √® chiamato modello (a volte pi√π specificamente modello di osservazione o modello statistico) quando viene utilizzato per descrivere l‚Äôincertezza su \\(y\\) dato \\(\\theta\\) e \\(M\\). Una notazione pi√π lunga, \\(p_y(y|\\theta,M)\\), mostra esplicitamente che √® una funzione di \\(y\\).\nNella regola di Bayes, il termine \\(p(y|\\theta,M)\\) √® chiamato funzione di verosimiglianza. La distribuzione a posteriori descrive la probabilit√† (o la densit√† di probabilit√†) per i diversi valori di \\(\\theta\\) dato un \\(y\\) fisso, e quindi quando la distribuzione a posteriori viene calcolata, i termini sul lato destro (nella regola di Bayes) vengono anche valutati come una funzione di \\(\\theta\\) dato un \\(y\\) fisso. Una notazione pi√π lunga, \\(p_\\theta(y|\\theta,M)\\), mostra esplicitamente che √® una funzione di \\(\\theta\\). Questo termine ha un nome proprio (verosimiglianza) per distinguersi dal modello. La funzione di verosimiglianza √® una distribuzione di probabilit√† non normalizzata che descrive l‚Äôincertezza legata a \\(\\theta\\) (ecco perch√© la regola di Bayes ha il termine di normalizzazione per ottenere la distribuzione a posteriori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#applicazioni-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#applicazioni-dellaggiornamento-bayesiano",
    "title": "33¬† Modellazione bayesiana",
    "section": "33.2 Applicazioni dell‚ÄôAggiornamento Bayesiano",
    "text": "33.2 Applicazioni dell‚ÄôAggiornamento Bayesiano\nPer spiegare il concetto di aggiornamento bayesiano in maniera intuitiva, McElreath propone il seguente esempio. Supponiamo di avere un globo terrestre e di volere stimare qual √® la proporzione della superficie terrestre coperta d‚Äôacqua. Per stimare questa proporzione eseguiamo il seguente esperimento casuale: lanciamo in aria il globo e poi lo afferriamo quando cade. Registriamo se la superficie sotto il nostro indice destro √® terra o acqua. Ripetiamo questa procedura un certo numero di volte e calcoliamo la proporzione di volte in cui abbiamo osservato ‚Äúacqua‚Äù. In ogni lancio, ogni valore della proporzione sconosciuta \\(p\\) pu√≤ essere pi√π o meno probabile, date le evidenze fornite dai lanci precedenti.\nUn modello bayesiano inizia assegnando un insieme di probabilit√† iniziali a ciascuno dei possibili valori \\(p\\), dette probabilit√† a priori. Poi, queste probabilit√† vengono aggiornate alla luce dei dati raccolti, producendo le probabilit√† a posteriori. Questo processo di aggiornamento √® una forma di apprendimento, conosciuto come aggiornamento bayesiano.\nNell‚Äôesempio di McElreath, supponiamo che il nostro modello bayesiano assegni inizialmente la stessa probabilit√† a ogni possibile valore di \\(p\\) (proporzione di acqua). Ora, consideriamo il primo grafico in alto a sinistra nella figura.\nLa linea tratteggiata orizzontale rappresenta la distribuzione di probabilit√† a priori per ciascun possibile valore di \\(p\\). Dopo aver osservato il primo lancio, che risulta in ‚ÄúW‚Äù (acqua), il modello aggiorna le probabilit√† di \\(p\\) alla linea continua. La probabilit√† che \\(p\\) = 0 scende a zero, indicando che √® impossibile non avere acqua, dato che abbiamo osservato almeno una traccia di acqua sul globo. Allo stesso modo, la probabilit√† che \\(p\\) &gt; 0.5 aumenta, poich√© non c‚Äô√® ancora evidenza di terra sul globo, quindi le probabilit√† a priori vengono modificate per essere coerenti con questa osservazione. Tuttavia, le differenze nelle probabilit√† non sono ancora molto grandi, poich√© le evidenze raccolte finora sono limitate. In questo modo, la quantit√† di evidenza vista finora si riflette nelle probabilit√† di ciascun valore di \\(p\\): la probabilit√† che \\(p\\) sia 0 √® zero e la probabilit√† che \\(p\\) sia 1 √® massima. Quindi, la distribuzione a posteriori di \\(p\\) √® rappresentata dalla linea continua che collega questi due estremi.\n\n\n\n\n\n\n\n\n\nNei grafici successivi, vengono introdotti ulteriori campioni dal globo, uno alla volta. Ogni curva tratteggiata rappresenta la curva continua dal grafico precedente, spostandosi da sinistra a destra e dall‚Äôalto in basso.\nLa seconda osservazione √® ‚Äúterra‚Äù (L). La distribuzione a priori √® la linea tratteggiata del secondo pannello, mentre la distribuzione a posteriori √® la linea curva. Otteniamo questa curva poich√© assegniamo una probabilit√† pari a 0 agli eventi \\(p\\) = 0 (abbiamo osservato ‚Äúacqua‚Äù) e \\(p\\) = 1 (abbiamo osservato ‚Äúterra‚Äù). In due lanci, abbiamo osservato una volta ‚Äúterra‚Äù e una volta ‚Äúacqua‚Äù. Pertanto, la probabilit√† che \\(p\\) = 0.5 √® massima, da cui deriva la curva che abbiamo disegnato.\nIl terzo lancio del globo produce nuovamente ‚Äúacqua‚Äù. A questo punto, il valore pi√π probabile di \\(p\\) √® 0.75. Modifichiamo dunque la distribuzione a priori (linea tratteggiata nel terzo pannello) in modo da rappresentare le nostre nuove conoscenze, come indicato dalla linea continua.\nOgni volta che viene osservata ‚Äúacqua‚Äù (W), il picco della curva di probabilit√† si sposta a destra, verso valori maggiori di \\(p\\). Ogni volta che viene osservata ‚Äúterra‚Äù (L), si sposta nella direzione opposta. L‚Äôaltezza massima della curva aumenta con ogni campione, indicando che la probabilit√† complessiva (1) viene ridistribuita su un numero minore di valori di \\(p\\), i quali accumulano una maggiore probabilit√† man mano che cresce la quantit√† di evidenze. Con l‚Äôaggiunta di ogni nuova osservazione, la curva viene aggiornata in modo coerente con tutte le osservazioni precedenti.\n√à importante notare che ogni insieme aggiornato di probabilit√† diventa la probabilit√† iniziale per l‚Äôosservazione successiva. Ogni conclusione √® il punto di partenza per l‚Äôinferenza futura. Questo processo di aggiornamento funziona anche al contrario: conoscendo l‚Äôultimo set di probabilit√† e l‚Äôultima osservazione, √® possibile matematicamente dedurre la curva di probabilit√† precedente. I dati possono essere presentati al modello in qualsiasi ordine, o anche tutti insieme. Di solito, i dati vengono considerati tutti insieme per comodit√†, ma √® importante capire che ci√≤ rappresenta solo una semplificazione di un processo di apprendimento iterativo.\nQuesto esempio illustra come la funzione di probabilit√† a posteriori si modifichi progressivamente con l‚Äôacquisizione di nuove evidenze. Tale processo avviene automaticamente, riflettendo il meccanismo di aggiornamento delle credenze che caratterizza l‚Äôinferenza bayesiana. In ogni pannello, la transizione dalla linea tratteggiata alla linea piena simboleggia questo aggiornamento: la linea tratteggiata rappresenta la distribuzione di probabilit√† a priori, ovvero le nostre credenze iniziali prima dell‚Äôosservazione dei nuovi dati; la linea piena, invece, rappresenta la distribuzione di probabilit√† a posteriori, che integra le nuove evidenze ai preconcetti iniziali. Quest‚Äôultima rispecchia dunque una sintesi ottimizzata delle informazioni pregresse e attuali, offrendo una rappresentazione aggiornata e pi√π accurata della realt√† in esame.\nIn questo specifico esempio, la distribuzione a priori del parametro \\(p\\) √® la distribuzione uniforme indicata dalla linea tratteggiata del primo pannello. I dati sono costituiti dall‚Äôosservazione di 6 successi in 9 prove. La distribuzione a posteriori \\(p(\\theta \\mid y)\\) √® rappresentata dalla funzione continua presente nell‚Äôultimo pannello. L‚Äôaggiornamento bayesiano √® il passaggio dalla funzione a priori uniforme \\(p(\\theta)\\) alla funzione a posteriori \\(p(\\theta \\mid y)\\). La moda della funzione \\(p(\\theta \\mid y)\\) ci indica il valore pi√π verosimile di \\(\\theta\\) (proporzione di acqua sul globo terrestre) dopo aver osservato 6 successi in 9 prove del nostro esperimento casuale (lancio del mappamondo).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "33¬† Modellazione bayesiana",
    "section": "33.3 Il Processo Generatore dei Dati",
    "text": "33.3 Il Processo Generatore dei Dati\nNel processo di aggiornamento bayesiano, il ricercatore deve fare un‚Äôassunzione sul modello statistico che governa la produzione dei dati osservati. Questo modello statistico si chiama ‚Äúprocesso generatore dei dati‚Äù. Nel caso dell‚Äôesempio precedente, √® facile capire qual √® il modello generatore dei dati. I dati corrispondono a una sequenza di prove bernoulliane indipendenti, generate da un processo in cui possiamo assumere che la probabilit√† di successo, ovvero la probabilit√† di osservare ‚Äúacqua‚Äù, resta costante nella sequenza di prove. Questo √® giustificato dal fatto che le caratteristiche del mappamondo (ovvero la distribuzione spaziale di acqua e terra) restano costanti. In tali circostanze, il modello statistico all‚Äôorigine dei dati osservati √® il modello binomiale. Tenuto costante il numero di prove, il modello binomiale dipende da un solo parametro: la probabilit√† di successo \\(\\theta\\) (nel caso presente, la proporzione di acqua sul globo terrestre).\nL‚Äôaggiornamento bayesiano riguarda dunque le nostre credenze rispetto a \\(\\theta\\). In questo esempio, siamo passati da una situazione in cui non avevamo informazioni su \\(\\theta\\), rappresentata da una distribuzione uniforme in cui tutti i valori di \\(\\theta\\) nell‚Äôintervallo unitario [0, 1] erano ugualmente possibili, a una situazione in cui, avendo osservato 6 successi in 9 prove e applicato il teorema di Bayes, le nostre credenze su \\(\\theta\\) sono rappresentate dalla curva continua nell‚Äôultimo pannello. La moda (o la media, o la mediana) di tale funzione rappresenta il valore pi√π verosimile di \\(\\theta\\), avendo osservato i dati e integrato tali informazioni con le nostre credenze a priori. L‚Äôincertezza della nostra credenza a posteriori √® rappresentata dall‚Äôampiezza della distribuzione di \\(p(\\theta \\mid y)\\). Se la massa di \\(p(\\theta \\mid y)\\) si distribuisce su un intervallo ampio del supporto di \\(\\theta\\), significa che la nostra incertezza a posteriori √® grande; al contrario, se la massa di \\(p(\\theta \\mid y)\\) si distribuisce su un intervallo molto piccolo del supporto di \\(\\theta\\), possiamo concludere che abbiamo poca incertezza su quale sia il vero valore di \\(\\theta\\).\nIn questo esempio abbiamo visto come integrare una distribuzione uniforme con i dati costituiti da \\(y\\) successi in \\(N\\) prove bernoulliane. Nel capitolo Capitolo 34 vedremo in maniera pi√π dettagliata come si produce l‚Äôaggiornamento bayesiano nel caso di distribuzioni a priori discrete o continue, uniformi o non uniformi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#esempio-di-calcolo-della-verosimiglianza-marginale",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#esempio-di-calcolo-della-verosimiglianza-marginale",
    "title": "33¬† Modellazione bayesiana",
    "section": "33.4 Esempio di Calcolo della Verosimiglianza Marginale",
    "text": "33.4 Esempio di Calcolo della Verosimiglianza Marginale\nNell‚ÄôEquazione¬†33.1, la costante \\(p(y)\\), nota come verosimiglianza marginale, assicura che l‚Äôintegrale di \\(p(\\theta \\mid y)\\) su tutto lo spazio dei parametri \\(\\Theta\\) sia pari a uno.\nPer fare un esempio, consideriamo una variabile casuale binomiale \\(Y\\) con funzione di massa di probabilit√† (PMF) \\(p(Y)\\) in relazione a un parametro \\(\\theta\\). Supponiamo che \\(\\theta\\) possa assumere uno di tre valori specifici: 0.1, 0.5 o 0.9, ciascuno con probabilit√† \\(\\frac{1}{3}\\).\nFissiamo i dati a \\(n = 10\\) prove e \\(k = 7\\) successi, ottenendo la seguente funzione di likelihood:\n\\[\np(k = 7, n = 10 | \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\nPer calcolare la verosimiglianza marginale \\(p(k = 7, n = 10)\\), marginalizziamo il parametro \\(\\theta\\) valutando la likelihood per ciascun valore possibile di \\(\\theta\\), moltiplicandola per la probabilit√† di quel valore di \\(\\theta\\) e sommando i risultati ottenuti:\n\\[\np(k = 7, n = 10) = \\sum_{i=1}^{3} p(k = 7, n = 10 | \\theta_i) \\cdot p(\\theta_i).\n\\]\nSostituendo i valori di \\(\\theta\\) e la loro probabilit√†:\n\\[\np(k = 7, n = 10) = \\frac{1}{3} \\binom{10}{7} 0.1^7 (1 - 0.1)^3 + \\frac{1}{3} \\binom{10}{7} 0.5^7 (1 - 0.5)^3 + \\frac{1}{3} \\binom{10}{7} 0.9^7 (1 - 0.9)^3.\n\\]\nQuesto processo mostra come la marginalizzazione incorpori tutte le possibili variazioni di \\(\\theta\\), ottenendo una misura complessiva che considera l‚Äôincertezza su \\(\\theta\\).\nPer implementare questo calcolo in Python, possiamo definire una funzione che calcoli la likelihood per i valori discreti di \\(\\theta\\) e poi sommare i risultati. Per l‚Äôintegrazione su un intervallo continuo, possiamo utilizzare la libreria scipy.\n\n# Funzione di likelihood\ndef likelihood(theta, k=7, n=10):\n    return comb(n, k) * (theta**k) * ((1 - theta)**(n - k))\n\n# Likelihood marginale per valori discreti di theta\ntheta_vals = np.array([0.1, 0.5, 0.9])\nprob_theta = 1/3\nmarginal_likelihood_discrete = sum([likelihood(theta) * prob_theta for theta in theta_vals])\n\nprint(f\"Likelihood Marginale (discreta): {marginal_likelihood_discrete}\")\n\n# Likelihood marginale su un intervallo continuo [0, 1]\nmarginal_likelihood_continuous, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(f\"Likelihood Marginale (continua): {marginal_likelihood_continuous}\")\n\nLikelihood Marginale (discreta): 0.05819729199999999\nLikelihood Marginale (continua): 0.09090909090909091",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#metodi-per-determinare-la-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#metodi-per-determinare-la-distribuzione-a-posteriori",
    "title": "33¬† Modellazione bayesiana",
    "section": "33.5 Metodi per Determinare la Distribuzione a Posteriori",
    "text": "33.5 Metodi per Determinare la Distribuzione a Posteriori\nEsistono due approcci principali per determinare la distribuzione posteriore:\n\nApproccio Analitico: Questo metodo si applica quando la distribuzione a priori e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, dette coniugate. In questi casi, √® possibile calcolare analiticamente la distribuzione posteriore. Questo approccio √® efficiente ma limitato alle situazioni con coniugazione tra distribuzioni a priori e funzioni di verosimiglianza.\nApproccio Numerico: Quando l‚Äôapproccio analitico non √® applicabile, ovvero, quando non √® possible calcolare la verosimiglianza marginale, si usano tecniche di approssimazione numerica. Le catene di Markov Monte Carlo (MCMC) sono spesso impiegate per stimare numericamente la distribuzione posteriore. Questo metodo √® versatile ma richiede un maggiore impegno computazionale.\n\n\n33.5.1 Linguaggi di Programmazione Probabilistici\nL‚Äôuso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori √® facilitato dai linguaggi di programmazione probabilistica (PPL). Questi strumenti rendono la modellazione bayesiana pi√π accessibile, riducendo le barriere di competenza matematica e computazionale. I PPL permettono agli analisti di formulare modelli probabilistici con maggiore chiarezza e flessibilit√†, aprendo nuovi orizzonti nell‚Äôanalisi bayesiana e permettendo di affrontare problemi complessi con tecniche bayesiane avanzate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#incertezza-epistemica-e-aleatoria",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#incertezza-epistemica-e-aleatoria",
    "title": "33¬† Modellazione bayesiana",
    "section": "33.6 Incertezza epistemica e aleatoria",
    "text": "33.6 Incertezza epistemica e aleatoria\n√à cruciale distinguere tra due forme principali di incertezza: epistemica e aleatoria. L‚Äôincertezza epistemica si riferisce alla nostra mancanza di conoscenza o informazione su un fenomeno. Questa forma di incertezza pu√≤ essere ridotta attraverso l‚Äôacquisizione di pi√π dati o una migliore comprensione del fenomeno stesso. D‚Äôaltra parte, l‚Äôincertezza aleatoria √® intrinseca e si riferisce alla variabilit√† naturale o casuale di un fenomeno. Questa forma di incertezza non pu√≤ essere ridotta semplicemente raccogliendo pi√π informazioni. Un esempio classico √® il lancio di un dado: anche con una comprensione perfetta della fisica coinvolta, il risultato specifico di un singolo lancio rimane imprevedibile.\nIl teorema di Bayes √® uno strumento potente per descrivere e gestire l‚Äôincertezza, e si applica principalmente all‚Äôincertezza epistemica. Questo teorema ci permette di aggiornare le nostre credenze su un parametro o un fenomeno (Œ∏) alla luce di nuovi dati (y). Il processo bayesiano pu√≤ essere riassunto come segue:\n\nSi parte con una distribuzione a priori p(Œ∏), che rappresenta la nostra conoscenza iniziale (e quindi l‚Äôincertezza epistemica) sul parametro.\nSi osservano nuovi dati, la cui relazione con il parametro √® descritta dalla verosimiglianza p(y|Œ∏).\nSi applica il teorema di Bayes per combinare la conoscenza a priori con l‚Äôinformazione fornita dai dati.\nSi ottiene la distribuzione a posteriori p(Œ∏|y), che rappresenta la nostra conoscenza aggiornata su Œ∏ dopo aver considerato i dati.\n\nMentre il teorema di Bayes √® efficace nel gestire l‚Äôincertezza epistemica, non riduce l‚Äôincertezza aleatoria. Quest‚Äôultima viene invece incorporata nel modello attraverso la verosimiglianza p(y|Œ∏), che riflette la variabilit√† naturale nei dati. Il teorema di Bayes permette di aggiornare le nostre credenze in presenza di tale variabilit√†, ma non elimina l‚Äôincertezza intrinseca del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#commenti-e-considerazioni-finali",
    "title": "33¬† Modellazione bayesiana",
    "section": "33.7 Commenti e considerazioni finali",
    "text": "33.7 Commenti e considerazioni finali\nNell‚Äôambito dell‚Äôinferenza statistica, i metodi bayesiani stanno guadagnando una crescente popolarit√† anche in psicologia. Questa tendenza √® sostenuta dalla disponibilit√† di risorse educative e pubblicazioni specializzate che facilitano l‚Äôintegrazione dei metodi bayesiani nella pratica analitica. Opere come quelle di Albert e Hu (2019), Johnson, Ott, e Dogucu (2022), McElreath (2020) e (doingbayesian?) hanno svolto un ruolo cruciale in questo contesto, rendendo accessibili e comprensibili i concetti fondamentali della modellizzazione bayesiana.\nL‚Äôapproccio bayesiano offre una prospettiva unica sull‚Äôincertezza associata ai parametri di interesse, differenziandosi dalla metodologia frequentista basata sul test dell‚Äôipotesi nulla. Mentre il paradigma frequentista considera i parametri come valori fissi e sconosciuti, l‚Äôapproccio bayesiano li tratta come quantit√† probabilistiche, assegnando loro una distribuzione a priori che riflette le credenze iniziali. Attraverso il teorema di Bayes, queste credenze vengono aggiornate sulla base dei dati osservati, portando alla definizione della distribuzione a posteriori. Questa distribuzione fornisce una visione aggiornata dell‚Äôincertezza, integrando sia l‚Äôevidenza empirica che le informazioni pregresse.\nLa forza dell‚Äôapproccio bayesiano risiede nella sua capacit√† di combinare conoscenze pregresse con nuove osservazioni, producendo stime dei parametri di interesse che sono non solo pi√π accurate ma anche pi√π significative dal punto di vista interpretativo. Pi√π di un semplice strumento statistico, il bayesianesimo si rivela un potente mezzo decisionale, promuovendo un‚Äôinterazione dinamica tra teoria ed esperienza.\nTuttavia, uno svantaggio dell‚Äôapproccio bayesiano √® la sua potenziale inefficienza nel trattare dataset molto estesi. Questo pu√≤ comportare problemi di scalabilit√† e di efficienza computazionale, soprattutto con insiemi di dati di grandi dimensioni. Per affrontare questa sfida, sono in sviluppo metodi di variational inference, che offrono un‚Äôalternativa al campionamento MCMC. Questi metodi approssimativi permettono di calcolare la distribuzione a posteriori in tempi significativamente ridotti, migliorando l‚Äôefficienza computazionale senza sacrificare troppo la precisione delle stime.\nIn conclusione, l‚Äôapproccio bayesiano rappresenta un paradigma potente e flessibile per l‚Äôinferenza statistica, in grado di incorporare le conoscenze pregresse e aggiornarsi alla luce di nuove evidenze. Nonostante le sfide computazionali, i progressi nei metodi approssimativi come la variational inference promettono di rendere l‚Äôanalisi bayesiana sempre pi√π praticabile ed efficace, estendendo ulteriormente il suo utilizzo in campi come la psicologia e oltre.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "33¬† Modellazione bayesiana",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Mon Aug 05 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlbert, Jim, e Jingchen Hu. 2019. Probability and Bayesian Modeling. Boca Raton, Florida: CRC Press.\n\n\nBaribault, Beth, e Anne GE Collins. 2023. ¬´Troubleshooting Bayesian cognitive models.¬ª Psychological Methods.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>33</span>¬† <span class='chapter-title'>Modellazione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html",
    "href": "chapters/bayesian_inference/02_subj_prop.html",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Introduzione\nQuesto capitolo mira a esplorare in profondit√† il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L‚Äôobiettivo √® dimostrare come le nostre credenze preesistenti sulla probabilit√† \\(\\theta\\) di un evento specifico possano essere affinate mediante l‚Äôosservazione di nuovi dati.\nInizieremo descrivendo come rappresentare le nostre convinzioni iniziali, ovvero quelle formulate prima di raccogliere qualsiasi dato, tramite una distribuzione a priori. Successivamente, delineeremo i passaggi calcolativi necessari per derivare la distribuzione a posteriori di \\(\\theta\\). Questa distribuzione rappresenta le nostre credenze aggiornate su \\(\\theta\\) una volta considerati i dati osservati. L‚Äôottenimento della distribuzione a posteriori avviene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, seguita da una normalizzazione per garantire che il risultato sia una distribuzione di probabilit√† valida.\nIl capitolo si focalizza principalmente sul modello binomiale, un contesto elementare ma cruciale per l‚Äôinferenza bayesiana. Questo modello √® utilizzato per stimare una proporzione di popolazione sconosciuta a partire da una serie di ‚Äúprove di Bernoulli‚Äù, ovvero dati \\(y_1, \\ldots, y_n\\), ciascuno dei quali assume valore 0 o 1. Questo problema rappresenta un punto di partenza relativamente semplice ma fondamentale per la discussione dell‚Äôinferenza bayesiana. Inizieremo esplorando il caso in cui la distribuzione a priori √® discreta, per poi passare all‚Äôanalisi di scenari in cui essa √® continua.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/02_subj_prop.html#verosimiglianza-binomiale",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.1 Verosimiglianza Binomiale",
    "text": "34.1 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova d√† origine a uno dei due possibili esiti, convenzionalmente etichettati come ‚Äòsuccesso‚Äô e ‚Äòfallimento‚Äô. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilit√† di successo in ciascuna prova. Il modello di campionamento binomiale √®:\n\\[ p(y|\\theta) = \\text{Bin}(y|n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y}, \\]\ndove nella parte sinistra dell‚Äôequazione non si indica la dipendenza da \\(n\\) perch√© viene considerato parte del disegno sperimentale e fissato; tutte le probabilit√† discusse per questo problema sono considerate condizionate su \\(n\\), cio√® assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/02_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.2 Applicazione Specifica del Modello Binomiale",
    "text": "34.2 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, esaminiamo un‚Äôapplicazione specifica del modello binomiale per valutare la prestazione di un partecipante in un classico esperimento di psicologia, noto come Go/No-Go task (Shiffrin e Schneider 1977). In questo tipo di compito, ai partecipanti viene richiesto di rispondere a determinati stimoli (prove Go) e di trattenere la risposta ad altri stimoli (prove No-Go). Ad esempio, i partecipanti possono vedere una serie di lettere presentate su uno schermo e devono premere un pulsante quando vedono qualsiasi lettera tranne una specifica lettera bersaglio (ad esempio, la lettera ‚ÄúX‚Äù). In questo esperimento, ogni prova rappresenta un evento di tipo bernoulliano con due possibili esiti: o il partecipante risponde correttamente o commette un errore. I ricercatori analizzano la percentuale di risposte corrette e di inibizioni, concentrandosi in particolare sulla capacit√† del partecipante di controllare l‚Äôimpulso di rispondere durante le prove No-Go.\nConsideriamo un piccolo numero di prove No-Go di un partecipante, dove i risultati sono: 1, 0, 1, 1, 1, 0, 1, 0, 1. Qui, il valore ‚Äú1‚Äù indica che il partecipante √® stato in grado di inibire la risposta, mentre ‚Äú0‚Äù indica che non √® riuscito a farlo. L‚Äôobiettivo dell‚Äôanalisi √® quantificare l‚Äôincertezza nella stima di \\(\\theta\\), che rappresenta la proporzione di risposte corrette nel compito No-Go, ovvero la capacit√† inibitoria del partecipante.\nConsideriamo questi dati come una sequenza di 9 prove bernoulliane indipendenti. Utilizzando il modello binomiale, stimiamo la probabilit√† \\(\\theta\\) che il partecipante riesca a controllare il proprio impulso di rispondere durante le prove No-Go e quantifichiamo l‚Äôincertezza associata a questa stima.\n\n34.2.1 Processo di Lavoro\nMcElreath (2020) descrive il flusso lavoro bayesiano nel modo seguente.\n\nDefinire un Modello Generativo per i Dati: Un modello generativo descrive il processo attraverso il quale i dati vengono prodotti. Nel contesto del compito No-Go, consideriamo ogni prova come un processo di Bernoulli con due possibili esiti: una prestazione corretta, ovvero l‚Äôinibizione della risposta (rappresentata da 1), oppure una prestazione errata, ovvero la mancata inibizione della risposta (rappresentata da 0). Definiamo \\(\\theta\\) come la probabilit√† di ottenere una prestazione corretta nel compito No-Go. Il modello generativo per questi dati pu√≤ essere formalizzato come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, \\dots, 9\\) e \\(X_i\\) assume il valore 1 in caso di prestazione corretta e 0 in caso di prestazione errata nel compito No-Go.\nDefinire uno Stimatore per il Parametro di Interesse: Uno stimatore √® una regola o una formula che utilizza i dati campionari per fornire una stima del parametro di interesse. Nel nostro caso, lo stimatore di interesse √® la probabilit√† \\(\\theta\\) di inibire correttamente la risposta durante le prove No-Go. L‚Äôobiettivo √® non solo calcolare questa probabilit√†, ma anche quantificare l‚Äôincertezza associata alla stima di \\(\\theta\\), basandoci sui dati raccolti.\nSviluppare un Metodo Statistico per la Stima del Parametro di Interesse: Per stimare \\(\\theta\\), utilizziamo l‚Äôapproccio bayesiano. In statistica bayesiana, si parte da una distribuzione a priori che rappresenta le nostre convinzioni iniziali su \\(\\theta\\), e poi si aggiorna questa distribuzione alla luce dei dati osservati per ottenere una distribuzione a posteriori. Nel contesto di un modello Bernoulli/Binomiale, una scelta comune per la distribuzione a priori √® la distribuzione Beta. In questo caso, iniziamo con una distribuzione a priori non informativa, \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme su \\(\\theta\\).\nLa verosimiglianza dei nostri dati (6 ‚Äúsuccessi‚Äù, 3 ‚Äúinsuccessi‚Äù) √® data dalla distribuzione binomiale:\n\\[\nL(p) = {9 \\choose 6} \\theta^{6} (1-\\theta)^{3}.\n\\]\nUtilizziamo il teorema di Bayes per combinare priori e verosimiglianza e ottenere la distribuzione a posteriori:\n\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}\n\\]\nValidazione del Modello tramite Simulazioni:\nPrima di analizzare i dati reali, eseguiamo una simulazione predittiva a priori per verificare se il modello √® in grado di generare dati plausibili. Successivamente, dopo aver adattato il modello ai dati osservati, conduciamo una simulazione predittiva a posteriori per valutare la capacit√† del modello di riprodurre dati simili a quelli effettivamente osservati.\nAnalisi e Sintesi dei Risultati:\nInfine, analizziamo i dati reali calcolando la distribuzione a posteriori, tipicamente tramite metodi computazionali come il Monte Carlo a catene di Markov (MCMC). Riassumiamo questa distribuzione per fare inferenze su \\(\\theta\\), utilizzando statistiche descrittive come la media, la mediana e gli intervalli di credibilit√†.\n\nNel corso di questo capitolo, illustreremo come generare numericamente la distribuzione a posteriori, mentre nei capitoli successivi approfondiremo ulteriormente le varie fasi del flusso di lavoro proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/02_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.3 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano",
    "text": "34.3 Metodo Basato su Griglia nell‚ÄôAggiornamento Bayesiano\nDopo aver discusso l‚Äôaggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia √® un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l‚Äôuso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\nNormalizzazione dei risultati: Per garantire che la somma delle probabilit√† sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l‚Äôarea totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "34.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente considerare un valore di 0.5, suggerendo una probabilit√† ugualmente bilanciata tra la presenza e l‚Äôassenza di ideazione suicidaria. Tuttavia, questo valore non rappresenta adeguatamente l‚Äôintero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilit√† distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilit√† a priori uguale, creando cos√¨ una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) pi√π probabili.\nDopo aver osservato i dati ‚Äî nel nostro caso, 6 successi in 9 prove ‚Äî applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilit√† a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilit√† a posteriori aggiornata per \\(\\theta\\).\nLa distribuzione a posteriori integra quindi le nostre conoscenze pregresse con le nuove informazioni ottenute dalle osservazioni, offrendoci una visione aggiornata e quantitativamente informata del parametro \\(\\theta\\). Attraverso questo esempio, possiamo osservare un approccio sistematico ed efficace per affinare le nostre credenze alla luce di nuove prove.\n\ntheta = np.linspace(0, 1, 11)\nprint(theta)\n\n[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n\n\nNel caso in cui non vi siano motivi fondati per assegnare probabilit√† diverse ai vari valori di \\(\\theta\\), √® possibile attribuire la stessa probabilit√† a ciascun valore, creando cos√¨ una distribuzione uniforme. √à importante prestare attenzione alla seconda riga di codice, che esegue una standardizzazione. Poich√© unif_discr_pdf √® un vettore composto da un numero finito di elementi, questi elementi devono essere considerati come probabilit√†, e tali probabilit√† devono obbligatoriamente sommarsi a uno.\n\nunif_distr_pdf = stats.uniform.pdf(theta) \nunif_distr_pdf = unif_distr_pdf / np.sum(unif_distr_pdf)\nunif_distr_pdf\n\narray([0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n       0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n       0.09090909])\n\n\nUna rappresentazione visiva di questa distribuzione di massa di probabilit√† si ottiene nel modo seguente.\n\nplt.stem(theta, unif_distr_pdf, markerfmt=\" \")\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilit√†\");\n\n\n\n\n\n\n\n\nSe, al contrario, riteniamo che i valori centrali nella distribuzione di \\(\\theta\\) siano pi√π credibili rispetto a quelli situati agli estremi, potremmo esprimere questa opinione soggettiva mediante la seguente distribuzione di massa di probabilit√†.\n\nnot_unif_distr_pdf = [0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05]\nplt.stem(theta, not_unif_distr_pdf, markerfmt=\" \")\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilit√†\");\n\n\n\n\n\n\n\n\nLa prima distribuzione di probabilit√† √® una distribuzione discreta uniforme, in quanto assegna la stessa probabilit√† a ciascun elemento dell‚Äôinsieme discreto su cui √® definita, ossia i valori \\(\\{0, 0.1, 0.2, \\dots, 1.0\\}\\). La seconda distribuzione di probabilit√†, pur essendo discreta, segue un andamento non uniforme: si presume che \\(\\theta\\) abbia una probabilit√† maggiore di assumere un valore nell‚Äôinsieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) rispetto all‚Äôinsieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\).\nLe credenze iniziali riguardo ai possibili valori di \\(\\theta\\) costituiscono la ‚Äúdistribuzione a priori‚Äù. L‚Äôinferenza bayesiana aggiorna queste credenze iniziali utilizzando le informazioni ottenute dai dati. Queste informazioni vengono combinate con le credenze iniziali su \\(\\theta\\) attraverso l‚Äôapplicazione del teorema di Bayes, allo scopo di ottenere la ‚Äúdistribuzione a posteriori‚Äù. Quest‚Äôultima rappresenta le nostre credenze aggiornate sui possibili valori di \\(\\theta\\) dopo l‚Äôosservazione dei dati.\nAbbiamo osservato 6 successi in 9 prove. Per calcolare la distribuzione a posteriori, utilizzeremo la seconda delle due distribuzioni a priori precedentemente descritte. In base al teorema di Bayes, la distribuzione a posteriori si ottiene moltiplicando la verosimiglianza per la distribuzione a priori e quindi dividendo per una costante di normalizzazione (la verosimiglianza marginale):\n\\[ p(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}. \\]\nPer calcolare la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), √® essenziale comprendere il processo attraverso il quale i dati sono stati generati. Nel nostro caso, i dati rappresentano i risultati di 9 ripetizioni di un esperimento casuale, in cui ciascuna prova pu√≤ avere solo due esiti possibili: risposta corretta (inibizione della risposta nelle prove No-Go) o risposta scorretta (mancata inibizione della risposta nelle prove No-Go). Inoltre, assumiamo che le 9 prove siano indipendenti tra loro, cio√® che la prestazione in una prova non influenzi quella nelle prove successive. Date queste condizioni, possiamo modellare il processo generativo dei dati utilizzando un modello binomiale con una probabilit√† sconosciuta \\(\\theta\\).\nUtilizzando Python, √® possibile calcolare la funzione di verosimiglianza tramite la funzione binom.pmf().\n\nlk = stats.binom.pmf(6, 9, theta)\nlk = lk / np.sum(lk)\nlk\n\narray([0.00000000e+00, 6.11961968e-05, 2.75072287e-03, 2.09902955e-02,\n       7.42695176e-02, 1.63955860e-01, 2.50659622e-01, 2.66654495e-01,\n       1.76046264e-01, 4.46120274e-02, 0.00000000e+00])\n\n\nPer i 10 valori \\(\\theta\\) considerati, la funzione di verosimiglianza assume la forma indicata dalla figura seguente.\n\nplt.stem(theta, lk, markerfmt=\" \")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"$L(\\\\theta)$\");\n\n\n\n\n\n\n\n\nPer calcolare la distribuzione a posteriori, eseguiamo una moltiplicazione elemento per elemento tra il vettore contenente i valori della distribuzione a priori e il vettore contenente i valori della funzione di verosimiglianza. Usando Python, il risultato si trova nel modo seguente.\n\nnot_unif_distr_pdf * lk\n\narray([0.00000000e+00, 3.05980984e-06, 1.37536144e-04, 1.04951477e-03,\n       1.29971656e-02, 2.86922755e-02, 4.38654338e-02, 4.66645366e-02,\n       8.80231320e-03, 2.23060137e-03, 0.00000000e+00])\n\n\nPer illustrare con un esempio, il valore dell‚Äôottavo elemento della distribuzione a posteriori si calcola come segue (tenendo presente che in Python gli indici partono da 0):\n\nnot_unif_distr_pdf[7] * lk[7]\n\n0.04666453655213576\n\n\nDopo questa moltiplicazione, otteniamo una distribuzione che rappresenta le probabilit√† condizionate dei possibili valori di \\(\\theta\\) alla luce dei dati osservati. Tuttavia, questa distribuzione potrebbe non √® normalizzata, il che significa che la somma di tutte le probabilit√† condizionate non √® uguale a 1.\nPer ottenere una distribuzione di probabilit√† correttamente normalizzata, dobbiamo dividere ciascun valore ottenuto precedentemente per la probabilit√† marginale dei dati \\(y\\). La probabilit√† marginale dei dati \\(y\\) √® una costante di normalizzazione e pu√≤ essere calcolata utilizzando la legge della probabilit√† totale (si veda l‚Äôeq. {eq}eq-prob-tot).\nPer chiarire, ricordiamo che, nel capitolo {ref}cond-prob-notebook abbiamo considerato il caso di una partizione dello spazio campione in due eventi mutualmente esclusivi ed esaustivi, \\(H_1\\) e \\(H_2\\). All‚Äôinterno dello spazio campione abbiamo definito un evento \\(E\\) non nullo e abbiamo visto che \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\), ovvero \\(P(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2)\\). Usando la terminologia che stiamo usando qui, \\(P(E \\mid H_i)\\) corrisponde alla funzione di verosimiglianza e \\(P(H_i)\\) corrisponde alla funzione a priori. Nel caso discreto, come quello che stiamo considerando ora, il teorema della probabilit√† totale ci dice dunque che dobbiamo fare la somma dei prodotti tra i valori della funzione di verosimiglianza e i corrispondenti valori della distribuzione a priori.\n\nnp.sum(not_unif_distr_pdf * lk)\n\n0.14444243675028887\n\n\nOtteniamo dunque il seguente risultato.\n\npost = (not_unif_distr_pdf * lk) / np.sum(not_unif_distr_pdf * lk)\nprint(post)\n\n[0.00000000e+00 2.11835933e-05 9.52186538e-04 7.26597251e-03\n 8.99816278e-02 1.98641591e-01 3.03687994e-01 3.23066667e-01\n 6.09399384e-02 1.54428395e-02 0.00000000e+00]\n\n\nVerifichiamo di avere ottenuto una distribuzione di massa di probabilit√†:\n\nnp.sum(post)\n\n0.9999999999999999\n\n\nEsaminiamo la distribuzione a posteriori di \\(\\theta\\) con un grafico.\n\nplt.stem(theta, post, markerfmt=\" \")\nplt.title(\"Distribuzione a posteriori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\");\n\n\n\n\n\n\n\n\nUna volta trovata la distribuzione a posteriori di \\(\\theta\\), possiamo calcolare altre quantit√† di interesse. Ad esempio, la moda a posteriori di \\(\\theta\\) pu√≤ essere individuata direttamente dal grafico precedente e risulta pari a 0.5. Per calcolare invece la media a posteriori, ci avvaliamo della formula del valore atteso delle variabili casuali.\n\nnp.sum(theta * post)\n\n0.6086957633539818\n\n\nLa varianza della distribuzione a posteriori √®\n\nnp.sum(theta**2 * post) - (np.sum(theta * post)) ** 2\n\n0.013379767754025107\n\n\nCon questo metodo, possiamo calcolare la distribuzione a posteriori di \\(\\theta\\) per qualsiasi distribuzione a priori discreta.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/02_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.5 Aggiornamento bayesiano con una distribuzione a priori continua",
    "text": "34.5 Aggiornamento bayesiano con una distribuzione a priori continua\nA fini didattici, abbiamo esaminato il caso di una distribuzione a priori discreta. Tuttavia, √® importante notare che l‚Äôimpiego di una distribuzione a priori continua, come la distribuzione Beta, risulta pi√π appropriato in quanto permette di rappresentare un‚Äôampia gamma di possibili valori per il parametro non noto \\(\\theta\\), senza essere vincolati a un insieme discreto di valori. Inoltre, la distribuzione Beta presenta l‚Äôulteriore vantaggio di avere un dominio definito nell‚Äôintervallo [0, 1], che corrisponde alla gamma dei possibili valori per la proporzione \\(\\theta\\).\nPer esempio, consideriamo la distribuzione Beta(2, 2), caratterizzata da una simmetria nella sua forma. Per valutare la distribuzione Beta in corrispondenza di punti specifici, come ad esempio 0.5, 0.8 e 1.2, possiamo fare affidamento sulla funzione beta.pdf. A titolo illustrativo, la densit√† di probabilit√† della distribuzione Beta(2, 2) nel caso del valore 0.5 risulta essere 1.5, suggerendo che i valori di \\(\\theta\\) vicini a 0.5 appaiono pi√π plausibili rispetto a quelli intorno a 0.8, dove la funzione assume un valore di 0.96. √à importante sottolineare che la densit√† di probabilit√† della distribuzione Beta(2, 2) relativa al valore 1.2 √® pari a 0, poich√© tale valore esula dall‚Äôintervallo di definizione della distribuzione (0 e 1). La distribuzione Beta(2, 2) √® illustrata nella figura qui di seguito.\n\nalpha = 2\nbeta = 2\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nSupponiamo ‚Äì solo allo scopo di illustrare la procedura ‚Äì che le nostre credenze a priori siano rappresentate da una Beta(2, 5).\n\nalpha = 2\nbeta = 5\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nNel seguente esempio, useremo la funzione beta.pdf() per generare una distribuzione a priori discretizzata.\n\nprint(stats.beta.pdf(theta, 2, 5))\n\n[0.     1.9683 2.4576 2.1609 1.5552 0.9375 0.4608 0.1701 0.0384 0.0027\n 0.    ]\n\n\n\n_ = plt.plot(theta, stats.beta.pdf(theta, 2, 5))\n\n\n\n\n\n\n\n\nOra per√≤ usiamo un numero maggiore di valori \\(\\theta\\).\n\ntheta = np.linspace(0, 1, 1001)\nprint(theta)\n\n[0.    0.001 0.002 ... 0.998 0.999 1.   ]\n\n\nCalcoliamo la distribuzione a priori normalizzata.\n\nprior = stats.beta.pdf(theta, 2, 5) \nprior = prior / np.sum(prior)\nprint(prior)\n\n[0.00000000e+00 2.98802546e-05 5.95215869e-05 ... 4.79041198e-13\n 2.99700749e-14 0.00000000e+00]\n\n\n\nsum(prior)\n\n1.0000000000000002\n\n\nPer calcolare la verosimiglianza, seguiamo la medesima procedura illustrata nel capitolo {ref}cap-likelihood. In aggiunta, effettuiamo la normalizzazione dei valori discretizzati della verosimiglianza, come precedentemente descritto.\n\nlk = stats.binom.pmf(6, 9, theta)\nlk = lk / np.sum(lk)\nprint(lk)\n\n[0.00000000e+00 8.37482519e-19 5.34380847e-17 ... 6.63976213e-09\n 8.34972583e-10 0.00000000e+00]\n\n\nInfine, otteniamo la distribuzione a posteriori moltiplicando la distribuzione a priori per la verosimiglianza e dividendo per la costante di normalizzazione.\n\npost = (prior * lk) / np.sum(prior * lk)\n\n\nnp.sum(post)\n\n1.0\n\n\n\nplt.plot(theta, prior, linestyle=\"solid\", color=\"C0\", label=\"Prior\")\nplt.plot(theta, lk, linestyle=\"solid\", color=\"C1\", label=\"Likelihood\")\nplt.plot(theta, post, linestyle=\"solid\", color=\"C4\", label=\"Posterior\")\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nPossiamo calcolare la media e la deviazione standard della distribuzione a posteriori come abbiamo fatto in precedenza.\n\n# media\nnp.sum(theta * post)\n\n0.5000000000000001\n\n\n\n# deviazione standard\nnp.sqrt(np.sum(theta**2 * post) - (np.sum(theta * post)) ** 2)\n\n0.12126781251816628",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/02_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori",
    "text": "34.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori\nUna volta ottenuta la distribuzione a posteriori, √® possibile generare un campione casuale da questa distribuzione. A titolo di esempio, possiamo estrarre un campione di 10000 punti dalla distribuzione a posteriori di \\(\\theta\\) che abbiamo calcolato.\n\nsamples = np.random.choice(theta, p=post, size=int(1e4), replace=True)\n\nL‚Äôistruzione precedente genera un array denominato samples contenente 10000 punti campionati dalla distribuzione a posteriori calcolata. La funzione np.random.choice viene impiegata per selezionare casualmente i valori theta basandosi sulle probabilit√† definite da post.\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n# Primo subplot: Scatter plot\naxs[0].plot(samples, \"o\", alpha=0.2, color=\"rebeccapurple\")\naxs[0].set_xlabel(\"Numero di campione\")\naxs[0].set_ylabel(r\"$\\theta$\")\naxs[0].set_title(\"Scatter Plot dei Campioni\")\n\n# Secondo subplot: KDE plot\naz.plot_kde(samples, ax=axs[1], plot_kwargs={\"color\": \"rebeccapurple\"})\naxs[1].set_xlabel(r\"$\\theta$\")\naxs[1].set_ylabel(\"Densit√†\")\naxs[1].set_title(\"KDE Plot dei Campioni\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_40221/1469964889.py:15: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nSfruttando il campione estratto dalla distribuzione a posteriori, √® possibile calcolare diverse quantit√† di interesse. Ad esempio, la stima della media a posteriori di \\(\\theta\\) si ottiene semplicemente calcolando la media dei valori cos√¨ ottenuti.\n\nnp.mean(samples)\n\n0.4996295\n\n\nIn maniera analoga possiamo calcolare la deviazione standard della distribuzione a posteriori di \\(\\theta\\).\n\nnp.std(samples)\n\n0.12312749014639258\n\n\nLa moda a posteriori si pu√≤ calcolare nel modo seguente.\n\nprint(theta[post == max(post)])\n\n[0.5]\n\n\nOppure, usando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo\n\nstats.mode(samples)[0]\n\n0.512\n\n\nUsando il campione estratto dalla distribuzione a posteriori, √® immediato trovare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(samples)\n\n0.5\n\n\nPossiamo calcolare la probabilit√† di varie ipotesi relative a \\(\\theta\\) nella distribuzione a posteriori. Per esempio, calcoliamo la probabilit√† \\(P(\\theta &lt; 0.5)\\).\n\nsum(post[theta &lt; 0.5])\n\n0.49842895507812507\n\n\nAlternativamente, utilizzando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo un risultato analogo, sebbene soggetto a variazioni dovute all‚Äôapprossimazione numerica.\n\nsum(samples &lt; 0.5) / 1e4\n\n0.4988\n\n\nPossiamo trovare la probabilit√† a posteriori che \\(\\theta\\) sia compresa in un dato intervallo. Per esempio, troviamo \\(P(0.5 &lt; \\theta &lt; 0.75)\\).\n\nsum((samples &gt; 0.6) & (samples &lt; 0.8)) / 1e4\n\n0.2074\n\n\nUtilizzando il campionamento effettuato dalla distribuzione a posteriori di \\(\\theta\\), √® possibile risolvere il problema inverso, ovvero determinare l‚Äôintervallo che contiene \\(\\theta\\) con una specifica probabilit√†. Ad esempio, si pu√≤ calcolare l‚Äôintervallo che ha una probabilit√† pari a 0.94 di contenere \\(\\theta\\), basandosi sulla distribuzione a posteriori campionata.\n\nnp.percentile(samples, [2, 98])\n\narray([0.254  , 0.74702])\n\n\nL‚Äôintervallo specificato √® noto come intervallo di credibilit√† e rappresenta una quantificazione statistica dell‚Äôincertezza associata alla stima del parametro \\(\\theta\\). In termini probabilistici, si pu√≤ affermare con il 94% di credibilit√† che il valore ‚Äúvero‚Äù di \\(\\theta\\) √® contenuto nell‚Äôintervallo [0.26, 0.74].\nSe vogliamo trovare l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPD), usiamo la funzione ArviZ hdi() (si veda il capitolo {ref}sintesi-distr-post-notebook).\n\naz.hdi(samples, hdi_prob=0.94)\n\narray([0.279, 0.733])\n\n\nNel contesto attuale, la distribuzione a posteriori √® simmetrica. Di conseguenza, l‚Äôintervallo di credibilit√† calcolato attraverso i quantili e l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPDI) sono molto simili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#qual-√®-il-modo-migliore-per-stimare-il-parametro-theta",
    "href": "chapters/bayesian_inference/02_subj_prop.html#qual-√®-il-modo-migliore-per-stimare-il-parametro-theta",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.7 Qual √® il modo migliore per stimare il parametro \\(\\theta\\)?",
    "text": "34.7 Qual √® il modo migliore per stimare il parametro \\(\\theta\\)?\nNonostante abbiamo discusso in precedenza dei diversi metodi di stima puntuale e intervallare per riassumere la distribuzione a posteriori di \\(\\theta\\), la migliore stima del parametro che stiamo cercando di inferire √® rappresentata dall‚Äôintera distribuzione a posteriori. Per citare le parole di McElreath (2020):\n\nThat an arbitrary interval contains an arbitrary value is not meaningful. Use the whole distribution.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/02_subj_prop.html#metodo-basato-su-griglia",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.8 Metodo basato su griglia",
    "text": "34.8 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori √® noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l‚Äôapprossimazione della distribuzione a posteriori pu√≤ essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l‚Äôapprossimazione della densit√† a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densit√† a posteriori normalizzata.\n\nQuesto metodo pu√≤ essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all‚Äôaumentare della dimensionalit√† dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l‚Äôapproccio basato sulla griglia √® intuitivo e non richiede competenze di programmazione avanzate per l‚Äôimplementazione. Inoltre, fornisce un risultato che pu√≤ essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilit√† a posteriori condizionata ai dati. Tuttavia, questo metodo √® limitato a causa della maledizione della dimensionalit√†1, il che significa che pu√≤ essere applicato soltanto a modelli statistici semplici con non pi√π di due parametri. Di conseguenza, in pratica, √® spesso sostituito da altre tecniche pi√π efficienti, poich√© i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/02_subj_prop.html#commenti-e-considerazioni-finali",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.9 Commenti e Considerazioni Finali",
    "text": "34.9 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato l‚Äôaggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l‚Äôelaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell‚Äôinferenza relativa alle proporzioni, dove la distribuzione a priori √® modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, √® possibile derivare analiticamente la distribuzione a posteriori. L‚Äôanalisi dettagliata di questo caso sar√† trattata nel capitolo successivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/02_subj_prop.html#esercizi",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "34.10 Esercizi",
    "text": "34.10 Esercizi\n\nEsercizio 34.1 Viene chieso di calcolare la distribuzione a posteriori della probabilit√† che uno studio condivida i materiali di ricerca utilizzando il metodo basato su griglia. Si utilizzeranno dati reali per motivare e costruire una distribuzione a priori discretizzata.\nIn uno studio sull‚Äôanalisi delle pratiche di trasparenza e riproducibilit√† nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca √® stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali √® rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilit√† \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicit√†, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilit√† a priori ai 10 livelli, basandoti sull‚Äôinformazione che la condivisione dei materiali √® un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l‚Äôintervallo di credibilit√† al 89%.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlbert, Jim, e Jingchen Hu. 2019. Probability and Bayesian Modeling. Boca Raton, Florida: CRC Press.\n\n\nHardwicke, Tom E, Robert T Thibault, Jessica E Kosie, Joshua D Wallach, Mallory C Kidwell, e John PA Ioannidis. 2022. ¬´Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014‚Äì2017)¬ª. Perspectives on Psychological Science 17 (1): 239‚Äì51.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nShiffrin, Richard M, e Walter Schneider. 1977. ¬´Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory.¬ª Psychological Review 84 (2): 127‚Äì90.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/02_subj_prop.html#footnotes",
    "title": "34¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalit√†, possiamo considerare l‚Äôesempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). √à evidente che la quantit√† di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, √® necessario utilizzare un approccio diverso.‚Ü©Ô∏é",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>34</span>¬† <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02a_grid_gauss.html",
    "href": "chapters/bayesian_inference/02a_grid_gauss.html",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l‚Äôintelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l‚Äôapproccio psicometrico. Secondo questo approccio, una persona √® considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l‚Äôuso di un QI di 130 come soglia √® il criterio pi√π comune, non √® universalmente accettato. L‚Äôintelligenza nei bambini plusdotati non √® solo superiore rispetto a quella dei loro pari, ma √® qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosit√†, empatia, capacit√† di leadership, abilit√† visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguir√†, assumeremo che i dati provengano da una distribuzione normale. Per semplicit√†, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sar√† l‚Äôoggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02a_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/02a_grid_gauss.html#dati",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.1 Dati",
    "text": "35.1 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5. Utilizziamo il seguente codice Python per generare questi dati:\n\nnp.random.seed(RANDOM_SEED)  # Per la riproducibilit√†\nvera_media = 130  # Media vera\nsigma_conosciuta = 5  # Deviazione standard conosciuta\ndimensione_campione = 10  # Dimensione del campione\n\n# Generare un campione\ncampione = np.random.normal(loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione).round()\nprint(campione)\n\n[129. 124. 135. 141. 128. 123. 141. 119. 132. 131.]",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02a_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/02a_grid_gauss.html#griglia",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.2 Griglia",
    "text": "35.2 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150. Questa griglia ci servir√† per calcolare la verosimiglianza.\n\nmu_griglia = np.linspace(start=110, stop=150, num=100)  # 100 punti tra 110 e 150\nprint(mu_griglia)\n\n[110.         110.4040404  110.80808081 111.21212121 111.61616162\n 112.02020202 112.42424242 112.82828283 113.23232323 113.63636364\n 114.04040404 114.44444444 114.84848485 115.25252525 115.65656566\n 116.06060606 116.46464646 116.86868687 117.27272727 117.67676768\n 118.08080808 118.48484848 118.88888889 119.29292929 119.6969697\n 120.1010101  120.50505051 120.90909091 121.31313131 121.71717172\n 122.12121212 122.52525253 122.92929293 123.33333333 123.73737374\n 124.14141414 124.54545455 124.94949495 125.35353535 125.75757576\n 126.16161616 126.56565657 126.96969697 127.37373737 127.77777778\n 128.18181818 128.58585859 128.98989899 129.39393939 129.7979798\n 130.2020202  130.60606061 131.01010101 131.41414141 131.81818182\n 132.22222222 132.62626263 133.03030303 133.43434343 133.83838384\n 134.24242424 134.64646465 135.05050505 135.45454545 135.85858586\n 136.26262626 136.66666667 137.07070707 137.47474747 137.87878788\n 138.28282828 138.68686869 139.09090909 139.49494949 139.8989899\n 140.3030303  140.70707071 141.11111111 141.51515152 141.91919192\n 142.32323232 142.72727273 143.13131313 143.53535354 143.93939394\n 144.34343434 144.74747475 145.15151515 145.55555556 145.95959596\n 146.36363636 146.76767677 147.17171717 147.57575758 147.97979798\n 148.38383838 148.78787879 149.19191919 149.5959596  150.        ]\n\n\n\n35.2.1 Calcolo della Verosimiglianza\nPer ogni valore di media nella griglia, calcoleremo la verosimiglianza, che rappresenta la probabilit√† di osservare il nostro campione dati quei valori di media. Poich√© le osservazioni nel campione sono indipendenti, la verosimiglianza complessiva √® il prodotto delle densit√† di probabilit√† di ciascuna osservazione:\n\nlikelihood = np.array(\n    [np.prod(stats.norm.pdf(campione, loc=mu, scale=sigma_conosciuta)) for mu in mu_griglia]\n)\nlikelihood\n\narray([1.09207034e-51, 2.81130431e-50, 6.77962875e-49, 1.53159793e-47,\n       3.24133885e-46, 6.42606189e-45, 1.19345536e-43, 2.07638679e-42,\n       3.38416198e-41, 5.16695682e-40, 7.39025335e-39, 9.90203887e-38,\n       1.24288439e-36, 1.46142874e-35, 1.60977567e-34, 1.66109274e-33,\n       1.60569555e-32, 1.45402990e-31, 1.23345773e-30, 9.80202970e-30,\n       7.29707081e-29, 5.08887652e-28, 3.32457450e-27, 2.03465618e-26,\n       1.16650552e-25, 6.26503313e-25, 3.15210554e-24, 1.48565830e-23,\n       6.55960851e-23, 2.71317442e-22, 1.05127978e-21, 3.81592400e-21,\n       1.29754350e-20, 4.13318590e-20, 1.23335687e-19, 3.44773107e-19,\n       9.02856674e-19, 2.21485371e-18, 5.08993326e-18, 1.09577133e-17,\n       2.20987945e-17, 4.17501498e-17, 7.38904479e-17, 1.22506566e-16,\n       1.90270402e-16, 2.76836859e-16, 3.77326575e-16, 4.81783232e-16,\n       5.76271010e-16, 6.45717667e-16, 6.77796577e-16, 6.66494974e-16,\n       6.13953092e-16, 5.29802873e-16, 4.28286349e-16, 3.24335853e-16,\n       2.30089337e-16, 1.52911036e-16, 9.51967178e-17, 5.55195483e-17,\n       3.03326726e-17, 1.55244505e-17, 7.44324992e-18, 3.34310310e-18,\n       1.40662310e-18, 5.54429749e-19, 2.04718038e-19, 7.08119413e-20,\n       2.29455090e-20, 6.96513754e-21, 1.98062612e-21, 5.27613760e-22,\n       1.31665056e-22, 3.07797970e-23, 6.74065000e-24, 1.38286126e-24,\n       2.65764058e-25, 4.78469973e-26, 8.06963581e-27, 1.27495245e-27,\n       1.88701280e-28, 2.61635402e-29, 3.39827856e-30, 4.13487371e-31,\n       4.71309645e-32, 5.03258607e-33, 5.03404275e-34, 4.71719026e-35,\n       4.14086138e-36, 3.40516999e-37, 2.62317767e-38, 1.89302967e-39,\n       1.27975826e-40, 8.10474333e-42, 4.80829822e-43, 2.67229458e-44,\n       1.39129131e-45, 6.78566815e-47, 3.10033032e-48, 1.32697923e-49])\n\n\nQuesto codice svolge le seguenti operazioni:\n\nCalcolo della PDF: Per ogni valore di media nella griglia, stats.norm.pdf(campione, loc=mu, scale=sigma_conosciuta) calcola la densit√† di probabilit√† (PDF) per ogni osservazione del campione. Questo ci indica quanto sia probabile osservare quel campione, dato un certo valore di media.\nMoltiplicazione delle Probabilit√†: np.prod() moltiplica tutte queste densit√† di probabilit√†, ottenendo cos√¨ la verosimiglianza complessiva per quel particolare valore della media. Questo passo √® essenziale perch√© stiamo assumendo che le osservazioni siano indipendenti.\nIterazione su Tutti i Valori della Griglia: Il calcolo viene ripetuto per ciascun valore della media nella griglia, restituendo un array (likelihood) che contiene la verosimiglianza per ogni valore di media.\n\nAd esempio, per il primo valore della griglia, 110, il codice calcola quanto sia probabile osservare il campione, assumendo che la media sia effettivamente 110.\n\n\n35.2.2 Calcolo della Distribuzione a Posteriori\nDopo aver calcolato la verosimiglianza per ciascun valore della media, possiamo costruire la distribuzione a posteriori, che combina le informazioni provenienti dai dati con la conoscenza a priori.\n\nImpostazione della Prior: In questo esempio, usiamo una prior uniforme, cio√® assumiamo che tutti i valori di media siano inizialmente equiprobabili.\nCalcolo della Posteriori Non Normalizzata: Moltiplichiamo la verosimiglianza per la prior per ottenere la distribuzione a posteriori non normalizzata.\nNormalizzazione della Posteriori: Normalizziamo la distribuzione a posteriori dividendo ciascun valore per la somma totale degli elementi, ottenendo una distribuzione di probabilit√† valida.\n\nEcco come appare il codice:\n\nprior = np.ones(len(mu_griglia))  # Una prior uniforme\nposterior_non_norm = likelihood * prior  # Calcoliamo la posterior non normalizzata moltiplicando per la prior\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizziamo la posterior\n\nQuesto processo di normalizzazione garantisce che la distribuzione a posteriori sia una distribuzione di probabilit√† valida, con una somma totale pari a 1.\n\n\n35.2.3 Rappresentazione Grafica della Posterior\nPossiamo ora visualizzare la distribuzione a posteriori con un semplice grafico:\n\nplt.plot(mu_griglia, posterior)\nplt.title('Distribuzione a Posteriori della Media')\nplt.xlabel('Media')\nplt.ylabel('Probabilit√†')\nplt.show()\n\n\n\n\n\n\n\n\nPer esplorare ulteriormente, consideriamo una prior non uniforme, come una distribuzione gaussiana con media 140 e deviazione standard 3:\n\n# Calcolo della prior gaussiana per ogni valore della griglia della media\nprior = stats.norm.pdf(mu_griglia, loc=140, scale=3)\n\n# Calcolo della likelihood (rimane invariato)\nlikelihood = np.array([np.prod(stats.norm.pdf(campione, loc=mu, scale=sigma_conosciuta)) for mu in mu_griglia])\n\n# Calcolo della distribuzione a posteriori (aggiornamento con la nuova prior)\nposterior_non_norm = likelihood * prior  # Moltiplicazione element-wise\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizzazione\n\nPossiamo confrontare la nuova distribuzione a posteriori con la prior originale:\n\nplt.plot(mu_griglia, posterior, label='Posterior')\nplt.plot(mu_griglia, prior / np.sum(prior), label='Prior', linestyle='--')\nplt.title('Distribuzione a Posteriori e Prior della Media')\nplt.xlabel('Media')\nplt.ylabel('Densit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSi osserva che, con un campione di piccole dimensioni, l‚Äôutilizzo di una prior informativa ha influenzato considerevolmente la distribuzione a posteriori, spostandola verso la prior. Questo effetto √® evidente se confrontiamo la posterior ottenuta con la prior informativa rispetto a quella ottenuta con una prior uniforme.\n\n\n35.2.4 Campionamento dalla Posterior\nPer ottenere un campione dalla distribuzione a posteriori, possiamo utilizzare il campionamento ponderato:\n\n# Selezione casuale di un indice dalla griglia secondo le probabilit√† a posteriori\nindice_campionato = np.random.choice(a=len(mu_griglia), size=1000, p=posterior)\n\n# Estrazione del valore della media corrispondente all'indice campionato\nmedia_campionata = mu_griglia[indice_campionato]\nmedia_campionata.shape\n\n(1000,)\n\n\nIl metodo np.random.choice permette di selezionare un indice dalla griglia con probabilit√† proporzionale ai valori della distribuzione a posteriori. In questo modo, i valori della media con probabilit√† a posteriori pi√π alta saranno selezionati pi√π frequentemente, riflettendo la loro maggiore plausibilit√† data la combinazione dei dati osservati e della prior.\nQuesto campione dalla distribuzione a posteriori rappresenta quindi una possibile stima della media della popolazione, tenendo conto sia dei dati osservati (attraverso la likelihood) sia delle nostre conoscenze o supposizioni precedenti (attraverso la prior).\nQuesto campionamento riflette la plausibilit√† di ciascun valore della media, basandosi sui dati e sulla prior. L‚Äôistogramma risultante mostra la distribuzione dei campioni:\n\n_ = sns.histplot(media_campionata, alpha=0.5)\n\n\n\n\n\n\n\n\nCalcoliamo ora la media a posteriori:\n\nnp.mean(media_campionata)\n\n132.4363636363636\n\n\nPer calcolare l‚Äôintervallo di credibilit√† al 94%, possiamo fare cos√¨:\n\n# Calcolo del 3¬∞ e 97¬∞ percentile dei campioni per ottenere l'intervallo di credibilit√† al 95%\nlimite_inferiore = np.percentile(media_campionata, 3)\nlimite_superiore = np.percentile(media_campionata, 97)\n\nprint(f\"Intervallo di credibilit√† al 94% per la media: [{limite_inferiore}, {limite_superiore}]\")\n\nIntervallo di credibilit√† al 94% per la media: [129.7979797979798, 135.05050505050505]\n\n\nL‚Äôintervallo di credibilit√† offre una stima probabilistica di dove si trova il vero valore della media, riflettendo l‚Äôincertezza della nostra stima basata sui dati e sulle conoscenze precedenti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02a_grid_gauss.html#la-log-verosimiglianza",
    "href": "chapters/bayesian_inference/02a_grid_gauss.html#la-log-verosimiglianza",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.3 La Log-Verosimiglianza",
    "text": "35.3 La Log-Verosimiglianza\nNel calcolo della verosimiglianza, abbiamo visto che lavorare con la somma delle probabilit√† pu√≤ causare problemi (ovvero, produrre valori numerici estremamente piccoli). Per risolvere questi problemi, √® meglio usare i logaritmi.\n\nStabilit√† Numerica: Quando moltiplichiamo molte probabilit√† piccole, il risultato pu√≤ essere cos√¨ piccolo che il computer lo arrotonda a zero, causando errori. Usare i logaritmi trasforma le moltiplicazioni in somme, riducendo questo rischio.\nSemplificazione dei Calcoli: Il logaritmo di un prodotto √® uguale alla somma dei logaritmi (log(ab) = log(a) + log(b)). Questo ci permette di trasformare un prodotto complesso in una somma, rendendo i calcoli pi√π semplici e veloci.\nMiglioramento della Precisione: I calcolatori sono generalmente pi√π precisi nel sommare numeri che nel moltiplicarli, specialmente quando si tratta di numeri molto grandi o molto piccoli. Usare i logaritmi aiuta quindi a mantenere una maggiore precisione nei nostri calcoli.\nFacilit√† di Ottimizzazione: Molti algoritmi di ottimizzazione funzionano meglio con somme piuttosto che con prodotti. Questo √® particolarmente utile quando dobbiamo stimare parametri, come la media, in modo pi√π efficiente.\nGestione di Valori Estremi: I logaritmi aiutano a gestire meglio un‚Äôampia gamma di valori, riducendo l‚Äôimpatto di numeri estremamente grandi o piccoli che potrebbero influenzare negativamente i risultati.\n\nIn conclusione, usare i logaritmi nei calcoli probabilistici √® vantaggioso perch√© migliora la stabilit√†, la precisione e l‚Äôefficienza, rendendolo un metodo preferibile in molte situazioni.\nEsempio con Log-Verosimiglianza\nPer applicare questo concetto, riprendiamo l‚Äôesempio precedente e rifacciamo i calcoli usando i logaritmi. Questo ci aiuter√† a evitare problemi di precisione e a semplificare i calcoli. Seguiamo i passaggi uno per uno:\n\nGenerazione del Campione: Generiamo un campione di dati da una distribuzione normale.\nDefinizione della Griglia: Creiamo una serie di possibili valori per la media.\nCalcolo della Log-Verosimiglianza: Calcoliamo la log-verosimiglianza per ciascun valore della media.\nCalcolo della Log-Posterior: Combiniamo la log-verosimiglianza con la log-prior (se applicabile) e normalizziamo i risultati per ottenere la distribuzione a posteriori.\nVisualizzazione: Mostriamo graficamente la distribuzione a posteriori.\n\nEcco come fare in Python:\n\n# Per la riproducibilit√† dei risultati\nnp.random.seed(RANDOM_SEED)\n\n# Parametri veri e conosciuti\nvera_media = 130\nsigma_conosciuta = 5\ndimensione_campione = 10\n\n# Generazione di un campione casuale dalla distribuzione normale\ncampione = np.random.normal(\n    loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione\n)\n\n# Definizione della griglia per la media\nmu_griglia = np.linspace(start=110, stop=150, num=100)\n\n# Calcolo della log-verosimiglianza per ciascun valore nella griglia\nlog_likelihood = np.array(\n    [\n        np.sum(stats.norm.logpdf(campione, loc=mu, scale=sigma_conosciuta))\n        for mu in mu_griglia\n    ]\n)\n\n# Calcolo della log-prior gaussiana centrata su 140 con deviazione standard 3\nlog_prior = stats.norm.logpdf(mu_griglia, loc=140, scale=3)\n\n# Calcolo della log-posterior non normalizzata\nlog_posterior_non_norm = log_likelihood + log_prior\n\n# Normalizzazione della log-posterior (conversione alla scala lineare)\nlog_posterior = log_posterior_non_norm - np.log(\n    np.sum(np.exp(log_posterior_non_norm - np.max(log_posterior_non_norm)))\n)\nposterior = np.exp(log_posterior)\n\n# Visualizzazione della distribuzione a posteriori\nplt.plot(mu_griglia, posterior)\nplt.title(\"Distribuzione a Posteriori della Media (Log-verosimiglianza)\")\nplt.xlabel(\"Media\")\nplt.ylabel(\"Probabilit√†\")\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice ci permette di calcolare e visualizzare la distribuzione a posteriori in modo pi√π sicuro ed efficiente, utilizzando i logaritmi per gestire meglio i calcoli complessi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02a_grid_gauss.html#deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/02a_grid_gauss.html#deviazione-standard-ignota",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.4 Deviazione Standard Ignota",
    "text": "35.4 Deviazione Standard Ignota\nEstendere l‚Äôapproccio usato sopra al caso in cui la deviazione standard (\\(\\sigma\\)) della popolazione non √® conosciuta introduce una complessit√† maggiore nell‚Äôinferenza bayesiana, poich√© ora dobbiamo stimare due parametri (la media e la deviazione standard) invece di uno solo. In questo contesto, la distribuzione a posteriori diventa una funzione delle due dimensioni (media e \\(\\sigma\\)), e la sua esplorazione richiede metodi pi√π sofisticati per navigare efficacemente lo spazio dei parametri. Vediamo come affrontare questo problema:\n\n35.4.1 1. Definizione dello Spazio dei Parametri\nDobbiamo definire una griglia bidimensionale che copra le possibili combinazioni di valori per la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)). Questo approccio, sebbene computazionalmente intensivo, √® fattibile per problemi di dimensioni moderate.\n\nmu_griglia = np.linspace(start=110, stop=150, num=100)\nsigma_griglia = np.linspace(start=1, stop=10, num=50)\n\n\n\n35.4.2 2. Calcolo della Log-Likelihood Bidimensionale\nPer ogni coppia di valori (\\(\\mu\\), \\(\\sigma\\)) nella griglia, calcoliamo la log-likelihood del campione. Questo richiede un‚Äôiterazione su entrambe le dimensioni della griglia.\n\nlog_likelihood_2d = np.array([[np.sum(stats.norm.logpdf(campione, loc=mu, scale=sigma))\n                                for sigma in sigma_griglia] for mu in mu_griglia])\n\n\n\n35.4.3 3. Applicazione delle Priors\nLe priors per \\(\\mu\\) e \\(\\sigma\\) possono essere definite in modo indipendente e poi combinate, o si pu√≤ definire una prior congiunta che rifletta la conoscenza o le assunzioni sui parametri. Le log-priors per \\(\\mu\\) e \\(\\sigma\\) sono calcolate su ogni griglia rispettivamente e poi sommate per ottenere una log-prior congiunta.\n\nlog_prior_mu = stats.norm.logpdf(mu_griglia, loc=140, scale=5)\nlog_prior_sigma = stats.norm.logpdf(sigma_griglia, loc=5, scale=2)\nlog_prior_2d = log_prior_mu[:, np.newaxis] + log_prior_sigma\n\n\n\n35.4.4 4. Calcolo della Distribuzione a Posterior Bidimensionale\nSommando la log-likelihood con la log-prior congiunta e normalizzando, otteniamo la distribuzione a posteriori bidimensionale.\n\nlog_posterior_2d = log_likelihood_2d + log_prior_2d\nlog_posterior_2d -= np.max(log_posterior_2d)  # Stabilizzazione\nposterior_2d = np.exp(log_posterior_2d)\nposterior_2d /= np.sum(posterior_2d)\n\n\n\n35.4.5 5. Visualizzazione\nLa visualizzazione di distribuzioni bidimensionali pu√≤ essere effettuata tramite contour plot o heatmaps.\n\nplt.contourf(mu_griglia, sigma_griglia, posterior_2d.T)\nplt.xlabel('Media ($\\mu$)')\nplt.ylabel('Deviazione Standard ($\\sigma$)')\nplt.colorbar(label='Densit√† Posterior')\nplt.title('Distribuzione a Posteriori Bidimensionale')\nplt.show()\n\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:3: SyntaxWarning: invalid escape sequence '\\s'\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:3: SyntaxWarning: invalid escape sequence '\\s'\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63985/4162669767.py:2: SyntaxWarning: invalid escape sequence '\\m'\n  plt.xlabel('Media ($\\mu$)')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63985/4162669767.py:3: SyntaxWarning: invalid escape sequence '\\s'\n  plt.ylabel('Deviazione Standard ($\\sigma$)')",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02a_grid_gauss.html#conclusione-e-riflessioni-finali",
    "href": "chapters/bayesian_inference/02a_grid_gauss.html#conclusione-e-riflessioni-finali",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "35.5 Conclusione e Riflessioni Finali",
    "text": "35.5 Conclusione e Riflessioni Finali\nQuando si passa alla stima simultanea di pi√π parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l‚Äôanalisi diventa notevolmente pi√π complessa. Questo perch√© occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando cos√¨ il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poich√© queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri √® multidimensionale o quando l‚Äôesplorazione della griglia diventa impraticabile, l‚Äôuso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessit√† di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l‚Äôanalisi pi√π gestibile anche in contesti complessi.\nIn conclusione, l‚Äôestensione dell‚Äôapproccio bayesiano a problemi con pi√π parametri sconosciuti richiede un‚Äôattenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L‚Äôadozione di tecniche come l‚ÄôMCMC pu√≤ facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02a_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02a_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "35¬† Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Mar 20 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.1\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>35</span>¬† <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html",
    "title": "36¬† Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, ci focalizziamo sulla derivazione della distribuzione a posteriori attraverso l‚Äôuso di una distribuzione a priori coniugata. Sar√† esaminato in dettaglio il modello beta-binomiale, un esempio paradigmatico che evidenzia il vantaggio dell‚Äôuso delle distribuzioni a priori coniugate in inferenza bayesiana. L‚Äôimpiego di tali distribuzioni facilita notevolmente il processo di inferenza, permettendo di ottenere una distribuzione a posteriori attraverso calcoli analitici diretti e semplificati. Questa metodologia non solo rende il processo di inferenza pi√π gestibile ma anche pi√π intuitivo, offrendo una chiara dimostrazione di come le scelte a priori influenzino l‚Äôanalisi bayesiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#derivazione-analitica-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#derivazione-analitica-della-distribuzione-a-posteriori",
    "title": "36¬† Distribuzioni coniugate (1)",
    "section": "36.1 Derivazione analitica della distribuzione a posteriori",
    "text": "36.1 Derivazione analitica della distribuzione a posteriori\nLe distribuzioni a priori coniugate costituiscono una classe speciale di distribuzioni di probabilit√† aventi una particolare caratteristica: se la distribuzione a priori appartiene a questa classe, anche la distribuzione a posteriori appartiene alla stessa classe, ovvero mantiene la stessa forma funzionale. Questo aspetto semplifica notevolmente l‚Äôaggiornamento delle nostre credenze riguardo al parametro di interesse, in quanto coinvolge semplicemente la modifica dei parametri della distribuzione a priori. Ad esempio, quando selezioniamo una distribuzione a priori Beta e la verosimiglianza corrisponde a una distribuzione binomiale, la distribuzione a posteriori sar√† anch‚Äôessa una distribuzione Beta.\nNonostante le distribuzioni a priori coniugate siano la scelta preferibile dal punto di vista matematico, in quanto permettono di calcolare analiticamente la distribuzione a posteriori evitando calcoli complessi, le moderne tecniche di inferenza bayesiana offrono flessibilit√† nell‚Äôutilizzo di una vasta gamma di distribuzioni a priori. Questa flessibilit√† elimina la necessit√† di vincolarsi esclusivamente alle distribuzioni coniugate. Tuttavia, le distribuzioni a priori coniugate continuano a giocare un ruolo didattico rilevante, poich√© presentano una soluzione analitica per il processo di aggiornamento bayesiano. Nel presene capitolo, esploreremo dettagliatamente il modello beta-binomiale, in cui la verosimiglianza binomiale si combina con la scelta di una distribuzione a priori Beta. Questo modello rappresenta la base dell‚Äôinferenza bayesiana su una proporzione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#lo-schema-beta-binomiale",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#lo-schema-beta-binomiale",
    "title": "36¬† Distribuzioni coniugate (1)",
    "section": "36.2 Lo schema beta-binomiale",
    "text": "36.2 Lo schema beta-binomiale\nLa distribuzione Beta √® utilizzata per descrivere la variabilit√† di una variabile casuale che √® limitata all‚Äôintervallo [0,1]. Questa distribuzione √® definita come:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}, \\quad \\text{per } \\theta \\in (0, 1),\n\\]\ndove \\(B(\\alpha, \\beta)\\) rappresenta la funzione Beta di Eulero, espressa attraverso la funzione Gamma (\\(\\Gamma\\)) come segue:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}.\n\\]\nLa funzione Gamma, a sua volta, √® definita per i valori positivi di \\(x\\) e generalizza il concetto di fattoriale. I parametri \\(\\alpha\\) e \\(\\beta\\) modulano la forma della distribuzione Beta, influenzando la sua varianza e la sua moda.\nNel contesto bayesiano, la distribuzione Beta √® spesso usata come distribuzione a priori per modellare la nostra conoscenza preliminare sulla probabilit√† di successo \\(\\theta\\) in una serie di eventi di Bernoulli. Dopo aver raccolto i dati, possiamo aggiornare questa conoscenza a priori in base alle osservazioni effettive mediante l‚Äôapproccio di aggiornamento bayesiano.\nLa densit√† a priori, data da \\(\\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}\\), viene combinata con la funzione di verosimiglianza che, in caso di dati binomiali, assume la forma \\(\\theta^{y} (1 - \\theta)^{n - y}\\). Moltiplicando la densit√† a priori per la verosimiglianza e tralasciando il fattore di normalizzazione (che sar√† calcolato in seguito), otteniamo una forma che ricorda quella di una distribuzione Beta:\n\\[\n\\theta^{\\alpha + y - 1} (1 - \\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta √® la distribuzione a posteriori non normalizzata per \\(\\theta\\). Per convertirla in una distribuzione di probabilit√† valida, dobbiamo normalizzarla in modo che l‚Äôintegrale su tutto il suo dominio sia pari a 1. Questo si ottiene dividendo per la funzione Beta \\(B(\\alpha', \\beta')\\), dove \\(\\alpha' = \\alpha + y\\) e \\(\\beta' = \\beta + n - y\\).\nIn conclusione, la distribuzione a posteriori per \\(\\theta\\), dopo aver osservato \\(y\\) successi in \\(n\\) prove, diventa una distribuzione Beta con i parametri aggiornati \\(\\alpha'\\) e \\(\\beta'\\):\n\\[\n\\text{Beta}(\\theta \\mid \\alpha + y, \\beta + n - y).\n\\]\nLa normalizzazione richiede il calcolo di \\(B(\\alpha + y, \\beta + n - y)\\), che utilizza la funzione Gamma per garantire che l‚Äôarea sotto la curva della funzione di densit√† di probabilit√† sia esattamente 1 sull‚Äôintervallo [0,1].\nQuesto esempio illustra un‚Äôapplicazione dell‚Äôanalisi coniugata, dove la scelta di una distribuzione a priori Beta, combinata con una funzione di verosimiglianza binomiale, produce una distribuzione a posteriori che √® ancora una distribuzione Beta. Questo risultato √® noto come ‚Äúcaso coniugato beta-binomiale‚Äù, riassunto nel seguente teorema:\n\nTeorema: Se la funzione di verosimiglianza √® binomiale, data da \\(Bin(n, y \\mid \\theta)\\), e la distribuzione a priori √® una Beta con parametri \\((\\alpha, \\beta)\\), allora la distribuzione a posteriori di \\(\\theta\\) sar√† una distribuzione Beta con parametri aggiornati \\((\\alpha + y, \\beta + n - y)\\).\n\nQuesta relazione facilita l‚Äôaggiornamento bayesiano delle nostre credenze sulla proporzione di successi in una serie di prove, utilizzando un approccio analitico e computazionalmente efficiente.\n\nEsempio 36.1 In un esempio ispirato da McElreath (2020) nel suo libro ‚ÄúStatistical Rethinking‚Äù, consideriamo un esperimento dove otteniamo 6 successi (indicati come ‚Äúacqua‚Äù) su un totale di 9 prove (immaginate come lanci di un mappamondo). La verosimiglianza binomiale per questo esperimento √® data da:\n\\[\n\\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) √® il numero di successi e \\(n = 9\\) √® il numero totale di prove.\nSe scegliamo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 2\\), possiamo utilizzare l‚Äôaggiornamento bayesiano per calcolare i parametri della distribuzione a posteriori, dato l‚Äôesito delle nostre prove. L‚Äôapplicazione del teorema di Bayes porta a una distribuzione a posteriori Beta con i parametri aggiornati \\(\\alpha' = \\alpha + y = 8\\) e \\(\\beta' = \\beta + n - y = 5\\).\nOra, vediamo come visualizzare le tre distribuzioni di interesse: la distribuzione a priori Beta(\\(2, 2\\)), la verosimiglianza binomiale per \\(y=6\\) e \\(n=9\\), e la distribuzione a posteriori Beta(\\(8, 5\\)).\n\n# Definiamo i parametri\nalpha_prior, beta_prior = 2, 2\ny, n = 6, 9\nalpha_post, beta_post = alpha_prior + y, beta_prior + n - y\n\n# Creiamo un array di valori theta\ntheta = np.linspace(0, 1, 1000)  # Aumentiamo la risoluzione per un calcolo pi√π preciso\n\n# Calcoliamo le PDF\nprior_pdf = stats.beta.pdf(theta, alpha_prior, beta_prior)\nlikelihood = theta**y * (1-theta)**(n-y)\n\n# Normalizziamo la verosimiglianza\nlikelihood_integral = trapezoid(likelihood, theta)\nnormalized_likelihood = likelihood / likelihood_integral\n\nposterior_pdf = stats.beta.pdf(theta, alpha_post, beta_post)\n\n# Disegnamo le distribuzioni\nplt.plot(theta, prior_pdf, label=f'Prior Beta({alpha_prior}, {beta_prior})', color='blue')\nplt.plot(theta, normalized_likelihood, label='Likelihood (normalizzata)', linestyle='--', color='green')\nplt.plot(theta, posterior_pdf, label=f'Posterior Beta({alpha_post}, {beta_post})', color='red')\n\nplt.xlabel('$\\\\theta$')\nplt.ylabel('Density')\nplt.title('Distribuzioni Prior, Likelihood e Posterior')\n_ = plt.legend()\n\n\n\n\n\n\n\n\nIn questo codice, la funzione trapezoid viene usata per calcolare l‚Äôintegrale della funzione di verosimiglianza non normalizzata su Œ∏, fornendo il fattore di normalizzazione. Dividendo la funzione di verosimiglianza per questo fattore, otteniamo una funzione di verosimiglianza normalizzata, il cui integrale su [0, 1] √® uguale a 1. La normalizzazione della verosimiglianza √® eseguita solo a scopo di visualizzazione, per facilitare il confronto tra le curve.\n\n\nEsempio 36.2 Esaminiamo ora un esempio discuso da Johnson, Ott, e Dogucu (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorit√†, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell‚Äôarticolo, Milgram descrive lo studio come segue:\n\nconsistente nell‚Äôordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che √® un complice addestrato dell‚Äôesperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‚Äòesperimento di apprendimento‚Äô apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l‚Äôesperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre pi√π intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realt√† era un attore addestrato) sulla loro capacit√† di memorizzare una serie di item. Se l‚Äôattore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all‚Äôattore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l‚Äôattore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello ‚ÄúPericolo: Scossa Grave‚Äù. Il problema richiede di costruire la distribuzione a posteriori della probabilit√† \\(\\theta\\) di infliggere una scossa a l livello ‚ÄúPericolo: Scossa Grave‚Äù, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha = 1\nbeta_val = 10\n\n# Creazione di valori x per il plot\nx_values = np.linspace(0, 1, 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf = stats.beta.pdf(x_values, alpha, beta_val)\n\n# Plot della densit√† di probabilit√†\ncolor_fill = \"#b97c7c\"\nplt.plot(x_values, beta_pdf, label='Beta(1, 10)', color=color_fill)\nplt.title('Distribuzione Beta(1, 10)')\nplt.xlabel('x')\nplt.ylabel('Densit√† di probabilit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori √® una Beta di parametri aggiornati\n\ny = 26\nn = 40\n\nalpha_prior = 1\nbeta_prior = 10\n\nalpha_post = alpha_prior + y\nbeta_post = beta_prior + n - y\n\nalpha_post, beta_post\n\n(27, 24)\n\n\n\n# Creazione di valori x per il plot\nx_values = np.linspace(0, 1, 1000)\n\n# Calcolo della densit√† di probabilit√† per ogni valore di x\nbeta_pdf = stats.beta.pdf(x_values, alpha_post, beta_post)\n\n# Plot della densit√† di probabilit√†\nplt.plot(x_values, beta_pdf, label='Beta(27, 24)', color=color_fill)\nplt.title('Distribuzione Beta(1, 10)')\nplt.xlabel('theta')\nplt.ylabel('Densit√† di probabilit√†')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo la media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n\n0.5294117647058824\n\n\nCalcoliamo la moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n\n0.5306122448979592\n\n\nCalcoliamo la probabilit√† che \\(\\theta &gt; 0.6\\)\n\nstats.beta.sf(0.6, alpha_post, beta_post)\n\n0.15616833089995472\n\n\novvero\n\n1 - stats.beta.cdf(0.6, alpha_post, beta_post)\n\n0.15616833089995474\n\n\nSvolgiamo ora il problema usando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta = np.linspace(0, 1, 100)\n\n\nalpha_prior = 1  \nbeta_prior = 10   \n\n# Calcolo della PDF della distribuzione Beta per i valori x\nprior = stats.beta.pdf(theta, alpha_prior, beta_prior)\n\nplt.vlines(theta, 0, prior / np.sum(prior), color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione a priori')\n\nplt.show()\n\n\n\n\n\n\n\n\nCreiamo la verosimiglianza.\n\nlk = stats.binom.pmf(y, n, theta)\n\nplt.vlines(theta, 0, lk / np.sum(lk), color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Verosimiglianza')\n\nplt.show()\n\n\n\n\n\n\n\n\n\npost = (prior * lk) / np.sum(prior * lk)\n\nplt.vlines(theta, 0, post, color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilit√†')\nplt.title('Distribuzione a posteriori')\n\nplt.show()\n\n\n\n\n\n\n\n\nEstraiamo un campione dalla distribuzione a posteriori.\n\nsamples = np.random.choice(theta, p=post, size=int(1e6), replace=True)\n\nTroviamo la media a posteriori.\n\nnp.mean(samples)\n\n0.5294427575757579\n\n\nCalcoliamo la probabilit√† che \\(\\theta &gt; 0.6\\).\n\nnp.mean(samples &gt; 0.6)\n\n0.15274",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "36¬† Distribuzioni coniugate (1)",
    "section": "36.3 Principali distribuzioni coniugate",
    "text": "36.3 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle pi√π note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori √® \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori √® \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori √® \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori √® \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori √® \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#conclusioni",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#conclusioni",
    "title": "36¬† Distribuzioni coniugate (1)",
    "section": "36.4 Conclusioni",
    "text": "36.4 Conclusioni\nIn conclusione, l‚Äôutilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell‚Äôadozione di distribuzioni a priori coniugate risiede nella loro capacit√† di rendere l‚Äôanalisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, √® cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e pi√π realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilit√†. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale √® sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la pi√π adeguata (Johnson, Ott, e Dogucu 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#esercizi",
    "title": "36¬† Distribuzioni coniugate (1)",
    "section": "36.5 Esercizi",
    "text": "36.5 Esercizi\n\nEsercizio 36.1 Si consideri lo studio ‚ÄúAn excess of positive results: Comparing the standard psychology literature with registered reports‚Äù di Scheel, Schijen, e Lakens (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson, Ott, e Dogucu (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel, Schijen, e Lakens (2021)).\nInfine, si commentino i risultati derivanti dall‚Äôanalisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\nEsercizio 36.2 Tra i fattori che possono influenzare il rapporto tra i sessi alla nascita c‚Äô√® la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta √® impiantata in basso nell‚Äôutero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell‚Äôipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\nEsercizio 36.3 Per valutare la sensibilit√† della soluzione precedente alla scelta della distribuzione a priori, ripetere l‚Äôesercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione √® centrata su 0.485 e concentra la maggior parte della sua massa nell‚Äôintervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\nEsercizio 36.4 In uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralit√† manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralit√† manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al.¬†(2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "36¬† Distribuzioni coniugate (1)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, e Donald B Rubin. 1995. Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, Benedetta, Antonello Grippo, Martina Focardi, e Francesco Lolli. 2024. ¬´The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects¬ª. Laterality 29 (2): 151‚Äì68.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nPapadatou-Pastou, Marietta, Eleni Ntolka, Judith Schmitz, Maryanne Martin, Marcus R Munaf√≤, Sebastian Ocklenburg, e Silvia Paracchini. 2020. ¬´Human handedness: A meta-analysis.¬ª Psychological bulletin 146 (6): 481‚Äì524.\n\n\nScheel, Anne M, Mitchell RMJ Schijen, e Dani√´l Lakens. 2021. ¬´An excess of positive results: Comparing the standard psychology literature with registered reports¬ª. Advances in Methods and Practices in Psychological Science 4 (2): 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>36</span>¬† <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html",
    "title": "37¬† Distribuzioni coniugate (2)",
    "section": "",
    "text": "Introduzione\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale √® che, attraverso l‚Äôaggiornamento bayesiano, l‚Äôincertezza sulla stima del parametro si riduce. Questo √® dovuto al fatto che l‚Äôinformazione aggiuntiva fornita dai dati osservati consente di ‚Äúrestringere‚Äù la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo cos√¨ la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle {ref}distr-coniugate-1-notebook, focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello √® la sua capacit√† di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini pi√π semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l‚Äôadozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html#perch√©-usare-la-distribuzione-normale",
    "title": "37¬† Distribuzioni coniugate (2)",
    "section": "37.1 Perch√© Usare la Distribuzione Normale?",
    "text": "37.1 Perch√© Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori √® nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma √® solo approssimativamente normale. Nei casi in cui il ricercatore abbia un‚Äôidea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza pu√≤ offrire buone approssimazioni alla densit√† a posteriori desiderata, con la consapevolezza che, con l‚Äôaumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede propriet√† frequentiste desiderabili. Sebbene l‚Äôenfasi nell‚Äôanalisi bayesiana non sia sulle stime puntuali, si pu√≤ dimostrare che, con campioni sempre pi√π grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa propriet√† esiste perch√© la distribuzione a posteriori √® un compromesso ponderato tra la distribuzione a priori specificata dall‚Äôutente, che in questo capitolo √® normale, e la funzione di verosimiglianza derivata dai dati, anch‚Äôessa normale in questo capitolo. Con l‚Äôaumentare delle dimensioni del campione, la verosimiglianza diventa sempre pi√π dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l‚Äôaumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "37¬† Distribuzioni coniugate (2)",
    "section": "37.2 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "37.2 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo √® stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n37.2.1 Distribuzione a Priori\nNell‚Äôapproccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n\n37.2.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilit√† di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza √® data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n\n37.2.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l‚Äôevidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoich√© la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulter√† anch‚Äôessa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n\n37.2.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula √®:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) √® una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con pi√π dati, la nostra fiducia nella media campionaria cresce, mentre l‚Äôincertezza a priori diminuisce.\n\n\n37.2.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l‚Äôincertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula √®:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) √® sempre inferiore o uguale. In altre parole, l‚Äôincertezza sulla stima di \\(\\mu\\) si riduce con l‚Äôaumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l‚Äôincertezza a priori (\\(\\sigma_0^2\\)) e l‚Äôinformazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un‚Äôintegrazione bilanciata tra l‚Äôinformazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l‚Äôaumento del numero di osservazioni.\n\nEsempio 37.1 I test standard di QI sono progettati per misurare l‚Äôintelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un‚Äôulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poich√© le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L‚Äôidea chiave nella descrizione della distribuzione a posteriori √® se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq = np.array(\n    [\n        96,\n        100,\n        100,\n        85,\n        83,\n        97,\n        92,\n        99,\n        87,\n        72,\n        86,\n        85,\n        67,\n        99,\n        94,\n        103,\n        97,\n        101,\n        87,\n        98,\n        87,\n        73,\n        97,\n        59,\n        98,\n        79,\n        81,\n        93,\n        105,\n        92,\n        78,\n        98,\n        95,\n        96,\n        72,\n        104,\n        90,\n        96,\n        98,\n        102,\n        78,\n        90,\n        63,\n        84,\n        84,\n        107,\n        86,\n        102,\n        106,\n        94,\n        102,\n        72,\n        101,\n        89,\n        72,\n        101,\n        91,\n        100,\n        100,\n        66,\n        107,\n        86,\n        78,\n        84,\n        78,\n        64,\n        72,\n        101,\n        91,\n        100,\n        67,\n        86,\n    ]\n)\n\n\n# Numero di osservazioni\nn = len(iq)\n\n# Media campionaria\ny_bar = np.mean(iq)\n\n# Deviazione standard nota\nsigma = 15\n\n# Parametri a priori\nmu_0 = 100\nsigma_0 = 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\\(\\mu_0\\) √® la media a priori\n\\(\\sigma_0\\) √® la deviazione standard a priori\n\\(n\\) √® il numero di osservazioni\n\\(\\sigma\\) √® la deviazione standard delle osservazioni (nota)\n\\(\\bar{y}\\) √® la media campionaria\n\n\nmu_p = ((1 / sigma_0**2) * mu_0 + (n / sigma**2) * y_bar) / (\n    (1 / sigma_0**2) + (n / sigma**2)\n)\nprint(f\"Media a posteriori (mu_p): {mu_p}\")\n\nMedia a posteriori (mu_p): 89.35616438356165\n\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq = 1 / ((1 / sigma_0**2) + (n / sigma**2))\nprint(f\"Varianza a posteriori (sigma_p_sq): {sigma_p_sq}\")\n\nVarianza a posteriori (sigma_p_sq): 3.082191780821918\n\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\nsigma_p = np.sqrt(sigma_p_sq)\n\n# Definizione dei valori sull'asse x\nx = np.linspace(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, 1000)\n\n# Calcolo della densit√† di probabilit√†\npdf = stats.norm.pdf(x, mu_p, sigma_p)\n\n# Creazione del grafico\nplt.plot(x, pdf, label=f\"N({mu_p:.2f}, {sigma_p:.2f})\", color=\"blue\")\nplt.fill_between(x, pdf, color=\"blue\", alpha=0.2)\nplt.title(\"Distribuzione a Posteriori\")\nplt.xlabel(\"Media del Quoziente di Intelligenza\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nL‚Äôanalisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un‚Äôinterpretazione completa di questo dato, √® fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori √® ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo pu√≤ innescare un effetto di aggregazione, dove la media ‚Äúsmussata‚Äù risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilit√† potrebbero essere mascherate da questa media aggregata.\n√à importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ci√≤ significa che nazioni con popolazioni pi√π piccole, anche se con punteggi QI mediamente pi√π alti o pi√π bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni pi√π grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell‚Äôintelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l‚Äôaccesso all‚Äôistruzione, la qualit√† della nutrizione e l‚Äôesposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilit√† osservata tra le nazioni.\nInoltre, √® fondamentale considerare la possibilit√† di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l‚Äôimportanza di un‚Äôattenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L‚Äôeffetto di aggregazione, l‚Äôutilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un‚Äôanalisi pi√π approfondita che consideri questi fattori e utilizzi metodi statistici pi√π sofisticati per ottenere una comprensione pi√π completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html#commenti-e-considerazioni-finali",
    "title": "37¬† Distribuzioni coniugate (2)",
    "section": "37.3 Commenti e considerazioni finali",
    "text": "37.3 Commenti e considerazioni finali\nIn questa sezione, abbiamo approfondito il meccanismo dell‚Äôaggiornamento bayesiano attraverso l‚Äôimplementazione del modello normale-normale.\nIl processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l‚Äôacquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori $ _0 $ e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media √® determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) √® determinata utilizzando un‚Äôespressione che incorpora entrambe le varianze.\nIn sintesi, l‚Äôadozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la propriet√† di coniugatezza, semplificando cos√¨ l‚Äôintero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "37¬† Distribuzioni coniugate (2)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.8.4\nscipy     : 1.13.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGill, Jeff. 2015. Bayesian methods: A social and behavioral sciences approach. 3rd Edition. Chapman; Hall/CRC.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>37</span>¬† <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html",
    "href": "chapters/bayesian_inference/05_summary_posterior.html",
    "title": "38¬† Sintesi a posteriori",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell‚Äôinformazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell‚Äôinferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/05_summary_posterior.html#riepilogo-numerico",
    "title": "38¬† Sintesi a posteriori",
    "section": "38.1 Riepilogo numerico",
    "text": "38.1 Riepilogo numerico\nLa distribuzione a posteriori contiene in s√© tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con pi√π di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilit√†.\n\n\n38.1.1 Stima puntuale\nNel contesto dell‚Äôinferenza bayesiana, il processo di stima del valore pi√π credibile del parametro \\(\\theta\\) tramite la distribuzione a posteriori √® un compito cruciale. Comunemente, tale processo si avvale di tre statistiche: la moda, la mediana e la media, la cui scelta √® guidata dalla forma della distribuzione a posteriori. Queste statistiche sono utilizzate per ottenere una stima puntuale della tendenza centrale della distribuzione a posteriori, che a sua volta fornisce il ‚Äúvalore pi√π credibile‚Äù del parametro. Questo valore rappresenta la stima a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sui dati osservati e sulle nostre credenze a priori.\n\nMedia a posteriori: La media a posteriori √® il valore atteso del parametro \\(\\theta\\), calcolato sulla base della distribuzione a posteriori. In termini matematici, nel caso continuo, √® espressa dalla formula:\n\\[ E(\\theta | y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta | y) \\, d\\theta. \\]\nModa (Massimo a posteriori, MAP): La moda identifica il valore pi√π probabile del parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore √® noto come ‚Äúmassimo a posteriori‚Äù (MAP). La stima MAP inizia con il concetto di stima di massima verosimiglianza (MLE), che cerca il valore di \\(\\theta\\), denotato come \\(\\hat{\\theta}_{ML}\\), che massimizza la funzione di verosimiglianza \\(L(\\theta | y)\\), come segue:\n\\[ \\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta | y). \\]\nNell‚Äôinferenza bayesiana, \\(\\theta\\) √® considerato come una variabile casuale, e si specifica una distribuzione a priori su \\(\\theta\\) per riflettere la nostra incertezza su \\(\\theta\\). Integrando la distribuzione a priori, otteniamo la formula per la stima MAP:\n\\[ \\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta | y)p(\\theta). \\]\nQuesta formula evidenzia che la stima MAP corrisponde al valore che massimizza la densit√† a posteriori di \\(\\theta\\) dati \\(y\\), che coincide con la moda della densit√† a posteriori.\nMediana: La mediana √® il valore del parametro per cui il 50% della massa di probabilit√† a posteriori si distribuisce equamente a sinistra e a destra. √à una misura robusta della tendenza centrale, particolarmente utile in presenza di distribuzioni asimmetriche o multimodali, dove la moda potrebbe non fornire una stima accurata del valore pi√π probabile del parametro.\n\nPer valutare l‚Äôincertezza associata al parametro \\(\\theta\\), √® utile calcolare la varianza a posteriori. Questa varianza √® basata sulla tendenza centrale definita dalla media a posteriori, e la sua radice quadrata fornisce la deviazione standard a posteriori, che misura l‚Äôincertezza a posteriori relativa a \\(\\theta\\), espressa nelle stesse unit√† di misura dei dati. La formula per la varianza a posteriori √® data da:\n\\[ V(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2. \\]\nIn sintesi, la media, la moda e la mediana a posteriori, insieme alla varianza a posteriori, forniscono una descrizione comprensiva del comportamento della distribuzione a posteriori di \\(\\theta\\), permettendoci di derivare stime puntuali e misurare l‚Äôincertezza associata a \\(\\theta\\) in modo informativo.\n\n\n38.1.2 Intervallo di credibilit√†\nNel contesto dell‚Äôinferenza bayesiana, l‚Äôintervallo di credibilit√† √® uno strumento fondamentale per valutare l‚Äôampiezza dell‚Äôintervallo che racchiude una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo fornisce informazioni sulla nostra incertezza relativa al valore del parametro: un intervallo pi√π ampio indica una maggiore incertezza associata. L‚Äôobiettivo primario dell‚Äôintervallo di credibilit√† √® di fornire una misura quantitativa dell‚Äôincertezza legata alla stima del parametro \\(\\theta\\).\nLa definizione di intervallo di credibilit√† non determina un unico intervallo di ordine \\((1 - \\alpha) \\cdot 100\\%\\), ma rende possibile una gamma infinita di tali intervalli. Di conseguenza, √® essenziale introdurre condizioni aggiuntive per la selezione dell‚Äôintervallo di credibilit√†. Due delle condizioni aggiuntive pi√π comuni sono l‚Äôintervallo di credibilit√† simmetrico e l‚Äôintervallo di credibilit√† pi√π stretto.\n\nIntervallo di Credibilit√† Simmetrico: Questa condizione richiede che l‚Äôintervallo di credibilit√† sia simmetrico rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) √® il valore stimato del parametro, l‚Äôintervallo di credibilit√† avr√† la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) √® un valore positivo adeguato. Un intervallo di credibilit√† simmetrico al livello \\(\\alpha\\) pu√≤ essere rappresentato come:\n\\[ I_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}], \\]\ndove \\(q_z\\) √® un quantile della distribuzione a posteriori. Ad esempio, un intervallo di credibilit√† simmetrico al 94% sar√†:\n\\[ I_{0.06} = [q_{0.03}, q_{0.97}] \\]\nassicurando che il 3% della densit√† di probabilit√† a posteriori sia compreso in ciascuna coda dell‚Äôintervallo.\nIntervallo di Credibilit√† Pi√π Stretto (Intervallo di Massima Densit√† Posteriore, HPD): Questo intervallo √® scelto in modo da avere la larghezza minima tra tutti gli intervalli di ordine \\((1 - \\alpha) \\cdot 100\\%\\), rappresentando la stima pi√π precisa possibile del parametro \\(\\theta\\). A differenza dell‚Äôintervallo di credibilit√† simmetrico, l‚Äôintervallo di credibilit√† pi√π stretto, o Intervallo di Massima Densit√† Posteriore (HPD), √® costruito per includere tutti i valori di \\(\\theta\\) che godono di maggiore credibilit√† a posteriori. Questo intervallo pu√≤ essere ottenuto tracciando una linea orizzontale sulla rappresentazione grafica della distribuzione a posteriori e regolando l‚Äôaltezza della linea in modo che l‚Äôarea sottesa alla curva sia pari a \\(1 - \\alpha\\). L‚Äôintervallo HPD √® il pi√π stretto possibile tra tutti gli intervalli possibili con lo stesso livello di fiducia. Quando la distribuzione a posteriori √® unimodale e simmetrica, l‚Äôintervallo di credibilit√† pi√π stretto coincide con l‚Äôintervallo di credibilit√† simmetrico.\n\nIl calcolo degli intervalli di credibilit√† pu√≤ richiedere l‚Äôuso di software statistici dedicati, data la complessit√† nel determinarli manualmente, specialmente in situazioni con modelli bayesiani pi√π complessi o quando il calcolo coinvolge simulazioni numeriche.\nUn aspetto importante del trattare i parametri in modo probabilistico riguarda l‚Äôinterpretazione degli intervalli di confidenza. Nell‚Äôambito frequentista, √® necessario immaginare un parametro fisso, ad esempio la media della popolazione \\(\\mu\\), e immaginare un numero infinito di campioni ripetuti dalla popolazione caratterizzata da \\(\\mu\\). Per ogni campione, possiamo ottenere la media del campione \\(\\bar{x}\\) e quindi formare un intervallo di confidenza al \\(100(1 ‚àí \\alpha)\\%\\). L‚Äôinterpretazione corretta in termini frequentisti √® che il \\(100(1 ‚àí \\alpha)\\%\\) degli intervalli di confidenza formati in questo modo cattura il vero parametro \\(\\mu\\) sotto l‚Äôipotesi nulla. In questo contesto, la probabilit√† che il parametro sia nell‚Äôintervallo √® o 0 o 1.\nIn contrasto, il framework bayesiano assume che un parametro abbia una distribuzione di probabilit√†. Campionando dalla distribuzione a posteriori dei parametri del modello, possiamo ottenere i suoi quantili e, dai quantili, possiamo ottenere direttamente la probabilit√† che un parametro rientri in un determinato intervallo. Quindi, in questo caso, un intervallo di probabilit√† a posteriori del 95% significherebbe che la probabilit√† che il parametro rientri nell‚Äôintervallo √® 0.95. Questo √® completamente diverso dall‚Äôinterpretazione frequentista, e si allinea pi√π sensatamente con il senso comune.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/05_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "38¬† Sintesi a posteriori",
    "section": "38.2 Verifica di ipotesi bayesiana",
    "text": "38.2 Verifica di ipotesi bayesiana\nL‚Äôinferenza bayesiana pu√≤ anche procedere attraverso un altro approccio, conosciuto come verifica di ipotesi bayesiana. Questo secondo tipo di inferenza bayesiana si concentra su problemi in cui intendiamo valutare la plausibilit√† dell‚Äôaffermazione che il parametro \\(\\theta\\) assuma valori all‚Äôinterno di un intervallo specifico (ad esempio, \\(\\theta &gt; 0.5\\)). In questa situazione, √® possibile calcolare la probabilit√† a posteriori che \\(\\theta\\) cada all‚Äôinterno dell‚Äôintervallo di interesse (come ad esempio, [0.5, 1.0]), integrando la distribuzione a posteriori su tale intervallo.\n\nEsempio 38.1 Per comprendere meglio attraverso un esempio pratico, esaminiamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche, Buerkner, e Renneberg (2019). Il BDI-II √® un questionario utilizzato per valutare la gravit√† dei sintomi depressivi.\n\nbdi = np.array([\n    26,\n    35,\n    30,\n    25,\n    44,\n    30,\n    33,\n    43,\n    22,\n    43,\n    24,\n    19,\n    39,\n    31,\n    25,\n    28,\n    35,\n    30,\n    26,\n    31,\n    41,\n    36,\n    26,\n    35,\n    33,\n    28,\n    27,\n    34,\n    27,\n    22,\n])\nprint(*bdi)\n\n26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35 33 28 27 34 27 22\n\n\nUn valore BDI-II \\(\\geq 30\\) indica la presenza di un livello grave di depressione. Nel campione clinico di {cite:t}zetsche_2019future, 17 pazienti su 30 manifestano un livello grave di depressione.\n\nnp.sum(bdi &gt;= 30)\n\n17\n\n\nSupponiamo di volere stimare la distribuzione a posteriori della probabilit√† \\(\\theta\\) di depressione grave nei pazienti clinici, cos√¨ come viene misurata dal test BDI-II, imponendo su \\(\\theta\\) una distribuzione a priori \\(Beta(8, 2)\\).\nPoich√© i dati possono essere concepiti come una sequenza di prove Bernoulliane indipendenti, laddove la presenza di depressione grave viene concepita come un ‚Äúsuccesso‚Äù, la verosimiglianza sar√† Binomiale con paramentri \\(n\\) = 30 e \\(y\\) = 17.\nAvendo scelto, quale distribuzione a priori, una \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sar√† una \\(Beta(8 + 17, 2 + 30 - 17)\\):\n\\[\nf(\\theta \\mid y = 17) = \\frac{\\Gamma(25 + 15)}{\\Gamma(25)\\Gamma(15)}\\theta^{25-1} (1-\\theta)^{15-1} \\;\\; \\text{ for } \\theta \\in [0,1] \\; .\n\\] (eq-post-beta-25-15)\n\ntheta = np.linspace(0, 1, 200)\nalpha = 25\nbeta = 15\npdf = stats.beta.pdf(theta, alpha, beta)\nplt.plot(theta, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(alpha, beta))\nplt.xlabel(r\"$\\theta$\", fontsize=14)\nplt.ylabel(\"Densit√† di probabilit√†\", fontsize=14)\nplt.legend(loc=1)\nplt.show()\n\n\n\n\n\n\n\n\nVediamo ora come ottenere delle stime puntuali da tale distribuzione a posteriori.\nper il presente esempio, la media della distribuzione a posteriori di \\(\\theta\\) √®\n\\[\n\\mathbb{E}(\\pi \\mid y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25+15} = 0.625.\n\\]\nUna stima del massimo della probabilit√† a posteriori, o brevemente massimo a posteriori, MAP (da maximum a posteriori probability), √® la moda della distribuzione a posteriori. Nel caso presente, abbiamo\n\\[\nMo(\\pi \\mid y = 17) = \\frac{\\alpha-1}{\\alpha + \\beta-2} = \\frac{25-1}{25+15-2} = 0.6316.\n\\]\nLa mediana si ottiene con la funzione beta.ppf():\n\nstats.beta.ppf(0.5, alpha, beta)\n\n0.6271031100419254\n\n\nL‚Äôintervallo di credibilit√† simmetrico al 94% √® dato dalla chiamata a beta.ppf().\n\n[stats.beta.ppf(0.03, alpha, beta), stats.beta.ppf(0.97, alpha, beta)]\n\n[0.4781025861696672, 0.7612890799836668]\n\n\nIl calcolo precedente evidenzia l‚Äôinterpretazione intuitiva dell‚Äôintervallo di credibilit√†. Tale intervallo, infatti, pu√≤ essere interpretato nel modo seguente: possiamo attribuire una certezza soggettiva del 94% all‚Äôevento che \\(\\theta\\) assuma un valore compreso tra 0.478 e 0.761. Il valore di 0.94 corrisponde infatti all‚Äôarea sottesa dalla distribuzione a posteriori nell‚Äôintervallo \\[0.478, 0.761\\].\n\\[\nP(\\theta \\in (0.478, 0.761) \\mid Y = 17) = \\int_{0.478}^{0.761} f(\\theta \\mid y=17) d\\theta = 0.94.\n\\]\n\nbetacdf = stats.beta(alpha, beta).cdf\nbetacdf(0.7612890799836668) - betacdf(0.4781025861696672)\n\n0.9400000000000001\n\n\nPossiamo costruire vari intervalli di credibilit√† simmetrici. Ad esempio, l‚Äôintervallo di credibilit√† compreso tra il 25-esimo e il 75-esimo percentile:\n\n[stats.beta.ppf(0.25, alpha, beta), stats.beta.ppf(0.75, alpha, beta)]\n\n[0.5743877928498646, 0.6778673380880944]\n\n\nIn questo secondo caso, possiamo affermare con una certezza soggettiva del 50% che la probabilit√† di depressione grave tra i pazienti clinici si situa tra 0.57 e 0.68.\nNon esiste un livello ‚Äúgiusto‚Äù di credibilit√† soggettiva. I ricercatori adottano livelli differenti, come il 50%, l‚Äô80% o il 94%, a seconda del contesto dell‚Äôanalisi statistica. Ogni intervallo offre una prospettiva unica sulla nostra comprensione della distribuzione a posteriori del parametro d‚Äôinteresse.\nNon sempre √® appropriato presentare un intervallo di credibilit√† con le stesse code. Quando la distribuzione a posteriori √® marcatamente asimmetrica, risulta pi√π adeguato fornire l‚Äôintervallo di credibilit√† pi√π stretto (o Intervallo di Massima Densit√† Posteriore, HPD). L‚Äôintervallo HPD √® pi√π facilmente calcolabile quando si approssima la distribuzione a posteriori con il metodo MCMC.\nPassiamo ora alla verifica di ipotesi bayesiana. Supponiamo che la nostra ipotesi sia: \\(\\theta &gt;\\) 0.5. La credibilit√† soggettiva dell‚Äôevento \\(\\theta &gt; 0.5\\) pu√≤ essere ottenuta calcolando il seguente integrale:\n\\[\nf(\\theta &gt; 0.5 \\; \\mid \\; y = 17) = \\int_{0.5}^{1}f(\\theta \\mid y=17)d\\theta \\;,\n\\]\ndove \\(f(\\cdot)\\) √® la distribuzione Beta(25, 15).\n√à facile trovare questo valore con Python.\n\n# Parametri della distribuzione Beta\nalpha = 25\nbeta = 15\n\n# Calcoliamo la probabilit√† P(theta &lt; 0.5) utilizzando la funzione cdf \nprobability = stats.beta.cdf(0.5, alpha, beta)\n\n# La probabilit√† P(theta &lt; 0.5) √® data da 1 - P(theta &gt; 0.5)\nprobability_less_than_0_5 = 1 - probability\n\nprint(f\"La probabilit√† P(theta &lt; 0.5) per una Beta(25, 15) √®: {probability_less_than_0_5:.4f}\")\n\nLa probabilit√† P(theta &lt; 0.5) per una Beta(25, 15) √®: 0.9459",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/05_summary_posterior.html#commenti-e-considerazioni-finali",
    "title": "38¬† Sintesi a posteriori",
    "section": "38.3 Commenti e considerazioni finali",
    "text": "38.3 Commenti e considerazioni finali\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L‚Äôimpiego delle statistiche descrittive e l‚Äôanalisi degli intervalli di credibilit√† contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilit√† forniscono un intervallo di valori all‚Äôinterno del quale si ritiene, con un certo grado di probabilit√† soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l‚Äôincertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l‚Äôanalisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale pu√≤ essere condotto agevolmente calcolando l‚Äôarea appropriata sotto la distribuzione a posteriori, in accordo con l‚Äôipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "38¬† Sintesi a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 28 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nnumpy     : 1.26.4\narviz     : 0.17.1\nsys       : 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:51:20) [Clang 16.0.6 ]\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, e Babette Renneberg. 2019. ¬´Future expectations in clinical depression: biased or realistic?¬ª Journal of Abnormal Psychology 128 (7): 678.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>38</span>¬† <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html",
    "title": "39¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "",
    "text": "Introduzione\nIn questo capitolo si focalizza sull‚Äôimportanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi tratti dal libro ‚ÄúBayes Rules!‚Äù di Johnson e collaboratori {cite:p}Johnson2022bayesrules.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "39¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "39.1 La Distribuzione a Priori",
    "text": "39.1 La Distribuzione a Priori\nLa distribuzione a priori assume un ruolo centrale nell‚Äôapproccio bayesiano, poich√© riflette le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto √® di fondamentale importanza perch√© consente di integrare le informazioni pregresse con i dati osservati al fine di ottenere una stima pi√π precisa dei parametri. Le distribuzioni a priori possono variare in base al grado di certezza attribuito ai valori dei parametri.\n\n39.1.1 Distribuzioni a Priori Non Informative\nLe distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilit√† a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa √® la distribuzione uniforme, basata sul ‚ÄúPrincipio della Ragione Insufficiente‚Äù formulato da Laplace (1774/1951). Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\n\n\n39.1.2 Distribuzioni a Priori Debolmente Informative\nLe distribuzioni a priori debolmente informative consentendo di integrare una quantit√† limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori ‚Äúragionevoli‚Äù dei parametri del modello, tenendo conto delle incertezze presenti nell‚Äôanalisi. L‚Äôuso di informazioni a priori debolmente informative pu√≤ contribuire a migliorare la stabilit√† dell‚Äôanalisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non ‚Äúspostare‚Äù in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori ‚Äúneutri‚Äù dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ci√≤ che rende queste distribuzioni debolmente informative √® la specifica definizione di un intervallo ‚Äúplausibile‚Äù di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo pi√π stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l‚Äôanalisi verso soluzioni pi√π verosimili senza imporre vincoli eccessivi sui risultati.\n\n\n39.1.3 Distribuzioni a Priori Informativa\nLe conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l‚Äôincorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull‚Äôanalisi statistica, fornendo una solida base di conoscenza su cui fondare l‚Äôinferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L‚Äôincorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l‚Äôaccuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull‚Äôanalisi bayesiana.\nNell‚Äôambito della ricerca psicologica, l‚Äôutilizzo di distribuzioni a priori informative √® attualmente poco diffuso, tuttavia emergono segnali che all‚Äôinterno della comunit√† statistica sta crescendo l‚Äôinteresse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#il-caso-beta-binomiale",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#il-caso-beta-binomiale",
    "title": "39¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "39.2 Il caso beta-binomiale",
    "text": "39.2 Il caso beta-binomiale\nLa formula \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\) √® fondamentale per la comprensione dell‚Äôinferenza bayesiana. Essa illustra chiaramente che la distribuzione a posteriori emerge dalla congiunzione tra la distribuzione a priori e la funzione di verosimiglianza associata ai dati osservati. Questa sinergia permette di integrare informazioni a priori con evidenze empiriche recenti, risultando in una stima a posteriori del parametro \\(\\theta\\) che √® caratterizzata da un elevato grado di precisione e informativit√†.\nNel corso di questo capitolo, faremo uso di due funzioni specifiche per esplorare il modello beta-binomiale: plot_beta_binomial e summarize_beta_binomial. La prima funzione permette di visualizzare graficamente le distribuzioni a priori, di verosimiglianza e a posteriori, offrendo quindi un quadro intuitivo dell‚Äôaggiornamento bayesiano. La seconda funzione, invece, si concentra sull‚Äôestrazione di statistiche descrittive come la media, la moda e la varianza dalla distribuzione a posteriori. Entrambe queste risorse provengono dal testo di Johnson, Ott, e Dogucu (2022) e saranno strumentali per una comprensione approfondita del modello in esame.\n\ndef plot_beta_binomial(alpha, beta, y=None, n=None, prior=True, likelihood=True, posterior=True) -&gt; None:\n    \"\"\"Plot a Beta-Binomial Bayesian Model\n    \n    Parameters:\n    - alpha, beta: positive shape parameters of the prior Beta distribution\n    - y: observed number of successes\n    - n: observed number of trials\n    - prior: indicates whether the prior distribution should be plotted\n    - likelihood: indicates whether the scaled likelihood should be plotted\n    - posterior: indicates whether the posterior distribution should be plotted\n    \"\"\"\n    \n    Œ∏ = np.linspace(0, 1, 100)  # Range of possible values for Œ∏\n    \n    if prior:\n        p_theta = stats.beta.pdf(Œ∏, alpha, beta)\n        plt.fill_between(Œ∏, p_theta, step='mid', alpha=0.2, color='blue', label='Prior')\n    \n    if y is not None and n is not None:\n        if likelihood:\n            likelihood_values = stats.binom.pmf(y, n, Œ∏)\n            scale_factor = integrate.simpson(y=likelihood_values, x=Œ∏)  # Corrected to use keyword arguments\n            plt.plot(Œ∏, likelihood_values / scale_factor, color='orange', label='Likelihood (scaled)', lw=2)\n        \n        if posterior:\n            alpha_post = alpha + y\n            beta_post = beta + n - y\n            p_theta_post = stats.beta.pdf(Œ∏, alpha_post, beta_post)\n            plt.fill_between(Œ∏, p_theta_post, step='mid', alpha=0.4, color='green', label='Posterior')\n    \n    plt.xlabel(r'$\\theta$')\n    plt.ylabel('Density')\n    plt.legend(loc='upper left')\n    plt.title('Beta-Binomial Model')\n    plt.show()\n\n\ndef summarize_beta_binomial(alpha, beta, y=None, n=None):\n    \"\"\"Summarize a Beta-Binomial Bayesian model\n\n    @param alpha,beta positive shape parameters of the prior Beta model\n    @param y number of successes\n    @param n number of trials\n\n    Return: Pandas dataframe summarizing beta binomial\n    \"\"\"\n\n    def beta_mean(a, b):\n        return a / (a + b)\n\n    def beta_mode(a, b):\n        if a &lt; 1 and b &lt; 1:\n            return \"0 and 1\"\n        elif a &lt;= 1 and b &gt; 1:\n            return 0\n        elif a &gt; 1 and b &lt; 1:\n            return 1\n        else:\n            return (a - 1) / (a + b - 2)\n\n    def beta_var(a, b):\n        return a * b / ((a + b) ** 2 * (a + b + 1))\n\n    prior_mean = beta_mean(alpha, beta)\n    prior_mode = beta_mode(alpha, beta)\n    prior_var = beta_var(alpha, beta)\n    prior_sd = np.sqrt(prior_var)\n    if y is None and n is None:\n        summary = pd.DataFrame(\n            {\n                \"alpha\": alpha,\n                \"beta\": beta,\n                \"mean\": prior_mean,\n                \"mode\": prior_mode,\n                \"var\": prior_var,\n                \"sd\": prior_sd,\n            },\n            index=[\"prior\"],\n        )\n    else:\n        post_alpha = y + alpha\n        post_beta = n - y + beta\n        post_mean = beta_mean(post_alpha, post_beta)\n        post_mode = beta_mode(post_alpha, post_beta)\n        post_var = beta_var(post_alpha, post_beta)\n        post_sd = np.sqrt(post_var)\n        summary = pd.DataFrame(\n            {\n                \"alpha\": [alpha, post_alpha],\n                \"beta\": [beta, post_beta],\n                \"mean\": [prior_mean, post_mean],\n                \"mode\": [prior_mode, post_mode],\n                \"var\": [prior_var, post_var],\n                \"sd\": [prior_sd, post_sd],\n            },\n            index=[\"prior\", \"posterior\"],\n        )\n    return summary\n\nNel caso in cui disponiamo di un campione di dati di dimensioni molto ridotte, come ad esempio 15 successi su 20 tentativi in una distribuzione beta-binomiale, la distribuzione a priori pu√≤ esercitare un notevole impatto sulla distribuzione a posteriori. In contrasto, se consideriamo una distribuzione a priori uniforme, la distribuzione a posteriori assomiglier√† alla funzione di verosimiglianza, con l‚Äôeccezione dell‚Äôarea sotto le due curve. In parole pi√π semplici, quando la distribuzione a priori √® uniforme, la distribuzione a posteriori presenter√† un picco nella stima di massima verosimiglianza. Tuttavia, quando adottiamo diverse distribuzioni a priori, la distribuzione a posteriori potrebbe notevolmente discostarsi.\nCominciamo esaminando il caso in cui viene adottata una distribuzione a priori uniforme.\n\nplot_beta_binomial(alpha=1, beta=1, y=15, n=20)\n\n\n\n\n\n\n\n\nEsaminiamo ora l‚Äôeffetto di una distribuzione a priori poco informativa, come ad esempio una Beta(2, 2). In questa situazione, l‚Äôimpatto di tale scelta sulla distribuzione a posteriori √® di modesta entit√†, ma comunque presente. Questo fenomeno pu√≤ essere interpretato come un effetto di ‚Äúregolarizzazione‚Äù, il quale influisce sulla nostra stima in modo pi√π cauto rispetto a quanto ottenuto tramite il principio di massima verosimiglianza. In altre parole, la stima risultante risulta essere pi√π ‚Äúbilanciata‚Äù verso il valore intermedio di 0.5.\n\nplot_beta_binomial(alpha=2, beta=2, y=15, n=20)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=2, y=15, n=20)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n2\n0.500000\n0.500000\n0.050000\n0.223607\n\n\nposterior\n17\n7\n0.708333\n0.727273\n0.008264\n0.090906\n\n\n\n\n\n\n\n\nSe il campione √® di dimensioni maggiori, l‚Äôadozione di una distribuzione a priori Beta(2, 2) ha un effetto trascurabile: infatti, il valore massimo della distribuzione a posteriori risulta essere quasi identico alla stima di massima verosimiglianza.\n\nplot_beta_binomial(alpha=2, beta=2, y=150, n=200)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=2, y=150, n=200)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n2\n0.500000\n0.500000\n0.050000\n0.223607\n\n\nposterior\n152\n52\n0.745098\n0.747525\n0.000926\n0.030438\n\n\n\n\n\n\n\n\nSe optiamo per una distribuzione a priori informativa, questa avr√† un notevole impatto sulla distribuzione a posteriori quando ci si trova di fronte a un campione di dimensioni ridotte.\n\nplot_beta_binomial(alpha=2, beta=5, y=15, n=20)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=15, n=20)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.20\n0.025510\n0.159719\n\n\nposterior\n17\n10\n0.629630\n0.64\n0.008328\n0.091260\n\n\n\n\n\n\n\n\nAl contrario, la medesima distribuzione a priori ha un effetto insignificante sulla distribuzione a posteriori quando il campione √® di dimensioni considerevoli.\n\nplot_beta_binomial(alpha=2, beta=5, y=150, n=200)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=150, n=200)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.200000\n0.025510\n0.159719\n\n\nposterior\n152\n55\n0.734300\n0.736585\n0.000938\n0.030627\n\n\n\n\n\n\n\n\n\nplot_beta_binomial(alpha=2, beta=5, y=1500, n=2000)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=1500, n=2000)\n\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.200000\n0.025510\n0.159719\n\n\nposterior\n1502\n505\n0.748381\n0.748628\n0.000094\n0.009684",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "39¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "39.3 Connessione tra intuizioni e teoria",
    "text": "39.3 Connessione tra intuizioni e teoria\nL‚Äôequilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessit√† matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che pu√≤ essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL‚Äôequazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) √® significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sar√† principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) √® piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente √® \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilit√† a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletter√† l‚Äôimportanza attribuita all‚Äôinformazione a priori: maggiore √® il valore di \\(\\alpha + \\beta\\), maggiore sar√† il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) √® considerevolmente grande, la distribuzione a posteriori avr√† un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#un-esempio-controintuitivo",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#un-esempio-controintuitivo",
    "title": "39¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "39.4 Un Esempio Controintuitivo",
    "text": "39.4 Un Esempio Controintuitivo\nEsaminiamo ora un altro esempio proposto in un tweet di McElreath:\n\nLesson: Don‚Äôt trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi scenari in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libert√†) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code pi√π spesse.\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento pi√π ‚Äúprevedibile‚Äù e concentrato attorno al valore medio.\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code pi√π spesse. La presenza di ‚Äúextra massa‚Äù nelle code significa che ciascuna distribuzione trova il modo dell‚Äôaltra pi√π plausibile, portando a una media che non rappresenta il miglior ‚Äúcompromesso‚Äù. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa √® molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non √® sorpreso dalla likelihood. Questo porta a un posterior che √® pi√π influenzato dalla likelihood normale.\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, √® il prior normale a dominare. Il ragionamento √® simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code pi√π spesse della likelihood di Student-t.\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code pi√π spesse e quindi eserciti una maggiore influenza sul posterior.\nDi seguito √® riportato il codice per riprodurre i risultati delle figure precedenti.\n\n# Observed data\nyobs = 0\n\n# Number of samples\nn_samples = 2000\n\n# Model with normal prior and normal likelihood\nwith pm.Model() as mnn:\n    mu = pm.Normal('mu', mu=10, sigma=1)\n    y = pm.Normal('y', mu=mu, sigma=1, observed=yobs)\n    trace_mnn = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with t prior and t likelihood\nwith pm.Model() as mtt:\n    mu = pm.StudentT('mu', nu=2, mu=10, sigma=1)\n    y = pm.StudentT('y', nu=2, mu=mu, sigma=1, observed=yobs)\n    trace_mtt = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with t prior and normal likelihood\nwith pm.Model() as mnt:\n    mu = pm.StudentT('mu', nu=2, mu=10, sigma=1)\n    y = pm.Normal('y', mu=mu, sigma=1, observed=yobs)\n    trace_mnt = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with normal prior and t likelihood\nwith pm.Model() as mtn:\n    mu = pm.Normal('mu', mu=10, sigma=1)\n    y = pm.StudentT('y', nu=2, mu=mu, sigma=1, observed=yobs)\n    trace_mtn = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n\n# Function to plot the results\ndef plot_posterior(trace, model_name):\n    mu_samples = trace.posterior['mu'].values.flatten()  # Extracting 'mu' samples\n    plt.hist(mu_samples, density=True, bins=30, alpha=0.7, label=f'{model_name} Posterior')\n    plt.xlabel('mu')\n    plt.ylabel('Density')\n    plt.legend()\n\n# Plotting the results\nplt.figure(figsize=(9, 7))\n\nplt.subplot(2, 2, 1)\nplot_posterior(trace_mnn, 'Normal Prior, Normal Likelihood')\n\nplt.subplot(2, 2, 2)\nplot_posterior(trace_mtt, 't Prior, t Likelihood')\n\nplt.subplot(2, 2, 3)\nplot_posterior(trace_mnt, 't Prior, Normal Likelihood')\n\nplt.subplot(2, 2, 4)\nplot_posterior(trace_mtn, 'Normal Prior, t Likelihood')\nplt.tight_layout()\nplt.show()\n\n/var/folders/hl/dt523djx7_q7xjrthzjpdvc40000gn/T/ipykernel_61930/765634110.py:23: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nIn conclusione, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non √® una scelta consigliabile. √à invece fondamentale procedere con l‚Äôesecuzione dei calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#commenti-e-considerazioni-finali",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#commenti-e-considerazioni-finali",
    "title": "39¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "39.5 Commenti e considerazioni finali",
    "text": "39.5 Commenti e considerazioni finali\nLa conclusione dell‚Äôesempio presentato da Johnson (2022) ci offre una panoramica intuitiva ma fondamentale: l‚Äôaggiornamento bayesiano rispecchia i processi di ragionamento che intuitivamente utilizziamo nel quotidiano. Quando ci troviamo di fronte a nuove evidenze deboli, le nostre credenze preesistenti rimangono invariate. Al contrario, evidenze robuste ci costringono a rivedere e aggiornare le nostre credenze in linea con i nuovi dati. Questa √® la quintessenza dell‚Äôapproccio bayesiano: un meccanismo quantitativo e preciso che formalizza le nostre intuizioni.\nQuesto √® in netto contrasto con l‚Äôapproccio frequentista, che ignora le credenze o le conoscenze preesistenti. In questo schema, i risultati di un test statistico basato su un campione limitato di dati possono portare a una modifica delle credenze senza alcuna considerazione per le evidenze o le intuizioni pregresse. Questo divario metodologico tra i due approcci √® sintetizzata con efficacia nella celebre striscia comica di xkcd.\nEntrando nel dettaglio del contesto bayesiano, la scelta delle distribuzioni a priori √® un elemento cruciale, con due obiettivi principali. In primo luogo, l‚Äôutilizzo di distribuzioni a priori debolmente informative agisce come un meccanismo di regolarizzazione, contribuendo a ottenere inferenze pi√π prudenti mitigando l‚Äôeffetto di osservazioni estreme. Questo aspetto √® generalmente accettato e ritenuto non controverso nel campo statistico.\nIn secondo luogo, un settore in rapida crescita e di grande interesse √® l‚Äôintegrazione esplicita di conoscenza esperta preesistente. Tale processo, noto come ‚Äòelicitazione della conoscenza esperta‚Äô (expert knowledge elicitation) Brownstein et al. (2019), va ben oltre la semplice intervista con gli esperti. Esso richiede un elevato grado di rigore metodologico per prevenire l‚Äôinsorgenza di bias cognitivi. Questo aspetto √® particolarmente rilevante in ambiti come la psicologia, dove gli sviluppi teorici possono essere meno frequenti. Tale necessit√† √® supportata da un‚Äôampia letteratura accademica e da protocolli ben definiti, quali Cooke, SHELF e Delphi probabilistico O‚ÄôHagan (2019).\nIn conclusione, pur aspirando all‚Äôobiettivit√† come ideale della ricerca scientifica, √® indispensabile riconoscere e affrontare la soggettivit√† intrinseca nel processo di scelta dei priori. Attraverso l‚Äôuso di protocolli rigorosi di elicitazione della conoscenza esperta, √® possibile realizzare analisi bayesiane robuste e ben informate, che riflettano in modo accurato sia le incertezze intrinseche che la competenza specifica nel campo di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "39¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p jax\n\nLast updated: Tue Apr 09 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\njax: 0.4.25\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.0\nrequests  : 2.31.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\npymc      : 5.10.4\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBrownstein, Naomi C, Thomas A Louis, Anthony O‚ÄôHagan, e Jane Pendergast. 2019. ¬´The role of expert judgment in statistical inference and evidence-based decision-making¬ª. The American Statistician 73 (sup1): 56‚Äì68.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO‚ÄôHagan, Anthony. 2019. ¬´Expert knowledge elicitation: subjective but scientific¬ª. The American Statistician 73 (sup1): 69‚Äì81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>39</span>¬† <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_poisson_model.html",
    "href": "chapters/bayesian_inference/07_poisson_model.html",
    "title": "40¬† Modello di Poisson",
    "section": "",
    "text": "40.1 Introduzione\nUn tema di particolare importanza emerge quando ci occupiamo di variabili di risposta che rappresentano conteggi, indicate con \\(y\\). Queste variabili possono assumere valori discreti come 0, 1, 2, ecc., e trovano applicazione in numerosi ambiti della psicologia. In particolare, sono fondamentali nei modelli che indagano l‚Äôincidenza di eventi psicologici specifici, come la quantificazione della frequenza con cui si manifestano i sintomi di un disturbo in determinati intervalli di tempo.\nIn questo capitolo, ci concentreremo sulla stima del tasso medio di incidenza degli eventi all‚Äôinterno di un determinato sistema, cio√® sul numero medio di eventi che si verificano per unit√† di tempo o spazio. A tal fine, analizzeremo la stima del parametro \\(\\mu_i\\), comunemente noto come ‚Äúrate‚Äù, utilizzando il modello di Poisson.\nEsamineremo la derivazione della distribuzione a posteriori attraverso il metodo basato su griglia, impiegando una funzione di verosimiglianza di Poisson e una distribuzione a priori Gamma. Inoltre, dimostreremo l‚Äôequivalenza tra la soluzione ottenuta analiticamente e quella ricavata tramite simulazione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/07_poisson_model.html#distribuzione-di-poisson",
    "title": "40¬† Modello di Poisson",
    "section": "40.2 Distribuzione di Poisson",
    "text": "40.2 Distribuzione di Poisson\nLa distribuzione di Poisson √® un modello probabilistico utilizzato per descrivere il numero di eventi che si verificano in un intervallo di tempo o spazio fisso, partendo dall‚Äôassunto che tali eventi si verifichino con una frequenza media costante e in modo indipendente rispetto al tempo trascorso dall‚Äôultimo evento. Se un dato \\(y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), allora la probabilit√† di osservare un singolo valore \\(y_i\\) √® data da:\n\\[\nf(y_i | \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!},\n\\]\ndove \\(\\lambda &gt; 0\\) rappresenta la frequenza media di occorrenza degli eventi, e \\(y_i\\) √® il numero di eventi osservati. La distribuzione di Poisson ha la caratteristica che sia il valore atteso che la varianza di una variabile casuale \\(Y\\) che segue questa distribuzione sono pari a \\(\\lambda\\), cio√® \\(E(Y) = \\lambda\\) e \\(\\text{Var}(Y) = \\lambda\\).\n\n40.2.1 Esempio di Simulazione\nPer illustrare l‚Äôapplicazione pratica della distribuzione di Poisson, consideriamo un caso in cui il parametro della distribuzione √® \\(\\lambda = 2\\). Questo scenario pu√≤ rappresentare, ad esempio, il numero di compulsioni eseguite da un paziente con disturbo ossessivo-compulsivo in un determinato intervallo di tempo, supponendo che questi eventi si verifichino con una frequenza media di 2 all‚Äôora. In altre parole, con \\(\\lambda = 2\\), ci aspettiamo in media 2 eventi (compulsioni) per ora.\nLa probabilit√† di osservare esattamente \\(k\\) eventi in un‚Äôora √® calcolata dalla formula:\n\\[\nf(k | \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}\n\\]\nNel caso specifico con \\(\\lambda = 2\\), le probabilit√† per i primi valori di \\(k\\) sono:\n\nLa probabilit√† di osservare 0 eventi in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0{.}1353\\).\nLa probabilit√† di osservare 1 evento in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0{.}2707\\).\nLa probabilit√† di osservare 2 eventi in un‚Äôora √® \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0{.}2707\\).\nE cos√¨ via per \\(k = 3\\), \\(k = 4\\), e cos√¨ via.\n\nQuesto esempio illustra come la distribuzione di Poisson possa essere utilizzata per modellare il numero di eventi rari che si verificano in un intervallo temporale fisso, con una frequenza media nota.\nSvolgiamo i calcoli usando la funzione poisson del modulo scipy.stats:\n\nlam_true = 2\n# Creazione di un array di valori da 0 a 9\nk_values = np.arange(0, 10)  \n\n# Calcolo delle probabilit√† per ogni valore in k_values\nprobabilities = stats.poisson.pmf(k_values, lam_true)\n\nfor k, prob in zip(k_values, probabilities):\n    print(f\"Probabilit√† di {k} eventi: {prob:.4f}\")\n\nProbabilit√† di 0 eventi: 0.1353\nProbabilit√† di 1 eventi: 0.2707\nProbabilit√† di 2 eventi: 0.2707\nProbabilit√† di 3 eventi: 0.1804\nProbabilit√† di 4 eventi: 0.0902\nProbabilit√† di 5 eventi: 0.0361\nProbabilit√† di 6 eventi: 0.0120\nProbabilit√† di 7 eventi: 0.0034\nProbabilit√† di 8 eventi: 0.0009\nProbabilit√† di 9 eventi: 0.0002\n\n\nPer un vettore \\(y = (y_1, \\dots, y_n)\\) di osservazioni indipendenti e identicamente distribuite, la verosimiglianza diventa:\n\\[\nf(y|\\lambda)=\\prod_{i=1}^{n} \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!}\n=\\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^{n}y_i!}.\n\\]\n\n\n40.2.2 Distribuzione Gamma\nPrima di affrontare il modello coniugato gamma-poisson, √® utile rivedere brevemente la distribuzione Gamma‚Äîconsultare la sezione Capitolo 30 per maggiori dettagli. La funzione di densit√† della distribuzione Gamma √® definita come:\n\\[ f(x | \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x}, \\]\ndove:\n\n\\(\\alpha\\) determina la forma generale della curva di distribuzione. Con un valore basso di \\(\\alpha\\), la distribuzione √® fortemente inclinata verso valori bassi di \\(x\\) con una lunga coda che si estende verso valori pi√π alti. Man mano che \\(\\alpha\\) aumenta, la curva si sposta verso destra e diventa pi√π simmetrica.\n\\(\\beta\\) controlla quanto ampiamente i valori di \\(x\\) sono distribuiti lungo l‚Äôasse orizzontale. Un alto valore di \\(\\beta\\) comporta una distribuzione che decresce rapidamente, indicando una maggiore concentrazione di massa vicino all‚Äôorigine.\n\n√à importante notare che Scipy utilizza una parametrizzazione leggermente diversa della distribuzione Gamma:\n\nParametro di forma: equivalente a \\(\\alpha\\) come discusso sopra;\nParametro di scala: indicato come scale, che corrisponde al reciproco del parametro \\(\\beta\\) nella formula precedente.\n\nPertanto, per calcolare la densit√† di probabilit√† in scipy.stats, utilizzeremo:\nstats.gamma.pdf(x, a=alpha, scale=1/beta)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_poisson_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/07_poisson_model.html#metodo-basato-su-griglia",
    "title": "40¬† Modello di Poisson",
    "section": "40.3 Metodo Basato su Griglia",
    "text": "40.3 Metodo Basato su Griglia\nSupponiamo di avere osservato i seguenti dati.\n\ny = np.array([2, 1, 3, 2, 2, 1, 1, 1])\n\nPer questi dati, imponiamo una distribuzione Gamma quale distribuzione a priori per il parametro \\(\\lambda\\) della distribuzione di Poisson.\n\nalpha_prior = 9\nbeta_prior = 2\n\nx = np.linspace(start=0, stop=10, num=300)\n\nplt.plot(x, stats.gamma.pdf(x, a=alpha_prior, scale=1 / beta_prior))\nplt.axvline(x=alpha_prior / beta_prior, linestyle=\"--\", label=\"gamma mean\")\nplt.axvline(x=y.mean(), linestyle=\"--\", color=\"C2\", label=\"sample mean\")\nplt.legend()\nplt.title(f\"Gamma Density Function for a={9} and b={2}\")\nplt.show()\n\n\n\n\n\n\n\n\nPoniamoci l‚Äôobiettivo di usare il metodo basato su griglia per derivare la distribuzione a posteriori per il parametro \\(\\lambda\\) della distribuzione di Poisson. Iniziamo con la creazione della griglia per \\(\\lambda\\) nell‚Äôintervallo [0.01, 10].\n\n# Evita zero per evitare divisione per zero\nlambda_grid = np.linspace(0.01, 10, 1000)\n  \nlen(lambda_grid)\n\n1000\n\n\nCalcoliamo la distribuzione a priori.\n\nprior = stats.gamma.pdf(lambda_grid, a=alpha_prior, scale=1 / beta_prior)\n\nlen(prior)\n\n1000\n\n\nCalcoliamo la verosimiglianza per ciascun valore di lambda.\n\nlikelihood = np.ones_like(lambda_grid)\nfor yi in y:\n    likelihood *= stats.poisson.pmf(yi, lambda_grid)\n    \nlen(likelihood)\n\n1000\n\n\nCalcoliamo la distribuzione a posteriori non normalizzata.\n\nposterior_unnormalized = likelihood * prior\n\nNormalizziamo la distribuzione a posteriori.\n\nposterior = posterior_unnormalized / np.sum(\n    posterior_unnormalized * (lambda_grid[1] - lambda_grid[0])\n)\n\nlen(posterior)\n\n1000\n\n\nVisualizzazione dei risultati.\n\nplt.plot(lambda_grid, posterior, label=\"Distribuzione a Posteriori\")\nplt.plot(lambda_grid, prior, \"--\", label=\"Distribuzione a Priori\")\nplt.xlabel(r\"$\\lambda$\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.legend()\nplt.title(\"Distribuzione a Posteriori di $\\lambda$\")\nplt.show()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/07_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "40¬† Modello di Poisson",
    "section": "40.4 Modello Coniugato Gamma-Poission",
    "text": "40.4 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson √® coniugato, il che significa che la distribuzione a posteriori sar√† ancora una distribuzione Gamma.\nPartiamo dal teorema di Bayes:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) √® la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) √® la verosimiglianza, e \\(f(\\lambda)\\) √® la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa √® la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori √® una Gamma con parametri:\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\\(\\sum_{i=1}^n y_i\\) √® la somma di tutte le osservazioni,\n\\(n\\) √® il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l‚Äôinformazione dai dati osservati.\nUtilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori.\n\n# Aggiornamento dei parametri per la distribuzione a posteriori\nalpha_post = alpha_prior + np.sum(y)\nbeta_post = beta_prior + len(y)\n\n# Calcolo della distribuzione a posteriori analitica sulla griglia\nposterior_analytic = stats.gamma.pdf(lambda_grid, a=alpha_post, scale=1 / beta_post)\n\n# Plot della distribuzione a posteriori analitica\nplt.plot(lambda_grid, posterior_analytic)\nplt.title(\"Distribuzione a Posteriori Gamma-Poisson Analitica\")\nplt.xlabel(\"$\\lambda$\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.show()\n\n\n\n\n\n\n\n\nQuesto grafico visualizza la distribuzione a posteriori analitica per il parametro \\(\\lambda\\) del modello Poisson, usando una distribuzione a priori Gamma e i dati osservati. La distribuzione a posteriori √® calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), rappresentando la nostra conoscenza aggiornata dopo aver visto i dati. Il risultato replica quello ottenuto mediante simulazione numerica.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\).\n\n# Posterior gamma parameters.\nshape = alpha_prior + y.sum()\nrate = beta_prior + y.size\n\n# Posterior mean.\nprint(f\"Posterior Mean = {shape / rate: 0.3f}\")\n\nPosterior Mean =  2.200\n\n\nSapendo che la distribuzione a posteriori √® una Gamma di parametri\n\nprint(f\"shape = {shape: 0.1f}\")\nprint(f\"rate = {rate: 0.1f}\")\n\nshape =  22.0\nrate =  10.0\n\n\npossiamo calcolare la probabilit√† di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilit√† di osservare pi√π di 3 compulsioni per ora:\n\n# Calcolo della probabilit√† che y &gt; 3\nprob_y_greater_than_3 = 1 - stats.gamma.cdf(3, a=shape, scale=1/rate)\n\nprint(\n    f\"La probabilit√† di osservare pi√π di 3 compulsioni per ora √® {prob_y_greater_than_3: 0.3f}\"\n)\n\nLa probabilit√† di osservare pi√π di 3 complsioni per ora √®  0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_poisson_model.html#considerazioni-conclusive",
    "href": "chapters/bayesian_inference/07_poisson_model.html#considerazioni-conclusive",
    "title": "40¬† Modello di Poisson",
    "section": "40.5 Considerazioni Conclusive",
    "text": "40.5 Considerazioni Conclusive\nIn questo capitolo, abbiamo esplorato il modello di Poisson nel contesto dell‚Äôinferenza bayesiana. Il modello gamma-poisson √® particolarmente utile in psicologia per modellare fenomeni come la frequenza di sintomi, comportamenti o eventi in un determinato periodo. La comprensione di questo modello consente ai ricercatori e ai clinici di fare inferenze accurate e di prendere decisioni basate su solide basi statistiche.\nL‚Äôapproccio bayesiano offre il vantaggio di incorporare conoscenze pregresse (attraverso la distribuzione a priori) e di aggiornare queste conoscenze alla luce di nuovi dati. Questo √® particolarmente prezioso in contesti clinici, dove le informazioni precedenti possono essere combinate con nuove osservazioni per ottenere stime pi√π precise e affidabili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/07_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "40¬† Modello di Poisson",
    "section": "40.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "40.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npymc      : 5.15.0\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>¬† <span class='chapter-title'>Modello di Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_exponential_model.html",
    "href": "chapters/bayesian_inference/08_exponential_model.html",
    "title": "41¬† Modello Esponenziale",
    "section": "",
    "text": "41.1 Introduzione\nNel contesto dell‚Äôinferenza bayesiana, il caso coniugato Gamma-Esponenziale rappresenta un potente strumento per modellare fenomeni che seguono una distribuzione esponenziale. La distribuzione esponenziale √® spesso utilizzata per modellare il tempo tra eventi successivi in un processo che avviene a un tasso costante, come il tempo di attesa tra gli arrivi in una coda o la durata di certi eventi psicologici.\nAd esempio, in psicologia, possiamo utilizzare la distribuzione esponenziale per modellare la durata degli episodi di ansia o il tempo trascorso prima che un individuo manifesti un certo comportamento in risposta a uno stimolo. Supponiamo di osservare i tempi in cui diversi pazienti sperimentano episodi di disagio psicologico dopo un evento stressante. Questi tempi possono essere modellati utilizzando una distribuzione esponenziale, in cui il parametro \\(\\lambda\\) rappresenta il tasso con cui si verifica il disagio.\nLa verosimiglianza esponenziale per un campione di osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\), che rappresentano, ad esempio, i tempi di attesa fino a un episodio di disagio psicologico, √® data da:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nIn questo modello, \\(\\lambda\\) √® il parametro che controlla il tasso medio di occorrenza degli eventi (ad esempio, episodi di disagio). Poich√© spesso non conosciamo il valore di \\(\\lambda\\) a priori, possiamo utilizzare un approccio bayesiano per stimare \\(\\lambda\\), assumendo una distribuzione a priori su \\(\\lambda\\). Una scelta comune per la distribuzione a priori in questo contesto √® la distribuzione Gamma, che √® coniugata rispetto alla distribuzione esponenziale.\nQuando si assume una distribuzione Gamma come prior su \\(\\lambda\\), la distribuzione a posteriori di \\(\\lambda\\), dopo aver osservato i dati, sar√† anch‚Äôessa una distribuzione Gamma con parametri aggiornati. Questo aggiornamento incorpora le informazioni provenienti dai dati osservati, fornendo una stima pi√π precisa del tasso di occorrenza degli eventi psicologici osservati.\nAd esempio, dopo aver osservato i tempi di manifestazione del disagio psicologico in un gruppo di pazienti, possiamo aggiornare la nostra credenza su \\(\\lambda\\) e successivamente fare previsioni sui tempi futuri di occorrenza o valutare la probabilit√† di eventi specifici, come il verificarsi di un episodio severo di disagio psicologico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Modello Esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_exponential_model.html#distribuzione-esponenziale",
    "href": "chapters/bayesian_inference/08_exponential_model.html#distribuzione-esponenziale",
    "title": "41¬† Modello Esponenziale",
    "section": "41.2 Distribuzione Esponenziale",
    "text": "41.2 Distribuzione Esponenziale\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(X_1, X_2, \\dots, X_n\\) che seguono una distribuzione esponenziale con parametro \\(\\lambda\\) (dove \\(\\lambda &gt; 0\\)) √® data dal prodotto delle densit√† di probabilit√† delle osservazioni.\nLa funzione di densit√† di probabilit√† (pdf) di una distribuzione esponenziale √®:\n\\[\nf(x \\mid \\lambda) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0.\n\\]\nSupponiamo di avere un campione di \\(n\\) osservazioni indipendenti \\(X_1, X_2, \\dots, X_n\\). La funzione di verosimiglianza \\(L(\\lambda)\\) per questo campione √® il prodotto delle pdf per tutte le osservazioni:\n\\[\nL(\\lambda \\mid X_1, X_2, \\dots, X_n) = \\prod_{i=1}^{n} f(X_i \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda X_i}.\n\\]\nSviluppando il prodotto, otteniamo:\n\\[\nL(\\lambda \\mid X_1, X_2, \\dots, X_n) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} X_i}.\n\\]\nQuesta √® la funzione di verosimiglianza per il parametro \\(\\lambda\\) dato il campione \\(X_1, X_2, \\dots, X_n\\).\nPer ottenere il logaritmo della funzione di verosimiglianza, che spesso √® pi√π facile da manipolare, calcoliamo:\n\\[\n\\log L(\\lambda \\mid X_1, X_2, \\dots, X_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} X_i.\n\\]\nLa distribuzione esponenziale ha media pari a \\(1/\\lambda\\) e varianza \\(1/\\lambda^2\\).\n\n41.2.1 Dati\nSimuliamo un campione di dati.\n\n# Imposta il seed per rendere i risultati riproducibili\nnp.random.seed(42)\n\n# Parametro lambda per la distribuzione esponenziale\nmean = 3.0\nlambda_param = 1 / mean\n\n# Numero di osservazioni nel campione\nn = 15\n\n# Generazione del campione casuale\n\ny = np.random.exponential(scale=mean, size=n).round()\nprint(y)\n\n[ 1.  9.  4.  3.  1.  1.  0.  6.  3.  4.  0. 11.  5.  1.  1.]\n\n\nImmaginiamo che questi dati corrispondano al punteggio totale della scala psicologica di Kessler (K6) di 14 individui ‚Äì si veda il Capitolo 30. La media del campione √®\n\nnp.mean(y)\n\n\n\n41.2.2 Passi per definire un prior debolmente informativo\nImponiamo una distribuzione Gamma quale distribuzione a priori per il parametro \\(\\lambda\\) della distribuzione di Poisson.\nUn prior debolmente informativo √® progettato per avere un‚Äôinfluenza minima sull‚Äôinferenza, lasciando che i dati osservati guidino principalmente le stime. In generale, per una distribuzione Gamma, un prior debolmente informativo potrebbe essere scelto in modo da avere una varianza ampia e una media che non sia troppo specifica.\n\nStima preliminare di \\(\\lambda\\): Prima di definire il prior, possiamo calcolare una stima preliminare di \\(\\lambda\\) usando la media campionaria dei dati, dato che per una distribuzione esponenziale \\(\\text{E}[y] = \\frac{1}{\\lambda}\\).\n\\[\n\\hat{\\lambda} = \\frac{1}{\\text{media campionaria}}\n\\]\nCalcolo della media campionaria: La media campionaria dei dati √® \\(\\approx 3.33\\). Quindi, una stima preliminare di \\(\\lambda\\) √®:\n\\[\n\\hat{\\lambda} = \\frac{1}{3.33} \\approx 0.3\n\\]\nDefinizione del prior Gamma: Un prior debolmente informativo potrebbe avere una media simile a \\(\\hat{\\lambda}\\) ma con una varianza ampia, in modo da non essere troppo restrittivo.\nSupponiamo di voler impostare il prior con una media pari a 0.3 (come la stima preliminare di \\(\\lambda\\)) e una varianza molto ampia, ad esempio 10.\nLe equazioni per la media e la varianza di una distribuzione Gamma sono:\n\\[\n\\text{E}[\\lambda] = \\frac{\\alpha_{\\text{prior}}}{\\beta_{\\text{prior}}}\n\\]\n\\[\n\\text{Var}[\\lambda] = \\frac{\\alpha_{\\text{prior}}}{\\beta_{\\text{prior}}^2}\n\\]\nRisolvendo per \\(\\alpha_{\\text{prior}}\\) e \\(\\beta_{\\text{prior}}\\), otteniamo:\n\\[\n\\beta_{\\text{prior}} = \\frac{\\alpha_{\\text{prior}}}{\\text{E}[\\lambda]} = \\frac{\\alpha_{\\text{prior}}}{0.3}\n\\]\n\\[\n\\text{Var}[\\lambda] = \\frac{0.3 \\cdot \\beta_{\\text{prior}}}{\\beta_{\\text{prior}}^2} = \\frac{0.3}{\\beta_{\\text{prior}}} = 10\n\\]\nDa cui:\n\\[\n\\beta_{\\text{prior}} = \\frac{0.3}{10} = 0.03\n\\]\nInfine, usiamo \\(\\beta_{\\text{prior}} = 0.03\\) per trovare \\(\\alpha_{\\text{prior}}\\):\n\\[\n\\alpha_{\\text{prior}} = 0.3 \\cdot \\beta_{\\text{prior}} = 0.3 \\cdot 0.03 = 0.009\n\\]\n\nUn prior Gamma debolmente informativo per questi dati potrebbe essere definito con i seguenti parametri:\n\n\\(\\alpha_{\\text{prior}} = 0.009\\),\n\\(\\beta_{\\text{prior}} = 0.03\\).\n\nQuesto prior riflette una convinzione a priori debolmente informativa, con una media vicina alla stima preliminare di \\(\\lambda\\) e una varianza sufficientemente ampia da permettere ai dati di dominare l‚Äôinferenza.\n\nalpha_prior = 0.009\nbeta_prior = 0.03\n\nx = np.linspace(start=0, stop=10, num=300)\n\nplt.plot(x, stats.gamma.pdf(x, a=alpha_prior, scale=1 / beta_prior))\nplt.axvline(x=alpha_prior / beta_prior, linestyle=\"--\", label=\"gamma mean\")\nplt.axvline(x=y.mean(), linestyle=\"--\", color=\"C2\", label=\"sample mean\")\nplt.legend()\nplt.title(f\"Gamma Density Function for alpha_prior={0.009} and beta_prior={0.03}\")\nplt.show()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Modello Esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/08_exponential_model.html#metodo-basato-su-griglia",
    "title": "41¬† Modello Esponenziale",
    "section": "41.3 Metodo Basato su Griglia",
    "text": "41.3 Metodo Basato su Griglia\nPoniamoci l‚Äôobiettivo di usare il metodo basato su griglia per derivare la distribuzione a posteriori per il parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo con la creazione della griglia per \\(\\lambda\\) nell‚Äôintervallo [0.01, 10].\n\n# Evita zero per evitare divisione per zero\nlambda_grid = np.linspace(0.01, 10, 1000)\n\nCalcoliamo la distribuzione a priori.\n\nprior = stats.gamma.pdf(lambda_grid, a=alpha_prior, scale=1 / beta_prior)\n\nCalcoliamo la verosimiglianza per ciascun valore di lambda.\n\nlikelihood = np.ones_like(lambda_grid)\nfor yi in y:\n    likelihood *= stats.expon.pdf(yi, scale=1 / lambda_grid)\n\nCalcoliamo la distribuzione a posteriori non normalizzata.\n\nposterior_unnormalized = likelihood * prior\n\nNormalizziamo la distribuzione a posteriori.\n\nposterior = posterior_unnormalized / np.sum(\n    posterior_unnormalized * (lambda_grid[1] - lambda_grid[0])\n)\n\nVisualizzazione dei risultati.\n\nplt.plot(lambda_grid, posterior, label=\"Distribuzione a Posteriori\")\nplt.plot(lambda_grid, prior, \"--\", label=\"Distribuzione a Priori\")\nplt.xlabel(r\"$\\lambda$\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.legend()\nplt.title(\"Distribuzione a Posteriori di $\\lambda$\")\nplt.show()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Modello Esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/08_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "41¬† Modello Esponenziale",
    "section": "41.4 Modello Coniugato Gamma-Esponenziale",
    "text": "41.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch‚Äôessa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sar√† ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri √® una conseguenza della propriet√† coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n41.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) √® la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) √® la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) √® la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), √® data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l‚Äôinformazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla propriet√† coniugata.\nPer il caso dell‚Äôesempio in discussione,\n\nil numero di osservazioni nel campione \\(n\\) √® 15;\nla somma delle osservazioni del campione √®:\n\n\\[\n\\sum_{i=1}^{n} y_i = 1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50\n\\]\nI parametri aggiornati della distribuzione a posteriori sono:\n\\[\n\\alpha_{\\text{post}} = 15 + 0.009 = 15.009.\n\\]\n\\[\n\\beta_{\\text{post}} = 50 + 0.03 = 50.03.\n\\]\nUtilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori.\n\n# Aggiornamento dei parametri per la distribuzione a posteriori\nalpha_post = alpha_prior + len(y)\nbeta_post = beta_prior + np.sum(y)\n\nprint(f\"alpha_post = {alpha_post}; beta_post = {beta_post:.4f}\")\n\nalpha_post = 15.009; beta_post = 50.0300\n\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) √®:\n\\[\np(\\lambda \\mid y) \\sim \\text{Gamma}(15.009, 50.03).\n\\]\n\n# Parametri della distribuzione Gamma a posteriori\nalpha_post = 15.009\nbeta_post = 50.03\n\n# Griglia di valori di lambda per il plot\nlambda_grid = np.linspace(0, 0.6, 1000)\n\n# Calcolo della distribuzione Gamma a posteriori\nposterior_pdf = stats.gamma.pdf(lambda_grid, a=alpha_post, scale=1 / beta_post)\n\n# Plot della distribuzione a posteriori\nplt.figure(figsize=(8, 5))\nplt.plot(\n    lambda_grid,\n    posterior_pdf,\n    label=r\"$\\Gamma(\\alpha_{\\text{post}}=15.009, \\beta_{\\text{post}} = 50.03)$\",\n)\nplt.xlabel(r\"$\\lambda$\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.title(\"Distribuzione Gamma a Posteriori\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto grafico visualizza la distribuzione a posteriori analitica per il parametro \\(\\lambda\\) del modello gamma-esponenziale. Il risultato replica quello ottenuto mediante simulazione numerica.\nQuesta distribuzione Gamma a posteriori riflette l‚Äôinformazione combinata proveniente sia dal prior che dai dati osservati. Con \\(\\alpha_{\\text{posteriori}} = 15.009\\) e \\(\\beta_{\\text{posteriori}} = 50.03\\), la distribuzione a posteriori di \\(\\lambda\\) sar√† centrata attorno alla media:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{posteriori}}}{\\beta_{\\text{posteriori}}} \\approx \\frac{15.009}{50.03} \\approx 0.3\n\\]\ne con varianza:\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{posteriori}}}{\\beta_{\\text{posteriori}}^2} \\approx \\frac{15.009}{50.03^2} \\approx 0.006\n\\]\nLa distribuzione a posteriori sar√† pi√π concentrata rispetto al prior, poich√© incorpora l‚Äôinformazione aggiuntiva proveniente dai dati osservati.\n\n\n41.4.2 Applicazioni\nPossiamo ora rispondere a domande riguardanti la probabilit√† che una nuova osservazione \\(y\\) assuma determinati valori. Nel caso dell‚Äôesempio, ad esempio ci possiamo chiedere quale sia la probabilit√† degli eventi \\(y &gt; 5\\) (disagio psicologico lieve) o \\(y &gt; 13\\) (disagio psicologico severo). Utilizzando la distribuzione a posteriori di \\(\\lambda\\), possiamo procedere calcolando le probabilit√† richieste utilizzando simulazioni Monte Carlo.\nPer il caso della probabilit√† che \\(y \\geq 5\\),\n\nGeneriamo un campione di valori di \\(\\lambda\\) dalla distribuzione a posteriori \\(\\lambda \\sim \\text{Gamma}(15.009, 50.03)\\).\nGeneriamo un campione di valori di \\(y\\) per ciascun \\(\\lambda\\) dalla distribuzione esponenziale \\(y \\sim \\text{Expon}(\\lambda)\\).\nCalcoliamo la proporzione di valori di \\(y\\) che sono maggiori o uguali a 5.\n\n\n# Numero di simulazioni\nn_sim = 10000\n\n# Generazione di un campione di lambda dalla distribuzione a posteriori\nlambda_samples = stats.gamma.rvs(a=alpha_post, scale=1 / beta_post, size=n_sim)\n\n# Generazione di un campione di y dalla distribuzione esponenziale per ciascun lambda\ny_samples = stats.expon.rvs(scale=1 / lambda_samples, size=n_sim)\n\n# Calcolo della probabilit√† che y &gt;= 5\nprob_y_ge_5 = np.mean(y_samples &gt;= 5)\nprint(f\"Probabilit√† che y &gt;= 5: {prob_y_ge_5:.4f}\")\n\n# Calcolo della probabilit√† che y &gt; 13\nprob_y_gt_13 = np.mean(y_samples &gt; 13)\nprint(f\"Probabilit√† che y &gt; 13: {prob_y_gt_13:.4f}\")\n\nProbabilit√† che y &gt;= 5: 0.2322\nProbabilit√† che y &gt; 13: 0.0317\n\n\n\nProbabilit√† che \\(y \\geq 5\\): Questo valore rappresenta la probabilit√† che un nuovo individuo abbia un disagio psicologico almeno moderato (definito come \\(y \\geq 5\\)).\nProbabilit√† che \\(y &gt; 13\\): Questo valore rappresenta la probabilit√† che un nuovo individuo abbia un disagio psicologico severo (definito come \\(y &gt; 13\\)).\n\nLa probabilit√† del 23.22% di osservare un punteggio di 5 o superiore sulla scala K6 suggerisce che circa un quarto degli individui potrebbe sperimentare un livello di disagio psicologico almeno moderato. La probabilit√† del 3.17% di osservare un punteggio superiore a 13 indica che una piccola ma significativa percentuale di individui potrebbe sperimentare un disagio psicologico severo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Modello Esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_exponential_model.html#considerazioni-conclusive",
    "href": "chapters/bayesian_inference/08_exponential_model.html#considerazioni-conclusive",
    "title": "41¬† Modello Esponenziale",
    "section": "41.5 Considerazioni Conclusive",
    "text": "41.5 Considerazioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, particolarmente adatto per modellare fenomeni caratterizzati da tempi di attesa o durate di eventi. La sua applicazione spazia dall‚Äôanalisi dei tempi di reazione agli studi sulla durata degli episodi di ansia o depressione, fornendo preziose intuizioni sui processi psicologici sottostanti.\nL‚Äôapproccio bayesiano all‚Äôinferenza con il modello esponenziale offre diversi vantaggi:\n\nFlessibilit√† nell‚Äôincorporazione di conoscenze pregresse: Attraverso la scelta informata della distribuzione a priori, i ricercatori possono integrare conoscenze esistenti o risultati di studi precedenti, migliorando la robustezza delle inferenze.\nInterpretabilit√† diretta dei risultati: La distribuzione a posteriori fornisce una stima probabilistica completa del parametro di interesse, permettendo ai ricercatori di fare affermazioni dirette sulla probabilit√† di diversi valori del parametro.\nGestione dell‚Äôincertezza: L‚Äôapproccio bayesiano quantifica esplicitamente l‚Äôincertezza nelle stime, fornendo intervalli di credibilit√† che sono pi√π intuitivi e direttamente interpretabili rispetto agli intervalli di confidenza frequentisti.\nFacilit√† di aggiornamento delle conoscenze: Man mano che nuovi dati diventano disponibili, la distribuzione a posteriori pu√≤ essere utilizzata come nuova distribuzione a priori, permettendo un aggiornamento continuo e coerente delle conoscenze.\nRobustezza con campioni piccoli: L‚Äôinferenza bayesiana pu√≤ fornire risultati significativi anche con campioni di dimensioni ridotte, una situazione comune in molti studi psicologici.\n\nIn conclusione, l‚Äôutilizzo del modello esponenziale all‚Äôinterno del framework bayesiano offre agli psicologi un potente strumento per analizzare e interpretare dati relativi a tempi e durate. Questo approccio non solo fornisce stime pi√π ricche e interpretabili dei parametri di interesse, ma permette anche una pi√π naturale integrazione di conoscenze pregresse e una quantificazione esplicita dell‚Äôincertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Modello Esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "41¬† Modello Esponenziale",
    "section": "41.6 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "41.6 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npymc      : 5.15.0\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Modello Esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html",
    "title": "42¬† Distribuzione predittiva a posteriori",
    "section": "",
    "text": "42.1 Introduzione\nIn questo capitolo esploreremo il concetto di distribuzione predittiva a posteriori, concentrandoci sul caso discreto. Per illustrare questo concetto in modo chiaro e intuitivo, utilizzeremo il problema del ‚Äúbag of coins‚Äù come esempio esplicativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#previsioni-su-eventi-futuri",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#previsioni-su-eventi-futuri",
    "title": "42¬† Distribuzione predittiva a posteriori",
    "section": "42.2 Previsioni su Eventi Futuri",
    "text": "42.2 Previsioni su Eventi Futuri\nLa distribuzione predittiva a posteriori √® un concetto chiave nell‚Äôinferenza bayesiana. In parole semplici, rappresenta le probabilit√† degli eventi futuri basate su ci√≤ che abbiamo gi√† osservato. In altre parole, √® come fare previsioni su quello che potrebbe succedere, utilizzando le informazioni raccolte fino a quel momento e le nostre convinzioni aggiornate (a posteriori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#definizione",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#definizione",
    "title": "42¬† Distribuzione predittiva a posteriori",
    "section": "42.3 Definizione",
    "text": "42.3 Definizione\nImmagina di avere un insieme di dati che hai gi√† osservato, chiamato \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\). Supponiamo che questi dati siano stati generati da un modello con un parametro sconosciuto \\(\\theta\\), e che tu abbia una qualche idea iniziale (detta a priori) su quale possa essere il valore di \\(\\theta\\), rappresentata dalla distribuzione \\(p(\\theta)\\).\nDopo aver osservato i dati, possiamo aggiornare la nostra idea iniziale per ottenere una nuova distribuzione per \\(\\theta\\), chiamata distribuzione a posteriori, indicata come \\(p(\\theta | y)\\). Questa distribuzione riflette quello che abbiamo imparato sui parametri del modello dopo aver visto i dati.\nLa formula per la distribuzione a posteriori √®:\n\\[\np(\\theta | y) = \\frac{p(y | \\theta) p(\\theta)}{p(y)},\n\\]\ndove:\n\n\\(p(\\theta | y)\\) √® la distribuzione a posteriori del parametro \\(\\theta\\);\n\\(p(y | \\theta)\\) √® la probabilit√† di osservare i dati dati i parametri, chiamata verosimiglianza;\n\\(p(\\theta)\\) √® la distribuzione a priori del parametro \\(\\theta\\);\n\\(p(y)\\) √® la probabilit√† di osservare quei dati, chiamata anche evidenza.\n\nPer fare previsioni su un nuovo dato \\(\\tilde{y}\\), usiamo la distribuzione predittiva a posteriori. Questa si ottiene combinando tutte le possibili ipotesi sui parametri del modello, pesandole per quanto le riteniamo probabili in base ai dati osservati:\n\\[\np(\\tilde{y} | y) = \\int p(\\tilde{y} | \\theta) p(\\theta | y) \\, d\\theta.\n\\]\nSe il parametro \\(\\theta\\) pu√≤ assumere solo alcuni valori discreti, invece di un integrale si usa una somma:\n\\[\np(\\tilde{y} | y) = \\sum_{\\theta} p(\\tilde{y} | \\theta) p(\\theta | y).\n\\]\nQuesta distribuzione combina la nostra convinzione aggiornata sui parametri \\(\\theta\\) con la probabilit√† di osservare un nuovo dato \\(\\tilde{y}\\), dato un certo valore di \\(\\theta\\). In questo modo, possiamo fare previsioni considerando tutte le incertezze che abbiamo sui parametri del modello.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#il-sacchetto-di-monete",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#il-sacchetto-di-monete",
    "title": "42¬† Distribuzione predittiva a posteriori",
    "section": "42.4 Il Sacchetto di Monete",
    "text": "42.4 Il Sacchetto di Monete\nIn questo esempio discutiamo un problema che consente di presentare il concetto di distribuzione predittiva a posteriori in un modo intuivito. Immaginiamo di avere un sacchetto contenente tre tipi diversi di monete. Questi tre tipi di monete hanno caratteristiche uniche riguardo la probabilit√† di ottenere ‚Äútesta‚Äù o ‚Äúcroce‚Äù quando vengono lanciate:\n\nMoneta di Tipo 0: Questa moneta d√† sempre ‚Äúcroce‚Äù. La probabilit√† di ottenere ‚Äútesta‚Äù √® 0.\nMoneta di Tipo 1: Questa √® una moneta equa. La probabilit√† di ottenere ‚Äútesta‚Äù √® 0.5, e quindi anche la probabilit√† di ottenere ‚Äúcroce‚Äù √® 0.5.\nMoneta di Tipo 2: Questa moneta d√† sempre ‚Äútesta‚Äù. La probabilit√† di ottenere ‚Äútesta‚Äù √® 1.\n\nSupponiamo di scegliere una moneta a caso dal sacchetto e di lanciarla quattro volte. In tutte e quattro le volte otteniamo ‚Äúcroce‚Äù. Ora vogliamo calcolare la probabilit√† di ottenere ‚Äúcroce‚Äù al quinto lancio.\n\n42.4.1 Passo 1: Probabilit√† Iniziali\nPrima di lanciare la moneta, non sappiamo quale tipo di moneta abbiamo estratto dal sacchetto. Poich√© ogni moneta ha la stessa probabilit√† di essere scelta, attribuiamo una probabilit√† iniziale (prior) uguale a ciascun tipo di moneta:\n\nProbabilit√† di avere la Moneta di Tipo 0: \\(\\frac{1}{3}\\).\nProbabilit√† di avere la Moneta di Tipo 1: \\(\\frac{1}{3}\\).\nProbabilit√† di avere la Moneta di Tipo 2: \\(\\frac{1}{3}\\).\n\n\n\n42.4.2 Passo 2: Osservare i Risultati e Aggiornare le Probabilit√†\nDopo aver osservato quattro lanci che hanno dato tutti ‚Äúcroce‚Äù, possiamo aggiornare le nostre probabilit√† di avere un certo tipo di moneta utilizzando queste informazioni.\n\nMoneta di Tipo 0: Se avessimo questa moneta, ottenere ‚Äúcroce‚Äù in tutti i lanci √® ci√≤ che ci aspetteremmo, dato che d√† sempre ‚Äúcroce‚Äù.\nMoneta di Tipo 1: Con questa moneta, ottenere quattro ‚Äúcroce‚Äù di fila √® possibile ma piuttosto improbabile, dato che la probabilit√† di ‚Äúcroce‚Äù in ciascun lancio √® solo 0.5.\nMoneta di Tipo 2: Con questa moneta, ottenere ‚Äúcroce‚Äù √® impossibile perch√© d√† sempre ‚Äútesta‚Äù.\n\nBasandoci su queste osservazioni, √® molto pi√π probabile che la moneta scelta sia di Tipo 0. La probabilit√† di avere la Moneta di Tipo 1 √® bassa, mentre la probabilit√† di avere la Moneta di Tipo 2 √® zero.\n\n\n42.4.3 Passo 3: Calcolare le Probabilit√† Posteriori\nPer calcolare le nuove probabilit√† (posteriori) per ogni tipo di moneta dopo aver visto quattro ‚Äúcroce‚Äù, utilizziamo la formula di Bayes. Supponiamo che \\(D\\) rappresenti il dato ‚Äúcroce, croce, croce, croce‚Äù. Dopo i calcoli (che qui non dettagliamo, ma che presenteremo in seguito), otteniamo le seguenti probabilit√† posteriori:\n\nProbabilit√† a posteriori di avere la Moneta di Tipo 0: circa 0.941.\nProbabilit√† a posteriori di avere la Moneta di Tipo 1: circa 0.059.\nProbabilit√† a posteriori di avere la Moneta di Tipo 2: 0.\n\n\n\n42.4.4 Passo 4: Predire il Risultato del Quinto Lancio\nPer prevedere la probabilit√† di ottenere ‚Äúcroce‚Äù al quinto lancio, combiniamo le probabilit√† posteriori di ogni tipo di moneta con la probabilit√† di ottenere ‚Äúcroce‚Äù specifica a ciascun tipo:\n\nMoneta di Tipo 0: Probabilit√† di ‚Äúcroce‚Äù = 1.\nMoneta di Tipo 1: Probabilit√† di ‚Äúcroce‚Äù = 0.5.\nMoneta di Tipo 2: Probabilit√† di ‚Äúcroce‚Äù = 0.\n\nCalcoliamo ora la probabilit√† totale di ottenere ‚Äúcroce‚Äù al quinto lancio:\n\nContributo della Moneta di Tipo 0: \\(0.941 \\times 1 = 0.941\\).\nContributo della Moneta di Tipo 1: \\(0.059 \\times 0.5 = 0.0295\\).\nContributo della Moneta di Tipo 2: \\(0 \\times 0 = 0\\).\n\nSommando queste probabilit√†:\n\\[\n0.941 + 0.0295 + 0 = 0.9705.\n\\]\nNel seguito considereremo come svolgere tutti i calcoli.\n\nEsempio 42.1 Iniziamo con una distribuzione a priori uniforme per ciascun tipo di moneta, poich√© inizialmente non sappiamo quale sia stata scelta:\n\\[\nP(X = 0) = P(X = 1) = P(X = 2) = \\frac{1}{3}.\n\\]\nDopo aver osservato una sequenza di lanci, ad esempio quattro ‚Äúcroce‚Äù (0, 0, 0, 0), possiamo aggiornare le nostre credenze sulla base dei dati.\nCalcoliamo la distribuzione a posteriori per ciascun tipo di moneta dopo aver osservato i risultati dei lanci.\nVerosimiglianza per ciascun tipo di moneta:\n\nMoneta tipo 0: Poich√© d√† sempre ‚Äúcroce‚Äù, la verosimiglianza di osservare quattro ‚Äúcroce‚Äù √® \\(P(D | X = 0) = 1\\).\nMoneta tipo 1: Poich√© √® equa, la verosimiglianza di osservare quattro ‚Äúcroce‚Äù √® \\(P(D | X = 1) = (0.5)^4 = 0.0625\\).\nMoneta tipo 2: Poich√© d√† sempre ‚Äútesta‚Äù, la verosimiglianza di osservare quattro ‚Äúcroce‚Äù √® \\(P(D | X = 2) = 0\\).\n\nCalcolo della distribuzione a posteriori per ciascun tipo di moneta:\n\\[\nP(X = 0 | D) = \\frac{P(D | X = 0)P(X = 0)}{P(D)},\n\\]\n\\[\nP(X = 1 | D) = \\frac{P(D | X = 1)P(X = 1)}{P(D)},\n\\]\n\\[\nP(X = 2 | D) = \\frac{P(D | X = 2)P(X = 2)}{P(D)},\n\\]\ndove \\(P(D) = P(D | X = 0)P(X = 0) + P(D | X = 1)P(X = 1) + P(D | X = 2)P(X = 2)\\).\nSostituendo i valori:\n\\[\nP(D) = \\frac{1}{3} \\times 1 + \\frac{1}{3} \\times 0.0625 + \\frac{1}{3} \\times 0 = \\frac{1 + 0.0625}{3} = \\frac{1.0625}{3}.\n\\]\nQuindi, le distribuzioni a posteriori diventano:\n\\[\nP(X = 0 | D) = \\frac{\\frac{1}{3}}{\\frac{1.0625}{3}} = \\frac{1}{1.0625} \\approx 0.941,\n\\]\n\\[\nP(X = 1 | D) = \\frac{\\frac{1}{3} \\times 0.0625}{\\frac{1.0625}{3}} = \\frac{0.0625}{1.0625} \\approx 0.059,\n\\]\n\\[\nP(X = 2 | D) = 0.\n\\]\nOra possiamo calcolare la distribuzione predittiva a posteriori per il prossimo lancio di moneta.\nLa probabilit√† che il prossimo lancio sia ‚Äúcroce‚Äù √® data dalla somma delle probabilit√† ponderate da ciascun tipo di moneta, basate sulle distribuzioni a posteriori:\n\\[\nP(\\text{croce nel prossimo lancio} | D) = P(X = 0 | D) \\times 1 + P(X = 1 | D) \\times 0.5 + P(X = 2 | D) \\times 0.\n\\]\nInserendo i valori calcolati:\n\\[\nP(\\text{croce nel prossimo lancio} | D) = 0.941 \\times 1 + 0.059 \\times 0.5 + 0 \\times 0 = 0.9705.\n\\]\nQuindi, la distribuzione predittiva a posteriori ci dice che, dato che abbiamo osservato quattro ‚Äúcroce‚Äù, la probabilit√† che il prossimo lancio sia ‚Äúcroce‚Äù √® circa \\(0.9705\\).\n\n\n\n42.4.5 Interpretazione\nIn questo esempio, abbiamo utilizzato la distribuzione predittiva a posteriori per fare una stima sulla probabilit√† di ottenere ‚Äúcroce‚Äù al quinto lancio. La distribuzione predittiva a posteriori rappresenta una combinazione delle nostre credenze aggiornate (probabilit√† posteriori) riguardo a quale moneta abbiamo selezionato, basate sui dati osservati (i primi quattro lanci), e le probabilit√† di ottenere ‚Äúcroce‚Äù associate a ciascun tipo di moneta. In altre parole, ci dice qual √® la probabilit√† di un nuovo dato (il quinto lancio che dia ‚Äúcroce‚Äù) tenendo conto delle evidenze raccolte fino a quel punto.\nNel contesto dell‚Äôesempio, la distribuzione predittiva a posteriori √® data dalla combinazione delle probabilit√† posteriori di avere ciascun tipo di moneta con le probabilit√† di ottenere ‚Äúcroce‚Äù con quella moneta. Questa distribuzione ci permette di fare previsioni future (come il risultato del quinto lancio) basandoci sulle informazioni aggiornate dalle osservazioni precedenti. Il risultato finale di 0.9705 rappresenta la probabilit√† di ottenere ‚Äúcroce‚Äù al prossimo lancio, tenendo conto delle evidenze osservate.\nLa distribuzione predittiva a posteriori √® fondamentale nell‚Äôinferenza bayesiana perch√© permette di fare previsioni che considerano tutte le incertezze riguardo ai parametri del modello. Non ci basiamo solo sul valore stimato dei parametri, ma teniamo conto anche della nostra incertezza su questi valori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#considerazioni-conclusive",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#considerazioni-conclusive",
    "title": "42¬† Distribuzione predittiva a posteriori",
    "section": "42.5 Considerazioni Conclusive",
    "text": "42.5 Considerazioni Conclusive\nUtilizzando il modello ‚Äúbag of coins‚Äù, possiamo vedere come le osservazioni passate influenzano le previsioni future attraverso la distribuzione predittiva a posteriori. Questo esempio mostra come, anche con una conoscenza iniziale limitata, possiamo aggiornare le nostre credenze in modo sistematico e fare previsioni ragionevoli basate sui dati raccolti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#esercizi",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#esercizi",
    "title": "42¬† Distribuzione predittiva a posteriori",
    "section": "42.6 Esercizi",
    "text": "42.6 Esercizi\n\nEsercizio 42.1 Utilizzando un set di dati diverso, ovvero tre ‚Äútesta‚Äù seguite da una ‚Äúcroce‚Äù, calcola la distribuzione predittiva a posteriori per il prossimo lancio.\n\n\nEsercizio 42.2 Consideriamo un modello in cui ci sono tre tipi di monete, ognuna con una probabilit√† diversa di dare ‚Äútesta‚Äù o ‚Äúcroce‚Äù:\n\nMoneta di Tipo 0: Questa moneta d√† sempre ‚Äúcroce‚Äù. La probabilit√† di ottenere ‚Äútesta‚Äù √® 0.\nMoneta di Tipo 1: Questa moneta ha una probabilit√† di 0.7 di ottenere ‚Äútesta‚Äù e 0.3 di ottenere ‚Äúcroce‚Äù.\nMoneta di Tipo 2: Questa moneta d√† sempre ‚Äútesta‚Äù. La probabilit√† di ottenere ‚Äútesta‚Äù √® 1.\n\nNel sacchetto ci sono: 2 monete di tipo 0, 1 moneta di tipo 1 e 1 moneta di tipo 2. Supponiamo di osservare la sequenza croce, testa, croce. Vogliamo calcolare la probabilit√† di ottenere ‚Äúcroce‚Äù al quarto lancio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "42¬† Distribuzione predittiva a posteriori",
    "section": "42.7 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "42.7 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npymc      : 5.15.0\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>¬† <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all‚Äôalgoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non √® possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l‚Äôinferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l‚Äôanalisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "",
    "text": "Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana relativi alla distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche discusso l‚Äôutilizzo di approcci come l‚Äôapprossimazione tramite griglia e i metodi dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione e spiegheremo perch√© sono necessari approcci speciali noti come metodi di Monte Carlo a Catena di Markov (MCMC).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.1 Il denominatore bayesiano",
    "text": "43.1 Il denominatore bayesiano\nNell‚Äôapproccio bayesiano, il nostro obiettivo principale √® determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando sia i dati osservati $ y $ che la distribuzione a priori \\(p(\\theta)\\). Questo processo si basa sul teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIn questa formula, il denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta l‚Äôintegrazione (o la somma, nel caso di variabili discrete) su tutti i possibili valori di \\(\\theta\\), fornendo cos√¨ la probabilit√† marginale di \\(y\\). Questo assicura che $ p(y) $ sia una distribuzione di probabilit√† valida che si integra (o si somma) a 1.\nTuttavia, spesso incontriamo una sfida significativa: il calcolo dell‚Äôevidenza \\(p(y) = \\int p(y \\mid \\theta) p(\\theta) d\\theta\\) pu√≤ essere estremamente complesso, specialmente per modelli pi√π articolati, rendendo difficile ottenere con precisione la distribuzione a posteriori.\nUna soluzione possibile √® rappresentata dalle distribuzioni a priori coniugate, che offrono un metodo analitico per determinare la distribuzione a posteriori. Tuttavia, questo limita la selezione delle distribuzioni a priori e di verosimiglianza.\nUn metodo per superare questa limitazione √® ricorrere a soluzioni numeriche, ma i metodi di campionamento a griglia sono applicabili solo nel caso di modelli con un numero di parametri molto piccolo.\nLa soluzione generale √® utilizzare i Metodi di Monte Carlo a Catena di Markov (MCMC). Questi metodi consentono di derivare la distribuzione a posteriori basandosi su presupposti teorici e senza restrizioni nella scelta delle distribuzioni. L‚Äôapproccio Monte Carlo si basa sulla generazione di sequenze di numeri casuali per creare un ampio campione di osservazioni dalla distribuzione a posteriori. Da questi campioni, possiamo poi stimare empiricamente le propriet√† di interesse. Questo approccio richiede l‚Äôuso di metodi computazionalmente intensivi e, con la crescente potenza di calcolo dei computer moderni, tali metodi stanno diventando sempre pi√π accessibili e popolari nell‚Äôanalisi dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-metodo-di-monte-carlo",
    "href": "chapters/mcmc/01_metropolis.html#il-metodo-di-monte-carlo",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.2 Il Metodo di Monte Carlo",
    "text": "43.2 Il Metodo di Monte Carlo\nNei capitoli precedenti abbiamo gi√† esplorato l‚Äôefficacia della simulazione nel campo della teoria delle probabilit√†. Un esempio classico √® il problema di Monty Hall, che mostra come la simulazione ripetuta possa fornire stime affidabili per la media e la varianza di variabili casuali. Inoltre, applicando la legge dei grandi numeri, queste stime diventano pi√π accurate all‚Äôaumentare del numero di simulazioni. Ci√≤ evidenzia la potenza dei metodi Monte Carlo, che evitano la necessit√† di calcolare integrali complessi.\nIl Metodo di Monte Carlo, sviluppato durante il Progetto Manhattan negli anni ‚Äô40, utilizza numeri casuali per risolvere problemi matematici complessi. Originariamente ideato da Stanislaw Ulam e successivamente implementato da John von Neumann, il metodo prende il nome dallo zio giocatore d‚Äôazzardo di Ulam, come suggerito da Nicholas Metropolis. Da allora, questo metodo √® diventato una tecnica fondamentale in diverse discipline, contribuendo significativamente alla risoluzione di problemi complessi.\nLa metodologia di Monte Carlo genera un‚Äôampia serie di punti casuali per stimare quantit√† di interesse, come l‚Äôintegrazione numerica. Un esempio classico √® l‚Äôapprossimazione dell‚Äôintegrale di un cerchio in 2D, dove il rapporto tra il numero di punti che cadono all‚Äôinterno del cerchio e tutti i campioni fornisce un‚Äôapprossimazione dell‚Äôarea (per un esempio numerico, si veda Appendice O).\nPer illustrare ulteriormente questo concetto, consideriamo ora una distribuzione continua \\(p(\\theta \\mid y)\\) con una media \\(\\mu\\). Se siamo in grado di generare una sequenza di campioni casuali \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) indipendenti e identicamente distribuiti secondo \\(p(\\theta \\mid y)\\), possiamo stimare il valore atteso teorico di \\(\\theta\\) utilizzando la media campionaria \\(\\frac{1}{T} \\sum_{i=1}^T \\theta^{(t)}\\). Questa approssimazione diventa sempre pi√π accurata man mano che aumenta il numero di campioni \\(T\\), grazie alla Legge Forte dei Grandi Numeri.\nUn altro vantaggio del Metodo di Monte Carlo √® la sua capacit√† di approssimare la probabilit√† che una variabile casuale \\(\\theta\\) cada all‚Äôinterno di un intervallo specifico \\((l, u)\\). Questo pu√≤ essere ottenuto calcolando la media campionaria della funzione indicatrice \\(I(l &lt; \\theta &lt; u)\\) per ogni realizzazione \\(\\theta^{(t)}\\), cio√® \\(Pr(l &lt; \\theta &lt; u) \\approx \\frac{\\text{numero di realizzazioni } \\theta^{(t)} \\in (l, u)}{T}\\).\nNonostante la loro efficacia, un limite dei metodi Monte Carlo tradizionali risiede nella generazione efficiente di un elevato numero di campioni \\(X_1, X_2, \\ldots, X_n\\). In risposta a questa sfida, i metodi di Monte Carlo basati su catene di Markov (MCMC) offrono una soluzione potente per simulare da distribuzioni complesse attraverso catene di Markov. L‚Äôevoluzione di questi algoritmi ha trasformato radicalmente la statistica e il calcolo scientifico, permettendo la simulazione da una vasta gamma di distribuzioni, anche in spazi di alta dimensionalit√†.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "href": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.3 Le Catene di Markov",
    "text": "43.3 Le Catene di Markov\nLe catene di Markov, ideate da Andrey Markov nel 1906, rappresentano un tentativo di estendere la legge dei grandi numeri a contesti in cui le variabili casuali non sono indipendenti. Tradizionalmente, la statistica si concentra su sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), simboleggiate come \\(X_0, X_1, \\ldots, X_n, \\ldots\\). In tali sequenze, ogni variabile √® indipendente dalle altre e segue la stessa distribuzione, con \\(n\\) che rappresenta un indice temporale discreto. Tuttavia, questa assunzione di indipendenza non √® sempre realistica nei modelli di fenomeni complessi, portando alla necessit√† di esplorare forme alternative di dipendenza tra variabili.\nPer superare le limitazioni dell‚Äôindipendenza, le catene di Markov introducono una cosiddetta ‚Äúdipendenza a un passo‚Äù, incarnata nella ‚Äúpropriet√† di Markov‚Äù. Questa propriet√† stabilisce che la previsione di un evento futuro \\(X_{n+1}\\) dipende unicamente dall‚Äôevento immediatamente precedente \\(X_n\\), indipendentemente dagli eventi passati \\(X_0, X_1, X_2, \\ldots, X_{n-1}\\). La propriet√† di Markov √® espressa matematicamente come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nQuesta propriet√† afferma che la previsione di un evento futuro dipende solo dall‚Äôevento immediatamente precedente, semplificando i calcoli relativi alle probabilit√† condizionali.\nLe catene di Markov rappresentano un framework fondamentale per la modellazione delle dipendenze tra variabili casuali, una nozione cruciale in numerosi campi della statistica e della scienza dei dati, inclusa la metodologia MCMC (Markov Chain Monte Carlo). In particolare, nell‚Äôambito dell‚Äôanalisi bayesiana, l‚Äôuso di MCMC si rivela di estrema importanza, soprattutto quando non √® possibile calcolare in modo analitico la distribuzione a posteriori.\nL‚Äôalgoritmo di Metropolis rappresenta una delle implementazioni pi√π semplici del metodo MCMC. Questo algoritmo sfrutta la natura dipendente delle catene di Markov per navigare in modo efficace attraverso lo spazio della distribuzione a posteriori. Questo aspetto rende il MCMC uno strumento di grande potenza per affrontare problemi complessi in cui i metodi analitici tradizionali non possono essere applicati (per ulteriori dettagli, si veda Appendice O). In breve, il MCMC consente di generare un vasto insieme di valori per il parametro \\(\\theta\\). Idealmente, questi valori riflettono la distribuzione a posteriori \\(p(\\theta \\mid y)\\) quando questa non pu√≤ essere ottenuta direttamente. Questa caratteristica rende il MCMC uno strumento essenziale per risolvere problemi complessi in cui i metodi analitici convenzionali non sono applicabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.4 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "43.4 Estrazione di campioni dalla distribuzione a posteriori\nNella discussione seguente ci porremo l‚Äôobiettivo di comprendere come utilizzare l‚Äôalgoritmo di Metropolis per approssimare la distribuzione a posteriori \\(p(\\theta \\mid y)\\). A questo fine, il capitolo √® strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o ‚Äúa posteriori,‚Äù sia gi√† conosciuta o disponibile per l‚Äôanalisi.\nIn seguito, passeremo a illustrare come l‚Äôalgoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non √® direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un‚Äôapprossimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse √® focalizzato sulla determinazione della probabilit√† che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilit√† sar√† indicata come \\(\\pi\\). Iniziamo importando i dati.\n\nfile_path = os.path.join(project_directory, \"data\", \"moma_sample.csv\")\nmoma_sample = pd.read_csv(file_path)\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample.head()\n\n\n\n\n\n\n\n\n\nartist\ncountry\nbirth\ndeath\nalive\ngenx\ngender\ncount\nyear_acquired_min\nyear_acquired_max\n\n\n\n\n0\nAd Gerritsen\ndutch\n1940\n2015.0\nFalse\nFalse\nmale\n1\n1981\n1981\n\n\n1\nKirstine Roepstorff\ndanish\n1972\nNaN\nTrue\nTrue\nfemale\n3\n2005\n2005\n\n\n2\nLisa Baumgardner\namerican\n1958\n2015.0\nFalse\nFalse\nfemale\n2\n2016\n2016\n\n\n3\nDavid Bates\namerican\n1952\nNaN\nTrue\nFalse\nmale\n1\n2001\n2001\n\n\n4\nSimon Levy\namerican\n1946\nNaN\nTrue\nFalse\nmale\n1\n2012\n2012\n\n\n\n\n\n\n\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\nresult = moma_sample[\"genx\"].value_counts()\nprint(result)\n\ngenx\nFalse    86\nTrue     14\nName: count, dtype: int64\n\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che √® stato osservato. Tuttavia, poich√© il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilit√† di appartenere alla generazione X o a una generazione successiva) all‚Äôinterno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l‚Äôesito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le propriet√† delle distribuzioni coniugate, possiamo calcolare la distribuzione a posteriori esatta:\nY ~ Binomiale(100, œÄ)\nŒ∏ = Beta(4, 6)\nŒ∏ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) ‚Üí Beta(18, 92)\nNella figura successiva √® rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori scelta.\n\nx = np.linspace(0, 1, 1000)\n\nprior_density = stats.beta.pdf(x, 4, 6)\nposterior_density = stats.beta.pdf(x, 18, 92)\n\nplt.fill_between(x, prior_density, alpha=0.5, label=\"Prior: Beta(4, 6)\")\nplt.fill_between(x, posterior_density, alpha=0.5, label=\"Posterior: Beta(18, 92)\")\nplt.xlabel(\"Parameter Value\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.title(\"Prior and Posterior Densities\")\nplt.show()\n\n\n\n\n\n\n\n\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto √®\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n43.4.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un‚Äôapprossimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con poche osservazioni (ad esempio, 10), possiamo procedere con la seguente simulazione:\n\ny = stats.beta(18, 92).rvs(10)\nprint(y)\n\n[0.14016127 0.08832897 0.17334772 0.1572305  0.11142873 0.1810981\n 0.15692468 0.1674944  0.16207672 0.10429501]\n\n\n\nnp.mean(y)\n\n0.14423860913930076\n\n\nTuttavia, con solo 10 campioni l‚Äôapprossimazione potrebbe non essere molto accurata. Pi√π aumentiamo il numero di campioni (cio√® il numero di osservazioni casuali generate), pi√π precisa sar√† l‚Äôapprossimazione. Aumentando il numero di campioni, ad esempio a 10000, otteniamo un risultato pi√π preciso:\n\nstats.beta(18, 92).rvs(10000).mean()\n\n0.16323788047779372\n\n\nQuando il numero di campioni a posteriori diventa molto grande, la distribuzione campionaria converge alla densit√† della popolazione. Questo concetto si applica non solo alla media, ma anche ad altre statistiche descrittive, come la moda e la varianza.\n√à importante sottolineare che l‚Äôapplicazione della simulazione di Monte Carlo √® efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ci√≤ √® stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poich√© le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l‚Äôespressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l‚Äôutilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, per√≤, √® possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l‚Äôuso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l‚Äôalgoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#algoritmo-di-metropolis",
    "href": "chapters/mcmc/01_metropolis.html#algoritmo-di-metropolis",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.5 Algoritmo di Metropolis",
    "text": "43.5 Algoritmo di Metropolis\nL‚Äôalgoritmo di Metropolis √® un metodo avanzato per il campionamento da distribuzioni probabilistiche complesse. Appartiene alla famiglia dei metodi Monte Carlo Markov Chain (MCMC) e combina strategie di campionamento Monte Carlo con catene di Markov per navigare nello spazio dei parametri in modo intelligente. Questo consente di ottenere campioni rappresentativi della distribuzione di interesse indipendentemente dal punto di partenza, riducendo il rischio di bias nei risultati.\n\n43.5.1 Passaggi Fondamentali dell‚ÄôAlgoritmo di Metropolis\n\nScegli un valore iniziale \\(\\theta_1\\). Imposta \\(t = 1\\).\nCampiona un possibile nuovo valore \\(\\theta_p\\) basato su una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\). Di solito, si usa una distribuzione normale \\(N(\\theta_t, \\tau)\\) come distribuzione di proposta, dove \\(\\tau\\) funge da parametro di regolazione che controlla la dimensione del passo.\nCalcola il rapporto \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\).\nSe \\(\\alpha \\geq 1\\), imposta \\(\\theta_{t+1} = \\theta_p\\).\nSe \\(\\alpha &lt; 1\\), imposta \\(\\theta_{t+1} = \\theta_p\\) con probabilit√† \\(\\alpha\\). Altrimenti, imposta \\(\\theta_{t+1} = \\theta_t\\).\nRipeti dal passo 2 per campionare un nuovo valore \\(\\theta_p\\).\n\n\n\n43.5.2 Dettagli dell‚ÄôAlgoritmo\n\nDistribuzione di Proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) √® usata per generare nuovi campioni di \\(\\theta_p\\) basati sul valore corrente \\(\\theta_t\\). Una scelta comune √® la distribuzione normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) √® un parametro di tuning che controlla la dimensione dei passi del campionamento. Un valore di \\(\\tau\\) troppo grande o troppo piccolo pu√≤ influenzare negativamente l‚Äôefficienza del campionamento.\nCalcolo del Rapporto \\(\\alpha\\): Il rapporto \\(\\alpha\\) √® dato dalla probabilit√† a posteriori del nuovo valore \\(\\theta_p\\) rispetto alla probabilit√† a posteriori del valore corrente \\(\\theta_t\\). Questo rapporto determina l‚Äôaccettazione o il rifiuto del nuovo campione.\nDecisione di Accettazione:\n\nSe \\(\\alpha \\geq 1\\), il nuovo valore \\(\\theta_p\\) √® sempre accettato.\nSe \\(\\alpha &lt; 1\\), il nuovo valore \\(\\theta_p\\) √® accettato con probabilit√† \\(\\alpha\\). Se non viene accettato, il valore corrente \\(\\theta_t\\) √® mantenuto per il prossimo passo.\n\n\nALGORITHM Metropolis(nsamp, xinit)\n    // Initialize samples as an empty array of size nsamp\n    x_prev = xinit\n\n    FOR i = 0 TO nsamp - 1 DO\n        x_star = GENERATE_NORMAL(mean = x_prev, std_dev = 0.1)\n        \n        IF 0 ‚â§ x_star ‚â§ 1 THEN\n            p_star = POSTERIOR(x_star)\n            p_prev = POSTERIOR(x_prev)\n            \n            IF p_prev &gt; 0 THEN\n                pdfratio = p_star / p_prev\n            ELSE\n                pdfratio = 1\n            END IF\n            \n            random_chance = RANDOM_UNIFORM(0, 1)\n            acceptance_probability = MIN(1, pdfratio)\n            \n            IF random_chance &lt; acceptance_probability THEN\n                samples[i] = x_star\n                x_prev = x_star\n            ELSE\n                samples[i] = x_prev\n            END IF\n        ELSE\n            samples[i] = x_prev\n        END IF\n    END FOR\n\n    RETURN samples\nEND ALGORITHM\n\nFUNCTION POSTERIOR(x)\n    // This function should be defined elsewhere\n    // It represents the product of the prior and likelihood\nEND FUNCTION\nQuesto processo permette di esplorare lo spazio dei parametri \\(\\theta\\) generando una catena di Markov che, nel tempo, converge verso la distribuzione a posteriori \\(p(\\theta \\mid y)\\). Utilizzando questa catena, possiamo stimare empiricamente le propriet√† della distribuzione a posteriori.\nLa procedura continua con l‚Äôiterazione dei passi dal 2 al 5, permettendo alla catena di campioni di convergere alla distribuzione target. Inizialmente, i campioni potrebbero non essere rappresentativi, ma dopo un sufficiente numero di iterazioni (il cosiddetto ‚Äúburn-in‚Äù), la distribuzione dei punti accettati dovrebbe avvicinarsi a quella che si intende esplorare.\nL‚Äôefficienza di questo algoritmo deriva dalla sua abilit√† nel mantenere un equilibrio tra l‚Äôesplorazione di nuove possibilit√† e l‚Äôutilizzo di quelle gi√† note. Questo viene realizzato attraverso l‚Äôadozione di un meccanismo che accetta i punti suggeriti in modo probabilistico, facilitando cos√¨ la raccolta di un campione che riflette accuratamente la distribuzione di probabilit√† complessa sotto indagine.\nPer una visualizzazione del comportamento dell‚Äôalgoritmo di Metropolis nell‚Äôesplorare lo spazio dei parametri, si pu√≤ consultare questo post. La distinzione tra i diversi metodi MCMC si basa principalmente sul tipo di distribuzione proposta e sul criterio di accettazione dei punti nel campionamento.\n\n\n43.5.3 Implementazione dell‚ÄôAlgoritmo di Metropolis (1)\nPer comprendere il funzionamento dell‚Äôalgoritmo di Metropolis, iniziamo con un esempio semplice. Consideriamo un piccolo set di dati simulati che rappresentano 6 successi su 9 prove in un test Go-No Go, come discusso nella sezione Capitolo 34. In questo contesto, la verosimiglianza segue una distribuzione binomiale.\nSupponiamo che la distribuzione a priori per la probabilit√† \\(\\theta\\) (la probabilit√† di inibire correttamente la risposta in una prova No Go) sia uniforme. In queste condizioni, la distribuzione a posteriori coincide con la verosimiglianza, fatta eccezione per un fattore di scala che √® irrilevante per l‚Äôalgoritmo. Pertanto, l‚Äôalgoritmo di Metropolis pu√≤ essere implementato come segue.\n\nn_samples = 10_000\np = np.full(\n    n_samples, np.nan\n)  # Inizializza un array di dimensione n_samples con valori NaN\np[0] = 0.5  # Imposta il primo elemento dell'array a 0.5\n\nncor = 6 # Numero di prove corrette\nnerr = 3 # Numero di errori\n\nnp.random.seed(42)\n\nfor i in range(1, n_samples):\n    p_new = np.random.normal(loc=p[i - 1], scale=0.1)\n    if p_new &lt; 0:\n        p_new = abs(p_new)\n    if p_new &gt; 1:\n        p_new = 2 - p_new\n\n    q0 = stats.binom.pmf(k=ncor, n=ncor + nerr, p=p[i - 1])\n    q1 = stats.binom.pmf(k=ncor, n=ncor + nerr, p=p_new)\n    p[i] = p_new if np.random.uniform() &lt; q1 / q0 else p[i - 1]\n\nDi seguito √® riportato un grafico che mostra un campione casuale estratto dalla distribuzione a posteriori utilizzando l‚Äôalgoritmo di Metropolis per i dati dell‚Äôesperimento Go-No Go.\n\n# Creazione del DataFrame\ndf = pd.DataFrame({\"p\": p})\n\n# Grafico di densit√†\n_ = sns.kdeplot(data=df, x=\"p\", fill=True, color=\"black\")\n\n\n\n\n\n\n\n\n\n\n43.5.4 Implementazione dell‚ÄôAlgoritmo di Metropolis (2)\nProcediamo ora con un‚Äôimplementazione pi√π generale dell‚Äôalgoritmo di Metropolis, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. In questo scenario, la verosimiglianza segue ancora una distribuzione binomiale, con 14 successi su 100 osservazioni. Tuttavia, diversamente dal caso precedente, adottiamo una distribuzione a priori non uniforme per \\(\\theta\\) (la probabilit√† di appartenere alla Generazione X), modellata secondo una distribuzione Beta(4, 6).\nPer implementare questo approccio, definiamo una funzione prior che accetta come argomento il valore di \\(\\theta\\) e restituisce la densit√† della distribuzione Beta(4, 6).\n\ndef prior(p):\n    alpha = 4\n    beta = 6\n    return stats.beta.pdf(p, alpha, beta)\n\nDefiniamo la funzione likelihood, che accetta come argomento il valore di \\(\\theta\\) e restituisce la densit√† della funzione di verosimiglianza binomiale per il caso di 14 successi su 100 prove.\n\ndef likelihood(p):\n    y = 14\n    n = 100\n    return stats.binom.pmf(y, n, p)\n\nInfine, definiamo la funzione posterior, che accetta come argomento il valore di \\(\\theta\\) e restituisce la densit√† della distribuzione a posteriori non normalizzata, calcolata come il prodotto della distribuzione a priori e della verosimiglianza. √à importante notare che, come spiegato in precedenza, non √® necessario normalizzare la distribuzione a posteriori per il nostro scopo.\n\ndef posterior(p):\n    return likelihood(p) * prior(p)\n\nNell‚Äôimplementazione dell‚Äôalgoritmo di Metropolis vi sono diversi aspetti da considerare attentamente. Ecco alcuni punti cruciali:\n\nSimmetria della Distribuzione Proposta: √à fondamentale che la distribuzione proposta sia simmetrica. Questa √® una condizione necessaria per il funzionamento dell‚Äôalgoritmo di Metropolis, ma non per quello di Metropolis-Hastings.\nValore Iniziale: Il valore iniziale scelto dovrebbe essere plausibile in base alla distribuzione a priori, in modo da facilitare la convergenza dell‚Äôalgoritmo.\nProbabilit√† Zero: Nel caso in cui la verosimiglianza o il prior assumano un valore di zero, il rapporto tra le densit√† di probabilit√† (pdfratio) all‚Äôinterno dell‚Äôalgoritmo di Metropolis risulter√† indefinito. Pertanto, √® importante garantire che il valore x_star, generato dalla distribuzione proposta, cada sempre entro i limiti del supporto sia del prior che della verosimiglianza.\n\nDi seguito √® presentato il codice dell‚Äôalgoritmo di Metropolis per il caso presente.\n\n# Definizione della funzione dell'algoritmo di Metropolis.\n# nsamp: Numero di campioni da generare.\n# xinit: Valore iniziale da cui iniziare il sampling.\ndef metropolis(nsamp, xinit):\n    # Inizializza un array vuoto per conservare i campioni generati.\n    samples = np.empty(nsamp)\n\n    # Imposta il primo valore (valore iniziale) da cui partire per la generazione dei campioni.\n    x_prev = xinit\n\n    # Inizia un ciclo che si ripeter√† per il numero di volte specificato da nsamp (numero di campioni da generare).\n    for i in range(nsamp):\n        # Genera un nuovo punto (x_star) usando una distribuzione normale (gaussiana).\n        # Questo nuovo punto √® generato in modo da essere \"vicino\" al punto precedente (x_prev),\n        # con una deviazione standard di 0.1. Questo significa che la maggior parte dei punti\n        # sar√† entro 0.1 unit√† da x_prev, ma alcuni potrebbero essere pi√π lontani.\n        x_star = np.random.normal(x_prev, 0.1)\n\n        # Verifica che il nuovo punto (x_star) sia un valore plausibile nel contesto del problema.\n        # Qui, l'assunzione √® che x_star debba essere tra 0 e 1. Se non lo √®, il punto √® rifiutato.\n        if 0 &lt;= x_star &lt;= 1:\n            # Calcola il valore della funzione di densit√† di probabilit√† posterior per il nuovo punto e il punto precedente.\n            # La funzione posterior √® definita altrove e rappresenta il prodotto del prior e della likelihood.\n            p_star = posterior(x_star)\n            p_prev = posterior(x_prev)\n\n            # Calcola il rapporto tra le densit√† posterior del nuovo punto e del punto precedente.\n            # Questo rapporto determina la probabilit√† di accettare il nuovo punto.\n            # Se p_prev √® 0, per evitare la divisione per zero, il rapporto √® impostato a 1.\n            pdfratio = p_star / p_prev if p_prev &gt; 0 else 1\n\n            # Genera un numero casuale tra 0 e 1.\n            random_chance = np.random.uniform()\n\n            # Calcola il rapporto tra la densit√† posteriore del nuovo punto e quella del punto precedente.\n            # Se il nuovo punto √® migliore o uguale, questo rapporto sar√† &gt;= 1.\n            # Se il nuovo punto √® peggiore, il rapporto sar√† un numero fra 0 e 1.\n            acceptance_probability = min(1, pdfratio)\n\n            # Se il numero casuale √® minore dell'acceptance_probability, accettiamo il nuovo punto.\n            # Ci√≤ significa che un punto migliore o uguale viene sempre accettato (perch√© random_chance sar√† sempre &lt; 1),\n            # mentre un punto peggiore ha una possibilit√† basata sul quanto √® peggiore.\n            if random_chance &lt; acceptance_probability:\n                samples[i] = x_star  # Accetta il nuovo punto.\n                x_prev = (\n                    x_star  # Aggiorna il punto precedente con il nuovo punto accettato.\n                )\n            else:\n                samples[i] = (\n                    x_prev  # Mantiene il punto precedente se il nuovo punto non √® accettato.\n                )\n        else:\n            samples[i] = (\n                x_prev  # Se x_star non √® nel supporto, conserva il punto precedente.\n            )\n\n    # Dopo aver generato il numero desiderato di campioni, ritorna l'array dei campioni.\n    return samples\n\nL‚Äôidea fondamentale dietro la fase dell‚Äôalgoritmo di Metropolis successiva al calcolo di p_star e p_prev √® decidere se ‚Äúmuoversi‚Äù verso un nuovo punto basandosi su quanto √® probabile (o ‚Äúbuono‚Äù) quel punto rispetto al punto attuale, in termini della densit√† posteriore. Qui, la ‚Äúprobabilit√†‚Äù di un punto √® data dalla sua densit√† posteriore, che √® un modo per misurare quanto bene un certo valore del parametro si adatta ai dati osservati, dato un modello.\nEcco come funziona:\n\nGenerazione di un numero casuale.\nConfronto tra i punti: Si confronta il ‚Äúvalore‚Äù del nuovo punto (x_star) con quello del punto precedente (x_prev). Questo ‚Äúvalore‚Äù √® dato dalla densit√† posteriore: pi√π alto √®, meglio √®.\nDecisione:\n\nSe il nuovo punto √® migliore del precedente (ovvero, ha una densit√† posteriore maggiore o uguale), lo accettiamo sempre.\nSe il nuovo punto √® peggiore del precedente (ha una densit√† posteriore minore), non lo rifiutiamo subito. Invece, gli diamo una chance di essere scelto, ma questa chance √® pi√π piccola quanto pi√π il nuovo punto √® ‚Äúpeggiore‚Äù.\n\n\nIn termini di codice, questa logica si traduce cos√¨:\n# Genera un numero casuale tra 0 e 1.\nrandom_chance = np.random.uniform()\n\n# Calcola il rapporto tra la densit√† posteriore del nuovo punto e quella del punto precedente.\n# Se il nuovo punto √® migliore o uguale, questo rapporto sar√† &gt;= 1.\n# Se il nuovo punto √® peggiore, il rapporto sar√† un numero fra 0 e 1.\nacceptance_probability = min(1, pdfratio)\n\n# Se il numero casuale √® minore dell'acceptance_probability, accettiamo il nuovo punto.\n# Ci√≤ significa che un punto migliore o uguale viene sempre accettato (perch√© random_chance sar√† sempre &lt; 1),\n# mentre un punto peggiore ha una possibilit√† basata sul quanto √® peggiore.\nif random_chance &lt; acceptance_probability:\n    samples[i] = x_star  # Accetta il nuovo punto.\n    x_prev = x_star      # Aggiorna il punto precedente con il nuovo punto accettato.\nelse:\n    samples[i] = x_prev  # Mantiene il punto precedente se il nuovo punto non √® accettato.\nIn sintesi, questo meccanismo consente all‚Äôalgoritmo di esplorare lo spazio dei parametri in modo efficiente, accettando sempre miglioramenti e, occasionalmente, facendo passi in direzioni non ottimali per evitare di rimanere intrappolati in ‚Äúminimi locali‚Äù, ovvero in soluzioni che sembrano buone rispetto a quelle vicine ma non sono le migliori globalmente.\nSi osservi un punto importante: nel calcolo di pdfratio, il rapporto tra la densit√† a posteriori del parametro proposto x_star e quella del parametro corrente x_prev, la costante di normalizzazione si annulla grazie alla regola di Bayes. Questo lascia nel rapporto solamente le componenti relative alla verosimiglianza e alla distribuzione a priori, che sono entrambe facilmente calcolabili. Matematicamente, questo si esprime come:\n\\[\n\\begin{equation}\n\\text{pdfratio} = \\frac{p(\\theta^* \\mid y)}{p(\\theta^{\\text{prev}} \\mid y)} = \\frac{\\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y)}}{\\frac{p(y \\mid \\theta^{\\text{prev}}) p(\\theta^{\\text{prev}})}{p(y)}}\n= \\frac{p(y \\mid \\theta^*) p(\\theta^*)}{p(y \\mid \\theta^{\\text{prev}}) p(\\theta^{\\text{prev}})}.\n\\end{equation}\n\\tag{43.1}\\]\nEseguiamo dunque il campionamento usando l‚Äôalgoritmo che abbiamo definito.\n\nn_samples = 100_000\nsamps = metropolis(n_samples, 0.5)\n\nIn somma, l‚Äôalgoritmo Metropolis accetta come input il numero nsamp di passi da simulare e il punto di partenza. Come output, l‚Äôalgoritmo restituisce una catena di valori del parametro, specificamente la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\ldots, \\theta^{\\text{nsamp}}\\). Uno degli aspetti cruciali per la riuscita dell‚Äôalgoritmo √® il raggiungimento della stazionariet√† da parte della catena. In genere, i primi 1000-5000 valori vengono scartati in quanto rappresentano il periodo di ‚Äúburn-in‚Äù della catena. Dopo un determinato numero di passi \\(k\\), la catena converge e i valori diventano campioni effettivi dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nIl modello descritto √® stato inizialmente proposto da Metropolis et al.¬†nel 1953 (Metropolis et al. 1953). Hastings nel 1970 introdusse un‚Äôestensione nota come algoritmo Metropolis-Hastings (Hastings 1970). Altre varianti includono il campionatore di Gibbs, introdotto da Geman e Geman nel 1984 (Geman e Geman 1984), l‚ÄôHamiltonian Monte Carlo (Duane et al. 1987), e il No-U-Turn Sampler (NUTS) utilizzato in pacchetti come PyMC e Stan (Hoffman, Gelman, et al. 2014). Per un‚Äôanalisi pi√π dettagliata e intuitiva dell‚Äôalgoritmo Metropolis, si rimanda a (doingbayesian?).\nUn elemento chiave da considerare nell‚Äôuso dell‚Äôalgoritmo Metropolis √® il tasso di accettazione, che √® il rapporto tra il numero di valori del parametro proposti e il numero di quei valori che vengono effettivamente accettati. Un limite di questo algoritmo √® la sua inefficienza relativa: rispetto alle sue varianti pi√π moderne, l‚Äôalgoritmo Metropolis tende ad essere meno efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#aspetti-computazionali",
    "href": "chapters/mcmc/01_metropolis.html#aspetti-computazionali",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.6 Aspetti computazionali",
    "text": "43.6 Aspetti computazionali\n\n43.6.1 Warm-up/Burn-in\nUna catena di Markov ha bisogno di alcune iterazioni per raggiungere la distribuzione stazionaria. Queste iterazioni sono comunemente chiamate iterazioni di warm-up o burn-in (a seconda dell‚Äôalgoritmo e del software utilizzato) e vengono di solito scartate. In molti programmi software, la prima met√† delle iterazioni viene considerata come iterazioni di warm-up, quindi, nel caso presente, anche se abbiamo ottenuto 100000 iterazioni, ne utilizzeremo solo 50000.\n\n\n43.6.2 Sintesi della distribuzione a posteriori\nL‚Äôarray samps contiene 100000 valori di una catena di Markov. Escludiamo i primi 50000 valori considerati come burn-in e consideriamo i restanti 50000 valori come un campione casuale estratto dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nMediante i valori della catena cos√¨ ottenuta √® facile trovare una stima a posteriori del parametro \\(\\theta\\). Per esempio, possiamo trovare la stima della media a posteriori.\n\nburnin = int(n_samples * 0.5)\nburnin\n\n50000\n\n\n\nnp.mean(samps[burnin:])\n\n0.16408968344081415\n\n\nOppure possiamo stimare la deviazione standard della distribuzione a posteriori.\n\nnp.std(samps[burnin:])\n\n0.03513787973422409\n\n\nVisualizziamo un trace plot dei valori della catena di Markov dopo il periodo di burn-in.\n\nplt.plot(samps[burnin:])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nIl trace plot indica che la catena inizia con un valore casuale per poi spostarsi rapidamente nell‚Äôarea intorno a 0.16, che √® l‚Äôarea con alta densit√† a posteriori. Successivamente, oscilla intorno a quel valore per le iterazioni successive.\n\nplt.plot(samps[:500])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nL‚Äôistogramma mostrato di seguito, sul quale √® stata sovrapposta la distribuzione a posteriori derivata analiticamente ‚Äì specificamente una \\(\\text{Beta}(25, 17)\\) ‚Äì dimostra che la catena converge effettivamente alla distribuzione a posteriori desiderata.\n\nplt.hist(samps[burnin:], bins=30, alpha=0.4, label=\"MCMC distribution\", density=True)\n# plot the true function\nx = np.linspace(0, 1, 1000)\nplt.plot(x, stats.beta.pdf(x, 18, 92), \"C0\", label=\"True distribution\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n√à possibile usare la funzione summary del pacchetto AriviZ per calolare l‚Äôintervallo di credibilit√†, ovvero l‚Äôintervallo che contiene la proporzione indicata dei valori estratti a caso dalla distribuzione a posteriori.\n\naz.summary(samps[burnin:], kind=\"stats\", hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nx\n0.16\n0.04\n0.1\n0.23\n\n\n\n\n\n\n\n\nUn KDE plot corrispondente all‚Äôistogramma precedente si pu√≤ generare usando az.plot_posterior(). La curva rappresenta l‚Äôintera distribuzione a posteriori e viene calcolata utilizzando la stima della densit√† del kernel (KDE) che serve a ‚Äúlisciare‚Äù l‚Äôistogramma.\n\naz.plot_posterior(samps[burnin:])\nplt.show()\n\n\n\n\n\n\n\n\nL‚ÄôHDI √® una scelta comune nelle statistiche bayesiane e valori arrotondati come 50% o 95% sono molto popolari. Ma ArviZ utilizza il 94% come valore predefinito. La ragione di questa scelta √® che il 94% √® vicino al valore ampiamente utilizzato del 95%, ma √® anche diverso da questo, cos√¨ da servire da ‚Äúamichevole promemoria‚Äù che non c‚Äô√® niente di speciale nella soglia del 5%. Idealmente sarebbe opportuno scegliere un valore che si adatti alle specifiche esigenze dell‚Äôanalisi statistica che si sta svolgendo, o almeno riconoscere che si sta usando un valore arbitrario.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.7 Diagnostiche della soluzione MCMC",
    "text": "43.7 Diagnostiche della soluzione MCMC\n\n43.7.1 Catene multiple\nPoich√© ciascuno stato in una catena di Markov dipende dagli stati precedenti, il valore o i valori iniziali possono influenzare i valori campionati. Una soluzione per verificare la sensibilit√† rispetto ai valori iniziali √® utilizzare pi√π catene, ognuna con diversi valori iniziali. Se pi√π catene campionano la stessa distribuzione target, queste dovrebbero mescolarsi bene, ovvero intersecarsi l‚Äôuna con l‚Äôaltra in un trace plot.\n\n\n43.7.2 Stazionariet√†\nUn punto importante da verificare √® se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta ‚Äúmixing‚Äù.\n\n\n43.7.3 Autocorrelazione\nOgni passo nell‚Äôalgoritmo MCMC √® chiamato iterazione. I valori campionati sono dipendenti, il che significa che il valore all‚Äôiterazione \\(m\\) dipende dal valore all‚Äôiterazione \\(m-1\\). Questa √® una differenza importante rispetto alle funzioni che generano campioni casuali indipendenti, come beta(25, 17).rvs(). I valori campionati formano una catena di Markov, il che significa che ciascun valore campionato √® correlato con il valore precedente (ad esempio, se \\(\\theta(m)\\) √® grande, \\(\\theta(m+1)\\) sar√† anch‚Äôesso grande).\nInformazioni sul ‚Äúmixing‚Äù della catena di Markov sono fornite dall‚Äôautocorrelazione. L‚Äôautocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore \\(m\\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantit√† \\(k\\) (dove \\(k\\) √® l‚Äôentit√† del ritardo) per verificare quanto si correli al variare di \\(k\\). L‚Äôautocorrelazione di ordine 1 (lag 1) misura la correlazione tra valori successivi della catena di Markow (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-1)}\\)); l‚Äôautocorrelazione di ordine 2 (lag 2) misura la correlazione tra valori della catena di Markow separati da due ‚Äúpassi‚Äù (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-2)}\\)); e cos√¨ via.\nL‚Äôautocorrelazione di ordine \\(k\\) √® data da \\(\\rho_k\\) e pu√≤ essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\] (eq-autocor)\nPer fare un esempio pratico, simuliamo dei dati autocorrelati.\n\nx = pd.array([22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51])\nprint(x)\n\n&lt;IntegerArray&gt;\n[22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51]\nLength: 15, dtype: Int64\n\n\nL‚Äôautocorrelazione di ordine 1 √® semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza.\n\nsm.tsa.acf(x)\n\narray([ 1.        ,  0.83174224,  0.65632458,  0.49105012,  0.27863962,\n        0.03102625, -0.16527446, -0.30369928, -0.40095465, -0.45823389,\n       -0.45047733, -0.36933174])\n\n\nNell‚Äôesempio, il vettore x √® una sequenza temporale di 15 elementi. Il vettore \\(x'\\) include gli elementi con gli indici da 0 a 13 nella sequenza originaria, mentre il vettore \\(x''\\) include gli elementi 1:14. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((0, 1)\\), \\((1, 2), (2, 3), \\dots (13, 14)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori \\(x'\\) e \\(x''\\) corrisponde all‚Äôautocorrelazione di ordine 1 della serie temporale.\nNell‚Äôoutput precedente\n\n0.83174224 √® l‚Äôautocorrelazione di ordine 1 (lag = 1),\n0.65632458 √® l‚Äôautocorrelazione di ordine 2 (lag = 2),\n0.49105012 √® l‚Äôautocorrelazione di ordine 3 (lag = 3),\necc.\n\n√à possibile specificare il numero di ritardi (lag) da utilizzare con l‚Äôargomento nlags:\n\nsm.tsa.acf(x, nlags=4)\n\narray([1.        , 0.83174224, 0.65632458, 0.49105012, 0.27863962])\n\n\nIn Python possiamo creare un grafico della funzione di autocorrelazione (correlogramma) per una serie temporale usando la funzione tsaplots.plot_acf() dalla libreria statsmodels.\n\ntsaplots.plot_acf(x, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nPer i dati dell‚Äôesempio in discussione otteniamo la situazione seguente.\n\ntsaplots.plot_acf(samps[burnin:], lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nIl correlogramma √® uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall‚Äôautocorrelazione \\(\\rho_k\\) di una catena di Markov in funzione del ritardo \\(k\\) con cui l‚Äôautocorrelazione √® calcolata: nel grafico ogni barretta verticale riporta il valore dell‚Äôautocorrelazione (sull‚Äôasse delle ordinate) in funzione del ritardo (sull‚Äôasse delle ascisse).\nIn situazioni ottimali l‚Äôautocorrelazione diminuisce rapidamente ed √® effettivamente pari a 0 per piccoli lag. Ci√≤ indica che i valori della catena di Markov che si trovano a pi√π di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del ‚Äúmixing‚Äù della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l‚Äôautocorrelazione √® quella di assottigliare l‚Äôoutput immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di thinning.\nNel seguente correlogramma, analizziamo la medesima catena di Markov. Tuttavia, in questa occasione applichiamo un ‚Äúthinning‚Äù (sottocampionamento) con un fattore di 5.\n\nthin = 5\nsampsthin = samps[burnin::thin]\ntsaplots.plot_acf(sampsthin, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nSi pu√≤ notare come l‚Äôautocorrelazione diminuisce molto pi√π rapidamente.\n\n43.7.3.1 Tasso di accettazione\nQuando si utilizza l‚Äôalgoritmo Metropolis, √® importante monitorare il tasso di accettazione e assicurarsi che sia nell‚Äôintervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegher√† molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D‚Äôaltra parte, se il tasso di accettazione √® molto basso, la catena rimarr√† bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l‚Äôalgoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale √® compreso tra il 40% e il 50%.\n\n\n43.7.3.2 Test di convergenza\nPer valutare la convergenza di una catena di Markov Monte Carlo (MCMC), esistono diversi metodi, tra cui approcci grafici e test statistici. Ecco una spiegazione pi√π chiara e dettagliata:\n\n\n\n43.7.4 Approcci Grafici: Tracce delle Serie Temporali (Trace Plots)\nLe tracce delle serie temporali, o trace plots, sono grafici che mostrano l‚Äôevoluzione dei valori campionati rispetto al numero di iterazioni. Questi grafici sono utili per valutare visivamente se la catena ha raggiunto la convergenza. Segni che indicano una potenziale convergenza includono:\n\nAssenza di Tendenze: Non ci sono trend ascendenti o discendenti nel corso delle iterazioni.\nCostanza dell‚ÄôAmpiezza: La variabilit√† dei valori campionati rimane costante nel tempo, senza significative fluttuazioni.\nMancanza di Periodicit√†: Non si osservano cicli o ripetizioni regolari che potrebbero indicare la presenza di correlazioni residue.\n\n\n\n43.7.5 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n43.7.5.1 Test di Geweke\nIl test di Geweke √® una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l‚Äôultimo 50% dei campioni, dopo aver escluso un iniziale periodo di ‚Äúburn-in‚Äù (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base √® che, se la catena √® in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n\n43.7.5.2 Geweke Z-score\nUna variante del test di Geweke √® lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in pi√π esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. √à importante notare che nessun test pu√≤ garantire con certezza la convergenza, ma l‚Äôutilizzo congiunto di approcci grafici e test statistici pu√≤ offrire una buona indicazione dello stato della catena.\n\n\n\n43.7.6 Effective sample size (ESS)\nQuando le iterazioni sono dipendenti, ogni iterazione contiene informazioni sovrapposte con le iterazioni precedenti. In altre parole, quando si ottengono 500 campioni dipendenti dalla distribuzione a posteriori, questi contengono solo informazioni equivalenti a &lt; 500 campioni indipendenti. L‚ÄôESS (Effective Sample Size) quantifica la quantit√† effettiva di informazioni, quindi una catena con ESS = n conterr√† approssimativamente la stessa quantit√† di informazioni di n campioni indipendenti. In generale, vogliamo che l‚ÄôESS sia almeno 400 per un‚Äôutilizzazione generale nel riassumere la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.8 Caso Normale-Normale",
    "text": "43.8 Caso Normale-Normale\nConsideriamo ora il caso Normale-Normale di cui √® possibile trovare una soluzione analitica. Supponiamo, come prior, una \\(\\mathcal{N}(30, 5\\).\n\ndef prior(mu):\n    return stats.norm.pdf(mu, 30, 5)\n\nPer la verosimiglianza del parametro \\(\\mu\\), supponiamo \\(\\sigma\\) nota e uguale alla deviazione standard del campione.\n\ndef likelihood(mu, data):\n    std_data = np.std(data)  # Calcola la deviazione standard dei dati\n    return np.prod(stats.norm.pdf(data, mu, std_data))\n\nDefiniamo il posterior non normalizzato:\n\ndef posterior(mu, data):\n    return likelihood(mu, data) * prior(mu)\n\nModifichiamo ora l‚Äôalgoritmo di Metropolis descritto sopra per adattarlo al caso presente.\n\n# Algoritmo di Metropolis per il caso normale-normale\ndef metropolis_for_normal(nsamp, xinit, data):\n    samples = np.empty(nsamp)\n    x_prev = xinit\n\n    for i in range(nsamp):\n        x_star = np.random.normal(x_prev, 0.5)  # Genera un nuovo punto dalla proposta\n\n        # Calcola il rapporto di accettazione e accetta il nuovo punto con una certa probabilit√†\n        if posterior(x_star, data) / posterior(x_prev, data) &gt; np.random.uniform():\n            x_prev = x_star\n\n        samples[i] = x_prev\n\n    return samples\n\nVediamo cosa fa la presente versione dell‚Äôalgoritmo di Metropolis passo dopo passo:\n\nCiclo sui Campioni: for i in range(nsamp): inizia un ciclo che si ripeter√† nsamp volte, dove nsamp √® il numero totale di campioni che vogliamo generare. Ogni iterazione di questo ciclo produrr√† un campione dalla distribuzione di interesse.\nGenerazione di un Nuovo Punto: x_star = np.random.normal(x_prev, 0.5) genera un nuovo punto (x_star) come proposta per il prossimo passo del campionamento. Questo √® fatto campionando da una distribuzione normale con media uguale all‚Äôultimo punto accettato (x_prev) e una deviazione standard di 0.5. Questa distribuzione √® detta distribuzione di proposta e serve a esplorare lo spazio dei parametri.\nCalcolo del Rapporto di Accettazione:\n\nIl rapporto di accettazione √® calcolato come posterior(x_star, data) / posterior(x_prev, data), che √® il rapporto tra la probabilit√† del posterior del nuovo punto proposto (x_star) e la probabilit√† del posterior dell‚Äôultimo punto accettato (x_prev).\nQuesto rapporto indica quanto sia preferibile il nuovo punto rispetto al precedente, basandosi sulla funzione posterior, che calcola la probabilit√† a posteriori del modello dato il parametro e i dati osservati.\n\nDecisione di Accettazione del Nuovo Punto:\n\nLa decisione se accettare o meno il nuovo punto (x_star) si basa su un confronto del rapporto di accettazione con un numero casuale uniformemente distribuito tra 0 e 1 (np.random.uniform()).\nSe il rapporto di accettazione √® maggiore di questo numero casuale, il nuovo punto √® accettato come il prossimo punto nella catena (x_prev = x_star). Ci√≤ significa che il nuovo punto ha una probabilit√† a posteriori pi√π alta rispetto al punto precedente, o √® stato ‚Äúfortunato‚Äù nel processo di selezione casuale, consentendo all‚Äôalgoritmo di esplorare lo spazio dei parametri anche in zone di minore probabilit√†.\nSe il nuovo punto non viene accettato, la catena rimane nel punto precedente (x_prev), e questo punto viene nuovamente aggiunto all‚Äôarray dei campioni.\n\nSalvataggio del Campione: samples[i] = x_prev salva il punto corrente (che pu√≤ essere il nuovo punto accettato o il punto precedente se il nuovo punto √® stato rifiutato) nell‚Äôarray samples. Questo processo si ripete fino a quando non si raggiunge il numero desiderato di campioni.\n\nCome dati, usiamo il campione di 30 valori BDI-II ottenuti dai soggetti clinici esaminati da {cite}zetsche_2019future.\n\ny = np.array([\n    26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n    41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n])\n\nProcediamo con l‚Äôesecuzione dell‚Äôalgoritmo di Metropolis.\n\nsamples = metropolis_for_normal(100_000, np.mean(y), y)\nsamples.shape\n\n(100000,)\n\n\n\n43.8.1 Calcolo dei Parametri del Posterior Analitico\nNel caso normale-normale, possiamo derivare analiticamente la distribuzione posteriore quando sia il prior che la likelihood sono distribuzioni normali. La bellezza di questo approccio sta nella forma chiusa del posterior, che √® anch‚Äôesso una distribuzione normale con parametri specifici facilmente calcolabili. Ecco come si fa:\n\nMedia Posteriore (\\(\\mu_{post}\\)): La media del posterior √® un peso tra la media del campione e la media del prior, dove i pesi sono determinati dalle varianze del prior e dei dati.\n\\[\n\\mu_{post} = \\frac{\\frac{\\mu_{prior}}{\\sigma_{prior}^2} + \\frac{\\sum y_i}{\\sigma_{data}^2}}{\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}}\n\\]\nVarianza Posteriore (\\(\\sigma_{post}^2\\)): La varianza del posterior √® determinata dalle varianze del prior e dei dati.\n\\[\n\\sigma_{post}^2 = \\left(\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}\\right)^{-1}\n\\]\n\nDove: - \\(\\mu_{prior}\\) √® la media del prior (in questo caso, 30), - \\(\\sigma_{prior}^2\\) √® la varianza del prior (\\(5^2\\) in questo caso), - \\(\\sigma_{data}^2\\) √® la varianza dei dati (calcolata dai dati), - \\(n\\) √® il numero di osservazioni, - \\(\\sum y_i\\) √® la somma delle osservazioni.\n\n\n43.8.2 Codice per il Grafico\nPer produrre il grafico con l‚Äôistogramma dei campioni dal posterior (usando l‚Äôalgoritmo di Metropolis) e la curva della distribuzione posteriore analitica, usiamo i parametri calcolati:\n\n# Parametri del prior\nmu_prior = 30\nstd_prior = 5\nvar_prior = std_prior ** 2\n\n# Dati osservati\nn = len(y)\nsum_y = np.sum(y)\nvar_data = np.var(y, ddof=1)  # ddof=1 for sample variance\n\n# Calcolo dei parametri posterior\nmu_post = (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post = 1 / (1 / var_prior + n / var_data)\nstd_post = np.sqrt(var_post)\n\n# Generazione dei punti x per il grafico\nx = np.linspace(mu_post - 4 * std_post, mu_post + 4 * std_post, 1000)\n\n# Istogramma dei campioni dal posterior\nplt.hist(samples[burnin:], bins=30, alpha=0.4, density=True, label=\"MCMC Samples Distribution\")\n\n# Curva della distribuzione posteriore analitica\nplt.plot(x, stats.norm.pdf(x, mu_post, std_post), \"C1\", label=\"Analytical Posterior Distribution\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice mostra come integrare l‚Äôanalisi MCMC con l‚Äôapproccio analitico per il caso normale-normale, offrendo sia una visualizzazione dei risultati del sampling che la conferma attraverso la soluzione analitica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/01_metropolis.html#commenti-e-considerazioni-finali",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "43.9 Commenti e considerazioni finali",
    "text": "43.9 Commenti e considerazioni finali\nIn generale, la distribuzione a posteriori dei parametri di un modello statistico non pu√≤ essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilit√† che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre pi√π semplice l‚Äôuso dei metodi MCMC, insieme all‚Äôincremento della potenza di calcolo dei computer, ha contribuito a rendere sempre pi√π popolare il metodo dell‚Äôinferenza bayesiana che, in questo modo, pu√≤ essere estesa a problemi di qualunque grado di complessit√†.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "43¬† Monte Carlo a Catena di Markov",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 15 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nsys        : 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:35:20) [Clang 16.0.6 ]\nmatplotlib : 3.8.4\narviz      : 0.18.0\nstatsmodels: 0.14.2\nscipy      : 1.13.1\nnumpy      : 1.26.4\nseaborn    : 0.13.2\npymc       : 5.15.1\npandas     : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nDuane, Simon, Anthony D Kennedy, Brian J Pendleton, e Duncan Roweth. 1987. ¬´Hybrid monte carlo¬ª. Physics letters B 195 (2): 216‚Äì22.\n\n\nGeman, Stuart, e Donald Geman. 1984. ¬´Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images¬ª. IEEE Transactions on pattern analysis and machine intelligence 6: 721‚Äì41.\n\n\nHastings, W. Keith. 1970. ¬´Monte Carlo sampling methods using Markov chains and their applications¬ª. Biometrika 57 (1): 97‚Äì109.\n\n\nHoffman, Matthew D, Andrew Gelman, et al. 2014. ¬´The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.¬ª Journal of Machine Learning Research 15 (1): 1593‚Äì623.\n\n\nMetropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, e Edward Teller. 1953. ¬´Equation of state calculations by fast computing machines¬ª. The Journal of Chemical Physics 21 (6): 1087‚Äì92.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html",
    "href": "chapters/mcmc/02_stan_beta_binomial.html",
    "title": "44¬† Linguaggio Stan",
    "section": "",
    "text": "44.1 Introduzione\nStan implementa una versione pi√π efficiente dell‚Äôalgoritmo di Metropolis (Capitolo 43) chiamata Hamiltonian Monte Carlo (HMC), che viene ulteriormente ottimizzata in Stan attraverso l‚Äôalgoritmo NUTS (No-U-Turn Sampler). Sebbene l‚Äôalgoritmo di Metropolis e NUTS producano la stessa soluzione finale, l‚Äôalgoritmo di Metropolis richiede un numero molto maggiore di iterazioni per raggiungere una condizione di equilibrio, dove i valori prodotti possono essere considerati equivalenti a un campione casuale estratto dalla distribuzione a posteriori desiderata. Questo aspetto diventa particolarmente critico nei modelli complessi, dove la convergenza pu√≤ richiedere un grande numero di iterazioni, comportando tempi di calcolo molto lunghi. Di conseguenza, l‚Äôefficienza del campionamento diventa essenziale.\nDal punto di vista concettuale, ci√≤ che l‚Äôalgoritmo di Metropolis e NUTS producono √® sostanzialmente lo stesso: una catena di campioni che riflette la distribuzione a posteriori target. La differenza principale risiede nella velocit√† con cui NUTS raggiunge questo obiettivo, rendendolo una scelta preferibile per modelli complessi.\nNel presente capitolo, introdurremo un linguaggio di programmazione probabilistica (PPL) denominato Stan. Stan permette di estrarre campioni da distribuzioni di probabilit√† costruendo una catena di Markov, la cui distribuzione di equilibrio (o stazionaria) coincide con la distribuzione desiderata. Il nome del linguaggio onora Stanislaw Ulam, uno dei pionieri del metodo Monte Carlo. Una presentazione dettagliata del linguaggio Stan √® fornita nella sezione Appendice P. In questo capitolo, utilizzeremo Stan per fare inferenza su una proporzione.\nIl linguaggio Stan √® compatibile con diverse piattaforme e offre varie interfacce, tra cui R, Python e Julia. In questo corso, utilizzeremo CmdStanPy, un‚Äôinterfaccia pensata specificamente per gli utenti di Python. CmdStanPy √® un pacchetto scritto in Python3 che funge da wrapper per CmdStan, l‚Äôinterfaccia a riga di comando per Stan, scritta in C++. Di conseguenza, oltre a Python3, CmdStanPy richiede un toolchain C++ per compilare ed eseguire i modelli Stan.\nLe istruzioni per installare CmdStanPy e i componenti necessari di CmdStan dal repository conda-forge sono descritte nell‚ÄôAppendice E.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#stan-e-la-programmazione-probabilistica",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#stan-e-la-programmazione-probabilistica",
    "title": "44¬† Linguaggio Stan",
    "section": "44.2 Stan e la Programmazione Probabilistica",
    "text": "44.2 Stan e la Programmazione Probabilistica\nStan si configura come un PPL concepito per definire modelli statistici complessi e effettuare inferenze su di essi. Un PPL consente di esprimere modelli probabilistici in modo conciso e di utilizzare algoritmi avanzati per l‚Äôinferenza. Ci√≤ risulta particolarmente utile nell‚Äôinferenza bayesiana, dove si aggiornano le distribuzioni a priori con dati osservati per ottenere distribuzioni a posteriori.\n\n44.2.1 Struttura di un Programma Stan\nUn programma Stan richiede la specificazione di variabili e parametri, definendo le distribuzioni a priori dei parametri del modello statistico e la funzione di verosimiglianza. In sostanza, un programma Stan descrive l‚Äôinterazione tra dati e parametri e le distribuzioni probabilistiche che li governano. Questo consente di effettuare inferenze sulle distribuzioni a posteriori dei parametri del modello, dedotte dai dati osservati e dalle distribuzioni a priori.\n\n\n44.2.2 Esecuzione di un Programma Stan\nUn programma Stan utilizza metodi Monte Carlo a catena di Markov (MCMC) per generare campioni dalle distribuzioni a posteriori. √à inoltre possibile impiegare metodi approssimativi, noti come ‚Äúinferenza variazionale‚Äù, che forniscono stime delle distribuzioni a posteriori.\nStan pu√≤ generare dati attraverso procedure pseudo-casuali in due contesti principali: nel caso delle simulazioni in avanti, dove i dati vengono simulati a partire dai parametri del modello noti, e nel caso del problema inverso, in cui, partendo dai dati osservati e dalle distribuzioni a priori, si stima la distribuzione a posteriori dei parametri del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#simulazione-in-avanti",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#simulazione-in-avanti",
    "title": "44¬† Linguaggio Stan",
    "section": "44.3 Simulazione in Avanti",
    "text": "44.3 Simulazione in Avanti\nLa simulazione in avanti consiste nella generazione di dati simulati a partire da un insieme di parametri noti di un modello probabilistico. In altri termini, date determinate assunzioni sui parametri di un modello, si utilizza la simulazione in avanti per prevedere i possibili risultati.\nAd esempio, consideriamo uno studio clinico con \\(N\\) soggetti e una probabilit√† \\(\\theta\\) di esito positivo per ciascun soggetto. Conoscendo il valore di \\(\\theta\\) e il numero di soggetti \\(N\\), possiamo impiegare una distribuzione binomiale per simulare il numero di pazienti che avranno un esito positivo. Questo processo ci consente di generare dati che riflettono le nostre assunzioni sui parametri del modello.\nIn notazione statistica, questo si esprime come:\n\\[\nY \\sim \\text{Binomiale}(N, \\theta)\n\\]\ndove \\(Y\\) rappresenta il numero di esiti positivi su \\(N\\) pazienti, con probabilit√† \\(\\theta\\) di esito positivo per ciascun paziente.\nSupponiamo di avere \\(N = 100\\) soggetti in uno studio clinico e un tasso di successo \\(\\theta = 0.3\\). Possiamo simulare un risultato \\(Y\\) generando casualmente il numero di soggetti con esito positivo. Utilizzando una distribuzione binomiale, possiamo calcolare la probabilit√† di ottenere esattamente \\(y\\) esiti positivi su \\(N\\) tentativi:\n\\[\np(Y = y \\mid N, \\theta) = \\binom{N}{y} \\cdot \\theta^y \\cdot (1 - \\theta)^{N - y}.\n\\]\nQuesta espressione ci permette di calcolare la probabilit√† di ottenere un certo numero di successi, dato il numero di soggetti e la probabilit√† di successo.\nIn altre parole, possiamo utilizzare Stan per generare valori casuali da una distribuzione binomiale, proprio come abbiamo fatto in precedenza utilizzando librerie Python come numpy. Ad esempio, in Python possiamo generare valori casuali da una distribuzione binomiale con numpy nel seguente modo:\n\n# Genera 20 valori casuali da una distribuzione binomiale con n=100 e p=0.3\nrandom_values = np.random.binomial(n=100, p=0.3, size=20)\nprint(random_values)\n\n[38 18 23 33 23 35 34 23 27 30 27 29 29 27 29 27 34 29 34 27]\n\n\nCon Stan, possiamo ottenere un risultato simile ma all‚Äôinterno di un contesto pi√π ampio, ad esempio, durante l‚Äôesecuzione di un modello di inferenza bayesiana che utilizza la distribuzione binomiale come parte di un modello probabilistico. Questo ci permette di integrare la generazione di valori casuali con la stima dei parametri e altre analisi complesse in un‚Äôunica procedura.\n\n44.3.1 Un Primo Programma in Stan: Generazione di Dati Casuali\nSupponiamo di voler generare valori casuali \\(Y\\) da una distribuzione binomiale con parametri \\(N = 100\\) e \\(\\theta = 0.3\\). Questo pu√≤ essere realizzato utilizzando il seguente programma Stan:\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0, upper=1&gt; theta;\n}\n\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y;\n  y = binomial_rng(N, theta);\n}\n\n\n44.3.2 Organizzazione di un Programma Stan\nLa prima cosa da notare √® che un programma Stan √® strutturato in blocchi. In questo esempio, abbiamo due blocchi principali: il blocco dei dati (data), che contiene le dichiarazioni delle variabili da fornire come input, e il blocco delle quantit√† generate (generated quantities), che non solo dichiara le variabili, ma assegna anche dei valori. In questo programma Stan, la variabile y viene assegnata come risultato di una singola estrazione da una distribuzione \\(\\textrm{binomiale}(N, \\theta)\\), utilizzando la funzione binomial_rng fornita da Stan.\n\n\n44.3.3 Tipi di Variabili in Stan\nLa seconda cosa da notare √® che in un programma Stan tutte le variabili devono essere dichiarate con tipi specifici. Stan utilizza la tipizzazione statica, il che significa che, a differenza di linguaggi come Python o R, il tipo di una variabile deve essere dichiarato esplicitamente nel programma prima che venga utilizzata, e non viene determinato dinamicamente durante l‚Äôesecuzione in base al valore assegnato. Una volta dichiarato, il tipo di una variabile rimane invariato.\nNel programma in esame, vengono dichiarate tre variabili: N e y, entrambe di tipo int (intero), e theta, di tipo real (numero reale).\n\n\n44.3.4 Vincoli sui Tipi\nLe variabili in Stan possono avere dei vincoli specifici. Ad esempio, poich√© N rappresenta un conteggio, deve essere maggiore o uguale a zero; questo √® indicato con il vincolo lower=0. Allo stesso modo, la variabile y, che rappresenta il numero di successi su N tentativi, deve essere compresa tra 0 e N (inclusi), e questo √® specificato con il vincolo lower=0, upper=N. Infine, la variabile theta, essendo una probabilit√†, deve essere compresa tra 0 e 1, il che viene espresso con il vincolo lower=0, upper=1. Sebbene tecnicamente i limiti per i numeri reali siano aperti, in pratica √® possibile ottenere valori di 0 o 1 a causa di errori di arrotondamento nei calcoli.\n\n\n44.3.5 Esecuzione del Programma Stan\nLa funzione cmdstan_model() crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan. In background, CmdStan traduce un programma Stan in C++ e creare un eseguibile compilato.\n\nstan_file = os.path.join(project_directory, \"stan\", \"binomial-rng.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0, upper=1&gt; theta;\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y = binomial_rng(N, theta);\n}\n\n\n\nDurante l‚Äôesecuzione, il programma Stan compilato richiede i valori di N e theta. Ad ogni iterazione, il programma campiona un valore di y utilizzando il suo generatore di numeri pseudocasuali integrato. I valori di N e theta devono essere forniti in un dizionario Python.\n\nN = 100\ntheta = 0.3\ndata = {\n    'N': N, \n    'theta': theta\n}\n\nInfine campioniamo dal modello utilizzando il metodo sample di CmdStanModel.\n\ntrace = model.sample(\n    data=data, \n    seed=123, \n    chains=1,\n    iter_sampling=20, \n    iter_warmup=1,\n    show_progress=False, \n    show_console=False\n)\n\nNell‚Äôinterfaccia Python, il metodo sample() accetta i seguenti argomenti:\n\ndata: i dati letti nel blocco dati del programma Stan,\nseed: generatore di numeri pseudocasuali per la riproducibilit√†,\nchains: il numero di simulazioni da eseguire (parallel_chains indica quante eseguire in parallelo),\niter_sampling: numero di estrazioni (cio√®, dimensione del campione) da restituire,\niter_warmup: numero di iterazioni di riscaldamento per tarare i parametri dell‚Äôalgoritmo di campionamento (non necessari qui, quindi impostato a 0),\nshow_progress: se True, stampa aggiornamenti di progresso,\nshow_console: apre un monitor di progresso GUI.\n\nIl risultato della chiamata a sample() sull‚Äôistanza del modello viene assegnato alla variabile trace e contiene le 20 estrazioni richieste con l‚Äôargomento iter_sampling = 20.\nQuando si chiama model.sample(...), CmdStan esegue Stan come programma C++ autonomo in un processo in background. Questo programma inizia copiando i dati forniti nell‚Äôargomento data di Python in un file, quindi legge quel file di dati per costruire un oggetto C++ che rappresenta il modello statistico. Poich√© il nostro programma Stan ha solo un blocco di quantit√† generate, l‚Äôunico compito rimanente della classe C++ √® generare il numero richiesto di estrazioni. Per ciascuna delle estrazioni specificate da iter_sampling, Stan utilizza un generatore di numeri pseudocasuali per ottenere un valore dalla distribuzione binomiale specificata.\nLa generazione di numeri casuali √® determinata dal valore seed specificato nella chiamata.\n\n\n44.3.6 Estrazione dei Risultati\nUna volta completato il campionamento, possiamo estrarre il campione di 20 valori per la variabile scalare y sotto forma di array e quindi stampare i loro valori insieme ai valori delle variabili di input.\n\ny = trace.stan_variable('y')\nprint(\"N =\", N, \";  theta =\", theta, \";  y =\", *y.astype(int))\n\nN = 100 ;  theta = 0.3 ;  y = 28 34 31 29 26 25 31 28 30 36 29 36 37 27 29 23 29 34 30 42",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#il-problema-inverso",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#il-problema-inverso",
    "title": "44¬† Linguaggio Stan",
    "section": "44.4 Il Problema Inverso",
    "text": "44.4 Il Problema Inverso\nIl problema inverso consiste nella stima dei parametri del modello, come la probabilit√† di successo \\(\\theta\\), dato un insieme di dati osservati. Iniziamo con il caso pi√π semplice, quello dei dati fittizi dell‚Äôesperimento con il compito Go-No Go in cui abbiamo osservato 6 successi in 9 prove. Inoltre, abbiamo imposto una distribuzione a priori uniforme sul parametro \\(\\theta\\) (probabilit√† di riuscire ad inibire la risposta in una prova No Go).\nAbbiamo un campione di dati con \\(N = 9\\) tentativi e \\(y = 6\\) successi. L‚Äôobiettivo √® stimare \\(\\theta\\), la probabilit√† di successo.\nNell‚Äôapproccio bayesiano, si specifica una distribuzione a priori per \\(\\theta\\). Supponiamo di utilizzare una distribuzione Beta(\\(\\alpha\\), \\(\\beta\\)) come prior per \\(\\theta\\), dove \\(\\alpha\\) e \\(\\beta\\) rappresentano la forza delle convinzioni precedenti sui successi e insuccessi rispettivamente.\nLa distribuzione a posteriori di \\(\\theta\\) dato il risultato osservato \\(y\\) segue una distribuzione Beta con parametri aggiornati, che si ottiene sommando \\(y\\) a \\(\\alpha\\) e \\(N-y\\) a \\(\\beta\\). Questa √® una propriet√† ben nota delle distribuzioni Beta, che funge da distribuzione coniugata per la distribuzione binomiale.\nQuindi, la distribuzione a posteriori √®:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(\\alpha + y, \\beta + N - y).\n\\]\nSe scegliamo una distribuzione a priori non informativa con \\(\\alpha = 1\\) e \\(\\beta = 1\\), otteniamo:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(1 + 6, 1 + 9 - 6) = \\text{Beta}(7, 4).\n\\]\nLa distribuzione a posteriori di \\(\\theta\\) √® una Beta(7, 4), che riflette l‚Äôinformazione aggiornata a partire dal campione di dati osservati.\nUtilizzando Stan, √® possibile ottenere campioni da questa distribuzione a posteriori per calcolare statistiche riassuntive e effettuare previsioni.\nIn sintesi, la simulazione in avanti e il problema inverso rappresentano due approcci complementari: la simulazione in avanti genera dati simulati da parametri noti, mentre il problema inverso stima i parametri del modello dai dati osservati.\nEcco come possiamo specificare il modello Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"go_nogo_model.stan\")\nmodel_go_nogo = CmdStanModel(stan_file=stan_file)\nprint(model_go_nogo.code())\n\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=0&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  y ~ binomial(N, p); // Likelihood\n  p ~ beta(1, 1); // Prior\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; p_gt_chance = p &gt; 0.5;\n}\n\n\n\nIn questo programma Stan, vediamo che il numero totale di prove (n) e il numero di successi (y) vengono forniti come dati. Successivamente, sono presenti due blocchi aggiuntivi: un blocco dei parametri, utilizzato per dichiarare i valori sconosciuti (in questo caso, la probabilit√† di rispondere correttamente, p), e un blocco del modello, dove vengono specificate la distribuzione a priori e la verosimiglianza. Stan calcola la distribuzione a posteriori combinando queste due componenti. Inoltre, √® presente un blocco delle quantit√† generate in cui viene calcolata una variabile booleana che indica se la probabilit√† di risposta corretta √® maggiore di 0.5.\nIl modello bayesiano e la sua implementazione in Stan ci permettono di affrontare il problema inverso: inferire la probabilit√† di una risposta corretta (inibizione nelle prove No-Go) a partire dai dati osservati. Utilizzando Stan, possiamo stimare non solo la probabilit√† di rispondere correttamente nelle prove No-Go, ma anche la probabilit√† che tale probabilit√† sia superiore al valore atteso per caso (p_gt_chance).\n\n44.4.1 Campionare dalla Distribuzione a Posteriori\nQuando eseguiamo un programma Stan, vengono generati campioni casuali che approssimano la distribuzione a posteriori. Con l‚Äôaumentare del numero di campioni, questi si avvicinano sempre pi√π a veri campioni della distribuzione a posteriori.\nStan utilizza un algoritmo Markov Chain Monte Carlo (MCMC), che pu√≤ introdurre autocorrelazione tra i campioni, cio√® i campioni successivi sono correlati tra loro. Sebbene l‚Äôautocorrelazione non crei bias, pu√≤ aumentare la varianza delle stime, rendendo meno precise le stime nei modelli pi√π complessi.\nPer migliorare l‚Äôefficienza del campionamento, specialmente nei modelli ad alta dimensionalit√†, Stan utilizza un algoritmo chiamato No-U-Turn Sampler (NUTS), che √® una versione avanzata dell‚ÄôHamiltonian Monte Carlo (HMC). NUTS pu√≤ generare campioni anti-correlati, riducendo la varianza e migliorando la precisione delle stime rispetto ai campioni indipendenti.\n\n\n44.4.2 Compilazione del Codice Stan\nPer utilizzare Stan, dobbiamo compilare il codice del modello. Questo crea un file eseguibile che, nel nostro caso, abbiamo chiamato model_go_nogo:\nmodel_go_nogo = CmdStanModel(stan_file=stan_file)\nInseriamo i dati richiesti in un dizionario.\n\nstan_data = {\"N\": 9, \"y\": 6}\nprint(stan_data)\n\n{'N': 9, 'y': 6}\n\n\nEseguiamo il campionamento con la seguente chiamata:\n\nfit = model_go_nogo.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    chains=4, \n    parallel_chains=4,\n    show_progress=False,\n    show_console=False,\n)\n\nIl metodo .sample() viene applicato al file eseguibile del modello Stan che abbiamo compilato e nominato model_go_nogo.\nAssumendo una distribuzione a priori per il parametro p, l‚Äôalgoritmo procede iterativamente, aggiornando la distribuzione a priori di p condizionandola ai valori gi√† generati. Dopo un certo numero di iterazioni, l‚Äôalgoritmo raggiunge la convergenza, e i valori estratti possono essere considerati campioni dalla distribuzione a posteriori di p.\nAll‚Äôinizio del campionamento, la distribuzione dei campioni pu√≤ essere significativamente diversa dalla distribuzione stazionaria. Questo periodo iniziale √® chiamato ‚Äúburn-in‚Äù. Durante il burn-in, i campioni possono non rappresentare accuratamente la distribuzione a posteriori e vengono tipicamente scartati. Con l‚Äôaumentare del numero di iterazioni, la distribuzione dei campioni si avvicina sempre pi√π alla distribuzione target.\nUna volta eseguito il modello in Stan, otteniamo una serie di campioni di p dalla distribuzione a posteriori \\(p(p \\mid N, y)\\). Ogni campione rappresenta un possibile valore di p compatibile con i dati osservati y. Procediamo quindi a estrarre i campioni a posteriori per le variabili p e p_gt_chance.\n\np_draws = fit.stan_variable(\"p\")\np_gt_chance_draws = fit.stan_variable(\"p_gt_chance\")\n\nTracciando un istogramma di questi campioni, possiamo visualizzare dove i valori di p sono pi√π probabili e comprendere meglio la forma della distribuzione a posteriori. L‚Äôistogramma ci fornisce diverse informazioni:\n\nValore pi√π probabile di p: Questo √® il valore intorno al quale i campioni sono pi√π concentrati, noto come la moda della distribuzione.\nDistribuzione dei possibili valori di p: Questo ci d√† un‚Äôidea dell‚Äôincertezza nella stima di p.\n\nSe l‚Äôistogramma √® stretto e concentrato attorno a un valore specifico, significa che c‚Äô√® poca incertezza nella stima di p. In altre parole, possiamo essere abbastanza sicuri che il valore vero di p sia vicino a questo valore. Se l‚Äôistogramma √® largo e distribuito, significa che c‚Äô√® maggiore incertezza nella stima di p. Questo indica che i dati osservati non forniscono una stima precisa e che il valore di p potrebbe variare notevolmente.\n\nplt.hist(\n    p_draws,\n    bins=30,\n    alpha=0.5,\n    density=True,\n)\nplt.title(\"Istogramma della distribizione a posteriori di p\")\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\nCon un numero cos√¨ piccolo di prove la nostra incertezza relativamente al valore vero di \\(p\\) √® enorme. Si noti la corrispondenza tra questo istogramma e quello calcolato ‚Äúmanualmente‚Äù nella Sezione 43.5.3.\nPossiamo anche calcolare la probabilit√† posteriore che la probabilit√† di successo (p) sia superiore al livello di casualit√† (0.5). In altre parole, possiamo stimare la probabilit√† che il soggetto abbia una performance migliore di quella casuale nel compito go/no-go. Questa probabilit√† √® data dalla proporzione di campioni nella distribuzione posteriore di \\(p\\) per cui \\(p\\) √® maggiore di 0.5. Utilizziamo la funzione np.mean() per calcolare la media delle estrazioni di p_gt_chance, che fornisce una stima di questa probabilit√†.\n\nnp.mean(p_gt_chance_draws)\n\n0.821125\n\n\n\nEsempio 44.1 Ora consideriamo una seconda versione del modello Stan, questa volta utilizzando una distribuzione a priori informativa. Prendiamo in esame i dati relativi alla proporzione di artisti della Generazione X presenti al MoMA, dove 14 artisti su un campione di 100 appartenevano a questa generazione. Ci poniamo due obiettivi: (1) calcolare la distribuzione a posteriori per \\(\\theta\\), la probabilit√† che un artista appartenga alla Generazione X, e (2) determinare se la Generazione X √® rappresentata al MoMA con almeno un artista su quattro. Per fare ci√≤, imponiamo una distribuzione a priori Beta(4, 6) su \\(\\theta\\) e utilizziamo Stan per l‚Äôinferenza. Il codice Stan aggiornato √® il seguente.\n\nstan_file = os.path.join(project_directory, \"stan\", \"moma_model.stan\")\nmodel_moma = CmdStanModel(stan_file=stan_file)\nprint(model_moma.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0, upper=N&gt; y;\n  int&lt;lower=0&gt; alpha_prior;\n  int&lt;lower=0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y_rep;\n  int&lt;lower=0, upper=1&gt; theta_gt_025 = theta &gt; 0.25;\n  \n  y_rep = binomial_rng(N, theta);\n}\n\n\n\nCreiamo un dizionario con i dati.\n\ndata_moma = {\n    \"N\": 100,\n    \"y\": 14,\n    \"alpha_prior\": 4,\n    \"beta_prior\": 6\n}\nprint(stan_data)\n\n{'N': 9, 'y': 6}\n\n\nEseguiamo il campionamento.\n\nfit_moma = model_moma.sample(\n    data=data_moma,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nUn grafico con le tracce si ottiene nel modo seguente:\n\n_ = az.plot_trace(fit_moma, var_names=(\"theta\"))\n\n\n\n\n\n\n\n\nCon Stan, possiamo ottenere un riepilogo completo della variabile \\(\\theta\\) nella distribuzione a posteriori. Per fare ci√≤, basta chiamare la funzione .summary() sul campione. Questo riepilogo include tutte le statistiche rilevanti.\n\naz.summary(fit_moma, var_names=(\"theta\"), hdi_prob=0.94, round_to=4)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta\n0.164\n0.0348\n0.103\n0.2309\n0.0006\n0.0005\n2952.633\n3837.07\n1.001\n\n\n\n\n\n\n\n\nSi noti come la stima putuale a posteriori e l‚Äôintervallo di credibilit√† riproducono i valori ottenuti utilizzando l‚Äôalgoritmo di Metropolis nella Sezione 43.6.2.\nIl modello relativo agli artisti della Generazione X √® abbastanza semplice da permettere una soluzione analitica della distribuzione a posteriori:\n\\[\n\\begin{aligned}\n    p(\\theta \\mid y, N) &\\propto p(y \\mid N, \\theta) \\cdot p(\\theta) \\\\\n    &= \\text{binomiale}(y \\mid N, \\theta) \\cdot \\text{beta}(\\theta \\mid 1, 1) \\\\\n    &\\propto \\theta^y \\cdot (1 - \\theta)^{N - y} \\cdot \\theta^{1 - 1} \\cdot (1 - \\theta)^{1 - 1} \\\\\n    &= \\theta^{y} \\cdot (1 - \\theta)^{N - y} \\\\\n    &\\propto \\text{beta}(\\theta \\mid y + 1, N - y + 1).\n\\end{aligned}\n\\]\nQuindi, possiamo concludere che\n\\[\np(\\theta \\mid y, N) = \\text{beta}(\\theta \\mid y + 1, N - y + 1),\n\\]\novvero \\(p(\\theta \\mid y, N) = \\text{beta}(\\theta \\mid 14 + 4, 100 - 14 + 6) = \\text{beta}(18, 92)\\).\nNella figura successiva, possiamo osservare la buona corrispondenza tra le stime a posteriori di \\(\\theta\\) ottenute con Stan e la distribuzione teorica \\(\\text{beta}(18, 92)\\).\n\ntheta_draws = fit_moma.stan_variable(\"theta\")\n\n# Create the histogram of the posterior draws\nplt.hist(\n    theta_draws, bins=30, density=True, alpha=0.5, color=\"blue\", label=\"Posterior draws\"\n)\n\n# Generate the x values for the theoretical Beta(18, 92) distribution\nx = np.linspace(0, 1, 1000)\ny = stats.beta.pdf(x, 18, 92)  # Calculate the PDF of the Beta distribution\n\n# Overlay the theoretical distribution on the histogram\nplt.plot(x, y, \"r-\", lw=2, label=\"Beta(18, 92) theoretical distribution\")\n\n# Add labels and legend\nplt.xlabel(\"Theta\")\nplt.ylabel(\"Density\")\nplt.title(\"Posterior Distribution vs Theoretical Beta(18, 92)\")\nplt.legend()\n\n# Show the plot\nplt.show()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#stime-puntuali-bayesiane",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#stime-puntuali-bayesiane",
    "title": "44¬† Linguaggio Stan",
    "section": "44.5 Stime Puntuali Bayesiane",
    "text": "44.5 Stime Puntuali Bayesiane\nIn termini bayesiani, una stima puntuale per un parametro \\(\\Theta\\) condizionato sui dati osservati \\(Y = y\\) √® un singolo valore \\(\\hat{\\theta} \\in \\mathbb{R}^D\\) che riassume la distribuzione a posteriori \\(p(\\theta \\mid y)\\). La notazione \\(\\hat{\\theta}\\) √® convenzionale nella statistica per indicare una stima di un parametro \\(\\theta\\). In questa sezione definiamo tre stimatori e discutiamo come i due stimatori bayesiani minimizzino una funzione di perdita tra il valore vero e la stima. Torneremo alla funzione di perdita e alle propriet√† degli stimatori dopo averli definiti.\n\n44.5.1 Stimatore della Media Posteriori\nLa stima puntuale bayesiana pi√π comune per un parametro √® la media posteriori,\n\\[\n\\begin{align}\n\\widehat{\\theta}\n&= \\mathbb{E}[\\Theta \\mid Y = y] \\\\\n&= \\int_{\\Theta} \\theta \\cdot p(\\theta \\mid y) \\, \\textrm{d}\\theta \\\\\n&= \\lim_{M \\rightarrow \\infty} \\, \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)} \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)},\n\\end{align}\n\\]\ndove nelle ultime due righe, ogni estrazione √® distribuita approssimativamente secondo la distribuzione a posteriori,\n\\[\n\\theta^{(m)} \\sim p(\\theta \\mid y).\n\\]\nAbbiamo introdotto la notazione di aspettativa condizionale nella prima riga di questa definizione. Le aspettative sono semplicemente medie ponderate, con i pesi dati da una densit√† di probabilit√†. L‚Äôinferenza bayesiana coinvolge aspettative sulla distribuzione a posteriori, la cui notazione concisa √® quella dell‚Äôaspettativa condizionale,\n\\[\n\\mathbb{E}\\!\n\\left[ f(\\Theta) \\mid Y = y \\right]\n= \\int_{\\mathbb{R^N}} f(\\theta) \\cdot p_{\\Theta \\mid Y}(\\theta \\mid y) \\, \\textrm{d}\\theta,\n\\]\ndove \\(\\Theta\\) e \\(Y\\) sono variabili casuali, mentre \\(\\theta\\) e \\(y\\) sono variabili vincolate ordinarie.\nPer il modello dell‚ÄôEsempio¬†44.1, la stima per la proporzione \\(\\theta\\) di artisti della Generazione X condizionata sui dati \\(y\\) osservati nel campione √® calcolata come la media campionaria delle estrazioni per theta.\n\ntheta_hat = np.mean(theta_draws)\nprint(f\"estimated theta = {theta_hat:.3f}\")\n\nestimated theta = 0.164\n\n\n\n\n44.5.2 Stimatore della Mediana Posteriori, Quantili e Intervalli\nUn‚Äôalternativa popolare alla stima puntuale bayesiana √® la mediana posteriori, \\(\\theta^+\\). La mediana √® il valore tale che, per ogni dimensione \\(d \\in 1{:}D\\),\n\\[\n\\Pr[\\Theta_d \\leq \\theta^+_d] = \\frac{1}{2}.\n\\]\nIn altre parole, la mediana √® il valore che divide la distribuzione a posteriori in due parti uguali: il 50% dei campioni √® al di sotto della mediana e il 50% √® al di sopra. La mediana posteriori pu√≤ essere calcolata prendendo la mediana dei campioni dalla distribuzione a posteriori.\nPer il modello dell‚ÄôEsempio¬†44.1, ecco come calcolare la mediana posteriori utilizzando Python:\n\ntheta_plus = np.median(theta_draws)\nprint(f\"estimated (median) theta = {theta_plus:.3f}\")\n\nestimated (median) theta = 0.162\n\n\nPoich√© la distribuzione a posteriori per i dati degli artisti della Generazione X √® quasi simmetrica, la media posteriori e la mediana posteriori sono molto simili.\n\n\n44.5.3 Quantili e Intervalli di Credibilit√†\nOltre alla mediana, possiamo anche calcolare i quantili e gli intervalli di credibilit√† per fornire ulteriori informazioni sulla distribuzione a posteriori. I quantili sono valori che dividono la distribuzione in intervalli con una probabilit√† specificata. Gli intervalli di credibilit√† indicano l‚Äôintervallo entro il quale cade una certa percentuale della distribuzione a posteriori.\nAd esempio, se vogliamo calcolare il quantile al 95% della distribuzione a posteriori, possiamo semplicemente prendere il valore che si trova al 95¬∞ percentile nella sequenza ordinata dei campioni. Di seguito sono riportati i quantili al 5% e al 95% della distribuzione a posteriori del modello dell‚ÄôEsempio¬†44.1, calcolati utilizzando i quantili empirici.\n\nquantile_05 = np.quantile(theta_draws, 0.05)\nquantile_95 = np.quantile(theta_draws, 0.95)\nprint(f\"\"\"0.05 quantile = {quantile_05:.3f};\n0.95 quantile = {quantile_95:.3f}\"\"\")\n\n0.05 quantile = 0.111;\n0.95 quantile = 0.224\n\n\n\n44.5.3.1 Intervalli Posteriori\nInsieme, il quantile al 5% e al 95% ci forniscono i limiti del nostro intervallo di probabilit√† centrale al 90%. Questo intervallo √® definito come l‚Äôintervallo che contiene il 90% della massa di probabilit√† a posteriori, con il 5% della massa rimanente al di sotto dell‚Äôintervallo e il 5% al di sopra.\n\n\n\n44.5.4 Errore di Stima e Bias\nL‚Äôerrore di una stima √® la differenza tra la stima stessa e il valore vero del parametro,\n\\[\n\\textrm{err} = \\hat{\\theta} - \\theta.\n\\]\nLa nostra stima \\(\\hat{\\theta}\\) √® implicitamente una funzione dei dati \\(y\\), quindi anche l‚Äôerrore dipende dai dati. Possiamo rendere esplicita questa dipendenza scrivendo\n\\[\n\\text{err}(y) = \\hat{\\theta}(y) - \\theta.\n\\]\nIl bias di uno stimatore √® definito come l‚Äôerrore atteso, cio√® la media dell‚Äôerrore rispetto alla distribuzione dei dati per la variabile casuale \\(Y\\),\n\\[\n\\begin{align}\n\\text{bias}\n&= \\mathbb{E}[\\text{err}(Y)] \\\\\n&= \\mathbb{E}[\\hat{\\theta}(Y) - \\theta] \\\\\n&= \\int_Y (\\hat{\\theta}(y) - \\theta) \\, \\text{d}y.\n\\end{align}\n\\]\nIn altre parole, il bias misura quanto, in media, la stima \\(\\hat{\\theta}\\) si discosta dal valore vero \\(\\theta\\) considerando tutte le possibili realizzazioni dei dati \\(Y\\). Un bias nullo indica che lo stimatore √® corretto in media, cio√® non tende a sovrastimare o sottostimare il valore vero del parametro.\n\n\n44.5.5 Stimatore della Moda Posteriori\nUno stimatore popolare, sebbene non strettamente bayesiano, √® la moda a posteriori, che rappresenta il valore del parametro \\(\\theta\\) per cui la densit√† a posteriori √® massima. Formalmente, √® definita come:\n\\[\n\\theta^* = \\text{arg max}_\\theta \\ p(\\theta \\mid y).\n\\]\nLa stima \\(\\theta^*\\) √® spesso chiamata stima MAP (Maximum A Posteriori). La moda a posteriori non √® considerata un vero stimatore bayesiano perch√© non tiene conto dell‚Äôincertezza nella stessa misura in cui lo fanno altri metodi bayesiani. In altre parole, non minimizza una funzione di perdita basata sui valori veri dei parametri, ma cerca semplicemente il valore pi√π probabile dato i dati osservati.\n\n\n44.5.6 Caratteristiche della Moda Posteriori\n\nNon considera l‚Äôincertezza: La stima MAP si focalizza solo sul valore pi√π probabile della distribuzione a posteriori, senza tenere conto della variabilit√† dei dati.\nMassimo della densit√† a posteriori: La moda a posteriori rappresenta il punto in cui la densit√† a posteriori raggiunge il suo massimo.\nPossibili limitazioni: La stima MAP potrebbe non esistere in alcuni casi, come nei modelli in cui la densit√† cresce senza limiti. Questo pu√≤ accadere, ad esempio, nei modelli bayesiani gerarchici o in distribuzioni semplici come la distribuzione esponenziale con parametro 1 (\\(\\textrm{esponenziale}(1)\\)).\n\n\n\n44.5.7 Funzioni di Perdita e Propriet√† degli Stimatori\nLa media a posteriori √® uno stimatore bayesiano popolare per due ragioni principali. Primo, √® uno stimatore non distorto, il che significa che ha un bias nullo. Secondo, ha l‚Äôerrore quadratico medio atteso minimo tra tutti gli stimatori non distorti. L‚Äôerrore quadratico di una stima √® definito come:\n\\[\n\\text{err}^2(y) = \\left(\\hat{\\theta}(y) - \\theta\\right)^2.\n\\]\nQuesta √® una funzione di perdita, che misura la differenza tra una stima \\(\\hat{\\theta}\\) e il valore vero \\(\\theta\\). Tuttavia, la media a posteriori potrebbe non esistere se la distribuzione a posteriori ha code molto ampie, come accade nella distribuzione di Cauchy standard.\n\n\n44.5.8 Propriet√† della Mediana Posteriori\nLa mediana a posteriori \\(\\theta^+\\) ha tre propriet√† interessanti:\n\nSempre ben definita: La mediana a posteriori √® sempre ben definita, anche per densit√† con poli o code molto ampie.\nMinimizzazione dell‚Äôerrore assoluto atteso: La mediana minimizza l‚Äôerrore assoluto atteso, il che la rende robusta.\nRobustezza ai valori anomali: La mediana √® meno sensibile ai valori anomali rispetto alla media, perch√© minimizza l‚Äôerrore assoluto anzich√© l‚Äôerrore quadrato.\n\n\n\n44.5.9 Concentrazione sulle Medie a Posteriori\nIn questa introduzione a Stan, ci concentreremo principalmente sulle medie a posteriori. La media a posteriori non solo fornisce una stima non distorta, ma minimizza anche l‚Äôerrore quadratico medio atteso, rendendola uno strumento potente per l‚Äôinferenza bayesiana. Tuttavia, √® importante essere consapevoli delle sue limitazioni, specialmente in presenza di distribuzioni a posteriori con code molto ampie.\n\n\n44.5.10 Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo\nQuando utilizziamo un campionatore di catene di Markov per stimare parametri, otteniamo una sequenza di campioni casuali. Questa sequenza √® essa stessa una variabile casuale, perch√© √® composta da molte variabili casuali. A causa di questa natura casuale, ogni esecuzione del campionatore pu√≤ produrre risultati leggermente diversi, introducendo quello che √® noto come errore Monte Carlo.\nL‚Äôerrore Monte Carlo √® l‚Äôerrore introdotto dal fatto che utilizziamo solo un numero finito di campioni (\\(M\\)) per stimare i parametri. Questo tipo di errore si verifica perch√©, con un numero limitato di campioni, non possiamo catturare perfettamente l‚Äôintera distribuzione a posteriori.\n\n44.5.10.1 Errore Standard di Monte Carlo (MCMC)\nStan riporta l‚Äôerrore standard di Monte Carlo (MCMC) insieme alle stime della media. L‚Äôerrore standard MCMC per un parametro scalare $ _d $ √® definito come:\n\\[\n\\text{mcmc-se} = \\frac{\\textrm{sd}[\\Theta_d \\mid Y = y]}{\\sqrt{N^{\\text{eff}}}},\n\\]\ndove:\n\n\\(\\text{sd}[\\Theta_d \\mid Y = y]\\) √® la deviazione standard del parametro \\(\\theta_d\\) nella distribuzione a posteriori.\n\\(N^{\\text{eff}}\\) √® la dimensione del campione effettivo, che riflette il numero di campioni indipendenti equivalenti ottenuti dal campionatore.\n\n\n\n44.5.10.2 Dimensione del Campione Effettivo\nNel teorema del limite centrale, la dimensione del campione (numero di estrazioni indipendenti) appare al posto di \\(N^{\\text{eff}}\\). Tuttavia, nel contesto delle catene di Markov, i campioni successivi sono correlati tra loro. La dimensione del campione effettivo (\\(N^{\\text{eff}}\\)) tiene conto di questa correlazione e rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle nostre estrazioni correlate.\nLa dimensione del campione effettivo per un campione di dimensione \\(M\\) √® definita come:\n\\[\nN^{\\text{eff}} = \\frac{M}{\\text{IAT}},\n\\]\ndove \\(\\text{IAT}\\) √® il tempo di autocorrelazione integrata. Sebbene non sia definito formalmente qui, pu√≤ essere considerato come l‚Äôintervallo tra estrazioni effettivamente indipendenti nella nostra catena di Markov. Se l‚Äôautocorrelazione √® bassa, \\(\\text{IAT}\\) sar√† vicino a 1; se l‚Äôautocorrelazione √® alta, \\(\\text{IAT}\\) sar√† molto pi√π alto.\nIn sintesi, \\(N^{\\text{eff}}\\) rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle estrazioni correlate della nostra catena di Markov.\nIn conclusione, l‚Äôerrore standard di Monte Carlo (MCMC) fornisce una misura di quanto varierebbero le nostre stime se ripetessimo il processo di campionamento pi√π volte. √à un indicatore dell‚Äôaffidabilit√† delle nostre stime, tenendo conto della casualit√† introdotta dall‚Äôutilizzo di un numero finito di campioni. Conoscere questo errore ci aiuta a valutare la precisione delle nostre stime e a comprendere meglio l‚Äôincertezza associata ai risultati ottenuti tramite il campionamento di catene di Markov.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#stima-delle-probabilit√†-di-evento",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#stima-delle-probabilit√†-di-evento",
    "title": "44¬† Linguaggio Stan",
    "section": "44.6 Stima delle Probabilit√† di Evento",
    "text": "44.6 Stima delle Probabilit√† di Evento\nNella seconda domanda dell‚ÄôEsempio¬†44.1, non stiamo cercando un valore specifico per \\(\\theta\\), ma vogliamo sapere qual √® la probabilit√† che \\(\\theta\\) sia maggiore di \\(\\frac{1}{4}\\) dopo aver osservato \\(y\\) artisti della Generazione X su un totale di \\(N\\) = 100 artisti. In termini probabilistici, stiamo cercando di stimare la probabilit√† di un evento.\nUn sottoinsieme di valori di un parametro definisce un evento. Ad esempio, la condizione \\(\\theta &gt; \\frac{1}{4}\\) pu√≤ essere espressa come l‚Äôevento:\n\\[ A = \\left\\{ \\theta \\in \\Theta : \\theta &gt; \\frac{1}{4} \\right\\}. \\]\nLa probabilit√† dell‚Äôevento \\(A\\), cio√® che la proporzione di artisti della Generazione X sia maggiore di 0.25, pu√≤ essere calcolata come \\(\\Pr\\!\\left[\\Theta &gt; \\frac{1}{4} \\, \\big| \\, N, y\\right]\\).\n\n44.6.1 Probabilit√† di Evento tramite Indicatori\nLa funzione indicatrice \\(\\textrm{I}\\) assegna il valore 1 alle proposizioni vere e 0 a quelle false. Ad esempio, \\(\\textrm{I}(\\theta &gt; \\frac{1}{4}) = 1\\) se \\(\\theta &gt; 0.25\\) √® vero.\nLe probabilit√† di evento sono definite come aspettative condizionali posteriori delle funzioni indicatrici:\n\\[\n\\begin{align}\n\\Pr[\\Theta &gt; 0.25 \\mid N, y]\n&= \\mathbb{E}\\!\\left[\\textrm{I}[\\Theta &gt; 0.25] \\mid N, y\\right] \\\\\n&= \\int_{\\Theta} \\textrm{I}(\\theta &gt; 0.25) \\cdot p(\\theta \\mid N, y) \\, \\textrm{d}\\theta \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\textrm{I}(\\theta^{(m)} &gt; 0.25),\n\\end{align}\n\\]\ndove \\(\\theta^{(m)}\\) rappresenta i campioni dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\).\nIn Stan, possiamo codificare questa funzione indicatrice direttamente e assegnarla a una variabile nel blocco generated quantities.\nPer rispondere alla seconda domanda dell‚ÄôEsempio¬†44.1, possiamo aggiungere la seguente linea di codice nel blocco generated quantities:\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; theta_gt_025 = theta &gt; 0.25;\n}\nQuesta espressione assume il valore 1 se theta &gt; 0.25 √® vero e 0 se √® falso. In notazione matematica, questa funzione indicatrice sarebbe scritta come \\(\\textrm{I}(\\theta &gt; 0.25)\\). In Stan, l‚Äôoperatore &gt; restituisce 0 o 1, quindi possiamo semplicemente scrivere theta &gt; 0.25.\nLa media a posteriori della variabile theta_gt_025 rappresenta quindi la nostra stima per \\(\\Pr[\\theta &gt; 0.25 \\mid N, y]\\).\n\ntheta_gt_025_draws = fit_moma.stan_variable(\"theta_gt_025\")\nPr_theta_gt_025 = np.mean(theta_gt_025_draws)\nprint(f\"estimated Pr[theta &gt; 0.25] = {Pr_theta_gt_025:.4f}\")\n\nestimated Pr[theta &gt; 0.25] = 0.0119\n\n\nTale valore √® approssimativamente uguale a 1.2%. Possiamo dunque rigettare l‚Äôidea che almeno un artista su quattro tra quelli rappresentati al MoMA appartenga alla Generazione X.\n\n\n44.6.2 Diagnostiche del Campionamento\nL‚Äôistruzione print(fit_moma.diagnose()) in Stan viene utilizzata per eseguire una diagnosi completa del campionamento MCMC. Questa funzione fornisce una serie di statistiche diagnostiche che aiutano a valutare la qualit√† e la convergenza del campionamento.\nQuesti sono alcuni degli aspetti che possono essere diagnosticati:\n\nConvergenza: La diagnosi verifica se le catene di Markov sono convergenti, ad esempio controllando il valore di \\(\\hat{R}\\). Un valore di \\(\\hat{R}\\) vicino a 1 indica che le catene sono ben mescolate e convergenti.\nAutocorrelazione: Fornisce informazioni sull‚Äôautocorrelazione delle catene, che pu√≤ influire sull‚Äôefficienza del campionamento. Bassa autocorrelazione √® desiderabile per ottenere campioni indipendenti.\nEfficienza del campionamento: Viene calcolata la dimensione del campione effettivo (\\(N_{\\text{eff}}\\)), che indica quanti campioni indipendenti equivarrebbero ai campioni correlati ottenuti.\nVarianza e Deviazione Standard: Viene riportata la varianza e la deviazione standard dei campioni, aiutando a comprendere la distribuzione a posteriori del parametro.\n\nPer il modello dell‚ÄôEsempio¬†44.1 abbiamo:\n\nprint(fit_moma.diagnose())\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp0ej9isqe/moma_modelg7wkz2hg/moma_model-20240820100852_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp0ej9isqe/moma_modelg7wkz2hg/moma_model-20240820100852_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp0ej9isqe/moma_modelg7wkz2hg/moma_model-20240820100852_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp0ej9isqe/moma_modelg7wkz2hg/moma_model-20240820100852_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#riscaldamento-e-monitoraggio-della-convergenza",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#riscaldamento-e-monitoraggio-della-convergenza",
    "title": "44¬† Linguaggio Stan",
    "section": "44.7 Riscaldamento e monitoraggio della convergenza",
    "text": "44.7 Riscaldamento e monitoraggio della convergenza\nQuando si eseguono catene di Markov, √® importante assicurarsi che i campioni siano approssimativamente estratti dalla distribuzione a posteriori. Un modo standard per monitorare la convergenza √® avviare pi√π catene di Markov con inizializzazioni diverse (idealmente scelte da una distribuzione iniziale diffusa) e misurare se stanno producendo campioni dalla stessa distribuzione.\n\n44.7.1 Riscaldamento\nNelle fasi iniziali del riscaldamento, Stan cerca di individuare la regione di alta probabilit√† da cui estrarre campioni, ottimizzare la dimensione del passo e stimare la varianza a posteriori. La varianza stimata viene utilizzata per migliorare l‚Äôefficienza del campionatore attraverso un processo noto come ‚Äúprecondizionamento‚Äù. Il precondizionamento implica il ridimensionamento dei parametri per rendere il campionamento pi√π efficiente.\nStan √® anche in grado di stimare una matrice di covarianza completa, che cattura le relazioni tra tutti i parametri del modello. Con l‚Äôausilio di questa matrice, Stan pu√≤ eseguire rotazioni e ridimensionamenti dei parametri, operazioni che facilitano un campionamento pi√π efficace. Nel contesto di Stan, ‚Äúrotazione e scalatura‚Äù si riferiscono alla trasformazione dei parametri in una nuova base (rotazione) e alla regolazione delle loro scale (scalatura), ottimizzando cos√¨ il processo di campionamento e rendendolo pi√π veloce e affidabile. Per un approfondimento su questi processi, si pu√≤ consultare Neal (2011).\nIl riscaldamento si considera concluso quando la dimensione del passo e le stime della covarianza a posteriori si stabilizzano. Con pi√π catene, √® possibile verificare che tutte convergano verso una dimensione del passo e una stima della covarianza simili. Di solito, non si misura la convergenza dell‚Äôadattamento in s√©, ma piuttosto si valuta se i campioni a posteriori ottenuti dopo il riscaldamento sono ragionevoli.\nDurante la fase di riscaldamento, Stan non produce una catena di Markov coerente poich√© si adatta dinamicamente alle condizioni del modello per trovare i parametri di campionamento ottimali. Tuttavia, una volta completato il riscaldamento e avviata la fase di campionamento, Stan inizia a generare una vera e propria catena di Markov.\nLe nostre analisi a posteriori si basano esclusivamente sui campioni raccolti durante la fase di campionamento, escludendo quelli ottenuti durante il riscaldamento. Tuttavia, √® possibile salvare ed esaminare i campioni del riscaldamento per comprendere meglio come √® avvenuto il processo di adattamento e identificare eventuali problematiche.\n\n\n44.7.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)\nStan utilizza la statistica di riduzione potenziale della scala, nota come \\(\\widehat{R}\\) (pronunciata ‚ÄúR hat‚Äù), per valutare la convergenza delle catene di Markov. Questa statistica serve a verificare se le catene indipendenti stanno campionando dalla stessa distribuzione a posteriori.\nPer calcolare \\(\\widehat{R}\\), Stan esegue i seguenti passaggi:\n\nOgni catena di Markov viene divisa a met√† per controllare la coerenza tra la prima met√† e la seconda met√† della catena. Questo consente di rilevare se la catena si √® stabilizzata o se ci sono ancora problemi di convergenza.\nVengono calcolate due varianze:\n\nLa varianza all‚Äôinterno delle catene (intra-chain variance), che misura la variabilit√† dei campioni all‚Äôinterno di ciascuna met√† della catena.\nLa varianza tra le catene (inter-chain variance), che misura la variabilit√† tra le diverse catene.\n\nLa statistica \\(\\widehat{R}\\) confronta la varianza tra le catene con la varianza all‚Äôinterno delle catene. Se le catene sono convergenti, ci si aspetta che queste varianze siano simili.\n\nQuando \\(\\widehat{R}\\) si avvicina a 1, indica che le catene di Markov stanno campionando dalla stessa distribuzione, suggerendo che la convergenza √® stata raggiunta. Un valore di \\(\\widehat{R}\\) significativamente maggiore di 1, invece, indica che le catene non hanno ancora raggiunto la convergenza, suggerendo la necessit√† di un‚Äôulteriore fase di riscaldamento o di una revisione del modello.\n\n\n44.7.3 Quante catene per quanto tempo?\nUna regola pratica per valutare la convergenza di una catena di Markov √® eseguire quattro catene fino a quando \\(\\widehat{R}\\) non scende sotto 1.01 e la dimensione campionaria effettiva (ESS) supera 100. L‚Äôobiettivo di avere un ESS di almeno 100 √® legato al fatto che, con questo numero di campioni, l‚Äôerrore standard delle stime √® ridotto a circa un decimo della deviazione standard. Dato che la deviazione standard a posteriori rappresenta l‚Äôincertezza residua, ottenere stime ancora pi√π precise raramente aggiunge valore significativo.\nPer raggiungere questi obiettivi, un metodo semplice √® iniziare con 100 iterazioni di riscaldamento e 100 iterazioni di campionamento. Se \\(\\widehat{R}\\) √® ancora troppo alto o se l‚ÄôESS √® troppo basso, si pu√≤ raddoppiare il numero di iterazioni di riscaldamento e di campionamento e riprovare. √à importante avere un riscaldamento sufficientemente lungo perch√© un campionamento efficiente richiede che il modello abbia raggiunto la convergenza durante questa fase. Usare lo stesso numero di iterazioni per il riscaldamento e il campionamento potrebbe risultare in un costo computazionale massimo doppio rispetto all‚Äôottimo, ma questo ottimo non √® prevedibile in anticipo.\nSe si decide di utilizzare pi√π di quattro catene, √® essenziale che l‚ÄôESS per ogni catena sia almeno 25. Questo requisito non √® tanto per la qualit√† dell‚Äôinferenza quanto per garantire la fiducia nell‚Äôaccuratezza dello stimatore ESS, che diventa inaffidabile con valori troppo bassi. Un modo per verificare la correttezza dello stimatore ESS √® raddoppiare il numero di campioni e controllare se anche l‚ÄôESS raddoppia di conseguenza. Se ci√≤ non accade, la stima iniziale dell‚ÄôESS potrebbe non essere accurata.\n\n\n44.7.4 Esecuzione delle catene contemporaneamente\n√à possibile impostare il numero di catene da eseguire utilizzando l‚Äôargomento chains del metodo sample(). Inoltre, √® possibile controllare quante catene possono essere eseguite contemporaneamente con l‚Äôargomento parallel_cores (che per default √® impostato su 1, ovvero esecuzione sequenziale).\nSe il numero massimo di catene parallele √® impostato troppo basso, le risorse della CPU potrebbero non essere sfruttate appieno. Al contrario, se √® impostato troppo alto, la CPU o la memoria potrebbero diventare il collo di bottiglia, rallentando le prestazioni complessive rispetto all‚Äôesecuzione con un numero inferiore di catene parallele.\nIn progetti personali sul nostro hardware, l‚Äôobiettivo √® solitamente ottenere la massima dimensione campionaria effettiva nel minor tempo possibile. Tuttavia, a volte √® necessario lasciare abbastanza potenza di elaborazione per continuare a lavorare su altre attivit√† come documenti, email, ecc.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#considerazioni-conclusive",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#considerazioni-conclusive",
    "title": "44¬† Linguaggio Stan",
    "section": "44.8 Considerazioni Conclusive",
    "text": "44.8 Considerazioni Conclusive\nIn conclusione, l‚Äôutilizzo di Stan per generare campioni casuali dalla distribuzione a posteriori dei parametri in un modello bayesiano rappresenta un potente strumento per l‚Äôinferenza statistica, specialmente quando ci si confronta con modelli complessi. La capacit√† di eseguire estrazioni indipendenti ci ha permesso di calcolare stime delle aspettative, fornendo un mezzo robusto per gestire l‚Äôincertezza nella stima dei parametri.\nIl calcolo bayesiano, che integra intrinsecamente l‚Äôincertezza, si basa spesso su aspettative che si traducono in integrali difficili da risolvere analiticamente. Tuttavia, l‚Äôapplicazione dei metodi Monte Carlo a catena di Markov (MCMC) consente di superare questa difficolt√†, trasformando integrali complessi in somme di campioni generati dalle distribuzioni a posteriori. Questo approccio non solo rende il problema computazionalmente trattabile, ma apre anche la strada all‚Äôanalisi di modelli che altrimenti sarebbero inaccessibili.\nCome abbiamo visto nella sezione Appendice O, anche problemi concettualmente semplici, come l‚Äôaspettativa di una variabile indicatrice discreta, possono essere risolti efficacemente tramite simulazioni Monte Carlo, dimostrando l‚Äôampia applicabilit√† di questi metodi.\nIn definitiva, i metodi MCMC, e in particolare l‚ÄôHamiltonian Monte Carlo implementato in Stan, rappresentano una rivoluzione nell‚Äôinferenza bayesiana, permettendoci di affrontare con successo modelli complessi che sfuggono alle soluzioni analitiche tradizionali. Questo rende i metodi MCMC uno strumento essenziale per l‚Äôanalisi statistica moderna, ampliando notevolmente le frontiere della ricerca e dell‚Äôapplicazione pratica nella statistica bayesiana.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#esercizi",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#esercizi",
    "title": "44¬† Linguaggio Stan",
    "section": "44.9 Esercizi",
    "text": "44.9 Esercizi\n\nEsercizio 44.1 Circa un decennio dopo la pubblicazione della regola di Bayes, Laplace sfrutt√≤ la funzione beta di Eulero per derivare formalmente la distribuzione a posteriori nel contesto del modello beta-binomiale. A tale scopo, egli analizz√≤ i dati relativi al sesso dei nati vivi a Parigi tra il 1745 e il 1770:\n\n\n\nSesso\nNati vivi\n\n\n\n\nFemmina\n105287\n\n\nMaschio\n110312\n\n\n\nLaplace si interrog√≤ sulla possibilit√† che, sulla base di questi dati, la probabilit√† di nascita di un maschio, denotata con \\(\\theta\\), fosse superiore a quella di una femmina. Si propone di risolvere il problema di Laplace utilizzando Stan, assumendo una distribuzione uniforme a priori per \\(\\theta\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_stan_beta_binomial.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/02_stan_beta_binomial.html#informazioni-sullambiente-di-sviluppo",
    "title": "44¬† Linguaggio Stan",
    "section": "44.10 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "44.10 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\npandas    : 2.2.2\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>44</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html",
    "href": "chapters/mcmc/03_stan_summary_posterior.html",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo capitolo √® quello di descrivere i metodi di sintesi della distribuzione a posteriori mediante l‚Äôutilizzo della tecnica MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.1 Sintesi della Distribuzione a Posteriori",
    "text": "45.1 Sintesi della Distribuzione a Posteriori\nIl risultato di un‚Äôanalisi bayesiana √® una distribuzione a posteriori, contenente tutte le informazioni sui parametri dati un modello e un insieme di dati. Pertanto, riassumere la distribuzione a posteriori significa sintetizzare le conseguenze logiche del modello e dei dati analizzati. √à prassi comune riportare, per ciascun parametro, una misura di posizione centrale (come la media, la moda o la mediana) per fornire un‚Äôidea della localizzazione della distribuzione, accompagnata da una misura di dispersione, quale la deviazione standard, per quantificare l‚Äôincertezza delle stime. La deviazione standard √® adeguata per distribuzioni simili alla normale, ma pu√≤ risultare fuorviante per distribuzioni di altra natura, come quelle asimmetriche.\nPer riassumere la dispersione di una distribuzione a posteriori, si utilizza spesso l‚ÄôIntervallo di Densit√† Pi√π Alta (HDI, Highest-Density Interval). L‚ÄôHDI √® l‚Äôintervallo pi√π breve che contiene una data porzione della densit√† di probabilit√†. Ad esempio, se diciamo che l‚ÄôHDI al 95% per un‚Äôanalisi √® [2, 5], intendiamo che, secondo i nostri dati e modello, il parametro in questione si trova tra 2 e 5 con una probabilit√† di 0.95. Non vi √® nulla di particolare nella scelta del 95%, del 50% o di qualsiasi altro valore; siamo liberi di scegliere, ad esempio, l‚Äôintervallo HDI all‚Äô89% o al 94% secondo le nostre preferenze. Idealmente, le giustificazioni per queste scelte dovrebbero dipendere dal contesto e non essere automatiche, ma √® accettabile stabilire un valore comune come il 95%. Per ricordarci della natura arbitraria di questa scelta, il valore predefinito in ArviZ √® del 94%.\nArviZ √® un pacchetto Python per l‚Äôanalisi esplorativa di modelli bayesiani e offre numerose funzioni utili per riassumere la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#campionamento-con-stan",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#campionamento-con-stan",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.2 Campionamento con Stan",
    "text": "45.2 Campionamento con Stan\nA scopo illustrativo, utilizziamo ancora una volta i dati relativi agli artisti della Generazione X presenti al MOMA. I dati consistono in 14 casi di successo, ovvero artisti della Generazione X, su un totale di 100 opere selezionate casualmente dal MOMA. Come fatto in precedenza, impostiamo il parametro \\(\\theta\\), che rappresenta la probabilit√† di appartenere alla Generazione X o alle successive, seguendo una distribuzione Beta(4, 6).\nPer iniziare, eseguiamo il processo di campionamento MCMC usando Stan.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'moma.stan')\n\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y_rep;\n  y_rep = binomial_rng(N, theta);\n}\n\n\n\nCompiliamo il modello:\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nDefiniamo il dizionario con i dati:\n\nN = 100\ny = 14\n\ndata = {\n    'N': N, \n    'y': y,\n    \"alpha_prior\" : 4,\n    \"beta_prior\" : 6\n    }\n\nprint(data)\n\n{'N': 100, 'y': 14, 'alpha_prior': 4, 'beta_prior': 6}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=data,\n    iter_warmup = 1000,\n    iter_sampling = 4_000,\n    chains = 4,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.3 Analisi della distribuzione a posteriori",
    "text": "45.3 Analisi della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata riguardo al valore del parametro \\(\\theta\\) dopo aver osservato i dati. Combina le nostre credenze a priori riguardo al parametro (la distribuzione a priori) con le nuove evidenze fornite dai dati osservati (la funzione di verosimiglianza) per ottenere una nuova distribuzione che riflette la nostra comprensione aggiornata del parametro, ovvero la distribuzione a posteriori.\nLa distribuzione a posteriori ci dice quanto sia probabile ogni possibile valore del parametro alla luce dei dati osservati. Un picco stretto indica che i dati sono molto informativi rispetto al parametro, portando a una maggiore certezza nella sua stima. Un picco largo, invece, indica maggiore incertezza.\nLa distribuzione a posteriori rappresenta un aggiornamento delle nostre credenze a priori in base ai dati osservati.\nIn genere, il primo passo da fare dopo il campionamento √® quello di verificare l‚Äôaspetto dei risultati.\n\ntrace.draws().shape\n\n(4000, 4, 9)\n\n\nLe dimensioni (4000, 4, 9) restituite dall‚Äôistruzione trace.draws().shape in CmdStanPy si riferiscono alla struttura dei dati campionati ottenuti dall‚Äôesecuzione del modello Stan. Vediamo cosa rappresenta ciascuna dimensione:\n\n4000: Questo rappresenta il numero di iterazioni di campionamento per catena. Qui, abbiamo specificato iter_sampling = 4000, quindi ci sono 4000 campioni per ciascuna catena.\n4: Questo √® il numero di catene. Abbiamo specificato chains = 4, quindi ci sono 4 catene di campionamento eseguite in parallelo.\n9: Questo rappresenta il numero di parametri o quantit√† di interesse (inclusi parametri trasformati e quantit√† generate) che sono stati campionati. Include tutte le variabili definite nei blocchi parameters, transformed parameters e generated quantities del modello Stan.\n\nPossiamo recuperare i nomi delle variabili dall‚Äôoggetto trace e il numero di campioni a posteriori per ciascuna variabile nel modo seguente:\n\nvars = trace.stan_variables()\nfor (k,v) in vars.items():\n    print(k, v.shape)\n\ntheta (16000,)\ny_rep (16000,)\n\n\nRecuperiamo i campioni posteriori per theta:\n\ntheta_samples = trace.stan_variable('theta')\ntheta_samples.shape\n\n(16000,)\n\n\nGeneriamo un istogramma della distribuzione a posteriori di theta:\n\nplt.hist(theta_samples, bins=30, density=True, alpha=0.5, color='blue')\nplt.xlabel('Valori di $\\\\theta$')\nplt.ylabel('Frequenza')\nplt.title('Istogramma della Distribuzione a Posteriori di $\\\\theta$')\nplt.show()\n\n\n\n\n\n\n\n\nIn alternativa, possiamo passare l‚Äôoggetto trace alle funzioni di ArviZ. La funzione plot_trace di ArviZ √® particolarmente adatta a questo scopo:\n\n_ = az.plot_trace(trace, var_names=['theta'])\n\n\n\n\n\n\n\n\nLa figura illustra il risultato predefinito ottenuto chiamando az.plot_trace; vengono generati due subplot per ogni variabile non osservata. Nella configurazione del nostro modello, l‚Äôunica variabile non osservata √® Œ∏. A sinistra, viene visualizzato un grafico di stima della densit√† del kernel (KDE), che rappresenta una versione liscia dell‚Äôistogramma. √à auspicabile che tutte le catene abbiano un KDE molto simile ad una gaussiana, come mostrato nella figura. A destra, vengono mostrati i valori individuali ad ogni passo di campionamento, con tante linee quanti sono i percorsi delle catene. L‚Äôideale √® che questa rappresentazione appaia rumorosa, senza un pattern chiaro, rendendo difficile l‚Äôidentificazione di una catena rispetto alle altre. Il concetto chiave √® che, eseguendo molte catene, ci aspettiamo che risultino praticamente indistinguibili l‚Äôuna dall‚Äôaltra. Nel caso presente, il campionatore ha svolto un buon lavoro e possiamo fiduciosi nei risultati ottenuti.\nConfrontiamo la distribuzione a posteriori con la distribuzione a priori di \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha, beta_param = 4, 6\n\n# Creazione di un range di valori\nx = np.linspace(0, 1, 1000)\n\n# Calcolo della PDF\npdf = stats.beta.pdf(x, alpha, beta_param)\n\n# Visualizzazione della PDF\n_ = plt.plot(x, pdf, lw=2)\n\n\n\n\n\n\n\n\nNel caso presente, la distribuzione a posteriori differisce in maniera importante dalla distribuzione a priori. Ci√≤ indica che i dati hanno avuto un forte impatto sulle nostre credenze riguardo al valore del parametro.\n\n45.3.1 Intervallo di credibilit√†\nLa funzione az.plot_posterior ci consente di generare un grafico della distribuzione a posteriori che include la media e l‚Äôintervallo di credibilit√† HDI al 94%. Questo tipo di grafico √® stato presentato da John K. Kruschke nel suo libro ‚ÄúDoing Bayesian Data Analysis‚Äù (doingbayesian?).\n\n_ = az.plot_posterior(trace, var_names=['theta'])\n\n\n\n\n\n\n\n\nL‚Äôintervallo di credibilit√† fornisce una stima dell‚Äôintervallo entro cui il parametro si trova con una certa probabilit√†. Nel caso presente, l‚Äôintervallo di credibilit√† del 94% ci dice che, data la nostra comprensione a posteriori del parametro, c‚Äô√® il 94% di probabilit√† che il vero valore del parametro si trovi all‚Äôinterno dell‚Äôintervallo [0.1, 0.23].\nA differenza dell‚Äôintervallo di confidenza frequentista, che √® interpretato in termini di lungo termine su ripetuti campionamenti, l‚Äôintervallo di credibilit√† bayesiano √® direttamente interpretato come la probabilit√† che il parametro si trovi all‚Äôinterno di un certo intervallo dato il set di dati specifico.\nUn sommario numerico della distribuzione a posteriori si ottiene con la funzione az.summary, la quale ritorna una Pandas Data Frame:\n\naz.summary(trace, var_names=['theta'], kind=\"stats\").round(2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\ntheta\n0.16\n0.04\n0.1\n0.23\n\n\n\n\n\n\n\n\nNella prima colonna abbiamo il nome della variabile, nella seconda colonna troviamo la media del posteriore, nella terza colonna la deviazione standard del posteriore, e nelle ultime due colonne troviamo i limiti inferiore e superiore dell‚Äôintervallo di densit√† pi√π alta al 94%. Di conseguenza, secondo il nostro modello e i dati a disposizione, riteniamo che il valore di Œ∏ sia probabilmente 0.16, con una probabilit√† del 94% che si trovi effettivamente tra 0.1 e 0.23. Possiamo riportare un riassunto simile utilizzando la deviazione standard. Il vantaggio della deviazione standard rispetto all‚ÄôHDI √® che √® una statistica pi√π conosciuta. Come svantaggio, dobbiamo essere pi√π attenti nell‚Äôinterpretarla; altrimenti, potrebbe portare a risultati privi di significato. Nel caso presente, se calcoliamo la media ¬± 2 deviazioni standard, otterremo gli intervalli (0.08, 0.24) che sono simili ai limiti dell‚Äôintervallo HDI riportato sopra.\n\n[0.16 + i*0.04 for i in (-2, 2)]\n\n[0.08, 0.24]\n\n\nTuttavia, in alcuni casi, questa procedura potrebbe generare un limite inferiore o superiore al di fuori dell‚Äôintervallo consentito per i valori di Œ∏, il quale √® compreso tra 0 e 1.\n\n\n45.3.2 Test di Ipotesi Bayesiane\nIn alcune situazioni, la mera descrizione della distribuzione a posteriori non basta. Spesso ci troviamo di fronte alla necessit√† di fare scelte basate sulle nostre inferenze, traducendo stime continue in decisioni binarie: ad esempio, affermare se un individuo √® sano o malato, se un intervento ha avuto successo o meno, e cos√¨ via.\nPrendiamo come esempio la questione se, nel Museum of Modern Art (MoMA), gli artisti appartenenti alla generazione X rappresentino il 50% dell‚Äôintero corpus. Avvalendoci di un campione casuale di 100 opere, unitamente alle nostre convinzioni pregresse (prior), abbiamo determinato un Intervallo di Massima Densit√† (HDI) che va da 0.1 a 0.23. La nostra ipotesi prevede che Œ∏ (la proporzione degli artisti della generazione X) sia 0.5. Confrontando questo valore con l‚ÄôHDI ottenuto, osserviamo che 0.5 non rientra nell‚Äôintervallo [0.1, 0.23]. Questo risultato pu√≤ essere interpretato come un‚Äôindicazione che il MoMA manifesti una preferenza per artisti nati prima del periodo 1965-1980. Tuttavia, non possiamo escludere del tutto la possibilit√† che la generazione X contribuisca per met√† alle opere presenti nel museo. Per arrivare a una conclusione pi√π definita, sarebbe necessario raccogliere ulteriori dati per ridurre la variabilit√† della distribuzione a posteriori, o considerare l‚Äôadozione di un prior pi√π informativo per affinare la nostra analisi.\nOppure possiamo chiederci quale sia la probabilit√† che il valore a posteriori \\(\\theta\\) assuma un valore minore di 0.5. La funzione az.plot_posterior(idata, ref_val=0.5) ci dice che questa probabilit√† √® uguale a 1. Ovvero, possiamo essere del tutto certi che la proporzione di opere d‚Äôarte della generazione X rappresentate al MoMA sia minore del 50% del totale.\n\n_ = az.plot_posterior(trace, var_names=['theta'], ref_val=0.5)\n\n\n\n\n\n\n\n\nPossiamo usare qualsiasi valore di riferimento. Per esempio\n\n_ = az.plot_posterior(trace, var_names=['theta'], ref_val=0.20)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#la-regione-di-equivalenza-pratica-rope",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#la-regione-di-equivalenza-pratica-rope",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.4 La Regione di Equivalenza Pratica (ROPE)",
    "text": "45.4 La Regione di Equivalenza Pratica (ROPE)\nLa Regione di Equivalenza Pratica (ROPE) costituisce un elemento chiave nei test di equivalenza, mirando a stabilire la rilevanza pratica di un parametro. Questa regione si allinea a un‚Äôipotesi nulla predefinita, permettendo di valutare se un parametro pu√≤ essere considerato equivalente rispetto a tale ipotesi.\n√à fondamentale comprendere che, data l‚Äôinfinita precisione teorica nella misurazione dei parametri, la probabilit√† di identificare un valore esatto di un parametro √® sempre uguale a zero. Pertanto, l‚Äôanalisi si concentra non sull‚Äôottenimento di valori precisi, ma piuttosto su valori che rientrano in un intervallo di accettabilit√† prefissato.\nIl metodo decisionale ‚ÄúHDI+ROPE‚Äù (Kruschke, 2014; Kruschke & Liddell, 2018) viene frequentemente utilizzato per determinare se i valori di un parametro debbano essere considerati accettabili o meno in relazione all‚Äôipotesi nulla delineata dalla ROPE. Questo metodo esamina la percentuale dell‚ÄôIntervallo Credibile (CI) che si trova all‚Äôinterno della ROPE, considerata come regione corrispondente all‚Äôipotesi nulla. Se questa percentuale √® notevolmente bassa, l‚Äôipotesi nulla viene scartata; viceversa, se √® elevata, l‚Äôipotesi viene accettata.\nPer illustrare, consideriamo l‚Äôesempio di una moneta teoricamente equilibrata, la cui probabilit√† di ottenere ‚Äútesta‚Äù si vuole sia vicina al valore teorico di 0.5. Al posto di focalizzarsi esclusivamente sul valore esatto di 0.5, possiamo definire una ROPE, ad esempio tra [0.45, 0.55]. Tale intervallo viene considerato praticamente equivalente a 0.5 ai fini della nostra analisi, consentendo di valutare l‚Äôequit√† della moneta tenendo conto delle naturali fluttuazioni nelle misurazioni.\nDopo aver definito la ROPE, confrontiamo il nostro risultato con l‚Äôintervallo di densit√† pi√π alta (HDI). Da questo confronto emergono tre possibili scenari:\n\nAssenza di sovrapposizione tra ROPE e HDI: Indica che i risultati ottenuti sono sufficientemente distanti dall‚Äôintervallo di equivalenza pratica, portando al rifiuto dell‚Äôipotesi di equivalenza. Questo scenario suggerisce che il parametro analizzato ha un impatto pratico che va oltre l‚Äôipotesi di nullit√† considerata dalla ROPE.\nLa ROPE include completamente l‚ÄôHDI: Questo scenario si verifica quando l‚Äôintero intervallo di densit√† pi√π alta cade all‚Äôinterno della ROPE, indicando che i risultati sono pienamente compatibili con l‚Äôipotesi di nullit√†. In questo caso, possiamo accettare l‚Äôipotesi che il parametro sia praticamente equivalente all‚Äôipotesi nulla, suggerendo una mancanza di significativit√† pratica del parametro in esame.\nSovrapposizione parziale tra ROPE e HDI: In questo caso, una porzione dell‚ÄôHDI si sovrappone con la ROPE, ma non completamente. Questo risultato implica che non possiamo trarre conclusioni definitive riguardo all‚Äôequivalenza pratica del parametro rispetto all‚Äôipotesi nulla. Si rende necessaria un‚Äôulteriore analisi o l‚Äôimpiego di altri criteri decisionali per determinare la rilevanza pratica del parametro.\n\nConsiderando un esempio relativo all‚Äôanalisi dei dati della Generazione X, con una ROPE definita come [0.25, 0.35].\n\n_ = az.plot_posterior(trace, var_names=['theta'], rope=[0.25, .35])\n\n\n\n\n\n\n\n\nLa ROPE cos√¨ definita corrisponde all‚Äôipotesi del parametro \\(\\theta\\) = 0.3 e considerando equivalenti i valori osservati nell‚Äôintervallo [0.25, 0.35].\nL‚Äôanalisi mostra che l‚ÄôHDI non si sovrappone alla ROPE. Inoltre, solo l‚Äô1.3% della distribuzione a posteriori √® contenuta nella ROPE. Possiamo dunque rifiutare l‚Äôipotesi specificata dalla ROPE.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#estrazione-degli-attributi-da-inferencedata",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#estrazione-degli-attributi-da-inferencedata",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.5 Estrazione degli attributi da InferenceData",
    "text": "45.5 Estrazione degli attributi da InferenceData\nVediamo ora nei dettagli come sia possibile effettuare le varie operazioni sulla distribuzione a posteriori, ovvero la stima puntuale, gli intervalli di credibilit√† e i test di ipotesi, mediante la manipolazione dell‚Äôoggetto theta_draws ottenuto dalla funzione sample.stan_variable().",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#stima-puntuale",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#stima-puntuale",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.6 Stima puntuale",
    "text": "45.6 Stima puntuale\nPossiamo recuperare la traccia di campionamento dalla variabile latente theta nel modo seguente:\n\ntheta_draws = trace.stan_variable('theta')\ntheta_draws.shape\n\n(16000,)\n\n\nIn cmdstanpy, quando si utilizza il metodo stan_variable per estrarre i campioni di un parametro specifico dai campioni posteriori, questo restituisce un array numpy contenente i campioni.\nIl metodo stan_variable('theta') estrae tutti i campioni per il parametro theta dalla distribuzione posteriore. Questo include i campioni da tutte le catene e tutte le iterazioni dopo il warmup. Il risultato, theta_draws, √® un array numpy in cui i campioni di tutte le catene sono concatenati insieme. La forma di theta_draws √® tipicamente (num_samples * num_chains, ) se theta √® un parametro scalare, o (num_samples * num_chains, dim1, dim2, ...) se theta √® un vettore o una matrice. I campioni delle 4 catene sono concatenati. Questo significa che i campioni di ciascuna catena sono aggiunti uno dopo l‚Äôaltro in un singolo array. Non sono mescolati insieme in modo casuale; piuttosto, sono semplicemente posizionati in sequenza.\nPer visualizzare il primi 30 valori di theta_draws, ad esempio, usiamo:\n\ntheta_draws[0:30]\n\narray([0.152399, 0.164544, 0.185841, 0.210788, 0.210788, 0.158488,\n       0.152418, 0.117835, 0.161514, 0.168753, 0.137032, 0.162867,\n       0.168521, 0.182565, 0.123249, 0.114717, 0.123867, 0.128263,\n       0.171871, 0.142336, 0.204677, 0.221803, 0.171478, 0.121296,\n       0.108108, 0.199047, 0.133709, 0.138647, 0.144356, 0.174385])\n\n\nDi conseguenza, possiamo calcolare su theta_draws tutte le misure statistiche descrittive che si possono ottenere da un vettore di dati. Per esempio, possiamo calcolare la media a posteriori.\n\nnp.mean(theta_draws)\n\n0.16424613186875\n\n\nPossiamo calcolare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(theta_draws)\n\n0.16208250000000002\n\n\nOppure la deviazione standard della stima a posteriori di \\(\\theta\\).\n\nnp.std(theta_draws)\n\n0.03521655992174475",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#intervallo-di-credibilit√†-1",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#intervallo-di-credibilit√†-1",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.7 Intervallo di credibilit√†",
    "text": "45.7 Intervallo di credibilit√†\nL‚Äôinferenza bayesiana tramite l‚Äôintervallo di credibilit√† riguarda invece la stima dell‚Äôintervallo che contiene il parametro \\(\\theta\\) ad un dato livello di probabilit√† soggettiva.\nUsando l‚Äôoggetto sample, possiamo ottenere un sommario della distribuzione a posteriori con il metodo az.summary().\n\naz.summary(trace, var_names=['theta'], hdi_prob=0.94, round_to=3)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta\n0.164\n0.035\n0.1\n0.231\n0.0\n0.0\n5412.045\n7678.797\n1.0\n\n\n\n\n\n\n\n\nSi ottiene cos√¨ l‚Äôintervallo di credibilit√† a pi√π alta densit√† a posteriori (HPD) al 94%. Questo intervallo ci informa sul fatto che, a posteriori, possiamo essere certi al 94%, che il vero valore del parametro \\(\\theta\\) sia contenuto nell‚Äôintervallo [0.103, 0.23].\nDato che, nel caso presente, conosciamo la soluziona analitica, possiamo verificare il risultato precedente calcolando i quantili della distribuzione a posteriori Beta(18, 92) di ordine 0.03 e 0.97.\n\nll = stats.beta.ppf(0.03, 18, 92)\nul = stats.beta.ppf(0.97, 18, 92)\nlist([ll, ul])\n\n[0.10303527075398665, 0.23457657606771784]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.8 Verifica di ipotesi bayesiana",
    "text": "45.8 Verifica di ipotesi bayesiana\nUn secondo tipo di inferenza bayesiana riguarda problemi in cui siamo interessati a valutare la plausibilit√† che il parametro \\(\\theta\\) assuma valori contenuti in un dato intervallo di valori. Per esempio, ci potrebbe interessare l‚Äôipotesi \\(\\theta &gt; 0.5\\). In questo caso, possiamo calcolare la probabilit√† a posteriori che \\(\\theta\\) cada nell‚Äôintervallo di interesse, integrando la distribuzione a posteriori Beta su tale intervallo.\nNel caso dell‚Äôesempio degli artisti della Generazione X, supponiamo di essere interessati alle due seguenti ipotesi:\n\\[\n\\begin{split}\nH_0: & \\; \\; \\pi \\ge 0.2 \\\\\nH_a: & \\; \\; \\pi &lt; 0.2\n\\end{split}\n\\]\nLa nostra domanda √® la seguente: Date le nostre credenze iniziali e i dati disponibili, quale importanza relativa possiamo attribuire a queste due ipotesi?\nPer affrontare questa questione, iniziamo a calcolare la probabilit√† \\(P(\\theta &lt; 0.2)\\).\n\nprint(np.mean(theta_draws &lt; 0.2))\n\n0.846125\n\n\nPassiamo ora a calcolare gli odds a posteriori:\n\npost_odds = (np.mean(theta_draws &lt; 0.2)) / (1 - np.mean(theta_draws &lt; 0.2))\nprint(post_odds)\n\n5.498781478472787\n\n\nCi√≤ implica che la probabilit√† che \\(\\pi\\) sia inferiore al 20% √® circa 6 volte superiore rispetto alla probabilit√† che sia al di sopra del 20%.\nQuesto risultato si basa solo sulle informazioni relative alla distribuzione a posteriori. Prima di avere osservato i dati del campione, avevamo una distribuzione a priori \\(\\operatorname{Beta}(6, 4)\\), e in quel contesto avevamo una probabilit√† del 9% che \\(H_a\\) fosse vera e una probabilit√† del 91% che fosse falsa.\n\nthreshold = 0.2\nprior_prob = stats.beta.cdf(threshold, a=4, b=6)\n\n\nprior_odds = prior_prob / (1 - prior_prob)\nprint(prior_odds)\n\n0.09366320688790145\n\n\nOra possiamo combinare le informazioni degli odds a posteriori e degli odds a priori in una quantit√† chiamata Bayes Factor, che √® semplicemente il rapporto tra le due:\n\nBF = post_odds / prior_odds\nprint(BF)\n\n58.70802058970575\n\n\nIn conclusione, dopo aver appreso informazioni riguardo a 14 artisti appartenenti alla generazione X, le probabilit√† posteriori della nostra ipotesi \\(H_a: \\; \\pi &lt; 0.2\\) sono circa 60 volte superiori rispetto alle probabilit√† a priori.\nQuesto √® un esempio di test di ipotesi bayesiano.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#commenti-e-considerazioni-finali",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "45.9 Commenti e considerazioni finali",
    "text": "45.9 Commenti e considerazioni finali\nLa crescente popolarit√† dei metodi bayesiani in psicologia e nelle scienze sociali √® stata fortemente influenzata dalla (ri)scoperta di algoritmi numerici capaci di stimare le distribuzioni a posteriori dei parametri del modello a partire dai dati osservati. Prima di questi sviluppi, ottenere misure riassuntive delle distribuzioni a posteriori, soprattutto per modelli complessi con molti parametri, era praticamente impossibile.\nQuesto capitolo fornisce un‚Äôintroduzione a cmdstanpy, un‚Äôimplementazione in Python di cmdstan, che permette di compilare ed eseguire modelli probabilistici espressi in linguaggio Stan. Grazie a questa tecnologia, √® possibile generare una stima della distribuzione a posteriori attraverso il campionamento Markov Chain Monte Carlo (MCMC), rivoluzionando la capacit√† di effettuare inferenze bayesiane e rendendo l‚Äôanalisi di modelli complessi pi√π accessibile e gestibile.\nInoltre, nel capitolo sono state presentate diverse strategie per la trasformazione della distribuzione a posteriori e sono state esplorate modalit√† per ottenere intervalli di credibilit√†. Successivamente, √® stata discussa l‚Äôanalisi delle ipotesi a posteriori, che consente di confrontare due ipotesi contrapposte riguardanti il parametro \\(\\theta\\). In alcune situazioni, questo confronto viene tradotto in una misura denominata Fattore di Bayes.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/03_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "45¬† Metodi di sintesi della distribuzione a posteriori",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Mon Jun 10 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.1\npandas    : 2.2.2\nnumpy     : 1.26.4\nlogging   : 0.5.1.2\nmatplotlib: 3.8.4\ncmdstanpy : 1.2.3\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n# Stampa la versione di CmdStan\nprint(\"CmdStan version:\", cmdstanpy.utils.cmdstan_version())\n\nCmdStan version: (2, 35)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>45</span>¬† <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html",
    "href": "chapters/mcmc/04_stan_diagnostics.html",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "",
    "text": "Introduzione\nLe catene di Markov sono utilizzate per approssimare la distribuzione a posteriori. Tuttavia, √® fondamentale riconoscere che tale approssimazione √® soggetta a errori e imperfezioni. Schoot et al. (2020) propongono una When-to-Worry- and-How-to-Avoid-the-Misuse-of-Bayesian-Statistics (WAMBS) checklist.\nLa diagnostica delle catene Markoviane, quindi, si configura come un insieme di pratiche e strumenti mirati a indagare vari aspetti della convergenza. Questi includono l‚Äôaccuratezza dell‚Äôapprossimazione della distribuzione a posteriori, l‚Äôefficienza del campionamento e l‚Äôesplorazione esaustiva dello spazio dei parametri. Tali strumenti diagnostici possono essere sia grafici che numerici e dovrebbero essere applicati in un contesto olistico per fornire una panoramica completa della qualit√† della catena di Markov.\nNon esiste un‚Äôunica metrica o diagnostico che possa fornire un quadro completo; piuttosto, √® l‚Äôanalisi combinata di pi√π metriche e diagnostici che permette di acquisire una comprensione pi√π profonda del comportamento della catena. Inoltre, l‚Äôesperienza del ricercatore gioca un ruolo significativo nel distinguere tra una ‚Äúbuona‚Äù e una ‚Äúcattiva‚Äù catena di Markov e nel suggerire strategie per migliorare la qualit√† del campionamento.\nIn sintesi, l‚Äôanalisi della convergenza e la diagnostica delle catene Markoviane sono fasi imprescindibili nel processo di inferenza bayesiana, soprattutto quando si utilizzano metodi MCMC. La loro applicazione consente di garantire che le stime a posteriori siano tanto accurate e affidabili quanto possibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#grafici-di-tracciamento",
    "href": "chapters/mcmc/04_stan_diagnostics.html#grafici-di-tracciamento",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.1 Grafici di Tracciamento",
    "text": "46.1 Grafici di Tracciamento\nUn metodo diagnostico comunemente utilizzato per valutare la convergenza nei metodi di Monte Carlo basati su catene di Markov (MCMC) √® l‚Äôanalisi dei grafici di tracciamento, o ‚Äútrace plots‚Äù. Questi grafici rappresentano sequenzialmente le stime dei parametri posteriori ottenute ad ogni iterazione della catena. In generale, si tende a interpretare che un parametro sta convergendo quando le stime campionarie si aggregano in una banda orizzontale ristretta lungo l‚Äôasse delle iterazioni che compongono la catena. Tuttavia, considerare questa disposizione come prova conclusiva di convergenza √® piuttosto grossolano, in quanto una traccia compatta non garantisce che la convergenza sia stata effettivamente raggiunta. Di fatto, questa metodologia risulta essere pi√π un indicatore di non-convergenza. Ad esempio, se due catene per lo stesso parametro sono campionate da regioni diverse della distribuzione target e le stime rimangono separate lungo la storia della catena, ci√≤ costituisce un‚Äôevidenza di non-convergenza. Allo stesso modo, se il grafico mostra fluttuazioni significative o salti nella catena, √® probabile che la catena associata a quel parametro non abbia raggiunto la convergenza.\nUn trace plot ideale presenta una dispersione casuale dei valori attorno a un livello medio stabile, indicando una buona miscelazione delle catene e un‚Äôadeguata configurazione del processo MCMC. Questo pattern suggerisce che l‚Äôalgoritmo √® assestato su una distribuzione stabile e le inferenze tratte dai dati campionati sono affidabili.\nApprofondendo con l‚Äôesempio di Martin, Kumar, e Lao (2022), √® possibile osservare diversi esempi di trace plots per catene MCMC. Questi esempi illustrano sia scenari in cui il comportamento √® ottimale, segnalando una convergenza adeguata, sia casi in cui le catene mostrano segni di problemi di convergenza o di miscelazione. Tali situazioni indicano la necessit√† di un‚Äôulteriore affinazione dei parametri dell‚Äôalgoritmo MCMC per garantire l‚Äôaffidabilit√† delle stime statistiche ottenute.\n\ngood_chains = stats.beta.rvs(2, 5, size=(2, 2000))\nbad_chains0 = np.random.normal(\n    np.sort(good_chains, axis=None), 0.05, size=4000\n).reshape(2, -1)\n\nbad_chains1 = good_chains.copy()\nfor i in np.random.randint(1900, size=4):\n    bad_chains1[i % 2 :, i : i + 100] = np.random.beta(i, 950, size=100)\n\nchains = {\n    \"good_chains\": good_chains,\n    \"bad_chains0\": bad_chains0,\n    \"bad_chains1\": bad_chains1,\n}\n\n\naz.plot_trace(chains)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/2425599176.py:2: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nLe cattive catene non convergono n√© si mescolano tra loro. Uno dei motivi per l‚Äôesecuzione di pi√π catene √® che ogni singola catena potrebbe convergere verso un target, mentre un‚Äôaltra catena potrebbe convergere su un target diverso, e questo sarebbe un problema. Inoltre, catene altrimenti sane possono bloccarsi occasionalmente nel corso della serie, il che suggerirebbe la necessit√† di modifiche al modello o alle impostazioni del campionatore. Un altro modo per valutare la convergenza dell‚Äôalgoritmo √® plottando la densit√† della distribuzione a posteriori degli effetti stimati, per assicurarsi che si avvicini ad una classica curva a campana.\nIn pratica, non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perch√© la diagnostica delle catene di Markov √® cos√¨ importante: se vediamo trace-plots come le precedenti ‚Äúbad chains‚Äù, sappiamo che non abbiamo ottenuto una approssimazione adeguata della distribuzione a posteriori. In tali circostanze possiamo ricorrere ad alcuni rimedi.\n\nControllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati?\nUtilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-della-densit√†-posteriore-sono-adeguati",
    "href": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-della-densit√†-posteriore-sono-adeguati",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.2 I Grafici della Densit√† Posteriore Sono Adeguati?",
    "text": "46.2 I Grafici della Densit√† Posteriore Sono Adeguati?\nI grafici della densit√† posteriore rappresentano uno degli strumenti diagnostici pi√π efficaci per identificare eventuali anomalie nella convergenza delle catene di Markov nell‚Äôanalisi bayesiana. Questi grafici mostrano la distribuzione dei valori campionati per ogni parametro del modello statistico e per ogni catena di Markov. L‚Äôimportanza di questi grafici √® primaria: essi sono la base da cui deriviamo le statistiche riassuntive dei parametri del modello, quali la media, la mediana, o l‚Äôintervallo di credibilit√†.\nPrendiamo come esempio un parametro di interesse in un modello di regressione che assume una distribuzione a priori gaussiana (normale). In un contesto ideale, senza problemi di convergenza, ci aspetteremmo che la densit√† posteriore del parametro sia anch‚Äôessa normalmente distribuita, centrata intorno a una media con una certa varianza. Questo andamento simmetrico e unimodale della densit√† posteriore √® un segnale che la catena di Markov ha esplorato adeguatamente lo spazio dei parametri e che i campioni estratti possono essere considerati rappresentativi della distribuzione posteriore effettiva del parametro.\nTuttavia, se il grafico della densit√† posteriore mostra deviazioni significative dalla forma attesa, come ad esempio asimmetrie marcate o bimodalit√†, questo suggerisce che potrebbero esserci problemi nella convergenza della catena al vero valore del parametro. Una distribuzione bimodale, in particolare, pu√≤ indicare che la catena √® rimasta ‚Äúintrappolata‚Äù in aree locali dello spazio dei parametri, senza riuscire a esplorare adeguatamente l‚Äôintero spazio e raggiungere l‚Äôequilibrio.\nPer risolvere tali problemi e ottenere una stima pi√π accurata della distribuzione posteriore, potremmo considerare diverse strategie:\n\nAumentare il Numero di Iterazioni: Incrementare il numero delle iterazioni delle catene di Markov pu√≤ permettere una migliore esplorazione dello spazio dei parametri e aiutare a superare le barriere tra i picchi di una distribuzione bimodale.\nOttimizzazione delle Distribuzioni a Priori: La scelta delle distribuzioni a priori pu√≤ influenzare fortemente la convergenza della catena. Selezionare priori pi√π informativi o pi√π flessibili pu√≤ aiutare la catena a guidare l‚Äôesplorazione dello spazio dei parametri in modo pi√π efficace.\nAffinamento dei Parametri dell‚ÄôAlgoritmo MCMC: Modificare i parametri di configurazione dell‚Äôalgoritmo MCMC, come il passo del campionamento o i criteri di accettazione, pu√≤ migliorare la qualit√† del campionamento e favorire una convergenza pi√π rapida e stabile.\n\nIn definitiva, l‚Äôanalisi dei grafici della densit√† posteriore non solo fornisce una stima visiva dell‚Äôandamento dei parametri, ma serve anche come fondamento per decisioni metodologiche che possono migliorare la robustezza e l‚Äôaffidabilit√† delle inferenze bayesiane.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#lautocorrelazione-nelle-catene-di-markov-monte-carlo-√®-troppo-alta",
    "href": "chapters/mcmc/04_stan_diagnostics.html#lautocorrelazione-nelle-catene-di-markov-monte-carlo-√®-troppo-alta",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.3 L‚ÄôAutocorrelazione nelle Catene di Markov Monte Carlo √à Troppo Alta?",
    "text": "46.3 L‚ÄôAutocorrelazione nelle Catene di Markov Monte Carlo √à Troppo Alta?\nNell‚Äôambito dell‚Äôanalisi bayesiana tramite le catene di Markov Monte Carlo (MCMC), √® di fondamentale importanza valutare la rapidit√† con cui i campioni estratti dalla distribuzione a posteriori raggiungono l‚Äôindipendenza. Inizialmente, come √® noto, i campioni della distribuzione a posteriori non sono indipendenti l‚Äôuno dall‚Äôaltro, ma ci si aspetta che, nel tempo, la catena ‚Äúdimentichi‚Äù il suo stato iniziale e converga verso un insieme di estrazioni indipendenti e stazionarie dalla distribuzione a posteriori.\nUna metodologia per determinare la velocit√† con cui la catena si allontana dallo stato iniziale √® l‚Äôanalisi della funzione di autocorrelazione (ACF), che si basa sull‚Äôosservazione che un campione \\(\\theta^{(s)}\\) tende a essere pi√π simile al campione immediatamente precedente \\(\\theta^{(s-1)}\\) rispetto a quelli pi√π distanti come \\(\\theta^{(s-2)}\\), \\(\\theta^{(s-3)}\\), e cos√¨ via. La correlazione di lag-l per una catena stazionaria di Markov, dove \\(s = 1, \\ldots, S\\), pu√≤ essere espressa come:\n\\[\n\\rho_l = \\text{cor}(\\theta^{(s)}, \\theta^{(s+l)}).\n\\]\nIn generale, ci aspettiamo che l‚Äôautocorrelazione a lag-1 sia vicina a 1, ma che diminuisca man mano che il lag aumenta, indicando che i componenti della catena stanno diventando indipendenti. Una riduzione rapida dell‚Äôautocorrelazione con il numero di iterazioni √® preferibile, poich√© una lenta diminuzione pu√≤ suggerire che la catena sia ‚Äúintrappolata‚Äù e non esplori completamente il supporto della distribuzione target.\nIl correlogramma, che mostra l‚Äôautocorrelazione in funzione dei ritardi fino a un certo valore (ad esempio 20), √® utile per valutare questa caratteristica. Se l‚Äôautocorrelazione a lag 1 non √® eccessivamente alta e diminuisce rapidamente con l‚Äôincremento dei lag, ci√≤ indica che la catena sta fornendo una buona approssimazione di un campionamento casuale dalla distribuzione \\(p(\\theta \\mid y)\\).\nCatene che mostrano un rapido ‚Äúmixing‚Äù si comportano in modo simile a un campione indipendente: i valori si concentrano nei range pi√π plausibili della distribuzione a posteriori e l‚Äôautocorrelazione tra i campioni diminuisce rapidamente, risultando in un rapporto campionario effettivo alto. Al contrario, catene che non sono rapidamente ‚Äúmixing‚Äù tendono a non concentrarsi nei valori pi√π plausibili, presentano un‚Äôautocorrelazione che diminuisce lentamente e un rapporto campionario effettivo basso.\nIn caso di catene non rapidamente ‚Äúmixing‚Äù, si possono adottare due strategie:\n\nAumento del Numero di Iterazioni: Anche una catena lenta nel ‚Äúmixing‚Äù pu√≤ alla fine fornire una buona approssimazione della distribuzione a posteriori se si permette un numero sufficientemente grande di iterazioni.\nThinning (Diradamento): Questo processo consiste nel selezionare solo alcuni campioni a intervalli regolari, come ogni secondo o ogni decimo valore della catena, con l‚Äôobiettivo di ridurre le autocorrelazioni presenti nei lag pi√π brevi.\n\nUn esempio pratico √® fornito da Martin, Kumar, e Lao (2022).\n\nfig, ax = plt.subplots(3, 1)  \naz.plot_autocorr(chains, combined=True, ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/4208770402.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-dimensione-effettiva-del-campione-√®-sufficiente",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-dimensione-effettiva-del-campione-√®-sufficiente",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.4 La Dimensione Effettiva del Campione √à Sufficiente?",
    "text": "46.4 La Dimensione Effettiva del Campione √à Sufficiente?\nNell‚Äôambito delle analisi con catene di Markov Monte Carlo (MCMC), un aspetto strettamente correlato alla diagnosi di autocorrelazione √® la dimensione effettiva del campione, indicata con \\(N_{\\text{eff}}\\) nell‚Äôoutput del software Stan. Questa grandezza rappresenta una stima del numero di estrazioni indipendenti dalla distribuzione a posteriori. In altre parole, corrisponde al numero di campioni indipendenti che possiede lo stesso potere di stima di \\(T\\) campioni autocorrelati. Seguendo la notazione di Stan, la \\(N_{\\text{eff}}\\) √® calcolata come segue:\n\\[\nN_{\\text{eff}} = \\frac{T}{1 + 2 \\sum_{s=1}^{S} \\rho_{s}},\n\\]\ndove \\(T\\) √® il numero totale di campioni e \\(\\rho_{s}\\) rappresenta l‚Äôautocorrelazione a lag \\(s\\).\nPoich√© i campioni della distribuzione a posteriori non sono indipendenti, ci aspettiamo che la \\(N_{\\text{eff}}\\) sia minore del numero totale di estrazioni. Se il rapporto tra la dimensione effettiva del campione e il numero totale di estrazioni √® vicino a 1, ci√≤ indica che l‚Äôalgoritmo ha raggiunto un campionamento sostanzialmente indipendente. Valori molto inferiori potrebbero essere motivo di preoccupazione poich√© indicano una forte dipendenza tra i campioni, ma √® importante notare che questo rapporto dipende fortemente dalla scelta dell‚Äôalgoritmo MCMC, dal numero di iterazioni di ‚Äúwarmup‚Äù (o ‚Äúburn-in‚Äù), e dal numero di iterazioni successive al ‚Äúwarmup‚Äù.\nUn metodo per affrontare il problema dell‚Äôautocorrelazione e del conseguente abbassamento della dimensione effettiva del campione coinvolge l‚Äôuso del diradamento (thinning). Supponiamo che l‚Äôalgoritmo venga impostato per effettuare 3.000 estrazioni dalla distribuzione a posteriori. Questo pu√≤ essere paragonato a effettuare 30.000 estrazioni ma conservando solo ogni decima. Sebbene questo metodo sia un modo per ridurre il carico sulla memoria, il vantaggio √® che tipicamente l‚Äôautocorrelazione viene ridotta, risultando in una dimensione effettiva del campione maggiore.\nPer distinguere tra buone e cattive catene MCMC, possiamo utilizzare la statistica \\(N_{\\text{eff}}\\). Un basso valore di \\(N_{\\text{eff}}\\) pu√≤ indicare una catena con una mescolanza insufficiente, suggerendo la necessit√† di aumentare il numero di iterazioni o di implementare il diradamento. In contrasto, un valore alto di \\(N_{\\text{eff}}\\) √® indice di una catena con una buona mescolanza, che assicura un campionamento efficace dalla distribuzione a posteriori. Esempi pratici di queste considerazioni sono illustrati in Martin, Kumar, e Lao (2022), dove la statistica \\(N_{\\text{eff}}\\) √® utilizzata per valutare la qualit√† delle catene MCMC.\n\n_, axes = plt.subplots(2, 3, sharey=True, sharex=True)\naz.plot_ess(chains, kind=\"local\", ax=axes[0])\naz.plot_ess(chains, kind=\"quantile\", ax=axes[1])\n\nfor ax_ in axes[0]:\n    ax_.set_xlabel(\"\")\nfor ax_ in axes[1]:\n    ax_.set_title(\"\")\n\nfor ax_ in axes[:, 1:].ravel():\n    ax_.set_ylabel(\"\")\nplt.ylim(-100, 5000);",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-statistica-hatr-√®-prossima-a-uno",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-statistica-hatr-√®-prossima-a-uno",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.5 La Statistica \\(\\hat{R}\\) √à Prossima a Uno?",
    "text": "46.5 La Statistica \\(\\hat{R}\\) √à Prossima a Uno?\nNell‚Äôambito dell‚Äôanalisi bayesiana, √® cruciale assicurarsi che ogni catena di Markov sia stazionaria e che le diverse catene mostrino coerenza tra loro. La statistica \\(\\hat{R}\\), introdotta da Gelman e Rubin nel 1992, serve proprio a valutare il grado di convergenza tra pi√π catene per ciascun parametro in esame. Questo indicatore si basa sul confronto tra due tipi di varianza: la varianza media all‚Äôinterno di ogni singola catena (W) e la varianza tra le diverse catene (B). Questo metodo ricorda l‚Äôapproccio dell‚Äôanalisi della varianza unidirezionale, in cui si confrontano stime di varianza per determinare se esistono differenze significative, in questo caso tra le catene.\nLa formula per calcolare \\(\\hat{R}\\) √® \\(\\hat{R} = \\frac{W + \\frac{1}{n} (B - W)}{W}\\), e tale metrica viene calcolata automaticamente dalla maggior parte dei software Bayesiani, come indicato da Gelman e collaboratori nel 2014. Nel contesto pratico, un valore di \\(\\hat{R}\\) superiore a 1.1 √® generalmente considerato un segnale di convergenza inadeguata delle catene. Inoltre, √® fondamentale esaminare visivamente la convergenza delle catene attraverso il confronto delle distribuzioni posteriori di ciascun parametro per ogni catena. In condizioni ideali, \\(\\hat{R}\\) dovrebbe essere pari a 1. Se \\(\\hat{R}\\) si discosta notevolmente da questo valore, ci√≤ indica che la convergenza non √® stata ancora raggiunta.\nPi√π specificamente, un valore di \\(\\hat{R}\\) maggiore di 1.01, secondo Vehtari et al. (2021), segnala una mancanza di coerenza nelle approssimazioni della distribuzione a posteriori ottenute dalle diverse catene parallele. Un valore cos√¨ elevato di \\(\\hat{R}\\) suggerisce una simulazione non stabile, indicando la necessit√† di ulteriori iterazioni o di un raffinamento del modello per garantire una convergenza affidabile. Questo aspetto √® fondamentale per assicurare che le simulazioni Monte Carlo basate su catene di Markov (MCMC) forniscano risultati consistenti e attendibili per l‚Äôanalisi statistica in corso.\n\naz.rhat(chains)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:      ()\nData variables:\n    bad_chains0  float64 8B 2.43\n    bad_chains1  float64 8B 1.018\n    good_chains  float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)bad_chains0()float642.43array(2.42962207)bad_chains1()float641.018array(1.01782964)good_chains()float641.001array(1.00080843)Indexes: (0)Attributes: (0)\n\n\nNell‚Äôesempio di Martin, Kumar, e Lao (2022) vediamo come \\(\\hat{R}\\) √® in grado di distinguere tra le buone e le cattive catene MCMC. Mentre bad_chains0 ha valori \\(\\hat{R}\\) totalmente inadeguati, bad_chains1 tende ad avere valori accettabili e good_chains ha un valore \\(\\hat{R}\\) praticamente uguale a 1.0.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-diagnostica-di-geweke-√®-prossima-a-zero",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-diagnostica-di-geweke-√®-prossima-a-zero",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.6 La Diagnostica di Geweke √à Prossima a Zero?",
    "text": "46.6 La Diagnostica di Geweke √à Prossima a Zero?\nLa statistica diagnostica di convergenza di Geweke √® basata su un test per l‚Äôuguaglianza delle medie della prima e dell‚Äôultima parte di una catena di Markov (di default il primo 10% e l‚Äôultimo 50% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.\nInterpretazione: la statistica di Geweke √® uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali; valori maggiori di \\(\\mid 2 \\mid\\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#lerrore-standard-di-monte-carlo-√®-piccolo",
    "href": "chapters/mcmc/04_stan_diagnostics.html#lerrore-standard-di-monte-carlo-√®-piccolo",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.7 L‚ÄôErrore Standard di Monte Carlo √à Piccolo?",
    "text": "46.7 L‚ÄôErrore Standard di Monte Carlo √à Piccolo?\nQuando utilizziamo i metodi MCMC introduciamo un ulteriore livello di incertezza poich√© stiamo approssimando il posteriore con un numero finito di campioni. Possiamo stimare la quantit√† di questo tipo di errore mediante la statistica errore standard di Monte Carlo (MCSE). Il MCSE √® definitp come la deviazione standard delle catene MCMC divisa per la loro numerosit√† campionaria effettiva (ESS). Il MCSE ci fornisce dunque un‚Äôindicazione quantitativa di quanto √® grande sia il ‚Äúrumore‚Äù della stima.\nPer l‚Äôesempio di Martin, Kumar, e Lao (2022) otteniamo i valori seguenti.\n\naz.mcse(chains)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:      ()\nData variables:\n    bad_chains0  float64 8B 0.1087\n    bad_chains1  float64 8B 0.01616\n    good_chains  float64 8B 0.002583xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)bad_chains0()float640.1087array(0.10870935)bad_chains1()float640.01616array(0.01615769)good_chains()float640.002583array(0.00258312)Indexes: (0)Attributes: (0)\n\n\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 9))  \naz.plot_mcse(chains, ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/1242931680.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-di-rango-sono-piatti",
    "href": "chapters/mcmc/04_stan_diagnostics.html#i-grafici-di-rango-sono-piatti",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.8 I Grafici di Rango Sono Piatti?",
    "text": "46.8 I Grafici di Rango Sono Piatti?\nIn alcune situazioni, l‚Äôinterpretazione dei grafici di traccia pu√≤ risultare estremamente complessa. Ad esempio, quando si raccolgono un numero molto elevato di campioni, comprimere lunghe tracce in un grafico di dimensioni standard pu√≤ occultare alcuni comportamenti problematici delle catene, facendo apparire erroneamente buone le tracce. Giudicare i grafici di traccia pu√≤ essere difficile anche quando le distribuzioni sono fortemente asimmetriche e/o a code pesanti. Per queste ragioni, ora si raccomanda di utilizzare i grafici di rango oltre, se non al posto, dei grafici di traccia, in modo che qualsiasi differenza nei valori campionati da ogni catena possa essere riconosciuta in un modo pi√π affidabile (Vehtari et al., 2021).\nIn statistica, il ‚Äúrango‚Äù di un‚Äôosservazione √® la sua posizione in un insieme di dati ordinati. Ad esempio, consideriamo il seguente insieme di dati: [5, 3, 8, 10]. Se ordiniamo questi dati in ordine crescente otterremo [3, 5, 8, 10]. In questo caso, il rango del numero 5 √® 2 perch√© √® il secondo numero nell‚Äôinsieme ordinato. Allo stesso modo, il rango del numero 10 √® 4 perch√© √® il quarto numero nell‚Äôinsieme ordinato.\nI grafici di rango rappresentano un nuovo strumento diagnostico che si ottiene ordinando i campioni aggregati da tutte le catene, e poi presentando un istogramma dei ranghi derivanti da ogni catena separatamente. Se tutte le catene hanno come target la stessa distribuzione, allora la distribuzione dei ranghi per ogni catena dovrebbe approssimare una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ci√≤ indica una buon mixing delle catene. Le deviazioni dall‚Äôuniformit√† possono indicare una vasta gamma di problemi di convergenza. Qui sotto √® riportato l‚Äôesempio fornito da Martin, Kumar, e Lao (2022):\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 8))  \naz.plot_rank(chains, kind=\"bars\", ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/2441558539.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa (con dei segmenti verticali al posto delle barre) √® la seguente:\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 8))  \naz.plot_rank(chains, kind=\"vlines\", ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_24737/353816278.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#ci-sono-transizioni-divergenti",
    "href": "chapters/mcmc/04_stan_diagnostics.html#ci-sono-transizioni-divergenti",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.9 Ci Sono Transizioni Divergenti?",
    "text": "46.9 Ci Sono Transizioni Divergenti?\nQuando usiamo l‚Äôalgoritmo di campionamento Hamiltonian Monte Carlo (HMC), √® molto importante assicurarci che non ci siano ‚Äútransizioni divergenti‚Äù riportate nei risultati. Idealmente, il numero di queste transizioni dovrebbe essere zero. Una transizione divergente √® come un segnale di allarme che ci avverte di possibili problemi nella fase in cui l‚Äôalgoritmo esplora i vari parametri. In pratica, indica che l‚Äôalgoritmo non √® riuscito a esaminare correttamente alcune aree dello spazio dei parametri.\nOgni volta che notiamo una transizione divergente, dobbiamo indagare attentamente il motivo. La presenza di queste transizioni ci dice che l‚Äôalgoritmo potrebbe non avere esplorato adeguatamente certe zone, mettendo a rischio l‚Äôaffidabilit√† delle conclusioni del nostro studio. In presenza di divergenze, i campioni risultanti non possono essere considerati affidabili e, pertanto, non dovrebbero essere impiegati per la stima dei parametri, il confronto tra modelli, o qualsiasi altra forma di inferenza statistica Gelman et al. (2020).\nPer capire e risolvere il problema delle transizioni divergenti, possiamo considerare diverse soluzioni:\n\nControllo dei dati: √à utile controllare se ci sono dati anormali o estremi che potrebbero complicare il lavoro dell‚Äôalgoritmo.\nValutazione delle distribuzioni a priori: Dobbiamo assicurarci che le distribuzioni a priori usate si adattino bene al modello e ai dati che stiamo analizzando. Se non sono appropriate, possono creare problemi durante l‚Äôesplorazione dello spazio dei parametri.\nRegolazione della dimensione del passo: √à importante controllare e, se necessario, modificare la dimensione del passo (o step size) dell‚Äôalgoritmo HMC. Un passo troppo lungo o troppo breve pu√≤ causare instabilit√† e favorire l‚Äôoccorrenza di transizioni divergenti.\n\nAffrontando questi problemi con attenzione, possiamo migliorare la performance dell‚Äôalgoritmo HMC e ridurre il rischio di incontrare transizioni divergenti. Risolvere questi problemi √® fondamentale per assicurare che l‚Äôalgoritmo fornisca una rappresentazione precisa della distribuzione a posteriori e per garantire inferenze statistiche corrette.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-bmfi-√®-sufficientemente-grande",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-bmfi-√®-sufficientemente-grande",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.10 LA BMFI √à Sufficientemente Grande?",
    "text": "46.10 LA BMFI √à Sufficientemente Grande?\nUn altro strumento diagnostico che √® stato recentemente sviluppato per il campionamento HMC/NUTS si chiama Bayesian Fraction of Missing Information (BFMI), calcolato in modo bayesiano. Questo indicatore si basa sull‚Äôanalisi delle variazioni di energia durante ciascuna iterazione del campionamento nelle catene. Esso ci permette di capire con maggiore precisione quanto bene l‚Äôalgoritmo HMC/NUTS sta funzionando a un livello pi√π dettagliato rispetto ad altre tecniche di diagnostica.\nUn valore basso di BFMI in una catena specifica indica che l‚Äôalgoritmo non sta esplorando efficacemente la distribuzione dei dati che stiamo analizzando, il che pu√≤ portare a risultati distorti o fuorvianti. √à generalmente accettato che il valore di BFMI debba essere almeno 0.2 per ogni catena. Se in una o pi√π catene il valore scende al di sotto di 0.2, si considera che i risultati ottenuti non siano affidabili per fare inferenze corrette, poich√© le stime prodotte potrebbero essere distorte (Betancourt 2016).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#la-leave-one-out-cross-validation-fornisce-evidenze-di-buon-adattamento",
    "href": "chapters/mcmc/04_stan_diagnostics.html#la-leave-one-out-cross-validation-fornisce-evidenze-di-buon-adattamento",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.11 La Leave-One-Out Cross-Validation Fornisce Evidenze di Buon Adattamento?",
    "text": "46.11 La Leave-One-Out Cross-Validation Fornisce Evidenze di Buon Adattamento?\nLa Leave-One-Out Cross-Validation (LOO) rappresenta un metodo ampiamente impiegato nell‚Äôambito dell‚Äôanalisi bayesiana per valutare quanto adeguatamente un modello statistico si adatta ai dati osservati. Immaginiamo di avere una serie di foto e di voler valutare quanto bene un software riesce a riconoscere le persone in queste foto. La LOO ci aiuta a testare il software in un modo accurato.\nIl processo √® semplice: prendiamo tutte le foto tranne una, e usiamo queste per insegnare al software come riconoscere le persone. Poi, usiamo la foto che abbiamo messo da parte per vedere se il software riesce a riconoscere la persona in quella foto. Ripetiamo questo processo per ogni singola foto, una alla volta. Ogni volta, il software apprende da tutte le foto tranne una, e quella esclusa serve per testarlo.\nQuesto metodo √® molto efficace perch√© assicura che il software non impari solo a riconoscere le persone nelle foto specifiche che ha gi√† visto (questo si chiama ‚Äúoverfitting‚Äù, ovvero sovraadattamento), ma che sia davvero capace di riconoscere persone anche in foto nuove che non ha mai analizzato. Inoltre, evita il problema opposto, chiamato ‚Äúunderfitting‚Äù, dove il software non impara abbastanza dai dati e quindi non riesce a fare buone previsioni.\nNel contesto dell‚Äôanalisi bayesiana, dove si utilizzano modelli statistici complessi, la LOO √® spesso accompagnata da calcoli come il logaritmo della verosimiglianza, che aiutano a quantificare quanto bene il modello riesce a prevedere i dati esclusi. I risultati di questi calcoli possono essere usati per calcolare un indice chiamato LOOIC (Leave-One-Out Information Criterion), che permette di confrontare diversi modelli per scegliere quello che si adatta meglio ai dati.\nIn conclusione, la LOO √® uno strumento molto utile per valutare in modo imparziale e preciso quanto bene un modello statistico possa prevedere nuovi dati, garantendo che le nostre previsioni siano il pi√π accurate possibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#il-parametro-k",
    "href": "chapters/mcmc/04_stan_diagnostics.html#il-parametro-k",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "46.12 Il Parametro \\(k\\)",
    "text": "46.12 Il Parametro \\(k\\)\nIl parametro \\(k\\), noto anche come parametro di coda di Pareto, riveste un ruolo importante nell‚Äôambito del campionamento MCMC. √à utilizzato per valutare l‚Äôefficienza e la convergenza delle catene di campionamento, nonch√© per misurare la qualit√† del processo di campionamento di importanza, come nel caso del Pareto Smoothed Importance Sampling (PSIS).\nImmaginiamo di essere a una festa dove stai cercando di scoprire quale gusto di gelato √® il preferito tra gli invitati. Invece di chiedere a tutti, decidiamo di assaggiare solo alcuni gelati per avere un‚Äôidea generale. Questo processo di selezionare solo alcuni gelati per fare un‚Äôassunzione sul gusto preferito √® simile a quello che avviene nel campionamento per l‚ÄôImportance Sampling: scegliamo solo alcuni punti (o ‚Äúcampioni‚Äù) da un insieme molto grande per fare delle stime su tutta la popolazione.\nNel Pareto Smoothed Importance Sampling (PSIS), dopo aver scelto i campioni, cerchiamo di ‚Äúlisciare‚Äù le nostre stime per renderle pi√π precise e meno variabili. Pensalo come se stessi cercando di bilanciare le risposte per non dare troppo peso a poche opinioni estreme.\nIl parametro \\(k\\) ci dice quanto siamo vicini a raggiungere questo obiettivo di bilanciamento. Se \\(k\\) √® vicino a 0, significa che abbiamo fatto un buon lavoro: le nostre stime sono affidabili e non troppo dipendenti da pochi campioni estremi. Se, invece, \\(k\\) √® pi√π alto, specialmente sopra 0.7, ci indica che ci sono problemi: forse abbiamo dato troppo peso a poche opinioni estreme, o non abbiamo un buon mix di opinioni per fare una stima affidabile. In pratica, un \\(k\\) alto √® come un campanello d‚Äôallarme che ci dice che dobbiamo essere cauti con le nostre conclusioni e, possibilmente, raccogliere pi√π dati o ripensare come li stiamo campionando.\nIn sostanza, il parametro \\(k\\) √® uno strumento per aiutarci a capire quanto possiamo fidarci delle nostre stime basate su un campione limitato di dati. Un valore basso √® buono, indicando che le stime sono solide e ben equilibrate, mentre un valore alto suggerisce che potremmo avere dei problemi e che dovremmo esaminare pi√π attentamente i dati che abbiamo raccolto.\nPer calcolare il parametro \\(\\hat{\\kappa}\\), √® possibile fare uso di ArviZ, uno strumento appositamente progettato per le analisi bayesiane avanzate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_diagnostics.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/04_stan_diagnostics.html#informazioni-sullambiente-di-sviluppo",
    "title": "46¬† Diagnostica delle catene markoviane",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jun 10 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nlogging   : 0.5.1.2\ncmdstanpy : 1.2.3\nscipy     : 1.13.1\narviz     : 0.18.0\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBetancourt, Michael. 2016. ¬´Diagnosing suboptimal cotangent disintegrations in Hamiltonian Monte Carlo¬ª. arXiv preprint arXiv:1604.00695.\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian B√ºrkner, e Martin Modr√°k. 2020. ¬´Bayesian workflow¬ª. arXiv preprint arXiv:2011.01808.\n\n\nMartin, Osvaldo A, Ravin Kumar, e Junpeng Lao. 2022. Bayesian Modeling and Computation in Python. CRC Press.\n\n\nSchoot, Van Rens de, Duco Veen, Laurent Smeets, e Sonja Winter. 2020. ¬´A tutorial on using the WAMBS checklist to avoid the misuse of Bayesian statistics¬ª. Routledge.\n\n\nVehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, e Paul-Christian B√ºrkner. 2021. ¬´Rank-normalization, folding, and localization: An improved R ÃÇ for assessing convergence of MCMC (with discussion)¬ª. Bayesian analysis 16 (2): 667‚Äì718.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>46</span>¬† <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html",
    "href": "chapters/mcmc/05_stan_prediction.html",
    "title": "47¬† La predizione bayesiana",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esamineremo in dettaglio le distribuzioni predittive a priori e a posteriori. La distribuzione predittiva a priori rappresenta le aspettative sui dati prima di qualsiasi osservazione reale, riflettendo le conoscenze preesistenti e le ipotesi sui parametri del modello. Essa fornisce un‚Äôindicazione delle caratteristiche che i dati potrebbero assumere in base al modello. Confrontare queste previsioni con i dati effettivamente osservati consente di valutare la validit√† delle ipotesi incorporate nel modello.\nLa distribuzione predittiva √® spesso di maggiore interesse rispetto alla distribuzione a posteriori. Mentre la distribuzione a posteriori descrive l‚Äôincertezza sui parametri (ad esempio, la proporzione di palline rosse in un‚Äôurna), la distribuzione predittiva descrive anche l‚Äôincertezza sugli eventi futuri (ad esempio, il colore della pallina che verr√† estratta in futuro). Questa differenza √® cruciale, soprattutto quando si tratta di prevedere gli effetti di un intervento, come la somministrazione di un trattamento a un paziente.\nLa distribuzione predittiva a posteriori √® inoltre fondamentale per valutare quanto le previsioni del modello siano coerenti con i dati osservati. Se le previsioni del modello risultano allineate con i dati raccolti, il modello pu√≤ essere considerato accurato nel rappresentare il processo generativo sottostante. Questo confronto √® essenziale per convalidare il modello e assicurarsi che le ipotesi riflettano adeguatamente la realt√† osservata.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#sec-posterior-predictive-distribution",
    "href": "chapters/mcmc/05_stan_prediction.html#sec-posterior-predictive-distribution",
    "title": "47¬† La predizione bayesiana",
    "section": "47.1 La distribuzione predittiva a posteriori",
    "text": "47.1 La distribuzione predittiva a posteriori\nLa distribuzione predittiva a posteriori offre una valutazione critica della coerenza tra i dati reali e quelli simulati dal modello (Gelman e Shalizi 2013). Confrontando direttamente i dati osservati con quelli generati dal modello, essa permette di identificare eventuali discrepanze che potrebbero segnalare problemi nella specificazione del modello. In pratica, la PPC (Posterior Predictive Check) funge da test diagnostico, consentendo di rilevare e correggere eventuali carenze nel modello, migliorandone cos√¨ le capacit√† predittive.\nPer comprendere meglio il concetto, consideriamo la distribuzione predittiva a posteriori in termini di un modello coniugato normale-normale. Supponiamo di voler predire la media di una distribuzione normale futura, basandoci sui dati osservati e sulle nostre conoscenze a priori. La PPD ci offre uno strumento per calcolare queste probabilit√†, combinando le informazioni provenienti dai dati osservati con quelle fornite dalla distribuzione a priori.\nAd esempio, immaginiamo di aver raccolto dati sulle altezze di 100 persone, ottenendo una media campionaria di 170 cm e una deviazione standard campionaria di 10 cm. Il nostro obiettivo √® stimare la media delle altezze in un futuro campione di \\(n=100\\) persone. La nostra conoscenza a priori sulla media delle altezze √® rappresentata da una distribuzione normale con media 175 cm e deviazione standard di 5 cm.\nIn termini di notazione, possiamo esprimere questa distribuzione come \\(P(\\tilde{y}|\\theta=\\theta_1)\\), dove \\(\\tilde{y}\\) rappresenta un nuovo dato che √® diverso dai dati attuali \\(y\\), e \\(\\theta_1\\) √® la media a posteriori. Tuttavia, in statistica bayesiana, √® fondamentale incorporare tutta l‚Äôincertezza nei risultati. Poich√© \\(\\theta_1\\) √® solo uno dei possibili valori per \\(\\theta\\), dovremmo includere ogni valore di \\(\\theta\\) per la nostra previsione. Per ottenere la migliore previsione, possiamo ‚Äúmediare‚Äù le previsioni attraverso i diversi valori di \\(\\theta\\), ponderando ciascun valore secondo la sua probabilit√† a posteriori.\nLa distribuzione risultante √® la distribuzione predittiva a posteriori, che in notazione matematica √® data da:\n\\[ P(\\tilde{y}|y) = \\int_\\theta p(\\tilde{y}|\\theta, y) p(\\theta|y) d\\theta. \\]\nIn questo modo, la distribuzione predittiva a posteriori combina le informazioni dai dati osservati con la conoscenza a priori, fornendo una previsione che riflette l‚Äôincertezza associata a tutti i possibili valori dei parametri del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "href": "chapters/mcmc/05_stan_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "title": "47¬† La predizione bayesiana",
    "section": "47.2 Distribuzione predittiva a posteriori nel modello normale-normale",
    "text": "47.2 Distribuzione predittiva a posteriori nel modello normale-normale\nNel modello coniugato normale-normale, se i dati osservati \\(Y = \\{y_1, y_2, ..., y_n\\}\\) sono modellati come provenienti da una distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e assumendo una distribuzione a priori normale per \\(\\mu\\), la distribuzione a posteriori di \\(\\mu\\) sar√† anch‚Äôessa normale.\n\n47.2.1 Formule della distribuzione predittiva a posteriori\nDato che:\n\nI dati osservati \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nLa prior per \\(\\mu\\) √® \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)\\)\n\nLa distribuzione a posteriori per \\(\\mu\\) sar√†:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)\n\\]\ndove:\n\\[\n\\mu_n = \\frac{\\tau_0^2 \\bar{y} + \\sigma^2 \\mu_0}{\\tau_0^2 + \\sigma^2}\n\\]\ne\n\\[\n\\tau_n^2 = \\frac{\\tau_0^2 \\sigma^2}{\\tau_0^2 + \\sigma^2}\n\\]\nQui, \\(\\bar{y}\\) √® la media campionaria dei dati osservati.\n\nEsempio 47.1 Consideriamo che:\n\n\\(\\mu_0 = 175\\) cm (media a priori)\n\\(\\tau_0 = 5\\) cm (deviazione standard a priori)\n\\(\\bar{y} = 170\\) cm (media campionaria)\n\\(\\sigma = 10\\) cm (deviazione standard campionaria)\n\\(n = 100\\) (numero di osservazioni)\n\nI parametri della distribuzione a posteriori sono:\n\\[\n\\mu_n = \\frac{(5^2 \\cdot 170) + (10^2 \\cdot 175)}{5^2 + 10^2} = \\frac{42500 + 175000}{25 + 100} = \\frac{217500}{125} = 174 \\quad \\text{cm}\n\\]\n\\[\n\\tau_n^2 = \\frac{5^2 \\cdot 10^2}{5^2 + 10^2} = \\frac{2500}{125} = 20 \\quad \\text{cm}^2 \\Rightarrow \\tau_n = \\sqrt{20} \\approx 4.47 \\quad \\text{cm}\n\\]\nPertanto, la distribuzione a posteriori per \\(\\mu\\) √®:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(174, 4.47^2)\n\\]\nPer la distribuzione predittiva a posteriori, dobbiamo considerare anche la varianza della distribuzione futura. Se stiamo predicendo per \\(n_{\\text{fut}}=100\\) nuove osservazioni, la varianza della media predittiva sar√†:\n\\[\n\\sigma_{\\text{pred}}^2 = \\tau_n^2 + \\frac{\\sigma^2}{n_{\\text{fut}}}\n\\]\n\\[\n\\sigma_{\\text{pred}}^2 = 20 + \\frac{10^2}{100} = 20 + 1 = 21 \\quad \\text{cm}^2 \\Rightarrow \\sigma_{\\text{pred}} = \\sqrt{21} \\approx 4.58 \\quad \\text{cm}\n\\]\nQuindi, la distribuzione predittiva a posteriori √®:\n\\[\n\\tilde{Y} \\sim \\mathcal{N}(174, 4.58^2)\n\\]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#implementazione-con-cmdstanpy",
    "href": "chapters/mcmc/05_stan_prediction.html#implementazione-con-cmdstanpy",
    "title": "47¬† La predizione bayesiana",
    "section": "47.3 Implementazione con cmdstanpy",
    "text": "47.3 Implementazione con cmdstanpy\nPer illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare cmdstanpy per eseguire l‚Äôanalisi. Il codice seguente mostra come configurare il modello e generare previsioni.\n\n# Dati osservati\ny_observed = np.random.normal(170, 10, 100)\nmean_y = np.mean(y_observed)\nstd_y = np.std(y_observed)\n\n# Parametri a priori\nmu_0 = 175\ntau_0 = 5\n\n# Parametri posteriori\ntau_n_sq = (tau_0**2 * std_y**2) / (tau_0**2 + std_y**2)\ntau_n = np.sqrt(tau_n_sq)\nmu_n = (tau_0**2 * mean_y + std_y**2 * mu_0) / (tau_0**2 + std_y**2)\n\n# Parametri predittivi\nn_fut = 100\nsigma_pred_sq = tau_n_sq + (std_y**2 / n_fut)\nsigma_pred = np.sqrt(sigma_pred_sq)\nmu_pred = mu_n\n\n# Simulazioni\ny_pred_samples = np.random.normal(mu_pred, sigma_pred, 1000)\n\ncolor_fill = \"#B17F7D\"\ncolor_edge = \"#832F2B\"\n\n# Grafico\nplt.hist(y_pred_samples, bins=30, density=True, color=color_fill, alpha=0.5, label='Posterior Predictive')\nx = np.linspace(160, 190, 200)\nplt.plot(x, stats.norm.pdf(x, mu_pred, sigma_pred), 'r-', lw=2, label='Predictive Distribution')\nplt.axvline(x=mu_pred, color=color_edge, linestyle='--', label='Mean Prediction')\nplt.xlabel('Heights (cm)')\nplt.ylabel('Density')\nplt.title('Posterior Predictive Distribution for Heights')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori √® stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#metodo-mcmc",
    "href": "chapters/mcmc/05_stan_prediction.html#metodo-mcmc",
    "title": "47¬† La predizione bayesiana",
    "section": "47.4 Metodo MCMC",
    "text": "47.4 Metodo MCMC\nQuando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che √® particolarmente utile in scenari complessi dove l‚Äôanalisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future \\(p(\\tilde{y} \\mid y)\\), indicate come \\(p(y^{rep} \\mid y)\\), seguendo questi passaggi:\n\nSi campiona \\(\\theta_i \\sim p(\\theta \\mid y)\\): Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.\nSi campiona \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\): Viene scelta casualmente un‚Äôosservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.\n\nRipetendo questi due passaggi un numero sufficiente di volte, l‚Äôistogramma risultante approssimer√† la distribuzione predittiva a posteriori.\nEsaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell‚Äôesempio precedente. Iniziamo creando le distribuzioni a posteriori di \\(\\mu\\) e \\(\\sigma\\).\n\nstan_ncp_file = os.path.join(\n    project_directory, 'stan', 'gaussian_model.stan')\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\nprint(model_ncp.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of observations\n  vector[N] y; // observed data\n  real mu_prior; // prior mean for mu\n  real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n  real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n  real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n}\nparameters {\n  real mu; // parameter of interest\n  real&lt;lower=0&gt; sigma; // parameter for the standard deviation\n}\nmodel {\n  mu ~ normal(mu_prior, sigma_prior); // prior for mu\n  sigma ~ normal(sigma_prior_mean, sigma_prior_sd); // prior for sigma\n  y ~ normal(mu, sigma); // likelihood\n}\ngenerated quantities {\n  array[N] real y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\n\n\nDefiniamo un dizionario che contiene i dati.\n\nstan_data = {\n    'N': len(y_observed), \n    'y': y_observed,\n    'mu_prior': 180,\n    'sigma_prior': 20,\n    'sigma_prior_mean': 10,\n    'sigma_prior_sd': 3\n}\n\nprint(stan_data)\n\n{'N': 100, 'y': array([162.84787146, 161.04839081, 179.47577095, 181.12527437,\n       171.49098193, 159.22874224, 176.45915011, 185.03984279,\n       155.86708548, 166.74740115, 178.42289272, 172.60852497,\n       172.44806286, 167.26396127, 166.30450208, 170.05155153,\n       180.8355277 , 172.55633398, 170.17618804, 173.07907092,\n       163.54108406, 165.73937461, 181.31548994, 149.61562483,\n       167.40960479, 170.69764087, 155.04683583, 174.53102596,\n       174.13818648, 156.86288728, 151.03523009, 157.39548176,\n       163.70335409, 166.11651898, 155.22542166, 165.02308717,\n       169.6978678 , 184.06879508, 179.77051126, 160.28623502,\n       168.35101542, 170.29659473, 154.82238549, 178.62021142,\n       176.1802103 , 157.61538566, 163.02477907, 182.03113017,\n       192.00390212, 167.57285945, 179.18080576, 172.08287015,\n       154.41187389, 159.49697373, 170.1896094 , 174.42961851,\n       170.80827696, 168.62216784, 163.97488914, 164.5576843 ,\n       161.13774343, 160.59831839, 174.79536747, 181.71164366,\n       185.60098039, 160.46056883, 158.34680483, 155.84009689,\n       182.21908406, 163.21383868, 181.04765122, 177.73559479,\n       176.09674444, 145.33347281, 167.16959796, 171.78867767,\n       194.14953508, 177.29486361, 171.08615454, 155.68094096,\n       175.51890099, 183.82918407, 178.04883624, 158.13937901,\n       169.96512415, 162.17717457, 190.64787268, 169.68701713,\n       176.276485  , 157.29360776, 175.59538391, 189.98182609,\n       166.98236999, 163.19208668, 160.11878234, 164.24464514,\n       172.26831966, 165.03295583, 177.08597046, 177.22899718]), 'mu_prior': 180, 'sigma_prior': 20, 'sigma_prior_mean': 10, 'sigma_prior_sd': 3}\n\n\n\ny_mean = np.mean(y_observed)\ny_std = np.std(y_observed)\n\nprint(f\"Mean of y: {y_mean}\")\nprint(f\"Standard Deviation of y: {y_std}\")\n\nMean of y: 169.57193226941754\nStandard Deviation of y: 9.930634097490112\n\n\nEseguiamo il campionamento MCMC:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n16:57:29 - cmdstanpy - INFO - CmdStan start processing\n16:57:29 - cmdstanpy - INFO - Chain [1] start processing\n16:57:29 - cmdstanpy - INFO - Chain [2] start processing\n16:57:29 - cmdstanpy - INFO - Chain [3] start processing\n16:57:29 - cmdstanpy - INFO - Chain [4] start processing\n16:57:29 - cmdstanpy - INFO - Chain [1] done processing\n16:57:29 - cmdstanpy - INFO - Chain [2] done processing\n16:57:29 - cmdstanpy - INFO - Chain [3] done processing\n16:57:29 - cmdstanpy - INFO - Chain [4] done processing\n\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\naz.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n169.62\n1.00\n167.73\n171.43\n0.01\n0.01\n6155.68\n5203.68\n1.0\n\n\nsigma\n10.09\n0.71\n8.69\n11.35\n0.01\n0.01\n7169.12\n5070.39\n1.0\n\n\n\n\n\n\n\n\nConvertiamo l‚Äôoggetto sample_ncp in un oggetto di classe InferenceData:\n\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp, \n    posterior_predictive='y_rep', \n    observed_data={\"y\": y_observed}\n)\n\nLa distribuzione predittiva a posteriori √® utilizzata per eseguire i controlli predittivi a posteriori (PPC), noti come Posterior Predictive Checks. I PPC consistono in un confronto grafico tra \\(p(y^{rep} \\mid y)\\), ossia la distribuzione delle osservazioni future previste, e i dati osservati \\(y\\). Questo confronto visivo permette di valutare se il modello utilizzato √® adeguato per descrivere le propriet√† dei dati osservati.\nOltre al confronto grafico tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\), √® possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni \\(y^{rep}\\) e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma √® possibile confrontare qualsiasi altra statistica rilevante.\nI controlli predittivi a posteriori offrono un valido strumento per un‚Äôanalisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi pi√π adatti ai dati in esame.\nPossiamo ora usare ArviZ per generare il posterior-predictive plot:\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#distribuzione-predittiva-a-priori",
    "href": "chapters/mcmc/05_stan_prediction.html#distribuzione-predittiva-a-priori",
    "title": "47¬† La predizione bayesiana",
    "section": "47.5 Distribuzione Predittiva a Priori",
    "text": "47.5 Distribuzione Predittiva a Priori\nLe verifiche predittive a priori generano dati utilizzando unicamente le distribuzioni a priori, ignorando i dati osservati, al fine di valutare se tali distribuzioni a priori sono appropriate (Gabry et al.¬†2019). La distribuzione predittiva a priori √® quindi simile alla distribuzione predittiva a posteriori, ma senza dati osservati, rappresentando il caso limite di una verifica predittiva a posteriori senza dati.\nQuesto processo pu√≤ essere realizzato facilmente simulando i parametri secondo le distribuzioni a priori e poi simulando i dati in base al modello dati i parametri simulati. Il risultato √® una simulazione dalla distribuzione predittiva a priori.\nQuesta procedura √® fondamentale per verificare se le ipotesi a priori sono realistiche e adeguate prima di raccogliere o utilizzare i dati osservati. Se i dati simulati dalla distribuzione predittiva a priori non risultano plausibili, potrebbe essere necessario rivedere le scelte delle distribuzioni a priori.\nUn prior predictive check √® codificato come un posterior predictive check. Se disponiamo gi√† del codice per un posterior predictive check ed √® possibile impostare i dati come vuoti, allora non √® necessario alcun codice ulteriore. I prior predictive checks possono essere codificati interamente all‚Äôinterno del blocco generated quantities utilizzando la generazione di numeri casuali. I draw risultanti saranno indipendenti.\nConsideriamo, quale esempio, il caso discusso in precedenza di un campione di dati gaussiani e di un modello gaussiano in cui le distribuzioni a priori per Œº e œÉ sono gaussiane.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'gaussian_model_prior.stan')\nmodel_gauss = CmdStanModel(stan_file=stan_file)\nprint(model_gauss.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of observations\n  real mu_prior; // prior mean for mu\n  real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n  real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n  real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n}\ngenerated quantities {\n  real mu = normal_rng(mu_prior, sigma_prior); // prior draw for mu\n  real&lt;lower=0&gt; sigma = normal_rng(sigma_prior_mean, sigma_prior_sd); // prior draw for sigma\n  array[N] real y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\n\n\nIl codice precedente\nfor (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\nillustra come generare campioni predittivi a priori nel blocco generated quantities. In questo esempio, mu e sigma sono generati dalle loro rispettive distribuzioni a priori e usati per generare campioni di dati simulati y_rep.\nEseguiamo il campionamento MCMC.\n\nprior_predictive_samples = model_gauss.sample(\n    data=stan_data, \n    fixed_param=True, \n    iter_sampling=1000, \n    iter_warmup=1, \n    chains=1,\n    show_progress=False, \n    show_console=False\n)\n\n16:57:47 - cmdstanpy - INFO - CmdStan start processing\n16:57:47 - cmdstanpy - INFO - Chain [1] start processing\n16:57:47 - cmdstanpy - INFO - Chain [1] done processing\n\n\nEstraiamo le variabili necessarie.\n\ny_rep_samples = prior_predictive_samples.stan_variable(\"y_rep\")\ny_rep_flattened = y_rep_samples.flatten()\n\nCalcoliamo le statistiche descrittive dei valori y_rep.\n\ny_rep_mean = np.mean(y_rep_flattened)\ny_rep_std = np.std(y_rep_flattened)\n\nprint(f'Mean of y_rep: {y_rep_mean}')\nprint(f'Standard Deviation of y_rep: {y_rep_std}')\n\nMean of y_rep: 179.22629213099998\nStandard Deviation of y_rep: 22.230201028377742\n\n\nCreiamo un KDE plot con la distribuzione predittiva a priori.\n\nsns.kdeplot(y_rep_flattened, fill=True, color=color_fill)\nplt.title('Prior Predictive Check')\nplt.xlabel('Height (cm)')\nplt.ylabel('Density')\nplt.axvline(x=y_rep_mean, color=color_edge, linestyle='--', label=f'Mean: {y_rep_mean:.2f}')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico della distribuzione predittiva a priori ci mostra che i prior utilizzati nel codice Stan implicano una distribuzione della variabile di interesse y che √® approssimativamente normale con media di 180.25 e deviazione standard di 22.23. Questo prior predictive check garantisce che le distribuzioni a priori dei parametri mu e sigma siano realistiche e adeguate per l‚Äôanalisi dei dati considerati. Questo passaggio consente di identificare e correggere eventuali ipotesi errate prima di procedere con l‚Äôanalisi dei dati osservati, migliorando cos√¨ la validit√† dei risultati ottenuti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#considerazioni-conclusive",
    "href": "chapters/mcmc/05_stan_prediction.html#considerazioni-conclusive",
    "title": "47¬† La predizione bayesiana",
    "section": "47.6 Considerazioni Conclusive",
    "text": "47.6 Considerazioni Conclusive\nLe distribuzioni predittive a priori e a posteriori, pur essendo generate in modo simile, differiscono per la fonte di informazione utilizzata nella loro costruzione.\n\nDistribuzione Predittiva a Priori: Questa distribuzione rappresenta le nostre aspettative sui dati prima che qualsiasi osservazione effettiva sia disponibile. Per costruirla, prendiamo i valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati simulati. La distribuzione risultante di questi dati generati √® la distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze iniziali, prima di osservare i dati reali.\nDistribuzione Predittiva a Posteriori: Dopo aver osservato i dati, aggiorniamo le nostre credenze sui parametri utilizzando il teorema di Bayes, ottenendo cos√¨ la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene quindi generata prendendo valori dei parametri dalla distribuzione a posteriori, che ora incorpora l‚Äôinformazione ottenuta dai dati osservati, e utilizzandoli nella funzione di verosimiglianza per generare nuovi dati simulati. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver tenuto conto dei dati gi√† raccolti.\n\nLa differenza principale tra queste due distribuzioni predittive risiede nella distribuzione dei parametri utilizzata: nella distribuzione predittiva a priori si utilizzano i parametri estratti dal prior, mentre nella distribuzione predittiva a posteriori si utilizzano i parametri estratti dal posterior. La distribuzione predittiva a posteriori √® generalmente pi√π informativa poich√© integra i dati osservati, migliorando le previsioni future.\n√à cruciale per l‚Äôintegrit√† del modello che la distribuzione predittiva a posteriori sia coerente con la distribuzione dei dati osservati. Per verificare questa coerenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite tecniche come le stime di densit√† kernel (KDE). Questo confronto permette di valutare quanto bene il modello riesca ad approssimare la struttura reale dei dati e la sua capacit√† di fornire previsioni affidabili.\nAd esempio, consideriamo un modello gaussiano con varianza \\(\\sigma^2\\) nota:\n\\[\n\\begin{aligned}\n  y\\sim \\mathop{\\mathrm{N}}(\\theta,\\sigma^2),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2\\) descrive l‚Äôincertezza aleatoria. Usando un prior uniforme, la distribuzione a posteriori per \\(\\theta\\) sar√†:\n\\[\n\\begin{aligned}\n  p(\\theta|y) \\sim \\mathop{\\mathrm{N}}(\\theta|\\bar{y},\\sigma^2/n),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2/n\\) rappresenta l‚Äôincertezza epistemica legata a \\(\\theta\\). La distribuzione predittiva a posteriori per un nuovo valore \\(\\tilde{y}\\) sar√†:\n\\[\n\\begin{aligned}\n  p(\\tilde{y}|y) \\sim \\mathop{\\mathrm{N}}(\\tilde{y}|\\bar{y},\\sigma^2+\\sigma^2/n),\n\\end{aligned}\n\\]\nIn questo caso, l‚Äôincertezza totale √® data dalla somma dell‚Äôincertezza epistemica (\\(\\sigma^2/n\\)) e dell‚Äôincertezza aleatoria (\\(\\sigma^2\\)).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_prediction.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/05_stan_prediction.html#informazioni-sullambiente-di-sviluppo",
    "title": "47¬† La predizione bayesiana",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Sun Aug 04 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, Andrew, e Cosma Rohilla Shalizi. 2013. ¬´Philosophy and the practice of Bayesian statistics¬ª. British Journal of Mathematical and Statistical Psychology 66 (1): 8‚Äì38.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>47</span>¬† <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html",
    "href": "chapters/mcmc/06_stan_odds_ratio.html",
    "title": "48¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo l‚Äôapplicazione degli strumenti statistici descritti nei capitoli precedenti all‚Äôanalisi bayesiana di due proporzioni. Inizieremo definendo i concetti di odds, odds ratio e logit. Successivamente, mostreremo come effettuare l‚Äôanalisi bayesiana per il confronto tra due proporzioni.\nUn rapporto di odds (OR) √® una misura di associazione tra un‚Äôesposizione (o un certo gruppo o una certa conditione) e un risultato. L‚ÄôOR rappresenta gli odds che si verifichi un risultato dato un‚Äôesposizione particolare, confrontate con gli odds del risultato che si verifica in assenza di tale esposizione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#odds",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#odds",
    "title": "48¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "48.1 Odds",
    "text": "48.1 Odds\nIl termine ‚Äúodds‚Äù rappresenta il rapporto tra la probabilit√† che un evento si verifichi e la probabilit√† che l‚Äôevento opposto si verifichi. Matematicamente, l‚Äôodds pu√≤ essere calcolato come:\n\\[ \\text{odds} = \\frac{\\pi}{1-\\pi}, \\]\ndove \\(\\pi\\) rappresenta la probabilit√† dell‚Äôevento di interesse.\nMentre una probabilit√† \\(\\pi\\) √® sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Per comprendere meglio gli odds lungo questo spettro, consideriamo tre diversi scenari in cui \\(\\pi\\) rappresenta la probabilit√† di un evento.\nSe la probabilit√† di un evento √® \\(\\pi = \\frac{2}{3}\\), allora la probabilit√† che l‚Äôevento non si verifichi √® \\(1 - \\pi = \\frac{1}{3}\\) e gli odds del verificarsi dell‚Äôevento sono:\n\\[ \\text{odds} = \\frac{2/3}{1-2/3} = 2. \\]\nQuesto significa che la probabilit√† che l‚Äôevento si verifichi √® il doppio della probabilit√† che non si verifichi.\nSe, invece, la probabilit√† dell‚Äôevento √® \\(\\pi = \\frac{1}{3}\\), allora gli odds che l‚Äôevento si verifichi sono la met√† rispetto agli odds che non si verifichi:\n\\[ \\text{odds} = \\frac{1/3}{1-1/3} = \\frac{1}{2}. \\]\nInfine, se la probabilit√† dell‚Äôevento √® \\(\\pi = \\frac{1}{2}\\), allora gli odds dell‚Äôevento sono pari a 1:\n\\[ \\text{odds} = \\frac{1/2}{1-1/2} = 1. \\]\n\n48.1.1 Interpretazione\nGli odds possono essere interpretati nel modo seguente. Consideriamo un evento di interesse con probabilit√† \\(\\pi \\in [0, 1]\\) e gli odds corrispondenti \\(\\frac{\\pi}{1-\\pi} \\in [0, \\infty)\\). Confrontando gli odds con il valore 1, possiamo ottenere una prospettiva sull‚Äôincertezza dell‚Äôevento:\n\nGli odds di un evento sono inferiori a 1 se e solo se le probabilit√† dell‚Äôevento sono inferiori al 50-50, cio√® \\(\\pi &lt; 0.5\\).\nGli odds di un evento sono uguali a 1 se e solo se le probabilit√† dell‚Äôevento sono del 50-50, cio√® \\(\\pi = 0.5\\).\nGli odds di un evento sono superiori a 1 se e solo se le probabilit√† dell‚Äôevento sono superiori al 50-50, cio√® \\(\\pi &gt; 0.5\\).\n\nUno dei motivi per preferire l‚Äôuso dell‚Äôodds rispetto alla probabilit√†, nonostante quest‚Äôultima sia un concetto pi√π intuitivo, risiede nel fatto che quando le probabilit√† si avvicinano ai valori estremi (cio√® 0 o 1), √® pi√π facile rilevare e apprezzare le differenze tra gli odds piuttosto che le differenze tra le probabilit√†.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#odds-ratio",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#odds-ratio",
    "title": "48¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "48.2 Odds Ratio",
    "text": "48.2 Odds Ratio\nQuando abbiamo una variabile di interesse espressa come proporzione, possiamo confrontare i gruppi utilizzando l‚Äôodds ratio. L‚Äôodds ratio rappresenta il rapporto tra gli odds di un evento in un gruppo e gli odds dello stesso evento in un secondo gruppo:\n\\[ OR = \\frac{odds_1}{odds_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}. \\]\nInterpretazione:\n\nOR = 1: l‚Äôappartenenza al gruppo non influenza il risultato;\nOR &gt; 1: l‚Äôappartenenza al gruppo specificato al numeratore dell‚ÄôOR aumenta la probabilit√† dell‚Äôevento rispetto al gruppo specificato al denominatore;\nOR &lt; 1: l‚Äôappartenenza al gruppo specificato al numeratore dell‚ÄôOR riduce la probabilit√† dell‚Äôevento rispetto al gruppo specificato al denominatore.\n\nL‚Äôodds ratio √® particolarmente utile quando vogliamo confrontare due gruppi e vedere come l‚Äôappartenenza a uno di essi influenza la probabilit√† di un certo evento. Ad esempio, consideriamo uno studio psicologico in cui stiamo valutando l‚Äôefficacia di una terapia comportamentale per ridurre l‚Äôansia. Possiamo suddividere i partecipanti allo studio in due gruppi: quelli che sono stati sottoposti al trattamento (gruppo di trattamento) e quelli che non sono stati sottoposti al trattamento (gruppo di controllo).\nCalcolando l‚Äôodds ratio tra il gruppo di trattamento e il gruppo di controllo, possiamo capire se la terapia ha aumentato o ridotto la probabilit√† di riduzione dell‚Äôansia. Se l‚Äôodds ratio √® maggiore di 1, significa che la terapia ha aumentato le probabilit√† di riduzione dell‚Äôansia; se √® inferiore a 1, significa che il trattamento ha ridotto le probabilit√† di riduzione dell‚Äôansia. L‚Äôodds ratio ci fornisce quindi una misura dell‚Äôeffetto della terapia rispetto al controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "title": "48¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "48.3 Logaritmo dell‚ÄôOdds Ratio",
    "text": "48.3 Logaritmo dell‚ÄôOdds Ratio\nIl logaritmo dell‚Äôodds ratio √® una trasformazione matematica molto utilizzata nell‚Äôanalisi statistica, specialmente nella regressione logistica. Essa permette di rendere l‚Äôodds ratio interpretabile su una scala lineare, semplificando l‚Äôanalisi e l‚Äôinterpretazione dei risultati.\nLa formula per calcolare il logaritmo dell‚Äôodds ratio √® la seguente:\n\\[ \\text{logit}(OR) = \\log(OR) = \\log\\left(\\frac{odds_1}{odds_2}\\right). \\]\nIn altre parole, il logaritmo dell‚Äôodds ratio √® il logaritmo naturale del rapporto tra gli odds di un evento nel primo gruppo e gli odds dello stesso evento nel secondo gruppo.\n\n48.3.1 Interpretazione\nL‚Äôinterpretazione del logaritmo dell‚Äôodds ratio √® pi√π intuitiva rispetto all‚Äôodds ratio stesso. Una variazione di una unit√† nel logaritmo dell‚Äôodds ratio corrisponde a un cambiamento costante nell‚Äôodds ratio stesso.\nSe il logaritmo dell‚Äôodds ratio √® positivo, significa che l‚Äôodds dell‚Äôevento nel primo gruppo √® maggiore rispetto al secondo gruppo. Pi√π il valore del logaritmo dell‚Äôodds ratio si avvicina a zero, pi√π l‚Äôodds dell‚Äôevento nei due gruppi si avvicina a essere simile.\nSe, invece, il logaritmo dell‚Äôodds ratio √® negativo, l‚Äôodds dell‚Äôevento nel primo gruppo √® inferiore rispetto al secondo gruppo. Un valore di logaritmo dell‚Äôodds ratio vicino a zero indica che l‚Äôodds dell‚Äôevento √® simile nei due gruppi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "title": "48¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "48.4 Analisi bayesiana delle proporzioni",
    "text": "48.4 Analisi bayesiana delle proporzioni\nUna volta compresi i concetti di odds, odds ratio e logit, possiamo procedere all‚Äôanalisi bayesiana delle proporzioni. Questo approccio consente di confrontare le proporzioni di due gruppi, ottenendo stime delle probabilit√† a posteriori e degli intervalli di credibilit√†.\nL‚Äôanalisi bayesiana si basa sull‚Äôapplicazione del teorema di Bayes per aggiornare le conoscenze a priori con l‚Äôevidenza fornita dai dati osservati. Questo permette di ottenere una distribuzione a posteriori delle quantit√† di interesse, come l‚Äôodds ratio.\nIn questo capitolo, analizzeremo un set di dati fittizio ispirato a un classico esperimento di etologia descritto da Hoffmann, Hofman, e Wagenmakers (2022). Von Frisch (1914) ha voluto verificare se le api possiedono la visione dei colori confrontando il comportamento di due gruppi di api. L‚Äôesperimento si compone di una fase di addestramento e di una fase di test.\nNella fase di addestramento, le api del gruppo sperimentale vengono esposte a un disco blu e a un disco verde. Solo il disco blu √® ricoperto di una soluzione zuccherina, molto appetita dalle api. Il gruppo di controllo, invece, non riceve alcun addestramento.\nNella fase di test, la soluzione zuccherina viene rimossa dal disco blu e si osserva il comportamento di entrambi i gruppi. Se le api del gruppo sperimentale hanno appreso che solo il disco blu contiene la soluzione zuccherina e sono in grado di distinguere tra il blu e il verde, dovrebbero preferire esplorare il disco blu piuttosto che quello verde durante la fase di test.\nIl ricercatore osserva che in 130 casi su 200, le api del gruppo sperimentale continuano ad avvicinarsi al disco blu dopo la rimozione della soluzione zuccherina. Le api del gruppo di controllo, che non sono state addestrate, si avvicinano al disco blu 100 volte su 200.\nPer confrontare il comportamento delle api nelle due condizioni, useremo l‚Äôodds ratio, cos√¨ da confrontare le probabilit√† dell‚Äôevento critico (scelta del disco blu) tra i due gruppi.\nCalcoliamo la proporzione delle api che scelgono il disco blu nella condizione sperimentale:\n\\[ p_e = \\frac{130}{200} = 0.65 \\]\nCalcoliamo gli odds nella condizione sperimentale:\n\\[ \\text{odds}_e = \\frac{p_e}{1 - p_e} \\approx 1.86 \\]\nQuesto ci indica che, nel gruppo sperimentale, ci sono circa 1.86 ‚Äúsuccessi‚Äù (ossia la scelta del disco blu) per ogni ‚Äúinsuccesso‚Äù (scelta del disco verde).\nProcediamo calcolando gli odds nella condizione di controllo:\n\\[ p_c = \\frac{100}{200} = 0.5 \\]\n\\[ \\text{odds}_c = \\frac{p_c}{1 - p_c} = 1.0 \\]\nQuesto ci indica che, nel gruppo di controllo, il numero di ‚Äúsuccessi‚Äù e ‚Äúinsuccessi‚Äù √® uguale.\nInfine, confrontiamo gli odds tra la condizione sperimentale e la condizione di controllo per calcolare l‚Äôodds ratio (OR):\n\\[ \\text{OR} = \\frac{\\text{odds}_e}{\\text{odds}_c} = 1.86 \\]\nGli odds di scelta del disco blu aumentano di circa 1.86 volte nel gruppo sperimentale rispetto al gruppo di controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "title": "48¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "48.5 Analisi Bayesiana dell‚ÄôOdds Ratio",
    "text": "48.5 Analisi Bayesiana dell‚ÄôOdds Ratio\nNella nostra analisi, ci focalizziamo sull‚ÄôOdds Ratio (OR) per valutare la differenza nel comportamento di scelta delle api nelle due condizioni dell‚Äôesperimento discusso. L‚ÄôOR fornisce una stima puntuale della differenza basata sul nostro campione specifico. Tuttavia, per realizzare un‚Äôinferenza statistica robusta, √® essenziale considerare l‚Äôincertezza nelle nostre stime, caratterizzata attraverso la distribuzione a posteriori.\nL‚Äôanalisi bayesiana si basa sull‚Äôapplicazione del teorema di Bayes per aggiornare le nostre conoscenze a priori con l‚Äôevidenza fornita dai dati osservati. Questo ci permette di ottenere una distribuzione a posteriori delle quantit√† di interesse, come l‚Äôodds ratio.\nPer affrontare questa questione, adottiamo un approccio bayesiano, costruendo la distribuzione a posteriori dell‚ÄôOR. A partire da questa distribuzione, determiniamo un intervallo di credibilit√† del 90%, che rappresenta l‚Äôintervallo entro il quale, con il 90% di confidenza, possiamo aspettarci che ricada il vero valore dell‚ÄôOR della popolazione.\nSe questo intervallo non include il valore 1, disponiamo di una solida evidenza (con un livello di credibilit√† del 90%) che la differenza tra le due condizioni esaminate corrisponde a una differenza reale nella popolazione, il che suggerisce che non si tratta di un artefatto generato dalla nostra incertezza. In altre parole, possiamo affermare con ragionevole certezza che le api dispongono di una visione cromatica.\nD‚Äôaltro canto, se l‚Äôintervallo di credibilit√† includesse il valore 1, ci√≤ indicherebbe che la differenza osservata nel nostro campione potrebbe non riflettere una differenza significativa nella popolazione generale, suggerendo che potrebbe essere una peculiarit√† del nostro campione specifico.\nL‚Äôanalisi bayesiana e il calcolo dell‚Äôintervallo di credibilit√† verranno condotti utilizzando cmdstanpy, che ci permette di implementare modelli bayesiani in modo efficiente e rigoroso. Utilizzeremo una distribuzione a priori debolmente informativa per l‚ÄôOR, in modo da non influenzare eccessivamente i risultati con assunzioni preliminari.\nUna volta ottenuta la distribuzione a posteriori dell‚ÄôOR, possiamo calcolare il nostro intervallo di credibilit√† del 90%. Questo intervallo fornir√† una rappresentazione della nostra incertezza riguardo il vero valore dell‚ÄôOR nella popolazione. Se il nostro intervallo di credibilit√† esclude il valore 1, possiamo concludere che esiste una differenza significativa tra i due gruppi, confermando che le api possono distinguere i colori e preferire il disco blu.\nIn sintesi, l‚Äôapproccio bayesiano non solo ci permette di stimare l‚ÄôOR, ma anche di quantificare la nostra incertezza e fare inferenze pi√π solide e informative sulla capacit√† delle api di distinguere tra colori.\n\n48.5.1 Likelihood\nLa likelihood del modello descrive la probabilit√† di osservare i dati dati i parametri del modello. Nel nostro caso, abbiamo due gruppi con eventi binomiali.\nPer il gruppo 1:\n\\[ y_1 \\sim \\text{Binomiale}(N_1, \\theta_1) .\\]\nPer il gruppo 2:\n\\[ y_2 \\sim \\text{Binomiale}(N_2, \\theta_2) .\\]\n\n\n48.5.2 Priors\nI priors del modello descrivono le nostre convinzioni iniziali sui parametri prima di osservare i dati. Nel nostro caso, i parametri \\(\\theta_1\\) e \\(\\theta_2\\) seguono una distribuzione Beta(2, 2).\nPer \\(\\theta_1\\):\n\\[ \\theta_1 \\sim \\text{Beta}(2, 2) .\\]\nPer \\(\\theta_2\\):\n\\[ \\theta_2 \\sim \\text{Beta}(2, 2) .\\]\nCompiliamo e stampiamo il modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'odds-ratio.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n08:02:19 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio\n08:02:28 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio\n\n\n//  Comparison of two groups with Binomial\ndata {\n  int&lt;lower=0&gt; N1; // number of experiments in group 1\n  int&lt;lower=0&gt; y1; // number of events in group 1\n  int&lt;lower=0&gt; N2; // number of experiments in group 2\n  int&lt;lower=0&gt; y2; // number of events in group 2\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta1; // probability of event in group 1\n  real&lt;lower=0, upper=1&gt; theta2; // probability of event in group 2\n}\nmodel {\n  // model block creates the log density to be sampled\n  theta1 ~ beta(2, 2); // prior\n  theta2 ~ beta(2, 2); // prior\n  y1 ~ binomial(N1, theta1); // observation model / likelihood\n  y2 ~ binomial(N2, theta2); // observation model / likelihood\n}\ngenerated quantities {\n  real oddsratio = (theta1 / (1 - theta1)) / (theta2 / (1 - theta2));\n}\n\n\n\nNel blocco generated quantities, calcoliamo l‚Äôodds ratio:\n\\[ \\text{oddsratio} = \\frac{\\theta_1 / (1 - \\theta_1)}{\\theta_2 / (1 - \\theta_2)}. \\]\nQuesto rapporto delle odds ci d√† una misura della forza dell‚Äôassociazione tra l‚Äôevento e i gruppi.\nIn sintesi, il modello bayesiano utilizza i dati osservati per aggiornare le nostre convinzioni iniziali sui parametri \\(\\theta_1\\) e \\(\\theta_2\\), fornendo una distribuzione a posteriori che riflette sia le informazioni a priori sia le evidenze empiriche.\nCreiamo un dizionario che contiene i dati.\n\nn1 = 200\ny1 = 130\nn2 = 200\ny2 = 100\n\nstan_data = {\n    'N1': n1,\n    'y1': y1,\n    'N2': n2,\n    'y2': y2\n}\n\nprint(stan_data)\n\n{'N1': 200, 'y1': 130, 'N2': 200, 'y2': 100}\n\n\nEseguiamo il campionamento.\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n08:02:35 - cmdstanpy - INFO - CmdStan start processing\n08:02:35 - cmdstanpy - INFO - Chain [1] start processing\n08:02:35 - cmdstanpy - INFO - Chain [2] start processing\n08:02:35 - cmdstanpy - INFO - Chain [3] start processing\n08:02:35 - cmdstanpy - INFO - Chain [4] start processing\n08:02:35 - cmdstanpy - INFO - Chain [1] done processing\n08:02:35 - cmdstanpy - INFO - Chain [2] done processing\n08:02:35 - cmdstanpy - INFO - Chain [3] done processing\n08:02:35 - cmdstanpy - INFO - Chain [4] done processing\n\n\nEstraiamo la distribuzione a posteriori dell‚Äôodds ratio e generiamo un istogramma.\n\nor_draws = trace.stan_variable('oddsratio')\n\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(\n    or_draws, bins=30, alpha=0.5, color=color_fill, edgecolor=color_edge, density=True\n)\nplt.title('Istogramma della distribizione a posteriori di OR')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione posteriore del rapporto degli odds √® il modo pi√π semplice e accurato per descrivere la differenza tra i due gruppi. Nel caso presente, notiamo che vi √® un‚Äôelevata probabilit√† che la differenza tra i due gruppi sia affidabile e relativamente grande.\nUn sommario della distribuzione a posteriori dell‚Äôodds ratio si ottine nel modo seguente.\n\naz.summary(trace, var_names=['oddsratio'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.88\n0.39\n1.2\n2.6\n0.0\n0.0\n6936.86\n5183.54\n1.0\n\n\n\n\n\n\n\n\nPossiamo determinare la probabilit√† che il rapporto di probabilit√† (odds ratio) superi 1. Per farlo, √® sufficiente analizzare gli 8000 campioni della distribuzione posteriore dell‚Äôodds ratio\n\nlen(or_draws)\n\n8000\n\n\ne calcolare la proporzione di questi che presenta un valore maggiore di 1:\n\nnp.mean(or_draws &gt; 1.0)\n\n0.9985",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "title": "48¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "48.6 Diagnostica delle catene markoviane",
    "text": "48.6 Diagnostica delle catene markoviane\nPrima di esaminare i risultati, eseguiamo la diagnostica delle catene markoviane.\n\n48.6.1 Mixing\nIl trace plot precedente dimostra un buon mixing. Questo √® evidenza che il campionamento MCMC ha raggiunto uno stato stazionario.\n\n_ = az.plot_trace(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n48.6.2 NumerositaÃÄ campionaria effettiva\nQuando si utilizzano metodi di campionamento MCMC, √® ragionevole chiedersi se un particolare campione estratto dalla distribuzione a posteriori sia sufficientemente grande per calcolare con sicurezza le quantit√† di interesse, come una media o un HDI. Questo non √® qualcosa che possiamo rispondere direttamente guardando solo il numero di punti della catena MCMC, e il motivo √® che i campioni ottenuti dai metodi MCMC hanno un certo grado di autocorrelazione, quindi la quantit√† effettiva di informazioni contenute in quel campione sar√† inferiore a quella che otterremmo da un campione iid della stessa dimensione. Possiamo pensare alla dimensione del campione effettivo (ESS) come a un stimatore che tiene conto dell‚Äôautocorrelazione e fornisce il numero di estrazioni che avremmo se il nostro campione fosse effettivamente iid.\nPer le catene buone, solitamente, il valore della dimensione del campione effettivo sar√† inferiore al numero di campioni. Ma l‚ÄôESS pu√≤ essere in realt√† pi√π grande del numero di campioni estratti. Quando si utilizza il campionatore NUTS, valori di ESS maggiori del numero totale di campioni possono verificarsi per parametri le cui distribuzioni posteriori sono vicine alla Gaussiana e che sono quasi indipendenti da altri parametri nel modello.\nNell‚Äôoutput di PyCM si considera ESS_BULK. Un euristica √® che deve essere almeno uguale a 400. Nel caso presente questo si verifica, quindi il valore ESS_BULK non fornisce alcuna evidenza di cattivo mixing.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.881\n0.386\n1.198\n2.597\n0.005\n0.003\n6937.0\n5184.0\n1.0\n\n\ntheta1\n0.647\n0.033\n0.585\n0.710\n0.000\n0.000\n6865.0\n5296.0\n1.0\n\n\ntheta2\n0.499\n0.035\n0.434\n0.564\n0.000\n0.000\n7465.0\n5391.0\n1.0\n\n\n\n\n\n\n\n\n\n\n48.6.3 R hat\nIn condizioni molto generali, i metodi di Markov chain Monte Carlo hanno garanzie teoriche che otterranno la risposta corretta indipendentemente dal punto di partenza. Sfortunatamente, tali garanzie sono valide solo per campioni infiniti. Quindi, nella pratica, abbiamo bisogno di modi per stimare la convergenza per campioni finiti. Un‚Äôidea diffusa √® quella di generare pi√π di una catena, partendo da punti molto diversi e quindi controllare le catene risultanti per vedere se sembrano simili tra loro. Questa nozione intuitiva pu√≤ essere formalizzata in un indicatore numerico noto come R-hat. Esistono molte versioni di questo stimatore, poich√© √® stato perfezionato nel corso degli anni. In origine il R-hat veniva interpretato come la sovrastima della varianza dovuta al campionamento MCMC finito. Ci√≤ significa che se si continua a campionare all‚Äôinfinito si dovrebbe ottenere una riduzione della varianza della stima di un fattore R-hat. E quindi il nome ‚Äúfattore di riduzione potenziale della scala‚Äù (potential scale reduction factor), con il valore target di 1 che significa che aumentare il numero di campioni non ridurr√† ulteriormente la varianza della stima. Tuttavia, nella pratica √® meglio pensarlo solo come uno strumento diagnostico senza cercare di sovra-interpretarlo.\nL‚ÄôR-hat per il parametro theta viene calcolato come la deviazione standard di tutti i campioni di theta, ovvero includendo tutte le catene insieme, diviso per la radice quadratica media delle deviazioni standard separate all‚Äôinterno della catena. Il calcolo effettivo √® un po‚Äô pi√π complesso ma l‚Äôidea generale √® questa. Idealmente dovremmo ottenere un valore di 1, poich√© la varianza tra le catene dovrebbe essere la stessa della varianza all‚Äôinterno della catena. Da un punto di vista pratico, valori di R-hat inferiori a 1.1 sono considerati sicuri.\nNel caso presente questo si verifica. Possiamo ottenere R hat con Arviz:\n\naz.rhat(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 1.0\n    theta1     float64 8B 1.001\n    theta2     float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float641.0array(1.00038283)theta1()float641.001array(1.00052497)theta2()float641.001array(1.00059406)Indexes: (0)Attributes: (0)\n\n\nIl valore di \\(\\hat{R}\\), al massimo, raggiunge il valore di 1.001. Essendo il valore molto simile a 1 nel caso presente, possiamo dire che non ci sono evidenza di assenza di convergenza.\n\n\n48.6.4 Errore standard di Monte Carlo\nQuando si utilizzano metodi MCMC introduciamo un ulteriore livello di incertezza poich√© stiamo approssimando la posteriore con un numero finito di campioni. Possiamo stimare la quantit√† di errore introdotta utilizzando l‚Äôerrore standard di Monte Carlo (MCSE). L‚ÄôMCSE tiene conto del fatto che i campioni non sono veramente indipendenti l‚Äôuno dall‚Äôaltro e sono in realt√† calcolati dall‚ÄôESS. Mentre i valori di ESS e R-hat sono indipendenti dalla scala dei parametri, la statistica MCSE non lo √®. Se vogliamo riportare il valore di un parametro stimato al secondo decimale, dobbiamo essere sicuri che MCSE sia al di sotto del secondo decimale altrimenti, finiremo, erroneamente, per riportare una precisione superiore a quella che abbiamo realmente. Dovremmo controllare MCSE solo una volta che siamo sicuri che ESS sia abbastanza alto e R-hat sia abbastanza basso; altrimenti, MCSE non √® utile.\nNel nostro caso il MCSE √® sufficientemente piccolo.\n\naz.mcse(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 0.004636\n    theta1     float64 8B 0.0004029\n    theta2     float64 8B 0.0004034xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float640.004636array(0.00463567)theta1()float640.0004029array(0.00040294)theta2()float640.0004034array(0.00040337)Indexes: (0)Attributes: (0)\n\n\nCome per l‚ÄôESS, l‚ÄôMCSE varia nello spazio dei parametri e quindi potremmo anche volerlo valutare per diverse regioni dello spazio dei parametri.\n\n_ = az.plot_mcse(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nL‚Äôerrore standard di Monte Carlo ci informa della precisione della stima ottenuta usando il metodo MCMC. Non possiamo riportare una precisione dei risultati maggiore di quella indicata dalla MCSE. Pertanto, per il caso presente relativo all‚ÄôOdds Ratio (OR), possiamo affermare che la precisione massima raggiungibile √® limitata a due decimali.\n\n\n48.6.5 Autocorrelazione\nL‚Äôautocorrelazione riduce la quantit√† effettiva di informazioni contenute in un campione e quindi √® qualcosa che vogliamo mantenere al minimo. Possiamo ispezionare direttamente l‚Äôautocorrelazione con az.plot_autocorr.\n\n_ = az.plot_autocorr(trace, combined=True, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n48.6.6 Rank Plots\nI grafici dei ranghi sono un altro strumento diagnostico visivo che possiamo utilizzare per confrontare il comportamento del campionamento sia all‚Äôinterno che tra le catene. I grafici dei ranghi, in parole semplici, sono istogrammi dei campioni della distribuzione a posteriori espressi in termini di ranghi. Nei grafici dei ranghi, i ranghi sono calcolati combinando prima tutte le catene ma poi rappresentando i risultati separatamente per ogni catena. Se tutte le catene stimano la stessa distribuzione, ci aspettiamo che i ranghi abbiano una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ci√≤ indica un buon mix delle catene.\nPossiamo ottenere i grafici dei ranghi con az.plot_rank.\n\n_ = az.plot_rank(trace, kind=\"bars\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa √® la seguente.\n\n_ = az.plot_rank(trace, kind=\"vlines\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nPossiamo vedere nella figura che i ranghi sono molto simili ad una distribuzione uniforme e che tutte le catene sono simili tra loro senza alcuno scostamento distintivo.\n\n\n48.6.7 Divergenza\nFinora abbiamo diagnosticato il funzionamento di un campionatore esaminando i campioni generati. Un altro modo per eseguire una diagnosi √® monitorare il comportamento dei meccanismi interni del metodo di campionamento. Un esempio importante di tali diagnosi √® il concetto di divergenza presente in alcuni metodi Hamiltonian Monte Carlo (HMC). Le divergenze (o transizioni divergenti) sono un modo potente e sensibile per diagnosticare i campioni e funzionano come complemento alle diagnosi che abbiamo visto nelle sezioni precedenti.\nPyMC riporta il numero di transizioni divergenti. Se non viene riportato alcun messaggio che informa della presenza di transizioni divergenti, questo vuol dire che la distribuzione a posteriori √® stata stimata correttamente.\n\n\n48.6.8 BFMI\nIl BFMI (Fraction of Missing Information) serve a valutare quanto bene il processo di campionamento si allinea con la distribuzione della ‚Äúenergia‚Äù associata a ciascun campione. Nel contesto del campionamento Hamiltoniano, il termine ‚Äúenergia‚Äù si riferisce a una quantit√† calcolata durante il processo di campionamento che aiuta a valutare quanto √® probabile un certo set di parametri alla luce dei dati osservati e del modello statistico in esame.\nIl BFMI √® uno strumento che ci aiuta a valutare se il processo di campionamento sta ‚Äúesplorando‚Äù adeguatamente lo spazio dei parametri possibili. In altre parole, ci dice se il nostro processo di campionamento sta dando un‚Äôimmagine accurata delle regioni dello spazio dei parametri che sono realmente plausibili dati i nostri dati e il nostro modello. Un valore BFMI basso indica che il campionamento non √® riuscito a esplorare adeguatamente alcune regioni dello spazio dei parametri che dovrebbero essere state esplorate, e quindi i risultati del campionamento potrebbero non essere affidabili.\nGeneralmente, un valore inferiore a 0.3 indica un campionamento insufficiente.\nNel caso presente, dal momento che i valori BFMI sono superiori a 0.3 per tutte le catene, sembra che il processo di campionamento sia riuscito a esplorare adeguatamente lo spazio dei parametri.\n\naz.bfmi(trace)\n\narray([1.14346921, 1.11602384, 1.1467078 , 1.03197001])\n\n\nLa validazione del processo di campionamento pu√≤ essere efficacemente eseguita analizzando graficamente le quantit√† note come ‚Äúenergy transition‚Äù e ‚Äúmarginal energy‚Äù. Queste metriche sono strettamente legate alla funzione obiettivo che l‚Äôalgoritmo di campionamento intende ottimizzare e giocano un ruolo cruciale nel rilevare potenziali problematiche che possono emergere durante il campionamento.\n\nEnergy transition: questa metrica illustra l‚Äô‚Äúenergia‚Äù calcolata in ogni singolo passo dell‚Äôalgoritmo di campionamento, offrendo una visione dettagliata delle fluttuazioni che intervengono ad ogni iterazione. Facilita l‚Äôidentificazione delle aree dello spazio dei parametri dove l‚Äôalgoritmo potrebbe incontrare difficolt√† nel campionare in modo corretto.\nMarginal energy: fornisce un profilo dell‚Äô‚Äúenergia‚Äù marginale per l‚Äôintero set di campioni, riflettendo l‚Äô‚Äúenergia‚Äù media in ogni punto del campione. √à una rappresentazione grafica dell‚Äô‚Äúenergia‚Äù associata alla distribuzione a posteriori che si intende campionare.\n\nPer un‚Äôanalisi diagnostica efficace, √® auspicabile che il tracciato dell‚Äô‚Äúenergy transition‚Äù coincida sostanzialmente con quello della ‚Äúmarginal energy‚Äù. Tale congruenza √® indicativa di una esplorazione ben riuscita dello spazio dei parametri, assicurando che le regioni ad alta probabilit√† nella distribuzione a posteriori siano state correttamente campionate. Pertanto, una buona sovrapposizione tra i grafici delle due metriche attesterebbe un funzionamento ottimale del modello, conferendo un grado di affidabilit√† elevato alle stime dei parametri derivanti dal processo di campionamento.\n\n_ = az.plot_energy(trace)\n\n\n\n\n\n\n\n\n\n\n48.6.9 Conclusione\nIn questo capitolo abbiamo approfondito l‚Äôanalisi bayesiana focalizzandoci sulla stima dell‚Äôodds ratio (OR). I risultati della diagnosi delle catene Markoviane non evidenziano problematiche relative alla convergenza dell‚Äôalgoritmo n√© discrepanze nel modello statistico adottato, permettendoci di procedere con l‚Äôanalisi dei risultati ottenuti.\nL‚Äôanalisi ha determinato un valore a posteriori per l‚ÄôOR di 1.88, accompagnato da un intervallo di credibilit√† del 94% compreso tra 1.20 e 2.60. Poich√© questo intervallo non include il valore 1, possiamo affermare, con un grado di certezza del 94%, che il comportamento delle api differisce nelle due condizioni sperimentali. Questo fornisce evidenza a supporto dell‚Äôipotesi che le api dispongano di una visione cromatica.\nL‚Äôapproccio bayesiano adottato ci ha permesso di integrare le conoscenze a priori con i dati ottenuti dall‚Äôanalisi, risultando in una stima dell‚Äôodds ratio pi√π affidabile e accurata.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/06_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "title": "48¬† Analisi bayesiana dell‚Äôodds-ratio",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nscipy     : 1.14.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHoffmann, Tabea, Abe Hofman, e Eric-Jan Wagenmakers. 2022. ¬´Bayesian tests of two proportions: A tutorial with R and JASP¬ª. Methodology 18 (4): 239‚Äì77.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>48</span>¬† <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html",
    "href": "chapters/mcmc/07_stan_normal_normal.html",
    "title": "49¬† Inferenza bayesiana su una media",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo principale di questo capitolo √® esaminare un contesto che abbiamo gi√† preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione √® stato estratto. Tuttavia, anzich√© procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo i metodi MCMC con Stan.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#il-modello-normale",
    "href": "chapters/mcmc/07_stan_normal_normal.html#il-modello-normale",
    "title": "49¬† Inferenza bayesiana su una media",
    "section": "49.1 Il modello Normale",
    "text": "49.1 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l‚Äôapprossimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l‚Äôesercizio descritto nel capitolo {ref}distr-coniugate-2-notebook usando Stan.\n\n49.1.1 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell‚Äôarea di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ‚Äô60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un‚Äôeconomia basata su caccia e raccolta. Riprodurremo l‚Äôanalisi descritta da {cite:t}McElreath_rethinking, esaminando unicamente i valori di altezza per individui di et√† superiore ai 18 anni.\n\ndf = pd.read_csv('../../data/Howell_18.csv')\ndf.head()\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\n\n\nlen(df[\"height\"])\n\n352\n\n\n\nsns.kdeplot(df[\"height\"], bw_adjust=0.5, fill=True)  # Adjust bw_adjust for smoothing\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\nLa media dei valori dell‚Äôaltezza nel campione √®:\n\nnp.mean(df[\"height\"])\n\n154.5970926136364\n\n\ncon una deviazione standard pari a:\n\nnp.std(df[\"height\"], ddof=1)\n\n7.742332137351995\n\n\n\n\n49.1.2 Modello di Base\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo {cite:t}McElreath_rethinking, ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell‚Äôaltezza.\nPertanto, il modello Normale si definisce nel seguente modo:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilit√†, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l‚Äôoggetto dell‚Äôinferenza.\n\nstan_file = os.path.join(project_directory, 'stan', 'gaussian_height.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\nparameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  sigma ~ normal(0, 20);\n  mu ~ normal(181, 30);\n}\n\n\n\nCreaiamo un dizionario con i dati in formato appropriato per Stan:\n\nstan_data = {'N': len(df[\"height\"]), 'y': df[\"height\"]}\nprint(stan_data)\n\n{'N': 352, 'y': 0      151.765\n1      139.700\n2      136.525\n3      156.845\n4      145.415\n        ...   \n347    162.560\n348    142.875\n349    162.560\n350    156.210\n351    158.750\nName: height, Length: 352, dtype: float64}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell‚Äôinferenza insieme alle loro tracce (cio√® i vettori dei campioni dei parametri \\(\\mu\\) e \\(\\sigma\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\nUna sintesi delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente.\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.60\n0.42\n153.84\n155.39\n0.0\n0.0\n7864.52\n5825.33\n1.0\n\n\nsigma\n7.77\n0.30\n7.21\n8.34\n0.0\n0.0\n6655.48\n5167.04\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#parametrizzazione-non-centrata",
    "href": "chapters/mcmc/07_stan_normal_normal.html#parametrizzazione-non-centrata",
    "title": "49¬† Inferenza bayesiana su una media",
    "section": "49.2 Parametrizzazione Non Centrata",
    "text": "49.2 Parametrizzazione Non Centrata\nNella versione precedente del modello Normale abbiamo specificato le distribuzioni a priori per i parametri oggetto dell‚Äôinferenza (\\(\\mu\\) e \\(\\sigma\\)) sulla scala dei dati grezzi osservati, i quali hanno una media di 154.6 e una deviazione standard di 7.7. Sul parametro \\(\\mu\\) abbiamo imposto una distribuzione a priori normale con media 181 e deviazione standard 30, e sul parametro \\(\\sigma\\) abbiamo imposto una distribuzione a priori normale con media 0 e deviazione standard 20. Queste distribuzioni a priori sono specifiche per ciascun particolare campione che possiamo osservare.\n√à possibile usare un approccio diverso, che consente di definire delle distribuzioni a priori sui parametri che sono indipendenti dal particolare campione che osserviamo. Questa procedura √® chiamata ‚Äúparametrizzazione non centrata‚Äù (non-centered parametrization). In questo modello, utilizziamo variabili latenti \\(\\mu_{\\text{raw}}\\) e \\(\\sigma_{\\text{raw}}\\), che seguono una distribuzione normale standard:\n\\[\n\\begin{align}\n\\mu_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\\\\\n\\sigma_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\n\\end{align}\n\\]\nQueste variabili vengono poi trasformate per ottenere i parametri \\(\\mu\\) e \\(\\sigma\\) sulla scala originale:\n\\[\n\\begin{align}\n\\mu &= y_{\\text{mean}} + y_{\\text{sd}} \\cdot \\mu_{\\text{raw}} \\notag\\\\\n\\sigma &= y_{\\text{sd}} \\cdot \\sigma_{\\text{raw}} \\notag\n\\end{align}\n\\]\nDove: - \\(y_{\\text{mean}}\\) √® la media dei dati osservati \\(y\\). - \\(y_{\\text{sd}}\\) √® la deviazione standard dei dati osservati \\(y\\).\n\nstan_ncp_file = os.path.join(project_directory, 'stan', 'gaussian_ncp.stan')\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\n\nDi seguito √® riportato il codice Stan per questo modello con la parametrizzazione non centrata:\n\nprint(model_ncp.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\ntransformed data {\n    real y_mean = mean(y);\n    real y_sd = sd(y);\n}\nparameters {\n    real mu_raw;\n    real&lt;lower=0&gt; sigma_raw;\n}\ntransformed parameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Priors:\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    // Likelihood:\n    y ~ normal(mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\n\n\nEcco una spiegazione dettagliata del modello Stan con parametrizzazione non centrata.\n\nBlocco Dati:\n\nint&lt;lower=1&gt; N;: Il numero totale di prove o osservazioni.\nvector[N] y;: Il vettore dei punteggi osservati per ciascuna prova. Questi punteggi sono sulla loro scala originale e non standardizzati.\n\nBlocco Dati Trasformati:\n\nreal y_mean = mean(y);: La media dei dati osservati y.\nreal y_sd = sd(y);: La deviazione standard dei dati osservati y.\n\nBlocco Parametri:\n\nreal mu_raw;: Un parametro latente che segue una distribuzione normale standard.\nreal&lt;lower=0&gt; sigma_raw;: Un parametro latente che segue una distribuzione normale standard vincolata a essere positiva.\n\nBlocco Parametri Trasformati:\n\nreal mu;: La media della distribuzione normale per y sulla sua scala originale.\nreal&lt;lower=0&gt; sigma;: La deviazione standard della distribuzione normale per y sulla sua scala originale.\nQuesti parametri trasformati sono definiti come:\nmu = y_mean + y_sd * mu_raw;\nsigma = y_sd * sigma_raw;\n\n\nLa parametrizzazione non centrata comporta la riparametrizzazione del modello in termini di variabili standardizzate (mu_raw e sigma_raw) e poi la loro trasformazione di nuovo sulla scala originale dei dati. Questo approccio spesso porta a una migliore efficienza di campionamento e propriet√† di convergenza, specialmente nei modelli gerarchici.\n\nParametri Latenti (mu_raw e sigma_raw):\n\nmu_raw ~ normal(0, 1);: mu_raw √® una variabile normale standardizzata.\nsigma_raw ~ normal(0, 1);: sigma_raw √® una variabile normale standardizzata vincolata a essere positiva.\n\nTrasformazione alla Scala Originale:\n\nmu = y_mean + y_sd * mu_raw;: Questo scala e trasla mu_raw alla posizione e scala dei dati osservati y.\nsigma = y_sd * sigma_raw;: Questo scala sigma_raw alla scala dei dati osservati y.\n\n\nLa dichiarazione della verosimiglianza y ~ normal(mu, sigma); indica che i dati osservati y seguono una distribuzione normale con media mu e deviazione standard sigma. Ecco perch√© ha senso anche se y √® sulla sua scala originale:\n\nDati Osservati sulla Scala Originale: I dati osservati y sono sulla loro scala originale.\nParametri sulla Scala Originale: I parametri mu e sigma, dopo la trasformazione nel blocco transformed parameters, sono anch‚Äôessi sulla scala originale di y.\n\nQuindi, la dichiarazione y ~ normal(mu, sigma); specifica correttamente che i dati osservati y (sulla loro scala originale) sono modellati da una distribuzione normale con media mu e deviazione standard sigma, entrambe sulla scala originale di y.\nInfine, il blocco generated quantities viene utilizzato per i controlli predittivi posteriori generando nuovi dati (y_rep) dalla distribuzione posteriore dei parametri (mu e sigma):\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\ny_rep: Questo genera punti dati replicati dalla distribuzione normale con la media posteriore mu e la deviazione standard posteriore sigma. Questo ti permette di confrontare le previsioni del modello con i dati osservati per eseguire controlli predittivi posteriori.\n\nEseguiamo il campionamento MCMC per il modello che segue una parametrizzazione non centrata:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\n_ = az.plot_trace(trace_ncp, var_names=['mu', 'sigma'])\n\n\n\n\n\n\n\n\nOtteniamo una sintesi delle distribuzioni a posteriori dei parametri:\n\nsummary = az.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\nprint(summary)\n\n         mean    sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nmu     154.61  0.42  153.83   155.39       0.01      0.0   6329.64   5029.29   \nsigma    7.76  0.29    7.20     8.30       0.00      0.0   7836.78   5829.76   \n\n       r_hat  \nmu       1.0  \nsigma    1.0  \n\n\nI risultati sono molto simili a quelli ottenuti in precedenza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#posterior-predictive-check",
    "href": "chapters/mcmc/07_stan_normal_normal.html#posterior-predictive-check",
    "title": "49¬† Inferenza bayesiana su una media",
    "section": "49.3 Posterior predictive check",
    "text": "49.3 Posterior predictive check\nUno dei vantaggi del toolkit bayesiano √® che una volta ottenuta la distribuzione a posteriori congiunta dei parametri p(Œ∏|Y) √® possibile utilizzarla per generare le previsioni p(·ª∏). Matematicamente, questo pu√≤ essere fatto calcolando:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta distribuzione √® nota come distribuzione predittiva posteriore. √à predittiva perch√© viene utilizzata per fare previsioni e posteriore perch√© √® calcolata utilizzando la distribuzione posteriore. Quindi possiamo pensare a questa come la distribuzione dei dati futuri dati il modello e i dati osservati.\nUtilizzando Stan √® facile per ottenere campioni predittivi posteriori: non √® necessario calcolare alcun integrale. Dobbiamo convertire l‚Äôoggetto creato dalla funzione sample() nel formato ArviZ InferenceData:\n\n# Convert to ArviZ InferenceData object\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nUn uso comune della distribuzione predittiva posteriore √® quello di eseguire controlli predittivi posteriori. Questi sono un insieme di test che possono essere utilizzati per verificare se il modello √® una buona rappresentazione dei dati. Possiamo utilizzare la funzione plot_ppc di ArviZ per visualizzare la distribuzione predittiva posteriore e i dati osservati. Il codice √®:\n\n# Plot the posterior predictive check\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nNella figura, la linea nera rappresenta una KDE (Kernel Density Estimation) dei dati, mentre le linee blu sono KDE calcolate da ciascuno dei 500 campioni predittivi posteriori. Le linee blu riflettono l‚Äôincertezza associata alla distribuzione dei dati previsti.\nDi default, in ArviZ le KDE vengono stimati all‚Äôinterno dell‚Äôintervallo effettivo dei dati e si assume che siano zero al di fuori di questo intervallo.\nDato che il tracciato del KDE plot √® contenuto nell‚Äôinsieme di profili dei KDE plot dei campioni predittivi a posteriori, si pu√≤ concludere che il modello utilizzato offre una rappresentazione adeguata dei dati ed √® utile per la maggior parte delle analisi. Tuttavia, √® importante considerare che potrebbero esistere altri modelli in grado di adattarsi meglio all‚Äôintero dataset. Esploreremo ora come poter sviluppare un modello alternativo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#modello-robusto",
    "href": "chapters/mcmc/07_stan_normal_normal.html#modello-robusto",
    "title": "49¬† Inferenza bayesiana su una media",
    "section": "49.4 Modello ‚Äúrobusto‚Äù",
    "text": "49.4 Modello ‚Äúrobusto‚Äù\nNon √® necessario presupporre che i dati seguano una distribuzione gaussiana. Le lievi deviazioni dalla gaussianit√† possono essere considerate attraverso l‚Äôutilizzo della distribuzione t di Student, che √® particolarmente utile quando queste deviazioni si manifestano nelle code della distribuzione, come sembra essere il caso in questa situazione. Pertanto, proponiamo di adottare un modello ‚Äòrobusto‚Äô, maggiormente adatto a gestire osservazioni che si discostano dalla normalit√† nelle code della distribuzione.\nLa distribuzione t di Student √® caratterizzata dal parametro \\(\\nu\\), noto come ‚Äògradi di libert√†‚Äô. Quando \\(\\nu\\) √® pari o superiore a 30, la distribuzione t di Student diventa quasi indistinguibile da una distribuzione normale.\n\nnu_values = [1, 2, 10]\n\nfig, ax = plt.subplots()\n\nfor nu in nu_values:\n    x = np.linspace(-5, 5, 1000)\n    y = stats.t.pdf(x, df=nu, loc=0, scale=1)\n    ax.plot(x, y, label=f\"ŒΩ={nu}\")\n\nx = np.linspace(-5, 5, 1000)\ny = stats.t.pdf(x, df=np.inf, loc=0, scale=1)\nax.plot(x, y, linestyle=\"--\", color=\"k\", label=\"ŒΩ=‚àû\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nTuttavia, le code della distribuzione t di Student risultano pi√π pesanti rispetto a quelle della normale quando \\(\\nu\\) √® basso. Pertanto, proponiamo di assegnare a \\(\\nu\\) una distribuzione a priori che concentri la maggior parte della sua massa su valori bassi, come ad esempio una distribuzione esponenziale con un parametro di rate pari a 1/30.\n\n# Define the rate parameter for the exponential distribution\nrate = 1 / 30\n\n# Generate samples from the exponential distribution\nsamples = np.random.exponential(scale=1 / rate, size=10000)\n\n# Create the histogram plot of the samples\nplt.hist(samples, bins=50, density=True, alpha=0.75, label=\"Sampled Distribution\")\nplt.title(\"Exponential Distribution (Œª = 1/30)\")\nplt.xlabel(\"Values\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nstan_student_file = os.path.join(project_directory, 'stan', 'student-model.stan')\nmodel_student = CmdStanModel(stan_file=stan_student_file)\nprint(model_student.code())\n\ndata {\n    int&lt;lower=1&gt; N;  // Numero totale di prove\n    vector[N] y;  // Punteggio in ciascuna prova\n}\ntransformed data {\n    real y_mean = mean(y);  // Media dei dati osservati\n    real y_sd = sd(y);  // Deviazione standard dei dati osservati\n}\nparameters {\n    real mu_raw;  // Parametro latente standardizzato per mu\n    real&lt;lower=0&gt; sigma_raw;  // Parametro latente standardizzato per sigma\n    real&lt;lower=1&gt; nu;  // Gradi di libert√† per la distribuzione t di Student\n}\ntransformed parameters {\n    real mu;  // Media sulla scala originale\n    real&lt;lower=0&gt; sigma;  // Deviazione standard sulla scala originale\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Distribuzioni a priori non centrate\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    nu ~ exponential(1.0 / 30.0);  // Prior esponenziale per i gradi di libert√†\n    // Verosimiglianza\n    y ~ student_t(nu, mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = student_t_rng(nu, mu, sigma);\n    }\n}\n\n\n\n\ntrace_student = model_student.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori e le tracce dei parametri del nuovo modello.\n\n_ = az.plot_trace(trace_student, var_names=['mu', 'sigma', 'nu'])\n\n\n\n\n\n\n\n\nConvertiamo i risultati in un oggetto InferenceData di ArviZ.\n\nidata = az.from_cmdstanpy(\n    posterior=trace_student,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nGeneriamo la distribuzione predittiva a posteriori.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nLa figura illustra che la situazione √® analoga a quella del caso gaussiano. Questo non √® sorprendente, dato che i dati relativi all‚Äôaltezza si distribuiscono in maniera gaussiana nella popolazione. Pertanto, l‚Äôimpiego della distribuzione t di Student o della distribuzione normale producono risultati sostanzialmente equivalenti in questo contesto.\n\naz.summary(trace_student, var_names=['mu', 'sigma', 'nu'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.57\n0.42\n153.85\n155.40\n0.00\n0.00\n8798.72\n6040.50\n1.0\n\n\nsigma\n7.63\n0.30\n7.08\n8.21\n0.00\n0.00\n7145.94\n6226.65\n1.0\n\n\nnu\n62.39\n36.10\n11.40\n129.62\n0.41\n0.31\n7870.31\n5565.90\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/07_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "title": "49¬† Inferenza bayesiana su una media",
    "section": "49.5 Commenti e considerazioni finali",
    "text": "49.5 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato il metodo per calcolare l‚Äôintervallo di credibilit√† per la media di una variabile casuale normale utilizzando Stan. Inoltre, abbiamo illustrato come sia possibile ampliare l‚Äôinferenza sulla media utilizzando un modello robusto basato sulla distribuzione t di Student.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#esercizi",
    "href": "chapters/mcmc/07_stan_normal_normal.html#esercizi",
    "title": "49¬† Inferenza bayesiana su una media",
    "section": "49.6 Esercizi",
    "text": "49.6 Esercizi\n\nEsercizio 49.1 Utilizzando i dati dell‚Äôesempio sui bambini plusdotati discusso nella Capitolo 35, impiegare Stan per replicare i risultati ottenuti con il metodo basato su griglia.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/07_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "title": "49¬† Inferenza bayesiana su una media",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\narviz     : 0.18.0\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>49</span>¬† <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html",
    "href": "chapters/mcmc/08_stan_two_groups.html",
    "title": "50¬† Confronto tra due gruppi",
    "section": "",
    "text": "Introduzione\nL‚Äôobiettivo di questo capitolo √® di ampliare la discussione del Capitolo 49, affrontando il confronto tra le medie di due gruppi indipendenti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "href": "chapters/mcmc/08_stan_two_groups.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.1 Stima bayesiana e test dell‚Äôipotesi nulla",
    "text": "50.1 Stima bayesiana e test dell‚Äôipotesi nulla\nSpesso, ci troviamo ad affrontare la necessit√† di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo √® maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, √® fondamentale utilizzare un modello statistico, poich√© le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o pi√π gruppi √® quello di utilizzare un test statistico. Questo approccio prevede l‚Äôindividuazione di un‚Äôipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l‚Äôutilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L‚Äôipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significativit√† adottare) √® spesso arbitraria e basata su convenzioni piuttosto che sulla specificit√† del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l‚Äôipotesi nulla (Goodman, 1999).\nUn approccio pi√π informativo ed efficace per il confronto tra gruppi √® quello basato sulla stima invece che sul test dell‚Äôipotesi nulla, ed √® guidato dalla probabilit√† bayesiana anzich√© dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio √® intrinsecamente pi√π informativo. Inoltre, viene inclusa una stima dell‚Äôincertezza associata a tale differenza, che tiene conto sia dell‚Äôincertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell‚Äôincertezza causata dalla variabilit√† intrinseca del sistema (incertezza aleatoria).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#un-esempio-illustrativo",
    "href": "chapters/mcmc/08_stan_two_groups.html#un-esempio-illustrativo",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.2 Un esempio illustrativo",
    "text": "50.2 Un esempio illustrativo\nIn questo esempio, l‚Äôobiettivo √® stimare la differenza tra le medie del quoziente di intelligenza dei bambini di due gruppi distinti in base al livello di scolarit√† della madre. Il primo gruppo include i bambini la cui madre non ha completato le scuole superiori, mentre il secondo gruppo comprende quelli la cui madre ha ottenuto il diploma superiore. Per questo, useremo i dati kidiq e un modello bayesiano al fine di ottenere una stima affidabile della differenza tra le medie dei due gruppi nella popolazione.\nI dati utilizzati sono forniti da Gelman e Hill (2007) e costituiscono un sottocampione estratto dal National Longitudinal Survey of Youth.\nLeggiamo i dati.\n\ndf = pd.read_stata(\"../../data/kidiq.dta\")\ndf.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nIl dataset contiene le seguenti colonne:\n\n‚Äúkid_score‚Äù: il quoziente intellettivo (QI) dei bambini. √à una misura dell‚Äôintelligenza del bambino.\n‚Äúmom_hs‚Äù: una variabile binaria che indica se la madre del bambino ha completato o meno la scuola superiore. Pu√≤ assumere i valori 0 o 1, dove 0 rappresenta ‚Äúno‚Äù (la madre non ha completato la scuola superiore) e 1 rappresenta ‚Äús√¨‚Äù (la madre ha completato la scuola superiore).\n\nCi sono 93 bambini la cui madre non ha completato la scuola superiore e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\ndf.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nLe statistiche descrittive si ottengono nel modo seguente.\n\ndf[\"kid_score\"].mean()\n\n86.79723502304148\n\n\n\nsummary_stats = [np.mean, stat.stdev]\ndf.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63722/1859022749.py:2: FutureWarning: The provided callable &lt;function mean at 0x11c1f6660&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  df.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\n\nI bambini la cui madre ha completato le superiori tendono ad avere un QI maggiore di 11.8 punti rispetto ai bambini la cui madre non ha concluso le superiori.\n\n89.319648 - 77.548387\n\n11.771260999999996\n\n\nCreiamo due vettori che contengono il QI dei bambini dei due gruppi.\n\n# Vector of kid_score when mom_hs is 1\nkid_score_mom_hs_1 = df[df[\"mom_hs\"] == 1][\"kid_score\"]\n\n# Vector of kid_score when mom_hs is 0\nkid_score_mom_hs_0 = df[df[\"mom_hs\"] == 0][\"kid_score\"]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#dimensione-delleffetto",
    "href": "chapters/mcmc/08_stan_two_groups.html#dimensione-delleffetto",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.3 Dimensione dell‚Äôeffetto",
    "text": "50.3 Dimensione dell‚Äôeffetto\nNel caso presente, la differenza tra le medie dei due gruppi √® di 11.8 punti sulla scala del QI, e potrebbe sembrare un risultato rilevante, considerando che la metrica del QI √® facilmente interpretabile. Tuttavia, √® importante notare che il test utilizzato in questo studio non √® il WISC, che ha una distribuzione normale con media 100 e deviazione standard 15, ma il test PIAT.\nIn generale, √® difficile comprendere il significato di una differenza tra le medie di due gruppi quando viene presentata solo come valore assoluto, soprattutto quando le varianze dei gruppi sono diverse. Per ottenere una misura pi√π informativa, √® necessario considerare sia la differenza tra le medie dei gruppi che l‚Äôincertezza associata a queste stime delle medie della popolazione. L‚Äôindice statistico che soddisfa questo scopo √® noto come ‚Äúdimensione dell‚Äôeffetto‚Äù (effect size).\nLa dimensione dell‚Äôeffetto √® una misura della forza dell‚Äôassociazione osservata, che tiene conto sia della grandezza della differenza tra i gruppi attesi che dell‚Äôincertezza sui dati. Tra gli indici pi√π comunemente utilizzati per quantificare la dimensione dell‚Äôeffetto, vi √® l‚Äôindice \\(d\\) di Cohen.\nNel caso di due medie, questo indice √® dato da:\n\\[\nd={\\frac {{\\bar {x}}_{1}-{\\bar {x}}_{2}}{s}},\n\\]\nladdove\n\\[\ns={\\sqrt {\\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}\n\\]\ne la varianza di ciascun gruppo √® calcolata come\n\\[\ns_{1}^{2}={\\frac {1}{n_{1}-1}}\\sum _{i=1}^{n_{1}}(x_{1,i}-{\\bar {x}}_{1})^{2}.\n\\]\nSolitamente, l‚Äôindice \\(d\\) di Cohen si interpreta usando la metrica seguente:\n\n\n\nDimensione dell‚Äôeffetto\n\\(d\\)\n\n\n\n\nVery small\n0.01\n\n\nSmall\n0.20\n\n\nMedim\n0.50\n\n\nLarge\n0.80\n\n\nVery large\n1.20\n\n\nHuge\n2.0\n\n\n\nPer una trattazione bayesiana della stima della dimensione dell‚Äôeffetto, si veda (doingbayesian?).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#modello-bayesiano",
    "href": "chapters/mcmc/08_stan_two_groups.html#modello-bayesiano",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.4 Modello bayesiano",
    "text": "50.4 Modello bayesiano\nIl modello bayesiano per il confronto tra le medie di due gruppi indipendenti comprende la definizione della verosimiglianza per i dati di ciascun gruppo e la descrizione delle distribuzioni a priori dei parametri rilevanti. Inoltre, in questo caso, abbiamo incluso anche la stima della dimensione dell‚Äôeffetto, che ci permette di valutare la forza dell‚Äôassociazione osservata tra i gruppi, tenendo conto dell‚Äôincertezza sui dati.\nCreiamo un dizonario con i dati rilevanti.\n\nstan_data = {\n    'N1': len(kid_score_mom_hs_1), \n    'N2': len(kid_score_mom_hs_0), \n    'y1': kid_score_mom_hs_1,\n    'y2': kid_score_mom_hs_0\n}\nstan_data\n\n{'N1': 341,\n 'N2': 93,\n 'y1': 0       65\n 1       98\n 2       85\n 3       83\n 4      115\n       ... \n 425    102\n 426    104\n 430     76\n 432     88\n 433     70\n Name: kid_score, Length: 341, dtype: int32,\n 'y2': 5       98\n 14     102\n 19     101\n 24      99\n 33     106\n       ... \n 422    100\n 427     59\n 428     93\n 429     94\n 431     50\n Name: kid_score, Length: 93, dtype: int32}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#modello-stan",
    "href": "chapters/mcmc/08_stan_two_groups.html#modello-stan",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.5 Modello Stan",
    "text": "50.5 Modello Stan\nPer analizzare questi dati ci serviremo del seguente modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'kid-score.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response times (group 1)\n  vector[N2] y2;  // response times (group 2)\n}\n\nparameters {\n  real mu_1;  // mean of group 1\n  real mu_2;  // mean of group 2\n  real&lt;lower=0&gt; sigma_1;  // standard deviation of group 1\n  real&lt;lower=0&gt; sigma_2;  // standard deviation of group 2\n}\n\ntransformed parameters {\n  real delta;  // difference in means\n  real cohen_d;  // Cohen's d effect size\n  delta = mu_1 - mu_2;\n  cohen_d = delta / sqrt((sigma_1^2 + sigma_2^2) / 2);\n}\n\nmodel {\n  // Priors\n  mu_1 ~ normal(80, 20);  // Prior for mean of group 1\n  mu_2 ~ normal(80, 20);  // Prior for mean of group 2\n  sigma_1 ~ normal(0, 10);  // Prior for standard deviation of group 1\n  sigma_2 ~ normal(0, 10);  // Prior for standard deviation of group 2\n\n  // Likelihood\n  y1 ~ normal(mu_1, sigma_1);\n  y2 ~ normal(mu_2, sigma_2);\n}\n\ngenerated quantities {\n  vector[N1] y1_rep;  // replicated data for group 1\n  vector[N2] y2_rep;  // replicated data for group 2\n  for (i in 1:N1) {\n    y1_rep[i] = normal_rng(mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2_rep[i] = normal_rng(mu_2, sigma_2);\n  }\n}\n\n\n\nNel nostro modello: - N1 √® il numero di osservazioni nel primo gruppo (bambini le cui madri hanno completato le superiori) - N2 √® il numero di osservazioni nel secondo gruppo (bambini le cui madri non hanno completato le superiori) - y1 √® un vettore contenente i valori di QI per il primo gruppo - y2 √® un vettore contenente i valori di QI per il secondo gruppo\n\n50.5.1 Spiegazione del modello\n\n50.5.1.1 Parametri\n\nmu_1 e mu_2: Rappresentano le medie dei valori di QI per i due gruppi.\nsigma_1 e sigma_2: Rappresentano le deviazioni standard dei valori dei QI per i due gruppi.\n\n\n\n50.5.1.2 Parametri trasformati\n\ndelta: √à la differenza tra le medie dei due gruppi (mu_1 - mu_2).\ncohen_d: √à la dimensione dell‚Äôeffetto di Cohen, che quantifica la differenza tra i gruppi in unit√† di deviazione standard.\n\n\n\n50.5.1.3 Prior\nImpostiamo delle prior per i parametri:\nmu_1 ~ normal(80, 20);\nmu_2 ~ normal(80, 20);\nsigma_1 ~ normal(0, 10);\nsigma_2 ~ normal(0, 10);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri. Per esempio, ci aspettiamo che i QI medi siano intorno a 80, ma con una certa variabilit√†.\n\n\n50.5.1.4 Likelihood\ny1 ~ normal(mu_1, sigma_1);\ny2 ~ normal(mu_2, sigma_2);\nQuesta parte del modello descrive come i dati osservati (y1 e y2) sono generati, date le medie e le deviazioni standard per ciascun gruppo. Assumiamo che i valori del QI seguano una distribuzione normale in ciascun gruppo.\n\n\n\n50.5.2 Quantit√† generate\ny1_rep[i] = normal_rng(mu_1, sigma_1);\ny2_rep[i] = normal_rng(mu_2, sigma_2);\nQueste righe generano dati ‚Äúreplicati‚Äù basati sul modello stimato. Questi possono essere utilizzati per il controllo del modello (posterior predictive checks).\n\n\n50.5.3 Interpretazione dei risultati\n\nmu_1 e mu_2: Ci dicono i valori QI medi stimati per ciascun gruppo.\nsigma_1 e sigma_2: Ci dicono quanto variano i valori del QI all‚Äôinterno di ciascun gruppo.\ndelta: Ci dice quanto √® grande la differenza nei valori dei QI medi tra i due gruppi.\ncohen_d: Ci fornisce una misura standardizzata della dimensione dell‚Äôeffetto.\n\n\n\n50.5.4 Conclusione\nQuesto modello ci permette di:\n\nStimare i valori dei QI medi e la loro variabilit√† per ciascun gruppo.\nQuantificare la differenza tra i gruppi e la sua incertezza.\nCalcolare una misura standardizzata della dimensione dell‚Äôeffetto (Cohen‚Äôs d).\nGenerare previsioni basate sul modello per future osservazioni.\n\nIl vantaggio principale di questo approccio bayesiano √® che otteniamo distribuzioni di probabilit√† complete per tutti i parametri di interesse, permettendoci di fare affermazioni probabilistiche sulla differenza tra i gruppi e sulla dimensione dell‚Äôeffetto.\nEseguiamo il campionamento MCMC:\n\nsample = model.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=1000, iter_warmup=1000,\n    show_progress=False, show_console=False\n)\n\n10:30:52 - cmdstanpy - INFO - CmdStan start processing\n10:30:52 - cmdstanpy - INFO - Chain [1] start processing\n10:30:52 - cmdstanpy - INFO - Chain [2] start processing\n10:30:52 - cmdstanpy - INFO - Chain [3] start processing\n10:30:52 - cmdstanpy - INFO - Chain [4] start processing\n10:30:52 - cmdstanpy - INFO - Chain [1] done processing\n10:30:52 - cmdstanpy - INFO - Chain [3] done processing\n10:30:52 - cmdstanpy - INFO - Chain [2] done processing\n10:30:52 - cmdstanpy - INFO - Chain [4] done processing\n10:30:52 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_lpdf: Scale parameter is 0, but must be positive! (in 'kid-score.stan', line 30, column 2 to column 29)\n    Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in 'kid-score.stan', line 30, column 2 to column 29)\nConsider re-running with show_console=True if the above output is unclear!\n\n\nEsaminiamo le tracce:\n\n_ = az.plot_trace(\n    sample, \n    figsize=(9, 12), \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    divergences=\"bottom\"\n)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63722/1925110735.py:7: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nLe distribuzioni predittive a posteriori sono adeguate, senza essere perfette.\n\nidata = az.from_cmdstanpy(\n    posterior=sample, \n    posterior_predictive=['y1_rep'], \n    observed_data={\"y1\": stan_data[\"y1\"]}\n)\n_ = az.plot_ppc(idata, data_pairs={\"y1\": \"y1_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\n\nidata = az.from_cmdstanpy(\n    posterior=sample, \n    posterior_predictive=['y2_rep'], \n    observed_data={\"y2\": stan_data[\"y2\"]}\n)\n_ = az.plot_ppc(idata, data_pairs={\"y2\": \"y2_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\naz.summary(\n    sample, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.28\n1.04\n87.33\n91.18\n0.02\n0.01\n3990.38\n2947.67\n1.0\n\n\nmu_2\n77.61\n2.27\n73.61\n82.01\n0.03\n0.02\n4317.58\n2940.56\n1.0\n\n\nsigma_1\n19.03\n0.73\n17.70\n20.42\n0.01\n0.01\n4729.21\n3162.76\n1.0\n\n\nsigma_2\n22.27\n1.63\n19.35\n25.38\n0.02\n0.02\n4419.97\n2908.53\n1.0\n\n\ndelta\n11.67\n2.47\n6.89\n16.32\n0.04\n0.03\n4346.03\n2887.27\n1.0\n\n\ncohen_d\n0.56\n0.12\n0.33\n0.78\n0.00\n0.00\n4334.34\n2953.62\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#modello-robusto",
    "href": "chapters/mcmc/08_stan_two_groups.html#modello-robusto",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.6 Modello Robusto",
    "text": "50.6 Modello Robusto\nUn modello bayesiano robusto per il confronto tra due medie indipendenti pu√≤ gestire deviazioni standard disuguali e outlier sostituendo la verosimiglianza normale con quella della distribuzione t di Student. Utilizzare una distribuzione t di Student al posto di una normale rende il modello pi√π resistente agli outlier. La distribuzione t di Student ha code pi√π pesanti rispetto alla normale, il che significa che √® meno influenzata da valori estremi nei dati. Questo √® particolarmente utile quando si sospetta la presenza di outlier nei dati o quando le deviazioni standard tra i gruppi sono disuguali. In questo modo, il modello bayesiano robusto offre stime pi√π affidabili delle medie e delle deviazioni standard dei gruppi, nonch√© della differenza tra le medie e della dimensione dell‚Äôeffetto.\n\nstan_file_t = os.path.join(project_directory, 'stan', 'kid-score-t.stan')\nmodel_t = CmdStanModel(stan_file=stan_file_t)\nprint(model_t.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response time (group 1)\n  vector[N2] y2;  // response time (group 2)\n}\nparameters {\n  real mu_2;  // mean of group 2\n  real delta;  // difference in means\n  real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n  real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n  real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n}\ntransformed parameters {\n  real mu_1 = mu_2 + delta; \n}\nmodel {\n  y1 ~ student_t(nu, mu_1, sigma_1);\n  y2 ~ student_t(nu, mu_2, sigma_2);\n  // priors\n  mu_2 ~ normal(80, 20);\n  delta ~ normal(0, 10);\n  sigma_1 ~ normal(0, 10);\n  sigma_2 ~ normal(0, 10);\n  nu ~ gamma(2, 0.1);\n}\ngenerated quantities {\n  vector[N1] y1rep;\n  vector[N2] y2rep;\n  real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n  real cohen_d = delta / pooled_sd;\n  \n  for (i in 1:N1) {\n    y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n  }\n}\n\n\n\n\nsample_t = model_t.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=1000, iter_warmup=1000,\n    show_progress=False, show_console=False\n)\n\n10:31:20 - cmdstanpy - INFO - CmdStan start processing\n10:31:20 - cmdstanpy - INFO - Chain [1] start processing\n10:31:20 - cmdstanpy - INFO - Chain [2] start processing\n10:31:20 - cmdstanpy - INFO - Chain [3] start processing\n10:31:20 - cmdstanpy - INFO - Chain [4] start processing\n10:31:20 - cmdstanpy - INFO - Chain [1] done processing\n10:31:20 - cmdstanpy - INFO - Chain [3] done processing\n10:31:20 - cmdstanpy - INFO - Chain [2] done processing\n10:31:20 - cmdstanpy - INFO - Chain [4] done processing\n10:31:20 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nConsider re-running with show_console=True if the above output is unclear!\n\n\nNel caso presente, usare un modello robusto non produce nessuna differenza rispetto al modello precedente in quanto non ci sono deviazoni importanti rispetto alla gaussianit√† e le due deviazioni standard sono simili.\n\naz.summary(\n    sample_t, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.49\n1.07\n87.43\n91.37\n0.02\n0.01\n3892.59\n3003.83\n1.0\n\n\nmu_2\n78.39\n2.29\n74.04\n82.63\n0.05\n0.03\n2486.44\n2273.07\n1.0\n\n\nsigma_1\n18.43\n0.77\n17.04\n19.94\n0.01\n0.01\n3278.45\n2545.50\n1.0\n\n\nsigma_2\n21.71\n1.62\n18.77\n24.82\n0.03\n0.02\n3175.33\n2299.83\n1.0\n\n\ndelta\n11.11\n2.50\n6.40\n15.82\n0.05\n0.04\n2487.74\n2084.50\n1.0\n\n\ncohen_d\n0.55\n0.13\n0.33\n0.81\n0.00\n0.00\n2496.90\n2123.93\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#modello-con-iper-priors",
    "href": "chapters/mcmc/08_stan_two_groups.html#modello-con-iper-priors",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.7 Modello con Iper-priors",
    "text": "50.7 Modello con Iper-priors\nIl seguente modello bayesiano per il confronto tra due medie indipendenti utilizza una distribuzione di Student‚Äôs t per gestire deviazioni standard disuguali e outlier. Inoltre, include iper-priors per una maggiore flessibilit√† nella definizione dei parametri delle distribuzioni a priori, che vengono stimate dai dati. Questo approccio permette di incorporare in modo pi√π efficace le incertezze sui parametri dei priors stessi, migliorando la robustezza del modello.\n\nstan_file_h = os.path.join(project_directory, 'stan', 'kid-score-h.stan')\nmodel_h = CmdStanModel(stan_file=stan_file_h)\nprint(model_t.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response time (group 1)\n  vector[N2] y2;  // response time (group 2)\n}\nparameters {\n  real mu_2;  // mean of group 2\n  real delta;  // difference in means\n  real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n  real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n  real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n}\ntransformed parameters {\n  real mu_1 = mu_2 + delta; \n}\nmodel {\n  y1 ~ student_t(nu, mu_1, sigma_1);\n  y2 ~ student_t(nu, mu_2, sigma_2);\n  // priors\n  mu_2 ~ normal(80, 20);\n  delta ~ normal(0, 10);\n  sigma_1 ~ normal(0, 10);\n  sigma_2 ~ normal(0, 10);\n  nu ~ gamma(2, 0.1);\n}\ngenerated quantities {\n  vector[N1] y1rep;\n  vector[N2] y2rep;\n  real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n  real cohen_d = delta / pooled_sd;\n  \n  for (i in 1:N1) {\n    y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n  }\n}\n\n\n\n\nsample_h = model_h.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=2_000, iter_warmup=1_000,\n    show_progress=False, show_console=False\n)\n\n10:31:27 - cmdstanpy - INFO - CmdStan start processing\n10:31:27 - cmdstanpy - INFO - Chain [1] start processing\n10:31:27 - cmdstanpy - INFO - Chain [2] start processing\n10:31:27 - cmdstanpy - INFO - Chain [3] start processing\n10:31:27 - cmdstanpy - INFO - Chain [4] start processing\n10:31:28 - cmdstanpy - INFO - Chain [1] done processing\n10:31:28 - cmdstanpy - INFO - Chain [4] done processing\n10:31:28 - cmdstanpy - INFO - Chain [2] done processing\n10:31:28 - cmdstanpy - INFO - Chain [3] done processing\n10:31:28 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nConsider re-running with show_console=True if the above output is unclear!\n10:31:28 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 1 had 25 divergent transitions (1.2%)\n    Chain 2 had 8 divergent transitions (0.4%)\n    Chain 3 had 24 divergent transitions (1.2%)\n    Chain 4 had 12 divergent transitions (0.6%)\n    Use the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n\n\nAnche in questo caso, la risposta non cambia:\n\naz.summary(\n    sample_h, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.52\n1.03\n87.65\n91.54\n0.01\n0.01\n8653.78\n6400.92\n1.0\n\n\nmu_2\n78.30\n2.29\n73.95\n82.52\n0.03\n0.02\n5688.16\n5777.55\n1.0\n\n\nsigma_1\n18.43\n0.79\n16.97\n19.94\n0.01\n0.01\n7954.84\n5392.71\n1.0\n\n\nsigma_2\n21.88\n1.65\n18.88\n25.08\n0.02\n0.01\n9745.94\n5250.42\n1.0\n\n\ndelta\n11.22\n2.50\n6.51\n15.83\n0.03\n0.02\n5590.51\n6029.02\n1.0\n\n\ncohen_d\n0.56\n0.13\n0.32\n0.79\n0.00\n0.00\n5626.06\n5815.05\n1.0\n\n\n\n\n\n\n\n\nIl nostro obiettivo √® comprendere se le medie dei due gruppi sono diverse, e l‚Äôincertezza associata alla stima a posteriori del parametro delta √® fondamentale per rispondere a questa domanda. Se l‚Äôintervallo di credibilit√† associato a delta non include lo 0, allora possiamo concludere con un certo grado di sicurezza che le medie dei due gruppi sono diverse. In altre parole, se l‚Äôintervallo di credibilit√† non contiene lo 0, allora ci sono prove convincenti che le medie dei due gruppi sono diverse.\nNel caso presente, l‚Äôintervallo di credibilit√† al 94% non include lo 0. Pertanto, possiamo concludere, con un livello di sicurezza soggettivo del 94%, che il QI dei bambini le cui madri hanno completato le scuole superiori tende ad essere pi√π elevato rispetto a quello dei bambini le cui madri non hanno completato le scuole superiori.\n\n_ = az.plot_posterior(sample_h, var_names=\"delta\", ref_val=0, figsize=(6, 3))\n\n\n\n\n\n\n\n\nLa figura seguente mostra la distribuzione a posteriori della grandezza dell‚Äôeffetto.\n\n_ = az.plot_posterior(sample_h, var_names=\"cohen_d\", ref_val=0, figsize=(6, 3))\n\n\n\n\n\n\n\n\nPossiamo dunque concludere che, per ci√≤ che concerne l‚Äôeffetto della scolarit√† della madre sul quoziente di intelligenza del bambino, la dimensione dell‚Äôeffetto √® ‚Äúmedia‚Äù.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/mcmc/08_stan_two_groups.html#verifica-di-ipotesi-bayesiana",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.8 Verifica di ipotesi bayesiana",
    "text": "50.8 Verifica di ipotesi bayesiana\nCome ulteriore approfondimento di questa analisi statistica, possiamo esaminare l‚Äôapproccio bayesiano equivalente al test di ipotesi tradizionale.\nDopo aver ottenuto un campione dalla distribuzione a posteriori del parametro di interesse \\(\\mu\\) per ciascun gruppo, possiamo porci la domanda: qual √® la probabilit√† che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell‚Äôaltro gruppo? Per rispondere a questa domanda, utilizzeremo campioni casuali dalle distribuzioni a posteriori dei parametri. Confronteremo le coppie di valori campionati dalle due distribuzioni a posteriori del parametro di interesse e calcoleremo la media di tali confronti. Questo ci fornir√† un‚Äôindicazione sulla probabilit√† che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell‚Äôaltro gruppo, basandoci sulla distribuzione a posteriori dei parametri stimati dal modello.\nPer eseguire un test d‚Äôipotesi per calcolare la probabilit√† che $ _1 &gt; _2 $ utilizzando il modello Stan fornito e cmdstanpy, √® necessario estrarre i campioni posteriori per i parametri \\(\\mu_1\\) e \\(\\mu_2\\) dopo aver adattato il modello. Successivamente, √® possibile calcolare la probabilit√† basandosi sui campioni posteriori. Ad esempio, ci possiamo chiedere quale sia la probabilit√† che un bambino la cui madre ha completato la scuola superiore abbia un QI maggiore di un bambino la cui madre non ha completato la scuola superiore.\n\n# Extract the posterior samples for mu_1 and mu_2\nposterior = sample_h.draws_pd()\nposterior['mu_1'] = posterior['mu_2'] + posterior['delta']\n\n# Compute the probability that mu_1 &gt; mu_2\nprob_mu1_greater_mu2 = np.mean(posterior['mu_1'] &gt; posterior['mu_2'])\n\nprint(f\"Probability that mu_1 &gt; mu_2: {prob_mu1_greater_mu2:.4f}\")\n\nProbability that mu_1 &gt; mu_2: 1.0000\n\n\nUna tale probabilit√† √® effettivamente uguale a 1 il che conferma il risultato precedente, ovvero l‚Äôiportanza del livello di istruzione della madre per il QI del figlio.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/08_stan_two_groups.html#commenti-e-considerazioni-finali",
    "title": "50¬† Confronto tra due gruppi",
    "section": "50.9 Commenti e considerazioni finali",
    "text": "50.9 Commenti e considerazioni finali\nIn questo capitolo abbiamo esaminato la procedura bayesiana per calcolare la distribuzione a posteriori della differenza tra le medie di due gruppi indipendenti. Inoltre, abbiamo esplorato il calcolo della dimensione dell‚Äôeffetto in termini bayesiani. Nell‚Äôesempio trattato, abbiamo considerato il caso in cui la verosimiglianza √® descritta da una distribuzione Gaussiana. Tuttavia, va sottolineato che la scelta di una distribuzione specifica per la verosimiglianza non √® vincolante nella statistica bayesiana. √à possibile utilizzare qualsiasi distribuzione di probabilit√†, purch√© sia adeguata ai dati del campione.\nNel caso del confronto tra le medie di due gruppi indipendenti, una distribuzione molto utilizzata √® la distribuzione \\(t\\) di Student. Questa distribuzione √® particolarmente vantaggiosa quando si desidera condurre un‚Äôanalisi statistica ‚Äúrobusta‚Äù, ovvero un‚Äôanalisi che non sia influenzata da osservazioni anomale o outlier presenti nei dati. Per questo motivo, la distribuzione \\(t\\) di Student √® spesso preferita quando si lavora con dati che potrebbero contenere valori anomali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_two_groups.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/08_stan_two_groups.html#informazioni-sullambiente-di-sviluppo",
    "title": "50¬† Confronto tra due gruppi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBland, J Martin, e Douglas G Altman. 2011. ¬´Comparisons within randomised groups can be very misleading¬ª. Bmj 342.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>50</span>¬† <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_poisson_model_1.html",
    "href": "chapters/mcmc/09_stan_poisson_model_1.html",
    "title": "51¬† Modello di Poisson (1)",
    "section": "",
    "text": "Introduction\nNel Capitolo 40, abbiamo determinato la distribuzione a posteriori sia attraverso il metodo basato su griglia, sia tramite la derivazione analitica utilizzando la famiglia coniugata gamma-poisson. In questo capitolo, affronteremo lo stesso problema utilizzando Stan.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_poisson_model_1.html#dati",
    "href": "chapters/mcmc/09_stan_poisson_model_1.html#dati",
    "title": "51¬† Modello di Poisson (1)",
    "section": "51.1 Dati",
    "text": "51.1 Dati\nRiconsideriamo lo stesso problema discusso nella sezione Capitolo 40. I dati disponibili sono:\n\ny = np.array([2, 1, 3, 2, 2, 1, 1, 1])",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_poisson_model_1.html#modello-di-poisson-con-stan",
    "href": "chapters/mcmc/09_stan_poisson_model_1.html#modello-di-poisson-con-stan",
    "title": "51¬† Modello di Poisson (1)",
    "section": "51.2 Modello di Poisson con Stan",
    "text": "51.2 Modello di Poisson con Stan\nNel modello Stan utilizzeremo una verosimiglianza di Poisson e una distribuzione a priori per il parametro \\(\\lambda\\) modellata da una distribuzione Gamma con parametri \\(\\alpha_{\\text{prior}} = 9\\) e \\(\\beta_{\\text{prior}} = 2\\).\n\nstan_file = os.path.join(project_directory, \"stan\", \"gamma_poisson_mcmc.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  array[N] int&lt;lower=0&gt; y; // dati osservati\n  real&lt;lower=0&gt; alpha_prior; // parametro alpha della priori Gamma\n  real&lt;lower=0&gt; beta_prior; // parametro beta della priori Gamma\n}\nparameters {\n  real&lt;lower=0&gt; lambda; // parametro di interesse\n}\nmodel {\n  // Priori\n  lambda ~ gamma(alpha_prior, beta_prior);\n  \n  // Verosimiglianza\n  y ~ poisson(lambda);\n}\ngenerated quantities {\n  real alpha_post = alpha_prior + sum(y);\n  real beta_post = beta_prior + N;\n}\n\n\n\nSistemiamo i dati nel formato richiesto da Stan.\n\nN = len(y)\nalpha_prior = 9\nbeta_prior = 2\n\n# Preparazione dei dati per Stan\nstan_data = {\"N\": N, \"y\": y, \"alpha_prior\": alpha_prior, \"beta_prior\": beta_prior}\nprint(stan_data)\n\n{'N': 8, 'y': array([2, 1, 3, 2, 2, 1, 1, 1]), 'alpha_prior': 9, 'beta_prior': 2}\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEstraiamo un campione casuale dalla distribuzione a posteriori di lambda.\n\nlambda_samples = fit.stan_variable(\"lambda\")\n\nCalcoliamo i parametri della Gamma a posteriori teorica.\n\nalpha_post = alpha_prior + np.sum(y)\nbeta_post = beta_prior + N\n\nCreiamo un istogramma con i campioni della distribuzione a posteriori di \\(\\lambda\\) e sovrapposta la densit√† teorica della distribuzione a posteriori.\n\nplt.figure(figsize=(10, 6))\n\n# Istogramma normalizzato dei campioni MCMC\nplt.hist(\n    lambda_samples,\n    bins=50,\n    density=True,\n    alpha=0.7,\n    label=\"Distribuzione a posteriori empirica\",\n)\n\n# Gamma teorica\nx = np.linspace(0, max(lambda_samples), 200)\ngamma_pdf = stats.gamma.pdf(x, a=alpha_post, scale=1 / beta_post)\nplt.plot(x, gamma_pdf, \"r-\", lw=2, label=\"Distribuzione Gamma teorica\")\n\n# Personalizzazione del grafico\nplt.title(\"Distribuzione a posteriori di lambda\")\nplt.xlabel(\"lambda\")\nplt.ylabel(\"Densit√†\")\nplt.legend()\n\n# Aggiungiamo informazioni sui parametri\nplt.text(\n    0.95,\n    0.95,\n    f\"alpha_post = {alpha_post:.2f}\\nbeta_post = {beta_post:.2f}\",\n    transform=plt.gca().transAxes,\n    verticalalignment=\"top\",\n    horizontalalignment=\"right\",\n    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n)\n\nText(0.95, 0.95, 'alpha_post = 22.00\\nbeta_post = 10.00')\n\n\n\n\n\n\n\n\n\nUsiamo ArviZ per un sommario della distribuzione a posteriori del parametro \\(\\lambda\\).\n\naz.summary(fit, var_names=\"lambda\")\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nlambda\n2.214\n0.467\n1.395\n3.11\n0.008\n0.006\n3262.0\n4279.0\n1.0\n\n\n\n\n\n\n\n\nGeneriamo l‚Äôintervallo di credibilit√† al 94% per la distribuzione a posteriori del parametro lambda.\n\naz.plot_posterior(fit, var_names=\"lambda\")\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, analizzando i dati disponibili e utilizzando una distribuzione a priori Gamma(9, 2), possiamo affermare con un grado di certezza soggettivo del 94% che il tasso stimato di occorrenza dell‚Äôevento considerato sia di 2.2 compulsioni all‚Äôora, con un intervallo di credibilit√† compreso tra 1.4 e 3.1.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_poisson_model_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/09_stan_poisson_model_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "51¬† Modello di Poisson (1)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Fri Aug 16 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\narviz     : 0.18.0\nscipy     : 1.14.0\nlogging   : 0.5.1.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\ncmdstanpy : 1.2.4",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>¬† <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html",
    "title": "52¬† Modello di Poisson (2)",
    "section": "",
    "text": "Introduction\nNel capitolo precedente abbiamo esaminato il processo di derivazione della distribuzione a posteriori per i parametri della distribuzione Gamma, la quale viene impiegata quando si adotta un prior Gamma per una verosimiglianza di Poisson. In questo capitolo, useremo tale metodo per affrontare una questione relativa all‚Äôanalisi di un set di dati reali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#domanda-della-ricerca",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#domanda-della-ricerca",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.1 Domanda della ricerca",
    "text": "52.1 Domanda della ricerca\nCome spiegato qui, i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1¬∞ gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\nLo scopo della presente analisi dei dati √® determinare il tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, e fornire una stima dell‚Äôincertezza associata a questo valore.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#importazione-e-pre-processing-dei-dati",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#importazione-e-pre-processing-dei-dati",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.2 Importazione e pre-processing dei dati",
    "text": "52.2 Importazione e pre-processing dei dati\n\nurl = \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat = pd.read_csv(url)\nfps_dat.head()\n\n\n# Convert date\nfps_dat[\"date\"] = pd.to_datetime(fps_dat[\"date\"])\n\n# Create a new column 'year' to store the year information from the 'date' column\nfps_dat[\"year\"] = fps_dat[\"date\"].dt.year\n\nfps_dat.columns\n\nIndex(['id', 'date', 'threat_type', 'flee_status', 'armed_with', 'city',\n       'county', 'state', 'latitude', 'longitude', 'location_precision',\n       'name', 'age', 'gender', 'race', 'race_source',\n       'was_mental_illness_related', 'body_camera', 'agency_ids', 'year'],\n      dtype='object')\n\n\n\n# Filter out rows with year equal to 2024\nfps = fps_dat[fps_dat[\"year\"] != 2024]\n\n# Count occurrences of each year in fps\nyear_counts = fps[\"year\"].value_counts()\nprint(year_counts)\n\nyear\n2023    1161\n2022    1095\n2021    1050\n2020    1020\n2019     996\n2015     995\n2018     992\n2017     984\n2016     959\nName: count, dtype: int64\n\n\nCreiamo un DataFrame con i dati necessari per PyMC.\n\nyear_counts.values\n\narray([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959])\n\n\n\n# Convert year_counts Series to a DataFrame\ndf = year_counts.reset_index()  # This converts the index (year) to a column and resets the index of the DataFrame\ndf.columns = ['year', 'events']  # Renaming the columns to 'year' and 'events'\n\n# Now, df is the DataFrame you wanted, with 'year' and 'events' columns\nprint(df)\n\n   year  events\n0  2023    1161\n1  2022    1095\n2  2021    1050\n3  2020    1020\n4  2019     996\n5  2015     995\n6  2018     992\n7  2017     984\n8  2016     959",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#modello-di-poisson",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#modello-di-poisson",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.3 Modello di Poisson",
    "text": "52.3 Modello di Poisson\nIl nostro interesse riguarda il tasso di occorrenza di sparatorie fatali da parte della polizia per anno. Indicheremo questo tasso come \\(\\theta\\), e il suo intervallo di valori possibili √® \\([0, \\infty)\\). Un modello di Poisson rappresenta tipicamente il punto di partenza per l‚Äôanalisi di dati relativi alle frequenze assolute di un evento in un intervallo di tempo fissato. Il modello presuppone che i dati seguano una distribuzione di Poisson con un parametro di tasso \\(\\lambda\\):\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#distribuzione-a-priori",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#distribuzione-a-priori",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.4 Distribuzione a priori",
    "text": "52.4 Distribuzione a priori\nCome distribuzione a priori per il parametro \\(\\lambda\\) nel modello di Poisson possiamo usare la distribuzione Gamma, poich√© √® una scelta coniugata. Ci√≤ significa che, quando viene combinata con la distribuzione di Poisson come verosimiglianza dei dati, la distribuzione Gamma produce una distribuzione a posteriori con una forma analitica semplice. Questa caratteristica semplifica il processo di inferenza bayesiana.\nNel nostro caso, il parametro \\(\\lambda\\) rappresenta il tasso di occorrenza di sparatorie fatali per anno negli Stati Uniti. Prima di osservare i dati effettivi riportati dal Washington Post, abbiamo una conoscenza limitata su tale fenomeno. Pertanto, dobbiamo specificare una distribuzione a priori per \\(\\lambda\\) che rifletta la nostra incertezza iniziale. As esempio, possiamo ipotizzare che ci sia, in media, una sparatoria mortale per stato al mese, quindi 12 sparatorie mortali all‚Äôanno per stato. Questo ci porta a una stima iniziale di 600 sparatorie fatali negli Stati Uniti ogni anno. Dato che non siamo molto sicuri di questa ipotesi, vogliamo specificare una distribuzione a priori con un certo grado di incertezza. Imponiamo dunque una deviazione standard pari a 200.\nPer visualizzare la distribuzione a priori per il parametro \\(\\lambda\\), creiamo un istogramma della distribuzione Gamma con i parametri specificati usando PyMC.\n\n# Parameters for the Gamma distribution\nmu = 600\nsigma = 200\n\n# Convert mu and sigma to shape (k) and scale (theta) parameters\ntheta = sigma**2 / mu\nk = mu / theta\n\n# Draw samples from the Gamma distribution\nx_draws = stats.gamma.rvs(a=k, scale=theta, size=50000, random_state=2)\n\n# Plot the histogram of the drawn samples\nsns.histplot(x_draws, kde=False)\n\n# Add labels and title\nplt.xlabel(\"Tasso di occorrenza (anno)\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione Gamma con mu = 600 e sigma = 200\")\nplt.show()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#modello-di-poisson-con-stan",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#modello-di-poisson-con-stan",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.5 Modello di Poisson con Stan",
    "text": "52.5 Modello di Poisson con Stan\nFormuliamo il modello di Poisson usando questi iper-parametri per la distribuzione a priori del parametro \\(\\lambda\\) (rate) della distribuzione di Poisson.\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_model2.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y; // dati osservati  \n}\nparameters {\n  real&lt;lower=0&gt; rate; // parametro rate per la distribuzione Poisson\n}\nmodel {\n  // Priori\n  rate ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y ~ poisson(rate);\n}\n\n\n\n\n# Caricare i dati\nstan_data = {\n    \"y\": [1161, 1095, 1050, 1020, 996, 995, 992, 984, 959],\n    \"N\": 9,\n    \"mu\": 600,\n    \"sigma\": 200\n}\nprint(stan_data)\n\n{'y': [1161, 1095, 1050, 1020, 996, 995, 992, 984, 959], 'N': 9, 'mu': 600, 'sigma': 200}\n\n\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro rate.\n\naz.plot_trace(trace, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\nIl modello converge rapidamente e i grafici delle tracce sembrano ben mescolati.\nGeneriamo un sommario numerico della distribuzione a posteriori.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n1027.83\n10.819\n1007.71\n1048.01\n0.21\n0.149\n2650.0\n3735.0\n1.0\n\n\n\n\n\n\n\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y; // dati osservati  \n}\nparameters {\n  real&lt;lower=0&gt; rate; // parametro rate per la distribuzione Poisson\n}\nmodel {\n  // Priori\n  rate ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y ~ poisson(rate);\n}\n\n\n\nUsiamo ArviZ per generare l‚Äôintervallo di credibilit√† al 94% per la distribuzione a posteriori del parametro rate.\n\naz.plot_posterior(trace, var_names=\"rate\")\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, analizzando i dati compresi tra il 2015 e il 2023 e basandoci su una distribuzione a priori che presuppone una sparatoria mortale al mese per stato, possiamo concludere con un grado di certezza soggettivo del 94% che il tasso stimato di sparatorie fatali da parte della polizia negli Stati Uniti sia di 1028 casi all‚Äôanno, con un intervallo di credibilit√† compreso tra 1008 e 1048.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#derivazione-analitica",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#derivazione-analitica",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.6 Derivazione analitica",
    "text": "52.6 Derivazione analitica\nPer derivare i parametri della distribuzione Gamma (\\(\\alpha\\) e \\(\\beta\\)) conoscendo la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), possiamo utilizzare le seguenti relazioni:\n\n\\(\\alpha = (\\frac{\\mu}{\\sigma})^2\\)\n\\(\\beta = \\frac{\\mu}{\\sigma^2}\\)\n\nQueste formule si basano sul fatto che la media della distribuzione Gamma √® data da \\(\\frac{\\alpha}{\\beta}\\), mentre la varianza √® \\(\\frac{\\alpha}{\\beta^2}\\). Inoltre, la deviazione standard √® la radice quadrata della varianza.\nLa distribuzione a posteriori per \\(\\lambda\\), data una verosimiglianza di Poisson e una distribuzione a priori gamma, √® ancora una distribuzione gamma con parametri aggiornati. Possiamo calcolare i parametri della distribuzione a posteriori nel modo seguente:\n\nParametro di forma a posteriori (Œ±_post) = Œ±_prior + Œ£(y_i), dove Œ£(y_i) rappresenta la somma dei dati osservati.\nParametro di tasso a posteriori (Œ≤_post) = Œ≤_prior + n, dove n √® il numero di punti dati.\n\nCon questi parametri aggiornati, possiamo poi calcolare la media a posteriori della distribuzione gamma e l‚Äôintervallo di credibilit√†.\n\ndata = df[\"events\"]\n\n# Prior hyperparameters\nalpha_prior = (mu / sigma)**2\nbeta_prior = mu / sigma**2\n\n# Data summary\nn = len(df[\"events\"])\nsum_y = np.sum(df[\"events\"])\n\n# Posterior hyperparameters\nalpha_post = alpha_prior + sum_y\nbeta_post = beta_prior + n\n\n# Posterior distribution (Gamma)\nposterior_gamma = stats.gamma(alpha_post, scale=1 / beta_post)\n\n# Calculate the mean and credibility interval (94%)\nposterior_mean = posterior_gamma.mean()\ncredible_interval = posterior_gamma.interval(0.94)\n\nprint(\"Estimated Rate (Posterior Mean):\", posterior_mean)\nprint(\"Credibility Interval (94%):\", credible_interval)\n\nEstimated Rate (Posterior Mean): 1027.287853577371\nCredibility Interval (94%): (1007.3046264976574, 1047.4587209661117)\n\n\nL‚Äôoutput delle istruzioni precedenti fornisce il tasso stimato a posteriori e l‚Äôintervallo di credibilit√† al 94%. A causa di approssimazioni numeriche, i valori non coincidono esattamente con i risultati ottenuti con PyMC, ma sono molto simili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#vittime-non-armate",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#vittime-non-armate",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.7 Vittime non armate",
    "text": "52.7 Vittime non armate\nConsideriamo ora uno studio di Ross, Winterhalder, e McElreath (2021). Nell‚Äôintroduzione allo studio, gli autori affermano che studi precedenti hanno dimostrato che la polizia negli Stati Uniti uccide cittadini neri rispetto a cittadini bianchi a tassi pi√π elevati di quanto ci si potrebbe aspettare secondo un modello generativo in cui la polizia incontra e uccide cittadini neri e bianchi in proporzione alle loro dimensioni relative della popolazione (ad esempio, Gabrielson et al., 2014; The Guardian, 2016; Takagi, 1981). Tuttavia, l‚Äôutilit√† di questi studi nel rilevare disparit√† razziali ingiustificabili nel comportamento della polizia √® stata messa in discussione (Cesario et al., 2019; Fryer, 2017; Selby et al., 2016; Tregle et al., 2019) perch√© la polizia uccide principalmente individui - neri o bianchi - che erano armati e impegnati in attivit√† criminali al momento dell‚Äôinterazione (Ross, 2015; Selby et al., 2016). Le differenze sottostanti nei tassi di attivit√† criminale armata specifici per la razza, piuttosto che - o oltre a - pregiudizi e/o bias stereotipati non intenzionali (Payne, 2006) da parte della polizia, sono state quindi citate come possibili cause dell‚Äôaumento dei tassi di sparatorie della polizia contro gli afroamericani. Tuttavia, Ross, Winterhalder, e McElreath (2021) fanno notare che le disparit√† a discapito degli individui afro-americani nell‚Äôuso della forza da parte della polizia statunitense persistono nel caso di individui disarmati sia a livello non letale (Fryer, 2016) che letale (Ross, 2015).\nPer verificare questa affermazione di Ross, Winterhalder, e McElreath (2021), usiamo i dati forniti dal Washington Post. Iniziamo a considerare il numero di sparatorie fatali da parte delle polizia statunitense nei confronti di un individuo disarmato caucasico.\n\n# Filter the dataframe to include only rows where the individual was unarmed\nunarmed_events = fps[fps[\"armed_with\"] == \"unarmed\"]\n\n# Filter the dataframe to create two separate dataframes for white and non-white races\nwhite_df = unarmed_events[unarmed_events[\"race\"] == \"W\"]\nnon_white_df = unarmed_events[unarmed_events[\"race\"] != \"W\"]\n\nprint(\"\\nWhite Race DataFrame:\")\nprint(white_df.head())\n\n\nWhite Race DataFrame:\n      id       date threat_type flee_status armed_with         city  \\\n8     16 2015-01-06    accident         not    unarmed   Burlington   \n72   342 2015-01-29        move        foot    unarmed   Stillwater   \n76   114 2015-02-02        flee        foot    unarmed  Hummelstown   \n119  159 2015-02-17        flee        foot    unarmed  Springfield   \n136  371 2015-02-23        move         not    unarmed        Omaha   \n\n         county state   latitude  longitude location_precision  \\\n8    Des Moines    IA  40.809250 -91.118875      not_available   \n72        Payne    OK  36.121177 -97.050127      not_available   \n76      Dauphin    PA  40.273404 -76.712841      not_available   \n119      Greene    MO  37.225250 -93.319432      not_available   \n136     Douglas    NE  41.244051 -95.933308      not_available   \n\n                name   age  gender race    race_source  \\\n8      Autumn Steele  34.0  female    W  not_available   \n72      Ralph Willis  42.0    male    W  not_available   \n76     David Kassick  59.0    male    W  not_available   \n119  Michael Ireland  31.0    male    W  not_available   \n136     Daniel Elrod  39.0    male    W  not_available   \n\n     was_mental_illness_related  body_camera agency_ids  year  \n8                         False         True        287  2015  \n72                        False        False        164  2015  \n76                        False        False        303  2015  \n119                       False        False        350  2015  \n136                       False        False        158  2015  \n\n\n\nprint(\"\\nNon-White Race DataFrame:\")\nprint(non_white_df.head())\n\n\nNon-White Race DataFrame:\n     id       date threat_type flee_status armed_with         city    county  \\\n2     5 2015-01-03        move         not    unarmed      Wichita  Sedgwick   \n17   36 2015-01-08      attack         not    unarmed       Strong     Union   \n62  352 2015-01-26        flee         car    unarmed       Tahoka      Lynn   \n83  116 2015-02-04      attack         not    unarmed  Tallahassee      Leon   \n86  125 2015-02-04    accident         not    unarmed        Tempe  Maricopa   \n\n   state   latitude   longitude location_precision                 name   age  \\\n2     KS  37.694766  -97.280554      not_available   John Paul Quintero  23.0   \n17    AR  33.111333  -92.358981      not_available  Artago Damon Howard  36.0   \n62    TX  33.166180 -101.666311      not_available   Joshua Omar Garcia  24.0   \n83    FL  30.465764  -84.330427      not_available          Jeremy Lett  28.0   \n86    AZ  33.378178 -111.978345      not_available    Joaquin Hernandez  28.0   \n\n   gender race    race_source  was_mental_illness_related  body_camera  \\\n2    male    H  not_available                       False        False   \n17   male    B  not_available                       False        False   \n62   male    H  not_available                       False        False   \n83   male    B  not_available                       False        False   \n86   male    H  not_available                       False        False   \n\n          agency_ids  year  \n2                238  2015  \n17               249  2015  \n62               179  2015  \n83               311  2015  \n86  247;195;2267;319  2015  \n\n\nDi seguito sono riportate le frequenze assolute di vittime disarmate di razza caucasica.\n\n# Filter the dataframe to include only rows where the individual was unarmed and identified as white\nunarmed_white_events = white_df[white_df[\"armed_with\"] == \"unarmed\"]\n\n# Group the filtered dataframe by year and count the occurrences\nevents_by_year_white_race = unarmed_white_events.groupby(\"year\").size().reset_index(name=\"event_count\")\n\nprint(events_by_year_white_race)\n\n   year  event_count\n0  2015           31\n1  2016           29\n2  2017           29\n3  2018           26\n4  2019           26\n5  2020           27\n6  2021            7\n7  2022           23\n8  2023           17\n\n\nPer gli stessi anni, qui sotto sono riportate le frequenze assolute delle vittime di razza non caucasica.\n\n# Filter the dataframe to include only rows where the individual was unarmed and identified as non-white\nunarmed_non_white_events = non_white_df[non_white_df[\"armed_with\"] == \"unarmed\"]\n\n# Group the filtered dataframe by year and count the occurrences\nevents_by_year_non_white_race = unarmed_non_white_events.groupby(\"year\").size().reset_index(name=\"event_count\")\n\nprint(events_by_year_non_white_race)\n\n   year  event_count\n0  2015           63\n1  2016           35\n2  2017           40\n3  2018           33\n4  2019           28\n5  2020           34\n6  2021           26\n7  2022           29\n8  2023           34\n\n\nCome distribuzione a priori per il tasso di morti, usiamo la media dei due campioni.\n\n0.5 * (np.mean(events_by_year_non_white_race.event_count) + \nnp.mean(events_by_year_white_race.event_count))\n\n29.833333333333336\n\n\nUtilizziamo una deviazione standard piuttosto grande per esprimere la nostra incertezza.\n\n# Parameters for the Gamma distribution\nmu = 30\nsigma = 10\n\n# Convert mu and sigma to shape (k) and scale (theta) parameters\ntheta = sigma**2 / mu\nk = mu / theta\n\n# Draw samples from the Gamma distribution\nx_draws = stats.gamma.rvs(a=k, scale=theta, size=50000, random_state=2)\n\n# Plot the histogram of the drawn samples\nsns.histplot(x_draws, kde=False)\n\n# Add labels and title\nplt.xlabel(\"Tasso di occorrenza (anno)\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione Gamma con mu = 30 e sigma = 10\")\nplt.show()\n\n\n\n\n\n\n\n\nEseguiamo il campionamento per i dati del campione caucasico.\n\n# Gruppo caucasico\nstan_data_white = {\n    \"y\": events_by_year_white_race[\"event_count\"],\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n}\n\n\ntrace_white = model.sample(\n    data=stan_data_white,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori della frequenze di vittime di razza caucasica.\n\naz.plot_trace(trace_white, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(trace_white)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n24.141\n1.583\n21.246\n27.201\n0.03\n0.021\n2864.0\n3732.0\n1.0\n\n\n\n\n\n\n\n\nEseguiamo il campionamento per i dati del campione caucasico.\n\n# Gruppo non caucasico\nstan_data_non_white = {\n    \"y\": events_by_year_non_white_race[\"event_count\"],\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n}\n\n\ntrace_non_white = model.sample(\n    data=stan_data_non_white,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori della frequenze di vittime di razza noln caucasica.\n\naz.plot_trace(trace_non_white, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(trace_non_white)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n35.615\n1.954\n32.06\n39.396\n0.036\n0.026\n2920.0\n4095.0\n1.0\n\n\n\n\n\n\n\n\nIl confronto tra i due intervalli di credibilit√† suggerisce che le frequenze attese del modello di Poisson risultano maggiori nel gruppo non caucasico rispetto al gruppo caucasico. √à importante considerare anche che la popolazione caucasica negli Stati Uniti √® numericamente superiore rispetto agli individui non caucasici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#modello-combinato-per-i-due-gruppi",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#modello-combinato-per-i-due-gruppi",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.8 Modello combinato per i due gruppi",
    "text": "52.8 Modello combinato per i due gruppi\nIn alternativa, possiamo creare un modello Stan unico che valuti direttamente la differenza a posteriori delle frequenze attese dal modello di Poisson per i due gruppi. Per fare questo, possiamo estendere il modello per includere due rate, uno per ogni gruppo, e calcolare la differenza a posteriori delle frequenze attese.\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_diff_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni per ogni gruppo\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y_white; // dati osservati per il gruppo caucasico\n  array[N] int&lt;lower=0&gt; y_non_white; // dati osservati per il gruppo non caucasico\n}\nparameters {\n  real&lt;lower=0&gt; rate_white; // parametro rate per la distribuzione Poisson per il gruppo caucasico\n  real&lt;lower=0&gt; rate_non_white; // parametro rate per la distribuzione Poisson per il gruppo non caucasico\n}\nmodel {\n  // Priori\n  rate_white ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  rate_non_white ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y_white ~ poisson(rate_white);\n  y_non_white ~ poisson(rate_non_white);\n}\ngenerated quantities {\n  real diff_rate = rate_non_white - rate_white; // differenza tra le frequenze attese\n}\n\n\n\nNel blocco generated quantities calcoliamo la distribuzione a posteriori della differenza tra i tassi di occorrenza stimati per i gruppi non caucasici e caucasici. Questa differenza permette di quantificare direttamente il confronto tra i tassi di incidenza dei due gruppi.\nGeneriamo il dizionario appropriato per il modello.\n\nstan_groups_data = {\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n    \"y_white\": events_by_year_white_race[\"event_count\"],\n    \"y_non_white\": events_by_year_non_white_race[\"event_count\"],\n}\nprint(stan_groups_data)\n\n{'N': 9, 'mu': 30, 'sigma': 10, 'y_white': 0    31\n1    29\n2    29\n3    26\n4    26\n5    27\n6     7\n7    23\n8    17\nName: event_count, dtype: int64, 'y_non_white': 0    63\n1    35\n2    40\n3    33\n4    28\n5    34\n6    26\n7    29\n8    34\nName: event_count, dtype: int64}\n\n\nEseguiamo il campionamento.\n\ntrace_groups = model.sample(\n    data=stan_groups_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro di interesse.\n\n_ = az.plot_trace(trace_groups, combined=True, var_names=[\"diff_rate\"], figsize= (9, 3))\n\n\n\n\n\n\n\n\n\naz.summary(trace_groups)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ndiff_rate\n11.508\n2.586\n6.792\n16.443\n0.033\n0.023\n6263.0\n5254.0\n1.0\n\n\nrate_non_white\n35.577\n1.946\n31.978\n39.260\n0.023\n0.016\n7282.0\n5576.0\n1.0\n\n\nrate_white\n24.069\n1.627\n21.098\n27.285\n0.021\n0.015\n5931.0\n4896.0\n1.0\n\n\n\n\n\n\n\n\nSulla base dei risultati ottenuti dal modello di Poisson, possiamo trarre le seguenti conclusioni:\nIl tasso stimato di incidenza delle vittime disarmate uccise dalla polizia negli Stati Uniti √® pi√π alto per il gruppo non caucasico rispetto al gruppo caucasico. La differenza media stimata tra i due tassi di incidenza √® di 11.508, con una deviazione standard di 2.586. Questo significa che, in media, il tasso per il gruppo non caucasico √® di circa 11.5 punti superiore rispetto al tasso per il gruppo caucasico.\nL‚Äôintervallo di credibilit√† al 94% per questa differenza va da 6.792 a 16.443, indicando che √® molto probabile che la vera differenza tra i tassi di incidenza dei due gruppi si trovi all‚Äôinterno di questo intervallo. Questo intervallo di credibilit√† non include lo zero, il che fornisce ulteriore evidenza che il tasso di incidenza per il gruppo non caucasico √® effettivamente pi√π alto rispetto al gruppo caucasico.\nInoltre, i tassi di incidenza stimati per ciascun gruppo sono i seguenti:\n\nGruppo non caucasico: tasso medio di 35.577 con un intervallo di credibilit√† al 94% tra 31.978 e 39.260.\nGruppo caucasico: tasso medio di 24.069 con un intervallo di credibilit√† al 94% tra 21.098 e 27.285.\n\nQuesti risultati indicano chiaramente che il gruppo non caucasico ha un tasso di incidenza pi√π alto di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico. L‚Äôintervallo di credibilit√† per ciascun tasso fornisce una stima robusta e credibile della variabilit√† di questi tassi.\nIn sintesi, il modello di Poisson fornisce una forte evidenza che esiste una differenza robusta tra i tassi di incidenza dei due gruppi, con il gruppo non caucasico che presenta un tasso pi√π elevato di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#esercizi",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#esercizi",
    "title": "52¬† Modello di Poisson (2)",
    "section": "52.9 Esercizi",
    "text": "52.9 Esercizi\n\nEsercizio 52.1 Nella finale olimpica di calcio 2024, la Spagna ha sconfitto la Francia con un punteggio di 5 a 3. Supponiamo di voler calcolare la probabilit√† di superiorit√† della Spagna rispetto alla Francia utilizzando un modello coniugato gamma-poisson.\nPer fare ci√≤, consideriamo che il numero di gol segnati da una squadra in una partita segua una distribuzione di Poisson, con un parametro Œª che rappresenta il tasso medio di gol per partita. Supponiamo di avere una distribuzione a priori gamma per Œª con i parametri \\(\\alpha = 1\\) e \\(\\beta = 1\\) sia per la Spagna che per la Francia. Questi parametri rappresentano la nostra incertezza iniziale sulla capacit√† delle squadre di segnare gol.\n\nCalcola la distribuzione a posteriori del tasso medio di gol (Œª) per entrambe le squadre dopo aver osservato il risultato della partita.\nUtilizzando queste distribuzioni a posteriori, calcola la probabilit√† che la Spagna sia superiore alla Francia, definita come la probabilit√† che \\(Œª_{Spagna} &gt; Œª_{Francia}\\), ovvero la probabilit√† che la Spagna abbia un tasso medio di gol superiore rispetto alla Francia (Esercizio ispirato da The World Cup Problem, Downey (2021)).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_poisson_model_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/10_stan_poisson_model_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "52¬† Modello di Poisson (2)",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\nlogging   : 0.5.1.2\narviz     : 0.18.0\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\n\n\n\n\n\n\n\nDowney, Allen B. 2021. Think Bayes. \" O‚ÄôReilly Media, Inc.\".\n\n\nRoss, Cody T, Bruce Winterhalder, e Richard McElreath. 2021. ¬´Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates¬ª. Social Psychological and Personality Science 12 (3): 323‚Äì32.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>¬† <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_gaussian_mixture.html",
    "href": "chapters/mcmc/11_stan_gaussian_mixture.html",
    "title": "53¬† Modelli Mistura Gaussiani",
    "section": "",
    "text": "Introduzione\nLa distribuzione gaussiana √® estremamente utile, non solo quando i dati seguono una distribuzione normale, ma anche in situazioni dove la distribuzione dei dati non √® gaussiana. Un esempio rilevante √® quello delle misture di distribuzioni. Una mistura di distribuzioni rappresenta una variabile casuale la cui funzione di probabilit√† (per variabili discrete) o funzione di densit√† di probabilit√† (per variabili continue) √® data da una combinazione lineare ponderata di pi√π funzioni di probabilit√† o densit√† di altre variabili casuali.\nAd esempio, la densit√† di probabilit√† di una mistura di due distribuzioni normali pu√≤ essere espressa come:\n\\[\nf(x; \\pi_1, \\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = \\pi_1 \\phi(x; \\mu_1, \\sigma_1) + \\pi_2 \\phi(x; \\mu_2, \\sigma_2)\n\\]\ndove:\n\\[\n\\pi_2 = 1 - \\pi_1\n\\]\ne \\(\\phi(x; \\mu, \\sigma)\\) rappresenta la funzione di densit√† di probabilit√† di una variabile casuale normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\).\nUn‚Äôapplicazione comune delle misture di distribuzioni √® il caso delle subpopolazioni. Quando una popolazione √® composta da pi√π sottopopolazioni, ciascuna con una propria distribuzione di valori, l‚Äôintera popolazione pu√≤ essere modellata come una mistura di distribuzioni. Ad esempio, se si assume che l‚Äôaltezza degli uomini e quella delle donne seguano entrambe una distribuzione normale, ma con medie diverse, l‚Äôaltezza degli individui senza distinzione di sesso pu√≤ essere rappresentata come una mistura di due distribuzioni normali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_gaussian_mixture.html#simulazione-dei-dati",
    "href": "chapters/mcmc/11_stan_gaussian_mixture.html#simulazione-dei-dati",
    "title": "53¬† Modelli Mistura Gaussiani",
    "section": "53.1 Simulazione dei Dati",
    "text": "53.1 Simulazione dei Dati\nI dati simulati si basano su uno studio condotto da Rowland e Wenzel (2020) che ha esaminato gli effetti di un training di mindfulness ultra-breve sulla consapevolezza e l‚Äôautocontrollo percepito. Lo studio confronta i giudizi espressi da due gruppi: un gruppo sperimentale sottoposto a training di mindfulness e un gruppo di controllo che non ha ricevuto alcun training di mindfulness. I giudizi sono stati raccolti su diverse dimensioni attraverso un protocollo di valutazione ambulatoriale, iniziato il giorno successivo alla prima sessione di laboratorio e proseguito per 40 giorni consecutivi. Qui esamineremo i dati simulati ispirati dallo studio, concentrandoci sui giudizi relativi alla dimensione ‚Äúsad‚Äù.\n\n# Parametri per le distribuzioni normali\n# Sad mindfulness\nmu_mindfulness = 20  # giudizi sad\nsigma_mindfulness = 10  # deviazione standard\n\n# Sad control\nmu_control = 60  # giudizi sad\nsigma_control = 10  # deviazione standard\n\n# Simulazione di 60 casi per ciascuna sottopopolazione\nnp.random.seed(42)  # per la riproducibilit√†\nsad_mindfulness = np.random.normal(mu_mindfulness, sigma_mindfulness, 60)\nsad_control = np.random.normal(mu_control, sigma_control, 60)\n\n# Creazione del DataFrame per visualizzare i dati\ndati_sad = pd.DataFrame(\n    {\n        \"Sad\": np.concatenate([sad_mindfulness, sad_control]),\n        \"Group\": [\"Mindfulness\"] * 60 + [\"Control\"] * 60,\n    }\n)\n\n# Mostra i parametri di ciascuna distribuzione e i primi dati simulati\nparametri_distribuzioni = pd.DataFrame(\n    {\n        \"Sottopopolazione\": [\"Mindfulness\", \"Control\"],\n        \"Media (mu)\": [mu_mindfulness, mu_control],\n        \"Deviazione Standard (sigma)\": [sigma_mindfulness, sigma_control],\n    }\n)\n\ndati_sad.head()\n\n\n\n\n\n\n\n\n\nSad\nGroup\n\n\n\n\n0\n24.967142\nMindfulness\n\n\n1\n18.617357\nMindfulness\n\n\n2\n26.476885\nMindfulness\n\n\n3\n35.230299\nMindfulness\n\n\n4\n17.658466\nMindfulness\n\n\n\n\n\n\n\n\n\ndati_sad.tail()\n\n\n\n\n\n\n\n\n\nSad\nGroup\n\n\n\n\n115\n63.015473\nControl\n\n\n116\n59.652882\nControl\n\n\n117\n48.313220\nControl\n\n\n118\n71.428228\nControl\n\n\n119\n67.519330\nControl\n\n\n\n\n\n\n\n\n\nprint(parametri_distribuzioni)\n\n  Sottopopolazione  Media (mu)  Deviazione Standard (sigma)\n0      Mindfulness          20                           10\n1          Control          60                           10\n\n\n\n# Standardizzazione dei dati\ndati_sad[\"Sad_z\"] = (\n    dati_sad[\"Sad\"] - dati_sad[\"Sad\"].mean()\n) / dati_sad[\"Sad\"].std()\n\n# Creazione dell'istogramma per i dati standardizzati\nplt.figure(figsize=(10, 6))\nplt.hist(\n    dati_sad[\"Sad_z\"], bins=20, color=\"skyblue\", edgecolor=\"black\"\n)\nplt.title(\"Istogramma dei Giudizi Sad Standardizzati\")\nplt.xlabel(\"Giudizi 'Sad' Standardizzati\")\nplt.ylabel(\"Frequenza\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIl seguente codice Stan √® stato ottenuto da Identifying Bayesian Mixture Models di Michael Betancourt.\n\nstan_file = os.path.join(project_directory, \"stan\", \"bimodal_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n}\nparameters {\n  ordered[2] mu;\n  array[2] real&lt;lower=0&gt; sigma;\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  sigma ~ normal(0, 2);\n  mu ~ normal(0, 2);\n  theta ~ beta(5, 5);\n  for (n in 1 : N) \n    target += log_mix(theta, normal_lpdf(y[n] | mu[1], sigma[1]),\n                      normal_lpdf(y[n] | mu[2], sigma[2]));\n}\n\n\n\nQuesto codice Stan implementa un modello per una mistura di distribuzioni gaussiane. Ecco una spiegazione dettagliata delle varie sezioni del codice:\n\nBlocco data\n\n\nint&lt;lower=0&gt; N;: Definisce il numero di osservazioni, \\(N\\), che deve essere un intero non negativo. Questo rappresenta il numero di dati osservati.\nvector[N] y;: Definisce un vettore \\(y\\) di lunghezza \\(N\\) che contiene i dati osservati. Ogni elemento di \\(y\\) rappresenta un valore osservato.\n\n\nBlocco parameters\n\n\nordered[2] mu;: Definisce un vettore ordinato di lunghezza 2 per i parametri \\(\\mu\\), che rappresentano le medie delle due distribuzioni gaussiane nella mistura. La propriet√† ordered garantisce che \\(\\mu[1] \\leq \\mu[2]\\), il che aiuta a evitare problemi di identificabilit√† del modello.\narray[2] real&lt;lower=0&gt; sigma;: Definisce un array di 2 elementi per i parametri \\(\\sigma\\), che rappresentano le deviazioni standard delle due distribuzioni gaussiane. Il vincolo &lt;lower=0&gt; garantisce che le deviazioni standard siano sempre positive.\nreal&lt;lower=0, upper=1&gt; theta;: Definisce il parametro \\(\\theta\\), che rappresenta la proporzione della prima distribuzione gaussiana nella mistura. Essendo vincolato tra 0 e 1, \\(\\theta\\) pu√≤ essere interpretato come la probabilit√† che un‚Äôosservazione provenga dalla prima distribuzione.\n\n\nBlocco model\n\n\nsigma ~ normal(0, 2);: Impone una distribuzione a priori normale (\\(\\mathcal{N}(0, 2)\\)) sui parametri \\(\\sigma\\). Questo riflette la convinzione a priori che le deviazioni standard siano distribuite normalmente attorno a 0 con deviazione standard 2.\nmu ~ normal(0, 2);: Impone una distribuzione a priori normale (\\(\\mathcal{N}(0, 2)\\)) sui parametri \\(\\mu\\). Questo rappresenta l‚Äôassunzione che le medie delle due gaussiane siano anch‚Äôesse distribuite normalmente attorno a 0 con deviazione standard 2.\ntheta ~ beta(5, 5);: Impone una distribuzione a priori beta (\\(\\text{Beta}(5, 5)\\)) su \\(\\theta\\), che √® una distribuzione simmetrica con valori centrati attorno a 0.5. Questo riflette l‚Äôassunzione che ciascuna delle due gaussiane abbia una probabilit√† iniziale del 50% di generare un dato, con un po‚Äô di flessibilit√†.\nfor (n in 1 : N): Questo ciclo for scorre su tutte le osservazioni \\(y[n]\\).\ntarget += log_mix(...): Questa riga √® fondamentale per calcolare la log-verosimiglianza del modello. La funzione log_mix(theta, ...) calcola la log-verosimiglianza di una mistura di due distribuzioni:\n\nnormal_lpdf(y[n] | mu[1], sigma[1]): Calcola la log-verosimiglianza del dato \\(y[n]\\) sotto la prima distribuzione normale con parametri \\(\\mu[1]\\) e \\(\\sigma[1]\\).\nnormal_lpdf(y[n] | mu[2], sigma[2]): Calcola la log-verosimiglianza del dato \\(y[n]\\) sotto la seconda distribuzione normale con parametri \\(\\mu[2]\\) e \\(\\sigma[2]\\).\nlog_mix(theta, ..., ...): Mescola queste due log-verosimiglianze pesandole con \\(\\theta\\) (per la prima gaussiana) e \\(1 - \\theta\\) (per la seconda).\n\n\nIn sintesi, questo modello Stan cerca di adattare una mistura di due distribuzioni gaussiane ai dati osservati \\(y\\). Il modello assume che ciascun dato provenga da una delle due gaussiane e cerca di stimare i parametri delle due distribuzioni (le medie \\(\\mu\\) e le deviazioni standard \\(\\sigma\\)), insieme alla proporzione \\(\\theta\\) che indica la probabilit√† che un dato provenga dalla prima distribuzione. Il codice utilizza distribuzioni a priori per informare il modello sulle aspettative dei parametri, ma √® abbastanza flessibile da adattarsi ai dati osservati.\nCreiamo il dizionario con i dati nel formato richiesto da Stan.\n\nstan_data = {\"N\": len(dati_sad[\"Sad_z\"]), \"y\": dati_sad[\"Sad_z\"]}\nprint(stan_data)\n\n{'N': 80, 'y': 0    -0.596309\n1    -0.870798\n2    -0.531045\n3    -0.152652\n4    -0.912249\n        ...   \n75    1.273390\n76    0.955725\n77    0.788841\n78    0.957763\n79    0.058908\nName: Sad_z, Length: 80, dtype: float64}\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri del modello.\n\naz.plot_trace(fit, var_names=[\"mu\", \"sigma\", \"theta\"], figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(fit)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu[0]\n-0.859\n0.096\n-1.045\n-0.688\n0.002\n0.001\n3873.0\n3587.0\n1.0\n\n\nmu[1]\n0.942\n0.085\n0.791\n1.103\n0.001\n0.001\n6252.0\n4828.0\n1.0\n\n\nsigma[0]\n0.468\n0.079\n0.334\n0.623\n0.001\n0.001\n4663.0\n4282.0\n1.0\n\n\nsigma[1]\n0.390\n0.076\n0.267\n0.532\n0.001\n0.001\n4461.0\n4506.0\n1.0\n\n\ntheta\n0.520\n0.060\n0.410\n0.633\n0.001\n0.001\n5590.0\n5627.0\n1.0\n\n\n\n\n\n\n\n\nRappresentiamo graficamente la distribuzione ottenuta dai parametri medi posteriori.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Using the provided posterior estimates\nmu_0 = -0.859\nmu_1 = 0.942\nsigma_0 = 0.468\nsigma_1 = 0.390\ntheta = 0.520  # Probability for the first component (mu_0)\n\n# Assuming dati_sad is your DataFrame, you need to provide the actual data\n# For this example, I'll generate some random data\nnp.random.seed(42)\ndata = np.concatenate(\n    [\n        np.random.normal(mu_0, sigma_0, int(1000 * theta)),\n        np.random.normal(mu_1, sigma_1, int(1000 * (1 - theta))),\n    ]\n)\n\n# Generate the histogram from the data\nfig, axes = plt.subplots(1, figsize=(10, 6))\n\n# Plot the histogram with actual counts\ncounts, bins, _ = axes.hist(data, bins=50, alpha=0.6, color=\"g\", density=False)\n\n# Calculate the KDE with a higher resolution\nx = np.linspace(data.min(), data.max(), 1000)\nkde = theta * norm.pdf(x, loc=mu_0, scale=sigma_0) + (1 - theta) * norm.pdf(\n    x, loc=mu_1, scale=sigma_1\n)\n\n# Scale the KDE to match the histogram's area\nhist_area = np.sum(counts) * np.diff(bins)[0]\nkde_scaled = kde * hist_area\n\n# Plot the KDE\naxes.plot(x, kde_scaled, linewidth=2, color=\"black\")\n\n# Additional plot settings\naxes.set_title(\"Estimated Bimodal Distribution from Posterior Parameters\")\naxes.set_xlabel(\"Sadness Score\")\naxes.set_ylabel(\"Counts\")\n\nplt.show()\n\n\n\n\n\n\n\n\nNotiamo la buona corrispondenza tra il grafico precedente e quello sopra che rappresenta i dati in input.\nPossiamo anche convertire i parametri recuperati in modo che siano espressi sulla scala dei dati grezzi.\n\n# I valori di media e deviazione standard della distribuzione originale\nmean_original = dati_sad[\"Sad\"].mean()\nstd_original = dati_sad[\"Sad\"].std()\n\n# Parametri posteriori delle distribuzioni standardizzate\nmu_0_standardized = -0.859\nmu_1_standardized = 0.942\nsigma_0_standardized = 0.468\nsigma_1_standardized = 0.390\n\n# Convertire i parametri alla scala originale\nmu_0_original = mu_0_standardized * std_original + mean_original\nmu_1_original = mu_1_standardized * std_original + mean_original\nsigma_0_original = sigma_0_standardized * std_original\nsigma_1_original = sigma_1_standardized * std_original\n\n\nprint(\n    f\"Media a posteriori della prima sottopopolazione: {mu_0_original:.2f}\\nMedia a posteriori della seconda sottopopolazione: {mu_1_original:.2f}\"\n)\nprint(\n    f\"Deviazione standard a poseriori della prima sottopopolazione: {sigma_0_original:.2f}\\nDeviazione standard a posteriori della seconda sottopopolazione: {sigma_1_original:.2f}\"\n)\n\nMedia a posteriori della prima sottopopolazione: 18.89\nMedia a posteriori della seconda sottopopolazione: 60.55\nDeviazione standard a poseriori della prima sottopopolazione: 10.83\nDeviazione standard a posteriori della seconda sottopopolazione: 9.02\n\n\nNella simulazione, i valori di \\(\\mu\\) erano \\([20, 60]\\) e i due valori di \\(\\sigma\\) erano entrambi pari a 10. Si osserva quindi una corrispondenza molto buona tra i valori utilizzati per simulare i dati e i parametri stimati per ciascun gruppo. √à importante notare che il codice Stan non includeva l‚Äôinformazione che assegnava ogni osservazione a un gruppo specifico. Questo dimostra come la tecnica della mistura di gaussiane sia in grado di classificare correttamente le osservazioni dei dati campionari nelle diverse sottopopolazioni e di stimare con precisione i parametri per ciascuna di esse.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_gaussian_mixture.html#considerazioni-conlusive",
    "href": "chapters/mcmc/11_stan_gaussian_mixture.html#considerazioni-conlusive",
    "title": "53¬† Modelli Mistura Gaussiani",
    "section": "53.2 Considerazioni Conlusive",
    "text": "53.2 Considerazioni Conlusive\nIn questo capitolo, abbiamo esplorato l‚Äôapplicazione dei modelli di mistura gaussiana nel contesto della ricerca psicologica, utilizzando come esempio uno studio sugli effetti del training di mindfulness sui giudizi di tristezza.\nImplicazioni per la ricerca psicologica:\n\nQuesti modelli possono aiutare i ricercatori a identificare sottogruppi nascosti all‚Äôinterno dei loro dati, portando a una comprensione pi√π sfumata dei fenomeni psicologici.\nL‚Äôapproccio bayesiano offre una flessibilit√† che pu√≤ essere particolarmente utile quando si lavora con campioni di dimensioni ridotte o dati complessi.\n\nIn conclusione, i modelli di mistura gaussiana rappresentano uno strumento statistico che pu√≤ arricchire l‚Äôanalisi dei dati in psicologia, permettendo ai ricercatori di scoprire strutture latenti e di modellare la complessit√† intrinseca dei fenomeni psicologici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_gaussian_mixture.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/11_stan_gaussian_mixture.html#informazioni-sullambiente-di-sviluppo",
    "title": "53¬† Modelli Mistura Gaussiani",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\nlogging   : 0.5.1.2\narviz     : 0.18.0\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\n\n\n\n\n\n\n\nRowland, Zarah, e Mario Wenzel. 2020. ¬´Mindfulness and affect-network density: Does mindfulness facilitate disengagement from affective experiences in daily life?¬ª Mindfulness 11: 1253‚Äì66.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>¬† <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_nuisance_parameters.html",
    "href": "chapters/mcmc/12_stan_nuisance_parameters.html",
    "title": "54¬† Modelli con pi√π di un parametro",
    "section": "",
    "text": "54.1 Introduzione\nIn statistica, √® comune dover affrontare problemi che coinvolgono pi√π parametri sconosciuti o non osservabili. Tuttavia, anche in presenza di numerosi parametri, l‚Äôinteresse principale √® spesso limitato a uno o pochi di essi. L‚Äôobiettivo principale di un‚Äôanalisi bayesiana √® quindi ottenere la distribuzione marginale a posteriori dei parametri di interesse specifico.\nEsistono due approcci principali per ottenere questa distribuzione marginale a posteriori. Il primo approccio consiste nel calcolare esplicitamente la distribuzione congiunta a posteriori di tutti i parametri e successivamente integrare analiticamente (o numericamente) rispetto ai parametri di disturbo per ottenere la distribuzione marginale dei parametri di interesse. Questo metodo, sebbene teoricamente corretto, pu√≤ risultare complesso o addirittura impraticabile nei modelli pi√π sofisticati, a causa della difficolt√† dell‚Äôintegrazione.\nIl secondo approccio, pi√π pratico e comunemente utilizzato, si basa sulla simulazione della distribuzione congiunta a posteriori tramite tecniche come il campionamento MCMC (Markov Chain Monte Carlo). In questo caso, si generano campioni da tutta la distribuzione congiunta e, nella fase di analisi, si ignorano i campioni relativi ai parametri di disturbo, concentrandosi solo su quelli di interesse. Questo metodo √® particolarmente vantaggioso per modelli complessi, dove l‚Äôintegrazione analitica sarebbe proibitiva.\nSpesso, in molti problemi statistici, non c‚Äô√® un interesse diretto a fare inferenze su numerosi parametri sconosciuti, anche se sono essenziali per la costruzione di un modello realistico. Questi parametri sono comunemente noti come ‚Äúparametri di disturbo‚Äù o ‚Äúnuisance parameters‚Äù.\nIn questo tutorial, esamineremo un modello che include sia parametri di interesse, come le medie dei punteggi dei test tra due gruppi (\\(\\mu_1\\) e \\(\\mu_2\\)), sia parametri di disturbo, come le abilit√† cognitive di base dei partecipanti (\\(\\theta\\)). Attraverso il processo di marginalizzazione, ci concentreremo sui parametri di interesse ignorando i campioni relativi ai parametri di disturbo, mantenendo comunque la complessit√† del modello necessaria per descrivere accuratamente i dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modelli con pi√π di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_nuisance_parameters.html#stima-delleffetto-di-un-intervento-cognitivo-sui-punteggi-dei-test",
    "href": "chapters/mcmc/12_stan_nuisance_parameters.html#stima-delleffetto-di-un-intervento-cognitivo-sui-punteggi-dei-test",
    "title": "54¬† Modelli con pi√π di un parametro",
    "section": "54.2 Stima dell‚Äôeffetto di un intervento cognitivo sui punteggi dei test",
    "text": "54.2 Stima dell‚Äôeffetto di un intervento cognitivo sui punteggi dei test\nSupponiamo di voler valutare l‚Äôeffetto di un intervento cognitivo, come un programma di formazione progettato per migliorare la memoria di lavoro, sui punteggi di un test che misura la performance dei partecipanti. I partecipanti sono suddivisi in due gruppi: uno che riceve l‚Äôintervento e un gruppo di controllo che non lo riceve.\nL‚Äôobiettivo principale √® stimare la differenza nei punteggi medi dei test tra i due gruppi dopo l‚Äôintervento. Tuttavia, siamo consapevoli che i punteggi dei test possono essere influenzati da una serie di fattori, come le differenze individuali nelle capacit√† cognitive di base, i livelli di motivazione e gli errori di misurazione.\nIn questo contesto, il parametro di interesse √® la differenza nei punteggi medi dei test tra il gruppo che ha ricevuto l‚Äôintervento e il gruppo di controllo, tenendo conto delle capacit√† cognitive di base. Tuttavia, queste capacit√† cognitive di base e gli errori di misurazione sono considerati parametri di disturbo‚Äîelementi indispensabili per costruire un modello accurato, ma che non rappresentano il focus principale dell‚Äôanalisi.\n\n54.2.1 Specificazione del modello:\nPer stimare la distribuzione marginale a posteriori del parametro di interesse‚Äîla differenza nei punteggi medi dei test tra il gruppo che ha ricevuto l‚Äôintervento e il gruppo di controllo‚Äîdefiniamo il modello nel seguente modo:\n\n\\(y_{ij}\\): Il punteggio del test per il partecipante \\(j\\) nel gruppo \\(i\\) (dove \\(i = 1\\) per il gruppo di intervento e \\(i = 2\\) per il gruppo di controllo).\n\\(\\mu_i\\): La media dei punteggi del test per il gruppo \\(i\\).\n\\(\\delta\\): La differenza tra le medie (\\(\\mu_1 - \\mu_2\\))‚Äîquesto √® il parametro di interesse principale.\n\\(\\sigma_y\\): La deviazione standard dei punteggi dei test, considerata un parametro di disturbo comune a entrambi i gruppi.\n\\(\\theta_j\\): La capacit√† cognitiva di base del partecipante \\(j\\), modellata come un effetto casuale e trattata anch‚Äôessa come un parametro di disturbo.\n\\(\\sigma_\\theta\\): La deviazione standard delle capacit√† cognitive di base, anch‚Äôessa considerata un parametro di disturbo.\n\nAssumiamo che i punteggi dei test \\(y_{ij}\\) siano distribuiti normalmente con media \\(\\mu_i + \\theta_j\\) e varianza \\(\\sigma_y^2\\).\nIl codice Stan che implementa questo modello √® il seguente:\n\nstan_file = os.path.join(project_directory, \"stan\", \"nuisance_params_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N1; // Number of participants in group 1 (intervention)\n  int&lt;lower=0&gt; N2; // Number of participants in group 2 (control)\n  array[N1] real y1; // Test scores for group 1\n  array[N2] real y2; // Test scores for group 2\n}\nparameters {\n  real mu1; // Mean test score for group 1\n  real mu2; // Mean test score for group 2\n  real&lt;lower=0&gt; sigma_y; // Standard deviation of test scores\n  real&lt;lower=0&gt; sigma_theta; // Standard deviation of baseline cognitive ability\n  array[N1 + N2] real theta; // Baseline cognitive abilities for all participants\n}\nmodel {\n  // Priors\n  mu1 ~ normal(0, 10);\n  mu2 ~ normal(0, 10);\n  sigma_y ~ normal(0, 5);\n  sigma_theta ~ normal(0, 5);\n  \n  for (j in 1 : (N1 + N2)) {\n    theta[j] ~ normal(0, sigma_theta); // Random effects for baseline abilities\n  }\n  \n  // Likelihood\n  for (j in 1 : N1) {\n    y1[j] ~ normal(mu1 + theta[j], sigma_y);\n  }\n  \n  for (j in 1 : N2) {\n    y2[j] ~ normal(mu2 + theta[N1 + j], sigma_y);\n  }\n}\ngenerated quantities {\n  real delta = mu1 - mu2; // Difference in means\n}\n\n\n\nEsaminiamo ora il codice Stan in dettaglio. I partecipanti sono suddivisi in due gruppi:\n\nGruppo 1 (Intervento): Partecipanti che hanno ricevuto l‚Äôintervento cognitivo.\nGruppo 2 (Controllo): Partecipanti che non hanno ricevuto l‚Äôintervento.\n\nOgni partecipante ha un punteggio al test, influenzato sia dall‚Äôappartenenza al gruppo (che riflette l‚Äôeffetto del trattamento) sia dalle capacit√† cognitive di base individuali, che variano da persona a persona.\nIl punteggio di ciascun partecipante pu√≤ essere visto come la somma di due componenti principali:\n\nComponente di gruppo: Questa componente rappresenta l‚Äôeffetto generale dell‚Äôappartenenza al gruppo, ossia se il partecipante ha ricevuto l‚Äôintervento (Gruppo 1) o meno (Gruppo 2). Questo effetto √® costante per tutti i partecipanti dello stesso gruppo.\n\nNel Gruppo 1 (Intervento), questa componente √® rappresentata da \\(\\mu_1\\).\nNel Gruppo 2 (Controllo), questa componente √® rappresentata da \\(\\mu_2\\).\nLa differenza tra \\(\\mu_1\\) e \\(\\mu_2\\) (\\(\\delta = \\mu_1 - \\mu_2\\)) √® il parametro di interesse, poich√© rappresenta l‚Äôeffetto medio dell‚Äôintervento.\n\nComponente individuale: Questa componente cattura le differenze individuali nei punteggi dei test, attribuibili a vari fattori, come le capacit√† cognitive di base di ciascun partecipante. Questa componente varia tra i partecipanti ed √® modellata come un ‚Äúeffetto casuale‚Äù.\n\nQuesto effetto √® rappresentato da \\(\\theta_j\\), dove \\(j\\) indica il partecipante. Ogni \\(\\theta_j\\) descrive la deviazione del punteggio di un partecipante rispetto al valore previsto solo dall‚Äôeffetto di gruppo.\n\n\nParametri di Disturbo. Il modello include diversi parametri di disturbo che, pur non essendo di interesse primario, sono essenziali per una descrizione accurata dei dati:\n\n\\(\\theta_j\\): Rappresenta le abilit√† cognitive di base dei partecipanti, distribuite normalmente attorno a 0 con deviazione standard \\(\\sigma_\\theta\\). Questi parametri sono considerati di disturbo poich√© non sono il focus dell‚Äôanalisi, ma sono necessari per modellare correttamente i punteggi.\n\\(\\sigma_y\\): Rappresenta la variabilit√† residua nei punteggi dei test che non pu√≤ essere spiegata n√© dall‚Äôappartenenza al gruppo n√© dalle capacit√† cognitive individuali. Anche questo √® un parametro di disturbo.\n\nIl modello descrive i punteggi come una combinazione dell‚Äôeffetto di gruppo (\\(\\mu_i\\)) e delle differenze individuali (\\(\\theta_j\\)). Tuttavia, l‚Äôobiettivo principale √® stimare \\(\\delta = \\mu_1 - \\mu_2\\), ovvero la differenza tra gli effetti medi dei due gruppi.\nMarginalizzazione. Per concentrarci su \\(\\delta\\), dobbiamo ‚Äúmarginalizzare‚Äù i parametri di disturbo \\(\\theta_j\\) e \\(\\sigma_y\\). In un contesto bayesiano, questo si ottiene integrando rispetto a questi parametri, cio√® calcolando la distribuzione a posteriori di \\(\\delta\\) indipendentemente dai valori specifici dei parametri di disturbo. Questo processo avviene simulando l‚Äôintera distribuzione a posteriori (di tutti i parametri) e poi estraendo solo l‚Äôinformazione rilevante su \\(\\delta\\).\nIn sintesi, i punteggi dei partecipanti del gruppo di intervento (\\(y_1\\)) e del gruppo di controllo (\\(y_2\\)) vengono scomposti in una componente di gruppo e una componente individuale. L‚Äôinteresse principale risiede nella differenza tra le componenti di gruppo dei due gruppi (\\(\\delta\\)), mentre le differenze individuali (\\(\\theta_j\\)) sono considerate ma non sono l‚Äôoggetto principale dell‚Äôanalisi.\nQuesto modello ci permette di stimare l‚Äôeffetto dell‚Äôintervento cognitivo sui punteggi dei test, tenendo conto delle differenze individuali nelle capacit√† cognitive di base, e dimostra come i parametri di disturbo possano essere gestiti in modo efficace all‚Äôinterno di un quadro bayesiano.\n\n\n54.2.2 Dati\nSimuliamo un campione di dati.\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Parameters for the simulation\nN1 = 50  # Number of participants in group 1 (intervention)\nN2 = 50  # Number of participants in group 2 (control)\n\nmu1_true = 10  # True mean test score for group 1\nmu2_true = 8  # True mean test score for group 2\nsigma_y_true = 2  # True standard deviation of test scores\nsigma_theta_true = 1  # True standard deviation of baseline cognitive abilities\n\n# Simulate baseline cognitive abilities for all participants\ntheta = np.random.normal(0, sigma_theta_true, N1 + N2)\n\n# Simulate test scores for group 1 (intervention)\ny1 = np.random.normal(mu1_true + theta[:N1], sigma_y_true)\n\n# Simulate test scores for group 2 (control)\ny2 = np.random.normal(mu2_true + theta[N1:], sigma_y_true)\n\n# Create the dictionary for Stan input\nstan_data = {\n    \"N1\": N1, \n    \"N2\": N2, \n    \"y1\": y1.tolist(), \n    \"y2\": y2.tolist()\n}\n\n# Output the generated data for verification\nprint(stan_data)\n\n{'N1': 50, 'N2': 50, 'y1': [7.665972668910404, 9.020445053298097, 9.962259505047152, 9.918475317964788, 9.443275201944646, 10.573964756679896, 15.351584617928452, 11.116590354816587, 10.045626395510576, 10.393668212053631, 5.699039876589454, 9.48124249553131, 10.362422691448087, 13.013203980312774, 7.890360237924723, 10.040807155426252, 8.91774534025509, 7.976891257356209, 11.37762155350883, 10.091562364038257, 13.047712663007648, 7.955448789923987, 12.873116826560123, 5.771549688201982, 10.629331463075358, 14.491833841329822, 6.86793377231632, 9.243102559140128, 9.598664040256478, 8.701354941974325, 6.2969665256383385, 11.989404134120992, 7.861895347809856, 9.889473932314464, 8.983696443635582, 11.879025160064057, 8.642357010332281, 7.396206843708874, 10.298848385840909, 7.7351326030012135, 11.19338644920367, 12.785653789754827, 6.669385248489304, 10.06816402147532, 9.04124359812942, 10.843801535159912, 7.065459807284048, 8.416209000050362, 11.387501420802256, 8.830929191103637], 'y2': [8.825069670086549, 8.307814138577635, 5.9630285565370595, 9.076183683162876, 9.617144469093313, 7.502577283063463, 10.892331499066875, 8.638453465972361, 5.948656436998267, 10.28865234439002, 5.571462421700067, 9.388510230821087, 9.21085618400878, 5.162428739215908, 10.739278080882842, 10.18180188244382, 9.572110198408646, 12.797118863199918, 7.870859793041893, 5.847407916679897, 6.5823667462573665, 7.906415996535093, 7.80997054206184, 10.246947605447293, 5.933636494570293, 10.476269002447271, 8.113050851993984, 10.608060803848765, 7.56244711005959, 11.452769418578345, 9.0316628076925, 6.642797458679182, 7.336109048619292, 8.446674612212723, 6.7445808264551115, 8.926243944599648, 9.861877366849164, 8.183093284345938, 5.7766523600961515, 5.4835729837416265, 7.204047645213997, 10.681442579179834, 7.726134394383055, 5.180860295978256, 7.954253698570206, 7.307119811325555, 6.52840540466231, 8.568505484070945, 8.12153089353446, 5.479472270963607]}\n\n\n\n\n54.2.3 Campionamento e Sintesi della Distribuzione a Posteriori\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo visivamente la distribuzione a posteriori.\n\naz.plot_trace(fit, var_names=[\"delta\"])\nplt.show()\n\n\n\n\n\n\n\n\nOtteniamo un sommario numerico della distribuzione a posteriori del parametro di interesse.\n\naz.summary(fit, var_names=[\"delta\"])\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ndelta\n1.502\n0.406\n0.689\n2.231\n0.01\n0.007\n1666.0\n1863.0\n1.0\n\n\n\n\n\n\n\n\nSi osserva che la stima di \\(\\delta\\) √® coerente con il valore teorico utilizzato per la simulazione dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modelli con pi√π di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_nuisance_parameters.html#considerazioni-conclusive",
    "href": "chapters/mcmc/12_stan_nuisance_parameters.html#considerazioni-conclusive",
    "title": "54¬† Modelli con pi√π di un parametro",
    "section": "54.3 Considerazioni Conclusive",
    "text": "54.3 Considerazioni Conclusive\nL‚Äôapproccio bayesiano discusso in questo capitolo √® strettamente correlato ai modelli gerarchici con intercette casuali, ma esistono importanti differenze che possono influenzare la scelta tra i due metodi.\nEntrambi gli approcci mirano a stimare la differenza tra i punteggi medi dei test nei due gruppi (\\(\\delta = \\mu_1 - \\mu_2\\)). Sia la marginalizzazione dei parametri di disturbo sia l‚Äôadozione di un modello gerarchico conducono a una distribuzione a posteriori per \\(\\delta\\), tenendo conto delle variazioni individuali nei punteggi (\\(\\theta_j\\)). Queste variazioni individuali, che non possono essere attribuite direttamente all‚Äôeffetto di gruppo, vengono considerate in entrambi i metodi per garantire una stima accurata di \\(\\delta\\).\nTuttavia, ci sono differenze chiave tra i due approcci. La marginalizzazione si concentra sulla riduzione della complessit√† del modello, permettendo di isolare i parametri di interesse dopo aver considerato quelli di disturbo. Al contrario, il modello gerarchico prevede sin dall‚Äôinizio una struttura che include relazioni gerarchiche tra i parametri. In questo caso, la marginalizzazione avviene naturalmente durante il processo di inferenza, rendendo l‚Äôapproccio gerarchico pi√π integrato e coerente nella modellazione di dati complessi.\nIn termini di flessibilit√† e interpretazione, il modello gerarchico offre vantaggi significativi. La sua struttura consente di aggiungere facilmente ulteriori livelli di variazione o effetti casuali, rendendolo particolarmente adatto a contesti complessi con molteplici livelli gerarchici o dipendenze strutturate. D‚Äôaltra parte, la marginalizzazione √® un metodo diretto per concentrarsi sui parametri di interesse, ma potrebbe risultare meno flessibile quando si tratta di estendere il modello per includere nuove variabili o fonti di variazione.\nInfine, i modelli gerarchici bayesiani sono noti per la loro robustezza in contesti con pi√π fonti di variazione e sono spesso preferiti in situazioni complesse. La loro capacit√† di modellare relazioni gerarchiche e dipendenze nei dati li rende strumenti particolarmente potenti per l‚Äôinferenza. Sebbene la marginalizzazione sia un approccio efficace, pu√≤ risultare limitata rispetto ai modelli gerarchici quando si affrontano problemi con strutture dati pi√π complesse.\nIn conclusione, sebbene entrambi gli approcci producano stime simili per parametri come \\(\\delta\\), il modello gerarchico bayesiano offre un quadro pi√π generale e flessibile per gestire la complessit√† dei dati, soprattutto in presenza di pi√π livelli di variazione o dipendenze strutturate. Pertanto, i modelli gerarchici sono generalmente preferibili in contesti pi√π complessi o quando √® necessaria una maggiore flessibilit√† nella modellazione, in linea con le indicazioni della letteratura scientifica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modelli con pi√π di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_nuisance_parameters.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/12_stan_nuisance_parameters.html#informazioni-sullambiente-di-sviluppo",
    "title": "54¬† Modelli con pi√π di un parametro",
    "section": "54.4 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "54.4 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npymc      : 5.15.0\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>¬† <span class='chapter-title'>Modelli con pi√π di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_hier_beta_binom.html",
    "href": "chapters/mcmc/13_stan_hier_beta_binom.html",
    "title": "55¬† Modello gerarchico beta-binomiale con Stan",
    "section": "",
    "text": "Introduzione\nNel Capitolo 54, abbiamo analizzato un modello gerarchico che prevede la marginalizzazione dei parametri di disturbo. In questa sezione, introdurremo una nuova variante del modello gerarchico, applicata a un contesto in cui osserviamo un numero di successi per ciascun partecipante su un numero fisso di prove, trattando la probabilit√† di successo di ciascun partecipante come una variabile.\nIl modello che presentiamo qui condivide con quello precedente l‚Äôapproccio gerarchico per gestire la variabilit√† individuale, ma differisce per il tipo di parametri di interesse e il modo in cui affronta la variabilit√†. Mentre il modello precedente si concentrava sulla stima di una differenza media di gruppo, con una marginalizzazione esplicita dei parametri individuali, il modello attuale √® pi√π orientato a stimare le probabilit√† di successo individuali.\nEntrambi i modelli offrono un potente quadro per l‚Äôinferenza bayesiana, ma sono progettati per essere applicati in contesti diversi e con obiettivi distinti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "href": "chapters/mcmc/13_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "title": "55¬† Modello gerarchico beta-binomiale con Stan",
    "section": "55.1 Analisi bayesiana della ‚Äúterapia tattile‚Äù",
    "text": "55.1 Analisi bayesiana della ‚Äúterapia tattile‚Äù\nEsaminiamo un problema presentato nel lavoro di Kruschke (2014) riguardante la ‚Äúterapia tattile‚Äù (Therapeutic Touch), una pratica infermieristica incentrata sulla manipolazione del presunto ‚Äúcampo energetico‚Äù di un paziente. Nonostante la sua prevalenza nelle scuole di infermieristica e negli ospedali negli Stati Uniti, come riportato da Rosa et al. (1998), evidenze empiriche a supporto della sua efficacia sono scarse o assenti.\nIl focus dell‚Äôindagine di Rosa et al. (1998) √® una delle asserzioni cardine degli operatori di terapia tattile: la presunta capacit√† di percepire i campi energetici senza contatto visivo. Per testare questa affermazione, √® stato progettato un esperimento in cui gli operatori ponevano le loro mani attraverso un pannello che bloccava la visione. In ciascuna prova, un esaminatore, seguendo l‚Äôesito di un lancio di moneta, posizionava la sua mano sopra una delle mani dell‚Äôoperatore. L‚Äôoperatore doveva quindi identificare quale delle sue mani era stata ‚Äúselezionata‚Äù dall‚Äôesaminatore. Ogni tentativo √® stato classificato come ‚Äúcorretto‚Äù o ‚Äúerrato‚Äù.\nL‚Äôunit√† di osservazione in questo esperimento √® costituita da un set di 10 prove per operatore. In totale, lo studio ha coinvolto 21 operatori, con sette di loro sottoposti a retest dopo circa un anno. I dati di retest sono stati trattati come entit√† indipendenti, portando a un campione effettivo di 28 osservazioni. La metrica di interesse √® la proporzione di risposte corrette per ciascun operatore, con una proporzione attesa di 0.50 sotto l‚Äôipotesi nulla di performance casuale.\nLa domanda della ricerca centrale √® se il campione nel suo complesso √® in grado di ottenere una prestazione superiore a quella attesa in base al caso soltanto e, inoltre, se vi sono variazioni nelle prestazioni individuali.\nInizieremo importando i dati forniti da Kruschke (2014).\n\n# Define the URL of the CSV file on GitHub\nurl = \"https://raw.githubusercontent.com/boboppie/kruschke-doing_bayesian_data_analysis/master/2e/TherapeuticTouchData.csv\"\n# Download the content of the CSV file\nresponse = requests.get(url)\ntt_dat = pd.read_csv(StringIO(response.text))\nprint(tt_dat.head())\n\n   y    s\n0  1  S01\n1  0  S01\n2  0  S01\n3  0  S01\n4  0  S01\n\n\n\ntt_dat.shape\n\n(280, 2)\n\n\nNella colonna y, il valore 1 indica una risposta corretta, mentre 0 indica una risposta errata. La seconda colonna contiene il codice identificativo di ciascun operatore.\nCalcoliamo la proporzione di risposte corrette per ciascun operatore.\n\ntt_agg = tt_dat.groupby(\"s\").agg(proportion_correct=(\"y\", \"mean\")).reset_index()\ntt_agg\n\n\n\n\n\n\n\n\n\ns\nproportion_correct\n\n\n\n\n0\nS01\n0.1\n\n\n1\nS02\n0.2\n\n\n2\nS03\n0.3\n\n\n3\nS04\n0.3\n\n\n4\nS05\n0.3\n\n\n5\nS06\n0.3\n\n\n6\nS07\n0.3\n\n\n7\nS08\n0.3\n\n\n8\nS09\n0.3\n\n\n9\nS10\n0.3\n\n\n10\nS11\n0.4\n\n\n11\nS12\n0.4\n\n\n12\nS13\n0.4\n\n\n13\nS14\n0.4\n\n\n14\nS15\n0.4\n\n\n15\nS16\n0.5\n\n\n16\nS17\n0.5\n\n\n17\nS18\n0.5\n\n\n18\nS19\n0.5\n\n\n19\nS20\n0.5\n\n\n20\nS21\n0.5\n\n\n21\nS22\n0.5\n\n\n22\nS23\n0.6\n\n\n23\nS24\n0.6\n\n\n24\nS25\n0.7\n\n\n25\nS26\n0.7\n\n\n26\nS27\n0.7\n\n\n27\nS28\n0.8\n\n\n\n\n\n\n\n\nCostruiamo un modello gerarchico partendo dall‚Äôipotesi che il numero di risposte corrette di ciascun operatore sia modellato da una variabile casuale binomiale. Per ciascuno dei ventotto operatori, possiamo esprimere questo come segue:\n\\[\ny_i \\sim \\text{Binomial}(n_i, p_i),\n\\]\ndove \\(i = 0, \\dots, 27\\).\nPer modellare la distribuzione a priori del parametro sconosciuto \\(p_i\\), possiamo utilizzare una distribuzione Beta con parametri \\(a\\) e \\(b\\) ‚Äì si veda {cite:t}doingbayesian:\n\\[\np_i \\sim \\text{Beta}(a, b).\n\\]\n√à importante notare che gli iperparametri \\(a\\) e \\(b\\) sono condivisi tra tutti gli operatori, caratteristica che definisce un modello gerarchico.\nSe \\(a\\) e \\(b\\) sono noti, la distribuzione a posteriori del parametro \\(p\\) per ciascun operatore, dati i risultati osservati \\(y_i\\), √® anch‚Äôessa una distribuzione Beta:\n\\[\np_i \\mid y_i \\sim \\text{Beta}(a + y_i, b + n_i - y_i).\n\\]\nNel caso pi√π generale, dove gli iperparametri \\(a\\) e \\(b\\) sono incogniti, √® necessario stabilire una distribuzione a priori anche per questi. Nell‚Äôesempio seguente, useremo i seguenti prior:\n\\[\na \\sim \\text{Gamma}(8, 12)\\\\\nb \\sim \\text{Gamma}(27, 5)\n\\]\nPer applicare il modello gerarchico descritto sopra ai dati del therapeutic touch, iniziamo a calcolare il numero di risposte corrette di ciascun operatore.\n\nresult = tt_dat.groupby(\"s\")[\"y\"].sum().reset_index()\ny = result[\"y\"]\nprint(y)\n\n0     1\n1     2\n2     3\n3     3\n4     3\n5     3\n6     3\n7     3\n8     3\n9     3\n10    4\n11    4\n12    4\n13    4\n14    4\n15    5\n16    5\n17    5\n18    5\n19    5\n20    5\n21    5\n22    6\n23    6\n24    7\n25    7\n26    7\n27    8\nName: y, dtype: int64\n\n\nCreiamo il vettore N che fornisce il numero di prove per ciascun operatore.\n\nN = tt_dat.groupby(\"s\")[\"y\"].count()\n\nEsaminiamo dunque i dati a disposizione.\n\nprint(*N)\n\n10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n\n\n\nprint(y)\n\n0     1\n1     2\n2     3\n3     3\n4     3\n5     3\n6     3\n7     3\n8     3\n9     3\n10    4\n11    4\n12    4\n13    4\n14    4\n15    5\n16    5\n17    5\n18    5\n19    5\n20    5\n21    5\n22    6\n23    6\n24    7\n25    7\n26    7\n27    8\nName: y, dtype: int64\n\n\nCreaiamo un dizionario con i dati necessari per Stan.\n\ndata = {\n    \"N\": 28,\n    \"y\": y.tolist(),\n    \"n_trials\": N.tolist()\n}\n\nprint(data)\n\n{'N': 28, 'y': [1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 7, 8], 'n_trials': [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_hier_beta_binom.html#modello-stan",
    "href": "chapters/mcmc/13_stan_hier_beta_binom.html#modello-stan",
    "title": "55¬† Modello gerarchico beta-binomiale con Stan",
    "section": "55.2 Modello Stan",
    "text": "55.2 Modello Stan\nLeggiamo il codice Stan che implementa il modello gerarchico.\n\nstan_file = os.path.join(project_directory, \"stan\", \"h_beta_binom_model.stan\")\n\nwith open(stan_file, \"r\") as f:\n    print(f.read())\n\ndata {\n  int&lt;lower=0&gt; N;  // Number of participants\n  array[N] int&lt;lower=0&gt; y;  // Number of successes for each participant\n  array[N] int&lt;lower=0&gt; n_trials;  // Number of trials for each participant\n}\n\nparameters {\n  real&lt;lower=0&gt; alpha;  // Alpha parameter for the Beta distribution\n  real&lt;lower=0&gt; beta;   // Beta parameter for the Beta distribution\n  array[N] real&lt;lower=0, upper=1&gt; p;  // Success probability for each participant\n}\n\nmodel {\n  // Priors\n  alpha ~ gamma(8, 2);\n  beta ~ gamma(27, 5);\n  \n  // Each participant's success probability follows a Beta distribution\n  p ~ beta(alpha, beta);\n  \n  // Likelihood of the observed data\n  for (i in 1:N) {\n    y[i] ~ binomial(n_trials[i], p[i]);\n  }\n}\n\ngenerated quantities {\n  real overall_p = alpha / (alpha + beta);  // Calculate the mean success probability\n}\n\n\n\nNel modello:\n\nN √® il numero totale di partecipanti\ny √® un array che contiene il numero di successi per ogni partecipante\nn_trials √® un array che contiene il numero di prove per ogni partecipante\n\nIl modello √® chiamato ‚Äúgerarchico‚Äù perch√© considera due livelli:\n\nIl livello individuale: ogni partecipante ha la propria probabilit√† di successo\nIl livello di gruppo: c‚Äô√® una distribuzione generale che descrive come variano le probabilit√† di successo tra i partecipanti\n\n\np: √à un array che contiene la vera probabilit√† di successo per ogni partecipante.\nalpha e beta: Sono i parametri che definiscono la distribuzione Beta, che descrive come variano le probabilit√† di successo tra i partecipanti.\n\nImpostiamo delle prior per alpha e beta:\nalpha ~ gamma(8, 2);\nbeta ~ gamma(27, 5);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri.\np ~ beta(alpha, beta);\nQuesta riga √® il cuore del modello gerarchico. Dice che la probabilit√† di successo di ogni partecipante (p) segue una distribuzione Beta, i cui parametri sono alpha e beta. Questo crea un legame tra tutti i partecipanti: le loro prestazioni individuali sono considerate come variazioni attorno a una tendenza generale del gruppo.\nfor (i in 1:N) {\n  y[i] ~ binomial(n_trials[i], p[i]);\n}\nQuesta parte del modello descrive come i dati osservati (y) sono generati, dato il numero di prove (n_trials) e la vera probabilit√† di successo (p) per ogni partecipante.\nreal overall_p = alpha / (alpha + beta);\nQuesta riga calcola la probabilit√† di successo media per l‚Äôintero gruppo.\nIn conclusione, questo modello ci permette di stimare la probabilit√† di successo individuale per ogni partecipante, comprendere come queste probabilit√† variano nel gruppo e ottenere una stima della probabilit√† di successo media per l‚Äôintero gruppo. Il vantaggio principale di questo approccio gerarchico √® che combina informazioni a livello individuale e di gruppo, permettendo stime pi√π precise, specialmente per i partecipanti con pochi dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_hier_beta_binom.html#compilazione-e-sampling",
    "href": "chapters/mcmc/13_stan_hier_beta_binom.html#compilazione-e-sampling",
    "title": "55¬† Modello gerarchico beta-binomiale con Stan",
    "section": "55.3 Compilazione e sampling",
    "text": "55.3 Compilazione e sampling\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(\n    data=data,\n    iter_warmup=2000, \n    iter_sampling=4000,\n    seed=84735, \n    chains=4,\n    show_progress=False, \n    show_console=False\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_hier_beta_binom.html#esame-delle-distribuzioni-a-posteriori",
    "href": "chapters/mcmc/13_stan_hier_beta_binom.html#esame-delle-distribuzioni-a-posteriori",
    "title": "55¬† Modello gerarchico beta-binomiale con Stan",
    "section": "55.4 Esame delle distribuzioni a posteriori",
    "text": "55.4 Esame delle distribuzioni a posteriori\nEsaminiamo le stime a posteriori dei parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"p\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n4.591\n0.866\n2.991\n6.359\n0.008\n0.006\n10600.0\n10141.0\n1.0\n\n\nbeta\n5.756\n0.932\n4.009\n7.623\n0.008\n0.006\n12032.0\n11787.0\n1.0\n\n\np[0]\n0.273\n0.100\n0.091\n0.469\n0.001\n0.000\n20279.0\n11628.0\n1.0\n\n\np[1]\n0.324\n0.103\n0.129\n0.524\n0.001\n0.001\n20614.0\n11911.0\n1.0\n\n\np[2]\n0.373\n0.107\n0.174\n0.588\n0.001\n0.001\n20791.0\n11355.0\n1.0\n\n\np[3]\n0.372\n0.106\n0.179\n0.590\n0.001\n0.001\n22416.0\n11620.0\n1.0\n\n\np[4]\n0.373\n0.107\n0.173\n0.582\n0.001\n0.001\n22260.0\n11753.0\n1.0\n\n\np[5]\n0.374\n0.106\n0.173\n0.583\n0.001\n0.001\n21443.0\n12716.0\n1.0\n\n\np[6]\n0.372\n0.106\n0.172\n0.580\n0.001\n0.001\n21992.0\n12317.0\n1.0\n\n\np[7]\n0.372\n0.106\n0.173\n0.582\n0.001\n0.001\n21133.0\n11017.0\n1.0\n\n\np[8]\n0.372\n0.105\n0.176\n0.583\n0.001\n0.001\n21459.0\n11369.0\n1.0\n\n\np[9]\n0.372\n0.108\n0.167\n0.580\n0.001\n0.001\n22007.0\n11102.0\n1.0\n\n\np[10]\n0.422\n0.108\n0.209\n0.627\n0.001\n0.001\n21331.0\n12556.0\n1.0\n\n\np[11]\n0.421\n0.109\n0.217\n0.634\n0.001\n0.001\n22045.0\n11591.0\n1.0\n\n\np[12]\n0.422\n0.108\n0.213\n0.632\n0.001\n0.001\n22874.0\n12190.0\n1.0\n\n\np[13]\n0.421\n0.110\n0.214\n0.637\n0.001\n0.001\n22807.0\n12055.0\n1.0\n\n\np[14]\n0.421\n0.109\n0.213\n0.634\n0.001\n0.001\n21851.0\n12199.0\n1.0\n\n\np[15]\n0.471\n0.112\n0.257\n0.689\n0.001\n0.001\n22072.0\n10892.0\n1.0\n\n\np[16]\n0.471\n0.111\n0.249\n0.680\n0.001\n0.001\n22559.0\n11739.0\n1.0\n\n\np[17]\n0.470\n0.111\n0.258\n0.683\n0.001\n0.001\n23384.0\n11679.0\n1.0\n\n\np[18]\n0.471\n0.111\n0.259\n0.688\n0.001\n0.001\n22495.0\n11479.0\n1.0\n\n\np[19]\n0.471\n0.111\n0.264\n0.691\n0.001\n0.001\n22949.0\n11720.0\n1.0\n\n\np[20]\n0.472\n0.110\n0.251\n0.680\n0.001\n0.001\n22288.0\n11847.0\n1.0\n\n\np[21]\n0.472\n0.109\n0.264\n0.685\n0.001\n0.001\n24414.0\n12216.0\n1.0\n\n\np[22]\n0.519\n0.109\n0.306\n0.728\n0.001\n0.001\n22363.0\n11502.0\n1.0\n\n\np[23]\n0.521\n0.111\n0.305\n0.732\n0.001\n0.001\n20720.0\n11618.0\n1.0\n\n\np[24]\n0.570\n0.109\n0.357\n0.780\n0.001\n0.001\n22438.0\n11048.0\n1.0\n\n\np[25]\n0.570\n0.109\n0.349\n0.772\n0.001\n0.001\n20850.0\n12520.0\n1.0\n\n\np[26]\n0.569\n0.110\n0.358\n0.786\n0.001\n0.001\n21973.0\n11715.0\n1.0\n\n\np[27]\n0.620\n0.107\n0.409\n0.821\n0.001\n0.001\n22119.0\n11629.0\n1.0\n\n\n\n\n\n\n\n\nLe distribuzioni posteriori degli iperparametri, prese da sole, non hanno un significato chiaro. Tuttavia, possiamo utilizzarle per calcolare la distribuzione a posteriori della probabilit√† di una risposta corretta per tutto il gruppo.\nConvertiamo l‚Äôoggetto fit creato da cmdstanpy in un oggetto InferenceData usando ArviZ:\n\nidata = az.from_cmdstanpy(posterior=fit)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_hier_beta_binom.html#schrinkage-bayesiano",
    "href": "chapters/mcmc/13_stan_hier_beta_binom.html#schrinkage-bayesiano",
    "title": "55¬† Modello gerarchico beta-binomiale con Stan",
    "section": "55.5 Schrinkage bayesiano",
    "text": "55.5 Schrinkage bayesiano\nNel contesto dei modelli gerarchici bayesiani, il fenomeno dello ‚Äúshrinkage‚Äù (contrazione o riduzione) √® un aspetto fondamentale e desiderabile, specialmente quando si modellano dati provenienti da gruppi o sotto-popolazioni con campionature di dimensioni diverse o variazioni intrinseche. Questo fenomeno pu√≤ essere particolarmente rilevante e utile nel tuo modello gerarchico per il numero di risposte corrette di ciascun operatore, modello che utilizza una distribuzione binomiale per le osservazioni e una Beta per i priori dei parametri di successo \\(p_i\\).\nLo ‚Äúshrinkage‚Äù in un modello bayesiano gerarchico si riferisce al processo per cui le stime dei parametri individuali (ad esempio, le probabilit√† di successo per ciascun operatore nel presente modello) sono ‚Äúspostate‚Äù verso una media di gruppo. Questo accade perch√© il modello considera sia i dati osservati per ciascun gruppo (o individuo) sia le informazioni aggiuntive fornite dalla struttura gerarchica e dai dati degli altri gruppi.\nNel presente modello:\n\nogni operatore ha una probabilit√† di successo \\(p_i\\) che segue una distribuzione \\(\\text{Beta}(a, b)\\), dove \\(a\\) e \\(b\\) sono iperparametri condivisi tra tutti gli operatori;\ngli iperparametri \\(a\\) e \\(b\\) sono stimati dai dati di tutti gli operatori, e quindi forniscono una base comune che riflette le caratteristiche medie di tutti gli operatori.\n\nSe un operatore ha pochi dati (ad esempio, pochi tentativi o risposte), la stima di \\(p_i\\) per quell‚Äôoperatore sar√† fortemente influenzata dai valori di \\(a\\) e \\(b\\), ‚Äúspostando‚Äù la stima di \\(p_i\\) verso la media di gruppo. Questo riduce l‚Äôimpatto delle fluttuazioni casuali nei dati di quell‚Äôoperatore, che potrebbero altrimenti portare a stime eccessivamente ottimistiche o pessimistiche.\nLo shrinkage ha i seguenti benefici:\n\nmigliore Stima per Gruppi con Pochi Dati. Operatori con meno dati beneficiano maggiormente dello shrinkage, in quanto le loro stime sono stabilizzate attraverso l‚Äôinformazione ‚Äúprestata‚Äù dagli altri operatori;\nriduzione dell‚ÄôOverfitting. Il modello evita di adattarsi troppo ai dati di un singolo operatore, specialmente quando questi sono limitati o rumorosi, risultando in generalizzazioni pi√π robuste;\nincorporazione della Struttura dei Dati. Lo shrinkage riflette l‚Äôassunzione che gli operatori siano simili ma non identici, permettendo una certa individualit√† ma entro un quadro comune che li lega.\n\nSupponiamo che alcuni operatori abbiano mostrato risultati estremamente buoni o cattivi, che potrebbero essere dovuti a varianze casuali. Lo shrinkage modera queste stime estreme, specialmente se non sono supportate da una grande quantit√† di dati, rendendo le previsioni finali pi√π credibili e meno soggette a errori casuali.\nIn conclusione, lo shrinkage in un modello gerarchico aiuta a ottenere stime pi√π accurate e credibili per tutti i membri del gruppo, sfruttando le informazioni collettive e limitando l‚Äôimpatto delle anomalie nei dati individuali.\nPer rappresentare visivamente questo fenomeno, iniziamo con il recuperare le stime a posteriori di alpha e beta.\n\nalphas = idata.posterior[\"alpha\"]\nbetas = idata.posterior[\"beta\"]\n\nCreiamo un array che contiene le stime bayesiane della probabilit√† di successo di ciascun operatore fornite sopra dalla funzione summary di ArviZ. Per fare questo usiamo le funzionalit√† di xarray.\n\n# Calcola la media lungo le dimensioni 'chain' e 'draw'\nbayesian_estimates = idata.posterior[\"p\"].mean(dim=(\"chain\", \"draw\"))\nprint(bayesian_estimates.values)\n\n[0.27273311 0.32377131 0.37344338 0.37214022 0.37257493 0.37351838\n 0.37219305 0.37214675 0.37185773 0.37173435 0.42165569 0.42127528\n 0.42172633 0.42118034 0.42149943 0.47116033 0.47087155 0.46970487\n 0.47107502 0.47138671 0.47205312 0.47221249 0.51906367 0.52052519\n 0.57032404 0.57017976 0.56928041 0.62016621]\n\n\nGeneriamo un array con le probabilit√† empiriche.\n\n# Empirical probabilities\nempirical_probs = y.values / N.values\nprint(empirical_probs)\n\n[0.1 0.2 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.5 0.5 0.5\n 0.5 0.5 0.5 0.5 0.6 0.6 0.7 0.7 0.7 0.8]\n\n\nIl grafico seguente confronta le probabilit√† empiriche con le stime Bayesiane per la probabilit√† di successo associata a ciascun operatore. Questa rappresentazione evidenzia il fenomeno di ‚Äúshrinkage‚Äù intrinseco ai modelli Bayesiani gerarchici. In particolare, il grafico illustra come le stime Bayesiane delle probabilit√† di successo per gli operatori tendono a convergere verso la media generale, in confronto alle probabilit√† empiriche.\n\n# Calcola la media generale delle probabilit√† empiriche\nmean_empirical_prob = np.mean(empirical_probs)\nmean_empirical_prob\n\n0.43928571428571417\n\n\n\n# Calcola la media generale delle stime Bayesiane\nmean_bayesian_estimate = np.mean(bayesian_estimates)\nmean_bayesian_estimate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'p' ()&gt; Size: 8B\narray(0.44112334)xarray.DataArray'p'0.4411array(0.44112334)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\n\n# Crea il grafico\nplt.figure()\n\n# Traccia le probabilit√† empiriche\nplt.scatter(range(1, 29), empirical_probs, label=\"Probabilit√† Empiriche\")\n\n# Traccia le stime Bayesiane\nplt.scatter(range(1, 29), bayesian_estimates, color=\"C1\", label=\"Stime Bayesiane\")\n\n# Aggiungi linee orizzontali per indicare le medie generali\nplt.axhline(\n    y=mean_empirical_prob,\n    linestyle=\"--\",\n    label=f\"Media Generale Empirica: {mean_empirical_prob:.2f}\",\n)\nplt.axhline(\n    y=mean_bayesian_estimate,\n    linestyle=\"--\",\n    label=f\"Media Generale Bayesiana: {mean_bayesian_estimate:.2f}\",\n)\n\n# Etichette e titolo\nplt.xlabel(\"Indice dell'Operatore\")\nplt.ylabel(\"Probabilit√† di Successo\")\nplt.title(\"Fenomeno dello Shrinkage in un Modello Bayesiano Gerarchico\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nEsaminiamo la distribuzione a posteriori dei parametri alpha e beta.\n\naz.plot_posterior(idata, var_names=[\"alpha\", \"beta\"], figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\n_ = az.plot_trace(idata, combined=True, figsize=(9, 6), kind=\"rank_bars\")\n\n\n\n\n\n\n\n\nLe distribuzioni posteriori degli iperparametri, prese da sole, non hanno un significato chiaro. Tuttavia, possiamo utilizzarle per calcolare la distribuzione a posteriori della probabilit√† di una risposta corretta per tutto il gruppo.\n\n# Function to calculate the mean of a Beta distribution\ndef beta_mean(alpha, beta):\n    return alpha / (alpha + beta)\n\n# Calculate the means for each pair of alpha and beta\nsample_posterior_x_means = np.array([beta_mean(a, b) for a, b in zip(alphas, betas)])\n\n\nsample_posterior_x_means.shape\n\n(4, 4000)\n\n\n\nsample_posterior_x_means\n\narray([[0.37604496, 0.41922669, 0.47345362, ..., 0.49569844, 0.47777766,\n        0.4247707 ],\n       [0.45096577, 0.41051049, 0.49462864, ..., 0.50996786, 0.53271226,\n        0.4371311 ],\n       [0.47134244, 0.47201767, 0.44473739, ..., 0.35595368, 0.41136842,\n        0.46184053],\n       [0.36027889, 0.42282699, 0.43706697, ..., 0.41162794, 0.43983373,\n        0.46031791]])\n\n\n\nprint(sample_posterior_x_means.mean())\n\n0.4428264916259948\n\n\n\n_ = az.plot_posterior(sample_posterior_x_means)\n\n\n\n\n\n\n\n\nL‚Äôintervallo [0.37, 0.51] rappresenta l‚Äôintervallo di credibilit√† al 94% per la probabilit√† di risposta corretta p, considerando l‚Äôinsieme del gruppo degli operatori. Questo intervallo ci fornisce un‚Äôindicazione sulla variabilit√† delle probabilit√† di successo tra gli operatori, considerando sia le differenze tra di loro che le somiglianze all‚Äôinterno del gruppo.\nPoich√© l‚Äôintervallo di credibilit√† include il valore 0.5, possiamo concludere che non ci sono evidenze credibili che gli operatori, considerati nel loro insieme, siano in grado di ‚Äúpercepire il campo energetico di una persona senza vedere le mani‚Äù ad un livello diverso rispetto a quello che ci si potrebbe aspettare dal caso soltanto.\n\n55.5.1 Considerazioni Conclusive\nIn questo capitolo, abbiamo esplorato in profondit√† il concetto di modellazione gerarchica nell‚Äôapproccio bayesiano. Per rendere pi√π chiara questa idea, possiamo ricorrere a una semplice analogia: immaginate un‚Äôurna che contiene palline blu e rosse. Stimare la proporzione di palline blu in un campione estratto da questa urna rappresenta un problema statistico basilare, ma non riflette la complessit√† di scenari pi√π realistici.\nImmaginiamo ora un contesto pi√π articolato: un‚Äôurna grande che racchiude al suo interno diverse urne pi√π piccole, ciascuna con una propria proporzione di palline blu e rosse. In questo caso, l‚Äôanalisi si complica. Se consideriamo ogni urna piccola come indipendente dalle altre, ignoriamo il fatto che tutte sono contenute in un‚Äôurna pi√π grande e quindi potenzialmente correlate. Al contrario, se ci focalizziamo solo sull‚Äôurna grande, trascuriamo le peculiarit√† di ciascuna urna piccola.\nLa modellazione gerarchica offre un approccio ideale per gestire questa complessit√†. Attraverso di essa, possiamo stimare non solo la proporzione di palline blu in ogni urna minore, ma anche comprendere la relazione tra queste urne e l‚Äôurna principale. Questo approccio ci consente di effettuare previsioni pi√π precise, sfruttando la struttura gerarchica dei dati per coglierne le correlazioni e le interdipendenze.\nNel corso del capitolo, abbiamo applicato l‚Äôapproccio gerarchico a un modello con verosimiglianza binomiale, illustrando come questa metodologia possa essere estesa per affrontare dati organizzati gerarchicamente. Ci√≤ ci permette di affrontare problemi statistici complessi in modo pi√π solido, migliorando la nostra comprensione delle relazioni intrinseche tra i dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_hier_beta_binom.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/13_stan_hier_beta_binom.html#informazioni-sullambiente-di-sviluppo",
    "title": "55¬† Modello gerarchico beta-binomiale con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nrequests  : 2.32.3\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nKruschke, John. 2014. Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nRosa, Linda, Emily Rosa, Larry Sarner, e Stephen Barrett. 1998. ¬´A close look at therapeutic touch¬ª. Jama 279 (13): 1005‚Äì10.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>¬† <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html",
    "href": "chapters/mcmc/14_stan_categorical.html",
    "title": "56¬† Modello categoriale",
    "section": "",
    "text": "Introduzione\nNel capitolo Capitolo 85, utilizzeremo Stan per stimare i parametri di un processo dinamico utilizzando un modello di Markov di primo ordine. In quella discussione, impiegheremo la distribuzione di probabilit√† categoriale. L‚Äôobiettivo di questo capitolo √® familiarizzare con questa distribuzione.\nLa variabile casuale pi√π semplice pu√≤ assumere solo due stati, comunemente denominati ‚Äúsuccesso‚Äù e ‚Äúfallimento‚Äù. Tuttavia, variabili casuali pi√π complesse possono avere pi√π di due stati possibili. In questo capitolo, esploreremo come la teoria della probabilit√† tratta questi diversi scenari.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#distribuzioni-bernoulliana-e-binomiale",
    "href": "chapters/mcmc/14_stan_categorical.html#distribuzioni-bernoulliana-e-binomiale",
    "title": "56¬† Modello categoriale",
    "section": "56.1 Distribuzioni Bernoulliana e Binomiale",
    "text": "56.1 Distribuzioni Bernoulliana e Binomiale\n1. Distribuzione Bernoulliana:\n\nLa distribuzione Bernoulliana (o di Bernoulli) √® una distribuzione di probabilit√† discreta che descrive l‚Äôesito di un singolo esperimento dicotomico, cio√® un evento che ha due possibili risultati: ‚Äúsuccesso‚Äù (generalmente codificato come 1) o ‚Äúfallimento‚Äù (codificato come 0).\nUn esempio classico √® il lancio di una moneta: ‚Äútesta‚Äù (successo) o ‚Äúcroce‚Äù (fallimento).\nLa probabilit√† di successo √® denotata con \\(p\\) e quella di fallimento con \\(1 - p\\).\n\n2. Distribuzione Binomiale:\n\nLa distribuzione Binomiale descrive il numero di successi in una sequenza di \\(N\\) esperimenti indipendenti, ognuno dei quali segue una distribuzione di Bernoulli con probabilit√† di successo \\(p\\).\nUn esempio potrebbe essere il numero di volte in cui si ottiene ‚Äútesta‚Äù quando si lancia una moneta 10 volte.\nLa distribuzione binomiale ha due parametri: il numero di prove \\(N\\) e la probabilit√† di successo \\(p\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#distribuzioni-categoriale-e-multinomiale",
    "href": "chapters/mcmc/14_stan_categorical.html#distribuzioni-categoriale-e-multinomiale",
    "title": "56¬† Modello categoriale",
    "section": "56.2 Distribuzioni Categoriale e Multinomiale",
    "text": "56.2 Distribuzioni Categoriale e Multinomiale\n1. Distribuzione Categoriale:\n\nLa distribuzione Categoriale √® una generalizzazione della distribuzione di Bernoulli per variabili aleatorie con pi√π di due categorie possibili.\n√à utilizzata per descrivere l‚Äôesito di un singolo esperimento che pu√≤ avere pi√π di due risultati discreti (categorie), ciascuno con una propria probabilit√†.\nUn esempio psicologico potrebbe essere una prova in cui un partecipante deve scegliere tra quattro colori diversi (ad esempio, rosso, verde, blu, giallo). Le probabilit√† associate a ciascun colore rappresentano le probabilit√† categoriali.\nSe \\(K\\) √® il numero di categorie, la distribuzione categoriale √® descritta da un vettore di probabilit√† \\(\\mathbf{p} = (p_1, p_2, \\ldots, p_K)\\) dove la somma di tutte le probabilit√† √® 1 (\\(\\sum_{i=1}^{K} p_i = 1\\)).\n\n2. Distribuzione Multinomiale:\n\nLa distribuzione Multinomiale √® una generalizzazione della distribuzione Binomiale per esperimenti con pi√π di due risultati.\nDescrive la distribuzione del numero di successi in ciascuna delle \\(K\\) categorie in una sequenza di \\(N\\) esperimenti indipendenti, dove ogni esperimento segue una distribuzione categoriale con probabilit√† specifiche per ciascuna categoria.\nUn esempio psicologico potrebbe essere una serie di 20 prove in cui un partecipante sceglie uno dei quattro colori in ogni prova. La distribuzione multinomiale descrive il numero di volte in cui ciascun colore √® scelto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#relazioni-tra-distribuzioni",
    "href": "chapters/mcmc/14_stan_categorical.html#relazioni-tra-distribuzioni",
    "title": "56¬† Modello categoriale",
    "section": "56.3 Relazioni tra Distribuzioni",
    "text": "56.3 Relazioni tra Distribuzioni\nIn sintesi, possiamo descrivere le relazioni tra le distribuzioni nel modo seguente.\n\nBernoulliana e Binomiale: sono appropriate per eventi dicotomici (due possibili risultati). Una singola prova √® modellata da una distribuzione Bernoulliana; una serie di prove da una distribuzione Binomiale.\nCategoriale e Multinomiale: sono appropriate per eventi con pi√π di due risultati. Una singola prova √® modellata da una distribuzione categoriale; una serie di prove da una distribuzione Multinomiale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#esempio-con-la-distribuzione-binomiale",
    "href": "chapters/mcmc/14_stan_categorical.html#esempio-con-la-distribuzione-binomiale",
    "title": "56¬† Modello categoriale",
    "section": "56.4 Esempio con la Distribuzione Binomiale",
    "text": "56.4 Esempio con la Distribuzione Binomiale\nUn risultato consolidato nella letteratura psicologica √® che le persone con disturbi emotivi, come il disturbo d‚Äôansia sociale (SAD), il disturbo d‚Äôansia generalizzata (GAD) e la depressione, mostrano una tendenza costante, o bias, a generare interpretazioni negative di materiali ambigui. Questo √® diverso rispetto alle persone senza disturbi emotivi, che tendono, in generale, a fornire interpretazioni positive agli stimoli ambigui (Hirsch et al. (2016)).\nImmaginiamo un compito psicologico in cui a ciascun partecipante di un campione di \\(N\\) individui depressi viene chiesto di completare una singola prova. Viene presentata un‚Äôimmagine ambigua e il partecipante deve scegliere tra due emozioni: felice o triste. L‚Äôuso di una singola prova per ciascun soggetto pu√≤ essere giustificato per evitare di allertare il soggetto rispetto alle caratteristiche richieste dal compito, presentando questa prova cruciale all‚Äôinterno di una serie di altre prove diverse che fungono da ‚Äúfiller‚Äù.\nNegli esperimenti effettivi in quest‚Äôarea di ricerca si utilizzano stimoli come omofoni (ciascuno con un significato negativo e uno non negativo, ad esempio ‚Äúdie/dye‚Äù) oppure compiti di comprensione del testo in cui ogni set di frasi include una frase ambigua che ha un significato negativo e uno non correlato alla depressione (ad esempio, Mogg, Bradbury, e Bradley (2006)).\nNell‚Äôesempio presente, immaginiamo che i dati raccolti siano costituiti da \\(N\\) osservazioni, dove 1 indica un‚Äôinterpretazione negativa e 0 indica un‚Äôinterpretazione non negativa. La variabile casuale che rappresenta l‚Äôesito dell‚Äôesperimento √® Bernoulliana, poich√© ogni prova pu√≤ avere solo due risultati possibili (negativo o non negativo). Lo scopo dell‚Äôinferenza √® stimare il parametro \\(\\theta\\), che rappresenta la probabilit√† di un‚Äôinterpretazione negativa.\nEcco un esempio di codice Stan che modella questo scenario:\ndata {\n  int&lt;lower=1&gt; N; // Numero di partecipanti\n  int&lt;lower=0, upper=1&gt; y[N]; // Risultati delle prove (valori 0 e 1)\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Probabilit√† di interpretazione negativa\n}\nmodel {\n  y ~ bernoulli(theta); // Likelihood: distribuzione Bernoulliana per ciascuna prova\n}\ngenerated quantities {\n  int y_pred; // Predizione per una nuova prova\n  y_pred = bernoulli_rng(theta);\n}\nSpiegazione del Codice Stan:\n\nDati:\n\nN: il numero totale di partecipanti.\ny: un array di lunghezza \\(N\\) che contiene i risultati delle prove per ciascun partecipante, con valori 0 (interpretazione non negativa) o 1 (interpretazione negativa).\n\nParametri:\n\ntheta: un parametro che rappresenta la probabilit√† di un‚Äôinterpretazione negativa, vincolato tra 0 e 1.\n\nModello:\n\ny ~ bernoulli(theta): specifica che ogni osservazione \\(y[i]\\) segue una distribuzione Bernoulliana con parametro \\(\\theta\\). Questa √® la likelihood del modello, che indica come i dati osservati sono generati dato il parametro \\(\\theta\\).\n\nQuantit√† Generate:\n\ny_pred: una variabile che rappresenta la predizione di un nuovo esito sulla base delle probabilit√† posteriori stimate. Utilizza la funzione bernoulli_rng(theta) per generare un‚Äôosservazione simulata secondo la distribuzione Bernoulliana con parametro \\(\\theta\\).\n\n\nQuesto modello Stan permette di stimare la probabilit√† \\(\\theta\\) che un individuo con depressione interpreti un‚Äôambiguit√† in modo negativo, sulla base dei dati osservati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#esempio-con-la-distribuzione-categoriale",
    "href": "chapters/mcmc/14_stan_categorical.html#esempio-con-la-distribuzione-categoriale",
    "title": "56¬† Modello categoriale",
    "section": "56.5 Esempio con la Distribuzione Categoriale",
    "text": "56.5 Esempio con la Distribuzione Categoriale\nPer illustrare il modello categoriale, possiamo partire dallo scenario descritto in precedenza, con una piccola modifica. Immaginiamo che venga presentata un‚Äôimmagine ambigua al partecipante, ma questa volta il partecipante deve scegliere tra quattro emozioni possibili: felice, triste, arrabbiato o neutrale. Ogni scelta rappresenta un risultato categoriale, poich√© ci sono pi√π di due possibili risposte.\nIn questo caso, la variabile casuale \\(X\\) che rappresenta la risposta del soggetto pu√≤ assumere quattro valori distinti, corrispondenti alle quattro emozioni. La funzione di massa di probabilit√† (PMF) di \\(X\\) √® descritta da un simplex a 4 dimensioni, il che significa che ogni probabilit√† √® non negativa e la somma delle probabilit√† di tutte le categorie √® pari a uno. Formalmente, se \\(\\theta = (\\theta_1, \\theta_2, \\theta_3, \\theta_4)\\) rappresenta il vettore delle probabilit√† per ciascuna emozione, allora per \\(x \\in \\{1, 2, 3, 4\\}\\), la probabilit√† categoriale √® data da:\n\\[\nP(X = x) = \\theta_x,\n\\]\ndove \\(\\theta_x\\) rappresenta la probabilit√† di ciascun risultato \\(x\\).\nAd esempio, supponiamo che le probabilit√† per le quattro emozioni siano:\n\n\\(P(X = 1) = 0.2\\) (felice),\n\\(P(X = 2) = 0.4\\) (triste),\n\\(P(X = 3) = 0.1\\) (arrabbiato),\n\\(P(X = 4) = 0.3\\) (neutrale).\n\nIn questo caso, il vettore delle probabilit√† √® \\(\\theta = (0.2, 0.4, 0.1, 0.3)\\), che rappresenta una distribuzione categoriale in cui le probabilit√† di ogni emozione sommano a 1, come richiesto da un simplex.\nEcco come modellare questo scenario utilizzando Stan:\ndata {\n  int&lt;lower=1&gt; N; // Numero di partecipanti\n  array[N] int&lt;lower=1, upper=4&gt; y;  // Risultati delle prove (valori da 1 a 4)\n}\nparameters {\n  simplex[4] theta; // Vettore delle probabilit√† categoriali per le quattro emozioni\n}\nmodel {\n  y ~ categorical(theta); // Likelihood: distribuzione categoriale per ciascuna prova\n}\ngenerated quantities {\n  int y_pred; // Predizione per una nuova prova\n  y_pred = categorical_rng(theta);\n}\nNel codice precedente\n\nDati:\n\nN: il numero totale di partecipanti.\ny: un array di lunghezza \\(N\\) che contiene i risultati delle prove per ciascun partecipante, dove ogni valore pu√≤ essere 1 (felice), 2 (triste), 3 (arrabbiato), o 4 (neutrale).\n\nParametri:\n\ntheta: un vettore di probabilit√† di tipo simplex[4], che rappresenta la distribuzione delle probabilit√† per le quattro emozioni. Il tipo simplex garantisce che tutte le probabilit√† siano non negative e che la loro somma sia pari a 1.\n\n\nQuando \\(\\theta\\) √® dichiarato come simplex[4] senza una specifica dichiarazione di prior nel blocco model, Stan assume automaticamente una distribuzione a priori uniforme sulla superficie del simplex. In altre parole, ogni possibile configurazione di \\(\\theta\\) che soddisfa le condizioni di un simplex (ovvero, tutte le componenti sono non negative e sommano a 1) ha la stessa probabilit√† a priori. Questo significa che, prima di vedere i dati, tutte le combinazioni di valori di \\(\\theta\\) che sommano a 1 sono considerate ugualmente probabili. Non c‚Äô√® alcun bias a priori che favorisca una particolare configurazione di probabilit√† tra le quattro emozioni (felice, triste, arrabbiato, neutrale). Quindi, nel modello Stan, la distribuzione a priori su \\(\\theta\\) √® effettivamente uniforme sul simplex, riflettendo una posizione a priori non informativa.\n\nModello:\n\ny ~ categorical(theta): specifica che ogni osservazione \\(y[i]\\) segue una distribuzione categoriale con parametro \\(\\theta\\). Questa √® la likelihood del modello, che descrive come i dati osservati sono generati dato il vettore di probabilit√† \\(\\theta\\).\n\nQuantit√† Generate:\n\ny_pred: una variabile che rappresenta la predizione di un nuovo esito sulla base delle probabilit√† posteriori stimate. Utilizza la funzione categorical_rng(theta) per generare un‚Äôosservazione simulata secondo la distribuzione categoriale con parametro \\(\\theta\\).\n\n\nQuesto modello Stan consente di stimare le probabilit√† associate a ciascuna emozione scelta dai partecipanti in risposta a un‚Äôimmagine ambigua.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#simulazione",
    "href": "chapters/mcmc/14_stan_categorical.html#simulazione",
    "title": "56¬† Modello categoriale",
    "section": "56.6 Simulazione",
    "text": "56.6 Simulazione\nVediamo ora come implementare il modello categoriale in pratica. Iniziamo simulando dei dati dalla distribuzione categoriale.\n\n# Definire i valori possibili e le probabilit√† associate\nvalori = [1, 2, 3, 4]\nprobabilita = [0.2, 0.4, 0.1, 0.3]\n\n# Generare 50 valori casuali dalla distribuzione categoriale\ny = np.random.choice(valori, size=50, p=probabilita)\nprint(y)\n\n[3 2 2 2 1 1 2 2 4 2 4 1 3 2 1 4 2 2 2 2 4 3 3 1 3 4 1 4 1 4 2 4 4 2 1 2 4\n 3 2 2 2 1 1 4 2 4 2 4 2 4]\n\n\nInseriamo i dati in un dizionario come richiesto da Stan.\n\nstan_data = {\n    \"N\": len(y),\n    \"y\": y.tolist()\n}\n\nImportiamo il codice Stan che abbiamo discusso in precedenza.\n\nstan_file = os.path.join(project_directory, \"stan\", \"categorical_model.stan\")\n\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nEseguiamo il campionamento MCMC utilizzando i dati simulati.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2000, \n    iter_sampling=2000,\n    seed=42, \n    chains=4,\n    show_progress=False, \n    show_console=False\n)\n\nEsaminiamo le stime a posteriori dei parametri.\n\naz.summary(fit, var_names=\"theta\", hdi_prob=0.95).round(2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta[0]\n0.20\n0.05\n0.10\n0.31\n0.0\n0.0\n15575.0\n10516.0\n1.0\n\n\ntheta[1]\n0.39\n0.06\n0.27\n0.52\n0.0\n0.0\n15457.0\n12342.0\n1.0\n\n\ntheta[2]\n0.13\n0.04\n0.05\n0.22\n0.0\n0.0\n14350.0\n10458.0\n1.0\n\n\ntheta[3]\n0.28\n0.06\n0.16\n0.40\n0.0\n0.0\n15702.0\n11989.0\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#interpretazione-dei-risultati",
    "href": "chapters/mcmc/14_stan_categorical.html#interpretazione-dei-risultati",
    "title": "56¬† Modello categoriale",
    "section": "56.7 Interpretazione dei Risultati",
    "text": "56.7 Interpretazione dei Risultati\nNel contesto di questo esempio, immaginiamo un gruppo di pazienti depressi che giudicano delle immagini ambigue, assegnando loro un‚Äôemozione tra ‚Äúfelice‚Äù, ‚Äútriste‚Äù, ‚Äúarrabbiato‚Äù o ‚Äúneutrale‚Äù. I parametri \\(\\theta[0]\\), \\(\\theta[1]\\), \\(\\theta[2]\\) e \\(\\theta[3]\\) rappresentano le stime a posteriori delle probabilit√† che un partecipante scelga rispettivamente ciascuna di queste emozioni.\n\n56.7.1 Interpretazione Specifica dei Parametri\n\n\\(\\theta[0]\\): Emozione ‚Äúfelice‚Äù\nLa stima a posteriori della probabilit√† che un partecipante scelga l‚Äôemozione ‚Äúfelice‚Äù (\\(P(X = 1)\\)) √® 0.20, con un intervallo di credibilit√† al 95% (HDI) che va da 0.10 a 0.31. Questo suggerisce che, per questo gruppo di pazienti depressi, c‚Äô√® una probabilit√† relativamente bassa di interpretare un‚Äôimmagine ambigua come ‚Äúfelice‚Äù.\n\\(\\theta[1]\\): Emozione ‚Äútriste‚Äù\nLa stima a posteriori della probabilit√† che un partecipante scelga l‚Äôemozione ‚Äútriste‚Äù (\\(P(X = 2)\\)) √® 0.39, con un HDI al 95% tra 0.27 e 0.52. Questo valore pi√π alto rispetto alle altre emozioni indica che i pazienti depressi nel campione hanno una tendenza maggiore a interpretare immagini ambigue come ‚Äútristi‚Äù. Questo risultato √® coerente con le aspettative teoriche secondo cui le persone con depressione hanno una propensione a percepire situazioni ambigue in modo pi√π negativo.\n\\(\\theta[2]\\): Emozione ‚Äúarrabbiato‚Äù\nLa stima a posteriori della probabilit√† che un partecipante scelga l‚Äôemozione ‚Äúarrabbiato‚Äù (\\(P(X = 3)\\)) √® 0.13, con un HDI al 95% che va da 0.05 a 0.22. Questa probabilit√† relativamente bassa suggerisce che interpretare un‚Äôimmagine come ‚Äúarrabbiato‚Äù non √® un‚Äôinterpretazione comune tra i pazienti depressi nel campione.\n\\(\\theta[3]\\): Emozione ‚Äúneutrale‚Äù\nLa stima a posteriori della probabilit√† che un partecipante scelga l‚Äôemozione ‚Äúneutrale‚Äù (\\(P(X = 4)\\)) √® 0.28, con un HDI al 95% tra 0.16 e 0.40. Una probabilit√† del 28% indica che un‚Äôinterpretazione ‚Äúneutrale‚Äù delle immagini ambigue √® relativamente comune, ma non dominante, tra i pazienti depressi.\n\nIn sintesi, queste stime posteriori forniscono una chiara indicazione delle tendenze emotive dei partecipanti depressi nel contesto di interpretazioni di stimoli ambigui. L‚Äôalta probabilit√† di scegliere ‚Äútriste‚Äù e le basse probabilit√† associate alle altre emozioni sono coerenti con la letteratura esistente che indica un bias negativo nelle interpretazioni tra persone con depressione.\nIn questo esempio simulato, le stime posteriori di \\(\\theta\\) riflettono accuratamente i valori delle probabilit√† utilizzati per generare i dati, dimostrando che anche con un numero limitato di dati, il modello bayesiano √® capace di recuperare le distribuzioni delle probabilit√† a posteriori in modo efficace.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#considerazioni-conclusive",
    "href": "chapters/mcmc/14_stan_categorical.html#considerazioni-conclusive",
    "title": "56¬† Modello categoriale",
    "section": "56.8 Considerazioni Conclusive",
    "text": "56.8 Considerazioni Conclusive\nL‚Äôobiettivo di questo breve capitolo era fornire un esempio della distribuzione categoriale, che rappresenta un‚Äôestensione della distribuzione di Bernoulli per il caso in cui vi siano pi√π di due categorie possibili. Abbiamo mostrato come utilizzare Stan per eseguire inferenze su questa distribuzione, permettendo di stimare le probabilit√† associate a ciascuna categoria basandosi sui dati osservati. Questo approccio √® utile in vari contesti psicologici in cui le risposte dei partecipanti non si limitano a scelte dicotomiche, ma comprendono pi√π opzioni.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_categorical.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/14_stan_categorical.html#informazioni-sullambiente-di-sviluppo",
    "title": "56¬† Modello categoriale",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nrequests  : 2.32.3\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHirsch, Colette R, Frances Meeten, Charlotte Krah√©, e Clare Reeder. 2016. ¬´Resolving ambiguity in emotional disorders: The nature and role of interpretation biases¬ª. Annual Review of Clinical Psychology 12 (1): 281‚Äì305.\n\n\nMogg, Karin, Katherine E Bradbury, e Brendan P Bradley. 2006. ¬´Interpretation of ambiguous information in clinical depression¬ª. Behaviour Research and Therapy 44 (10): 1411‚Äì19.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>¬† <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo un approccio all‚Äôanalisi dei dati basato sull‚Äôuso della regressione lineare, esaminandolo dalla prospettiva dell‚Äôinferenza bayesiana. La regressione √® un metodo che consente ai ricercatori di riassumere come le previsioni o i valori medi di un risultato variano tra individui definiti da un insieme di predittori.\nCome indicato da Gelman, Hill, e Vehtari (2020), alcuni degli usi pi√π importanti della regressione sono:\n\nPrevisione: Modellare osservazioni esistenti o prevedere nuovi dati. Esempi con risultati continui o approssimativamente continui includono la previsione dei punteggi in un test futuro, la misurazione dei livelli di stress in un contesto di lavoro, o il monitoraggio del benessere psicologico in uno studio longitudinale. Esempi con risultati discreti o categoriali (a volte chiamati classificazione) includono la diagnosi di un disturbo psicologico, la riuscita o il fallimento in un compito cognitivo, e le decisioni individuali di partecipare a una terapia.\nEsplorazione delle associazioni: Riassumere quanto bene una variabile, o un insieme di variabili, predica il risultato. Esempi includono l‚Äôidentificazione dei tratti di personalit√† associati a una maggiore resilienza allo stress. Oppure l‚Äôanalisi della relazione tra stili di attaccamento infantile e capacit√† relazionali in et√† adulta. Oppure lo studio di come diversi fattori socio-economici influenzano lo sviluppo cognitivo nei bambini.\nEstrapolazione: Adeguare le analisi per tenere conto delle differenze conosciute tra il campione osservato e la popolazione di interesse. Per esempio, la generalizzazione dei risultati di uno studio sulla depressione condotto su studenti universitari alla popolazione generale. Oppure la stima dell‚Äôefficacia di una nuova terapia cognitivo-comportamentale testata in un contesto clinico controllato su una popolazione pi√π ampia e diversificata. Oppure la previsione dell‚Äôimpatto di un programma di prevenzione del bullismo testato in alcune scuole su un intero distretto scolastico.\nInferenza causale: Forse l‚Äôuso pi√π importante della regressione √® stimare gli effetti di un trattamento. Abbiamo gi√† definito l‚Äôinferenza causale pi√π dettagliatamente nel 18¬† Causalit√† dai dati osservazionali. Per esempio, la valutazione dell‚Äôeffetto di un intervento di mindfulness sui livelli di ansia, controllando per variabili confondenti come l‚Äôet√† e precedenti esperienze di meditazione. Oppure la stima dell‚Äôimpatto di un programma di sviluppo delle competenze emotive sulle performance lavorative, tenendo conto di fattori come l‚Äôambiente di lavoro e la personalit√† dei partecipanti. Oppure l‚Äôanalisi dell‚Äôefficacia di diverse tecniche psicoterapeutiche nel trattamento del disturbo post-traumatico da stress, considerando la gravit√† iniziale dei sintomi e il supporto sociale dei pazienti.\n\nIn tutti questi scenari, √® cruciale che il modello di regressione includa tutte le variabili rilevanti. Ad esempio, in uno studio sull‚Äôefficacia di una terapia per la depressione negli anziani, √® essenziale includere fattori come l‚Äôet√†, le condizioni di salute preesistenti e il supporto sociale. Omettere questi predittori potrebbe portare a stime inaccurate e conclusioni fuorvianti sull‚Äôeffettiva efficacia del trattamento in questa popolazione specifica.\n\n\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html",
    "href": "chapters/linear_models/01_reglin_bayesian.html",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "Introduzione\nI modelli lineari sono stati impiegati in molteplici contesti per lungo tempo. Come descritto da Stigler (1986), il metodo dei minimi quadrati, una tecnica per adattare una semplice regressione lineare, veniva gi√† utilizzato nel XVIII secolo per affrontare problemi di analisi dei dati in astronomia. Ad esempio, questo metodo era impiegato per determinare il moto della Luna e per riconciliare i movimenti non periodici di Giove e Saturno. All‚Äôepoca, gli astronomi erano tra i primi a sentirsi a proprio agio nell‚Äôuso di tali metodi, poich√© raccoglievano personalmente le loro osservazioni e sapevano che le condizioni di raccolta dei dati erano omogenee, anche se i valori osservati potevano differire. Questo contrastava con l‚Äôapproccio pi√π cauto delle scienze sociali, dove la riluttanza a combinare dati eterogenei ritardava l‚Äôadozione dei modelli lineari (Stigler 1986).\nIn questa sezione della dispensa, esploreremo due modelli statistici fondamentali: la regressione lineare bivariata e la regressione lineare multipla. Il primo modello considera una sola variabile esplicativa, mentre il secondo ne include diverse.\n√à cruciale sottolineare che i modelli statistici sono principalmente utilizzati per due scopi: inferenza e previsione. La previsione si limita a descrivere l‚Äôassociazione tra le variabili, mentre l‚Äôinferenza mira a stabilire relazioni di causa-effetto attraverso l‚Äôuso del modello lineare. Mentre la previsione non √® una tecnica controversa e pu√≤ essere facilmente verificata sulla base della sua effettiva capacit√† di predire la variabile dipendente, l‚Äôuso della regressione per l‚Äôinferenza causale √® molto pi√π problematico. Esso richiede una profonda comprensione del fenomeno in esame e una progettazione sperimentale o quasi-sperimentale adeguata per giustificare le assunzioni necessarie.\nIndipendentemente dall‚Äôapproccio scelto, √® fondamentale tenere presente che l‚Äôanalisi di regressione √® essenzialmente una forma di media ponderata. Di conseguenza, i risultati ottenuti riflettono inevitabilmente i bias e le peculiarit√† del dataset utilizzato.\nPer ciascun modello, esamineremo due approcci distinti:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#introduzione",
    "href": "chapters/linear_models/01_reglin_bayesian.html#introduzione",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "L‚Äôutilizzo delle funzioni di pingouin, particolarmente utile per l‚Äôanalisi esplorativa dei dati (EDA) quando si necessita di risultati rapidi.\nL‚Äôapproccio bayesiano, ideale quando l‚Äôobiettivo principale √® l‚Äôinferenza statistica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "href": "chapters/linear_models/01_reglin_bayesian.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.1 Adattare una Retta di Regressione a Dati Simulati",
    "text": "57.1 Adattare una Retta di Regressione a Dati Simulati\nSimuliamo 20 osservazioni di \\(x\\) e \\(y\\), dove \\(y\\) √® generato in base a un modello di regressione teorico con i parametri specificati di seguito.\n\n# Set seed for reproducibility\nnp.random.seed(123)\n\n# Define variables\nx = np.arange(1, 21)\nn = len(x)\na = 0.2\nb = 0.3\nsigma = 0.5\n\n# Generate y values\ny = a + b * x + sigma * np.random.normal(size=n)\n\nfake = pd.DataFrame({\"x\": x, \"y\": y})\nfake.head()\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1\n-0.042815\n\n\n1\n2\n1.298673\n\n\n2\n3\n1.241489\n\n\n3\n4\n0.646853\n\n\n4\n5\n1.410700\n\n\n\n\n\n\n\n\nAdattiamo ai dati un modello di regressione bayesiano. Compiliamo e stampiamo il codice Stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"bivariate_linreg_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  sigma ~ normal(0, 2.5);\n}\ngenerated quantities {\n  array[N] real y_rep = normal_rng(alpha + beta * x, sigma);\n}\n\n\n\nDefiniamo un dizionario che contiene i dati nel formato attesto da Stan.\n\nstan_data = {\"N\": len(fake[\"x\"]), \"x\": fake[\"x\"], \"y\": fake[\"y\"]}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo una sintesi della distribuzione a posteriori dei parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94).round(2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.15\n0.30\n-0.73\n0.40\n0.01\n0.0\n2639.0\n3041.0\n1.0\n\n\nbeta\n0.34\n0.02\n0.29\n0.39\n0.00\n0.0\n2692.0\n3281.0\n1.0\n\n\nsigma\n0.64\n0.12\n0.45\n0.86\n0.00\n0.0\n3531.0\n4126.0\n1.0\n\n\n\n\n\n\n\n\nLe prime due righe dell‚Äôoutput ci indicano che l‚Äôintercetta stimata √® -0.15 con un‚Äôincertezza di 0.30, e la pendenza stimata √® 0.34 con un‚Äôincertezza di 0.02. La deviazione standard residua \\(\\sigma\\) √® stimata a 0.64 con un‚Äôincertezza di 0.12.\n√à utile disegnare un diagramma a dispersione con la retta di regressione stimata.\n\n# Estrarre i parametri stimati dal modello bayesiano\nalpha_hat = -0.15  # Stima media di alpha\nbeta_hat = 0.34  # Stima media di beta\n\n# Scatterplot dei dati\nplt.scatter(fake[\"x\"], fake[\"y\"], color=\"blue\", label=\"Dati osservati\")\n\n# Disegnare la retta di regressione usando i parametri stimati\nx_values = np.linspace(fake[\"x\"].min(), fake[\"x\"].max(), 100)\ny_values = alpha_hat + beta_hat * x_values\nplt.plot(x_values, y_values, color=\"red\", label=\"Retta di regressione stimata\")\n\n# Aggiungere titoli e etichette\nplt.title(\"Scatterplot con Retta di Regressione\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.legend()\n\n# Mostrare il grafico\nplt.show()\n\n\n\n\n\n\n\n\nVediamo che la retta stimata si adatta bene alla nube di punti del campione. Possiamo ora confrontare le stime con i valori dei parametri assunti. Cominciamo con l‚Äôintercetta \\(a\\), che abbiamo impostato a 0.2 nelle simulazioni. Dopo aver adattato il modello ai dati simulati, la stima risulta essere ‚àí0.15, che √® molto diversa dal valore assunto di 0.2 ‚Äì ma l‚Äôincertezza, o errore standard, nella stima √® di 0.30. Approssimativamente, ci aspettiamo che la differenza tra la stima e il valore reale rientri in 1 errore standard nel 68% dei casi, e in 2 errori standard nel 95% dei casi. Quindi, se il valore reale √® 0.2, e l‚Äôerrore standard √® 0.30, non √® sorprendente che la stima risulti essere ‚àí0.15. Allo stesso modo, per le stime di \\(b\\) e œÉ, l‚Äôintervallo di credibilit√† al 95% contiene i loro valori reali.\nCome appena illustrato, una qualsiasi simulazione di dati fittizi con dati continui non riprodurr√† esattamente i valori dei parametri assunti. Tuttavia, sotto simulazioni ripetute, dovremmo osservare una copertura adeguata.\nPer semplicit√†, adottiamo l‚Äôapproccio frequentista e consideriamo l‚Äôintervallo di confidenza al 95%. Per livello di copertura si intende la proporzione di volte in cui, nelle simulazioni, il valore reale del parametro rientra nell‚Äôintervallo di confidenza stimato a partire dai dati.\n\n# Imposta il seme per la riproducibilit√†\nnp.random.seed(42)\n\n# Parametri veri\na_true = 0.2\nb_true = 0.3\nsigma_true = 0.5\n\n# Numero di simulazioni\nnum_simulations = 1000\n\n# Per tracciare il livello di copertura\ncoverage_a = 0\ncoverage_b = 0\n\n# Intervalli di confidenza al 95%\nz_value = 1.96  # valore z per il 95% di confidenza\n\nfor _ in range(num_simulations):\n    # Simula i dati\n    x = np.arange(1, 21)\n    n = len(x)\n    y = a_true + b_true * x + sigma_true * np.random.normal(size=n)\n\n    # Crea un DataFrame con i dati simulati\n    fake = pd.DataFrame({\"x\": x, \"y\": y})\n\n    # Fitting del modello\n    X = sm.add_constant(fake[\"x\"])  # Aggiunge il termine di intercetta\n    model = sm.OLS(fake[\"y\"], X).fit()\n\n    # Estrazione dei parametri stimati\n    a_hat = model.params[0]\n    b_hat = model.params[1]\n\n    # Calcolo degli errori standard\n    se_a = model.bse[0]\n    se_b = model.bse[1]\n\n    # Calcolo degli intervalli di confidenza al 95%\n    ci_a_low = a_hat - z_value * se_a\n    ci_a_high = a_hat + z_value * se_a\n    ci_b_low = b_hat - z_value * se_b\n    ci_b_high = b_hat + z_value * se_b\n\n    # Controlla se il valore vero √® all'interno degli intervalli di confidenza\n    if ci_a_low &lt;= a_true &lt;= ci_a_high:\n        coverage_a += 1\n    if ci_b_low &lt;= b_true &lt;= ci_b_high:\n        coverage_b += 1\n\n# Calcola e stampa i livelli di copertura\ncoverage_a_rate = coverage_a / num_simulations * 100\ncoverage_b_rate = coverage_b / num_simulations * 100\n\nprint(f\"Livello di copertura per l'intercetta a: {coverage_a_rate:.2f}%\")\nprint(f\"Livello di copertura per la pendenza b: {coverage_b_rate:.2f}%\")\n\nLivello di copertura per l'intercetta a: 93.80%\nLivello di copertura per la pendenza b: 94.10%\n\n\nI valori di copertura ottenuti empiricamente mediante la simulazione sono prossimi ai valori teorici attesi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "href": "chapters/linear_models/01_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.2 Modellare l‚Äôassociazione statistica tra variabili",
    "text": "57.2 Modellare l‚Äôassociazione statistica tra variabili\nAvendo verificato che il modello di regressione √® in grado di recuperare in modo attendibile i valori teorici dell‚Äôintercetta e della pendenza della retta di regressione, passiamo ora ad applicare il modello a un insieme di dati reali.\nEsamineremo un set di dati che riguarda la relazione tra i punteggi di affect e arousal. Questi dati provengono da due studi condotti presso il Personality, Motivation, and Cognition Laboratory della Northwestern University, nei quali sono stati utilizzati film per indurre stati affettivi (Rafaeli e Revelle 2006).\nCi concentreremo sull‚Äôassociazione tra l‚Äôansia di stato, considerata come variabile indipendente, e la scala di Tense Arousal del Motivational State Questionnaire (MSQ), considerata come variabile dipendente.\nIn precedenza, abbiamo applicato il modello normale a una singola variabile. Tuttavia, solitamente siamo interessati a modellare come una variabile di esito sia associata a una variabile predittiva. Se esiste un‚Äôassociazione statistica tra la variabile predittiva e quella di esito, possiamo utilizzarla per predire il risultato. Quando la variabile predittiva viene incorporata nel modello in un modo specifico, otteniamo una regressione lineare.\nI dati dell‚Äôesempio sono forniti di seguito.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"affect.csv\")\n\n# Leggere il file CSV in un DataFrame pandas\ndata = pd.read_csv(file_path)\n\n# Selezionare le colonne state1 e TA1\ndf = data[[\"state1\", \"TA1\"]]\ndf.head()\n\n\n\n\n\n\n\n\n\nstate1\nTA1\n\n\n\n\n0\n41\n11.0\n\n\n1\n26\n5.0\n\n\n2\n31\n8.0\n\n\n3\n28\n8.0\n\n\n4\n47\n12.0\n\n\n\n\n\n\n\n\nL‚Äôassociazione tra le due variabili, ansia di stato e Tense Arousal, √® rappresentata nel grafico sottostante. Il grafico suggerisce che l‚Äôassociazione pu√≤ essere approssimata da una semplice funzione matematica, come una retta. Tuttavia, √® evidente che una funzione lineare sia troppo semplicistica per rappresentare accuratamente questi dati, poich√© non √® possibile trovare una singola retta che passi per tutti i punti del diagramma di dispersione.\n\nplt.scatter(df[\"state1\"], df[\"TA1\"])\nplt.xlabel(\"State Anxiety\")\nplt.ylabel(\"Tense Arousal\")\nplt.show()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_bayesian.html#minimi-quadrati",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.3 Minimi Quadrati",
    "text": "57.3 Minimi Quadrati\nCi poniamo il duplice obiettivo di identificare la retta che meglio si adatta ai dati del diagramma e di valutare la qualit√† di tale adattamento. In altre parole, vogliamo misurare quanto, in media, i punti del diagramma si discostano dalla retta trovata.\nNel modello di regressione lineare classica, espresso come \\(y_i = \\beta_0 + \\beta_1 x_i + e_i\\), i coefficienti \\(\\beta_0\\) e \\(\\beta_1\\) vengono stimati minimizzando la somma dei quadrati degli errori \\(\\epsilon_i\\).\nPossiamo utilizzare la funzione linear_regression() del pacchetto pingouin per calcolare i coefficienti del modello seguendo questo approccio:\n\nx = df[\"state1\"]\ny = df[\"TA1\"]\n\nlm = pg.linear_regression(x, y)\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n1.56\n1.25\n1.25\n0.22\n0.52\n0.52\n-0.93\n4.04\n\n\n1\nstate1\n0.27\n0.03\n9.14\n0.00\n0.52\n0.52\n0.21\n0.33\n\n\n\n\n\n\n\n\nRecuperiamo i coefficienti b0 e b1 dall‚Äôoggetto lm creato da linear_regression().\n\nbeta = lm[\"coef\"]  # Coefficienti\nbeta\n\n0    1.555463\n1    0.267071\nName: coef, dtype: float64\n\n\n\nb0 = beta[0]\nb1 = beta[1]\n\nCalcoliamo i valori predetti dal modello di regressione:\n\nyhat = b0 + b1 * x\nyhat\n\n0     12.505379\n1      8.499312\n2      9.834668\n3      9.033455\n4     14.107806\n        ...    \n73    12.238308\n74    17.579731\n75     7.965170\n76    10.368810\n77    10.368810\nName: state1, Length: 78, dtype: float64\n\n\nI valori predetti \\(\\hat{y}\\) corrispondono alla retta di regressione:\n\nplt.plot(x, yhat)\nplt.xlabel(\"Ansia di stato\")\nplt.ylabel(\"Tense Arousal, $\\\\hat{y}$\")\n_ = plt.title(\"Retta di regressione\")\n\n\n\n\n\n\n\n\nAggiungiamo i dati osservati al grafico.\n\nplt.plot(x, yhat)\nplt.plot(x, y, \"x\")\nplt.xlabel(\"Ansia di stato\")\nplt.ylabel(\"Tense Arousal, $\\\\hat{y}$\")\n_ = plt.title(\"Retta di regressione\")\n\n\n\n\n\n\n\n\n\n57.3.1 Interpretazione\nIl coefficiente \\(\\beta_0\\) indica il valore atteso della distribuzione condizionata \\(p(y_i \\mid x_i = 0)\\). Nel caso presente, indica la media di Tense Arousal quando l‚Äôansia di stato √® uguale a 0. Ovviamente questa non √® un‚Äôinformazione di una qualche importanza pratica. Vedremo come migliorare l‚Äôinterpretabilit√† dell‚Äôintercetta usando una parametrizzazione alternativa dei dati.\nIl coefficiente \\(\\beta_1\\) indica il cambiamento del valore atteso della variabile dipendente quando la variabile indipendente aumenta di un‚Äôunit√†. Nel caso presente abbiamo che il punteggio di Tense Arousal aumenta in media di 0.27 punti quando l‚Äôansia di stato aumenta di un punto. In una parametrizzazione alternativa, standardizzando la variabile indipendente, \\(\\beta_1\\) indicherebbe di quanto varia in media Tense Arousal quando l‚Äôansia di stato aumenta di una deviazione standard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#residui",
    "href": "chapters/linear_models/01_reglin_bayesian.html#residui",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.4 Residui",
    "text": "57.4 Residui\nCalcoliamo i residui\n\\[\ne_i = y_i - \\hat{y}_i\n\\]\n\ne = y - yhat\n\nLa retta di regressine calcolata con il metodo della massima verosimiglianza ha le seguenti propriet√†:\n\nil valore atteso dei residui √® zero,\ni residui sono incorrelati con i valori predetti.\n\nValutiamo la media dei residui:\n\nnp.mean(e)\n\n2.1065770210836304e-15\n\n\nCalcoliamo la correlazione tra i residui \\(e\\) e i valori predetti \\(\\hat{y}\\):\n\nnp.corrcoef(e, yhat)[0, 1]\n\n3.7592426344877714e-16\n\n\nIl modello di regressione bivariato\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + e_i\n\\]\nscompone la variabile dipendente \\(y_i\\) in due componenti tra loro incorrelate, una componente deterministica\n\\[\n\\hat{y}_i = \\beta_0 + \\beta_1 x_i\n\\]\ne una componente aleatoria\n\\[\ne_i = y_i - \\hat{y}_i.\n\\]\n\ndf = pd.DataFrame()\ndf[\"x\"] = x\ndf[\"y\"] = y\ndf[\"yhat\"] = yhat\ndf[\"e\"] = e\ndf[\"sum\"] = df[\"yhat\"] + df[\"e\"]\ndf\n\n\n\n\n\n\n\n\n\nx\ny\nyhat\ne\nsum\n\n\n\n\n0\n41\n11.0\n12.505379\n-1.505379\n11.0\n\n\n1\n26\n5.0\n8.499312\n-3.499312\n5.0\n\n\n2\n31\n8.0\n9.834668\n-1.834668\n8.0\n\n\n3\n28\n8.0\n9.033455\n-1.033455\n8.0\n\n\n4\n47\n12.0\n14.107806\n-2.107806\n12.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n73\n40\n13.0\n12.238308\n0.761692\n13.0\n\n\n74\n60\n20.0\n17.579731\n2.420269\n20.0\n\n\n75\n24\n10.0\n7.965170\n2.034830\n10.0\n\n\n76\n33\n10.0\n10.368810\n-0.368810\n10.0\n\n\n77\n33\n6.0\n10.368810\n-4.368810\n6.0\n\n\n\n\n78 rows √ó 5 columns\n\n\n\n\n\n57.4.1 Errore Standard della Regressione\nL‚Äôerrore standard della regressione rappresenta la stima della deviazione standard dei residui nell‚Äôintera popolazione. Questo parametro pu√≤ essere calcolato attraverso la formula:\n\\[\n\\hat{\\sigma}_e = \\sqrt{\\frac{\\sum_i (e_i - \\bar{e})^2}{n-2}},\n\\]\ndove $ {e} $ indica la media dei residui, che teoricamente √® zero dato che si assume che la media degli errori sia zero.\nIl denominatore ‚Äún-2‚Äù deriva dalla perdita di due gradi di libert√†, necessaria per la stima dei due coefficienti, $ _0 $ (intercetta) e $ _1 $ (pendenza), che sono utilizzati per calcolare le stime previste $ _i = _0 + _1 x_i $. Questi gradi di libert√† vengono sottratti perch√© ciascun parametro stimato consuma un grado di libert√† dal totale disponibile.\nNel caso dell‚Äôesempio, la numerosit√† campionaria √®\n\nn = len(x)\nn\n\n78\n\n\nL‚Äôerrore standard della regressione diventa\n\nnp.sqrt(np.sum(e**2) / (n - 2))\n\n2.671556929795855\n\n\nQuesto valore indica che, in media, nella popolazione la distanza tra i valori osservati e la retta di regressione √® di 2.67 punti.\nCome discusso da {cite}gelman2020regression, la radice quadrata media dei residui, $ _{i=1}^n (y_i - ( + x_i))^2 $, tende a sottostimare la deviazione standard \\(\\sigma\\) dell‚Äôerrore nel modello di regressione. Questa sottostima √® spesso il risultato di un sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati usati anche per calcolare i residui.\nLa validazione incrociata rappresenta un approccio alternativo per valutare l‚Äôerrore predittivo che evita alcuni dei problemi legati al sovradimensionamento. La versione pi√π semplice della validazione incrociata √® l‚Äôapproccio leave-one-out, in cui il modello √® adattato \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti dati, e utilizzando questo modello adattato per predire l‚Äôosservazione esclusa: - Per \\(i = 1, \\ldots, n\\): - Adatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x,y)_j, j \\neq i\\). Denomina i coefficienti di regressione stimati come \\(\\hat{a}_{-i}, \\hat{b}_{-i}\\). - Calcola il residuo validato incrociato, $ r_{} = y_i - ({-i} + {-i} x_i) $. - Calcola la stima di \\(\\sigma_{\\text{CV}} = \\frac{1}{n} \\sum_{i=1}^n r_{\\text{CV}}^2\\).\nPer fare un esempio, eseguiamo i passaggi sopra descritti per il modello che predice Tense Arousal dall‚Äôansia di stato.\n\n# Inizializzazione di un modello di regressione lineare\nmodel = LinearRegression()\n\n# Array per salvare i residui cross-validated\nresiduals_cv = []\n\n# Loop per la validazione incrociata leave-one-out\nfor i in range(len(df)):\n    # Dati di training escludendo l'i-esimo punto\n    X_train = df.loc[df.index != i, [\"x\"]]\n    y_train = df.loc[df.index != i, \"y\"]\n\n    # Dati di test\n    X_test = df.loc[[i], [\"x\"]]\n    y_test = df.loc[i, \"y\"]\n\n    # Addestramento del modello\n    model.fit(X_train, y_train)\n\n    # Predizione sull'i-esimo punto\n    y_pred = model.predict(X_test)\n\n    # Calcolo del residuo validato incrociato\n    residual_cv = y_test - y_pred[0]\n    residuals_cv.append(residual_cv**2)\n\n# Calcolo di sigma_cv\nsigma_cv = np.sqrt(np.mean(residuals_cv))\n\nprint(\"Stima di œÉ_CV:\", sigma_cv)\n\nStima di œÉ_CV: 2.7114997423207527\n\n\nNel caso dei dati analizzati, si osserva che la stima ottenuta attraverso la validazione incrociata √® leggermente superiore rispetto a quella calcolata usando la formula $ _e = $. Questo incremento, sebbene minimo, riflette le differenze metodologiche tra i due approcci di stima dell‚Äôerrore standard.\n\n\n57.4.2 Parametrizzazione Alternativa\nPer consentire una migliore interpretazione dell‚Äôintercetta, centriamo i valori della variabile indipendente.\n\nx = df[\"state1\"]\ny = df[\"TA1\"]\n\nxc = x - np.mean(x)\nnp.mean(xc)\n\n-1.8219044506669234e-15\n\n\nEseguiamo l‚Äôanalisi di regressione.\n\nlm2 = pg.linear_regression(xc, y)\nlm2.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n12.62\n0.30\n41.73\n0.0\n0.52\n0.52\n12.02\n13.22\n\n\n1\nstate1\n0.27\n0.03\n9.14\n0.0\n0.52\n0.52\n0.21\n0.33\n\n\n\n\n\n\n\n\nNotiamo che la stima della pendenza della retta di regressione √® rimasta immutata, mentre cambia il coefficiente \\(\\beta_0\\). Nel caso in cui la variabile indipendente sia centrata, il coefficiente \\(\\beta_0\\) rappresenta il valore atteso della variabile dipendente quando la variabile indipendente assume il suo valore medio.\nNel caso presente, il valore 12.62 indica la media di Tense Arousal quando l‚Äôansia di stato assume il valore medio nel campione.\nAdesso standardizziamo sia la variabile dipendente che la variabile indipendente.\n\n# Standardizzazione\nzx = standardize(x)\nzy = standardize(y)\n\n\nprint(np.mean(zx), np.std(zx))\n\n-2.049642507000289e-16 1.0\n\n\n\nprint(np.mean(zy), np.std(zy))\n\n-1.25255930983351e-16 1.0\n\n\n\nlm3 = pg.linear_regression(zx, zy)\nlm3.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-0.00\n0.08\n-0.00\n1.0\n0.52\n0.52\n-0.16\n0.16\n\n\n1\nstate1\n0.72\n0.08\n9.14\n0.0\n0.52\n0.52\n0.57\n0.88\n\n\n\n\n\n\n\n\nDopo aver standardizzato entrambe le variabili, i coefficienti di regressione possono essere interpretati nel seguente modo:\n\n\\(\\beta_0\\) = 0: Questo si verifica perch√© la retta di regressione, calcolata attraverso il metodo dei minimi quadrati (ML), interseca il punto delle medie delle variabili standardizzate, ovvero \\((\\bar{X}, \\bar{Y})\\).\n\\(\\beta_1\\): Rappresenta la variazione media della variabile dipendente, espressa in termini di deviazioni standard, per ogni aumento di una deviazione standard nella variabile indipendente.\n\n\n\n57.4.3 Derivazione delle stime dei minimi quadrati\nL‚Äôapproccio classico al modello di regresione fa uso del metodo dei minimi quadrati per trovare la retta che meglio si adatta a un insieme di dati. L‚Äôobiettivo √® minimizzare la somma dei quadrati delle differenze (residui) tra i valori osservati e quelli predetti dal modello lineare.\nSupponiamo di avere un insieme di dati \\((x_i, y_i)\\), dove \\(i = 1, 2, \\dots, n\\). Il modello lineare si esprime come:\n\\[\ny_i = \\alpha + \\beta x_i + \\epsilon_i,\n\\]\ndove:\n\n\\(\\alpha\\) √® l‚Äôintercetta,\n\\(\\beta\\) √® il coefficiente angolare (pendenza),\n\\(\\epsilon_i\\) √® il residuo, ossia l‚Äôerrore associato al punto \\(i\\).\n\nIl metodo dei minimi quadrati mira a minimizzare la somma dei quadrati dei residui \\(\\epsilon_i\\):\n\\[\nS(\\alpha, \\beta) = \\sum_{i=1}^n \\epsilon_i^2 = \\sum_{i=1}^n (y_i - (\\alpha + \\beta x_i))^2\n\\]\nGeometricamente, trovare i valori di \\(\\alpha\\) e \\(\\beta\\) che minimizzano la funzione \\(S(\\alpha, \\beta)\\) significa trovare il punto in cui la funzione √® piatta, ossia dove la sua pendenza √® zero. Questo si fa calcolando le derivate parziali di \\(S(\\alpha, \\beta)\\) rispetto a \\(\\alpha\\) e \\(\\beta\\), e ponendole uguali a zero:\n\\[\n\\frac{\\partial S}{\\partial \\alpha} = 0 \\quad \\text{e} \\quad \\frac{\\partial S}{\\partial \\beta} = 0.\n\\]\nRisolvendo questo sistema di equazioni, si trovano le espressioni per \\(\\alpha\\) e \\(\\beta\\):\n\\[\n\\beta = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2},\n\\]\n\\[\n\\alpha = \\bar{y} - \\beta \\bar{x},\n\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie dei valori \\(x_i\\) e \\(y_i\\) rispettivamente.\nPer chiarire, ora consideriamo il caso in cui i dati sono standardizzati. Quando i dati sono standardizzati (cio√® \\(x_i\\) e \\(y_i\\) hanno media 0 e deviazione standard 1), l‚Äôintercetta \\(\\alpha\\) √® 0, quindi il modello diventa:\n\\[\ny_i = \\beta x_i + \\epsilon_i\n\\]\nDi conseguenza, dobbiamo solo stimare \\(\\beta\\).\nEcco come eseguire una simulazione in Python per questo caso:\n\n# Serie di valori di beta tra 0 e 1\nbeta_values = np.linspace(0.5, 1, 1000)\n\n# Calcolo della somma dei quadrati dei residui (SSE) per ciascun valore di beta\nSSE = []\nfor beta in beta_values:\n    residuals = zy - beta * zx\n    SSE.append(np.sum(residuals**2))\n\n# Convertiamo SSE in un array numpy per maggiore facilit√† nella visualizzazione\nSSE = np.array(SSE)\n\nbeta_true = 0.72 # trovato da pingouin\n\n# Visualizzazione della curva SSE in funzione di beta\nplt.plot(beta_values, SSE, label=\"SSE vs Beta\", color=\"blue\")\nplt.axvline(beta_true, color=\"red\", linestyle=\"--\", label=f\"Beta True = {beta_true}\")\nplt.xlabel(\"Beta\")\nplt.ylabel(\"SSE (Somma dei quadrati dei residui)\")\nplt.title(\"Curva SSE in funzione di Beta\")\nplt.legend()\nplt.show()\n\n# Troviamo il valore di beta che minimizza SSE\nbeta_min_index = np.argmin(SSE)\nbeta_min = beta_values[beta_min_index]\n\nprint(f\"Valore di beta stimato con la formula dei minimi quadrati: {beta_true}\")\nprint(f\"Valore stimato di beta (minimo SSE): {beta_min}\")\n\n\n\n\n\n\n\n\nValore di beta stimato con la formula dei minimi quadrati: 0.72\nValore stimato di beta (minimo SSE): 0.7232232232232232",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#metodo-della-massima-verosimiglianza",
    "href": "chapters/linear_models/01_reglin_bayesian.html#metodo-della-massima-verosimiglianza",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.5 Metodo della Massima Verosimiglianza",
    "text": "57.5 Metodo della Massima Verosimiglianza\nDopo aver discusso il metodo dei minimi quadrati, possiamo affrontare il metodo della massima verosimiglianza, che in molti casi porta agli stessi risultati ma con un approccio leggermente diverso.\n\n57.5.0.1 Connessione con il Metodo dei Minimi Quadrati\nNel contesto della regressione lineare, se gli errori del modello sono indipendenti e distribuiti normalmente, cio√® se \\(y_i \\sim \\text{Normale}(\\alpha + \\beta x_i, \\sigma^2)\\) per ogni \\(i\\), allora la stima dei parametri ottenuta con il metodo dei minimi quadrati coincide con quella ottenuta usando il metodo della massima verosimiglianza. Questo significa che i valori di \\(\\alpha\\) e \\(\\beta\\) che minimizzano la somma dei quadrati degli errori residui sono anche quelli che massimizzano la probabilit√† di osservare i dati dati quei parametri.\n\n\n57.5.0.2 La Funzione di Verosimiglianza\nIn un modello di regressione, la funzione di verosimiglianza √® definita come la probabilit√† (o densit√† di probabilit√†) di osservare i dati effettivi in funzione dei parametri e dei predittori del modello. In altre parole, dato un insieme di parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), la funzione di verosimiglianza ci dice quanto √® probabile osservare i dati \\(y\\) dati quei parametri.\nMatematicamente, la funzione di verosimiglianza per un modello di regressione lineare √® espressa come:\n\\[\np(y|\\alpha, \\beta, \\sigma, X) = \\prod_{i=1}^{n} N(y_i|\\alpha + \\beta x_i, \\sigma^2).\n\\]\nQui, \\(N(\\cdot|\\cdot, \\cdot)\\) rappresenta la funzione di densit√† della distribuzione normale.\nQuesta formula indica che la verosimiglianza totale √® il prodotto delle densit√† di probabilit√† per ciascun punto dati \\(y_i\\), considerando che ogni \\(y_i\\) segue una distribuzione normale con media \\(\\alpha + \\beta x_i\\) e varianza \\(\\sigma^2\\).\n\n\n57.5.0.3 Minimizzare i Residui Quadratici\nUn‚Äôanalisi della funzione di verosimiglianza mostra che massimizzare questa funzione equivale a minimizzare la somma dei quadrati dei residui, proprio come si fa nel metodo dei minimi quadrati. Questo perch√© la funzione di densit√† normale \\(N(y_i|\\alpha + \\beta x_i, \\sigma^2)\\) ha un massimo quando il valore di \\(y_i\\) √® vicino alla media prevista \\(\\alpha + \\beta x_i\\), e il prodotto delle densit√† √® massimizzato quando i residui sono minimi.\n\n\n57.5.0.4 Differenza nella Stima di \\(\\sigma\\)\nC‚Äô√® una piccola differenza nella stima della deviazione standard \\(\\sigma\\) tra i due metodi. Nel metodo della massima verosimiglianza, la stima di \\(\\sigma\\) viene calcolata come:\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^{n} \\left(y_i - (\\hat{\\alpha} + \\hat{\\beta} x_i)\\right)^2\n\\]\nIn questo caso, il denominatore √® \\(n\\), mentre nel metodo dei minimi quadrati il denominatore √® \\(n-2\\), che riflette l‚Äôaggiustamento per i gradi di libert√†.\nIn sintesi, il metodo della massima verosimiglianza trova i parametri che rendono i dati osservati i pi√π probabili, dato il modello. Quando gli errori sono normalmente distribuiti, questo approccio porta agli stessi risultati del metodo dei minimi quadrati, ma con un‚Äôinterpretazione basata sulla probabilit√†.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#coefficiente-di-determinazione",
    "href": "chapters/linear_models/01_reglin_bayesian.html#coefficiente-di-determinazione",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.6 Coefficiente di Determinazione",
    "text": "57.6 Coefficiente di Determinazione\nI modelli lineari, sia quelli stimati con il metodo dei minimi quadrati che quelli ottenuti tramite massima verosimiglianza, permettono una decomposizione della varianza totale della variabile dipendente \\(y\\) in due componenti indipendenti: la devianza spiegata e la devianza residua. Questa decomposizione deriva dal teorema della decomposizione della devianza, come descritto nell‚ÄôAppendice S.\nLa devianza spiegata (DS) rappresenta la parte della varianza totale che √® attribuibile al modello, ed √® definita come:\n\\[\nDS = \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2,\n\\]\ndove \\(\\hat{y}_i\\) √® il valore predetto dal modello per l‚Äôosservazione \\(i\\), e \\(\\bar{y}\\) √® la media delle osservazioni di \\(y\\).\nLa devianza residua (DR), invece, rappresenta la parte della varianza totale che non √® spiegata dal modello, ovvero l‚Äôerrore, ed √® calcolata come:\n\\[\nDR = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2.\n\\]\nLa somma delle due componenti, ovvero la devianza spiegata e la devianza residua, √® pari alla devianza totale (DT):\n\\[\nDT = \\sum_{i=1}^n (y_i - \\bar{y})^2.\n\\]\nIl coefficiente di determinazione \\(R^2\\) √® definito come il rapporto tra la devianza spiegata e la devianza totale:\n\\[\nR^2 = \\frac{DS}{DT}.\n\\]\nIl coefficiente di determinazione \\(R^2\\) fornisce una misura della proporzione della varianza totale di \\(y\\) che viene spiegata dal modello di regressione. Un valore di \\(R^2\\) vicino a 1 indica che il modello spiega una grande parte della variabilit√† osservata nei dati, mentre un valore vicino a 0 suggerisce che il modello spiega poco della variabilit√† della variabile dipendente.\nQuesto coefficiente √® particolarmente utile per valutare l‚Äôadeguatezza di un modello lineare, permettendo di comprendere quanto del fenomeno studiato viene catturato dalle variabili indipendenti incluse nel modello. Tuttavia, √® importante ricordare che un alto valore di \\(R^2\\) non implica necessariamente che il modello sia il migliore in senso assoluto; altri fattori come la complessit√† del modello e la presenza di potenziali errori di specificazione devono essere considerati nella valutazione complessiva del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#modello-di-regressione-bayesiano",
    "href": "chapters/linear_models/01_reglin_bayesian.html#modello-di-regressione-bayesiano",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.7 Modello di Regressione Bayesiano",
    "text": "57.7 Modello di Regressione Bayesiano\nL‚Äôapproccio bayesiano, a differenza del metodo dei minimi quadrati (o massimo della verosimiglianza), non si limita a cercare i parametri che meglio si adattano ai dati osservati secondo un criterio predefinito. Invece, integra questa stima con informazioni a priori sui parametri stessi, combinando la verosimiglianza dei dati con una distribuzione a priori che riflette le conoscenze o le ipotesi preesistenti sui parametri. Questo rende l‚Äôinferenza bayesiana un processo di aggiornamento delle credenze, in cui la distribuzione a posteriori dei parametri riassume la nostra conoscenza aggiornata dopo aver osservato i dati. A differenza dei minimi quadrati e della massima verosimiglianza, che forniscono delle stime puntuali, l‚Äôinferenza bayesiana produce distribuzioni a posteriori che descrivono la probabilit√† di ciascun valore dei parametri, data l‚Äôincertezza complessiva nel modello.\nNel contesto della relazione tra ansia di stato (\\(x\\)) e Tense Arousal (\\(y\\)), l‚Äôapproccio bayesiano ci consente di modellare questa relazione attraverso un modello statistico lineare simile a quello utilizzato nel metodo dei minimi quadrati. Anche qui si assume che gli errori siano indipendenti tra loro, distribuiti normalmente con media zero e varianza costante \\(\\sigma^2\\). Tuttavia, l‚Äôapproccio bayesiano va oltre, permettendo di specificare distribuzioni a priori per i parametri del modello (\\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\)). Queste distribuzioni a priori rappresentano la nostra conoscenza iniziale sui parametri prima di osservare i dati.\nDopo aver osservato i dati, l‚Äôinferenza bayesiana utilizza il teorema di Bayes per aggiornare queste distribuzioni a priori e ottenere le distribuzioni a posteriori dei parametri. Queste distribuzioni a posteriori combinano l‚Äôinformazione contenuta nei dati con le credenze iniziali, offrendo una stima dei parametri che riflette sia l‚Äôevidenza empirica che le conoscenze preesistenti.\n\n57.7.1 Verosimiglianza\nIl modello di verosimiglianza per descrivere la relazione tra \\(x\\) (ansia di stato) e \\(y\\) (Tense Arousal) assume che:\n\\[ y \\sim \\text{Normale}(\\alpha + \\beta x, \\sigma) \\]\nQuesto implica che i valori osservati di \\(y\\) sono distribuiti normalmente attorno alla retta di regressione \\(\\alpha + \\beta x\\), con una deviazione standard \\(\\sigma\\). In altre parole, ogni osservazione di \\(y\\) √® una combinazione lineare dell‚Äôintercetta \\(\\alpha\\), del coefficiente \\(\\beta\\) che moltiplica la variabile \\(x\\), e di un termine di errore normalmente distribuito.\n\n\n57.7.2 Distribuzioni a Priori\nPer implementare l‚Äôapproccio bayesiano, definiamo delle distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\). In una prima versione del modello, possiamo utilizzare delle distribuzioni a priori uniformi, che esprimono una mancanza di conoscenza specifica o una neutralit√† nelle credenze iniziali sui valori di questi parametri.\n\n\n57.7.3 Distribuzioni a Posteriori\nLe distribuzioni a posteriori sono ottenute combinando la verosimiglianza con le distribuzioni a priori mediante il teorema di Bayes. Queste distribuzioni a posteriori riflettono il nostro stato di conoscenza sui parametri dopo aver osservato i dati, incorporando sia le informazioni contenute nei dati che le credenze iniziali espresse dalle distribuzioni a priori. L‚Äôapproccio bayesiano, quindi, non solo fornisce stime dei parametri, ma anche una quantificazione dell‚Äôincertezza associata a queste stime, rendendolo particolarmente utile in situazioni con dati limitati o incertezza significativa.\nQuesta metodologia ci permette di modellare e comprendere in modo pi√π completo e robusto la relazione tra ansia di stato e Tense Arousal, integrando informazioni preesistenti con nuove evidenze empiriche.\nIn sintesi, il modello di regressione bayesiano pu√≤ essere riassunto come segue. La verosimiglianza √® data da:\n\\[\ny_i \\sim \\text{Normal}(\\alpha + \\beta \\cdot x_i, \\sigma).\n\\]\nIn una prima formulazione del modello, possiamo utilizzare prior uniformi per ciascuno dei parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\):\n\\[\n\\alpha \\sim \\text{Uniform}(-\\infty, \\infty),\n\\] \\[\n\\beta \\sim \\text{Uniform}(-\\infty, \\infty),\n\\] \\[\n\\sigma \\sim \\text{Uniform}(0, \\infty).\n\\]\n\n\n57.7.4 Codice Stan\nIl codice Stan che implementa il modello descritto in precedenza √® contenuto nel file arousal_model_1.stan. Compiliamo e stampiamo il modello.\n\nstan_file = os.path.join(project_directory, 'stan', 'arousal_model1.stan')\nmodel1 = CmdStanModel(stan_file=stan_file)\nprint(model1.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nSi osservi che, in questa prima istanziazione del modello bayesiano, non avendo specificato le distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), Stan assume distribuzioni a priori uniformi per questi parametri.\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = {\n    \"N\": len(df[\"TA1\"]),\n    \"x\": df[\"state1\"],\n    \"y\": df[\"TA1\"]\n}\nprint(stan_data)\n\n{'N': 78, 'x': 0     41\n1     26\n2     31\n3     28\n4     47\n      ..\n73    40\n74    60\n75    24\n76    33\n77    33\nName: state1, Length: 78, dtype: int64, 'y': 0     11.0\n1      5.0\n2      8.0\n3      8.0\n4     12.0\n      ... \n73    13.0\n74    20.0\n75    10.0\n76    10.0\n77     6.0\nName: TA1, Length: 78, dtype: float64}\n\n\nEseguiamo il campionamento MCMC.\n\nfit1 = model1.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(fit1, var_names=([\"alpha\", \"beta\", \"sigma\"]))\n\n\n\n\n\n\n\n\nLe tracce delle quattro catene indicano che sono ben mescolate e convergono verso una distribuzione stazionaria, segnalando una buona esplorazione dello spazio dei parametri. Questo √® evidenziato dal fatto che le tracce non mostrano trend evidenti e oscillano intorno a un valore centrale, suggerendo che le catene hanno raggiunto l‚Äôequilibrio.\nLa forma della distribuzione a posteriori, visibile nei grafici a densit√†, appare approssimativamente gaussiana per ciascun parametro (alpha, beta, e sigma). Questo suggerisce che, dato il modello e i dati, le stime a posteriori sono stabili e ben definite, con una concentrazione delle probabilit√† attorno ai valori medi e una simmetria che riflette una distribuzione normale.\nIn sintesi, i grafici di traccia indicano una buona convergenza e una distribuzione a posteriori stabile e ben definita, rafforzando la fiducia nelle stime bayesiane ottenute.\nL‚Äôoggetto fit generato da cmdstanpy appartiene alla classe cmdstanpy.stanfit.mcmc.CmdStanMCMC. Questo oggetto √® funzionalmente equivalente a un oggetto della classe InferenceData, consentendo la sua manipolazione tramite le funzioni offerte da ArviZ. Procediamo quindi con l‚Äôesame di un sommario delle distribuzioni a posteriori dei parametri del modello lineare.\n\naz.summary(fit1, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.552\n1.256\n-0.859\n3.816\n0.026\n0.019\n2395.0\n2748.0\n1.0\n\n\nbeta\n0.267\n0.029\n0.213\n0.323\n0.001\n0.000\n2436.0\n2858.0\n1.0\n\n\nsigma\n2.716\n0.227\n2.314\n3.149\n0.004\n0.003\n3410.0\n3273.0\n1.0\n\n\n\n\n\n\n\n\n\nAlpha (Intercetta): La stima media di alpha √® 1.552, con un intervallo di credibilit√† (HDI - Highest Density Interval) al 3% e 97% che va da -0.859 a 3.816. Questo significa che, date le informazioni disponibili e il modello specificato, c‚Äô√® una probabilit√† del 94% che l‚Äôintercetta reale si trovi all‚Äôinterno di questo intervallo. L‚Äôintercetta corrisponde al valore atteso di Tense Arousal quando l‚Äôansia di stato vale 0.\nBeta (Coefficiente angolare): La stima media di beta √® 0.267. Anche qui, l‚Äôintervallo di credibilit√† al 94% va da 0.213 a 0.323, suggerendo che √® molto probabile che l‚Äôeffetto del predittore x sulla variabile di risposta y sia positivo e compreso in questo intervallo. La pendenza \\(\\beta\\) ci informa sull‚Äôincremento atteso di Tense Arousal quando l‚Äôansia di stato aumenta di un‚Äôunit√†.\nSigma (Deviazione standard residua): La stima media di sigma √® 2.716, con un intervallo di credibilit√† da 2.314 a 3.149. Questa √® una misura della variabilit√† residua, ovvero la deviazione standard degli errori rispetto alla linea di regressione.\n\nLa colonna mean dell‚Äôoutput riporta la media della distribuzione a posteriori di ciasccun parametro, mentre nella colonna sd troviamo una misura di dispersione della distribuzione a posteriori del parametro, ovvero la quantificazione dell‚Äôintertezza della stima a posteriori. In pratica √® la deviazione standard della distribuzione a posteriori, ovvero la radice quadrata della varianza dei campioni della distribuzione a posteriori del parametro.\nSupponiamo di avere \\(S\\) campioni per il parametro \\(\\theta\\). Questi campioni possono essere denotati come \\(\\theta_1, \\theta_2, \\dots, \\theta_S\\). La media campionaria (o stima puntuale bayesiana) del parametro \\(\\theta\\) si calcola come:\n\\[\n\\bar{\\theta} = \\frac{1}{S} \\sum_{i=1}^{S} \\theta_i.\n\\]\nLa deviazione standard della distribuzione a posteriori, che √® ci√≤ che √® indicato con sd, si calcola come la radice quadrata della varianza campionaria dei campioni posteriori:\n\\[\n\\text{Var}(\\theta) = \\frac{1}{S-1} \\sum_{i=1}^{S} (\\theta_i - \\bar{\\theta})^2,\n\\]\n\\[\n\\text{sd}(\\theta) = \\sqrt{\\text{Var}(\\theta)}.\n\\]\nIn sintesi, sd √® calcolato come la deviazione standard dei campioni ottenuti dalla distribuzione a posteriori di un parametro.\nLe altre colonne sono le seguenti.\n\nHDI (Intervallo di Massima Densit√†): Questo intervallo rappresenta la regione pi√π densa dell‚Äôintera distribuzione a posteriori, contenente il 94% delle probabilit√†. √à l‚Äôequivalente bayesiano dell‚Äôintervallo di confidenza, ma con un‚Äôinterpretazione probabilistica diretta.\nR_hat: √à un indicatore di convergenza per le catene di Markov Monte Carlo (MCMC). Un valore di R_hat prossimo a 1 segnala che la catena √® probabilmente convergente, suggerendo che le stime a posteriori sono affidabili.\nESS (Dimensione Campionaria Effettiva): Indica l‚Äôequivalente di un campione indipendente in un‚Äôanalisi MCMC, valutando quanto efficacemente i campioni generati dalla catena rappresentano la distribuzione a posteriori.\n\nInfine, mcse_mean che mcse_sd sono misure che valutano la precisione delle stime ottenute tramite MCMC, quantificando quanto queste stime possono variare a causa della natura stocastica del processo di campionamento.\n\nmcse_mean (Monte Carlo Standard Error of the Mean): Questo valore rappresenta l‚Äôerrore standard Monte Carlo associato alla stima della media del parametro. In altre parole, mcse_mean quantifica l‚Äôincertezza introdotta dal processo di campionamento MCMC stesso. Un valore basso indica che la catena di Markov Monte Carlo ha fornito una stima della media del parametro con un‚Äôalta precisione.\nmcse_sd (Monte Carlo Standard Error of the Standard Deviation): Analogamente, mcse_sd √® l‚Äôerrore standard Monte Carlo associato alla stima della deviazione standard della distribuzione a posteriori del parametro. Questo valore misura l‚Äôincertezza nella stima della dispersione del parametro, dovuta al processo di campionamento MCMC. Anche qui, un valore basso indica che la stima della deviazione standard √® stabile e precisa.\n\nPossiamo confrontare i valori ottenuti con l‚Äôapproccio bayesiano con quelli trovati usando la procedura di massima verosimiglianza.\n\nlm = pg.linear_regression(df[\"state1\"], df[\"TA1\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n1.56\n1.25\n1.25\n0.22\n0.52\n0.52\n-0.93\n4.04\n\n\n1\nstate1\n0.27\n0.03\n9.14\n0.00\n0.52\n0.52\n0.21\n0.33\n\n\n\n\n\n\n\n\nLa somiglianza tra le due soluzioni indica che, quando usiamo dei prior uniformi per i parametri, i due approcci producono risultati sostanzialmente equivalenti.\nL‚Äôinterpretazione del significato dei parametri √® la stessa anche per l‚Äôapproccio frequentista:\n\nL‚Äôintercetta rappresenta il valore atteso della variabile di risposta TA1 quando il predittore state1 √® pari a zero.\nIl coefficiente beta rappresenta la variazione attesa nella variabile di risposta TA1 per ogni unit√† di incremento in state1.\n\nCi sono per√≤ delle differenze sostanziali nell‚Äôinterpretazione dell‚Äôincertezza associata alle stime dei parametri.\n\nStima Puntuale vs Distribuzione a Posteriori:\n\nFrequentista: Le stime di alpha e beta sono considerate come valori puntuali, ottenuti attraverso il metodo dei minimi quadrati. Gli errori standard associati a queste stime forniscono un‚Äôindicazione della variabilit√† delle stime se ripetessimo il campionamento molte volte.\nBayesiano: Le stime di alpha e beta sono presentate come distribuzioni a posteriori. La media di queste distribuzioni pu√≤ essere considerata la stima puntuale, ma l‚Äôintera distribuzione riflette la nostra incertezza attorno a queste stime, basata sia sui dati osservati che sulle informazioni a priori.\n\nIntervallo di Confidenza vs Intervallo Credibile:\n\nFrequentista: L‚Äôintervallo di confidenza al 95% indica che, se ripetessimo l‚Äôesperimento molte volte, il 95% di tali intervalli conterr√† il vero valore del parametro. Questo intervallo si basa sulla stima puntuale e sull‚Äôassunzione di distribuzione normale degli errori.\nBayesiano: L‚Äôintervallo credibile al 94% (ad esempio l‚ÄôHDI - Highest Density Interval) rappresenta la probabilit√† che il parametro si trovi entro quell‚Äôintervallo dato il modello, i dati osservati e le informazioni a priori. √à un‚Äôintervallo che ha una diretta interpretazione probabilistica.\n\np-value vs Significato Bayesiano:\n\nFrequentista: Il p-value √® utilizzato per testare l‚Äôipotesi nulla che il coefficiente sia uguale a zero. Un p-value molto basso (come in questo caso per beta) suggerisce che c‚Äô√® una forte evidenza contro l‚Äôipotesi nulla.\nBayesiano: In un‚Äôanalisi bayesiana, non si fa riferimento a p-value; l‚Äôaccento √® posto sulla distribuzione a posteriori e sull‚Äôintervallo credibile, che forniscono una comprensione diretta dell‚Äôincertezza attorno ai parametri senza bisogno di test di ipotesi tradizionali.\n\n\nIn sintesi,\n\nInterpretazione delle stime: Nell‚Äôapproccio frequentista, le stime dei parametri sono valori puntuali accompagnati da un intervallo di confidenza che riflette la variabilit√† campionaria. Nell‚Äôapproccio bayesiano, ogni parametro √® rappresentato come una distribuzione a posteriori che incorpora sia i dati osservati sia le informazioni a priori.\nGestione dell‚Äôincertezza: L‚Äôapproccio frequentista usa errori standard e intervalli di confidenza, mentre l‚Äôapproccio bayesiano utilizza l‚Äôintera distribuzione a posteriori per descrivere l‚Äôincertezza.\nProbabilit√† e significativit√†: Nell‚Äôapproccio frequentista, il p-value √® cruciale per determinare la significativit√† statistica, mentre nell‚Äôapproccio bayesiano si utilizza l‚Äôintervallo credibile e la probabilit√† a posteriori per descrivere quanto √® probabile un parametro dato i dati e le informazioni a priori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti",
    "href": "chapters/linear_models/01_reglin_bayesian.html#interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.8 Interpretare i coefficienti di regressione come confronti, non come effetti",
    "text": "57.8 Interpretare i coefficienti di regressione come confronti, non come effetti\nGelman, Hill, e Vehtari (2021) sottolineano che i coefficienti di regressione sono spesso chiamati ‚Äúeffetti‚Äù, ma questa terminologia pu√≤ essere fuorviante. Gli effetti, infatti, sono conseguenze di una relazione causale. Tuttavia, ci√≤ che il modello di regressione stima non √® necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, quello che viene osservato √® che la media della variabile \\(y\\) nella sottopopolazione con \\(X = x + 1\\) √® \\(b\\) volte maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione √® uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono essere sempre interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, √® possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non pu√≤ essere derivata unicamente dall‚Äôuso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#ricodifica-dei-dati",
    "href": "chapters/linear_models/01_reglin_bayesian.html#ricodifica-dei-dati",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.9 Ricodifica dei dati",
    "text": "57.9 Ricodifica dei dati\nL‚Äôintercetta (\\(\\alpha\\)) rappresenta il valore atteso di Tense Arousal quando l‚Äôansia di stato √® pari a 0. Tuttavia, poich√© l‚Äôansia di stato √® misurata su una scala ad intervalli, l‚Äôorigine √® arbitraria e non rappresenta l‚Äôassenza della propriet√†. Lo stesso vale per la variabile Tense Arousal. Per entrambe le variabili, inoltre, anche l‚Äôunit√† di misura √® arbitraria.\nIn queste circostanze, una trasformazione utile √® la standardizzazione. La standardizzazione fa s√¨ che il valore 0 corrisponda alla media campionaria e che l‚Äôunit√† di misura sia una deviazione standard.\nQuando standardizziamo l‚Äôansia di stato, il valore 0 della variabile standardizzata corrisponde alla media della variabile originale. Dato che la retta di regressione passa per il punto \\((\\bar{x}, \\bar{y})\\), utilizzando i valori standardizzati di \\(x\\) e \\(y\\), la nuova intercetta (\\(\\alpha\\)) sar√† 0. La pendenza (\\(\\beta\\)) avr√† un‚Äôinterpretazione utile: nel caso di dati standardizzati, la pendenza stima l‚Äôincremento (o decremento) atteso di \\(y\\) quando \\(x\\) aumenta di una deviazione standard.\n\n# Calcolo della media e della deviazione standard di state1\nmean_state1 = np.mean(df[\"state1\"])\nstd_state1 = np.std(df[\"state1\"])\n# Standardizzazione \ndf[\"state1_z\"] = (df[\"state1\"] - mean_state1) / std_state1\n\n# Calcolo della media e della deviazione standard di TA1\nmean_ta1 = np.mean(df[\"TA1\"])\nstd_ta1 = np.std(df[\"TA1\"])\n# Standardizzazione \ndf[\"ta1_z\"] = (df[\"TA1\"] - mean_ta1) / std_ta1\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_79156/3940630615.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"state1_z\"] = (df[\"state1\"] - mean_state1) / std_state1\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_79156/3940630615.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"ta1_z\"] = (df[\"TA1\"] - mean_ta1) / std_ta1\n\n\nCreiamo il dizionario dei dati con le nuove variabli standardizzate.\n\nstan_data2 = {\n    \"N\": len(df[\"state1_z\"]), \n    \"x\": df[\"state1_z\"], \n    \"y\": df[\"ta1_z\"]\n}\n\nEseguiamo il campionamento.\n\nfit2 = model1.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit2, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.000\n0.081\n-0.152\n0.155\n0.001\n0.001\n6678.0\n5110.0\n1.0\n\n\nbeta\n0.723\n0.082\n0.571\n0.879\n0.001\n0.001\n7508.0\n5666.0\n1.0\n\n\nsigma\n0.712\n0.059\n0.603\n0.822\n0.001\n0.000\n7985.0\n5955.0\n1.0\n\n\n\n\n\n\n\n\nOra possiamo assegnare al parametro \\(\\beta\\) la seguente interpretazione: quando l‚Äôansia di stato aumenta di una deviazione standard Tense Arousal aumenta, in media, di 0.72 deviazioni standard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#distribuzioni-a-priori-sui-parametri",
    "href": "chapters/linear_models/01_reglin_bayesian.html#distribuzioni-a-priori-sui-parametri",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.10 Distribuzioni a Priori sui Parametri",
    "text": "57.10 Distribuzioni a Priori sui Parametri\nNei modelli precedenti, abbiamo adottato distribuzioni a priori uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Tuttavia, in generale, quando non disponiamo di informazioni pregresse sul valore dei parametri, √® preferibile specificare distribuzioni debolmente informative. Queste distribuzioni sono progettate per essere centrate su un valore neutro, come lo zero, in modo tale da non influenzare in modo significativo la distribuzione a posteriori nella direzione ‚Äúdesiderata‚Äù dal ricercatore. L‚Äôobiettivo delle distribuzioni a priori debolmente informative √®, infatti, quello di regolarizzare il modello, penalizzando le osservazioni pi√π estreme e contribuendo a una stima pi√π robusta dei parametri.\nPer il caso in esame, specificheremo le seguenti distribuzioni a priori debolmente informative sui parametri del modello.\n\nIntercetta (\\(\\alpha\\)):\n\n\\(\\alpha \\sim \\text{Normale}(0, 1)\\)\nLa scelta di una deviazione standard ampia (2) riflette l‚Äôincertezza riguardo al valore iniziale dell‚Äôintercetta. Si crede che l‚Äôintercetta possa essere qualsiasi valore vicino a 0, ma con una variazione significativa.\n\nCoefficiente Angolare (\\(\\beta\\)):\n\n\\(\\beta \\sim \\text{Normale}(0, 2)\\)\nUn‚Äôampia deviazione standard (2) per \\(\\beta\\) permette di incorporare l‚Äôincertezza riguardo all‚Äôinfluenza della temperatura sui ricavi del gelato. Questo prior permette che \\(\\beta\\) possa essere sia positivo che negativo con una vasta gamma di valori.\n\nDeviazione Standard Residua (\\(\\sigma\\)):\n\n\\(\\sigma \\sim \\text{Cauchy}^+(0, 2)\\)\nLa distribuzione Half-Cauchy √® scelta perch√© √® debolmente informativa e adatta per i parametri di scala come la deviazione standard residua. La scala di 2 consente a \\(\\sigma\\) di assumere una vasta gamma di valori positivi, riflettendo l‚Äôincertezza riguardo alla variabilit√† residua.\n\n\nLe distribuzioni normali per \\(\\alpha\\) e \\(\\beta\\) con deviazioni standard ampie permettono una grande flessibilit√†, mentre la distribuzione Half-Cauchy per \\(\\sigma\\) √® scelta per la sua capacit√† di gestire bene i parametri di scala. Queste scelte garantiscono che il modello sia debolmente informativo, permettendo ai dati osservati di avere un‚Äôinfluenza predominante sulle stime posteriori dei parametri.\nCompiliamo e stampiamo il modello Stan che include le specificazioni delle distribuzioni a priori dei parametri su elencate.\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model_prior_raw.stan\")\nmodel3 = CmdStanModel(stan_file=stan_file)\nprint(model3.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nAdattiamo il modello ai dati.\n\nfit3 = model3.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit3, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.000\n0.081\n-0.147\n0.155\n0.001\n0.001\n6463.0\n5733.0\n1.0\n\n\nbeta\n0.724\n0.080\n0.569\n0.869\n0.001\n0.001\n8212.0\n6155.0\n1.0\n\n\nsigma\n0.710\n0.058\n0.605\n0.825\n0.001\n0.000\n7705.0\n5931.0\n1.0\n\n\n\n\n\n\n\n\nSi noti che, utilizzando distribuzioni a priori debolmente informative, le distribuzioni a posteriori dei parametri risultano molto simili a quelle ottenute usando distribuzioni uniformi. Tuttavia, le distribuzioni a priori debolmente informative sono preferibili poich√© forniscono una maggiore stabilit√† numerica e sono generalmente pi√π affidabili e robuste, specialmente quando si lavora con dati reali. L‚Äôuso di distribuzioni uniformi √® sconsigliato per via delle possibili instabilit√† numeriche che possono introdurre nei modelli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi",
    "href": "chapters/linear_models/01_reglin_bayesian.html#verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.11 Verifica della procedura di fitting del modello utilizzando una simulazione con dati fittizi",
    "text": "57.11 Verifica della procedura di fitting del modello utilizzando una simulazione con dati fittizi\nL‚Äôesempio precedente √® abbastanza semplice da permetterci di tracciare un grafico e vedere se la linea di regressione attraversa i punti. Tuttavia, in generale, √® una buona pratica verificare l‚Äôadattamento del modello eseguendo la procedura in condizioni controllate, dove conosciamo la verit√†. Mostriamo questo approccio utilizzando il modello precedente.\nPasso 1: Creazione di un mondo fittizio.\nIniziamo assumendo dei valori reali per tutti i parametri del modello. In questo caso, abbiamo gi√† adattato un modello ai dati, quindi procediamo assumendo che questi particolari valori dei parametri siano la verit√†. In altre parole, assumiamo che la relazione \\(y = 1.126 + 2.2x + \\text{errore}\\) sia vera, con gli errori estratti da una distribuzione normale con media 0 e deviazione standard 2.688. Successivamente, utilizzando i valori predittori \\(x\\) gi√† presenti nel nostro dataset, esaminiamo se questi predittori generano una distribuzione di \\(y\\) coerente con i valori osservati di \\(y\\).\n\na = 1.126   \nb = 0.277\nsigma = 2.688\nx = df[\"state1\"]\nn = len(x)\n\nPasso 2: Simulazione di dati fittizi.\nSuccessivamente, simuleremo un vettore \\(y\\) di dati fittizi e inseriremo tutto questo in un data frame:\n\ny = a + b * x + np.random.normal(0, sigma, size=n)\nfake = pd.DataFrame({\"x\": x, \"y\": y})\nfake.head()\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n41\n14.560092\n\n\n1\n26\n10.537546\n\n\n2\n31\n11.326387\n\n\n3\n28\n8.181064\n\n\n4\n47\n13.802861\n\n\n\n\n\n\n\n\nPasso 3: Adattamento del modello e confronto tra i valori stimati e quelli assunti.\nIl passo successivo √® adattare un modello di regressione a questi dati. Durante l‚Äôadattamento, non si fa alcun uso dei valori veri assunti di Œ±, Œ≤ e œÉ.\n\nlm = pg.linear_regression(fake[\"x\"], fake[\"y\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n1.44\n1.30\n1.11\n0.27\n0.53\n0.52\n-1.15\n4.03\n\n\n1\nx\n0.28\n0.03\n9.17\n0.00\n0.53\n0.52\n0.22\n0.34\n\n\n\n\n\n\n\n\nLe stime ottenute dai dati fittizzi sono molto simili a quelle ottenute con i dati veri.\nPasso 4: Inserire la simulazione in un loop.\nPer ottenere una stima dell‚Äôincertezza delle nostre stime, ripetiamo la simulazione molte volte e calcoliamo il livello di copertura dei parametri.\nIl livello di copertura rappresenta la proporzione delle volte in cui l‚Äôintervallo di confidenza calcolato contiene il vero valore del parametro \\(b\\). In altre parole, se l‚Äôintervallo di confidenza al 68% (o 95%) √® calcolato correttamente, ci aspetteremmo che, rispettivamente, il 68% (o 95%) di questi intervalli contenga il vero valore di \\(b\\).\n\nIl codice seguente esegue n_fake = 10_000 simulazioni, ciascuna delle quali genera un set di dati fittizio e adatta un modello di regressione a questi dati.\nI valori critici t_68 e t_95 sono calcolati utilizzando la funzione t.ppf di scipy.stats, che fornisce i quantili della distribuzione t di Student per il livello di confidenza desiderato:\n\nt_68 corrisponde al quantile dell‚Äô84%, che definisce l‚Äôintervallo di confidenza al 68%.\nt_95 corrisponde al quantile del 97,5%, che definisce l‚Äôintervallo di confidenza al 95%.\n\nPer ogni simulazione (s da 0 a n_fake - 1):\n\nVengono generati dati fittizi per la variabile indipendente x e per la variabile dipendente y usando i valori di a, b, e sigma.\nViene adattato un modello di regressione lineare ai dati fittizi usando la libreria pingouin.\nIl coefficiente stimato b_hat e il suo errore standard b_se sono estratti dai risultati della regressione.\nViene verificato se il vero valore di \\(b\\) si trova all‚Äôinterno dell‚Äôintervallo \\(b_hat \\pm t_68 \\times b_se\\).\n\ncover_68[s] = np.abs(b - b_hat) &lt; t_68 * b_se memorizza True (1) se il vero valore di \\(b\\) √® all‚Äôinterno dell‚Äôintervallo di confidenza al 68%, altrimenti False (0).\n\nViene verificato se il vero valore di \\(b\\) si trova all‚Äôinterno dell‚Äôintervallo \\(b_hat \\pm t_95 \\times b_se\\).\ncover_95[s] = np.abs(b - b_hat) &lt; t_95 * b_se memorizza True (1) se il vero valore di \\(b\\) √® all‚Äôinterno dell‚Äôintervallo di confidenza al 95%, altrimenti False (0).\n\n\nDopo aver completato tutte le simulazioni, i livelli di copertura sono calcolati come la media dei valori in cover_68 e cover_95:\n\ncover_68.mean() fornisce la proporzione di simulazioni in cui l‚Äôintervallo di confidenza al 68% ha contenuto il vero valore di \\(b\\).\ncover_95.mean() fornisce la proporzione di simulazioni in cui l‚Äôintervallo di confidenza al 95% ha contenuto il vero valore di \\(b\\).\n\nSe il risultato √® vicino a 0.68, significa che l‚Äôintervallo di confidenza al 68% calcolato per ogni simulazione ha contenuto il vero valore di \\(b\\) nel 68% delle simulazioni, come previsto teoricamente. Se il risultato √® vicino a 0.95, significa che l‚Äôintervallo di confidenza al 95% calcolato per ogni simulazione ha contenuto il vero valore di \\(b\\) nel 95% delle simulazioni, in linea con le aspettative teoriche.\nSe i livelli di copertura risultano sostanzialmente inferiori ai valori teorici (68% e 95%), potrebbe indicare problemi nella stima degli intervalli di confidenza o nelle assunzioni del modello.\n\nfrom scipy.stats import t\n\n# Parametri della simulazione\nn_fake = 10_000  # numero di simulazioni\n\n# Inizializzazione delle liste di copertura\ncover_68 = np.zeros(n_fake)\ncover_95 = np.zeros(n_fake)\n\n# Calcola i valori critici t per il 68% e il 95% utilizzando scipy.stats.t.ppf\nt_68 = t.ppf(0.84, df=n - 2)\nt_95 = t.ppf(0.975, df=n - 2)\n\n# Ciclo per la simulazione\nfor s in range(n_fake):\n    x = np.random.normal(size=n)\n    y = a + b * x + np.random.normal(0, sigma, size=n)\n    fake = pd.DataFrame({\"x\": x, \"y\": y})\n\n    # Fit del modello usando pingouin\n    fit = pg.linear_regression(fake[[\"x\"]], fake[\"y\"])\n    b_hat = fit[\"coef\"][1]\n    b_se = fit[\"se\"][1]\n\n    # Calcolo della copertura\n    cover_68[s] = np.abs(b - b_hat) &lt; t_68 * b_se\n    cover_95[s] = np.abs(b - b_hat) &lt; t_95 * b_se\n\n# Output dei risultati\nprint(f\"68% coverage: {cover_68.mean()}\")\nprint(f\"95% coverage: {cover_95.mean()}\")\n\n68% coverage: 0.6798\n95% coverage: 0.9462\n\n\nSi noti come la simulazione produce una copertura molto prossima a quella teorica. Ci√≤ significa che, nel caso di questa analisi, possiamo assegnare agli intervalli di confidenza o credibilit√† l‚Äôinterpretazione usuale. Se il livello di copertura della simulazione fosse stato inferiore a quello teorico (per modelli pi√π complessi), allora questo sarebbe un‚Äôindicazione che si dovrebbero interpetare gli intervalli di confidenza o credibilit√† con cautela.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#il-paradosso-della-regressione-verso-la-media",
    "href": "chapters/linear_models/01_reglin_bayesian.html#il-paradosso-della-regressione-verso-la-media",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.12 Il Paradosso della Regressione verso la Media",
    "text": "57.12 Il Paradosso della Regressione verso la Media\nIl fenomeno della regressione verso la media √® un concetto statistico importante, spesso frainteso e talvolta interpretato erroneamente come un effetto causale. Questo fenomeno fu osservato inizialmente da Galton in uno studio classico sull‚Äôereditariet√† dell‚Äôaltezza.\nGelman, Hill, e Vehtari (2021) discutono questo fenomeno analizzando i dati pubblicati nel 1903 da Karl Pearson e Alice Lee. Applicando un modello di regressione lineare a questi dati, si ottiene la seguente equazione:\n\\[\ny = 63.9 + 0.54(x ‚àí 62.5) + \\text{errore},\n\\]\ndove \\(y\\) rappresenta l‚Äôaltezza delle figlie e \\(x\\) l‚Äôaltezza delle madri. La variabile indipendente √® stata centrata per evitare interpretazioni prive di senso dell‚Äôintercetta.\nIl paradosso emerge dal coefficiente di regressione, che √® inferiore a 1. Questo implica che:\n\nSe una madre ha un‚Äôaltezza nella media, si prevede che sua figlia adulta avr√† anch‚Äôessa un‚Äôaltezza nella media.\nPer ogni pollice in pi√π (o in meno) rispetto alla media dell‚Äôaltezza materna, ci si aspetta che la figlia sia circa mezzo pollice pi√π alta (o pi√π bassa) rispetto alla media della sua generazione.\n\nQuesto porta a una domanda apparentemente paradossale: se le madri alte tendono ad avere figlie solo leggermente alte, e le madri basse figlie solo leggermente basse, non significa che le figlie saranno pi√π vicine alla media rispetto alle loro madri? E se questo processo continua, non dovremmo aspettarci che dopo poche generazioni tutti abbiano un‚Äôaltezza vicina alla media?\nLa risoluzione di questo apparente paradosso sta nel fatto che la previsione dell‚Äôaltezza di una donna √® pi√π vicina alla media rispetto all‚Äôaltezza di sua madre, ma l‚Äôaltezza effettiva non √® la stessa cosa della previsione, che ha un margine di errore. Le previsioni puntuali regrediscono verso la media - ecco perch√© il coefficiente √® inferiore a 1 - e questo riduce la variazione. Allo stesso tempo, per√≤, l‚Äôerrore nel modello - l‚Äôimperfezione della previsione - aggiunge variazione, sufficiente a mantenere la variazione totale dell‚Äôaltezza approssimativamente costante da una generazione all‚Äôaltra.\nLa regressione verso la media si verifica sempre in qualche forma quando le previsioni sono imperfette in un ambiente stabile. L‚Äôimperfezione della previsione induce variazione, e la regressione nella previsione puntuale √® necessaria per mantenere costante la variazione totale.\nQuesto fenomeno √® controintuitivo e spesso porta a interpretazioni causali errate. Per chiarire come ci√≤ possa accadere, possiamo considerare uno scenario matematicamente equivalente: studenti che affrontano due esami. Coloro che ottengono punteggi alti nel primo esame tendono a ottenere risultati solo leggermente superiori alla media nel secondo; d‚Äôaltra parte, chi ottiene punteggi bassi nel primo esame tende a migliorare leggermente, ottenendo risultati nel secondo esame che, pur restando inferiori alla media, non sono cos√¨ bassi come i primi.\nPotrebbe sembrare naturale dare a questo fenomeno una spiegazione causale, suggerendo che gli studenti che eccellono nel primo esame possano avere alte capacit√† ma poi, diventando troppo sicuri di s√©, tendano a rilassarsi, con il risultato di non ripetere la stessa performance nel secondo. Dall‚Äôaltro lato, si potrebbe ipotizzare che gli studenti con punteggi bassi nel primo esame siano motivati a impegnarsi di pi√π, migliorando cos√¨ i loro risultati nel secondo.\nIn realt√†, il fenomeno della regressione verso la media si verifica anche in assenza di fattori motivazionali, come dimostrano simulazioni in cui sia il primo che il secondo esame sono determinati dalla vera abilit√† dell‚Äôindividuo, pi√π un elemento di rumore casuale. La regressione verso la media √® un fenomeno puramente statistico, privo di una spiegazione causale intrinseca. Comprendere correttamente questo concetto √® essenziale per evitare di trarre conclusioni errate dai dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "href": "chapters/linear_models/01_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "57.13 Commenti e considerazioni finali",
    "text": "57.13 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato la stima dei parametri di un modello di regressione bivariato utilizzando l‚Äôapproccio bayesiano. Questo percorso ci ha portato a riflettere sulla natura e sul ruolo dei modelli statistici nella ricerca scientifica, in particolare nel campo della psicologia.\nCome sottolineato da Alexander (2023), √® fondamentale comprendere che i modelli statistici non sono strumenti per scoprire una verit√† assoluta, ma piuttosto mezzi per esplorare e interpretare i dati a nostra disposizione. Questa prospettiva ci invita a considerare i modelli non come rappresentazioni perfette della realt√†, ma come lenti attraverso le quali osserviamo e cerchiamo di comprendere il mondo che ci circonda.\nL‚Äôaffermazione di McElreath che ‚Äúla regressione √® in effetti un oracolo, ma un oracolo crudele. Parla per enigmi e si diletta nel punirci per aver posto domande sbagliate‚Äù (McElreath 2020) mette in luce la natura complessa e talvolta insidiosa dell‚Äôuso dei modelli statistici. Questa metafora ci ricorda che l‚Äôapplicazione dei modelli richiede non solo competenza tecnica, ma anche una profonda comprensione del contesto e una costante riflessione critica.\nNel processo di modellizzazione statistica, √® cruciale considerare due dimensioni interconnesse: il ‚Äúmondo del modello‚Äù, con le sue assunzioni e semplificazioni, e il ‚Äúmondo reale‚Äù, caratterizzato da una complessit√† spesso difficile da catturare pienamente. Questa distinzione ci invita a riflettere costantemente sulla relazione tra il modello e la realt√† che cerchiamo di comprendere, ponendoci domande sulla misura in cui il modello ci insegna qualcosa sui dati a disposizione e su quanto accuratamente questi dati riflettano la realt√† oggetto del nostro studio.\nL‚Äôevoluzione dei metodi statistici, dalle loro origini in campi come l‚Äôastronomia e l‚Äôagricoltura fino alle applicazioni moderne in psicologia, evidenzia la necessit√† di adattare e riconsiderare costantemente questi strumenti. Il lavoro pioneristico di Ronald Fisher, sviluppato in gran parte in un contesto di ricerca agricola, pone interrogativi sulla validit√† delle sue assunzioni fondamentali quando applicate alla psicologia contemporanea. McElreath (2020) sottolinea l‚Äôimportanza di sviluppare modelli basati su ipotesi relative ai meccanismi psicologici sottostanti al comportamento, suggerendo che questi possano offrire intuizioni pi√π profonde rispetto a un approccio puramente descrittivo come quello della regressione lineare.\nNonostante queste considerazioni, il modello di regressione rimane uno strumento di grande valore per la psicologia. Tuttavia, il suo utilizzo efficace richiede un equilibrio tra una solida conoscenza del fenomeno oggetto di studio e la flessibilit√† necessaria per adattarsi a contesti di ricerca in continua evoluzione. Gli psicologi sono chiamati a considerare una gamma pi√π ampia di strumenti statistici, cercando quelli pi√π appropriati per descrivere i complessi fenomeni psicologici, superando i limiti di un approccio puramente descrittivo.\nIn conclusione, questo capitolo ci ha permesso di esplorare l‚Äôapproccio bayesiano alla regressione, offrendo una prospettiva critica sull‚Äôuso dei modelli statistici in psicologia. Per un confronto pi√π ampio, l‚Äôappendice presenta un‚Äôintroduzione all‚Äôapproccio frequentista per il modello di regressione lineare bivariato, consentendo di apprezzare le differenze tra i due metodi nella stima dei parametri e nell‚Äôinterpretazione dei risultati. Per approfondimenti ulteriori, si consiglia la lettura di Applied Regression Analysis and Generalized Linear Models (Fox 2015), in particolare il capitolo 2, e, in italiano, Statistica per psicologi (Caudek e Luccio 2001).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "title": "57¬† Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\narviz     : 0.18.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\nlogging   : 0.5.1.2\npingouin  : 0.5.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nCaudek, Corrado, e Riccardo Luccio. 2001. ¬´Statistica per psicologi¬ª.\n\n\nFox, John. 2015. Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\n‚Äî‚Äî‚Äî. 2021. Regression and other stories. Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nRafaeli, Eshkol, e William Revelle. 2006. ¬´A premature consensus: are happiness and sadness truly opposite affects?¬ª Motivation and Emotion 30: 1‚Äì12.\n\n\nStigler, Stephen. 1986. The History of Statistics. Massachusetts: Belknap Harvard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>57</span>¬† <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_beauty_sex_power.html",
    "href": "chapters/linear_models/02_beauty_sex_power.html",
    "title": "58¬† Bellezza, sesso e potere",
    "section": "",
    "text": "Introduzione\nGelman e Weakliem (2009) discutono le difficolt√† statistiche che emergono nell‚Äôanalizzare piccoli campioni di dati. Uno degli studi che esaminano √® quello di Kanazawa (2007), in cui l‚Äôautore propone che i genitori con tratti ereditari che aumentano il successo riproduttivo maschile pi√π di quello femminile in un dato ambiente avranno una proporzione di figli maschi superiore al previsto. Al contrario, i genitori con tratti ereditari che favoriscono maggiormente il successo riproduttivo femminile rispetto a quello maschile avranno una proporzione di figlie superiore al previsto. Kanazawa identifica l‚Äôattrattivit√† fisica come un tratto ereditario che aumenta significativamente il successo riproduttivo delle figlie pi√π di quello dei figli. Pertanto, prevede che i genitori fisicamente attraenti avranno una proporzione di figlie superiore al previsto. Inoltre, se l‚Äôattrattivit√† √® ereditaria e i genitori attraenti hanno pi√π figlie, nel corso dell‚Äôevoluzione le donne dovrebbero diventare gradualmente pi√π attraenti degli uomini. Secondo Kanazawa (2007), l‚Äôanalisi dei dati della National Longitudinal Study of Adolescent Health (Add Health) conferma entrambe queste ipotesi: gli individui molto attraenti hanno il 26% di probabilit√† in meno di avere un figlio maschio, e le donne risultano significativamente pi√π attraenti degli uomini nel campione rappresentativo americano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_beauty_sex_power.html#lo-studio-di-kanazawa2007beautiful",
    "href": "chapters/linear_models/02_beauty_sex_power.html#lo-studio-di-kanazawa2007beautiful",
    "title": "58¬† Bellezza, sesso e potere",
    "section": "58.1 Lo Studio di @Kanazawa (2007)",
    "text": "58.1 Lo Studio di @Kanazawa (2007)\nL‚Äôattrattivit√† √® stata misurata su una scala da 1 a 5 (‚Äúmolto poco attraente‚Äù a ‚Äúmolto attraente‚Äù). Gelman e Weakliem (2009) si concentrano su questo risultato riportato da Kanazawa (2007):\n\nIf I dichotomize the respondents into those who are rated ‚Äò‚Äòvery attractive‚Äô‚Äô and everyone else, the difference in the proportion of sons between the two groups (0.52 vs.¬†0.44) is statistically significant (t = 2.44, p \\(\\geq\\) 0.05). There appears to be something qualitatively different about respondents rated ‚Äúvery attractive‚Äù.\n\nIn altre parole:\n\nil 56% dei figli di genitori nella categoria 5 erano femmine;\nil 48% dei figli di genitori nelle categorie da 1 a 4 erano femmine.\n\nQuesto risultato risulta ‚Äòstatisticamente significativo‚Äô.\nGelman e Weakliem (2009) fanno notare come la dicotomizzazione proposta da Kanazawa (2007) sia arbitraria. La variabile indipendente ha 5 livelli e sono possibili quattro confronti tra i livelli. Kanazawa (2007) ha scelto arbitariamente uno di questi confronti.\n√à dunque pi√π naturale esaminare tutti i dati mediante un modello di regressione. I dati sono i seguenti:\n\nx = np.arange(-2, 3, 1)\ny = np.array([50, 44, 50, 47, 56])\nsexratio = pd.DataFrame({\"x\": x, \"y\": y})\nsexratio\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-2\n50\n\n\n1\n-1\n44\n\n\n2\n0\n50\n\n\n3\n1\n47\n\n\n4\n2\n56\n\n\n\n\n\n\n\n\nPer comodit√†, le cinque categorie della \\(X\\) sono state ricodificate in modo tale che la categoria centrale abbia valore 0.\n\n# Calcolo dei prior Bayesiani\ntheta_hat_prior = 0\nse_prior = 0.25\ntheta_hat_data = 8\nse_data = 3\ntheta_hat_bayes = (theta_hat_prior / se_prior**2 + theta_hat_data / se_data**2) / (\n    1 / se_prior**2 + 1 / se_data**2\n)\nse_bayes = np.sqrt(1 / (1 / se_prior**2 + 1 / se_data**2))\n\n\n# Regressione lineare con Pingouin\nfm = pg.linear_regression(sexratio[[\"x\"]], sexratio[\"y\"])\nfm.round(4)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n49.4\n1.9442\n25.4086\n0.0001\n0.2841\n0.0455\n43.2126\n55.5874\n\n\n1\nx\n1.5\n1.3748\n1.0911\n0.3550\n0.2841\n0.0455\n-2.8751\n5.8751\n\n\n\n\n\n\n\n\n\n# Plot dei dati e della linea di regressione\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(x, y, \"o\", markersize=5)\nplt.ylim(43, 57)\nplt.xlabel(\"Attractiveness of parent\")\nplt.ylabel(\"Percentage of girl babies\")\nplt.title(\"Data on beauty and sex ratio\")\nplt.yticks([45, 50, 55], [f\"{i}%\" for i in [45, 50, 55]])\n\nplt.subplot(1, 2, 2)\nplt.plot(x, y, \"o\", markersize=5)\nplt.ylim(43, 57)\nplt.xlabel(\"Attractiveness of parent\")\nplt.ylabel(\"Percentage of girl babies\")\nplt.title(\"Data and least-squares regression line\")\nplt.yticks([45, 50, 55], [f\"{i}%\" for i in [45, 50, 55]])\nslope, intercept = fm[\"coef\"].values[1], fm[\"coef\"].values[0]\nplt.plot(x, intercept + slope * x, \"-\")\nplt.text(\n    1,\n    52.2,\n    f\"y = {intercept:.1f} + {slope:.1f} x\\n(Std err of slope is {fm['se'].values[1]:.1f})\",\n)\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_32471/3465279703.py:27: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_beauty_sex_power.html#analisi-bayesiana-con-prior-non-informativi",
    "href": "chapters/linear_models/02_beauty_sex_power.html#analisi-bayesiana-con-prior-non-informativi",
    "title": "58¬† Bellezza, sesso e potere",
    "section": "58.2 Analisi Bayesiana con Prior Non Informativi",
    "text": "58.2 Analisi Bayesiana con Prior Non Informativi\nMediante l‚Äôutilizzo di prior non informativi ci possiamo aspettare che l‚Äôanalisi bayesisana sostanzialmente replichi il risultato dell‚Äôanalisi frequentista.\nSistemiamo i dati nel formato richiesto da Stan.\n\nstan_data = {\"N\": len(sexratio), \"x\": sexratio[\"x\"].values, \"y\": sexratio[\"y\"].values}\nstan_data\n\n{'N': 5, 'x': array([-2, -1,  0,  1,  2]), 'y': array([50, 44, 50, 47, 56])}\n\n\nFormuliamo il modello di regressione bivariata utilizzando prior non informativi.\n\nstan_file = os.path.join(project_directory, 'stan', 'sex_ratio.stan')\nmodel1 = CmdStanModel(stan_file=stan_file)\nprint(model1.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nEseguiamo il campionamento MCMC.\n\nfit1 = model1.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit1, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n49.512\n6.228\n39.278\n58.560\n0.103\n0.081\n3384.0\n1640.0\n1.0\n\n\nbeta\n1.543\n4.567\n-5.028\n8.927\n0.088\n0.104\n3851.0\n1381.0\n1.0\n\n\nsigma\n9.406\n10.183\n2.109\n22.019\n0.357\n0.252\n912.0\n1188.0\n1.0\n\n\n\n\n\n\n\n\nLa soluzione ottenuta replica quella del metodo dei minimi quadrati. In entrambi i casi, sia l‚Äôintervallo di confidenza che l‚Äôintervallo credibile includono lo zero, il che indica che l‚Äôattrattivit√† dei genitori non sembra avere un effetto credibile sulla proporzione di nascite femminili. Tuttavia, nonostante la notevole incertezza, l‚Äôanalisi mostra che il coefficiente \\(\\beta\\) √® positivo e pari a 1.5.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_beauty_sex_power.html#analisi-bayesiana-con-prior-debolmente-informativi",
    "href": "chapters/linear_models/02_beauty_sex_power.html#analisi-bayesiana-con-prior-debolmente-informativi",
    "title": "58¬† Bellezza, sesso e potere",
    "section": "58.3 Analisi Bayesiana con Prior Debolmente Informativi",
    "text": "58.3 Analisi Bayesiana con Prior Debolmente Informativi\nGelman e Weakliem (2009) propongono l‚Äôuso di prior debolmente informativi nel contesto di un‚Äôanalisi sulla relazione tra l‚Äôattrattivit√† dei genitori e la percentuale di nascite femminili. Questi prior sono basati su informazioni precedenti e su ipotesi ragionevoli relative al problema studiato. Ecco come vengono definiti i due principali coefficienti del modello di regressione:\n\nIntercetta (a):\n\nLa variabile intercetta rappresenta la percentuale di nascite femminili quando l‚Äôattrattivit√† dei genitori √® nella media.\nGelman e Weakliem (2009) utilizzano una distribuzione normale centrata a 48.8 con una deviazione standard di 0.5. Questo indica che, sulla base dei dati esistenti, ci si aspetta che la percentuale di nascite femminili per genitori con attrattivit√† media sia circa il 48.8%, con un margine di variazione di ¬±0.5%. Questo valore √® scelto perch√©, in generale, la percentuale di nascite femminili √® stabile tra il 48.5% e il 49%.\n\nCoefficiente angolare (b):\n\nIl coefficiente angolare rappresenta l‚Äôeffetto dell‚Äôattrattivit√† dei genitori sulla percentuale di nascite femminili.\nGelman e Weakliem (2009) scelgono una distribuzione normale centrata a 0 con una deviazione standard di 0.2. Questo riflette l‚Äôassenza di una forte convinzione a priori che l‚Äôattrattivit√† sia correlata in modo robusto con il sesso del neonato. Il valore della deviazione standard di 0.2 indica che ci si aspetta che il coefficiente possa variare tra -0.2 e 0.2. Dato che la variabile predittiva (l‚Äôattrattivit√†) ha un intervallo di 4 punti, questa scelta implica che l‚Äôeffetto massimo atteso dell‚Äôattrattivit√† sulla percentuale di nascite femminili sia di ¬±0.8 punti percentuali, confrontando la categoria di attrattivit√† pi√π alta con quella pi√π bassa.\n\n\nQuesti prior debolmente informativi aiutano a guidare l‚Äôanalisi, integrando l‚Äôinformazione che la percentuale di nascite femminili √® molto stabile e suggerendo che, se c‚Äô√® un effetto dell‚Äôattrattivit√†, esso √® probabile che sia piuttosto piccolo.\nCompiliamo e stampiamo il modello che include i prior debolmente informativi.\n\nstan_file_ip = os.path.join(project_directory, \"stan\", \"sex_ratio_informative_prior.stan\")\nmodel2 = CmdStanModel(stan_file=stan_file_ip)\nprint(model2.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(48.8, 0.5);\n  beta ~ normal(0, 0.2);\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nEseguiamo il campionamento.\n\nfit2 = model2.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori.\n\naz.summary(fit2, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n48.828\n0.487\n47.879\n49.715\n0.006\n0.004\n6402.0\n5373.0\n1.0\n\n\nbeta\n0.028\n0.201\n-0.352\n0.395\n0.002\n0.002\n7334.0\n5464.0\n1.0\n\n\nsigma\n5.696\n3.290\n2.294\n10.366\n0.060\n0.049\n6248.0\n3964.0\n1.0\n\n\n\n\n\n\n\n\nSi osserva che, quando vengono utilizzati prior debolmente informativi, l‚Äôeffetto dell‚Äôattrattivit√† dei genitori risulta sostanzialmente nullo.\nI due grafici seguenti mostrano la variabilit√† della retta di regressione stimata dal modello bayesiano sia con prior non informativi che con prior informativi. Nel caso di prior non informativi, nonostante l‚Äôampia variabilit√† nella stima della pendenza della retta di regressione, emerge una lieve coerenza che suggerisce una relazione positiva molto debole. Al contrario, con prior debolmente informativi, la pendenza della retta di regressione stimata dal modello bayesiano risulta chiaramente piatta, eliminando qualsiasi incertezza.\n\n# Analisi dei risultati\nfit_bayes = [fit1, fit2]\n\nfor k, fit in enumerate(fit_bayes):\n    sims = fit.draws_pd()\n    coef_est = sims.median()\n    b_se = 1.483 * np.median(np.abs(sims[\"beta\"] - coef_est[\"beta\"]))\n\n    plt.figure(figsize=(10, 5))\n\n    # Plot delle simulazioni posteriori\n    plt.subplot(1, 2, 1)\n    plt.plot(sims[\"alpha\"], sims[\"beta\"], \"o\", markersize=2)\n    plt.xlabel(\"Intercept, a\")\n    plt.ylabel(\"Slope, b\")\n    plt.title(\n        f\"Posterior simulations under {'default prior' if k == 0 else 'informative prior'}\"\n    )\n\n    # Plot dei dati grezzi e della linea di regressione\n    plt.subplot(1, 2, 2)\n    plt.plot(x, y, \"o\", color=\"blue\", markersize=5)  \n    plt.ylim(43, 57)\n    plt.xlabel(\"Attractiveness of parent\")\n    plt.ylabel(\"Percentage of girl babies\")\n    plt.title(\n        f\"{'Least-squares regression line and\\nposterior uncertainty given default prior' if k == 0 else 'Bayes estimated regression line and\\nposterior uncertainty given informative prior'}\"\n    )\n    plt.yticks([45, 50, 55], [f\"{i}%\" for i in [45, 50, 55]])\n\n    # Aggiunta delle linee di regressione dai campioni posteriori\n    for i in range(100):\n        plt.plot(\n            x, sims[\"alpha\"].iloc[i] + sims[\"beta\"].iloc[i] * x, color=\"gray\", lw=0.5\n        )\n\n    # Linea di regressione basata sui valori mediani stimati\n    plt.plot(x, coef_est[\"alpha\"] + coef_est[\"beta\"] * x, color=\"black\", lw=2)\n\n    plt.tight_layout()\n    plt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_32471/2498333150.py:40: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_32471/2498333150.py:40: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_beauty_sex_power.html#considerazioni-conclusive",
    "href": "chapters/linear_models/02_beauty_sex_power.html#considerazioni-conclusive",
    "title": "58¬† Bellezza, sesso e potere",
    "section": "58.4 Considerazioni Conclusive",
    "text": "58.4 Considerazioni Conclusive\nL‚Äôanalisi delle relazioni tra bellezza e proporzione di nascite femminili nei campioni di piccole dimensioni mette in luce l‚Äôimportanza di considerare la potenza statistica e l‚Äôuso di prior informativi nei modelli statistici. In studi con campioni ridotti, c‚Äô√® un rischio notevole di ottenere risultati che, pur sembrando indicativi di un effetto, sono in realt√† frutto del caso e non rappresentano una realt√† sottostante. Questo fenomeno √® reso pi√π insidioso dall‚Äôattuale pratiche delle pubblicazioni scientifiche che molto spesso selezionano gli studi da pubblicare solo sulla presenza di effetti ‚Äústatisticamente significativi‚Äù, e che tendono a favorire e amplificare risultati che sembrano innovativi o controintuitivi, anche quando questi risultati non sono supportati da solide evidenze statistiche.\nGelman e Weakliem (2009) sottolineano che l‚Äôuso di prior debolmente informativi, come illustrato nel presente modello bayesiano, rappresenta un approccio metodologico che pu√≤ aiutare a contrastare queste problematiche. Ad esempio, quando vengono applicati prior debolmente informativi, l‚Äôeffetto dell‚Äôattrattivit√† dei genitori sulla proporzione di nascite femminili emerge come sostanzialmente nullo, evidenziando come l‚Äôapparente effetto osservato in modelli meno rigorosi possa essere semplicemente un artefatto dovuto a fluttuazioni casuali. Questo non solo rende pi√π chiaro il vero segnale presente nei dati, ma aiuta anche a prevenire l‚Äôinterpretazione errata dei risultati.\nInoltre, Gelman e Weakliem (2009) mettono in evidenza come le limitazioni legate alla potenza statistica siano spesso ignorate nella pratica di ricerca, portando a stime degli effetti sovrastimate, specialmente in studi con campioni piccoli ‚Äì si veda il Capitolo 97. Questo problema √® accentuato dalla tendenza della comunit√† scientifica a privilegiare risultati sensazionali, che possono far emergere ipotesi infondate come verit√† accettate. L‚Äôesempio del rapporto tra bellezza e sex-ratio mostra come questi errori possano condurre a una distorsione della conoscenza scientifica, con conseguenze che vanno ben oltre l‚Äôambito accademico.\nPer contrastare questi problemi, √® essenziale promuovere una maggiore trasparenza nel processo di revisione e pubblicazione scientifica, cos√¨ come un uso pi√π diffuso di metodi statistici che incorporino la conoscenza a priori e considerino la potenza statistica in tutte le fasi del processo di ricerca. Solo attraverso un approccio pi√π rigoroso e critico possiamo sperare di ridurre la diffusione di affermazioni infondate e migliorare la qualit√† complessiva della ricerca in psicologia e nelle scienze sociali. In questo contesto, l‚Äôadozione di modelli bayesiani con priori informativi rappresenta un passo avanti importante, permettendo ai ricercatori di evitare trappole comuni e di fornire risultati che riflettono pi√π accuratamente la realt√† dei fenomeni studiati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_beauty_sex_power.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_beauty_sex_power.html#informazioni-sullambiente-di-sviluppo",
    "title": "58¬† Bellezza, sesso e potere",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\narviz     : 0.18.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\nlogging   : 0.5.1.2\npingouin  : 0.5.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nGelman, Andrew, e David Weakliem. 2009. ¬´Of beauty, sex and power: Too little attention has been paid to the statistical challenges in estimating small effects¬ª. American Scientist 97 (4): 310‚Äì16.\n\n\nKanazawa, Satoshi. 2007. ¬´Beautiful parents have more daughters: A further implication of the generalized Trivers‚ÄìWillard hypothesis (gTWH)¬ª. Journal of Theoretical Biology 244 (1): 133‚Äì40.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>58</span>¬† <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html",
    "href": "chapters/linear_models/03_synt_sugar.html",
    "title": "59¬† Zucchero sintattico",
    "section": "",
    "text": "59.1 Introduzione\nI modelli lineari sono cos√¨ ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie √® bambi (BAyesian Model-Building Interface). bambi √® un pacchetto Python progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato √® un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm o brms. bambi si basa su PyMC, ma offre un‚ÄôAPI di livello superiore.\nIn questo capitolo esploreremo come condurre un‚Äôanalisi di regressione utilizzando bambi invece di cmdstan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#bayesian-model-building-interface",
    "href": "chapters/linear_models/03_synt_sugar.html#bayesian-model-building-interface",
    "title": "59¬† Zucchero sintattico",
    "section": "59.2 BAyesian Model-Building Interface",
    "text": "59.2 BAyesian Model-Building Interface\nLeggiamo i dati utilizzati nel capitolo precedente.\n\ndata_file = os.path.join(project_directory, \"data\", \"Howell_18.csv\")\ndf = pd.read_csv(data_file)\n\nGeneriamo un diagramma a dispersione:\n\nplt.plot(df[\"weight\"], df[\"height\"], \"x\")\nplt.xlabel(\"Weight\")\nplt.ylabel(\"Height\")\n\nText(0, 0.5, 'Height')\n\n\n\n\n\n\n\n\n\nBambi si concentra sui modelli di regressione, e questa specializzazione permette di adottare una sintassi pi√π semplice, conosciuta come sintassi di Wilkinson (Wilkinson e Rogers 1973).\nAd esempio, il modello \\(y = \\alpha + \\beta x + \\varepsilon\\) si implementa come segue:\na_model = bmb.Model(\"y ‚àº x\", data)\nNella sintassi di Wilkinson, il simbolo tilde (‚àº) separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra). In questo caso, stiamo specificando solo la media (\\(\\mu\\) nel modello lm di PyMC). Bambi assume di default che la distribuzione di verosimiglianza sia gaussiana, ma √® possibile modificarla tramite l‚Äôargomento family.\nSe desideriaamo escludere l‚Äôintercetta dal modello, possiamo farlo in questo modo:\nno_intercept_model = bmb.Model(\"y ‚àº 0 + x\", data)\nOppure in questo modo:\nno_intercept_model = bmb.Model(\"y ‚àº -1 + x\", data)\nPer includere ulteriori variabili nel modello, possiamo procedere cos√¨:\nmodel_2 = bmb.Model(\"y ‚àº x + z\", data)\nBambi consente anche di includere effetti a livello di gruppo (gerarchici). Ad esempio, se desideriamo un modello ad effetti misti nel quale abbiamo un effetto diverso di \\(x\\) in ciascun gruppo g, possiamo usare la seguente sintassi:\nmodel_h = bmb.Model(\"y ‚àº x + z + (x | g)\", data)\nLa sintassi delle formule non specifica le distribuzioni a priori, ma solo come le variabili dipendenti e indipendenti sono collegate. Bambi definir√† automaticamente delle distribuzioni a priori debolmente informative per noi.\nInoltre, Bambi implementa di default delle distribuzioni a priori debolmente informative, rendendo superflua la loro definizione esplicita. Tuttavia, se preferisci avere un maggiore controllo, possiamo specificarle manualmente.\nPer replicare il modello descritto nel capitolo precedente, possiamo utilizzare la seguente istruzione:\n\ndf[\"weight_c\"] = df[\"weight\"] - np.mean(df[\"weight\"])\n\nmodel = bmb.Model(\"height ~ weight_c\", df)\n\nSul lato sinistro della tilde (‚àº), abbiamo la variabile dipendente, e sul lato destro, le variabili indipendenti. Con questa sintassi, stiamo semplicemente specificando la media (Œº nel modello lm di PyMC). Per impostazione predefinita, Bambi assume che la verosimiglianza sia gaussiana; √® possibile modificarla con l‚Äôargomento family. La sintassi della formula non specifica la distribuzione delle priors, ma solo come sono associate le variabili dipendenti e indipendenti. Bambi definir√† automaticamente delle priors (molto) debolmente informative per noi. Possiamo ottenere ulteriori informazioni stampando il modello Bambi.\n\nprint(model)\n\n       Formula: height ~ weight_c\n        Family: gaussian\n          Link: mu = identity\n  Observations: 352\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 154.5971, sigma: 19.3283)\n            weight_c ~ Normal(mu: 0.0, sigma: 2.9978)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 7.7313)\n\n\nLa descrizione inizia mostrando la formula utilizzata per definire il modello, y ~ x, che indica come la variabile dipendente y √® predetta dalla variabile indipendente x in una relazione lineare. La seconda riga specifica che si sta utilizzando una distribuzione gaussiana (normale) come funzione di verosimiglianza per il modello, il che implica l‚Äôassunzione che i residui del modello (le differenze tra i valori osservati e i valori predetti) seguano una distribuzione normale.\nLa terza riga menziona la funzione di collegamento, in questo caso l‚Äôidentit√†, che non applica alcuna trasformazione al valore atteso della variabile dipendente. Questo √® caratteristico dei modelli lineari, dove il valore atteso di y √® direttamente modellato come una combinazione lineare delle variabili indipendenti (E(Y) = \\alpha + \\beta x). √à importante notare che, nei modelli lineari generalizzati, la funzione di collegamento gioca un ruolo cruciale nel collegare il valore atteso della variabile risposta alla combinazione lineare delle variabili predittive.\nSegue il numero di osservazioni utilizzate per adattare il modello, indicando la dimensione del dataset su cui il modello √® stato allenato.\nLa parte successiva dell‚Äôoutput dettaglia i priors utilizzati per i parametri del modello. In Bambi, i priors sono assunzioni a priori sui valori dei parametri prima di osservare i dati. Questi priors aiutano a guidare l‚Äôinferenza, soprattutto in presenza di dati limitati o per regolarizzare il modello. L‚Äôintercetta (Intercept) ha un prior normale con media (mu) 2.0759 e deviazione standard (sigma) 3.9401, indicando la posizione iniziale attesa della linea di regressione e quanto ci si aspetta che vari. Il coefficiente della variabile x ha anch‚Äôesso un prior normale, centrato in zero con una deviazione standard ampia (6.8159), riflettendo incertezza su quale possa essere il vero effetto di x su y senza presupporre una direzione specifica dell‚Äôeffetto.\nLa sezione finale riguarda i parametri ausiliari del modello, in questo caso il parametro sigma della distribuzione gaussiana, che rappresenta la deviazione standard dei residui del modello. Questo ha un prior HalfStudentT, che √® una distribuzione che ammette solo valori positivi (essendo la deviazione standard sempre positiva), con un grado di libert√† (nu) 4.0 e una scala (sigma) 0.791. Questo prior √® scelto per la sua flessibilit√† e la capacit√† di gestire dati con potenziali outlier.\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nSe vogliamo procedere con un‚Äôispezione visiva dei prior dei parametri del modello usiamo:\n\n_ = model.plot_priors()\n\nSampling: [Intercept, sigma, weight_c]\n\n\n\n\n\n\n\n\n\nEseguiamo il campionamento MCMC.\n\nidata = model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\nLe distribuzioni a posteriori dei parametri e i trace plot si ottengono con la seguente istruzione.\n\n_ = az.plot_trace(idata)\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(idata, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n154.59\n0.27\n154.07\n155.07\n0.0\n0.0\n4100.84\n2810.35\n1.0\n\n\nsigma\n5.11\n0.20\n4.74\n5.46\n0.0\n0.0\n4391.39\n2834.61\n1.0\n\n\nweight_c\n0.90\n0.04\n0.82\n0.98\n0.0\n0.0\n4522.69\n3091.93\n1.0\n\n\n\n\n\n\n\n\nI dati replicano quelli ottenuti in precedenza.\nPossiamo anche generare un grafico che descrive l‚Äôincertezza a posteriori delle predizioni del modello.\nLa funzione plot_predictions del pacchetto Bambi serve per facilitare l‚Äôinterpretazione dei modelli di regressione attraverso la visualizzazione grafica. Il metodo appartiene al sottomodulo interpret di Bambi e si concentra sulla rappresentazione delle previsioni generate dal modello.\nQuando si esegue la funzione plot_predictions con i parametri specificati (model, idata, [\"weight_c\"]), essa produce un grafico che sintetizza le previsioni del modello in relazione a una o pi√π variabili indipendenti. In questo caso, il parametro model indica il modello di regressione Bayesiana costruito con Bambi, idata rappresenta i dati inferenziali (ottenuti tramite il fit del modello), e [\"weight_c\"] specifica la variabile indipendente da considerare per il grafico.\n\nbmb.interpret.plot_predictions(model, idata, [\"weight_c\"]);\n\nDefault computed for conditional variable: weight_c\n\n\n\n\n\n\n\n\n\nIl grafico generato da questa funzione illustra due aspetti principali:\n\nMedia Posteriore di y: Il grafico include una linea che rappresenta la media posteriore della variabile dipendente (height) rispetto alla variabile indipendente specificata (weight_c). La media posteriore √® una stima centrale delle previsioni del modello, che riflette la posizione pi√π probabile dei valori di height data l‚Äôevidenza fornita dai dati.\nIntervallo di Densit√† pi√π Alta del 94%: Attorno alla retta della media posteriore, il grafico mostra anche un‚Äôarea evidenziata che rappresenta l‚Äôintervallo di densit√† pi√π alta (HDI) del 94%. Questo intervallo √® un modo per quantificare l‚Äôincertezza delle previsioni del modello. L‚ÄôHDI del 94% significa che, data la distribuzione posteriore delle previsioni di height, c‚Äô√® il 94% di probabilit√† che il valore vero di height cada all‚Äôinterno di questo intervallo per un dato valore di weight_c. Questo fornisce una misura visiva dell‚Äôincertezza associata alle stime del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "59¬† Zucchero sintattico",
    "section": "59.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "59.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Aug 14 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\ncmdstanpy : 1.2.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\npandas    : 2.2.2\nnumpy     : 1.26.4\nlogging   : 0.5.1.2\nbambi     : 0.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nWilkinson, GN, e CE Rogers. 1973. ¬´Symbolic description of factorial models for analysis of variance¬ª. Journal of the Royal Statistical Society Series C: Applied Statistics 22 (3): 392‚Äì99.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>59</span>¬† <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_two_means.html",
    "href": "chapters/linear_models/04_two_means.html",
    "title": "60¬† Confronto tra le medie di due gruppi",
    "section": "",
    "text": "Introduzione\nNel Capitolo 50, abbiamo discusso l‚Äôinferenza sulla differenza tra le medie di due campioni indipendenti utilizzando un approccio bayesiano. In quell‚Äôanalisi, i due gruppi sono stati considerati entit√† distinte e abbiamo calcolato la differenza tra le loro medie.\nUn‚Äôalternativa consiste nell‚Äôuso di un modello di regressione. In questo caso, invece di calcolare direttamente la differenza tra le medie, si introduce una variabile indicatrice (‚Äúdummy‚Äù) nel modello di regressione. La variabile indicatrice codifica l‚Äôappartenenza ai gruppi con valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto:\n\\[\nx_i =\n\\begin{cases}\n0 & \\text{se l'osservazione } i \\text{ √® nel gruppo 0} \\\\\n1 & \\text{se l'osservazione } i \\text{ √® nel gruppo 1}\n\\end{cases}\n\\]\nIl modello di regressione stima un coefficiente per la variabile indicatrice, che rappresenta la differenza tra le medie dei due gruppi. In questo modo, la variabile ‚Äúdummy‚Äù funge da indicatore del gruppo, permettendo di stimare in modo efficiente la differenza tra le medie.\nEntrambi i metodi sono validi per analizzare la differenza tra le medie di due gruppi indipendenti; tuttavia, il modello di regressione offre maggiore flessibilit√† e potenzialit√† di espansione. Questo modello permette di includere ulteriori variabili esplicative, ampliando la nostra capacit√† di comprendere i fattori che influenzano il risultato d‚Äôinteresse. Tale versatilit√† √® particolarmente vantaggiosa per esaminare come altre variabili possano influire sulla differenza tra le medie o per analizzare pi√π variabili contemporaneamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/04_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "60¬† Confronto tra le medie di due gruppi",
    "section": "60.1 Regressione bayesiana per due gruppi indipendenti",
    "text": "60.1 Regressione bayesiana per due gruppi indipendenti\nNel contesto bayesiano, il modello di regressione pu√≤ essere formulato nel modo seguente:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta x_i.\n\\end{align*}\n\\]\nIn questa rappresentazione:\n\n\\(\\alpha\\) agisce come intercetta,\n\\(\\beta\\) √® il coefficiente angolare o la pendenza,\n\\(\\sigma\\) √® l‚Äôerrore standard associato alle osservazioni.\n\nNel caso specifico, la variabile \\(x\\) √® una variabile indicatrice che assume i valori 0 o 1. Per il gruppo identificato da \\(x = 0\\), il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nQuesto implica che \\(\\alpha\\) rappresenta la media del gruppo codificato come \\(x = 0\\).\nPer il gruppo contrassegnato da \\(x = 1\\), il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta.\n\\end{align*}\n\\]\nIn termini dei parametri del modello, la media per il gruppo codificato con \\(x = 1\\) √® rappresentata da \\(\\alpha + \\beta\\). In questa configurazione, \\(\\beta\\) indica la differenza tra la media del gruppo con $ x = 1 $ e quella del gruppo con \\(x = 0\\). Di conseguenza, l‚Äôanalisi della differenza tra le medie dei due gruppi pu√≤ essere effettuata attraverso l‚Äôinferenza sul parametro \\(\\beta\\). In sintesi, per confrontare le medie dei due gruppi indipendenti, si pu√≤ esaminare la distribuzione a posteriori di \\(\\beta\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_two_means.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/04_two_means.html#un-esempio-illustrativo",
    "title": "60¬† Confronto tra le medie di due gruppi",
    "section": "60.2 Un esempio illustrativo",
    "text": "60.2 Un esempio illustrativo\nEsaminiamo nuovamente i dati relativi al quoziente di intelligenza dei bambini le cui madri hanno completato oppure no la scuola superiore. Ci poniamo il problema di replicare i risultati ottenuti in precedenza usando l‚Äôanalisi di regressione.\nLeggiamo i dati:\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\n\nkidiq.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nCi sono 93 bambini la cui madre non ha completato le superiori e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\nsummary_stats = [st.mean, st.stdev]\nkidiq.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\n\n\naz.plot_violin(\n    {\n        \"mom_hs=0\": kidiq.loc[kidiq.mom_hs == 0, \"kid_score\"],\n        \"mom_hs=1\": kidiq.loc[kidiq.mom_hs == 1, \"kid_score\"],\n    }\n);\n\n\n\n\n\n\n\n\nIniziamo l‚Äôinferenza statistica sulla differenza tra le medie dei due gruppi utilizzando bambi. Questo pacchetto offre una sintassi semplice per formulare il modello bayesiano di interesse. Un altro vantaggio √® che bambi selezioner√† automaticamente le distribuzioni a priori appropriate per i parametri del modello, rendendo il processo pi√π intuitivo.\nIl modello di regressione sopra descritto si scrive nel modo seguente.\n\nmod = bmb.Model(\"kid_score ~ mom_hs\", kidiq)\n\nEffettuiamo il campionamento.\n\nresults = mod.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nPossiamo ispezionare le propriet√† del modello nel modo seguente.\n\nmod\n\n       Formula: kid_score ~ mom_hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 86.7972, sigma: 110.1032)\n            mom_hs ~ Normal(mu: 0.0, sigma: 124.2132)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nLe distribuzioni a priori utilizzate di default dal modello possono essere visualizzate nel modo seguente.\n\n_ = mod.plot_priors()\n\nSampling: [Intercept, mom_hs, sigma]\n\n\n\n\n\n\n\n\n\nPer ispezionare il nostro posteriore e il processo di campionamento possiamo utilizzare az.plot_trace(). L‚Äôopzione kind='rank_vlines' ci fornisce una variante del grafico di rango che utilizza linee e punti e ci aiuta a ispezionare la stazionariet√† delle catene. Poich√© non c‚Äô√® un modello chiaro o deviazioni serie dalle linee orizzontali, possiamo concludere che le catene sono stazionarie.\n\n_ = az.plot_trace(results)\n\n\n\n\n\n\n\n\n\naz.summary(results, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n77.55\n2.01\n73.68\n81.27\n0.03\n0.02\n4272.34\n2738.90\n1.0\n\n\nmom_hs\n11.76\n2.25\n7.74\n16.17\n0.03\n0.03\n4169.77\n2921.90\n1.0\n\n\nsigma\n19.88\n0.66\n18.69\n21.12\n0.01\n0.01\n4540.09\n3039.19\n1.0\n\n\n\n\n\n\n\n\nIl parametro ‚ÄúIntercept‚Äù rappresenta la stima a posteriori del punteggio del QI per il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 0. La media a posteriori di questo gruppo √® di 77.6, che √® praticamente identica al valore campionario corrispondente.\nIl parametro ‚Äúmom_hs‚Äù corrisponde alla stima a posteriori della differenza nei punteggi del QI tra il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 1 e il gruppo codificato con ‚Äúmom_hs‚Äù uguale a 0. Anche in questo caso, la differenza a posteriori di 11.8 tra le medie dei due gruppi √® molto simile alla differenza campionaria tra le medie dei due gruppi. La parte importante della tabella riguarda l‚Äôintervallo di credibilit√† al 94%, che √® [7.5, 16.2], e che non include lo 0. Ci√≤ significa che, con un livello di certezza soggettiva del 94%, possiamo essere sicuri che il QI dei bambini le cui madri hanno il diploma superiore sar√† maggiore (in media) di almeno 7.5 punti, e tale differenza pu√≤ arrivare fino a 16.2 punti, rispetto al QI dei bambini le cui madri non hanno completato la scuola superiore.\nSe confrontiamo questi risultati con quelli ottenuti nel capitolo {ref}two_groups_comparison_notebook, notiamo che sono quasi identici. Le piccole differenze che si osservano possono essere attribuite sia all‚Äôapprossimazione numerica sia al fatto che nel modello precedente abbiamo consentito deviazioni standard diverse per i due gruppi, mentre nel caso attuale abbiamo assumo la stessa variabilit√† per entrambi i gruppi.\nUsiamo ora l‚Äôapproccio di massima verosimiglianza.\n\nlm = pg.linear_regression(kidiq[\"mom_hs\"], kidiq[\"kid_score\"])\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n77.55\n2.06\n37.67\n0.0\n0.06\n0.05\n73.50\n81.59\n\n\n1\nmom_hs\n11.77\n2.32\n5.07\n0.0\n0.06\n0.05\n7.21\n16.34\n\n\n\n\n\n\n\n\nI risultati sono quasi identici a quelli trovati con l‚Äôapproccio bayesiano.\nIl test bayesiano di ipotesi pu√≤ essere svolto, per esempio, calcolando la probabilit√† che \\(\\beta_{mean\\_diff} &gt; 0\\). Questa probabilit√† √® 1, per cui concludiamo che la media del gruppo codificato con ‚Äúmom_hs = 1‚Äù √® maggiore della media del gruppo codificato con ‚Äúmom_hs = 0‚Äù.\n\naz.plot_posterior(results, var_names=\"mom_hs\", ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\nUn valore numerico si ottiene nel modo seguente.\n\nresults.posterior\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 104kB\nDimensions:    (chain: 4, draw: 1000)\nCoordinates:\n  * chain      (chain) int64 32B 0 1 2 3\n  * draw       (draw) int64 8kB 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\nData variables:\n    Intercept  (chain, draw) float64 32kB 80.81 75.64 77.14 ... 77.32 77.43\n    mom_hs     (chain, draw) float64 32kB 7.963 13.55 10.86 ... 9.91 10.79 12.88\n    sigma      (chain, draw) float64 32kB 19.3 20.92 20.21 ... 19.26 19.12 20.3\nAttributes:\n    created_at:                  2024-07-30T09:47:03.975197+00:00\n    arviz_version:               0.18.0\n    inference_library:           numpyro\n    inference_library_version:   0.15.1\n    sampling_time:               1.772095\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (3)Intercept(chain, draw)float6480.81 75.64 77.14 ... 77.32 77.43array([[80.81483632, 75.63639888, 77.14478867, ..., 75.72595312,\n        77.5423379 , 77.5423379 ],\n       [79.368775  , 79.97070154, 75.33769344, ..., 74.13336094,\n        80.08358757, 81.84041564],\n       [78.28138375, 76.8210174 , 80.13760742, ..., 77.78397138,\n        76.51013651, 78.79410939],\n       [82.03066779, 73.96217327, 76.20589234, ..., 78.7092881 ,\n        77.31896306, 77.4298698 ]])mom_hs(chain, draw)float647.963 13.55 10.86 ... 10.79 12.88array([[ 7.96339175, 13.55420539, 10.86033092, ..., 13.62558002,\n        11.84062159, 11.84062159],\n       [ 9.35003845,  9.9135694 , 13.79285124, ..., 16.97280286,\n         8.09604384,  5.89320385],\n       [12.97640867, 10.9104082 ,  8.77804029, ..., 11.30792615,\n        12.21403645, 11.0726028 ],\n       [ 5.64421123, 16.74073888, 13.98410457, ...,  9.91029743,\n        10.78713598, 12.8766417 ]])sigma(chain, draw)float6419.3 20.92 20.21 ... 19.12 20.3array([[19.29803974, 20.92199049, 20.21123626, ..., 20.58998924,\n        20.11170957, 20.11170957],\n       [17.91763444, 20.64037291, 19.88999257, ..., 20.09847731,\n        19.51073177, 19.25492589],\n       [19.99147265, 19.78098389, 19.27150942, ..., 20.86967072,\n        19.83582888, 19.83827133],\n       [19.22442038, 20.07102966, 20.0293815 , ..., 19.26291194,\n        19.11822346, 20.29616769]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2024-07-30T09:47:03.975197+00:00arviz_version :0.18.0inference_library :numpyroinference_library_version :0.15.1sampling_time :1.772095tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.14.0\n\n\n\n# Probabiliy that posterior is &gt; 0\n(results.posterior[\"mom_hs\"] &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_two_means.html#parametrizzazione-alternativa",
    "href": "chapters/linear_models/04_two_means.html#parametrizzazione-alternativa",
    "title": "60¬† Confronto tra le medie di due gruppi",
    "section": "60.3 Parametrizzazione alternativa",
    "text": "60.3 Parametrizzazione alternativa\nConsideriamo adesso il caso in cui, per distinguere i gruppi, anzich√© una variabile dicotomica, con valori 0 e 1, usiamo una variabile qualitativa con i nomi dei due gruppi. Introduciamo questa nuova variabile nel data frame.\n\n# Add a new column 'hs' with the categories based on 'mom_hs'\nkidiq[\"hs\"] = kidiq[\"mom_hs\"].map({0: \"not_completed\", 1: \"completed\"})\nkidiq.tail()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\nhs\n\n\n\n\n429\n94\n0.0\n84.877412\n4\n21\nnot_completed\n\n\n430\n76\n1.0\n92.990392\n4\n23\ncompleted\n\n\n431\n50\n0.0\n94.859708\n2\n24\nnot_completed\n\n\n432\n88\n1.0\n96.856624\n2\n21\ncompleted\n\n\n433\n70\n1.0\n91.253336\n2\n25\ncompleted\n\n\n\n\n\n\n\n\nAdattiamo il modello ai dati, usando questa nuova variabile e forziamo a zero l‚Äôintercetta che Bambi aggiunge di default al modello.\n\nmod_2 = bmb.Model(\"kid_score ~ 0 + hs\", kidiq)\nresults_2 = mod_2.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nIspezionare il modello e le distribuzioni a priori.\n\nmod_2\n\n       Formula: kid_score ~ 0 + hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            hs ~ Normal(mu: [0. 0.], sigma: [124.2132 124.2132])\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\n_ = mod_2.plot_priors()\n\nSampling: [hs, sigma]\n\n\n\n\n\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri del modello.\n\n_ = az.plot_trace(results_2)\n\n\n\n\n\n\n\n\n\naz.summary(results_2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nhs[completed]\n89.297\n1.089\n87.209\n91.231\n0.016\n0.012\n4429.0\n3149.0\n1.0\n\n\nhs[not_completed]\n77.506\n1.988\n73.744\n81.191\n0.031\n0.022\n4102.0\n2940.0\n1.0\n\n\nsigma\n19.881\n0.660\n18.647\n21.112\n0.010\n0.007\n4216.0\n2870.0\n1.0\n\n\n\n\n\n\n\n\nIn questo caso, notiamo che abbiamo ottenuto le distribuzioni a posteriori per i parametri hs[completed] e hs[not_completed] che corrispondono alle medie dei due gruppi. Tali distribuzioni a posteriori illustrano direttamente l‚Äôincertezza sulla media dei due gruppi, alla luce della variabilit√† campionaria e delle nostre credenze a priori.\nPossiamo svolgere il test bayesiano di ipotesi sulla differenza tra le due medie a posteriori nel modo seguente.\n\npost_group = results_2.posterior[\"hs\"]\ndiff = post_group.sel(hs_dim=\"completed\") - post_group.sel(hs_dim=\"not_completed\")\naz.plot_posterior(diff, ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\n\n# Probabiliy that posterior is &gt; 0\n(post_group &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "60¬† Confronto tra le medie di due gruppi",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nbambi     : 0.14.0\nnumpy     : 1.26.4\npandas    : 2.2.2\npingouin  : 0.5.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>60</span>¬† <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_prediction.html",
    "href": "chapters/linear_models/05_prediction.html",
    "title": "61¬† Predizione e inferenza",
    "section": "",
    "text": "Introduzione\nGelman, Hill, e Vehtari (2021) osservano che l‚Äôinferenza bayesiana si sviluppa in tre passaggi fondamentali, che vanno oltre la stima classica. In primo luogo, i dati e il modello vengono combinati per formare una distribuzione a posteriori, che solitamente viene riassunta tramite le distribuzioni a posteriori dei parametri del modello. In secondo luogo, √® possibile propagare l‚Äôincertezza presente in questa distribuzione, ottenendo previsioni basate su simulazioni per risultati non osservati o futuri, tenendo conto dell‚Äôincertezza nei parametri del modello. Infine, √® possibile integrare ulteriori informazioni nel modello utilizzando una distribuzione a priori. Questo capitolo si concentra sui temi della previsione e dell‚Äôinferenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_prediction.html#predizione",
    "href": "chapters/linear_models/05_prediction.html#predizione",
    "title": "61¬† Predizione e inferenza",
    "section": "61.1 Predizione",
    "text": "61.1 Predizione\nPer discutere i temi della predizione e dell‚Äôinferenza bayesiana nel contesto del modello bayesiano di regressione lineare bivariata, esamineremo nuovamente il set di esaminati nel Capitolo 57 e relativi alla relazione tra Tense Arousal e ansia di stato.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"affect.csv\")\n\n# Leggere il file CSV in un DataFrame pandas\ndata = pd.read_csv(file_path)\n\n# Selezionare le colonne state1 e TA1\ndf = data[[\"state1\", \"TA1\"]]\n\nConsideriamo il modello bayesiano di regressione lineare bivariata che include prior uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) che abbiamo discusso nel Capitolo 57. Compiliamo e stampiamo tale modello.\n\nstan_file = os.path.join(project_directory, 'stan', 'arousal_model_prior_raw.stan')\nmodel1 = CmdStanModel(stan_file=stan_file)\nprint(model1.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 5.0);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 5.0);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = {\n    \"N\": len(df[\"TA1\"]),\n    \"x\": df[\"state1\"],\n    \"y\": df[\"TA1\"]\n}\n\nEseguiamo il campionamento MCMC.\n\nfit1 = model1.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit1, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.469\n1.249\n-0.815\n3.900\n0.027\n0.019\n2109.0\n2603.0\n1.0\n\n\nbeta\n0.269\n0.029\n0.212\n0.322\n0.001\n0.000\n2078.0\n2610.0\n1.0\n\n\nsigma\n2.714\n0.226\n2.302\n3.148\n0.004\n0.003\n3571.0\n3461.0\n1.0\n\n\n\n\n\n\n\n\nIl punto importante qui √® che la distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere trasformati in vari modi. Ad esempio, possiamo calcolare la predizione a posteriori del modello lineare per il valore atteso di Tense Arousal quando l‚Äôansia di stato √® pari a 30 usando il seguente comando nel blocco generated quantities:\npred = alpha + beta * 30;\nModifichiamo il modello Stan che include la specifica di distribuzioni debolmente informative sui parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) per aggiungere questo comando nel blocco generated quantities e compiliamo il modello.\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model2.stan\")\nmodel2 = CmdStanModel(stan_file=stan_file)\nprint(model2.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 5.0);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 5.0);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  real pred; // predizione\n  \n  pred = alpha + beta * 30;\n}\n\n\n\nIn questo modello Stan aggiornato, il blocco generated quantities calcola la predizione a posteriori pred per una variabile predittore con valore 30. Questa modifica permette di ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore.\nEseguiamo il campionamento.\n\nfit2 = model2.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la stima a posteriori del valore atteso di Tense Arousal quando l‚Äôansia di stato √® pari a 30. Questa analisi fornir√† sia una stima puntuale di Tense Arousal che una misura dell‚Äôincertezza associata, rappresentata dall‚Äôintervallo di credibilit√† al livello di confidenza scelto.\n\naz.summary(fit2, var_names=([\"pred\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npred\n9.544\n0.442\n8.713\n10.381\n0.008\n0.005\n3443.0\n4427.0\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_prediction.html#quantificazione-dellincertezza",
    "href": "chapters/linear_models/05_prediction.html#quantificazione-dellincertezza",
    "title": "61¬† Predizione e inferenza",
    "section": "61.2 Quantificazione dell‚Äôincertezza",
    "text": "61.2 Quantificazione dell‚Äôincertezza\nPer quantificare l‚Äôincertezza complessiva nelle predizioni del modello, possiamo calcolare la distribuzione a posteriori delle predizioni per tutti i valori di \\(x\\) del campione. Questo ci permette di ottenere sia le stime puntuali delle predizioni sia una misura dell‚Äôincertezza associata.\nPer fare ci√≤, modifichiamo il blocco generated quantities nel seguente modo:\ngenerated quantities {\n  vector[N] y_rep; // Predizioni a posteriori per ciascun valore di x\n  \n  for (n in 1:N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\nEsaminiamo le modifiche:\n\nDichiarazione del vettore y_rep:\n\nvector[N] y_rep;: Dichiara un vettore y_rep di lunghezza N per contenere le predizioni a posteriori per ciascun valore di x.\n\nCiclo for per generare le predizioni:\n\nfor (n in 1:N): Itera su tutte le osservazioni.\ny_rep[n] = normal_rng(alpha + beta * x[n], sigma);: Per ogni valore di x[n], genera una predizione dalla distribuzione normale con media alpha + beta * x[n] e deviazione standard sigma. La funzione normal_rng genera numeri casuali dalla distribuzione normale specificata, rappresentando l‚Äôincertezza nelle predizioni.\n\n\nQuesto approccio consente di ottenere la distribuzione a posteriori delle predizioni, fornendo una visione completa dell‚Äôincertezza associata. Dalla distribuzione a posteriori di y_rep, possiamo calcolare sia la stima puntuale (come la media o la mediana delle predizioni) sia gli intervalli di credibilit√† (come l‚Äôintervallo al 95%) per ogni valore di x. Questo offre una misura dell‚Äôincertezza delle predizioni, riflettendo la variabilit√† e l‚Äôaffidabilit√† del modello.\nModifichiamo il modello imponendo distribuzioni a priori debolmente informative sui parametri:\n\nPer \\(\\alpha\\) e \\(\\beta\\), utilizziamo una distribuzione Normale centrata su 0 con una deviazione standard di 2.\nPer \\(\\sigma\\), utilizziamo una distribuzione di Cauchy centrata su 0 con una scala di 2.\n\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model3.stan\")\nmodel3 = CmdStanModel(stan_file=stan_file)\nprint(model3.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 5.0);\n  beta ~ normal(0, 1.0);\n  sigma ~ cauchy(0, 1.0);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // variabili predette\n  \n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\nEseguiamo il campionamento.\n\nfit3 = model3.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori dei parametri.\n\naz.summary(fit3, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.436\n1.227\n-0.926\n3.694\n0.026\n0.020\n2185.0\n2421.0\n1.0\n\n\nbeta\n0.270\n0.029\n0.217\n0.324\n0.001\n0.000\n2050.0\n2391.0\n1.0\n\n\nsigma\n2.679\n0.219\n2.264\n3.070\n0.004\n0.003\n3724.0\n3418.0\n1.0\n\n\n\n\n\n\n\n\n\n61.2.1 Manipolare le Stime a Posteriori dei Parametri\nCostruiamo ora un grafico che rappresenta i valori osservati insieme alla linea di regressione stimata tramite il modello bayesiano. Al grafico aggiungeremo diverse linee di regressione, ciascuna orientata in base ai valori campionati casualmente dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\nPoniamoci dunque il problema di recuperare le stime a posteriori dei parametri dall‚Äôoggetto fit3, creato dal metodo sample(). La User‚Äôs Guide specifica quanto segue:\n\nThe sampler outputs are the set of per-chain Stan CSV files, a non-standard CSV file format. Each data row of the Stan CSV file contains the per-iteration estimate of the Stan model parameters, transformed parameters, and generated quantities variables.\n\nUtilizzando il metodo stan_variable(), possiamo ottenere un numpy.ndarray la cui struttura corrisponde a quella delle variabili del programma Stan, ossia i valori della distribuzione a posteriori di ciascun parametro. In questo caso, otteniamo i valori della distribuzione a posteriori di \\(\\alpha\\) e \\(\\beta\\):\n\n# Extract posterior samples\nalpha_samples = fit3.stan_variable(\"alpha\")\nbeta_samples = fit3.stan_variable(\"beta\")\n\nPer esempio, stampiamo i primi 20 valori di alpha_samples:\n\nprint(alpha_samples[0:20])\n\n[ 2.01713    2.37308    1.14274    2.80078    3.10586    1.77013\n  1.77256    0.529561   1.81511    0.0353212  0.125      0.722485\n -0.0975432 -0.364862   0.0669098 -1.44573   -2.34803   -1.87964\n -1.9525    -0.156463 ]\n\n\n\nlen(alpha_samples)\n\n8000\n\n\nAvendo ottenuto 8,000 stime della distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) (2,000 valori per ciascuna delle 4 catene), possiamo calcolare la stima puntuale a posteriori dei parametri nel seguente modo:\n\nmean_alpha = np.mean(alpha_samples)\nmean_beta = np.mean(beta_samples)\n\nprint(mean_alpha, mean_beta)\n\n1.4358008241905 0.26977196924999997\n\n\nPossiamo sovrapporre la retta di regressione al grafico a dispersione utilizzando le stime a posteriori dei parametri.\n\n# Plot y vs x\nx = df[\"state1\"] \nplt.scatter(\n    x, df[\"TA1\"], label=\"Data\", s=10\n)  # s is the size of the point\n\n# Draw lines from posterior samples\nfor i in range(300):  # assuming you have at least 300 samples\n    plt.plot(\n        x,\n        alpha_samples[i] + beta_samples[i] * x,\n        color=\"gray\",\n        linestyle=\"-\",\n        linewidth=0.5,\n        alpha=0.05,\n    )\n\n# Line using the mean of posterior estimates\nmean_alpha = np.mean(alpha_samples)\nmean_beta = np.mean(beta_samples)\ncolor_edge = \"#8f2727\"\nplt.plot(\n    x,\n    mean_alpha + mean_beta * x,\n    color=color_edge,\n    linewidth=2,\n    label=\"Mean Posterior Prediction\",\n)\n\n# Additional plot formatting\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Regression with Posterior Samples\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLe numerose linee di regressione presenti nel grafico visualizzano la nostra incertezza riguardo l‚Äôinclinazione esatta della linea di regressione principale. Tuttavia, il grafico mostra chiaramente che questa incertezza √® minima.\nPossiamo procedere in un altro modo per descrivere l‚Äôincertezza della stima. Anzich√© utilizzare le distribuzioni a posteriori di alpha e beta, possiamo utilizzare la distribuzione a posteriori di y_rep. Procedendo in questo modo otteniamo il grafico mostrato qui sotto.\nIn questo plot, la linea rossa rappresenta la media delle predizioni a posteriori, mentre l‚Äôarea grigia rappresenta l‚Äôintervallo di credibilit√† al 95%, mostrando l‚Äôincertezza delle predizioni del modello. Questo approccio fornisce una visione pi√π completa e realistica dell‚Äôincertezza nelle predizioni rispetto all‚Äôapproccio che utilizza solo alpha e beta.\n\n# Estrai i campioni posteriori di y_rep\ny_rep_samples = fit3.stan_variable(\"y_rep\")\n\n# Calcola la media e l'intervallo di credibilit√† (ad esempio, 95%) per y_rep\ny_rep_mean = np.mean(y_rep_samples, axis=0)\ny_rep_lower = np.percentile(y_rep_samples, 2.5, axis=0)\ny_rep_upper = np.percentile(y_rep_samples, 97.5, axis=0)\n\n# Plot y vs x\nx = df[\"state1\"]\ny = df[\"TA1\"]\nplt.scatter(x, y, label=\"Dati\", s=10)\n\n# Plot della media delle predizioni a posteriori\nplt.plot(x, y_rep_mean, color=color_edge, linewidth=2, label=\"Media delle predizioni\")\n\n# Plot dell'intervallo di credibilit√†\nplt.fill_between(\n    x,\n    y_rep_lower,\n    y_rep_upper,\n    color=\"gray\",\n    alpha=0.3,\n    label=\"Intervallo di credibilit√† 95%\",\n)\n\n# Formattazione del plot\nplt.xlabel(\"State Anxiety\")\nplt.ylabel(\"Tense Arousal\")\nplt.title(\"Incertezza delle predizioni del modello\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNel primo approccio, calcoliamo l‚Äôincertezza delle predizioni utilizzando le distribuzioni a posteriori di alpha e beta. Questo metodo consiste nel generare predizioni lineari per ciascun campione a posteriori di alpha e beta, tracciando quindi le linee di regressione risultanti. Questo ci permette di vedere come varia la linea di regressione in base alle incertezze nei parametri alpha e beta. Questo metodo visualizza come l‚Äôincertezza nei parametri del modello si traduce in incertezza nelle predizioni.\nNel secondo approccio, descriviamo l‚Äôincertezza delle predizioni utilizzando direttamente la distribuzione a posteriori di y_rep. In questo caso, generiamo predizioni per ciascun valore osservato di x nel modello Stan, tenendo conto delle distribuzioni a posteriori dei parametri del modello. Questo metodo visualizza direttamente l‚Äôincertezza nelle predizioni, tenendo conto delle variazioni nei dati osservati e delle distribuzioni a posteriori dei parametri.\nLe due descrizioni dell‚Äôincertezza delle predizioni del modello sono diverse perch√© riflettono aspetti differenti della distribuzione a posteriori:\n\nDistribuzione a posteriori di alpha e beta: Questo approccio considera solo l‚Äôincertezza nei parametri del modello (alpha e beta). Le linee di regressione tracciate variano in base a questi parametri, ma non tengono conto dell‚Äôincertezza residua (sigma).\nDistribuzione a posteriori di y_rep: Questo approccio include non solo l‚Äôincertezza nei parametri alpha e beta, ma anche l‚Äôincertezza residua (sigma). La distribuzione di y_rep riflette la variabilit√† totale nel modello, inclusa la variabilit√† nei dati osservati. Pertanto, l‚Äôincertezza nelle predizioni √® maggiore perch√© tiene conto di tutte le fonti di variabilit√†.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_prediction.html#verifica-predittiva-delle-distribuzioni-a-priori",
    "href": "chapters/linear_models/05_prediction.html#verifica-predittiva-delle-distribuzioni-a-priori",
    "title": "61¬† Predizione e inferenza",
    "section": "61.3 Verifica Predittiva delle Distribuzioni a Priori",
    "text": "61.3 Verifica Predittiva delle Distribuzioni a Priori\nLe verifiche predittive delle distribuzioni a priori (prior predictive checks) costituiscono una parte fondamentale del flusso di lavoro nella modellazione bayesiana. In sostanza, queste verifiche offrono due principali vantaggi:\n\nConsentono di verificare se si sta effettivamente incorporando la conoscenza scientifica nel modello. In altre parole, aiutano a controllare la credibilit√† delle ipotesi formulate prima di osservare i dati. Questo passaggio √® essenziale per assicurarsi che le assunzioni del modello riflettano realisticamente la realt√† che si sta cercando di modellare.\nPossono facilitare il processo di campionamento, limitando lo spazio dei risultati e dei parametri a valori ‚Äúragionevoli‚Äù. In pratica, questa restrizione contribuisce a migliorare l‚Äôefficienza del campionamento, evitando che il modello esplori aree dello spazio dei parametri che sono poco plausibili o che producono previsioni irrealistiche.\n\nConsideriamo qui il odello precedente che impone le seguenti distribuzioni a priori sui parametri alpha, beta e sigma del modello di regressione:\n\\[\n\\alpha \\sim \\text{Normal}(0, 5),\n\\] \\[\n\\beta \\sim \\text{Normal}(0, 2.5),\n\\] \\[\n\\sigma \\sim \\text{Chaucy}(0, 5).\n\\]\nLa verificha predittiva delle distribuzioni a priori genera un grafico nel quale vengono mostrate un certo numero (qui 30) di rette di regressione, ciascuna delle quali determinata da un valore a caso estratto dalla distribuzione a priori di alpha e un valore a caso estratto dalla distribuzione a priori di beta.\n\n# Number of samples to generate from the prior\nnum_samples = 50\n\n# Define the prior distributions for alpha and beta\nalpha_prior = np.random.normal(0, 5.0, num_samples)\nbeta_prior = np.random.normal(0, 2.5, num_samples)\n\n# Prepare a figure for plotting\nplt.figure(figsize=(10, 6))\n\n# Plot 30 regression lines from the prior distribution\nfor i in range(num_samples):\n    alpha_sample_prior = alpha_prior[i]\n    beta_sample_prior = beta_prior[i]\n\n    # Calculate the predicted y_hat without the noise term (sigma)\n    y_hat = alpha_sample_prior + beta_sample_prior * x\n\n    # Plot the regression line\n    plt.plot(x, y_hat, color=\"blue\", alpha=0.3)\n\n# Optional: Add labels and title to the plot\nplt.xlabel(\"x\")\nplt.ylabel(\"y_hat\")\nplt.title(\"Prior Predictive Checks with 50 Regression Lines\")\nplt.show()\n\n\n\n\n\n\n\n\nQueste distribuzioni a priori consentono di modellare relazioni plausibili tra la variabile dipendente e il predittore. Esse garantiscono che i valori dell‚Äôesito rimangano entro un intervallo ragionevole, permettendo al contempo che sia l‚Äôintercetta che il coefficiente angolare possano assumere valori sia positivi che negativi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_prediction.html#posterior-predictive-check",
    "href": "chapters/linear_models/05_prediction.html#posterior-predictive-check",
    "title": "61¬† Predizione e inferenza",
    "section": "61.4 Posterior-predictive check",
    "text": "61.4 Posterior-predictive check\nIl Posterior Predictive Check (PPC) √® un passaggio cruciale nella modellazione bayesiana, che ci permette di valutare quanto bene il modello si adatta ai dati osservati, tenendo conto delle informazioni aggiornate dai dati stessi. L‚Äôidea alla base del PPC √® confrontare le predizioni del modello, basate sulla distribuzione a posteriori dei parametri, con i dati reali, per vedere se il modello riesce a catturare correttamente le caratteristiche dei dati osservati.\n\nDopo aver adattato il modello ai dati, otteniamo campioni dai parametri a posteriori (\\(\\alpha\\), \\(\\beta\\), \\(\\sigma\\)). Questi campioni riflettono le nostre credenze aggiornate sui parametri, basate sia sulle distribuzioni a priori che sui dati osservati.\nUtilizzando i campioni della distribuzione a posteriori, simuliamo nuovi dati predetti (\\(y_{rep}\\)). Questi dati simulati rappresentano le previsioni del modello, date le nostre stime a posteriori dei parametri.\nConfrontiamo le osservazioni simulate (\\(y_{rep}\\)) con i dati osservati reali (\\(y\\)). Il PPC plot ci permette di vedere se il modello, con i parametri aggiornati, √® in grado di riprodurre correttamente i dati osservati.\n\nPer creare il PPC plot, usiamo ArviZ. Creiamo un oggetto InferenceData che contiene sia le predizioni a posteriori che i dati osservati, organizzati nel formato richiesto da ArviZ.\n\nidata = az.from_cmdstanpy(\n    posterior=fit3,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": df[\"TA1\"]},\n)\n\nAvendo generato l‚Äôoggetto idata, possiamo ora creare il pp-check plot.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=200)\n\n\n\n\n\n\n\n\nIl Posterior Predictive Check √® uno strumento potente per verificare la validit√† del modello dopo l‚Äôanalisi, assicurando che le predizioni del modello siano realistiche e che riflettano accuratamente le osservazioni effettive.\n\nEsempio 61.1 Il modo pi√π fondamentale per verificare l‚Äôadeguatezza di un modello √® visualizzare i dataset replicati e confrontarli con i dati effettivi. Qui illustriamo questo concetto con un semplice esempio tratto da un famoso dataset storico che non si adattava alla distribuzione normale. L‚Äôobiettivo di questo esempio √® dimostrare come la mancanza di adattamento possa essere osservata utilizzando repliche predittive.\nI dati provengono da una serie di misurazioni effettuate da Simon Newcomb nel 1882, nell‚Äôambito di un esperimento per stimare la velocit√† della luce. Abbiamo (inappropriatamente) adattato una distribuzione normale a questi dati, cosa che nel contesto della regressione pu√≤ essere fatta tramite una regressione lineare senza predittori. Il nostro modello implicito per la regressione lineare prevede errori distribuiti normalmente, e stimare la media √® equivalente a fare una regressione su una costante.\nImportiamo i dati:\n\ndata_file = os.path.join(project_directory, \"data\", \"newcomb.txt\")\nnewcomb = pd.read_csv(data_file)\nnewcomb.head()\n\n\n\n\n\n\n\n\n\ny\n\n\n\n\n0\n28\n\n\n1\n26\n\n\n2\n33\n\n\n3\n24\n\n\n4\n34\n\n\n\n\n\n\n\n\nEsaminiamo i dati con un istogramma. Si vede che ci sono alcune osservazioni devianti.\n\nplt.hist(newcomb[\"y\"], bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.3)\nplt.xlabel(\"y\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of y\")\nplt.show()\n\n\n\n\n\n\n\n\nIl valore mediano stimato, nei termini di una deviazione dal valore di 24.800 nanosecondi, √®\n\nnp.median(newcomb[\"y\"])\n\n27.0\n\n\nPer questi dati adattiamo un modello normale, ovvero un modello di regressione con la sola intercetta. Importiamo e compiliamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"newcomb_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of observations\n  vector[N] y; // Outcome variable\n}\nparameters {\n  real alpha; // Intercept\n  real&lt;lower=0&gt; sigma; // Standard deviation of the errors\n}\nmodel {\n  // Prior for the intercept\n  alpha ~ normal(27, 20);\n  \n  // Likelihood\n  y ~ normal(alpha, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // Replicated data\n  \n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(alpha, sigma);\n  }\n}\n\n\n\nCreiamo un dizionario con i dati nel formato atteso da Stan:\n\nstan_data = {\"N\": len(newcomb[\"y\"]), \"y\": newcomb[\"y\"]}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro \\(\\alpha\\).\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"sigma\"]))\n\n\n\n\n\n\n\n\n\naz.summary(fit, var_names=([\"alpha\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n26.226\n1.368\n23.584\n28.797\n0.017\n0.012\n6737.0\n4534.0\n1.0\n\n\nsigma\n10.947\n0.979\n9.102\n12.707\n0.012\n0.008\n6881.0\n5259.0\n1.0\n\n\n\n\n\n\n\n\nEsaminiamo la distribuzione predittiva a posteriori.\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": newcomb[\"y\"]},\n)\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"})\n\n\n\n\n\n\n\n\n√à evidente che il modello non riesce a predire adeguatamente i dati osservati nel campione.\nL‚Äôistogramma precedente rivela la presenza di alcune osservazioni anomale. Di conseguenza, √® pi√π appropriato utilizzare un modello ‚Äúrobusto‚Äù, come la distribuzione t di Student, che √® meglio in grado di gestire i dati devianti presenti nelle code della distribuzione.\nModifichiamo quindi il codice Stan per utilizzare una verosimiglianza basata sulla distribuzione t di Student, stimando i gradi di libert√† direttamente dal modello.\n\nstan2_file = os.path.join(project_directory, \"stan\", \"newcomb_t_model.stan\")\nmodel2 = CmdStanModel(stan_file=stan2_file)\nprint(model2.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of observations\n  vector[N] y; // Outcome variable\n}\nparameters {\n  real alpha; // Intercept\n  real&lt;lower=0&gt; sigma; // Standard deviation of the errors\n  real&lt;lower=1&gt; nu; // Degrees of freedom for the Student's t-distribution\n}\nmodel {\n  // Prior for the intercept\n  alpha ~ normal(27, 20);\n  \n  // Prior for degrees of freedom\n  nu ~ gamma(2, 0.1); // Weakly informative prior for nu, adjust as needed\n  \n  // Likelihood using Student's t-distribution\n  y ~ student_t(nu, alpha, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // Replicated data\n  \n  for (n in 1 : N) {\n    y_rep[n] = student_t_rng(nu, alpha, sigma);\n  }\n}\n\n\n\nEseguiamo il campionamento con la nuova versione del modello.\n\nfit2 = model2.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori dei parametri.\n\n_ = az.plot_trace(fit2, var_names=([\"alpha\", \"nu\", \"sigma\"]))\n\n\n\n\n\n\n\n\n\naz.summary(fit2, var_names=([\"alpha\", \"nu\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n27.436\n0.646\n26.125\n28.584\n0.009\n0.006\n5103.0\n4626.0\n1.0\n\n\nnu\n2.800\n0.943\n1.328\n4.579\n0.013\n0.009\n4799.0\n3810.0\n1.0\n\n\nsigma\n4.209\n0.650\n2.997\n5.470\n0.009\n0.007\n4882.0\n3769.0\n1.0\n\n\n\n\n\n\n\n\n\nidata2 = az.from_cmdstanpy(\n    posterior=fit2,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": newcomb[\"y\"]},\n)\n# Plot the posterior predictive checks\n_ = az.plot_ppc(idata2, data_pairs={\"y\": \"y_rep\"})\nplt.xlim(0, 50)\nplt.show()\n\n\n\n\n\n\n\n\nIl posterior predictive check √® ora adeguato.\nLa stima della deviazione dal valore di 24.800 nanosecondi √® ora di 27.436.\nSenza entrare nei dettagli delle trasformazioni algebriche, questo porta a una stima della velocit√† della luce di 299.762.442 m/s. Sebbene questo valore sia una sottostima rispetto al valore ‚Äúaccettato‚Äù di 299.792.458 m/s, l‚Äôerrore √® inferiore a quello che si otterrebbe utilizzando una stima a posteriori di 26.226, che condurrebbe a una stima della velocit√† della luce di 296.992.741 m/s.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_prediction.html#commenti-e-considerazioni-finali",
    "href": "chapters/linear_models/05_prediction.html#commenti-e-considerazioni-finali",
    "title": "61¬† Predizione e inferenza",
    "section": "61.5 Commenti e Considerazioni Finali",
    "text": "61.5 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo approfondito i temi della predizione bayesiana nel contesto del modello di regressione bivariato, evidenziando l‚Äôimportanza delle verifiche predittive a priori e a posteriori per la valutazione e la validazione del modello.\nAbbiamo visto come il Prior Predictive Check sia essenziale per verificare che le distribuzioni a priori siano appropriate per il modello e i dati del campione. Questo passaggio consente di esaminare se le ipotesi iniziali sono coerenti con la conoscenza preesistente e con i risultati attesi. Un‚Äôadeguata verifica predittiva a priori aiuta a prevenire l‚Äôadozione di distribuzioni a priori che possano portare a previsioni irrealistiche o fuorvianti. Se le predizioni basate sulle distribuzioni a priori risultano incompatibili con ci√≤ che ci si aspetta dai dati, √® un segnale che le distribuzioni a priori devono essere riviste.\nSuccessivamente, abbiamo esaminato il Posterior Predictive Check come strumento per valutare la capacit√† del modello di adattarsi ai dati osservati. Dopo aver integrato le informazioni dei dati con le distribuzioni a priori, il posterior predictive check permette di confrontare le predizioni del modello con i dati effettivamente osservati. Se il modello √® adeguato, le sue predizioni dovrebbero essere in linea con i dati reali. Tuttavia, se emerge una discrepanza sostanziale tra le predizioni e i dati osservati, questo √® un chiaro segnale che il modello potrebbe non essere appropriato per il fenomeno in esame e potrebbe richiedere una revisione. Tale revisione pu√≤ comportare la modifica delle assunzioni di base, l‚Äôinclusione di nuovi predittori, o l‚Äôadozione di un modello completamente diverso.\nIn conclusione, l‚Äôapproccio bayesiano alla predizione e alla verifica dei modelli offre un framework robusto e flessibile per l‚Äôanalisi statistica. I prior e posterior predictive checks non sono semplici passaggi tecnici, ma costituiscono una parte integrante del processo di modellizzazione, assicurando che il modello non solo sia ben adattato ai dati, ma anche che le sue assunzioni siano giustificate e realistiche. L‚Äôutilizzo di questi strumenti permette di costruire modelli che siano coerenti con la realt√† che intendono rappresentare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_prediction.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_prediction.html#informazioni-sullambiente-di-sviluppo",
    "title": "61¬† Predizione e inferenza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Tue Aug 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nsys       : 3.12.4 | packaged by conda-forge | (main, Jun 17 2024, 10:13:44) [Clang 16.0.6 ]\npandas    : 2.2.2\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\n\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\n‚Äî‚Äî‚Äî. 2021. Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>61</span>¬† <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_design.html",
    "href": "chapters/linear_models/06_design.html",
    "title": "62¬† Disegno della ricerca e potere statistico",
    "section": "",
    "text": "Introduzione\nbla bla",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_design.html#problema-della-potenza-statistica",
    "href": "chapters/linear_models/06_design.html#problema-della-potenza-statistica",
    "title": "62¬† Disegno della ricerca e potere statistico",
    "section": "62.1 Problema della potenza statistica",
    "text": "62.1 Problema della potenza statistica\nLa potenza statistica √® definita come la probabilit√†, prima che uno studio venga eseguito, che un determinato confronto raggiunga la ‚Äúsignificativit√† statistica‚Äù a un livello predefinito (tipicamente un p-value inferiore a 0.05), dato un certo effetto reale presunto. Un‚Äôanalisi della potenza viene eseguita ipotizzando prima una dimensione dell‚Äôeffetto, poi facendo alcune assunzioni sulla variazione dei dati e sulla dimensione del campione dello studio, e infine utilizzando calcoli di probabilit√† per determinare la probabilit√† che il p-value sia inferiore alla soglia.\nLa visione convenzionale suggerisce di evitare studi con bassa potenza perch√© √® improbabile che abbiano successo. Tuttavia, supponiamo che uno studio abbia bassa potenza ma possa essere eseguito a un costo molto basso rispetto ai potenziali benefici che potrebbero derivare da un successo nella ricerca. In questo caso, un ricercatore potrebbe concludere che vale ancora la pena condurre uno studio con bassa potenza, considerandolo una scommessa che vale la pena tentare. Pertanto, quando i costi sono bassi, i ricercatori sono spesso inclini a rischiare, nella convinzione che un risultato positivo potrebbe portare grandi benefici (per la carriera del ricercatore). Tuttavia, questo non √® necessariamente una buona idea, come verr√† discusso successivamente.\n\n62.1.1 La maledizione del vincitore negli studi a bassa potenza\nIl problema con il ragionamento convenzionale √® che, in uno studio a bassa potenza, il presunto ‚Äúsuccesso‚Äù della significativit√† statistica pu√≤ essere in realt√† una trappola. Concentrandosi su confronti che sono statisticamente significativi, la comunit√† accademica e i singoli ricercatori ottengono una visione sistematicamente distorta e eccessivamente ottimistica del mondo.\nIn termini semplici, quando il segnale √® debole e il rumore √® alto, i modelli statisticamente significativi nei dati sono probabilmente errati, nel senso che i risultati difficilmente si replicheranno.\nIn termini tecnici, i risultati statisticamente significativi sono soggetti a errori di tipo M e di tipo S (si veda il Capitolo 97). Uno studio a bassa potenza non ha praticamente alcuna possibilit√† di fornire informazioni utili, e possiamo affermarlo anche prima che i dati siano raccolti. Pertanto, un rischio chiave per uno studio a bassa potenza non √® tanto che abbia poche probabilit√† di successo, ma piuttosto che un apparente successo mascheri un fallimento pi√π grande. La pubblicazione di risultati rumorosi pu√≤ contribuire alla crisi di replicazione quando queste affermazioni fragili crollano sotto un‚Äôanalisi pi√π attenta o non si manifestano in tentativi di replicazione.\n\n\n62.1.2 Ipotesi di dimensione dell‚Äôeffetto\nUn‚Äôaltra sfida √® che qualsiasi analisi della potenza o calcolo della dimensione del campione √® condizionato da una dimensione dell‚Äôeffetto presunta, che √® l‚Äôobiettivo dello studio e quindi non √® mai conosciuta in anticipo. Esistono diversi modi per scegliere una dimensione dell‚Äôeffetto per eseguire un‚Äôanalisi di uno studio pianificato. Una strategia √® provare una gamma di valori coerenti con la letteratura precedente sull‚Äôargomento. Un‚Äôaltra √® decidere quale grandezza dell‚Äôeffetto sarebbe di interesse pratico.\nGelman, Hill, e Vehtari (2021) raccomandano di non prendere decisioni di progettazione basate sulla stima di un singolo studio rumoroso. √à meglio utilizzare un insieme di informazioni da studi precedenti per prendere decisioni informate sulla potenza statistica e la dimensione del campione. Gelman, Hill, e Vehtari (2021) notano come i risultati pubblicati tendono ad essere sovrastime degli effetti reali per vari motivi, tra cui il fatto che gli interventi vengono spesso testati su persone e in scenari in cui saranno pi√π efficaci, e i risultati ‚Äústatisticamente significativi‚Äù sono pi√π probabilmente riportati e pubblicati, portando a sovrastime.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_design.html#stimare-la-dimensione-del-campione",
    "href": "chapters/linear_models/06_design.html#stimare-la-dimensione-del-campione",
    "title": "62¬† Disegno della ricerca e potere statistico",
    "section": "62.2 Stimare la dimensione del campione",
    "text": "62.2 Stimare la dimensione del campione\nPrima di raccogliere i dati, pu√≤ essere utile stimare la precisione delle inferenze che ci si aspetta di ottenere con una determinata dimensione del campione, o stimare la dimensione del campione necessaria per ottenere una certa precisione.\nIn sintesi, per avere una potenza dell‚Äô80%, il vero valore del parametro deve essere 2.8 errori standard lontano dal punto di confronto. Tuttavia, questi calcoli sono validi solo quanto le loro assunzioni, e solitamente non si conosce il vero valore del parametro prima di eseguire lo studio.\n\n62.2.1 Determinazione della dimensione del campione per un errore standard specificato\nSupponiamo di voler stimare un valore medio della popolazione \\(\\theta\\) a partire dai dati \\(y_1, \\dots, y_n\\), un campione casuale di dimensione \\(n\\). Una stima veloce di \\(\\theta\\) √® la media campionaria \\(\\bar{y}\\), che ha un errore standard pari a \\(\\sigma/\\sqrt{n}\\), dove \\(\\sigma\\) √® la deviazione standard di \\(y\\) nella popolazione.\nSe l‚Äôobiettivo √® ottenere un errore standard specifico per \\(\\bar{y}\\), allora la dimensione del campione deve essere almeno:\n\\[\nn = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2,\n\\]\ndove \\(\\text{s.e.}\\) √® l‚Äôerrore standard desiderato.\nPer capire questo risultato, iniziamo ricordando la formula dell‚Äôerrore standard della media campionaria:\n\\[\\text{s.e.}(\\bar{y}) = \\frac{\\sigma}{\\sqrt{n}},\\]\ndove:\n\n\\(\\text{s.e.}(\\bar{y})\\) √® l‚Äôerrore standard della media campionaria,\n\\(\\sigma\\) √® la deviazione standard della popolazione,\n\\(n\\) √® la dimensione del campione.\n\nOra, supponiamo di voler ottenere un errore standard specifico, che chiameremo semplicemente \\(\\text{s.e.}\\). Possiamo quindi impostare l‚Äôequazione:\n\\(\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}\\)\nPer isolare \\(n\\), prima moltiplichiamo entrambi i lati per \\(\\sqrt{n}\\):\n\\(\\text{s.e.} \\cdot \\sqrt{n} = \\sigma\\)\nOra, eleviamo al quadrato entrambi i lati:\n\\((\\text{s.e.} \\cdot \\sqrt{n})^2 = \\sigma^2\\)\nSemplifichiamo il lato sinistro:\n\\(\\text{s.e.}^2 \\cdot n = \\sigma^2\\)\n6Infine, dividiamo entrambi i lati per \\(\\text{s.e.}^2\\):\n\\(n = \\frac{\\sigma^2}{\\text{s.e.}^2}\\)\nQuesta pu√≤ essere riscritta come:\n\\(n = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2\\)\nQuindi, se vogliamo ottenere un errore standard specifico per \\(\\bar{y}\\), la dimensione del campione deve essere almeno pari a \\(\\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2\\), dove \\(\\text{s.e.}\\) √® l‚Äôerrore standard desiderato.\nQuesta formula ci permette di calcolare la dimensione minima del campione necessaria per ottenere un determinato livello di precisione (misurato dall‚Äôerrore standard) nella stima della media della popolazione.\n\n\n62.2.2 Dimensione del campione per una potenza dell‚Äô80%\nSe l‚Äôobiettivo √® ottenere l‚Äô80% di potenza per distinguere \\(\\theta\\) da un valore specificato \\(\\theta_0\\), allora la dimensione del campione richiesta pu√≤ essere calcolata con una formula conservativa:\n\\[\nn = \\left(\\frac{2.8 \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\nQui, il valore \\(2.8\\) deriva dalla somma dei quantili della distribuzione normale per l‚Äô80% di potenza e il 95% di confidenza.\nPer derivare la formula per la dimensione del campione necessaria a ottenere l‚Äô80% di potenza per distinguere \\(\\theta\\) da un valore specificato \\(\\theta_0\\), seguiamo i passaggi seguenti.\nI termini che useremo sono i seguenti:\n\n\\(\\theta\\): Il valore medio della popolazione che stiamo cercando di stimare.\n\\(\\theta_0\\): Il valore specificato con cui vogliamo confrontare \\(\\theta\\).\n\\(\\sigma\\): La deviazione standard della popolazione.\n\\(\\text{s.e.}\\): L‚Äôerrore standard della media campionaria \\(\\bar{y}\\), che √® dato da \\(\\sigma/\\sqrt{n}\\).\n\nL‚Äôobiettivo √® determinare la dimensione del campione \\(n\\) necessaria per avere una potenza dell‚Äô80% nel distinguere \\(\\theta\\) da \\(\\theta_0\\), con un livello di significativit√† del 5%.\nLa differenza \\(\\theta - \\theta_0\\) √® l‚Äôeffetto che stiamo cercando di rilevare. L‚Äôerrore standard associato a questa differenza √® dato da:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nLa precisione della stima della differenza \\(\\theta - \\theta_0\\) dipende dalla dimensione del campione \\(n\\).\nPer una potenza dell‚Äô80%, vogliamo che la probabilit√† di rifiutare l‚Äôipotesi nulla (quando in realt√† \\(\\theta \\neq \\theta_0\\)) sia almeno dell‚Äô80%. Ci√≤ corrisponde a un‚Äôarea sotto la curva normale standard di \\(0.8\\).\nIl livello di significativit√† del 5% corrisponde a un valore critico di \\(1.96\\) (dalla distribuzione normale standard), che √® il valore z corrispondente al 97,5% della distribuzione (poich√© stiamo lavorando con un test a due code).\nPer ottenere l‚Äô80% di potenza, il valore osservato deve trovarsi non solo al di fuori dell‚Äôintervallo di confidenza del 95%, ma anche a una certa distanza dalla media, tale da coprire il restante 80% della distribuzione della differenza \\(\\theta - \\theta_0\\). Questo valore z corrispondente al restante 80% √® \\(0.84\\).\nQuindi, il valore z totale da considerare √®:\n\\[\nz_{\\text{totale}} = 1.96 + 0.84 = 2.8.\n\\]\nLa differenza \\(\\theta - \\theta_0\\) deve essere almeno \\(2.8\\) volte l‚Äôerrore standard per garantire l‚Äô80% di potenza. Pertanto, possiamo scrivere:\n\\[\n\\theta - \\theta_0 = 2.8 \\times \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(n\\):\n\\[\n\\sqrt{n} = \\frac{2.8 \\sigma}{\\theta - \\theta_0}.\n\\]\nElevando al quadrato entrambi i lati:\n\\[\nn = \\left(\\frac{2.8 \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\nQuesta formula ci dice che, per avere l‚Äô80% di potenza nel rilevare una differenza \\(\\theta - \\theta_0\\) con una deviazione standard \\(\\sigma\\), dobbiamo avere una dimensione del campione pari a \\(n = \\left(\\frac{2.8 \\sigma}{\\theta - \\theta_0}\\right)^2\\). Il valore \\(2.8\\) deriva dalla somma dei quantili della distribuzione normale standard: \\(1.96\\) (per un intervallo di confidenza del 95%) e \\(0.84\\) (per la potenza dell‚Äô80%). Questo valore assicura che l‚Äôintervallo di confidenza per \\(\\theta\\) non includa \\(\\theta_0\\) nel 80% dei casi, il che ci d√† l‚Äô80% di potenza.\n\n62.2.2.1 Correzione per la distribuzione t e incertezze nella deviazione standard\nNelle analisi di progettazione, utilizziamo la distribuzione normale per la regressione lineare quando la deviazione standard residua \\(\\sigma\\) √® conosciuta. Tuttavia, per studi molto piccoli, i gradi di libert√† sono bassi, e la deviazione standard residua non √® stimata con precisione dai dati. In questi casi, le incertezze inferenziali seguono la distribuzione t di Student anzich√© la normale. Di conseguenza, il valore \\(2.8\\) deve essere sostituito con un numero pi√π grande per tenere conto di questa ulteriore fonte di incertezza.\nAd esempio, per uno studio che confronta due gruppi di 6 pazienti ciascuno, i gradi di libert√† sono 10. In Python, la somma dei quantili della distribuzione t con 10 gradi di libert√† per l‚Äô80% di potenza e il 95% di confidenza √® \\(3.1\\), quindi \\(2.8\\) viene sostituito da \\(3.1\\) nei calcoli per la potenza dell‚Äô80%.\n\nimport scipy.stats as stats\n\n# Calcola i valori critici dalla distribuzione t di Student con 10 gradi di libert√†\ndf = 10\n\n# Calcola il quantile per l'80% di potenza (quindi 0.8) e il 95% di confidenza (quindi 0.975)\nt_value_80 = stats.t.ppf(0.8, df)\nt_value_95 = stats.t.ppf(0.975, df)\n\n# Somma dei due quantili\nt_total = t_value_80 + t_value_95\nt_total\n\n3.1071966805155227\n\n\nUtilizzando Python, abbiamo calcolato i valori critici dalla distribuzione t di Student con 10 gradi di libert√†. La somma dei quantili per l‚Äô80% di potenza e il 95% di confidenza √® pari a \\(3.107\\). Questo valore sostituisce il valore \\(2.8\\) nei calcoli per la potenza dell‚Äô80% quando si utilizzano piccoli campioni con una distribuzione t invece della distribuzione normale standard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_design.html#confronto-di-medie",
    "href": "chapters/linear_models/06_design.html#confronto-di-medie",
    "title": "62¬† Disegno della ricerca e potere statistico",
    "section": "62.3 Confronto di medie",
    "text": "62.3 Confronto di medie\nConsideriamo ora il caso del confronto tra due medie. L‚Äôerrore standard della differenza tra due medie campionarie \\(\\bar{y}_1 - \\bar{y}_2\\) √® dato da:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}.\n\\]\nSe supponiamo che le dimensioni dei campioni nei due gruppi siano uguali (\\(n_1 = n_2 = n/2\\)), l‚Äôerrore standard diventa semplicemente:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma_1^2 + \\sigma_2^2}{n/2}} = \\sqrt{\\frac{2\\sigma^2}{n}} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\nQuindi, la dimensione del campione richiesta per ottenere un errore standard specifico sar√†:\n\\[\nn = \\frac{2(\\sigma_1^2 + \\sigma_2^2)}{\\text{s.e.}^2}.\n\\]\nSe inoltre assumiamo che la variazione all‚Äôinterno di ciascun gruppo sia la stessa (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), allora:\n\\[\n\\text{s.e.} = \\frac{2\\sigma}{\\sqrt{n}}\n\\]\ne la dimensione del campione richiesta √®:\n\\[\nn = \\left(\\frac{2\\sigma}{\\text{s.e.}}\\right)^2.\n\\]\n\n62.3.1 Dimensione del campione per una differenza \\(\\Delta\\) con l‚Äô80% di potenza\nPer ottenere l‚Äô80% di potenza, la differenza \\(\\Delta\\) che vogliamo rilevare deve essere abbastanza grande rispetto all‚Äôerrore standard della differenza tra le medie. Dato che abbiamo gi√† calcolato che il valore \\(2.8\\) √® la somma dei quantili per l‚Äô80% di potenza e il 95% di confidenza, possiamo scrivere:\n\\[\n   \\Delta = 2.8 \\times \\text{s.e.}.\n   \\]\nSostituendo l‚Äôespressione per \\(\\text{s.e.}\\), otteniamo:\n\\[\n   \\Delta = 2.8 \\times \\sqrt{\\frac{2(\\sigma_1^2 + \\sigma_2^2)}{n}}.\n   \\]\nOra, risolviamo per \\(n\\):\n\\[\n   \\sqrt{n} = \\frac{2.8 \\times \\sqrt{2(\\sigma_1^2 + \\sigma_2^2)}}{\\Delta}.\n   \\]\nElevando al quadrato entrambi i lati, otteniamo:\n\\[\n   n = 2\\left(\\frac{2.8 \\sqrt{\\sigma_1^2 + \\sigma_2^2}}{\\Delta}\\right)^2 = 2\\left(\\frac{\\sigma_1^2 + \\sigma_2^2}{\\left(\\frac{\\Delta}{2.8}\\right)^2}\\right).\n   \\]\nSe assumiamo che la variazione all‚Äôinterno dei due gruppi sia la stessa (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), allora possiamo semplificare ulteriormente la formula. In questo caso, abbiamo:\n\\[\n   n = 2\\left(\\frac{\\sigma^2 + \\sigma^2}{\\left(\\frac{\\Delta}{2.8}\\right)^2}\\right) = 2\\left(\\frac{2\\sigma^2}{\\left(\\frac{\\Delta}{2.8}\\right)^2}\\right).\n   \\]\nSemplificando, otteniamo:\n\\[\n   n = \\left(\\frac{5.6 \\sigma}{\\Delta}\\right)^2.\n   \\]\nQui, \\(5.6\\) √® semplicemente \\(2 \\times 2.8\\).\nQuesta formula ci dice che, per rilevare una differenza \\(\\Delta\\) tra due gruppi con una potenza dell‚Äô80%, la dimensione del campione richiesta dipende dalla deviazione standard \\(\\sigma\\) comune a entrambi i gruppi e dalla differenza \\(\\Delta\\) che vogliamo rilevare.\n\nSe la deviazione standard \\(\\sigma\\) √® alta: Avremo bisogno di un campione pi√π grande per rilevare una differenza \\(\\Delta\\).\nSe la differenza \\(\\Delta\\) √® piccola: Anche in questo caso avremo bisogno di un campione pi√π grande per garantire che la differenza sia rilevabile con l‚Äô80% di potenza.\n\n\nEsempio 62.1 Se la differenza \\(\\Delta\\) che vogliamo rilevare √® pari a met√† della deviazione standard (\\(\\Delta = 0.5\\sigma\\)), allora la formula ci dir√† quanti partecipanti sono necessari in ciascun gruppo per rilevare questa differenza con l‚Äô80% di potenza. Ad esempio, se \\(\\Delta = 0.5\\sigma\\), la dimensione totale del campione sar√†:\n\\[\nn = \\left(\\frac{5.6 \\sigma}{0.5\\sigma}\\right)^2 = (11.2)^2 = 125.44 \\approx 126.\n\\]\nQuindi, servirebbero 63 partecipanti per gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_design.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/06_design.html#informazioni-sullambiente-di-sviluppo",
    "title": "62¬† Disegno della ricerca e potere statistico",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Sun Aug 11 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\ncmdstanpy : 1.2.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\npingouin  : 0.5.4\nnumpy     : 1.26.4\narviz     : 0.18.0\nlogging   : 0.5.1.2\n\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\n‚Äî‚Äî‚Äî. 2021. Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>62</span>¬† <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html",
    "href": "chapters/linear_models/07_linear_algebra.html",
    "title": "64¬† Elementi di algebra lineare",
    "section": "",
    "text": "64.1 Introduzione\nQuesto capitolo presenta alcune nozioni di base dell‚Äôalgebra lineare, una branca della matematica essenziale per la comprensione e l‚Äôanalisi dei modelli di regressione lineare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#rappresentazione-dei-vettori",
    "href": "chapters/linear_models/07_linear_algebra.html#rappresentazione-dei-vettori",
    "title": "64¬† Elementi di algebra lineare",
    "section": "64.2 Rappresentazione dei Vettori",
    "text": "64.2 Rappresentazione dei Vettori\nNell‚Äôalgebra lineare, un vettore, che rappresenta una lista ordinata di scalari, √® solitamente indicato con una lettera minuscola in grassetto, come \\(\\mathbf{v}\\). Gli elementi di un vettore sono generalmente indicati con un indice, ad esempio \\(\\mathbf{v}_1\\) si riferisce al primo elemento del vettore \\(\\mathbf{v}\\).\nUn vettore \\(\\mathbf{v}\\) di \\(n\\) elementi pu√≤ essere rappresentato sia come una colonna che come una riga, a seconda della convenzione scelta. Ad esempio, un vettore colonna di \\(n\\) elementi √® scritto come:\n\\[\n\\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix},\n\\]\nmentre un vettore riga appare come:\n\\[\n\\mathbf{v} = \\begin{bmatrix} v_1 & v_2 & \\cdots & v_n \\end{bmatrix}.\n\\]\nQuesta notazione consente di visualizzare chiaramente i singoli elementi del vettore e di riferirsi a ciascuno di essi in modo specifico.\nUna lista di \\(n\\) scalari organizzata in un vettore \\(\\mathbf{v}\\) √® chiamata ‚Äúdimensione‚Äù del vettore. Formalmente, si esprime come \\(\\mathbf{v} \\in \\mathbb{R}^n\\), indicando che il vettore \\(\\mathbf{v}\\) appartiene all‚Äôinsieme di tutti i vettori reali di dimensione \\(n\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#visualizzazione-geometrica-dei-vettori",
    "href": "chapters/linear_models/07_linear_algebra.html#visualizzazione-geometrica-dei-vettori",
    "title": "64¬† Elementi di algebra lineare",
    "section": "64.3 Visualizzazione Geometrica dei Vettori",
    "text": "64.3 Visualizzazione Geometrica dei Vettori\nI vettori possono essere rappresentati come frecce in uno spazio \\(n\\)-dimensionale, con l‚Äôorigine come punto di partenza e la punta della freccia che corrisponde alle coordinate specificate dal vettore. La norma \\(L_2\\) (o lunghezza) di un vettore, denotata come \\(\\|\\mathbf{v}\\|\\), rappresenta la distanza euclidea dall‚Äôorigine alla punta del vettore.\nPer un vettore \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\), la norma √® definita come:\n\\[\n\\|\\mathbf{v}\\| = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}.\n\\]\n\n64.3.1 Esempio Numerico\nConsideriamo un vettore in uno spazio bidimensionale, ad esempio \\(\\mathbf{v} = [3, 4]\\). Geometricamente, questo vettore parte dall‚Äôorigine \\((0, 0)\\) e termina nel punto \\((3, 4)\\) del piano cartesiano.\nPer calcolare la norma \\(L_2\\) di questo vettore, applichiamo la formula:\n\\[\n\\|\\mathbf{v}\\| = \\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5.\n\\]\nQuindi, la norma del vettore \\(\\mathbf{v} = [3, 4]\\) √® 5, che rappresenta la lunghezza della freccia dal punto di origine \\((0, 0)\\) al punto \\((3, 4)\\) nello spazio bidimensionale.\n\n\n64.3.2 Rappresentazione Geometrica\ny\n^\n|       * (3, 4)\n|      /\n|     /\n|    /\n|   /\n|  /\n| / \n|/____________&gt; x\n(0, 0)\nIn questo diagramma, il punto * rappresenta la fine del vettore \\(\\mathbf{v}\\) e la linea inclinata mostra il vettore stesso che parte dall‚Äôorigine. L‚Äôaltezza della linea fino al punto (3, 4) rappresenta visivamente la norma del vettore, che √® la distanza di 5 unit√† dall‚Äôorigine.\nQuesto esempio illustra chiaramente la relazione tra la rappresentazione numerica di un vettore e la sua interpretazione geometrica, facilitando la comprensione della lunghezza del vettore e della sua direzione nello spazio bidimensionale.\nSebbene noi siamo principalmente limitati a ragionare su spazi bidimensionali (2D) e tridimensionali (3D), i dati che raccogliamo spesso risiedono in spazi di dimensioni superiori. L‚Äôalgebra lineare permette di ragionare e sviluppare intuizioni su vettori e spazi di dimensioni molto pi√π elevate, superando i limiti della visualizzazione diretta.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#operazioni-di-base-sui-vettori",
    "href": "chapters/linear_models/07_linear_algebra.html#operazioni-di-base-sui-vettori",
    "title": "64¬† Elementi di algebra lineare",
    "section": "64.4 Operazioni di Base sui Vettori",
    "text": "64.4 Operazioni di Base sui Vettori\n\n64.4.1 1. Moltiplicazione di un Vettore per uno Scalare\nLa moltiplicazione di un vettore per uno scalare produce un nuovo vettore. Questa operazione pu√≤ essere interpretata come una ‚Äúscalatura‚Äù del vettore nello spazio: il vettore risultante mantiene la stessa direzione dell‚Äôoriginale, ma la sua lunghezza viene modificata in base allo scalare.\nSe \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\) √® un vettore e \\(c\\) √® uno scalare, la moltiplicazione del vettore per lo scalare √® data da:\n\\[\nc\\mathbf{v} = [cv_1, cv_2, \\ldots, cv_n]\n\\]\n\n\n64.4.2 2. Addizione di Vettori\n√à possibile sommare due vettori della stessa dimensione. La somma vettoriale si ottiene sommando gli elementi corrispondenti di ciascun vettore.\nSe \\(\\mathbf{u} = [u_1, u_2, \\ldots, u_n]\\) e \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\) sono due vettori di dimensione \\(n\\), la loro somma √®:\n\\[\n\\mathbf{u} + \\mathbf{v} = [u_1 + v_1, u_2 + v_2, \\ldots, u_n + v_n]\n\\]\n\n\n64.4.3 3. Prodotto Scalare (o Prodotto Interno)\nIl prodotto scalare tra due vettori della stessa dimensione √® uno scalare che fornisce informazioni sull‚Äôangolo tra i vettori nello spazio. Formalmente, il prodotto scalare di \\(\\mathbf{u} = [u_1, u_2, \\ldots, u_n]\\) e \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\) √® definito come:\n\\[\n\\mathbf{u} \\cdot \\mathbf{v} = u_1v_1 + u_2v_2 + \\cdots + u_nv_n\n\\]\nQuesto prodotto scalare pu√≤ anche essere espresso in termini dell‚Äôangolo \\(\\theta\\) tra i vettori:\n\\[\n\\mathbf{u} \\cdot \\mathbf{v} = \\|\\mathbf{u}\\| \\|\\mathbf{v}\\| \\cos(\\theta)\n\\]\nSe due vettori sono ortogonali, ovvero formano un angolo di \\(90^\\circ\\) tra loro, il loro prodotto scalare √® zero: \\(\\mathbf{u} \\cdot \\mathbf{v} = 0\\).\n\n\n64.4.4 4. Prodotto Scalare di un Vettore con Se Stesso\nIl prodotto scalare di un vettore con se stesso fornisce il quadrato della sua lunghezza. Se \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\), allora:\n\\[\n\\mathbf{v} \\cdot \\mathbf{v} = v_1^2 + v_2^2 + \\cdots + v_n^2 = \\|\\mathbf{v}\\|^2\n\\]\nQueste operazioni di base sui vettori sono fondamentali per molte applicazioni in matematica, fisica, informatica e altre scienze, fornendo una struttura potente per analizzare e risolvere problemi in spazi multidimensionali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#vettori-in-numpy",
    "href": "chapters/linear_models/07_linear_algebra.html#vettori-in-numpy",
    "title": "64¬† Elementi di algebra lineare",
    "section": "64.5 Vettori in NumPy",
    "text": "64.5 Vettori in NumPy\nNumPy √® la libreria di Python pi√π usata per manipolare vettori e matrici.\nUsiamo NumPy per creare un vettore con tre elementi: 1, 2 e 3:\n\nv = np.array([1, 2, 3])\nprint(v)\n\n[1 2 3]\n\n\nIn questo esempio, v √® un array NumPy che rappresenta un vettore con tre elementi: 1, 2 e 3.\nPer fare il prodotto tra un vettore e uno scalare, puoi semplicemente moltiplicare l‚Äôarray NumPy per uno scalare. Questa operazione moltiplica ogni elemento del vettore per lo scalare:\n\na = 5\n\n# Prodotto vettore-scalare\nva = v * a\nprint(va)\n\n[ 5 10 15]\n\n\nQuesto moltiplicher√† ogni elemento del vettore per 5, dando come risultato [5, 10, 15].\nIl prodotto interno (o prodotto scalare) tra due vettori √® una somma dei prodotti dei loro elementi corrispondenti. In NumPy, si pu√≤ calcolare usando la funzione np.dot() oppure l‚Äôoperatore @:\n\nv2 = np.array([4, 5, 6])\n\n# Prodotto interno usando np.dot()\nprodotto_interno = np.dot(v, v2)\nprint(prodotto_interno)\n\n# Prodotto interno usando l'operatore @\nprodotto_interno2 = v @ v2\nprint(prodotto_interno2)\n\n32\n32\n\n\nEntrambi i metodi daranno il risultato 32, dato che il prodotto interno √® calcolato come \\(1*4 + 2*5 + 3*6 = 32\\).\nIl prodotto esterno tra due vettori produce una matrice dove ogni elemento √® il prodotto degli elementi dei due vettori. In NumPy, si utilizza la funzione np.outer():\n\n# Prodotto esterno\nprodotto_esterno = np.outer(v, v2)\nprint(prodotto_esterno)\n\n[[ 4  5  6]\n [ 8 10 12]\n [12 15 18]]\n\n\nOgni elemento di questa matrice √® il risultato della moltiplicazione degli elementi corrispondenti dei due vettori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#matrici",
    "href": "chapters/linear_models/07_linear_algebra.html#matrici",
    "title": "64¬† Elementi di algebra lineare",
    "section": "64.6 Matrici",
    "text": "64.6 Matrici\nUna matrice √® una struttura matematica bidimensionale costituita da elementi disposti in righe e colonne. Formalmente, una matrice \\(\\mathbf{A}\\) di dimensioni \\(m \\times n\\) (si legge ‚Äúm per n‚Äù) √® un array rettangolare di numeri reali o complessi, denotato come:\n\\[ \\mathbf{A} = (a_{ij})_{m \\times n} = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix} \\]\ndove \\(a_{ij}\\) rappresenta l‚Äôelemento nella \\(i\\)-esima riga e \\(j\\)-esima colonna della matrice.\nLe matrici sono comunemente indicate con lettere maiuscole in grassetto, come \\(\\mathbf{A}\\), \\(\\mathbf{B}\\), \\(\\mathbf{C}\\), etc. Una matrice con \\(m\\) righe e \\(n\\) colonne si dice di ordine \\(m \\times n\\).\nIn molte matrici di dati, ogni elemento \\(a_{ij}\\) √® uno scalare che rappresenta il valore della \\(j\\)-esima variabile del \\(i\\)-esimo campione. Formalmente, possiamo indicare \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\), il che significa che la matrice \\(\\mathbf{A}\\) ha \\(m\\) righe e \\(n\\) colonne. Si dice comunemente che la ‚Äúdimensione‚Äù di \\(\\mathbf{A}\\) √® \\(m \\times n\\).\n\n64.6.1 Matrici come Collezioni di Vettori Colonna\nLe matrici possono essere interpretate come collezioni di vettori colonna. Ad esempio, una matrice di dati pu√≤ essere rappresentata come:\n\\[\n\\mathbf{A} = \\begin{bmatrix} \\mathbf{a}_1 & \\mathbf{a}_2 & \\cdots & \\mathbf{a}_n \\end{bmatrix}\n\\]\nIn questo caso, \\(\\mathbf{A}\\) √® composta da una sequenza di \\(n\\) vettori colonna \\(\\mathbf{a}_1, \\mathbf{a}_2, \\ldots, \\mathbf{a}_n\\), ciascuno dei quali √® un vettore di dimensione \\(m\\). Pi√π precisamente, ogni vettore colonna \\(\\mathbf{a}_j\\) rappresenta i dati di tutti i campioni per la \\(j\\)-esima variabile o feature.\n\n\n64.6.2 Matrici come Collezioni di Vettori Riga\nIn alternativa, una matrice pu√≤ essere vista come una collezione di vettori riga. In questo contesto, ogni riga di \\(\\mathbf{A}\\) rappresenta tutte le variabili misurate per un dato campione:\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n\\mathbf{a}_1^T \\\\\n\\mathbf{a}_2^T \\\\\n\\vdots \\\\\n\\mathbf{a}_m^T\n\\end{bmatrix}\n\\]\nQui, la matrice \\(\\mathbf{A}\\) √® composta da \\(m\\) vettori riga, denotati come \\(\\mathbf{a}_i^T\\). Ognuno di questi vettori riga \\(\\mathbf{a}_i^T\\) √® di dimensione \\(n\\), indicando che ciascun campione ha \\(n\\) variabili o feature associate.\n\n\n64.6.3 Trasposta di una Matrice\nIl simbolo \\(T\\) rappresenta la trasposta di una matrice. La trasposta di una matrice, denotata con un apice \\(T\\) (es. \\(\\mathbf{A}^T\\)), √® un‚Äôoperazione che trasforma ciascuna delle righe di \\(\\mathbf{A}\\) in colonne di \\(\\mathbf{A}^T\\). In altre parole, se \\(\\mathbf{A}\\) ha dimensione \\(m \\times n\\), allora \\(\\mathbf{A}^T\\) avr√† dimensione \\(n \\times m\\):\n\\[\n\\mathbf{A}^T = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{m1} \\\\\na_{12} & a_{22} & \\cdots & a_{m2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\cdots & a_{mn}\n\\end{bmatrix}\n\\]\nCon la trasposta, le variabili misurate diventano colonne e i campioni diventano righe. Essenzialmente, i vettori riga sono le trasposte dei vettori colonna. Questo concetto √® molto utile in algebra lineare, poich√© permette di passare facilmente da una rappresentazione dei dati a un‚Äôaltra.\nIn NumPy, una matrice √® semplicemente un array bidimensionale. Per esempio, possiamo creare una matrice 3x4 utilizzando la funzione np.array() e fornendo una lista di liste (dove ogni lista interna rappresenta una riga della matrice).\nEcco come definire una matrice 3x4:\n\n# Definizione della matrice 3x4\nM = np.array([\n    [1, 2, 3, 4], \n    [5, 6, 7, 8], \n    [9, 10, 11, 12]\n    ])\nprint(M)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nIn NumPy, puoi calcolare la trasposta di una matrice utilizzando l‚Äôattributo .T o la funzione np.transpose().\n\n# Calcolo della trasposta\ntrasposta = M.T\n\nprint(\"\\nTrasposta della matrice:\")\nprint(trasposta)\n\n\nTrasposta della matrice:\n[[ 1  5  9]\n [ 2  6 10]\n [ 3  7 11]\n [ 4  8 12]]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#moltiplicazione-tra-matrici",
    "href": "chapters/linear_models/07_linear_algebra.html#moltiplicazione-tra-matrici",
    "title": "64¬† Elementi di algebra lineare",
    "section": "64.7 Moltiplicazione tra Matrici",
    "text": "64.7 Moltiplicazione tra Matrici\nLa moltiplicazione tra matrici √® un‚Äôoperazione fondamentale nell‚Äôalgebra lineare. Per poter moltiplicare due matrici, √® necessario che siano conformabili, il che significa che il numero di colonne della prima matrice deve essere uguale al numero di righe della seconda matrice.\nSe abbiamo una matrice \\(\\mathbf{A}\\) di dimensioni \\(m \\times n\\) (cio√®, \\(m\\) righe e \\(n\\) colonne) e una matrice \\(\\mathbf{B}\\) di dimensioni \\(n \\times p\\) (cio√®, \\(n\\) righe e \\(p\\) colonne), allora il prodotto delle due matrici \\(\\mathbf{A} \\mathbf{B}\\) sar√† una matrice \\(\\mathbf{C}\\) di dimensioni \\(m \\times p\\).\nIl prodotto tra due matrici \\(\\mathbf{A}\\) e \\(\\mathbf{B}\\) si ottiene calcolando il prodotto interno tra le righe della prima matrice e le colonne della seconda matrice.\nPer ciascun elemento \\(c_{ij}\\) della matrice risultante \\(\\mathbf{C}\\), si esegue il seguente calcolo:\n\\[\nc_{ij} = \\sum_{k=1}^{n} a_{ik} b_{kj}.\n\\]\nQuesto significa che l‚Äôelemento \\(c_{ij}\\) √® il risultato del prodotto interno tra la \\(i\\)-esima riga della matrice \\(\\mathbf{A}\\) e la \\(j\\)-esima colonna della matrice \\(\\mathbf{B}\\).\nLa moltiplicazione di una matrice per un vettore √® un caso particolare della moltiplicazione tra matrici, dove il vettore pu√≤ essere visto come una matrice con una delle dimensioni uguale a 1.\nSe \\(\\mathbf{A}\\) √® una matrice \\(m \\times n\\) e \\(\\mathbf{x}\\) √® un vettore di dimensione \\(n\\) (cio√® una matrice di dimensione \\(n \\times 1\\)), allora il prodotto \\(\\mathbf{A} \\mathbf{x}\\) √® un vettore di dimensione \\(m\\). Ogni elemento del vettore risultante √® il prodotto interno tra una riga della matrice \\(\\mathbf{A}\\) e il vettore \\(\\mathbf{x}\\).\nConsideriamo le seguenti matrici:\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{bmatrix}, \\quad \\mathbf{B} = \\begin{bmatrix}\n7 & 8 \\\\\n9 & 10 \\\\\n11 & 12\n\\end{bmatrix}\n\\]\n\n\\(\\mathbf{A}\\) √® una matrice \\(2 \\times 3\\).\n\\(\\mathbf{B}\\) √® una matrice \\(3 \\times 2\\).\n\nIl prodotto \\(\\mathbf{A} \\mathbf{B}\\) √® una matrice \\(2 \\times 2\\) calcolata come segue:\n\\[\n\\mathbf{C} = \\mathbf{A} \\mathbf{B} = \\begin{bmatrix}\n(1 \\cdot 7 + 2 \\cdot 9 + 3 \\cdot 11) & (1 \\cdot 8 + 2 \\cdot 10 + 3 \\cdot 12) \\\\\n(4 \\cdot 7 + 5 \\cdot 9 + 6 \\cdot 11) & (4 \\cdot 8 + 5 \\cdot 10 + 6 \\cdot 12)\n\\end{bmatrix}\n\\]\nCalcolando ogni elemento:\n\\[\n\\mathbf{C} = \\begin{bmatrix}\n58 & 64 \\\\\n139 & 154\n\\end{bmatrix}\n\\]\nIn questo esempio, ogni elemento della matrice risultante \\(\\mathbf{C}\\) √® stato ottenuto calcolando il prodotto interno tra le righe di \\(\\mathbf{A}\\) e le colonne di \\(\\mathbf{B}\\).\nSvolgiamo ora i calcoli usando NumPy.\n\n# Definizione della matrice A (2x3)\nA = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Definizione della matrice B (3x2)\nB = np.array([[7, 8], [9, 10], [11, 12]])\n\n# Calcolo del prodotto A * B usando np.dot()\nprodotto_AB = np.dot(A, B)\nprint(\"\\nProdotto A * B usando np.dot():\")\nprint(prodotto_AB)\n\n# Calcolo del prodotto A * B usando l'operatore @\nprodotto_AB_operator = A @ B\nprint(\"\\nProdotto A * B usando l'operatore @:\")\nprint(prodotto_AB_operator)\n\n\nProdotto A * B usando np.dot():\n[[ 58  64]\n [139 154]]\n\nProdotto A * B usando l'operatore @:\n[[ 58  64]\n [139 154]]\n\n\n\n64.7.1 Matrice Identit√† e Matrice Inversa\n\n\n64.7.2 Matrice Identit√†\nLa matrice identit√†, denotata come \\(\\mathbf{I}_n\\), √® una matrice quadrata di dimensione \\(n \\times n\\) con tutti gli elementi sulla diagonale principale uguali a 1 e tutti gli altri elementi uguali a 0. Ad esempio, una matrice identit√† 3x3 √®:\n\\[\n\\mathbf{I}_3 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]\nIn generale, una matrice identit√† di dimensione \\(n \\times n\\) √®:\n\\[\n\\mathbf{I}_n = \\begin{bmatrix}\n1 & 0 & \\cdots & 0 \\\\\n0 & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & 1\n\\end{bmatrix}\n\\]\nLa matrice identit√† ha la propriet√† fondamentale di essere l‚Äôelemento neutro per la moltiplicazione matriciale. Per qualsiasi matrice \\(\\mathbf{A}\\) di dimensioni \\(n \\times n\\):\n\\[\n\\mathbf{A} \\mathbf{I}_n = \\mathbf{A} \\quad \\text{e} \\quad \\mathbf{I}_n \\mathbf{A} = \\mathbf{A}.\n\\]\nIn NumPy, per creare la matrice identi√† usiamo il modulo .eye(). Per esempio:\n\nI = np.eye(3)\nprint(I)\n\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n\n\n\n\n64.7.3 Determinante di una Matrice\nIl determinante √® un numero associato a una matrice quadrata che fornisce informazioni essenziali sulle propriet√† della matrice stessa. √à uno scalare che pu√≤ indicare se una matrice √® invertibile, se un sistema di equazioni lineari ha una soluzione unica, e molto altro.\nIl determinante di una matrice pu√≤ essere interpretato in diversi modi:\n\nIn termini geometrici, il determinante di una matrice \\(2 \\times 2\\) o \\(3 \\times 3\\) rappresenta rispettivamente l‚Äôarea o il volume del parallelogramma o del parallelepipedo definito dai vettori delle righe (o colonne) della matrice. Un determinante pari a zero indica che i vettori sono linearmente dipendenti e che l‚Äôarea o il volume √® nullo, suggerendo che la matrice non ha un‚Äôinversa.\nAlgebraicamente, il determinante di una matrice quadrata pu√≤ dirci se la matrice √® invertibile. Se il determinante √® diverso da zero, la matrice √® invertibile, cio√® esiste una matrice inversa tale che il prodotto delle due sia la matrice identit√†. Se il determinante √® zero, la matrice non √® invertibile.\nNel contesto dei sistemi di equazioni lineari, se il determinante del coefficiente della matrice associata a un sistema √® zero, il sistema pu√≤ non avere soluzioni o avere un numero infinito di soluzioni. Se √® diverso da zero, il sistema ha una soluzione unica.\n\n\n64.7.3.1 Calcolo del Determinante per una Matrice 2x2\nPer una matrice \\(2 \\times 2\\):\n\\[\n\\mathbf{A} = \\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\n\\]\nil determinante √® calcolato come:\n\\[\n\\det(\\mathbf{A}) = ad - bc\n\\]\nQuesto semplice calcolo deriva dalla differenza tra il prodotto degli elementi della diagonale principale (dall‚Äôangolo superiore sinistro all‚Äôangolo inferiore destro) e il prodotto degli elementi della diagonale secondaria (dall‚Äôangolo superiore destro all‚Äôangolo inferiore sinistro).\n\n\n64.7.3.2 Calcolo del Determinante per Matrici di Dimensioni Superiori\nPer matrici di dimensioni superiori a \\(2 \\times 2\\), il calcolo del determinante diventa pi√π complesso. Un metodo comune per calcolare il determinante di matrici pi√π grandi √® l‚Äôespansione di Laplace o espansione per cofattori. Questo metodo si basa sulla ricorsione, calcolando il determinante attraverso una somma pesata di determinanti di matrici pi√π piccole (minori) che si ottengono eliminando una riga e una colonna dalla matrice originale.\n\n\n64.7.3.3 Calcolo del Determinante con NumPy\n√à possibile calcolare il determinante di una matrice utilizzando la funzione np.linalg.det(). Questa funzione pu√≤ essere utilizzata per calcolare il determinante di matrici quadrate di qualsiasi dimensione.\nEcco come calcolare il determinante di una matrice \\(2 \\times 2\\) con NumPy:\n\n# Definizione di una matrice 2x2\nA = np.array([[1, 2], [3, 4]])\n\n# Calcolo del determinante\ndeterminante = np.linalg.det(A)\nprint(\"Determinante di A:\", determinante)\n\nDeterminante di A: -2.0000000000000004\n\n\nPer una matrice \\(3 \\times 3\\) o di dimensioni superiori, il procedimento √® lo stesso:\n\n# Definizione di una matrice 3x3\nB = np.array([[6, 1, 1], [4, -2, 5], [2, 8, 7]])\n\n# Calcolo del determinante\ndeterminante_B = np.linalg.det(B)\nprint(\"Determinante di B:\", determinante_B)\n\nDeterminante di B: -306.0\n\n\nIn conclusione, il determinante √® uno strumento fondamentale per la comprensione delle propriet√† di una matrice. Attraverso il determinante, √® possibile comprendere la geometria della trasformazione rappresentata dalla matrice, verificare l‚Äôinvertibilit√† e determinare il comportamento di sistemi di equazioni lineari.\n\n\n\n64.7.4 Inversa di una Matrice\nL‚Äôinversa di una matrice quadrata \\(\\mathbf{A}\\), denotata come \\(\\mathbf{A}^{-1}\\), √® una matrice che, moltiplicata per \\(\\mathbf{A}\\), restituisce la matrice identit√† \\(\\mathbf{I}_n\\). L‚Äôinversa di una matrice esiste solo per matrici quadrate non singolari, ovvero matrici il cui determinante √® diverso da zero.\nLa propriet√† fondamentale dell‚Äôinversa √®:\n\\[\n\\mathbf{A} \\mathbf{A}^{-1} = \\mathbf{I}_n \\quad \\text{e} \\quad \\mathbf{A}^{-1} \\mathbf{A} = \\mathbf{I}_n.\n\\]\ndove \\(\\mathbf{I}_n\\) √® la matrice identit√† di dimensione \\(n \\times n\\).\n\n64.7.4.1 Esempio: Calcolo dell‚ÄôInversa di una Matrice \\(2 \\times 2\\)\nPer una matrice \\(2 \\times 2\\):\n\\[\n\\mathbf{A} = \\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\n\\]\nl‚Äôinversa, se esiste, √® data dalla formula:\n\\[\n\\mathbf{A}^{-1} = \\frac{1}{ad-bc} \\begin{bmatrix}\nd & -b \\\\\n-c & a\n\\end{bmatrix}\n\\]\ndove \\(ad-bc\\) √® il determinante della matrice \\(\\mathbf{A}\\). L‚Äôinversa esiste solo se questo determinante √® diverso da zero (cio√®, se \\(\\mathbf{A}\\) √® non singolare).\n\n\n\n64.7.5 Utilizzo dell‚ÄôInversa di una Matrice\nL‚Äôinversa di una matrice √® particolarmente utile per risolvere sistemi di equazioni lineari. Ad esempio, consideriamo un sistema rappresentato in forma matriciale come \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\), dove \\(\\mathbf{A}\\) √® la matrice dei coefficienti, \\(\\mathbf{x}\\) √® il vettore delle variabili incognite e \\(\\mathbf{b}\\) √® il vettore dei termini noti.\nSe \\(\\mathbf{A}\\) √® una matrice invertibile, possiamo risolvere per \\(\\mathbf{x}\\) moltiplicando entrambi i lati dell‚Äôequazione per \\(\\mathbf{A}^{-1}\\):\n\\[\n\\mathbf{A}^{-1} \\mathbf{A} \\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}.\n\\]\nPoich√© \\(\\mathbf{A}^{-1} \\mathbf{A} = \\mathbf{I}\\), otteniamo:\n\\[\n\\mathbf{I} \\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b},\n\\]\n\\[\n\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}.\n\\]\nQuesta propriet√† √® utile anche per altre applicazioni, come nella derivazione della formula per i coefficienti della regressione lineare.\n\n\n64.7.6 Calcolo dell‚ÄôInversa con NumPy\nIn Python, possiamo usare la libreria NumPy per calcolare l‚Äôinversa di una matrice in modo semplice ed efficiente. La funzione np.linalg.inv() permette di calcolare l‚Äôinversa di una matrice quadrata, a condizione che sia invertibile (cio√®, il suo determinante non √® zero).\nEcco come calcolare l‚Äôinversa di una matrice \\(2 \\times 2\\) utilizzando NumPy:\n\n# Definizione di una matrice 2x2\nA = np.array([[1, 2], [3, 4]])\n\n# Calcolo dell'inversa\nA_inv = np.linalg.inv(A)\nprint(\"Inversa di A:\")\nprint(A_inv)\n\nInversa di A:\n[[-2.   1. ]\n [ 1.5 -0.5]]\n\n\nPer verificare che il calcolo dell‚Äôinversa sia corretto, possiamo moltiplicare la matrice originale \\(\\mathbf{A}\\) per la sua inversa \\(\\mathbf{A}^{-1}\\) e verificare che il risultato sia la matrice identit√†:\n\n# Verifica del calcolo dell'inversa\nidentita = np.dot(A, A_inv)\nprint(\"Prodotto di A e A_inv (matrice identit√†):\")\nprint(identita)\n\nProdotto di A e A_inv (matrice identit√†):\n[[1.0000000e+00 0.0000000e+00]\n [8.8817842e-16 1.0000000e+00]]\n\n\nIn conclusione, l‚Äôinversa di una matrice √® uno strumento utile per risolvere sistemi di equazioni lineari e molte altre applicazioni. Con NumPy, calcolare l‚Äôinversa di una matrice √® semplice e veloce, permettendo di eseguire operazioni complesse in modo efficiente. Tuttavia, √® importante ricordare che non tutte le matrici hanno un‚Äôinversa; una matrice deve essere quadrata e avere un determinante diverso da zero per essere invertibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#regressione-lineare-e-stima-dei-coefficienti",
    "href": "chapters/linear_models/07_linear_algebra.html#regressione-lineare-e-stima-dei-coefficienti",
    "title": "64¬† Elementi di algebra lineare",
    "section": "64.8 Regressione Lineare e Stima dei Coefficienti",
    "text": "64.8 Regressione Lineare e Stima dei Coefficienti\nLa regressione lineare √® una tecnica statistica utilizzata per modellare la relazione tra una variabile dipendente (o risposta) e una o pi√π variabili indipendenti (o predittori). √à possibile rappresentare questo modello in termini di algebra matriciale per semplificare il calcolo dei coefficienti.\n\n64.8.1 Regressione Lineare Semplice\nLa regressione lineare semplice descrive una relazione lineare tra una variabile indipendente \\(x\\) e una variabile dipendente \\(y\\). Quando abbiamo un campione di \\(n\\) osservazioni, il modello assume la seguente forma:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + e_i, \\quad \\text{per} \\; i = 1, 2, \\ldots, n,\n\\]\ndove:\n\n\\(y_i\\) √® il valore osservato della variabile dipendente per l‚Äôosservazione \\(i\\),\n\\(\\beta_0\\) √® l‚Äôintercetta, che rappresenta il valore di \\(y\\) quando \\(x = 0\\),\n\\(\\beta_1\\) √® il coefficiente di regressione, che indica quanto varia \\(y\\) per una variazione unitaria di \\(x\\),\n\\(x_i\\) √® il valore della variabile indipendente per l‚Äôosservazione \\(i\\),\n\\(e_i\\) √® l‚Äôerrore o residuo per l‚Äôosservazione \\(i\\), rappresenta la differenza tra il valore osservato \\(y_i\\) e il valore previsto \\(\\hat{y}_i = \\beta_0 + \\beta_1 x_i\\).\n\nPer un campione di \\(n\\) osservazioni, possiamo rappresentare la regressione lineare in forma matriciale, che rende il modello pi√π compatto e facilita i calcoli statistici. La rappresentazione matriciale del modello di regressione lineare √®:\n\\[\n\\mathbf{y} = \\mathbf{Xb} + \\mathbf{e},\n\\]\ndove:\n\n\\(\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\) √® il vettore delle osservazioni della variabile dipendente,\n\\(\\mathbf{X} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix}\\) √® la matrice di design, in cui la prima colonna √® costituita da 1 per includere l‚Äôintercetta \\(\\beta_0\\),\n\\(\\mathbf{b} = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) √® il vettore dei coefficienti del modello,\n\\(\\mathbf{e} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\) √® il vettore degli errori o residui.\n\nQuesta forma matriciale sintetizza tutte le \\(n\\) equazioni del modello di regressione lineare semplice in un‚Äôunica espressione compatta, che rappresenta la relazione tra le osservazioni della variabile dipendente \\(y\\) e le corrispondenti osservazioni della variabile indipendente \\(x\\), tenendo conto degli errori di previsione.\n\n\n64.8.2 Regressione Lineare Multipla\nLa regressione lineare multipla estende la regressione lineare semplice includendo pi√π variabili indipendenti, consentendo di modellare la relazione tra una variabile dipendente e diverse variabili indipendenti. Il modello di regressione lineare multipla per un campione di \\(n\\) osservazioni con \\(p\\) variabili indipendenti pu√≤ essere scritto come:\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} + e_i, \\quad \\text{per} \\; i = 1, 2, \\ldots, n,\n\\]\ndove:\n\n\\(y_i\\) √® il valore osservato della variabile dipendente per l‚Äôosservazione \\(i\\),\n\\(\\beta_0\\) √® l‚Äôintercetta del modello,\n\\(\\beta_1, \\beta_2, \\ldots, \\beta_p\\) sono i coefficienti di regressione associati alle variabili indipendenti,\n\\(x_{i1}, x_{i2}, \\ldots, x_{ip}\\) sono i valori delle variabili indipendenti per l‚Äôosservazione \\(i\\),\n\\(e_i\\) √® l‚Äôerrore o residuo per l‚Äôosservazione \\(i\\), che rappresenta la differenza tra il valore osservato \\(y_i\\) e il valore previsto \\(\\hat{y}_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}\\).\n\nIn termini matriciali, il modello di regressione lineare multipla pu√≤ essere scritto come:\n\\[\n\\mathbf{y} = \\mathbf{Xb} + \\mathbf{e},\n\\]\ndove:\n\n\\(\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\) √® il vettore delle osservazioni della variabile dipendente, di dimensione \\(n \\times 1\\),\n\\(\\mathbf{X} = \\begin{bmatrix} 1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\ 1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n1} & x_{n2} & \\cdots & x_{np} \\end{bmatrix}\\) √® la matrice di design, di dimensione \\(n \\times (p+1)\\), dove la prima colonna √® composta da 1 per includere l‚Äôintercetta \\(\\beta_0\\),\n\\(\\mathbf{b} = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\\) √® il vettore dei coefficienti, di dimensione \\((p+1) \\times 1\\),\n\\(\\mathbf{e} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\) √® il vettore degli errori o residui, di dimensione \\(n \\times 1\\).\n\nL‚Äôequazione in forma matriciale esplicita per il campione di \\(n\\) osservazioni con \\(p\\) variabili indipendenti √®:\n\\[\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix} +\n\\begin{bmatrix}\ne_1 \\\\\ne_2 \\\\\n\\vdots \\\\\ne_n\n\\end{bmatrix}.\n\\]\nIn questa rappresentazione:\n\nIl prodotto \\(\\mathbf{Xb}\\) rappresenta i valori previsti (o stimati) del modello come combinazione lineare delle colonne della matrice di design \\(\\mathbf{X}\\), ponderata dai coefficienti \\(\\mathbf{b}\\).\nIl vettore \\(\\mathbf{e}\\) rappresenta gli errori o residui, che sono le differenze tra i valori osservati \\(\\mathbf{y}\\) e i valori previsti \\(\\mathbf{Xb}\\).\n\nQuesta forma compatta e ordinata consente un‚Äôefficiente analisi statistica e facilita i calcoli necessari per stimare i coefficienti del modello di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#stima-dei-coefficienti-con-il-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/07_linear_algebra.html#stima-dei-coefficienti-con-il-metodo-dei-minimi-quadrati",
    "title": "64¬† Elementi di algebra lineare",
    "section": "64.9 Stima dei Coefficienti con il Metodo dei Minimi Quadrati",
    "text": "64.9 Stima dei Coefficienti con il Metodo dei Minimi Quadrati\nPer ogni osservazione \\(i\\), l‚Äôerrore (o residuo) √® definito come la differenza tra il valore osservato \\(y_i\\) e il valore predetto \\(\\hat{y}_i\\) dal modello:\n\\[\ne_i = y_i - \\hat{y}_i,\n\\]\ndove:\n\n\\(y_i\\) √® il valore osservato dell‚Äôoutput per l‚Äôosservazione \\(i\\),\n\\(\\hat{y}_i\\) √® il valore predetto dal modello per l‚Äôosservazione \\(i\\).\n\nIn forma matriciale, possiamo rappresentare l‚Äôerrore per tutte le \\(n\\) osservazioni come segue:\n\\[\n\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}},\n\\]\ndove:\n\n\\(\\mathbf{e} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\) √® il vettore degli errori o residui,\n\\(\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\) √® il vettore delle osservazioni della variabile dipendente,\n\\(\\hat{\\mathbf{y}} = \\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_n \\end{bmatrix} = \\mathbf{Xb}\\) √® il vettore dei valori predetti dal modello.\n\nL‚Äôequazione matriciale esplicita per il vettore degli errori \\(\\mathbf{e}\\) √® quindi:\n\\[\n\\mathbf{e} = \\mathbf{y} - \\mathbf{Xb}.\n\\]\nQuesta equazione mostra che il vettore degli errori \\(\\mathbf{e}\\) √® la differenza tra il vettore delle osservazioni \\(\\mathbf{y}\\) e il vettore dei valori predetti \\(\\hat{\\mathbf{y}} = \\mathbf{Xb}\\). In altre parole, ogni elemento \\(e_i\\) del vettore degli errori rappresenta la differenza tra il valore osservato \\(y_i\\) e il valore predetto \\(\\hat{y}_i\\) per l‚Äôosservazione \\(i\\).\nL‚Äôobiettivo della regressione lineare √® minimizzare la somma degli errori quadrati (\\(SSE\\), Sum of Squared Errors) per tutte le osservazioni. Questa somma √® data da:\n\\[\n\\text{SSE} = \\sum_{i=1}^m e_i^2 = \\sum_{i=1}^m (y_i - \\hat{y}_i)^2.\n\\]\nUtilizzando la notazione matriciale, possiamo esprimere la somma degli errori quadrati come:\n\\[\n\\text{SSE} = \\mathbf{e}^T \\mathbf{e} = (\\mathbf{y} - \\mathbf{X} \\mathbf{b})^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}).\n\\]\nIl problema di ottimizzazione per minimizzare la somma degli errori quadrati si traduce in:\n\\[\n\\min_{\\mathbf{b}} (\\mathbf{y} - \\mathbf{X} \\mathbf{b})^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}),\n\\]\ndove:\n\n\\(\\mathbf{b}\\) √® il vettore dei coefficienti da stimare.\n\\(\\mathbf{X}\\) √® la matrice di design che include tutte le osservazioni delle variabili indipendenti.\n\\(\\mathbf{y}\\) √® il vettore delle osservazioni della variabile dipendente.\n\nPer trovare i coefficienti ottimali \\(\\mathbf{b}\\), calcoliamo la derivata parziale dell‚Äôerrore quadratico totale rispetto a \\(\\mathbf{b}\\) e la impostiamo a zero:\n\\[\n\\frac{\\partial}{\\partial \\mathbf{b}} (\\mathbf{y} - \\mathbf{X} \\mathbf{b})^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}) = -2 \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}).\n\\]\nImpostando questa derivata uguale a zero, otteniamo:\n\\[\n-2 \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}) = 0.\n\\]\nSemplificando, possiamo riscrivere l‚Äôequazione come:\n\\[\n\\mathbf{X}^T \\mathbf{y} = \\mathbf{X}^T \\mathbf{X} \\mathbf{b}.\n\\]\nAssumendo che la matrice \\(\\mathbf{X}^T \\mathbf{X}\\) sia invertibile, risolviamo per \\(\\mathbf{b}\\):\n\\[\n\\mathbf{b} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}.\n\\]\nPer gli scopi presenti, non √® necessario comprendere la derivazione formale in dettaglio. Tuttavia, possiamo fare un parallelo con il metodo dei minimi quadrati per il caso univariato per ottenere un‚Äôintuizione geometrica su cosa stiamo facendo.\nNel caso della regressione lineare semplice (univariata), minimizzare la somma degli errori quadrati significa trovare la retta che meglio si adatta ai dati in uno spazio bidimensionale (2D). Dal punto di vista geometrico, questo processo equivale a calcolare la derivata della funzione di errore rispetto ai coefficienti della retta, quindi impostando la derivata a zero per trovare il punto in cui la pendenza della tangente √® piatta. In altre parole, cerchiamo il punto in cui la pendenza della funzione di errore √® zero, che corrisponde a un minimo della funzione.\nNel caso della regressione lineare multipla, invece di lavorare in uno spazio bidimensionale, stiamo operando in uno spazio multidimensionale. Ogni dimensione aggiuntiva rappresenta una variabile indipendente (regressore) nel nostro modello. Quando prendiamo la derivata dell‚Äôerrore quadratico totale rispetto ai coefficienti \\(\\mathbf{b}\\) e la impostiamo a zero, stiamo essenzialmente cercando il punto in questo spazio multidimensionale in cui tutte le ‚Äúpendenze‚Äù (derivate parziali) sono zero. Questo punto rappresenta il minimo dell‚Äôerrore quadratico totale e corrisponde alla migliore stima dei coefficienti del nostro modello di regressione lineare, minimizzando l‚Äôerrore di previsione su tutti i dati.\nQuindi, mentre nel caso univariato minimizzare l‚Äôerrore quadratico trova la migliore linea retta che si adatta ai dati in 2D, nel caso multivariato troviamo il miglior piano o iperpiano che si adatta ai dati in uno spazio di dimensioni superiori.\n\n64.9.1 Stima dei Coefficienti OLS\nQuesta formula:\n\\[\n\\mathbf{b} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n\\]\n√® conosciuta come stima dei minimi quadrati ordinari (Ordinary Least Squares, OLS) per i coefficienti della regressione lineare multivariata. Essa fornisce i valori dei coefficienti \\(\\mathbf{b}\\) che minimizzano la somma degli errori quadrati e, quindi, rappresenta la migliore approssimazione lineare dei dati osservati.\nPer fare un esempio, consideriamo un piccolo insieme di dati nel caso della regressione bivariata e implementiamo la formula precedente in NumPy per trovare i coefficienti dei minimi quadrati.\n\n# Simulazione di una regressione lineare semplice\n\n# Scegli valori casuali per b_0 e b_1\nb = np.array([3.4, 12.35])  # pendenza e intercetta\nb = b[:, np.newaxis]\n\n# Simula n punti dati. x √® distribuito normalmente\nn = 30\ndata_mean = 0\ndata_std = 1\ndata = np.random.normal(\n    data_mean, data_std, size=(n, 1)\n)  # rendi l'array 2D per semplificare\n\n# Poich√© abbiamo b_0 nel nostro vettore dei pesi, aggiungiamo una colonna di 1s alla nostra matrice di dati\nones = np.ones((n, 1))\nx = np.hstack((ones, data))  # x √® la nostra matrice di design\n\n# Aggiungi rumore gaussiano\nnoise_loc = 0\nnoise_scale = 5\ne = np.random.normal(loc=noise_loc, scale=noise_scale, size=(n, 1))\n\n# Simula i valori di y\ny = x.dot(b) + e\n\n# Calcola le stime per b, le predizioni\nb_hat = np.linalg.inv(x.T @ x) @ x.T @ y\n\nprint(\"Valori veri di b:\\n\", b)\nprint(\"La nostra stima:\\n\", b_hat)\n\nValori veri di b:\n [[ 3.4 ]\n [12.35]]\nLa nostra stima:\n [[ 2.06167676]\n [12.96660755]]\n\n\nUtilizziamo i coefficienti dei minimi quadrati per calcolare i valori predetti e il coefficiente di determinazione.\n\ny_hat = x.dot(b_hat)\n\n# Calcola R^2\nSS_res = e.T @ e\nstd = y - y.mean()\nSS_tot = std.T @ std\nr2 = 1 - (SS_res / SS_tot)\n\nprint(r2)\n\n[[0.85247043]]\n\n\nRappresentiamo ora i valori predetti con la retta di regressione sovrapposta al diagramma a dispersione del campione dei dati.\n\n# Grafico dei dati\nfig, ax = plt.subplots()\nax.scatter(data, y)  # Tracciamento dei dati\nax.set(xlabel=\"x\", ylabel=\"y\", title=\"Regressione lineare semplice\")\n\n# Traccia la linea vera\nb_0, b_1 = b\nax.plot(data, b_0 + (b_1 * data), color=\"k\", label=\"Valore reale\")\n\n# Traccia il nostro fit\nax.plot(data, y_hat, color=\"r\", label=\"Il nostro fit\")\n_ = ax.legend()\n\n\n\n\n\n\n\n\nReplichiamo i risultati usando pingouin:\n\ny = np.array(y).flatten()\nlm = pg.linear_regression(x, y)\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n2.06\n1.02\n2.02\n0.05\n0.86\n0.86\n-0.03\n4.16\n\n\n1\nx2\n12.97\n0.98\n13.29\n0.00\n0.86\n0.86\n10.97\n14.97",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_linear_algebra.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_linear_algebra.html#informazioni-sullambiente-di-sviluppo",
    "title": "64¬† Elementi di algebra lineare",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Aug 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>64</span>¬† <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html",
    "href": "chapters/linear_models/08_stan_multreg.html",
    "title": "65¬† Il modello di regressione multipla",
    "section": "",
    "text": "Introduzione\nIn questo capitolo introdurremo il modello di regressione multipla mostrando come possa essere implementato in Stan. Ci concentreremo sull‚Äôinterpretazione dei coefficienti parziali di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#regressione-multipla",
    "href": "chapters/linear_models/08_stan_multreg.html#regressione-multipla",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.1 Regressione multipla",
    "text": "65.1 Regressione multipla\nLa regressione multipla rappresenta un‚Äôestensione del modello di regressione semplice, e permette di esplorare e quantificare le relazioni tra una variabile dipendente e pi√π variabili indipendenti.\nUn modello lineare univariato pu√≤ essere descritto, in forma matriciale, come\n\\[\n\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon},\n\\tag{65.1}\\]\ndove \\(\\mathbf{y} \\in \\mathbb{R}^n\\) √® il vettore delle variabili di risposta, \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times p}\\) √® la matrice delle costanti note, \\(\\boldsymbol{\\beta} \\in \\mathbb{R}^p\\) √® il vettore dei parametri sconosciuti, e \\(\\boldsymbol{\\epsilon} \\in \\mathbb{R}^n\\) √® il vettore degli errori casuali non osservabili. Espanso in forma completa, il modello dell‚ÄôEquazione¬†65.1 pu√≤ essere espresso come\n\\[\n\\begin{pmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{pmatrix},\n\\tag{65.2}\\]\ndove la prima colonna di \\(\\mathbf{X}\\) √® spesso un vettore di uno, denotato \\(\\mathbf{1}_n\\). Il modello dell‚ÄôEquazione¬†65.2 esprime ciascuna delle \\(n\\) osservazioni in \\(\\mathbf{y}\\) come una combinazione lineare dei parametri sconosciuti in \\(\\boldsymbol{\\beta}\\) con coefficienti da \\(\\mathbf{X}\\), cio√®,\n\\[ y_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta} + \\epsilon_i = \\sum_{j=1}^p x_{ij} \\beta_j + \\epsilon_i, \\]\nper \\(i = 1, \\ldots, n\\), dove \\(\\mathbf{x}_i \\in \\mathbb{R}^p\\) √® l‚Äôennesima riga di \\(\\mathbf{X}\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#interpretazione",
    "href": "chapters/linear_models/08_stan_multreg.html#interpretazione",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.2 Interpretazione",
    "text": "65.2 Interpretazione\nPassando dal modello semplice \\(y = a + bx + \\text{errore}\\) al modello pi√π generale \\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\text{errore}\\), emergono nuove complessit√†. Queste includono le decisioni su quali predittori \\(x\\) includere nel modello, l‚Äôinterpretazione dei coefficienti e delle loro interazioni, e la costruzione di nuovi predittori a partire dalle variabili esistenti per catturare elementi di discrezionalit√† e non linearit√†.\nI coefficienti di regressione, in un contesto di regressione multipla, sono tipicamente pi√π complicati da interpretare rispetto a quelli di un modello con un solo predittore. L‚Äôinterpretazione di un dato coefficiente, infatti, √® parzialmente condizionata dalle altre variabili presenti nel modello. Il coefficiente \\(\\beta_k\\) rappresenta la differenza media o attesa nella variabile risposta \\(y\\), confrontando due individui che differiscono di un‚Äôunit√† nel predittore \\(x_k\\) ma sono identici per quanto riguarda gli altri predittori. Questo concetto √® talvolta sintetizzato con l‚Äôespressione ‚Äúconfrontare due osservazionni (o persone) che differiscono per \\(x_k\\) a parit√† delle altre variabili‚Äù.\nDal punto di vista dell‚Äôimplementazione con Stan, l‚Äôestensione del modello per includere molteplici predittori dell‚Äôintelligenza del bambino √® relativamente semplice. √à necessario costruire una matrice \\(X\\) contenente le colonne che rappresentano i vari predittori che intendiamo analizzare. Per l‚Äôesempio specifico in questione, i predittori selezionati per l‚Äôintelligenza del bambino includono: la scolarit√† della madre (codificata come 0 o 1 a seconda che la madre abbia completato o meno le scuole superiori), l‚Äôintelligenza della madre e l‚Äôet√† della madre. Prima di procedere con l‚Äôanalisi, √® importante standardizzare tutte queste variabili per facilitare l‚Äôinterpretazione dei risultati e migliorare la stabilit√† numerica del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#un-esempio-pratico",
    "href": "chapters/linear_models/08_stan_multreg.html#un-esempio-pratico",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.3 Un esempio pratico",
    "text": "65.3 Un esempio pratico\nPer fare un esempio pratico, analizzeremo nuovamente i dati sull‚Äôintelligenza di un gruppo di bambini. In questo caso, cercheremo di predire l‚Äôintelligenza media dei bambini considerando tre fattori: se le madri hanno completato la scuola superiore, l‚Äôintelligenza della madre e l‚Äôet√† della madre.\nImportiamo i dati:\n\ndata_file = os.path.join(project_directory, \"data\", \"kidiq.dta\")\nkidiq = pd.read_stata(data_file)\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nCompiliamo e stampiamo il modello Stan di regressione multipla per questi dati. Il modello assume che i dati siano standardizzati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"mreg.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;   // Numero di osservazioni\n    int&lt;lower=1&gt; K;   // Numero di variabili indipendenti, intercetta inclusa\n    vector[N] x1;     // Prima variabile indipendente\n    vector[N] x2;     // Seconda variabile indipendente\n    vector[N] x3;     // Seconda variabile indipendente\n    // Aggiungi altri vettori se ci sono pi√π variabili indipendenti\n    vector[N] y;      // Vettore della variabile dipendente\n}\nparameters {\n    real alpha;           // Intercetta\n    real beta1;           // Coefficiente per la prima variabile indipendente\n    real beta2;           // Coefficiente per la seconda variabile indipendente\n    real beta3;           // Coefficiente per la terza variabile indipendente\n    // Definisci altri real per ulteriori coefficienti\n    real&lt;lower=0&gt; sigma;  // Errore del modello\n}\nmodel {\n    // Prior\n    alpha ~ student_t(3, 0, 2.5);\n    beta1 ~ student_t(3, 0, 2.5);\n    beta2 ~ student_t(3, 0, 2.5);\n    beta3 ~ student_t(3, 0, 2.5);\n    // Definisci prior per altri coefficienti\n    sigma ~ exponential(1);\n\n    // Likelihood\n    for (n in 1:N) {\n        y[n] ~ normal(alpha + beta1 * x1[n] + beta2 * x2[n] + + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n    }\n}\ngenerated quantities {\n    vector[N] log_lik; // Log-likelihood per ogni osservazione\n    vector[N] y_rep;  // Predizioni posteriori per ogni osservazione\n\n    for (n in 1:N) {\n        log_lik[n] = normal_lpdf(y[n] | alpha + beta1 * x1[n] + beta2 * x2[n] + + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n        y_rep[n] = normal_rng(alpha + beta1 * x1[n] + beta2 * x2[n] + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n    }\n}\n\n\n\nStandaridizziamo i predittori:\n\nx1 = stats.zscore(kidiq[\"mom_hs\"])\nx2 = stats.zscore(kidiq[\"mom_iq\"])\nx3 = stats.zscore(kidiq[\"mom_age\"])\n\n\ndf = pd.DataFrame({\n    \"one\": [1] * len(x1),  # Crea una lista di 1 della stessa lunghezza di x1\n    \"x1\": x1,\n    \"x2\": x2,\n    \"x3\": x3\n})\n\ndf.head()\n\n\n\n\n\n\n\n\n\none\nx1\nx2\nx3\n\n\n\n\n0\n1\n0.522233\n1.409460\n1.562029\n\n\n1\n1\n0.522233\n-0.710026\n0.820727\n\n\n2\n1\n0.522233\n1.030732\n1.562029\n\n\n3\n1\n0.522233\n-0.036733\n0.820727\n\n\n4\n1\n0.522233\n-0.484177\n1.562029\n\n\n\n\n\n\n\n\n\n# Convert scaled DataFrame to numpy matrix\nX = df.to_numpy()\n\n\n# Verificare le dimensioni di X\nprint(\"Dimensioni di X:\", X.shape)\n\nDimensioni di X: (434, 4)\n\n\nCreiamo un dizionario con i dati nel formato atteso da Stan:\n\nstan_data = {\n    \"N\": X.shape[0],\n    \"K\": X.shape[1],  # Nota: questa include anche la colonna dell'intercetta\n    \"x1\": df[\"x1\"],\n    \"x2\": df[\"x2\"],\n    \"x3\": df[\"x3\"],\n    \"y\": stats.zscore(\n        kidiq[\"kid_score\"]\n    )\n}\n\nEseguiamo il campionamento MCMC:\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n21:00:45 - cmdstanpy - INFO - CmdStan start processing\n21:00:45 - cmdstanpy - INFO - Chain [1] start processing\n21:00:45 - cmdstanpy - INFO - Chain [2] start processing\n21:00:45 - cmdstanpy - INFO - Chain [3] start processing\n21:00:45 - cmdstanpy - INFO - Chain [4] start processing\n21:00:46 - cmdstanpy - INFO - Chain [2] done processing\n21:00:46 - cmdstanpy - INFO - Chain [1] done processing\n21:00:46 - cmdstanpy - INFO - Chain [4] done processing\n21:00:46 - cmdstanpy - INFO - Chain [3] done processing\n\n\nEsaminiamo le tracce dei parametri:\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"sigma\"]))\n\n\n\n\n\n\n\n\nAnche nel caso della regressione multipla, i risultati ottenuti con l‚Äôapproccio bayesiano sono molto simili a quelli prodotti dall‚Äôapproccio basato sulla massima verosimiglianza.\nCalcoliamo una sintesi delle distribuzioni a posteriori dei parametri:\n\naz.summary(\n    fit, var_names=([\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"sigma\"]), hdi_prob=0.94\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.000\n0.043\n-0.082\n0.080\n0.0\n0.001\n9553.0\n5261.0\n1.0\n\n\nbeta1\n0.114\n0.045\n0.031\n0.201\n0.0\n0.000\n9409.0\n6308.0\n1.0\n\n\nbeta2\n0.414\n0.044\n0.330\n0.496\n0.0\n0.000\n9556.0\n6280.0\n1.0\n\n\nbeta3\n0.029\n0.043\n-0.050\n0.112\n0.0\n0.000\n9647.0\n6545.0\n1.0\n\n\nsigma\n0.891\n0.031\n0.835\n0.949\n0.0\n0.000\n9403.0\n5961.0\n1.0\n\n\n\n\n\n\n\n\nReplichiamo il risultato usando l‚Äôapproccio di massima verosimiglianza:\n\nlm = pg.linear_regression(X, stats.zscore(kidiq[\"kid_score\"]))\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-0.00\n0.04\n-0.00\n1.00\n0.21\n0.21\n-0.08\n0.08\n\n\n1\nx2\n0.11\n0.05\n2.50\n0.01\n0.21\n0.21\n0.02\n0.20\n\n\n2\nx3\n0.41\n0.04\n9.28\n0.00\n0.21\n0.21\n0.33\n0.50\n\n\n3\nx4\n0.03\n0.04\n0.68\n0.50\n0.21\n0.21\n-0.06\n0.12",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/08_stan_multreg.html#interpretazione-dei-coefficienti",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.4 Interpretazione dei coefficienti",
    "text": "65.4 Interpretazione dei coefficienti\nNel contesto della regressione multipla, l‚Äôinterpretazione dei coefficienti parziali differisce da quella della regressione bivariata. Una differenza chiave rispetto al modello di regressione bivariato √® nell‚Äôinterpretazione dei coefficienti. Nel caso bivariato, il coefficiente \\(\\beta_1\\) viene interpretato come il cambiamento atteso in \\(Y\\) al variare di una unit√† in \\(X_1\\). Tuttavia, nel modello di regressione multipla, l‚Äôinterpretazione di \\(\\beta_1\\) cambia. In questo caso, \\(\\beta_1\\) rappresenta il cambiamento atteso in \\(Y\\) al variare di una unit√† in \\(X_1\\), mantenendo costanti gli effetti di tutte le altre variabili \\(X_2, X_3, \\ldots, X_p\\). In altre parole, \\(\\beta_1\\) ci dice come varia in media \\(Y\\) quando \\(X_1\\) cambia, ma considera che altre variabili possono variare insieme a \\(X_1\\), e \\(\\beta_1\\) tiene conto di queste variazioni.\nNel nostro caso, il coefficiente associato all‚Äôintelligenza della madre, indicato come \\(\\beta\\) = 0.41, assume il seguente significato: prevediamo che l‚Äôintelligenza del bambino aumenti di 0.41 deviazioni standard in media per ogni deviazione standard aggiuntiva nell‚Äôintelligenza della madre, mantenendo costanti gli effetti del livello di istruzione e dell‚Äôet√† della madre. Questo implica che stiamo considerando l‚Äôimpatto dell‚Äôintelligenza della madre sull‚Äôintelligenza del bambino all‚Äôinterno di una popolazione di madri che sono omogenee per quanto riguarda il livello di istruzione e l‚Äôet√†.\nCosa significa mantenere costante l‚Äôeffetto di altre variabili? Consideriamo l‚Äôesempio della correlazione tra il numero di scarpe e le abilit√† matematiche. Esiste una marcata correlazione positiva tra queste due variabili. Tuttavia, √® evidente che i bambini, avendo in genere numeri di scarpe pi√π piccoli rispetto agli adulti, mostrano anche, presumibilmente, minori capacit√† matematiche. Questo esempio illustra che, se controlliamo per l‚Äôet√†, ossia se consideriamo solo soggetti della stessa et√†, la correlazione tra il numero di scarpe e le abilit√† matematiche scompare. Pertanto, nell‚Äôanalisi della relazione tra abilit√† matematiche (Y) e numero di scarpe (X), l‚Äôet√† (Z) agisce come variabile confondente. Controllare per Z significa esaminare la relazione tra Y e X limitandosi a individui della stessa et√†.\nMa ovviamente questo controllo empirico non √® sempre possibile. Nel modello di regressione, esso viene ‚Äúapprossimato‚Äù con una procedura statistica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#distribuzione-predittiva-a-posteriori",
    "href": "chapters/linear_models/08_stan_multreg.html#distribuzione-predittiva-a-posteriori",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.5 Distribuzione predittiva a posteriori",
    "text": "65.5 Distribuzione predittiva a posteriori\nCalcoliamo la distribuzione predittiva a posteriori e generiamo il PPC plot:\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive='y_rep',\n    observed_data={'y': stats.zscore(kidiq[\"kid_score\"])},\n)\n\n\n_ = az.plot_ppc(idata, data_pairs={'y': 'y_rep'})",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#il-controllo-statisico",
    "href": "chapters/linear_models/08_stan_multreg.html#il-controllo-statisico",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.6 Il Controllo Statisico",
    "text": "65.6 Il Controllo Statisico\nNella seguente simulazione illustreremo la procedura statistica utilizzata per isolare l‚Äôeffetto di una variabile controllando per un‚Äôaltra.\n\n# Creiamo dei dati di esempio\nnp.random.seed(0)\nN = 100\nX1 = np.random.normal(0, 1, N)\nX2 = X1 + np.random.normal(0, 0.5, N)\nY = 1 + 2 * X1 + 3 * X2 + np.random.normal(0, 1, N)\n\n# Modello completo Y ~ X1 + X2\nmodel_full = sm.OLS(Y, sm.add_constant(np.column_stack((X1, X2))))\nresults_full = model_full.fit()\n\n# Regressione di Y su X2\nmodel_Y_on_X2 = sm.OLS(Y, sm.add_constant(X2))\nresiduals_Y = model_Y_on_X2.fit().resid\n\n# Regressione di X1 su X2\nmodel_X1_on_X2 = sm.OLS(X1, sm.add_constant(X2))\nresiduals_X1 = model_X1_on_X2.fit().resid\n\n# Regressione dei residui di Y sui residui di X1\nmodel_residuals = sm.OLS(residuals_Y, sm.add_constant(residuals_X1))\nresults_residuals = model_residuals.fit()\n\n# Stampiamo i risultati\nprint(\"Coefficient from full model for X1: {:.4f}\".format(results_full.params[1]))\nprint(\n    \"Coefficient from regression of residuals: {:.4f}\".format(\n        results_residuals.params[1]\n    )\n)\n\nCoefficient from full model for X1: 1.9782\nCoefficient from regression of residuals: 1.9782\n\n\nQuesto esempio illustra il concetto di coefficiente parziale di regressione. Questo coefficiente quantifica l‚Äôeffetto della variabile esplicativa \\(X_j\\) sulla variabile dipendente \\(Y\\), depurando l‚Äôeffetto di \\(X_j\\) dall‚Äôinfluenza degli altri predittori nel modello. In sostanza, il coefficiente parziale di regressione valuta l‚Äôimpiego di \\(X_j\\) su \\(Y\\) quando \\(X_j\\) √® considerata linearmente indipendente rispetto agli altri predittori \\(X\\). L‚Äôeffetto misurato √® quindi quello della sola componente di \\(X_j\\) che non √® spiegata linearmente dai restanti predittori \\(X\\) sulla parte di \\(Y\\) che √® anch‚Äôessa indipendente dai medesimi predittori.\nPer chiarire ulteriormente, questo approccio statistico si focalizza sull‚Äôanalizzare l‚Äôeffetto di \\(X_j\\) eliminando l‚Äôinfluenza lineare degli altri predittori \\(X\\). √à simile a valutare la relazione tra \\(Y\\) e \\(X_j\\) in un contesto ideale dove tutti gli individui presentano livelli identici per le altre variabili \\(X\\). Tale metodo non eguaglia gli effetti non lineari che possono essere presenti tra le variabili, limitandosi a correggere solo per le associazioni lineari. In questo modo, il controllo statistico tenta di approssimare una condizione di omogeneit√† tra i soggetti rispetto alle altre variabili \\(X\\), consentendo di isolare e valutare pi√π precisamente l‚Äôeffetto puro di \\(X_j\\) su \\(Y\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#quali-predittori-includere-nel-modello",
    "href": "chapters/linear_models/08_stan_multreg.html#quali-predittori-includere-nel-modello",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.7 Quali Predittori Includere nel Modello?",
    "text": "65.7 Quali Predittori Includere nel Modello?\nL‚Äôuso del modello di regressione multipla ha principalmente due scopi. In primo luogo, √® impiegato per la predizione, ovvero per ottenere la migliore stima possibile di \\(Y\\) utilizzando una combinazione lineare delle variabili \\(X_1, X_2, \\ldots, X_p\\). In questo contesto, i coefficienti \\(\\beta_i\\) sono interpretati come pesi che ottimizzano la previsione di \\(Y\\) in base ai valori delle variabili indipendenti.\nIn secondo luogo, il modello di regressione multipla viene spesso utilizzato per descrivere le relazioni tra variabili. Tuttavia, √® cruciale comprendere che il modello non √® stato originariamente creato per stabilire relazioni causali. Pertanto, bisogna essere cauti nell‚Äôattribuire interpretazioni causali dirette ai coefficienti \\(\\beta_i\\). Il modello stima correttamente i coefficienti parziali di regressione solo quando tutte le variabili che influenzano \\(Y\\) sono incluse nel modello. Nella pratica, spesso non conosciamo tutte le variabili rilevanti, il che pu√≤ portare a errori di specificazione.\nIl modello di regressione multipla √® uno strumento potente per predire e analizzare le relazioni tra variabili, ma √® fondamentale riconoscerne le limitazioni, soprattutto quando si cercano interpretazioni causali. In campi come la psicologia, dove √® cruciale comprendere le dinamiche causali, diventa essenziale una scelta accurata delle variabili da includere nel modello per prevenire distorsioni nelle stime dei coefficienti di regressione.\nTradizionalmente, si riteneva vantaggioso includere nel modello il maggior numero possibile di variabili per ottenere un livello di ‚Äúcontrollo‚Äù statistico pi√π elevato. Tuttavia, come sottolineato da McElreath (2020), questo approccio pu√≤ portare a una ‚Äúinsalata causale‚Äù. Questo termine descrive una situazione in cui la mancanza di attenzione alla struttura causale tra le variabili porta all‚Äôinclusione di variabili di controllo inappropriate, causando distorsioni nelle stime.\nIn alcuni casi, l‚Äôinserimento di determinate variabili di controllo √® indispensabile per evitare distorsioni, mentre in altri casi, l‚Äôinclusione di variabili non pertinenti pu√≤ portare a risultati fuorvianti. Questo sottolinea l‚Äôimportanza di formulare ipotesi chiare e ben ponderate sulla struttura causale tra le variabili in esame.\nL‚Äôefficacia e la validit√† dei risultati ottenuti tramite regressione dipendono strettamente dalla correttezza delle ipotesi causali formulate, sia esplicitamente che implicitamente, dal ricercatore. Per superare i limiti dell‚Äôapproccio dell‚Äô‚Äúinsalata causale‚Äù, √® cruciale che la costruzione del modello di regressione rifletta attentamente queste ipotesi causali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#utilizzo-della-regressione-multipla",
    "href": "chapters/linear_models/08_stan_multreg.html#utilizzo-della-regressione-multipla",
    "title": "65¬† Regressione multipla con Stan",
    "section": "65.8 Utilizzo della Regressione Multipla",
    "text": "65.8 Utilizzo della Regressione Multipla\nLa regressione √® il metodo pi√π comune per adattare una linea (o un iper-piano) che spiega la variazione di una variabile dipendente rispetto a una o pi√π variabili indipendenti. Utilizzare una o pi√π variabili per spiegare la variazione in un‚Äôaltra √® un concetto chiave dei modelli lineari.\n\n65.8.1 Identificazione degli Effetti Causali\nQuando si tratta di identificare effetti causali, la regressione √® il metodo pi√π comune per stimare la relazione tra due variabili, controllando contemporaneamente per altre variabili. Questo processo permette di chiudere ‚Äúporte backdoor‚Äù con questi controlli. √à pi√π preciso parlare di ‚Äúaggiustare‚Äù per queste variabili piuttosto che ‚Äúcontrollarle‚Äù, poich√© non esercitiamo un vero controllo come faremmo in un esperimento controllato. Tuttavia, il termine ‚Äúcontrollo‚Äù rimane il pi√π comunemente usato.\nEcco alcuni punti chiave:\n\nPredire una Variabile con un‚ÄôAltra: Possiamo utilizzare i valori di una variabile \\(X\\) per predire i valori di un‚Äôaltra variabile \\(Y\\). Questo √® chiamato spiegare \\(Y\\) utilizzando \\(X\\). Si tratta di una spiegazione puramente statistica che non chiarisce il motivo per cui \\(Y\\) accade, a meno che non abbiamo identificato un effetto causale di \\(X\\) su \\(Y\\).\nAdattare una Linea o un Iperpiano: Esistono diversi modi per modellare la relazione tra variabili; uno comune √® adattare una linea o un iperpiano. Ad esempio, nella regressione lineare standard \\(Y = a + bX\\), i coefficienti vengono stimati minimizzando la somma dei residui quadrati, ovvero la somma degli errori di previsione elevati al quadrato. Oppure, i coefficienti possono essere stimati con un metodo bayesiano. La qualit√† dell‚Äôapprossimazione dipende dalla linearit√† del vero modello.\nPro e Contro:\n\nPro: Utilizza efficientemente la variazione nei dati.\nPro: Una retta o un iperpiano sono facili da interpretare.\nContro: Pu√≤ perdere variazioni interessanti nei dati.\nContro: Se la forma funzionale scelta √® errata, i risultati possono essere inaccurati.\n\nInterpretazione dei Coefficienti: Il coefficiente associato a una variabile \\(X\\) pu√≤ essere interpretato come la pendenza: un aumento di un‚Äôunit√† in \\(X\\) √® associato a un aumento di \\(b\\) unit√† in \\(Y\\).\nCon pi√π Predittori: Con un solo predittore, la stima della pendenza √® la covarianza di \\(X\\) e \\(Y\\) divisa per la varianza di \\(X\\). Con pi√π predittori, la stima tiene conto delle correlazioni tra i diversi predittori.\nPrevisioni e Residui: Inserendo i valori predittivi di un‚Äôosservazione in una regressione stimata, otteniamo una previsione \\(\\hat{Y}\\). La differenza tra \\(Y\\) e \\(\\hat{Y}\\) rappresenta la parte non spiegata, chiamata ‚Äúresiduo‚Äù.\nAggiunta di un‚ÄôAltra Variabile: Aggiungendo una variabile \\(Z\\) all‚Äôequazione di regressione, il coefficiente di ciascuna variabile viene stimato utilizzando la variazione residua dopo aver rimosso quella spiegata dall‚Äôaltra variabile. Questo processo ‚Äúaggiusta per \\(Z\\)‚Äù.\nModelli Non Lineari: Se la relazione tra \\(X\\) e \\(Y\\) non √® ben rappresentata da una linea retta, possiamo utilizzare modelli non lineari. I modelli lineari possono essere adattati per previsioni non lineari mediante combinazioni lineari di variabili (sono ‚Äúlineari nei parametri‚Äù). Alternativamente, possiamo utilizzare modelli di regressione non lineare come il probit, il logit, o altri modelli avanzati.\n\nQuesti sono i concetti fondamentali della regressione. √à importante ricordare che, se il modello di regressione scelto si avvicina al vero modello della popolazione, le sue stime saranno generalmente accurate. Tuttavia, dobbiamo sempre tenere presente che il modello di regressione √® stato ideato per descrivere le associazioni tra variabili e non necessariamente per identificare rapporti causali, anche se spesso viene usato in questo modo ‚Äì si vedano il Capitolo 68 e il Capitolo 69.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Regressione multipla con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#considerazioni-conclusive",
    "href": "chapters/linear_models/08_stan_multreg.html#considerazioni-conclusive",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.9 Considerazioni Conclusive",
    "text": "65.9 Considerazioni Conclusive\nNel suo libro Statistical Rethinking, McElreath (2020) introduce una metafora per i modelli statistici, paragonandoli ai Golem, creature della mitologia antica, prive di volont√† propria e animate solo dall‚Äôintento di chi le crea. Questi esseri, dotati di grande forza ma privi di giudizio autonomo, possono diventare pericolosi se non vengono guidati con saggezza. Allo stesso modo, i modelli statistici sono strumenti potenti che, se utilizzati senza una comprensione adeguata del contesto e delle loro limitazioni, possono portare a conclusioni errate o fuorvianti.\nMcElreath (2020) suggerisce che, nella costruzione di modelli matematici, gli scienziati creano moderni equivalenti di questi Golem. Sebbene tali modelli influenzino il mondo reale attraverso le previsioni che generano e le intuizioni che offrono, non dovrebbero essere considerati come rappresentazioni assolute della verit√†. I modelli statistici, infatti, sono strumenti costruiti per uno scopo specifico: essi eseguono calcoli con grande precisione, ma mancano della capacit√† di comprendere o interpretare il contesto pi√π ampio in cui vengono applicati.\nIl modello di regressione, in particolare, √® un esempio di come questi strumenti possano produrre risultati numerici concreti, ma siano limitati nella loro capacit√† di affrontare questioni che richiedono un approccio pi√π creativo e comprensivo. McElreath (2020) sottolinea che nessun modello statistico, da solo, √® sufficiente per risolvere il complesso problema dell‚Äôinferenza causale a partire da dati empirici. Il modello di regressione, per quanto utile nel descrivere relazioni tra variabili, non √® dotato di una reale comprensione delle dinamiche di causa ed effetto. Senza un‚Äôinterpretazione critica e un uso consapevole da parte degli studiosi, questo strumento, progettato per scopi specifici, pu√≤ risultare non solo inefficace, ma anche potenzialmente dannoso.\nCarlin e Moreno-Betancur (2023) sottolineano che il modello di regressione pu√≤ essere usato per tre scopi diversi:\n\nDescrizione delle associazioni: ad esempio, descrivere la prevalenza di una certa condizione in diverse sottopopolazioni;\nPredizione: utilizzare un insieme di predittori per prevedere in modo attendibile il valore di (Y) per gli individui per i quali sono disponibili le misure di (X);\nAnalisi delle relazioni causali: determinare in che misura un esito dipende da un particolare intervento.\n\nSecondo Carlin e Moreno-Betancur (2023) √® importante che i ricercatori chiariscano l‚Äôobiettivo specifico per cui utilizzano il modello di regressione. Purtroppo, questa fondamentale classificazione delle domande di ricerca non √® ancora penetrata a fondo nell‚Äôinsegnamento e nella pratica della statistica, soprattutto per quanto riguarda i metodi di regressione. In molti campi, inclusa la psicologia, si continua a insegnare e a utilizzare i modelli di regressione come un toolkit universale, applicato senza un‚Äôadeguata considerazione dello scopo reale. Un approccio diffuso √® quello di ‚Äútrovare il miglior modello per i dati‚Äù e successivamente sviluppare un‚Äôinterpretazione del modello adattato.\nInvece, Carlin e Moreno-Betancur (2023) raccomandano che l‚Äôinsegnamento del modello di regressione sia guidato da una prospettiva basata sull‚Äôobiettivo specifico della ricerca. Suggeriscono di utilizzare la classificazione delle tre tipologie di domande di ricerca per orientare l‚Äôapprendimento, introducendo gli aspetti tecnici dei modelli di regressione e di altri metodi solo quando sono direttamente rilevanti per il particolare scopo della ricerca. Questo approccio permette di focalizzarsi sull‚Äôuso appropriato dei modelli in base al contesto e all‚Äôobiettivo specifico, evitando l‚Äôapplicazione indiscriminata e la conseguente possibilit√† di fraintendimenti.\nIn conclusione, come afferma McElreath (2020), √® fondamentale che i ricercatori utilizzino i modelli statistici con piena consapevolezza delle loro limitazioni e con una considerazione attenta del contesto in cui vengono applicati. I modelli sono strumenti potenti, ma la loro efficacia dipende dalla saggezza e dall‚Äôintenzione di chi li utilizza. Solo adottando un approccio critico e informato possiamo evitare di trasformare questi potenti strumenti in Golem senza controllo, assicurando che essi contribuiscano realmente alla comprensione del mondo che ci circonda.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#esercizi",
    "href": "chapters/linear_models/08_stan_multreg.html#esercizi",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.10 Esercizi",
    "text": "65.10 Esercizi\n\nEsercizio 65.1 Considera il seguente modello lineare univariato in forma matriciale:\n\\[ \\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\]\nI valori delle variabili indipendenti (\\(x_1\\), \\(x_2\\) e \\(x_3\\)) per cinque osservazioni sono:\n\\[\n  x_1 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix}, \\quad\n  x_2 = \\begin{pmatrix} 11 \\\\ 9 \\\\ 12 \\\\ 10 \\\\ 11 \\end{pmatrix}, \\quad\n  x_3 = \\begin{pmatrix} 12 \\\\ 9 \\\\ 7 \\\\ 8 \\\\ 6 \\end{pmatrix}\n  \\]\nI valori della variabile dipendente sono:\n\\[\n  y = \\begin{pmatrix} 5.7 \\\\ 4.7 \\\\ 12.6 \\\\ 10.8 \\\\ 8.5 \\end{pmatrix}\n\\]\nI coefficienti (\\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\) e \\(\\beta_3\\)) sono:\n\\[\n  \\beta_0 = -1.402020, \\quad \\beta_1 = 0.183838, \\quad \\beta_2 = 1.405051, \\quad \\beta_3 = -0.664646\n  \\]\n\nDetermina le matrici \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\) e \\(\\boldsymbol{\\epsilon}\\) e scrivi l‚Äôequazione completa in forma matriciale.\nEspandi il modello per ottenere cinque equazioni esplicite, una per ciascuna osservazione, utilizzando i valori forniti.\nTrova gli errori casuali (\\(\\epsilon_1\\), \\(\\epsilon_2\\) e \\(\\epsilon_3\\), \\(\\epsilon_4\\), \\(\\epsilon_5\\)).\nTrova i valori predetti (\\(\\hat{y}_1\\), \\(\\hat{y}_2\\) e \\(\\hat{y}_3\\), \\(\\hat{y}_4\\), \\(\\hat{y}_5\\)).\n\n\n\nEsercizio 65.2 Obiettivo: calcolare i coefficienti \\(\\beta\\) del modello lineare univariato usando il metodo dei minimi quadrati.\nI valori delle variabili indipendenti (\\(x_1\\), \\(x_2\\) e \\(x_3\\)) per cinque osservazioni sono:\n\\[\n  x_1 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix}, \\quad\n  x_2 = \\begin{pmatrix} 11 \\\\ 9 \\\\ 12 \\\\ 10 \\\\ 11 \\end{pmatrix}, \\quad\n  x_3 = \\begin{pmatrix} 12 \\\\ 9 \\\\ 7 \\\\ 8 \\\\ 6 \\end{pmatrix}\n\\]\nI valori delle variabili dipendenti (\\(\\mathbf{y}\\)) sono:\n\\[\n  y = \\begin{pmatrix} 5.7 \\\\ 4.7 \\\\ 12.6 \\\\ 10.8 \\\\ 8.5 \\end{pmatrix}\n\\]\nLa formula dei minimi quadrati per calcolare i coefficienti \\(\\beta\\) in un modello lineare √® data da:\n\\[ \\boldsymbol{\\beta} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}. \\]\nQuesta formula minimizza la somma dei quadrati degli errori tra i valori osservati e quelli previsti dal modello. In altre parole, cerca di trovare i valori di \\(\\beta\\) che riducono al minimo le discrepanze tra i dati osservati e quelli stimati dal modello lineare.\n\nAggiungi una colonna di 1 alla matrice \\(\\mathbf{X}\\) per includere l‚Äôintercetta.\nScrivi la matrice \\(\\mathbf{X}\\) e il vettore \\(\\mathbf{y}\\) utilizzando i dati forniti.\nCalcola i coefficienti \\(\\beta\\) utilizzando la formula dei minimi quadrati. Implementa la formula in Python e calcola i valori di \\(\\beta\\). Controlla i risultati usando pingouin.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_stan_multreg.html#informazioni-sullambiente-di-sviluppo",
    "title": "65¬† Il modello di regressione multipla",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas     : 2.2.2\narviz      : 0.18.0\nmatplotlib : 3.9.1\ncmdstanpy  : 1.2.4\npingouin   : 0.5.4\nscipy      : 1.14.0\nstatsmodels: 0.14.2\nnumpy      : 1.26.4\nlogging    : 0.5.1.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nCarlin, John B, e Margarita Moreno-Betancur. 2023. ¬´On the uses and abuses of regression models: a call for reform of statistical practice and teaching¬ª. arXiv preprint arXiv:2309.06668.\n\n\nGelman, Andrew, Jennifer Hill, e Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nWestreich, Daniel, e Sander Greenland. 2013. ¬´The table 2 fallacy: presenting and interpreting confounder and modifier coefficients¬ª. American Journal of Epidemiology 177 (4): 292‚Äì98.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html",
    "href": "chapters/linear_models/09_hier_regr.html",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "",
    "text": "Introduzione\nI modelli multilivello rappresentano uno strumento statistico di fondamentale importanza in psicologia, capace di affrontare la complessit√† intrinseca di molti disegni sperimentali nel campo. Tuttavia, il loro utilizzo non √® esente da insidie, come evidenziato in un recente studio di Gelman e Brown (2024).\nLa ricerca psicologica spesso si trova ad analizzare dati con strutture gerarchiche o nidificate: pensiamo alle misurazioni ripetute su singoli individui, alle manipolazioni sperimentali applicate a gruppi, o alle valutazioni fornite da diversi osservatori. In questi contesti, le domande di ricerca possono riguardare come una manipolazione influenzi un cambiamento, come gli effetti varino tra gruppi, o come l‚Äôimpatto di una variabile dipenda dai livelli di un‚Äôaltra. La variabilit√† interindividuale, inoltre, spinge spesso i ricercatori verso confronti intra-soggetto, sia per ragioni teoretiche che di efficienza statistica.\nGelman e Brown (2024) mettono in luce due fattori critici che possono portare a un‚Äôeccessiva fiducia nelle conclusioni tratte da dati rumorosi, contribuendo cos√¨ alla crisi di replicabilit√† in psicologia. Il primo fattore riguarda proprio la complessit√† dell‚Äôanalisi di dati multilivello: √® facile incorrere in falsi positivi dovuti a errori correlati, risulta difficile effettuare controlli di plausibilit√† su analisi complesse, e la modellazione multilivello introduce sfide interpretative specifiche.\nIl secondo fattore critico concerne l‚Äôinterpretazione della letteratura empirica. I risultati pubblicati tendono spesso a sovrastimare le dimensioni degli effetti, un fenomeno attribuibile alla bassa potenza statistica e alla selezione basata sulla significativit√† (Ioannidis 2008). Inoltre, si riscontrano frequentemente discrepanze tra le affermazioni fatte e le evidenze empiriche a loro supporto.\nUn esempio illuminante di queste problematiche emerge dalla ri-analisi condotta da Gelman e Brown (2024) sui dati di Aungle e Langer (2023). Applicando un modello statistico pi√π appropriato, l‚Äôeffetto originariamente riportato da Aungle e Langer (2023) scompare, evidenziando come l‚Äôuso inadeguato di modelli multilivello possa portare a conclusioni errate.\nAlla luce di queste considerazioni, appare evidente l‚Äôimportanza di una solida comprensione dei modelli multilivello per chi si occupa di ricerca psicologica. Questo capitolo si propone quindi di fornire un‚Äôintroduzione a questa classe di modelli statistici, con l‚Äôobiettivo di dotare gli studenti degli strumenti necessari per navigare le complessit√† di questa specifica classe di analisi dei dati in psicologia.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#concetti-di-base",
    "href": "chapters/linear_models/09_hier_regr.html#concetti-di-base",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.1 Concetti di base",
    "text": "66.1 Concetti di base\nI modelli multilivello affrontano una delle principali limitazioni del modello di regressione tradizionale: l‚Äôassunzione di indipendenza delle osservazioni. Nel modello di regressione classico, si presuppone che per ogni valore di \\(x\\), le osservazioni \\(y\\) siano campionate in modo indipendente dalla distribuzione \\(p(y \\mid x)\\). Ci√≤ implica che gli errori \\(y_i - E(Œ± + Œ≤x_i)\\) siano tra loro indipendenti, una condizione garantita solo in specifici disegni di ricerca, come il campionamento casuale semplice. Tuttavia, numerosi disegni sperimentali in psicologia violano questa assunzione. √à frequente, ad esempio, che lo stesso individuo venga osservato in diverse condizioni, generando una struttura di dati con osservazioni correlate o raggruppate (clustered).\nI modelli ad effetti misti, o multilivello, sono stati sviluppati proprio per gestire queste situazioni complesse, rendendoli particolarmente adatti per i disegni a misure ripetute, cos√¨ comuni nella ricerca psicologica. Questi modelli, conosciuti anche come modelli gerarchici, modelli ad effetti casuali o modelli nidificati, rappresentano un approccio efficace per l‚Äôanalisi di dati organizzati in gruppi o livelli.\nLa versatilit√† dei modelli gerarchici si manifesta nella loro applicabilit√† a diverse tipologie di dati: geograficamente nidificati (ad esempio, dati di citt√† all‚Äôinterno di province, province all‚Äôinterno di stati), organizzati gerarchicamente (come studenti all‚Äôinterno di scuole o pazienti in ospedali), o implicanti misurazioni ripetute sugli stessi individui. Questa flessibilit√† consente di gestire le complessit√† intrinseche a tali dati, tenendo conto sia delle variazioni condivise che di quelle uniche tra i gruppi.\nUn aspetto fondamentale dei modelli gerarchici √® la loro capacit√† di facilitare la condivisione di informazioni tra i gruppi. Ci√≤ avviene mediante l‚Äôimpiego di distribuzioni priori per i parametri, influenzate a loro volta da distribuzioni priori di livello superiore, comunemente chiamate iperpriori. Il prefisso ‚Äúiper‚Äù deriva dal termine greco per ‚Äúsopra‚Äù, indicando che queste distribuzioni priori operano a un livello superiore rispetto alle distribuzioni priori standard. Le distribuzioni degli iperparametri consentono al modello di equilibrare la descrizione delle caratteristiche specifiche dei gruppi con una descrizione delle tendenze comuni tra i gruppi.\nLa figura successiva illustra graficamente le differenze tra gli approcci dei modelli aggregati (dove i dati sono trattati come se provenissero da un unico gruppo), dei modelli non aggregati (dove ogni gruppo √® trattato separatamente) e dei modelli gerarchici (o parzialmente aggregati), dove le informazioni sono condivise tra i gruppi.\n\n\n\nLe differenze tra un modello aggregato (pooled), un modello non aggregato (unpooled) e un modello gerarchico. (Figura tratta da Martin (2024)).\n\n\nNel contesto della regressione lineare gerarchica Bayesiana, l‚Äôutilizzo di librerie specializzate come Bambi facilita l‚Äôimplementazione di questi modelli complessi. Questa metodologia si rivela particolarmente utile nell‚Äôanalisi di dataset che comprendono diverse unit√† di osservazione, rappresentate dai soggetti, ciascuna delle quali √® associata a multiple misurazioni.\nPer una comprensione visiva pi√π intuitiva dei modelli gerarchici, si consiglia di consultare il demo interattivo di Michael Freeman, accessibile su questo sito.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#complete-pooling-no-pooling-partial-pooling",
    "href": "chapters/linear_models/09_hier_regr.html#complete-pooling-no-pooling-partial-pooling",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.2 Complete Pooling, No Pooling, Partial Pooling",
    "text": "66.2 Complete Pooling, No Pooling, Partial Pooling\nNei capitoli precedenti, √® stato introdotto il concetto di modellazione gerarchica bayesiana, con particolare attenzione alla stima dei parametri di distribuzioni di probabilit√†. Per un approfondimento su questo tema, si veda il Capitolo 55. Il presente capitolo si propone di estendere tale concetto alla stima dei parametri in un modello di regressione lineare, focalizzandosi sull‚Äôanalisi di dati suddivisi in vari gruppi.\nNell‚Äôaffrontare l‚Äôanalisi di dati provenienti da gruppi eterogenei, si possono delineare tre principali approcci metodologici, ciascuno con peculiari vantaggi e limitazioni:\n\nComplete Pooling: Questo modello prescinde dalla struttura gerarchica dei dati, trattando tutte le unit√† osservative come appartenenti a un‚Äôunica popolazione. Sebbene questo approccio possa incrementare la precisione delle stime attraverso l‚Äôaggregazione di tutti i dati, rischia di obliterare informazioni cruciali specifiche di ciascun gruppo, risultando potenzialmente eccessivamente generalizzante.\nNo Pooling: In antitesi al precedente, questo modello considera ogni gruppo come entit√† indipendente, ignorando qualsiasi struttura gerarchica. Questa metodologia, pur consentendo di evidenziare le peculiarit√† di ogni gruppo, pu√≤ condurre a conclusioni meno robuste a causa della mancanza di un contesto pi√π ampio e della potenziale scarsit√† di dati per singoli gruppi.\nPartial Pooling (o Modello Multi-Livello): Rappresenta un approccio intermedio e pi√π equilibrato. Questo modello presuppone che pendenze e intercette di ciascun gruppo siano realizzazioni di variabili casuali, distribuite normalmente con parametri di media e varianza condivisi tra tutti i gruppi.\n\nIl modello di ‚Äúpartial pooling‚Äù si distingue per la sua capacit√† di conciliare l‚Äôindipendenza dei gruppi con l‚Äôesigenza di un‚Äôanalisi aggregata. Questa metodologia facilita un adeguato ‚Äúshrinkage‚Äù dei parametri, attenuando l‚Äôimpatto di valori anomali o di gruppi con campioni limitati. Consente inoltre alle stime parametriche di ogni gruppo di essere influenzate sia dai dati specifici che dalla tendenza generale osservata nei dati aggregati.\nL‚Äôanalisi gerarchica, incarnata nel modello di partial pooling, offre quindi un compromesso ottimale tra gli approcci di complete pooling e no pooling, sintetizzando i benefici di entrambe le metodologie. Questo approccio permette di preservare le informazioni specifiche di ciascun gruppo, mantenendo al contempo una visione d‚Äôinsieme che migliora la robustezza e l‚Äôaccuratezza delle stime.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#eda",
    "href": "chapters/linear_models/09_hier_regr.html#eda",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.3 EDA",
    "text": "66.3 EDA\nIniziamo importando i dati e ispezionando la struttura delle osservazioni suddivise nei diversi cluster.\n\ndata = bmb.load_data(\"sleepstudy\")\ndata.head()\n\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n0\n249.5600\n0\n308\n\n\n1\n258.7047\n1\n308\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n\n\n\n\n\n\nEliminiamo le righe in cui la colonna ‚ÄúDays‚Äù ha valore 0 o 1 dal dataset ‚Äúsleepstudy‚Äù utilizzando il seguente codice:\n\ndata = data[data['Days'].isin([0, 1]) == False]\ndata.head()\n\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n5\n414.6901\n5\n308\n\n\n6\n382.2038\n6\n308\n\n\n\n\n\n\n\n\nAnalizziamo il tempo di reazione medio in relazione ai giorni di deprivazione del sonno, osservando come questo varia per ciascun soggetto coinvolto nello studio.\n\ndef plot_data(data):\n    fig, axes = plt.subplots(3, 6, sharey=True, sharex=True, dpi=100, constrained_layout=True)\n    fig.subplots_adjust(left=0.075, right=0.975, bottom=0.075, top=0.925, wspace=0.03)\n\n    axes_flat = axes.ravel()\n\n    for i, subject in enumerate(data[\"Subject\"].unique()):\n        ax = axes_flat[i]\n        idx = data.index[data[\"Subject\"] == subject].tolist()\n        days = data.loc[idx, \"Days\"].values\n        reaction = data.loc[idx, \"Reaction\"].values\n\n        # Plot observed data points\n        ax.scatter(days, reaction, color=\"#B17F7D\", ec=\"#832F2B\", alpha=0.7)\n\n        # Add a title\n        ax.set_title(f\"Subject: {subject}\", fontsize=9)\n\n    # Remove axis labels for individual plots\n    for ax in axes_flat:\n        ax.set_xlabel(\"\")\n        ax.set_ylabel(\"\")\n\n    # Set x-axis ticks for the last row\n    for ax in axes[-1]:\n        ax.xaxis.set_ticks([0, 2, 4, 6, 8])\n\n    return axes\n\n\nplot_data(data)\nplt.tight_layout()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#modello-complete-pooling",
    "href": "chapters/linear_models/09_hier_regr.html#modello-complete-pooling",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.4 Modello complete pooling",
    "text": "66.4 Modello complete pooling\nIl modello complete pooling tratta tutte le osservazioni come se fossero indipendenti, aggregandole in un unico gruppo. In questo modello, le rette di regressione lineare per tutti i soggetti hanno la stessa pendenza e la stessa intercetta. Il modello pu√≤ essere descritto esplicitamente come segue:\nSe disponiamo di $ m $ soggetti e ciascun soggetto $ i $ ha $ n_i $ osservazioni, il modello pu√≤ essere definito da:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m, \\text{ e per l'osservazione } j = 1, \\ldots, n_i:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha + \\beta \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2),\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione per il soggetto $ i $ al giorno $ j $.\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto $ i $ all‚Äôosservazione $ j $.\n\\(\\alpha\\) √® l‚Äôintercetta comune a tutti i soggetti.\n\\(\\beta\\) √® la pendenza comune a tutti i soggetti.\n\\(\\epsilon_{ij}\\) √® il termine di errore casuale per il soggetto $ i $ all‚Äôosservazione $ j $, che si suppone sia distribuito normalmente con media 0 e varianza costante $ ^2 $.\n\nQuesto modello non distingue tra i gruppi di osservazoni che appartengono a soggetti diversi e stima un‚Äôunica pendenza e un‚Äôunica intercetta dai dati di tutti i soggetti. In Bambi, questo modello pu√≤ essere specificato utilizzando solo la variabile Days come predittore, senza includere il Subject come fattore.\n\nmodel_pooling = bmb.Model(\"Reaction ~ 1 + Days\", data)\n\nProcediamo con l‚Äôesecuzione del campionamento MCMC, utilizzando il metodo NUTS specifico per il campionatore JAX. Questo pu√≤ essere fatto semplicemente passando l‚Äôopzione method=\"nuts_numpyro\" durante la chiamata al campionamento. In questo modo, stiamo invocando direttamente il campionatore JAX, sfruttando le sue caratteristiche avanzate.\n\nresults_pooling = model_pooling.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\n\nmodel_pooling.build()\nmodel_pooling.graph()\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(results_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nDays\n11.40\n1.88\n7.89\n14.88\n0.03\n0.02\n3826.84\n2982.56\n1.0\n\n\nIntercept\n245.15\n11.22\n224.18\n266.21\n0.18\n0.13\n3871.91\n2719.25\n1.0\n\n\nsigma\n51.10\n3.03\n45.52\n56.72\n0.05\n0.04\n3277.56\n2502.12\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#modello-no-pooling",
    "href": "chapters/linear_models/09_hier_regr.html#modello-no-pooling",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.5 Modello no-pooling",
    "text": "66.5 Modello no-pooling\nIl modello no-pooling tratta ogni soggetto come indipendente e adatta una retta di regressione separata per ciascun soggetto. Se disponiamo di $ m $ soggetti e ciascun soggetto $ i $ ha $ n_i $ osservazioni, il modello pu√≤ essere definito da:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha_i + \\beta_i \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2), \\quad j = 1, \\ldots, n_i,\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione per il soggetto $ i $ al giorno $ j $.\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto $ i $ all‚Äôosservazione $ j $.\n\\(\\alpha_i\\) √® l‚Äôintercetta per il soggetto $ i $.\n\\(\\beta_i\\) √® la pendenza per il soggetto $ i $.\n\\(\\epsilon_{ij}\\) √® il termine di errore casuale per il soggetto $ i $ all‚Äôosservazione $ j $, che si suppone sia distribuito normalmente con media 0 e varianza costante $ ^2 $.\n\nQuesto modello non fa alcuna ipotesi sulle relazioni tra diversi soggetti e stima la pendenza e l‚Äôintercetta di ciascun soggetto indipendentemente dagli altri soggetti. In Bambi, questo modello viene specificato con l‚Äôinterazione tra Days e Subject, come descritto in seguito.\n\nmodel_no_pooling = bmb.Model(\"Reaction ~ Days * C(Subject)\", data=data)\nresults_no_pooling = model_no_pooling.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\n\nmodel_no_pooling.build()\nmodel_no_pooling.graph()\n\n\n\n\n\n\n\n\n\naz.summary(results_no_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nC(Subject)[309]\n-55.81\n32.73\n-117.09\n3.39\n1.47\n1.05\n498.93\n1286.54\n1.01\n\n\nC(Subject)[310]\n-29.49\n32.66\n-91.81\n30.77\n1.52\n1.08\n457.16\n1208.49\n1.02\n\n\nC(Subject)[330]\n9.81\n33.06\n-54.38\n70.30\n1.60\n1.13\n424.43\n1467.19\n1.02\n\n\nC(Subject)[331]\n40.59\n33.14\n-17.89\n104.88\n1.65\n1.17\n402.96\n1460.16\n1.02\n\n\nC(Subject)[332]\n63.12\n33.24\n3.03\n130.72\n1.57\n1.11\n454.04\n1248.37\n1.01\n\n\nC(Subject)[333]\n15.92\n32.92\n-47.16\n75.49\n1.46\n1.03\n489.51\n1451.70\n1.02\n\n\nC(Subject)[334]\n-45.95\n32.49\n-105.15\n14.85\n1.75\n1.24\n343.16\n1366.32\n1.02\n\n\nC(Subject)[335]\n23.44\n32.25\n-36.55\n82.48\n1.42\n1.01\n513.56\n1550.53\n1.02\n\n\nC(Subject)[337]\n19.76\n33.12\n-45.71\n77.39\n1.63\n1.15\n414.59\n1451.97\n1.02\n\n\nC(Subject)[349]\n-51.58\n32.86\n-111.09\n10.94\n1.57\n1.11\n437.61\n1557.00\n1.02\n\n\nC(Subject)[350]\n-46.21\n32.82\n-111.98\n13.33\n1.57\n1.11\n439.14\n1107.06\n1.02\n\n\nC(Subject)[351]\n-0.91\n33.30\n-63.92\n58.14\n1.45\n1.03\n532.34\n1525.08\n1.02\n\n\nC(Subject)[352]\n68.96\n32.63\n3.34\n127.98\n1.47\n1.04\n494.89\n1325.51\n1.02\n\n\nC(Subject)[369]\n-8.53\n32.77\n-70.04\n54.41\n1.46\n1.03\n502.71\n1346.09\n1.01\n\n\nC(Subject)[370]\n-54.17\n32.62\n-116.74\n5.41\n1.59\n1.12\n423.29\n1338.47\n1.02\n\n\nC(Subject)[371]\n-14.22\n32.78\n-71.89\n50.01\n1.54\n1.09\n453.79\n1263.58\n1.01\n\n\nC(Subject)[372]\n20.63\n33.07\n-37.39\n84.62\n1.60\n1.13\n426.34\n1288.41\n1.02\n\n\nDays\n21.21\n3.81\n13.66\n27.95\n0.28\n0.20\n190.54\n654.98\n1.03\n\n\nDays:C(Subject)[309]\n-16.90\n5.49\n-27.16\n-6.56\n0.23\n0.16\n563.01\n1286.88\n1.01\n\n\nDays:C(Subject)[310]\n-17.32\n5.46\n-27.41\n-6.81\n0.26\n0.19\n436.01\n1175.22\n1.02\n\n\nDays:C(Subject)[330]\n-13.25\n5.57\n-24.32\n-3.22\n0.26\n0.18\n454.06\n1477.08\n1.01\n\n\nDays:C(Subject)[331]\n-16.33\n5.54\n-26.02\n-5.47\n0.27\n0.19\n431.51\n1061.31\n1.02\n\n\nDays:C(Subject)[332]\n-18.75\n5.52\n-29.33\n-8.71\n0.25\n0.18\n506.42\n1275.26\n1.01\n\n\nDays:C(Subject)[333]\n-10.31\n5.50\n-20.58\n-0.35\n0.25\n0.17\n503.11\n1309.14\n1.01\n\n\nDays:C(Subject)[334]\n-3.09\n5.41\n-13.47\n6.89\n0.30\n0.21\n327.11\n1269.11\n1.02\n\n\nDays:C(Subject)[335]\n-25.37\n5.36\n-34.91\n-14.87\n0.24\n0.17\n499.52\n1632.53\n1.02\n\n\nDays:C(Subject)[337]\n1.31\n5.57\n-9.40\n11.36\n0.26\n0.18\n450.92\n1285.64\n1.02\n\n\nDays:C(Subject)[349]\n-4.81\n5.55\n-15.64\n5.20\n0.24\n0.17\n534.00\n1582.16\n1.01\n\n\nDays:C(Subject)[350]\n2.10\n5.55\n-8.33\n12.57\n0.26\n0.19\n438.22\n1180.72\n1.02\n\n\nDays:C(Subject)[351]\n-12.67\n5.52\n-22.70\n-2.30\n0.24\n0.17\n514.68\n1528.73\n1.02\n\n\nDays:C(Subject)[352]\n-13.89\n5.50\n-23.87\n-3.04\n0.26\n0.19\n430.77\n1230.56\n1.02\n\n\nDays:C(Subject)[369]\n-7.43\n5.45\n-18.21\n2.41\n0.24\n0.17\n495.72\n1255.54\n1.02\n\n\nDays:C(Subject)[370]\n-0.55\n5.51\n-10.04\n10.55\n0.26\n0.18\n450.52\n1328.24\n1.02\n\n\nDays:C(Subject)[371]\n-8.90\n5.52\n-18.74\n1.63\n0.26\n0.18\n461.25\n1229.82\n1.01\n\n\nDays:C(Subject)[372]\n-10.04\n5.57\n-20.17\n0.46\n0.26\n0.18\n473.14\n1291.15\n1.02\n\n\nIntercept\n247.65\n22.86\n205.21\n291.61\n1.55\n1.11\n216.31\n724.03\n1.03\n\n\nsigma\n25.75\n1.79\n22.47\n29.03\n0.03\n0.02\n3843.67\n2795.66\n1.00\n\n\n\n\n\n\n\n\nPer ricavare i coefficienti \\(\\alpha\\) delle regressioni individuali, dobbiamo sommare Intercept al valore del singolo soggetto. Per esempio, per il soggetto 309 abbiamo\n\n246.98 + -55.29\n\n191.69\n\n\nFacciamo lo stesso per la pendenza individuale delle rette di regressione. Per il soggetto 309 otteniamo\n\n21.30 + -16.97\n\n4.330000000000002\n\n\nQuesti valori sono identici a quelli che si otterrebbero se adattassimo il modello di regressione separatamente per ciascun soggetto. In effetti, abbiamo fatto proprio questo, utilizzando un modello unico. Per esempio, esaminiamo i singoli dati del soggetto 309.\n\ndata_subject_309 = data[data[\"Subject\"] == 309]\ndata_subject_309.shape\n\n(8, 3)\n\n\nStimiamo l‚Äôintercetta e la pendenza della retta di regressione usando l‚Äôapproccio frequentista mediante la funzione linear_regression del pacchetto pingouin.\n\nresult = pg.linear_regression(data_subject_309[\"Days\"], data_subject_309[\"Reaction\"])\nprint(result)\n\n       names        coef        se          T          pval        r2  \\\n0  Intercept  191.576970  3.723259  51.454104  3.615788e-09  0.890144   \n1       Days    4.357144  0.624898   6.972569  4.325982e-04  0.890144   \n\n     adj_r2    CI[2.5%]   CI[97.5%]  \n0  0.871834  182.466483  200.687458  \n1  0.871834    2.828074    5.886214  \n\n\nSi noti che i risultati ottenuti sono sostanzialmente gli stessi, con solo qualche minima differenza numerica. Questa discrepanza deriva dalla diversit√† degli approcci utilizzati: in un caso abbiamo applicato un metodo bayesiano, mentre nell‚Äôaltro abbiamo adottato una tecnica di stima frequentista.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#modello-partial-pooling",
    "href": "chapters/linear_models/09_hier_regr.html#modello-partial-pooling",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.6 Modello partial pooling",
    "text": "66.6 Modello partial pooling\nIl modello gerarchico, conosciuto anche come modello di ‚Äúpartial pooling‚Äù, consente di gestire la complessit√† presente nei dati raggruppati o clusterizzati, come nel caso presente. La regressione lineare classica presume che ogni osservazione sia indipendente dalle altre, ma questa ipotesi viene meno quando i dati sono organizzati in gruppi. Le osservazioni all‚Äôinterno dello stesso gruppo tendono ad essere pi√π correlate tra loro rispetto a quelle in gruppi diversi. Trascurare questa struttura gerarchica potrebbe portare a stime errate e conclusioni fuorvianti.\nIl modello gerarchico affronta questo problema introducendo la nozione di effetti casuali, in contrapposizione agli effetti fissi del modello classico. Gli effetti fissi rappresentano l‚Äôeffetto medio di una variabile predittiva su tutti gli individui o gruppi, mentre gli effetti casuali considerano come l‚Äôeffetto di una variabile possa variare da un gruppo all‚Äôaltro. Mentre gli effetti fissi sono comuni a tutto il dataset, gli effetti casuali tengono conto delle differenze tra i gruppi.\nQuesto modello gerarchico unisce effetti fissi e casuali per fornire una rappresentazione pi√π accurata dei dati, quando questi mostrano relazioni gerarchiche o raggruppate. Il modello gerarchico di ‚Äúpartial pooling‚Äù considera le somiglianze tra i soggetti stimando un‚Äôintercetta e una pendenza comuni, ma consente anche variazioni individuali attorno a questi valori medi.\nPossiamo rappresentare matematicamente il modello come segue:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m, \\text{ e per l'osservazione } j = 1, \\ldots, n_i:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha_i + \\beta_i \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2),\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) √® il tempo di reazione del soggetto \\(i\\) al giorno \\(j\\).\n\\(\\text{Days}_{ij}\\) √® il numero di giorni per il soggetto \\(i\\) all‚Äôosservazione \\(j\\).\n\\(\\alpha_i\\) √® l‚Äôintercetta per il soggetto \\(i\\), che segue la distribuzione \\(\\alpha_i \\sim \\mathcal{N}(\\alpha, \\tau_\\alpha^2)\\).\n\\(\\beta_i\\) √® la pendenza per il soggetto \\(i\\), che segue la distribuzione \\(\\beta_i \\sim \\mathcal{N}(\\beta, \\tau_\\beta^2)\\).\n\\(\\epsilon_{ij}\\) √® l‚Äôerrore casuale per il soggetto \\(i\\) all‚Äôosservazione \\(j\\), distribuito normalmente con media 0 e varianza costante \\(\\sigma^2\\).\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) rappresentano l‚Äôintercetta e la pendenza medie per tutti i soggetti, e le varianze \\(\\tau_\\alpha^2\\) e \\(\\tau_\\beta^2\\) quantificano le differenze tra gli individui.\nIn questo modo, il modello gerarchico riesce a rappresentare sia le informazioni comuni a tutti i soggetti, sia le differenze individuali, considerando sia gli effetti fissi che quelli casuali. Pu√≤ quindi offrire una visione pi√π completa e realistica dei dati, tenendo conto della loro struttura gerarchica. In Bambi, questo modello pu√≤ essere specificato utilizzando la variabile Days come predittore e includendo Subject come effetto casuale.\n\nmodel_partial_pooling = bmb.Model(\n    \"Reaction ~ 1 + Days + (Days | Subject)\", data, categorical=\"Subject\"\n)\n\nEseguiamo il campionamento.\n\nresults_partial_pooling = model_partial_pooling.fit(\n    nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\n\nmodel_partial_pooling.build()\nmodel_partial_pooling.graph()\n\n\n\n\n\n\n\n\nEsaminiamo i risultati.\n\naz.summary(results_partial_pooling, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\n1|Subject[308]\n10.02\n18.26\n-23.88\n45.32\n0.30\n0.24\n3801.21\n3296.70\n1.0\n\n\n1|Subject[309]\n-43.21\n20.82\n-81.90\n-2.40\n0.37\n0.26\n3192.01\n2770.58\n1.0\n\n\n1|Subject[310]\n-25.98\n19.01\n-60.23\n10.11\n0.34\n0.24\n3180.64\n2886.98\n1.0\n\n\n1|Subject[330]\n4.68\n17.93\n-28.33\n39.60\n0.28\n0.25\n4049.42\n3086.98\n1.0\n\n\n1|Subject[331]\n22.05\n18.80\n-12.81\n57.32\n0.32\n0.24\n3416.40\n2908.07\n1.0\n\n\n1|Subject[332]\n34.64\n19.83\n-1.54\n71.69\n0.38\n0.27\n2774.25\n2704.53\n1.0\n\n\n1|Subject[333]\n11.22\n18.56\n-22.97\n47.30\n0.28\n0.24\n4343.31\n3323.77\n1.0\n\n\n1|Subject[334]\n-22.66\n18.29\n-55.72\n13.01\n0.33\n0.25\n3106.34\n2785.24\n1.0\n\n\n1|Subject[335]\n1.42\n18.81\n-33.38\n37.33\n0.33\n0.28\n3188.72\n2799.45\n1.0\n\n\n1|Subject[337]\n26.62\n19.63\n-9.98\n63.52\n0.31\n0.25\n4073.78\n2966.54\n1.0\n\n\n1|Subject[349]\n-27.94\n19.23\n-68.63\n4.02\n0.33\n0.24\n3381.72\n3363.24\n1.0\n\n\n1|Subject[350]\n-17.37\n19.44\n-54.77\n19.69\n0.33\n0.25\n3549.86\n2998.39\n1.0\n\n\n1|Subject[351]\n-2.22\n18.12\n-35.17\n33.75\n0.29\n0.26\n3981.53\n3361.50\n1.0\n\n\n1|Subject[352]\n43.03\n19.80\n3.35\n78.09\n0.40\n0.28\n2495.13\n2423.89\n1.0\n\n\n1|Subject[369]\n-2.06\n18.31\n-35.31\n32.90\n0.31\n0.26\n3570.39\n2953.34\n1.0\n\n\n1|Subject[370]\n-25.09\n18.76\n-58.40\n10.74\n0.34\n0.26\n3062.92\n3093.42\n1.0\n\n\n1|Subject[371]\n-7.11\n18.62\n-45.12\n24.89\n0.30\n0.26\n3873.47\n3069.79\n1.0\n\n\n1|Subject[372]\n15.17\n18.60\n-20.32\n50.26\n0.30\n0.24\n3831.96\n3202.78\n1.0\n\n\n1|Subject_sigma\n31.56\n9.02\n16.45\n50.30\n0.24\n0.17\n1431.60\n1806.76\n1.0\n\n\nDays\n11.50\n1.93\n7.87\n15.22\n0.05\n0.04\n1283.13\n1993.22\n1.0\n\n\nDays|Subject[308]\n8.10\n3.28\n2.23\n14.54\n0.07\n0.05\n2528.98\n2551.19\n1.0\n\n\nDays|Subject[309]\n-8.34\n3.67\n-15.35\n-1.50\n0.07\n0.06\n2401.88\n2808.43\n1.0\n\n\nDays|Subject[310]\n-7.38\n3.41\n-13.66\n-0.92\n0.07\n0.05\n2466.36\n3249.44\n1.0\n\n\nDays|Subject[330]\n-2.28\n3.30\n-8.32\n4.07\n0.07\n0.05\n2202.51\n2665.53\n1.0\n\n\nDays|Subject[331]\n-3.20\n3.36\n-9.57\n2.86\n0.07\n0.05\n2415.10\n2643.60\n1.0\n\n\nDays|Subject[332]\n-4.02\n3.54\n-10.46\n2.85\n0.08\n0.05\n2179.69\n2644.19\n1.0\n\n\nDays|Subject[333]\n0.46\n3.34\n-6.16\n6.42\n0.07\n0.05\n2638.74\n2977.03\n1.0\n\n\nDays|Subject[334]\n3.18\n3.30\n-3.22\n9.10\n0.07\n0.05\n2469.34\n2803.19\n1.0\n\n\nDays|Subject[335]\n-11.26\n3.48\n-18.02\n-4.83\n0.07\n0.05\n2639.50\n2714.43\n1.0\n\n\nDays|Subject[337]\n9.74\n3.53\n2.88\n16.27\n0.06\n0.05\n3136.50\n3060.31\n1.0\n\n\nDays|Subject[349]\n1.56\n3.39\n-4.91\n7.90\n0.07\n0.05\n2458.79\n2962.88\n1.0\n\n\nDays|Subject[350]\n7.23\n3.41\n0.87\n13.50\n0.07\n0.05\n2588.63\n2942.92\n1.0\n\n\nDays|Subject[351]\n-2.24\n3.26\n-7.88\n4.24\n0.06\n0.05\n2652.33\n2599.26\n1.0\n\n\nDays|Subject[352]\n0.18\n3.47\n-6.29\n6.87\n0.08\n0.05\n2071.05\n2663.67\n1.0\n\n\nDays|Subject[369]\n1.52\n3.29\n-4.94\n7.61\n0.07\n0.05\n2545.95\n2919.43\n1.0\n\n\nDays|Subject[370]\n4.78\n3.31\n-1.58\n10.65\n0.07\n0.05\n2263.23\n2665.64\n1.0\n\n\nDays|Subject[371]\n0.05\n3.33\n-6.09\n6.48\n0.06\n0.05\n2652.55\n2772.53\n1.0\n\n\nDays|Subject[372]\n0.77\n3.41\n-5.43\n7.29\n0.07\n0.05\n2455.49\n2748.16\n1.0\n\n\nDays|Subject_sigma\n6.89\n1.64\n4.07\n9.97\n0.04\n0.03\n1596.04\n1911.24\n1.0\n\n\nIntercept\n245.40\n9.34\n228.41\n262.89\n0.18\n0.12\n2855.59\n2917.47\n1.0\n\n\nsigma\n26.06\n1.84\n22.59\n29.37\n0.03\n0.02\n2872.83\n2912.40\n1.0\n\n\n\n\n\n\n\n\nConsideriamo il soggetto 309. Per questo soggetto l‚Äôintercetta √®\n\n245.24 + -42.22\n\n203.02\n\n\ne la pendenza della retta di regressione √®\n\n11.34 + -8.27\n\n3.0700000000000003\n\n\nSi noti che questi valori sono diversi da quelli ottenuti con la procedura di no-pooling. Entrambi i modelli di no pooling e il modello gerarchico di partial pooling riconoscono che ci possono essere differenze tra i diversi gruppi (o soggetti) nel dataset, ma gestiscono queste differenze in modi diversi.\nNel modello di no pooling, ogni gruppo viene trattato in modo completamente indipendente dagli altri. Ogni intercetta e pendenza viene stimata separatamente per ogni gruppo, senza fare riferimento agli altri gruppi. In altre parole, si adatta una regressione lineare separata per ciascun gruppo. Ci√≤ significa che se si hanno molti gruppi, ci saranno molti parametri da stimare.\nQuesto approccio pu√≤ catturare le differenze tra i gruppi molto accuratamente se ci sono molte osservazioni in ogni gruppo, ma pu√≤ essere problematico se ci sono poche osservazioni per gruppo. Inoltre, non sfrutta le informazioni comuni tra i gruppi e pu√≤ portare a stime molto variabili.\nIl modello gerarchico di partial pooling, invece, riconosce che, anche se ci sono differenze tra i gruppi, questi potrebbero condividere alcune caratteristiche comuni. Invece di stimare le intercette e pendenze completamente separatamente per ogni gruppo, il modello gerarchico stima una media comune e una varianza comune per l‚Äôintercetta e la pendenza, e poi consente a ciascun gruppo di variare attorno a questi valori comuni.\nQuesto porta al concetto di ‚Äúshrinkage‚Äù. Le stime delle intercette e pendenze per ciascun gruppo tendono a essere ‚Äúcompresse‚Äù verso i valori medi. Se un gruppo ha poche osservazioni, la sua stima sar√† pi√π fortemente influenzata dalla media comune. Se ha molte osservazioni, la sua stima sar√† meno influenzata dalla media comune. In questo modo, il modello riesce a bilanciare tra due tendenze opposte: rendere conto delle differenze tra i gruppi e sfruttare le informazioni comuni.\nIn sintesi, la differenza principale tra il modello no-pooling e il modello gerarchico partial-pooling sta nel modo in cui gestiscono le intercette e pendenze individuali:\n\nIl modello no-pooling tratta ogni gruppo separatamente, stimando le intercette e pendenze individuali senza considerare gli altri gruppi.\nIl modello gerarchico partial-pooling stima le intercette e pendenze comuni e consente a ciascun gruppo di variare attorno a questi valori comuni, dando luogo al fenomeno dello shrinkage.\n\nIl modello di no pooling pu√≤ essere pi√π adatto se i gruppi sono veramente indipendenti e molto diversi tra loro, mentre il modello gerarchico √® maggiormente appropriato quando ci sono somiglianze tra i gruppi che possono essere sfruttate per ottenere stime pi√π precise e robuste.\n\n66.6.1 Modello Gerarchico e Distribuzione dei Coefficienti\nIn un contesto di modello gerarchico con partial pooling, gli effetti casuali, inclusi intercette e pendenze specifiche per ciascun gruppo o individuo, vengono trattati come esiti di variabili aleatorie. Questo approccio si distingue nettamente da quello adottato nei modelli di no pooling, nei quali ciascun coefficiente viene considerato come un parametro statico e indipendente.\nAll‚Äôinterno di un modello gerarchico, l‚Äôassunzione di base √® che questi effetti casuali siano distribuiti normalmente. Ci√≤ implica che ogni coefficiente specifico di un gruppo o individuo (come l‚Äôintercetta per un dato soggetto) √® visto come una manifestazione di una variabile aleatoria che segue una distribuzione normale. La distribuzione di queste variabili aleatorie, che rappresenta la popolazione degli effetti casuali, √® caratterizzata da una media e una varianza condivise tra tutti i gruppi o soggetti, le quali vengono inferite direttamente dai dati raccolti. Questo permette di modellare la variabilit√† intra-gruppo e inter-gruppo in modo pi√π flessibile e informato, offrendo una rappresentazione pi√π accurata della struttura dei dati e delle relazioni sottostanti.\nAd esempio, le intercette individuali \\(\\alpha_i\\) possono essere modellate come:\n\\[\n\\alpha_i \\sim \\mathcal{N}(\\alpha, \\tau_\\alpha^2),\n\\]\ndove \\(\\alpha\\) √® l‚Äôintercetta media per tutti i soggetti e \\(\\tau_\\alpha^2\\) √® la varianza delle intercette tra i soggetti. Analogamente, le pendenze individuali \\(\\beta_i\\) possono essere modellate come:\n\\[\n\\beta_i \\sim \\mathcal{N}(\\beta, \\tau_\\beta^2),\n\\]\ndove \\(\\beta\\) √® la pendenza media e \\(\\tau_\\beta^2\\) √® la varianza delle pendenze.\n\n\n66.6.2 Implicazioni\nQuesta struttura ha diverse implicazioni importanti:\n\nShrinkage: Come discusso in precedenza, le stime dei coefficienti individuali tendono a essere ‚Äúcompresse‚Äù verso i valori medi. Questo aiuta a stabilizzare le stime, specialmente quando ci sono poche osservazioni per gruppo.\nScambio di informazioni tra i gruppi: Poich√© i coefficienti individuali sono considerati come estratti dalla stessa distribuzione, ci√≤ permette uno scambio di informazioni tra i gruppi. Se un gruppo ha molte osservazioni, pu√≤ aiutare a informare le stime per un gruppo con poche osservazioni.\nInterpretazione gerarchica: Il modello riconosce una struttura gerarchica nei dati, con osservazioni raggruppate all‚Äôinterno di gruppi, e gruppi che condividono caratteristiche comuni. Questa struttura pu√≤ riflettere una realt√† sottostante nella quale gli individui o i gruppi non sono completamente indipendenti l‚Äôuno dall‚Äôaltro.\n\nIn conclusione, il modello gerarchico di partial-pooling offre un quadro flessibile e potente per analizzare dati raggruppati o clusterizzati, riconoscendo sia le somiglianze che le differenze tra i gruppi e utilizzando una struttura probabilistica per modellare le relazioni tra di loro.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#interpretazione",
    "href": "chapters/linear_models/09_hier_regr.html#interpretazione",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.7 Interpretazione",
    "text": "66.7 Interpretazione\nIniziamo considerando le stime a posteriori degli effetti fissi.\n\naz.summary(results_partial_pooling, var_names=[\"Intercept\", \"Days\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n245.4\n9.34\n228.41\n262.89\n0.18\n0.12\n2855.59\n2917.47\n1.0\n\n\nDays\n11.5\n1.93\n7.87\n15.22\n0.05\n0.04\n1283.13\n1993.22\n1.0\n\n\n\n\n\n\n\n\nIn media, il tempo di reazione medio delle persone all‚Äôinizio dello studio √® compreso tra 227 e 264 millisecondi. Con ogni giorno aggiuntivo di privazione del sonno, i tempi di reazione medi aumentano, in media, tra 7.9 e 15.1 millisecondi.\nL‚Äôinterpretazione degli effetti fissi √® semplice. Ma quest‚Äôanalisi sarebbe incompleta e fuorviante se non valutiamo i termini specifici per i singoli soggetti che abbiamo aggiunto al modello. Questi termini ci dicono quanto i soggetti differiscono l‚Äôuno dall‚Äôaltro in termini di tempo di reazione iniziale e dell‚Äôassociazione tra giorni di privazione del sonno e tempi di reazione.\nDi seguito, utilizziamo ArviZ per ottenere un traceplot delle intercetti specifiche per i soggetti 1|Subject e delle pendenze Days|Subject. Questo traceplot contiene due colonne. A sinistra, abbiamo le distribuzioni posteriori e a destra abbiamo i trace-plots. L‚Äôaspetto casuale stazionario, o l‚Äôapparenza di rumore bianco, ci dice che il campionatore ha raggiunto la convergenza e le catene sono ben mescolate.\n\naz.plot_trace(\n    results_partial_pooling, combined=True, var_names=[\"1|Subject\", \"Days|Subject\"]\n)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nDall‚Äôampiezza delle distribuzioni a posteriori delle intercette per i singoli soggetti possiamo vedere che il tempo di reazione medio iniziale per un determinato soggetto pu√≤ differire notevolmente dalla media generale che abbiamo visto nella tabella precedente. C‚Äô√® anche una grande differenza nelle pendenze. Alcuni soggetti vedono aumentare rapidamente i loro tempi di reazione quando vengono deprivati del sonno, mentre altri hanno una tolleranza migliore e peggiorano pi√π lentamente.\nUna rappresentazione grafica della stima a posteriore dei parametri e dei dati si ottiene con az.plot_forest().\n\naz.plot_forest(data=results_partial_pooling, r_hat=False, combined=True, textsize=8);\n\n\n\n\n\n\n\n\nIn sintesi, il modello gerarchico cattura il comportamento che abbiamo visto nella fase di esplorazione dei dati. Le persone differiscono sia nei tempi di reazione iniziali che nel modo in cui questi tempi di reazione sono influenzati dai giorni di deprivazione del sonno. Possiamo dunque giungere alle seguenti conclusioni:\n\nIl tempo di reazione medio delle persone aumenta quando sono deprivate del sonno.\nI soggetti hanno tempi di reazione diversi all‚Äôinizio dello studio.\nAlcuni soggetti sono pi√π colpiti dalla privazione del sonno rispetto ad altri.\n\nMa c‚Äô√® un‚Äôaltra domanda a cui non abbiamo ancora risposto: I tempi di reazione iniziali sono associati a quanto la deprivazione del sonno influisce sull‚Äôevoluzione dei tempi di reazione?\nCreiamo un diagramma a dispersione per visualizzare le stime a posteriori congiunte delle intercette e delle pendenze specifiche per i soggetti. Questo grafico usa colori diversi per i soggetti. Se guardiamo il quadro generale, cio√® trascurando i ragruppamenti dei dati in base ai soggetti, possiamo concludere che non c‚Äô√® associazione tra l‚Äôintercetta e la pendenza. In altre parole, avere tempi di reazione iniziali pi√π bassi o pi√π alti non dice nulla su quanto la deprivazione del sonno influisca sul tempo di reazione medio di un determinato soggetto.\nD‚Äôaltra parte, se guardiamo la distribuzione a posteriori congiunta per un determinato individuo, possiamo vedere una correlazione negativa tra l‚Äôintercetta e la pendenza. Questo indica che, condizionalmente a un determinato soggetto, le stime a posteriori dell‚Äôintercetta e della pendenza non sono indipendenti.\n\n#  extract a subsample from the posterior and stack the chain and draw dims\nposterior = az.extract(results_partial_pooling, num_samples=500)\n\n_, ax = plt.subplots()\n\nresults_partial_pooling.posterior.plot.scatter(\n    x=\"1|Subject\", y=\"Days|Subject\",\n    hue=\"Subject__factor_dim\",\n    add_colorbar=False,\n    add_legend=False,\n    edgecolors=None,\n)\n\nax.axhline(c=\"0.25\", ls=\"--\")\nax.axvline(c=\"0.25\", ls=\"--\")\nax.set_xlabel(\"Subject-specific intercept\")\nax.set_ylabel(\"Subject-specific slope\");",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#confronto-dei-modelli",
    "href": "chapters/linear_models/09_hier_regr.html#confronto-dei-modelli",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.8 Confronto dei modelli",
    "text": "66.8 Confronto dei modelli\nUn aspetto finale e cruciale del nostro studio riguarda il confronto tra i diversi modelli che abbiamo esaminato. La nostra intenzione √® determinare quale modello fornisce una rappresentazione migliore dei dati, trovando un equilibrio appropriato tra l‚Äôaccuratezza del modello e la sua complessit√†, cio√® la parsimonia.\nPer raggiungere questo scopo, faremo uso della metrica ELPD (Expected Log Predictive Density), che abbiamo introdotto in precedenza. ELPD ci consente di valutare un modello in termini di adattamento ai dati, considerando sia l‚Äôaccuratezza delle previsioni che la complessit√† del modello.\n\n66.8.1 Utilizzo di az.compare()\nIn Python, possiamo sfruttare la funzione az.compare() per confrontare direttamente modelli bayesiani. Questa funzione accetta un dizionario contenente gli oggetti InferenceData, risultanti dalla funzione Model.fit(), e restituisce un dataframe. I modelli vengono ordinati dal migliore al peggiore in base ai criteri selezionati, e di default, ArviZ usa il criterio di convalida incrociata ‚Äúleave one out‚Äù (LOO).\n\n66.8.1.1 Convalida Incrociata ‚ÄúLeave One Out‚Äù (LOO)\nLOO √® una tecnica di convalida che addestra il modello su tutti i dati disponibili tranne uno, utilizzando il singolo punto escluso come dati di test. Questo processo viene ripetuto per ogni punto dati nel set, e la media delle misure di errore fornisce una stima accurata dell‚Äôerrore di generalizzazione del modello. Anche se computazionalmente impegnativa, LOO fornisce una valutazione affidabile delle prestazioni del modello. In ArviZ, la funzione loo implementa questo metodo seguendo un approccio bayesiano.\n\n\n66.8.1.2 Widely Applicable Information Criterion (WAIC)\nOltre a LOO, possiamo anche utilizzare il criterio WAIC (Widely Applicable Information Criterion). Il WAIC √® uno strumento per la selezione del modello che mira a trovare il modello ottimale in un insieme di candidati, equilibrando l‚Äôadattamento ai dati e la complessit√† del modello, evitando cos√¨ il sovradattamento. WAIC √® particolarmente utile nel contesto bayesiano, poich√© tiene conto dell‚Äôincertezza associata ai parametri del modello.\nSia LOO che WAIC possono essere visti come stime empiriche dell‚ÄôELPD, fornendo un quadro comprensivo delle prestazioni dei modelli.\nUtilizzando la funzione az.compare(), siamo in grado di effettuare una comparazione rapida ed efficace tra i diversi modelli, valutandoli secondo i criteri LOO e WAIC. Nel nostro caso specifico, il modello di ‚Äúpartial pooling‚Äù emerge come il migliore, presentando il valore ELPD stimato pi√π alto. Questo risultato conferma la validit√† del modello nel rappresentare la struttura dei dati, tenendo conto delle differenze individuali all‚Äôinterno dei cluster, e fornendo una stima coerente e informativa dell‚Äôeffetto della deprivazione del sonno sul tempo di reazione.\n\nmodels_dict = {\n    \"pooling\": results_pooling,\n    \"no_pooling\": results_no_pooling,\n    \"partial_pooling\": results_partial_pooling\n}\ndf_compare = az.compare(models_dict)\ndf_compare\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\npartial_pooling\n0\n-692.203378\n31.116753\n0.000000\n0.945524\n21.750623\n0.000000\nTrue\nlog\n\n\nno_pooling\n1\n-694.239760\n35.771777\n2.036382\n0.004772\n21.582485\n3.251708\nTrue\nlog\n\n\npooling\n2\n-772.176595\n3.066678\n79.973217\n0.049704\n9.054093\n20.322146\nFalse\nlog\n\n\n\n\n\n\n\n\n√à importante sottolineare che, per ottenere una stima dell‚ÄôELPD (Expected Log Predictive Density), √® necessario includere l‚Äôopzione idata_kwargs={\"log_likelihood\": True} all‚Äôinterno della funzione responsabile dell‚Äôesecuzione del campionamento MCMC.\nLa figura che segue illustra visivamente le informazioni rilevanti per il confronto tra i diversi modelli. In grigio √® indicata l‚Äôincertezza nella stima della differenza tra i valori ELPD dei diversi modelli.\n\n_ = az.plot_compare(df_compare, insample_dev=False)\n\n\n\n\n\n\n\n\nIl confronto tra i modelli guida il processo di selezione. In particolare, la comparazione tra il modello di partial-pooling e il modello completo di pooling √® resa chiara dall‚Äôelpd_diff di 80.17 e dal suo errore standard di 19.97. Questi valori indicano inequivocabilmente che il modello di partial-pooling √® superiore.\nLa situazione diventa pi√π sfumata quando confrontiamo il modello di partial-pooling con il modello di no-pooling. In questo caso, le stime dell‚ÄôELPD mostrano una grande sovrapposizione, suggerendo che non c‚Äô√® una differenza netta tra i due modelli in termini di adattamento ai dati.\nTuttavia, nonostante la vicinanza dei valori di ELPD, il modello di partial-pooling √® da preferire. La ragione risiede nelle sue propriet√†: esso fornisce stime pi√π robuste e conservative delle differenze individuali. A differenza del modello di no-pooling, che pu√≤ essere troppo sensibile alle variazioni all‚Äôinterno dei cluster, il modello di partial-pooling incorpora un equilibrio tra la condivisione delle informazioni all‚Äôinterno del gruppo e il riconoscimento delle differenze tra i gruppi. Questo lo rende pi√π resistente alle fluttuazioni nei dati e offre una rappresentazione pi√π affidabile delle relazioni sottostanti, rendendolo la scelta preferibile in questo contesto.\n\n\n66.8.1.3 PPC plots\nPer affrontare il tema della selezione di modelli, Johnson, Ott, e Dogucu (2022) usano anche il metodo dei posterior predictive checks. Creiamo dunque i PPC plots per i tre modelli.\n\nmodel_pooling_fitted = model_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_pooling.predict(model_pooling_fitted, kind=\"pps\")\n\n\n_ = az.plot_ppc(model_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\n\nmodel_no_pooling_fitted = model_no_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_no_pooling.predict(model_no_pooling_fitted, kind=\"pps\");\n\n\n_ = az.plot_ppc(model_no_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\n\nmodel_partial_pooling_fitted = model_partial_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_partial_pooling.predict(model_partial_pooling_fitted, kind=\"pps\");\n\n\n_ = az.plot_ppc(model_partial_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\nIn questo contesto specifico, l‚Äôanalisi tramite i PPC (Posterior Predictive Checks) plots non rivela differenze evidenti tra i tre modelli in esame: tutti sembrano egualmente adeguati nell‚Äôadattarsi ai dati. Di conseguenza, i PPC plots non forniscono ulteriori chiarimenti o conferme alle conclusioni gi√† raggiunte attraverso il confronto tra modelli basato sulla differenza ELPD (Expected Log Predictive Density). In altre parole, l‚Äôanalisi visiva tramite i PPC plots non aggiunge valore o informazioni supplementari a quanto gi√† dedotto dalle metriche di confronto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#quale-modello-scegliere",
    "href": "chapters/linear_models/09_hier_regr.html#quale-modello-scegliere",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.9 Quale modello scegliere?",
    "text": "66.9 Quale modello scegliere?\nRitorniamo ora all‚Äôarticolo di Gelman e Brown (2024). Questi autori affermano che un lettore ingenuo di molte discussioni sulla crisi della replicazione potrebbe avere l‚Äôimpressione che tutto andrebbe bene se i ricercatori seguissero semplicemente i protocolli della scienza aperta ed evitassero le pratiche di ricerca disoneste. Tuttavia, i problemi sono pi√π profondi, e uno di essi riguarda le difficolt√† nell‚Äôanalisi statistica dei dati.\nAungle e Langer (2023) hanno seguito le raccomandazioni generali di utilizzare la modellazione multilivello quando si analizzano dati raggruppati, ma non si sono resi conto che era necessario permettere agli effetti del trattamento, non solo all‚Äôintercetta, di variare tra i partecipanti. Gelman e Brown (2024) se ne sono accorti grazie agli indici t insolitamente alti e perch√© sono stati in grado di scaricare e interpretare il codice degli autori.\nNell‚Äôaffrontare l‚Äôanalisi di dati con struttura multilivello, Gelman e Brown (2024) suggeriscono come approccio ottimale di consentire la variazione sia delle intercette che degli effetti attraverso ogni livello di raggruppamento quando si stima un effetto causale o un coefficiente di regressione. Tuttavia, gli stessi autori riconoscono i limiti pratici di questa strategia. L‚Äôinclusione di componenti di varianza aggiuntivi pu√≤ infatti compromettere la stabilit√† del modello, specialmente in presenza di campioni ridotti sia in termini di misurazioni che di partecipanti. Questa considerazione evidenzia come, nell‚Äôambito delle ricerche psicologiche caratterizzate spesso da dati complessi, sia necessario un approccio flessibile e contestualizzato, piuttosto che l‚Äôapplicazione di linee guida universali.\nIn aggiunta, quando emerge un risultato interessante, secondo Gelman e Brown (2024) √® fondamentale consolidarlo attraverso una replicazione esatta (Nosek, Spies, e Motyl 2012):\n\nWhen an interesting result arises, nail down the finding by designing and carrying out an exact replication. Contrary to all your expectations, the replication might fail; indeed that is the reason for performing the replication in the first place.\n\nQuesta pratica, oltre a rafforzare la validit√† delle scoperte, offre l‚Äôopportunit√† di rilevare eventuali falsi positivi, essenziale per il progresso scientifico.\nGelman e Brown (2024) suggeriscono inoltre di progettare nuovi studi basandosi su modelli ipotetici plausibili e di preregistrarli prima della raccolta dati. La fase di progettazione e preregistrazione √® un momento opportuno per riflettere attentamente sulle dimensioni degli effetti e sulla loro variazione, nonch√© per comprendere un disegno sperimentale utilizzando dati simulati (Gelman 2024).\nRiconoscendo l‚Äôimportanza della preregistrazione, diverse riviste stanno aumentando il loro supporto a questa pratica. La forma pi√π rigorosa attualmente disponibile, i Registered Reports, richiede che i piani di analisi statistica prespecificati dagli autori siano rivisti prima dell‚Äôinizio della raccolta dati, introducendo uno sguardo esterno e imparziale nel processo. I Registered Reports mostrano un notevole potenziale nella riduzione del bias di pubblicazione (Scheel, Schijen, e Lakens 2021).\nIn conclusione, secondo Gelman e Brown (2024), la scelta del modello statistico appropriato, la replicazione dei risultati e la preregistrazione degli studi sono elementi cruciali per affrontare le sfide metodologiche nella ricerca psicologica contemporanea.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#commenti-e-considerazioni-finali",
    "href": "chapters/linear_models/09_hier_regr.html#commenti-e-considerazioni-finali",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.10 Commenti e considerazioni finali",
    "text": "66.10 Commenti e considerazioni finali\nIn questo capitolo, abbiamo esaminato e messo a confronto tre modelli statistici - pooling, no pooling e partial pooling - applicandoli ai dati dello studio sul sonno di Belenky et al.¬†(2003). Ciascun modello presenta caratteristiche distintive:\n\nil pooling si basa su una struttura comune per tutti i gruppi,\nil no pooling mantiene l‚Äôindipendenza tra i gruppi,\nil partial pooling offre un equilibrio tra i due approcci precedenti.\n\nPer selezionare il modello pi√π appropriato, abbiamo utilizzato l‚Äôanalisi basata sulla differenza della densit√† predittiva logaritmica attesa (ELPD). Questo metodo fornisce una misura oggettiva della qualit√† di adattamento, facilitando la scelta del modello che meglio riflette la struttura sottostante dei dati, pur riconoscendo i vantaggi specifici di ciascun approccio.\nAl di l√† delle considerazioni puramente statistiche, i modelli multilivello rivestono un ruolo importante nella discussione sulla crisi della replicabilit√† dei risultati della ricerca psicologica. Gelman e Brown (2024) offrono diverse utili raccomandazioni a questo proposito, sottolineando come tali modelli possano contribuire a migliorare la robustezza e l‚Äôaffidabilit√† delle analisi.\nIn conclusione, l‚Äôadozione di metodologie statistiche avanzate, come la modellazione multilivello, rappresenta un passo cruciale verso una ricerca psicologica pi√π solida. Questi approcci consentono di:\n\ncogliere la complessit√† dei fenomeni studiati,\nprodurre risultati pi√π facilmente replicabili,\nfornire interpretazioni pi√π accurate e contestualizzate.\n\nL‚Äôimpiego di tali tecniche, unitamente a una maggiore consapevolezza metodologica, pu√≤ contribuire significativamente al progresso della disciplina e all‚Äôincremento della fiducia nei risultati della ricerca psicologica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#esercizi",
    "href": "chapters/linear_models/09_hier_regr.html#esercizi",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "66.11 Esercizi",
    "text": "66.11 Esercizi\n\nEsercizio 66.1 Un recente studio (Aungle e Langer 2023) ha presentato un esperimento che ‚Äúha esaminato se i segni lasciati dal cupping guarissero pi√π velocemente o pi√π lentamente in funzione del tempo percepito‚Äù. Il cupping ‚Äúconsiste nel creare una suzione localizzata sulla pelle ‚Ä¶[che porta a] lividi‚Äù.\nTrentatr√© partecipanti sono stati sottoposti a questo trattamento tre volte. In ogni sessione, al partecipante veniva assegnato un compito della durata di 28 minuti, e venivano scattate fotografie della pelle prima e dopo questo intervallo. Le tre sessioni differivano per la manipolazione del ‚Äútempo percepito‚Äù dell‚Äôintervallo di recupero: ai partecipanti veniva detto che l‚Äôintervallo era di 14 minuti, 28 minuti o 56 minuti.\nI risultati riportati sono stati i seguenti:\n\nHealing in the 14-min condition had a mean rating of 6.17 (SD = 2.59, 32 Subjects, 800 ratings); healing in the 28-min condition had a mean rating of 6.43 (SD = 2.54, 33 Subjects, 825 ratings); and healing in the 56-min condition had a mean rating of 7.30 (SD = 2.25, 32 Subjects, 800 ratings).\n\nLa guarigione √® stata valutata da 25 osservatori esterni, che hanno esaminato le fotografie prima e dopo il trattamento. La scala di valutazione era: ‚Äú0.0 = per nulla guarito, 5.0 = parzialmente guarito, 10.0 = completamente guarito‚Äù.\nPer ciascuno dei tre confronti (56 min vs 28 min, 56 min vs 14 min, 28 min vs 14 min), √® stato calcolato il punteggio t (stima divisa per l‚Äôerrore standard). I valori risultanti sono stati rispettivamente 7.2, 10.7 e 2.5.\nUsando i dati forniti dagli autori (si veda il file healing.R), si replichi l‚Äôanalisi di Gelman e Brown (2024) usando Bambi. Si interpretino i risultati alla luce delle considerazioni di Gelman e Brown (2024).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_hier_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_hier_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "66¬† Il modello lineare gerarchico",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npingouin  : 0.5.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nbambi     : 0.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAungle, Peter, e Ellen Langer. 2023. ¬´Physical healing as a function of perceived time¬ª. Scientific Reports 13 (1): 22432.\n\n\nGelman, Andrew. 2024. ¬´Before data analysis: Additional recommendations for designing experiments to learn about the world¬ª. Journal of Consumer Psychology 34: 190‚Äì91.\n\n\nGelman, Andrew, e Nicholas JL Brown. 2024. ¬´How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology¬ª.\n\n\nIoannidis, John PA. 2008. ¬´Why most discovered true associations are inflated¬ª. Epidemiology 19 (5): 640‚Äì48.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMartin, Osvaldo. 2024. Bayesian analysis with python. Packt Publishing Ltd.\n\n\nNosek, Brian A, Jeffrey R Spies, e Matt Motyl. 2012. ¬´Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability¬ª. Perspectives on Psychological Science 7 (6): 615‚Äì31.\n\n\nScheel, Anne M, Mitchell RMJ Schijen, e Dani√´l Lakens. 2021. ¬´An excess of positive results: Comparing the standard psychology literature with registered reports¬ª. Advances in Methods and Practices in Psychological Science 4 (2): 25152459211007467.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>66</span>¬† <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_stan_mixed_models.html",
    "href": "chapters/linear_models/10_stan_mixed_models.html",
    "title": "67¬† Modelli misti con Stan",
    "section": "",
    "text": "Introduzione\nQuesto capitolo descrive l‚Äôutilizzo di Stan nell‚Äôanalisi dei dati mediante modelli misti. Per un approfondimento, si veda Sorensen e Vasishth (2015).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_stan_mixed_models.html#applicazione-pratica",
    "href": "chapters/linear_models/10_stan_mixed_models.html#applicazione-pratica",
    "title": "67¬† Modelli misti con Stan",
    "section": "67.1 Applicazione Pratica",
    "text": "67.1 Applicazione Pratica\nPer fornire un esempio pratico, esamineremo i dati discussi da Gibson e Wu (2013) relativi a uno studio sulla comprensione delle frasi nelle proposizioni relative di soggetto e di oggetto. Una proposizione relativa di soggetto √® una frase in cui un sostantivo (ad esempio, ‚Äúsenatore‚Äù) viene modificato da una proposizione relativa (ad esempio, ‚Äúche ha interrogato il giornalista‚Äù), e il sostantivo modificato √® il soggetto grammaticale della proposizione relativa. In una proposizione relativa di oggetto, il sostantivo modificato dalla proposizione relativa √® l‚Äôoggetto grammaticale della proposizione (per esempio, ‚ÄúIl senatore che il giornalista ha interrogato si √® dimesso‚Äù). In entrambi i casi, il sostantivo modificato (‚Äúsenatore‚Äù) √® chiamato il sostantivo principale.\nUn risultato comune per l‚Äôinglese √® che le proposizioni relative di soggetto sono pi√π facili da elaborare rispetto a quelle di oggetto. Le lingue naturali, in generale, includono proposizioni relative, e fino a poco tempo fa il vantaggio delle proposizioni di soggetto √® stato considerato valido a livello cross-linguistico. Tuttavia, le proposizioni relative in cinese rappresentano un interessante controesempio a questa generalizzazione. Ricerche recenti condotte da Hsiao e Gibson (2003) hanno suggerito che in cinese le proposizioni relative di oggetto sono pi√π facili da elaborare rispetto a quelle di soggetto in un punto specifico della frase (il sostantivo principale della proposizione relativa). Viene presentata un‚Äôanalisi di un insieme di dati, successivamente pubblicata da Gibson e Wu (2013), che valuta questa affermazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_stan_mixed_models.html#i-dati",
    "href": "chapters/linear_models/10_stan_mixed_models.html#i-dati",
    "title": "67¬† Modelli misti con Stan",
    "section": "67.2 I Dati",
    "text": "67.2 I Dati\nLa variabile dipendente dell‚Äôesperimento di Gibson e Wu (2013) era il tempo di lettura (rt) in millisecondi del sostantivo principale della proposizione relativa. Questo √® stato registrato in due condizioni (proposizione relativa di soggetto e proposizione relativa di oggetto), con 37 soggetti e 15 item, presentati in un disegno standard a quadrato latino. Originariamente c‚Äôerano 16 item, ma uno √® stato rimosso, risultando in 37 √ó 15 = 555 punti dati. Tuttavia, otto punti dati da un soggetto (id 27) erano mancanti. Di conseguenza, abbiamo un totale di 555 - 8 = 547 punti dati. La condizione (object relative / subject relative) √® codificata dalla variabile so.\n\nfile_path = os.path.join(project_directory, \"data\", \"gibson_wu_2013.csv\")\ngibson_data = pd.read_csv(file_path)\ngibson_data.head()\n\n\n\n\n\n\n\n\n\nsubj\nitem\ntype\npos\nword\ncorrect\nrt\nregion\ntype2\nso\n\n\n\n\n0\n1\n13\nobj-ext\n8\nÁî∑‰∫∫\n-\n1561\nheadnoun\nobject relative\n1\n\n\n1\n1\n6\nsubj-ext\n8\nÂ•≥Â≠©\n-\n959\nheadnoun\nsubject relative\n-1\n\n\n2\n1\n5\nobj-ext\n8\nËΩéËªä\n-\n582\nheadnoun\nobject relative\n1\n\n\n3\n1\n9\nobj-ext\n8\nÊé¢Âì°\n-\n294\nheadnoun\nobject relative\n1\n\n\n4\n1\n14\nsubj-ext\n8\nÁ©∫ÊúçÂì°\n-\n438\nheadnoun\nsubject relative\n-1\n\n\n\n\n\n\n\n\n\ngibson_data.tail()\n\n\n\n\n\n\n\n\n\nsubj\nitem\ntype\npos\nword\ncorrect\nrt\nregion\ntype2\nso\n\n\n\n\n542\n9\n15\nobj-ext\n8\nÊºîÂì°\n-\n406\nheadnoun\nobject relative\n1\n\n\n543\n9\n16\nsubj-ext\n8\nË®òËÄÖ\n-\n342\nheadnoun\nsubject relative\n-1\n\n\n544\n9\n7\nobj-ext\n8\nÁãó\n-\n478\nheadnoun\nobject relative\n1\n\n\n545\n9\n8\nsubj-ext\n8\nÊ•≠È§òÈÅ∏Êâã\n-\n510\nheadnoun\nsubject relative\n-1\n\n\n546\n9\n11\nobj-ext\n8\nÁêÉÂì°\n-\n350\nheadnoun\nobject relative\n1\n\n\n\n\n\n\n\n\n\ngibson_data.shape\n\n(547, 10)\n\n\n\ngibson_data[\"RT\"] = gibson_data[\"rt\"] / 1000\n\n\n_ = sns.kdeplot(data=gibson_data, x='RT', hue='so', fill=True, common_norm=False, alpha=0.5)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_stan_mixed_models.html#modello-ad-effetti-fissi",
    "href": "chapters/linear_models/10_stan_mixed_models.html#modello-ad-effetti-fissi",
    "title": "67¬† Modelli misti con Stan",
    "section": "67.3 Modello ad effetti fissi",
    "text": "67.3 Modello ad effetti fissi\nIniziamo facendo l‚Äôassunzione che la variabile dipendente del tempo di lettura (rt) sul sostantivo principale sia distribuita approssimativamente in modo log-normale (Rouder, 2005). Questo presuppone che il logaritmo di rt sia distribuito approssimativamente in modo normale. Il logaritmo dei tempi di lettura, logrt, ha una media Œ≤0 sconosciuta. La media della distribuzione log-normale di rt √® la somma di Œ≤0 e di uno scarto Œ≤1so il cui valore dipende dal predittore categoriale so, che assume il valore di -1 quando rt proviene dalla condizione di proposizione relativa di soggetto, e 1 quando rt proviene dalla condizione di proposizione relativa di oggetto.\nIl modello del logaritmo dei tempi di lettura √® dunque il seguente:\n\\[\nlogrt_i = \\beta_0 + \\beta_1 so_i + \\epsilon_i.\n\\]\nQuesto √® un modello a effetti fissi. L‚Äôindice i rappresenta la i-esima riga nel frame dati (in questo caso, i ‚àà {1, . . . , 547}); il termine Œµi rappresenta l‚Äôerrore nella i-esima riga. Con la variabile so codificata come indicato sopra indicato, Œ≤0 rappresenta la media di log rt, indipendentemente dal tipo di proposizione relativa. Il parametro Œ≤1 √® lo scarto rispetto a Œ≤0 in modo che la media di log rt sia Œ≤0 + 1Œ≤1 quando log rt proviene dalla condizione di proposizione relativa di oggetto, e Œ≤0 - 1Œ≤1 quando log rt proviene dalla condizione di proposizione relativa di soggetto. In tali circostanze, 2Œ≤1 corrisponde alla differenza tra le medie nelle condizioni di proposizione relativa di oggetto e di soggetto. Insieme, Œ≤0 e Œ≤1 costituiscono le componenti del modello che caratterizzano l‚Äôeffetto della manipolazione sperimentale (il tipo di proposizione relativa) sulla variabile dipendente rt. Questo √® un modello ad effetti fissi perch√© i parametri Œ≤0 e Œ≤1 non variano da soggetto a soggetto o da item a item.\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"fixed_effects.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N;                // Number of data points\n  vector[N] rt;                  // Reading time\n  vector[N] so;                  // Predictor, constrained between -1 and 1\n}\nparameters {\n  vector[2] beta;                // Intercept and slope\n  real&lt;lower=0&gt; sigma_e;         // Error standard deviation\n}\nmodel {\n  vector[N] mu;\n\n  // Define the model for mu using vectorized operations\n  mu = beta[1] + beta[2] * so;\n\n  // Vectorized likelihood\n  rt ~ lognormal(mu, sigma_e);\n}\n\n\n\nCreiamo un dizionario che include i dati nel formato atteso dal precedente codice Stan.\n\nstan_data = {\n    \"N\" : gibson_data.shape[0],\n    \"rt\" : gibson_data[\"RT\"],\n    \"so\" : gibson_data[\"so\"] \n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo le tracce.\n\n_ = az.plot_trace(fit, var_names=([\"beta\", \"sigma_e\"]), compact=False)\n\n\n\n\n\n\n\n\nEsaminiamo le medie a posteriori e gli intervalli di credibilit√† dei parametri.\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.03\n-0.90\n-0.80\n0.0\n0.0\n3535.32\n2985.81\n1.0\n\n\nbeta[1]\n-0.04\n0.03\n-0.09\n0.01\n0.0\n0.0\n4901.41\n3327.06\n1.0\n\n\nsigma_e\n0.60\n0.02\n0.56\n0.63\n0.0\n0.0\n4436.39\n2709.09\n1.0\n\n\n\n\n\n\n\n\nL‚Äôanalisi della distribuzione di Œ≤1 indica che approssimativamente il 94% della densit√† di probabilit√† a posteriori √® al di sotto dello zero, suggerendo che, in cinese, ci sia qualche evidenza che le proposizioni relative oggetto siano pi√π facili da elaborare rispetto alle proposizioni relative soggetto, dati i dati di Gibson e Wu (2013). Tuttavia, poich√© l‚Äôintervallo di credibilit√† al 95% include lo zero, potremmo essere riluttanti a trarre questa conclusione, se vogliamo adottare un approccio ‚Äúquasi frequentista‚Äù di test di ipotesi.\nTuttavia, √® importante notare che il modello ad effetti fissi presentato qui non √® comunque appropriato per i dati attuali. L‚Äôassunzione di indipendenza degli errori viene violata, perch√© abbiamo misure ripetute per ciascun soggetto e per ciascun item. I modelli lineari misti estendono il modello lineare per risolvere precisamente questo problema.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_stan_mixed_models.html#modello-ad-intercette-casuali",
    "href": "chapters/linear_models/10_stan_mixed_models.html#modello-ad-intercette-casuali",
    "title": "67¬† Modelli misti con Stan",
    "section": "67.4 Modello ad Intercette Casuali",
    "text": "67.4 Modello ad Intercette Casuali\nIl modello degli effetti fissi non √® adatto per i dati di Gibson e Wu (2013) poich√© non tiene conto del fatto che abbiamo misurazioni multiple per ciascun soggetto e item. Come gi√† accennato, queste misurazioni multiple portano a una violazione dell‚Äôassunzione di indipendenza degli errori. Inoltre, i coefficienti degli effetti fissi Œ≤0 e Œ≤1 rappresentano medie su tutti i soggetti e gli item, ignorando il fatto che alcuni soggetti saranno pi√π veloci e alcuni pi√π lenti della media; allo stesso modo, alcuni item saranno letti pi√π rapidamente della media e altri pi√π lentamente.\nNei modelli lineari misti, prendiamo in considerazione questa variabilit√† per soggetto e per item aggiungendo i termini di correzione u0j e w0k, che aggiustano Œ≤0 per il soggetto j e l‚Äôitem k. Questo scompone parzialmente Œµi in una somma di termini u0j e w0k, che sono gli aggiustamenti dell‚Äôintercetta Œ≤0 per il soggetto j e l‚Äôitem k associato a rt_i. Se il soggetto j √® pi√π lento della media di tutti i soggetti, uj sar√† un numero positivo, e se l‚Äôitem k viene letto pi√π velocemente della durata media di tutti gli item, allora wk sar√† un numero negativo. Ogni soggetto j ha il proprio aggiustamento u0j, e ogni item ha il proprio aggiustamento w0k. Questi aggiustamenti u0j e w0k sono chiamati intercette casuali (random intercepts) da Pinheiro e Bates (2000) e intercette variabili (varying intercepts) da Gelman e Hill (2007), e aggiustando Œ≤0 con questi termini miglioriamo la nostra capacit√† di tener conto della variabilit√† per i soggetti e per gli item.\nIl modello statistico ad intercette casuali assume che questi aggiustamenti sono distribuiti normalmente intorno allo zero con deviazione standard sconosciuta:\n\\[\nu_0 \\sim N(0, \\sigma_u),\n\\]\n\\[\nw_0 ‚àº N(0, \\sigma_w).\n\\]\nAvendo specificato il modello in questo modo, ci sono tre fonti di varianza: la deviazione standard degli errori œÉe, la deviazione standard delle intercette casuali per i soggetti, œÉu, e la deviazione standard delle intercette casuali per gli item, œÉw. Ci riferiamo a questi valori come alle componenti della varianza.\nEsprimiamo ora il logaritmo del tempo di lettura, prodotto dai soggetti j ‚àà {1, . . . , 37} che leggono gli item k ‚àà {1,‚Ä¶, 15}, nelle condizioni i ‚àà {1, 2} (1 si riferisce alle proposizioni soggetto, 2 alle proposizioni oggetto), come la seguente somma.\n\\[\n\\log rt_{ijk} = \\beta_0 + \\beta_{1i} + u_{0j} + w_{0k} + \\varepsilon_{ijk}.\n\\]\nNotiamo che stiamo utilizzando un modo leggermente diverso per descrivere il modello, rispetto al modello degli effetti fissi. Stiamo utilizzando indici per soggetto, item e condizione per identificare ciascuna riga del data frame. Inoltre, anzich√© scrivere \\(\\beta_1 so_i\\), indicizziamo direttamente Œ≤1 in funzione della condizione i (essendo so \\(\\in \\{-1, 1\\}\\)).\nQuesto √® un modello √® un modello ad effetti misti, e pi√π specificamente un modello ad intercette casuali. Il coefficiente \\(\\beta_{1i}\\) √® quello di maggior interesse; avr√† un valore medio ‚àíŒ≤1 per le proposizioni soggetto e Œ≤1 per le proposizioni oggetto a causa della codifica del contrasto. Quindi, se la nostra media a posteriori per Œ≤1 √® negativa, ci√≤ suggerirebbe che le proposizioni oggetto vengono lette pi√π velocemente delle proposizioni soggetto.\n\nstan_file = os.path.join(project_directory, \"stan\", \"random_intercepts.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:33:49 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts\n12:34:01 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts\n\n\ndata {\n  int&lt;lower=0&gt; N;                  // Number of data points\n  vector[N] rt;                    // Reading time\n  vector[N] so;                    // Predictor, constrained between -1 and 1\n  int&lt;lower=0&gt; J;                  // Number of subjects\n  int&lt;lower=0&gt; K;                  // Number of items\n  array[N] int&lt;lower=0, upper=J&gt; subj;\n  array[N] int&lt;lower=0, upper=K&gt; item;\n}\nparameters {\n  vector[2] beta;                  // Fixed intercept and slope\n  vector[J] u;                     // Subject intercepts\n  vector[K] w;                     // Item intercepts\n  real&lt;lower=0&gt; sigma_e;           // Error standard deviation\n  real&lt;lower=0&gt; sigma_u;           // Subject standard deviation\n  real&lt;lower=0&gt; sigma_w;           // Item standard deviation\n}\nmodel {\n  vector[N] mu;\n\n  // Priors\n  beta ~ normal(0, 5);             // Assuming a weakly informative prior for beta\n  u ~ normal(0, sigma_u);\n  w ~ normal(0, sigma_w);\n  sigma_e ~ exponential(1);\n  sigma_u ~ exponential(1);\n  sigma_w ~ exponential(1);\n\n  // Likelihood\n  mu = beta[1] + beta[2] * so + u[subj] + w[item];  // Vectorized computation of mu\n  rt ~ lognormal(mu, sigma_e);\n}\n\n\n\n\nstan_data = {\n    'subj': pd.factorize(gibson_data['subj'])[0] + 1,\n    'item': pd.factorize(gibson_data['item'])[0] + 1,\n    'rt': gibson_data['RT'].values,\n    'so': gibson_data['so'].values,\n    'N': len(gibson_data),\n    'J': gibson_data['subj'].nunique(),\n    'K': gibson_data['item'].nunique()\n}\n\n\nfit = model.sample(data=stan_data)\n\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\", \"sigma_u\", \"sigma_w\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.07\n-0.97\n-0.70\n0.0\n0.0\n1101.73\n1576.57\n1.0\n\n\nbeta[1]\n-0.04\n0.02\n-0.08\n0.01\n0.0\n0.0\n9851.81\n3141.84\n1.0\n\n\nsigma_e\n0.52\n0.02\n0.49\n0.55\n0.0\n0.0\n7247.72\n2689.88\n1.0\n\n\nsigma_u\n0.25\n0.04\n0.17\n0.33\n0.0\n0.0\n3714.95\n2902.11\n1.0\n\n\nsigma_w\n0.20\n0.05\n0.11\n0.30\n0.0\n0.0\n3978.74\n2983.07\n1.0\n\n\n\n\n\n\n\n\nSi noti che rispetto al Modello ad effetti fissi, la stima di œÉe √® pi√π piccola; questo perch√© ora vengono stimate due componenti di varianza aggiuntive. Si noti inoltre che l‚Äôintervallo di credibilit√† al 95% per la stima di Œ≤1 include lo zero; quindi, c‚Äô√® ancora qualche evidenza che le proposizioni oggetto siano pi√π facili delle proposizioni soggetto, ma non possiamo escludere la possibilit√† che non ci sia una differenza credibile nei tempi di lettura tra i due tipi di proposizioni relative.\nIl presente modello con intercette casuali assume che l‚Äôeffetto della variabile so sia lo stesso per ciascun soggetto.Ma questo non √® necessariamente vero. Per consentire al modello di tenere conto che l‚Äôeffetto della variabile so possa variare tra i soggetti, dobbiamo estendere il presente modello e trasformarlo in un modello che include sia intercette sia pendenze casuali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_stan_mixed_models.html#random-intercepts-random-slopes-model",
    "href": "chapters/linear_models/10_stan_mixed_models.html#random-intercepts-random-slopes-model",
    "title": "67¬† Modelli misti con Stan",
    "section": "67.5 Random Intercepts, Random Slopes Model",
    "text": "67.5 Random Intercepts, Random Slopes Model\nPer esprimere la struttura descritta sopra nel modello lineare misto, dobbiamo specificare le pendenze casuali. Il primo cambiamento consiste nel permettere che la dimensione dell‚Äôeffetto per so varii per soggetto e per item. Consentiamo che la dimensione dell‚Äôeffetto vari per soggetto e per item includendo nel modello pendenze variabili per soggetto e per item, che costituiscono degli scarti rispetto alla pendenza fissa Œ≤1, allo stesso modo in cui le intercette variabili per soggetto e per item aggiustano l‚Äôintercetta fissa Œ≤0. Questo aggiustamento della pendenza per soggetto e per item √® espresso aggiustando Œ≤1 tramite due termini u1j e w1k. Questi termini rappresentano le pendenze casuali. Aggiungendo al modello tali termini aggiuntivi possiamo rendere conto del fatto che l‚Äôeffetto del tipo di proposizione relativa varia per soggetto j e per item k.\nEsprimiamo il logaritmo del tempo di lettura, prodotto dal soggetto j che legge l‚Äôitem k, come la seguente somma.\n\\[\n\\text{log } rt_{ijk} = \\beta_0 + u_{0j} + w_{0k} + \\beta_{1i} + u_{1ij} + w_{1ik} + \\epsilon_{ijk},\n\\]\ndove il pedice \\(i\\) indica le condizioni. Questo √® un modello di intercette variabili e pendenze variabili.\nIl modello √® specificato in linguaggio Stan come indicato nel file random_slopes.stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"random_slopes.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:35:00 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/random_slopes.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/random_slopes\n12:35:11 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/random_slopes\n\n\ndata {\n  int&lt;lower=0&gt; N;                  // Number of data points\n  vector[N] rt;                    // Reading time\n  vector[N] so;                    // Predictor, constrained between -1 and 1\n  int&lt;lower=0&gt; J;                  // Number of subjects\n  int&lt;lower=0&gt; K;                  // Number of items\n  array[N] int&lt;lower=0, upper=J&gt; subj;\n  array[N] int&lt;lower=0, upper=K&gt; item;\n}\nparameters {\n  vector[2] beta;                  // Fixed intercept and slope\n  real&lt;lower=0&gt; sigma_e;           // Error standard deviation\n  matrix[2,J] u;                   // Subject intercepts and slopes\n  vector&lt;lower=0&gt;[2] sigma_u;      // Subject standard deviations\n  matrix[2,K] w;                   // Item intercepts and slopes\n  vector&lt;lower=0&gt;[2] sigma_w;      // Item standard deviations\n}\nmodel {\n  // Priors\n  for (j in 1:J) {\n    u[1,j] ~ normal(0, sigma_u[1]); // Prior for subject intercepts\n    u[2,j] ~ normal(0, sigma_u[2]); // Prior for subject slopes\n  }\n  \n  for (k in 1:K) {\n    w[1,k] ~ normal(0, sigma_w[1]); // Prior for item intercepts\n    w[2,k] ~ normal(0, sigma_w[2]); // Prior for item slopes\n  }\n  \n  // Likelihood\n  for (i in 1:N) {\n    real mu = beta[1] + u[1, subj[i]] + w[1, item[i]]\n              + (beta[2] + u[2, subj[i]] + w[2, item[i]]) * so[i];\n    rt[i] ~ lognormal(mu, sigma_e);\n  }\n}\n\n\n\n\n\nfit = model.sample(\n    data=stan_data,\n    iter_sampling=2000,\n    iter_warmup=1000,\n)\n\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\", \"sigma_u\", \"sigma_w\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.07\n-0.98\n-0.71\n0.00\n0.0\n706.84\n302.85\n1.01\n\n\nbeta[1]\n-0.04\n0.03\n-0.09\n0.02\n0.00\n0.0\n1982.52\n4756.68\n1.00\n\n\nsigma_e\n0.52\n0.02\n0.48\n0.55\n0.00\n0.0\n2288.99\n5672.93\n1.00\n\n\nsigma_u[0]\n0.25\n0.04\n0.18\n0.34\n0.00\n0.0\n712.02\n275.18\n1.01\n\n\nsigma_u[1]\n0.06\n0.04\n0.01\n0.12\n0.01\n0.0\n39.10\n29.54\n1.09\n\n\nsigma_w[0]\n0.20\n0.05\n0.11\n0.30\n0.00\n0.0\n4099.46\n5332.27\n1.00\n\n\nsigma_w[1]\n0.04\n0.03\n0.00\n0.11\n0.00\n0.0\n114.76\n68.32\n1.03\n\n\n\n\n\n\n\n\nAnche in questo caso, Sorensen e Vasishth (2015) commentano che l‚Äôintervallo di credibilit√† al 95% per \\(\\beta_1\\) include lo zero.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_stan_mixed_models.html#modello-a-effetti-misti-con-pendenze-e-intercepce-casuali-correlate",
    "href": "chapters/linear_models/10_stan_mixed_models.html#modello-a-effetti-misti-con-pendenze-e-intercepce-casuali-correlate",
    "title": "67¬† Modelli misti con Stan",
    "section": "67.6 Modello a Effetti Misti con Pendenze e Intercepce Casuali Correlate",
    "text": "67.6 Modello a Effetti Misti con Pendenze e Intercepce Casuali Correlate\nSorensen e Vasishth (2015), nell‚Äôapprofondire l‚Äôanalisi dei dati presentati da Gibson e Wu (2013), propongono un avanzamento metodologico nel modello preso in considerazione, introducendo un modello a effetti misti che incorpora intercette e pendenze casuali correlate. La logica dietro questo approccio consiste nell‚Äôesaminare la possibilit√† che vi sia una relazione tra la velocit√† di lettura dei soggetti (espressa attraverso intercette casuali) e la loro reazione alle diverse tipologie di proposizioni (oggetto vs.¬†soggetto), ipotizzando che soggetti con una velocit√† di lettura superiore alla media possano esperire un rallentamento maggiore nel leggere proposizioni oggetto rispetto alle proposizioni soggetto, e viceversa. Questa ipotesi suggerisce l‚Äôesistenza di correlazioni tra le intercette casuali (che rappresentano variazioni individuali nella velocit√† di base di lettura) e le pendenze casuali (che rappresentano la variazione nella risposta al tipo di proposizione).\nPer integrare questa struttura nel modello lineare misto (LMM), √® essenziale modellare la correlazione tra intercette casuali e pendenze casuali. La formula del modello, la quale rimane inalterata rispetto alla versione precedente, √® rappresentata come segue:\n\\[\n\\text{log } rt_{ijk} = \\beta_0 + u_{0j} + w_{0k} + \\beta_1 + u_{1ij} + w_{1ik} + \\epsilon_{ijk}.\n\\]\nL‚Äôintroduzione di correlazioni tra intercette e pendenze casuali trasforma il modello in un approccio di intercette e pendenze correlate, richiedendo la definizione di una matrice di varianza-covarianza per gli effetti casuali. Questo implica la necessit√† di stabilire una relazione di covarianza tra le intercette casuali (per soggetto e per item) e le pendenze casuali (per soggetto e per item), suggerendo che le pendenze per soggetto (u1) potrebbero correlare con le intercette per soggetto (u0), cos√¨ come le pendenze per item (w1) potrebbero correlare con le intercette per item (w0). Questo approccio offre una visione pi√π dettagliata e accurata della dinamica tra velocit√† di lettura individuale e reazione alle differenti strutture sintattiche, arricchendo significativamente l‚Äôanalisi statistica dei dati comportamentali.\nNel contesto di questo insegnamento, non approfondiremo la formulazione del modello Stan che include la correlazione tra pendenze e intercette, data la sua complessit√† tecnica. Tuttavia, √® importante sottolineare che √® possibile ottenere risultati analoghi con un approccio pi√π accessibile utilizzando il pacchetto Bambi per Python. Questo strumento consente di specificare modelli statistici in maniera intuitiva e diretta. Per esempio, per incorporare la correlazione tra pendenze e intercette nel nostro modello, possiamo utilizzare la seguente sintassi con Bambi:\nmodel = bmb.Model(\"rt ~ so + (so | subject) + (so | item)\", data)\nQuesta espressione crea un modello in cui rt (il tempo di risposta) √® modellato come una funzione del tipo di proposizione so, con pendenze e intercette casuali correlate sia per subject che per item. L‚Äôuso di (so | subject) e (so | item) permette di modellare specificamente le variazioni nelle risposte attribuibili a differenze individuali tra i soggetti e caratteristiche uniche degli item, rispettivamente. Questa sintassi semplifica notevolmente l‚Äôimplementazione di modelli complessi, rendendo l‚Äôanalisi accessibile anche a chi possiede una conoscenza di base della statistica bayesiana e della modellazione statistica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_stan_mixed_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_stan_mixed_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "67¬† Modelli misti con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanp\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanp: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGibson, Edward, e H-H Iris Wu. 2013. ¬´Processing Chinese relative clauses in context¬ª. Language and Cognitive Processes 28 (1-2): 125‚Äì55.\n\n\nSorensen, Tanner, e Shravan Vasishth. 2015. ¬´Bayesian linear mixed models using Stan: A tutorial for psychologists, linguists, and cognitive scientists¬ª. arXiv preprint arXiv:1506.06201.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>67</span>¬† <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_specification_error.html",
    "href": "chapters/linear_models/11_specification_error.html",
    "title": "68¬† Errore di specificazione",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esamineremo l‚Äôerrore di specificazione nei modelli di regressione lineare. L‚Äôerrore di specificazione si verifica quando una variabile importante viene omessa dal modello, causando stime dei coefficienti che risultano sistematicamente distorte e inconsistenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_specification_error.html#dimostrazione",
    "href": "chapters/linear_models/11_specification_error.html#dimostrazione",
    "title": "68¬† Errore di specificazione",
    "section": "68.1 Dimostrazione",
    "text": "68.1 Dimostrazione\nLa dimostrazione algebrica dell‚Äôerrore di specificazione nel modello di regressione, in caso di omissione di una variabile rilevante, coinvolge l‚Äôanalisi delle conseguenze che questa omissione ha sulla stima dei coefficienti di regressione.\nQuando un modello di regressione omette una variabile rilevante che √® correlata sia con la variabile dipendente \\(Y\\) sia con almeno una delle variabili indipendenti incluse nel modello, il coefficiente stimato per le variabili indipendenti incluse pu√≤ essere sistematicamente distorto.\nPer comprendere il bias causato dall‚Äôomissione di una variabile rilevante in un modello di regressione, √® essenziale analizzare dettagliatamente il calcolo delle covarianze e varianze coinvolte. Di seguito viene fornita una spiegazione dei passaggi algebrici che portano alla formulazione del bias di omissione variabile (Omitted Variable Bias, OVB).\n\n68.1.1 Modello Completo e Modello Ridotto\n\nModello Completo:\n\\[\nY = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\epsilon\n\\]\nQui, \\(Y\\) √® la variabile dipendente, \\(X\\) e \\(Z\\) sono variabili indipendenti, \\(\\beta_0, \\beta_1, \\beta_2\\) sono i coefficienti, e \\(\\epsilon\\) √® il termine di errore.\nModello Ridotto (con omissione di \\(Z\\)):\n\\[\nY = \\alpha_0 + \\alpha_1 X + u\n\\]\ndove \\(u = \\beta_2 Z + \\epsilon\\) rappresenta il nuovo termine di errore che ora include l‚Äôeffetto non osservato di \\(Z\\).\n\n\n\n68.1.2 Decomposizione di \\(X\\)\nIpotesi:\n\\[ X = \\gamma_0 + \\gamma_1 Z + V \\]\ndove \\(V\\) √® una parte di \\(X\\) indipendente da \\(Z\\), quindi \\(\\text{Cov}(V, Z) = 0\\).\n\n\n68.1.3 Sostituzione nel Modello Ridotto\nSostituendo la decomposizione di \\(X\\) nel modello ridotto, otteniamo:\n\\[ Y = \\alpha_0 + \\alpha_1 (\\gamma_0 + \\gamma_1 Z + V) + u \\]\n\\[ Y = \\alpha_0 + \\alpha_1 \\gamma_0 + \\alpha_1 \\gamma_1 Z + \\alpha_1 V + \\beta_2 Z + \\epsilon \\]\n\\[ Y = (\\alpha_0 + \\alpha_1 \\gamma_0) + (\\alpha_1 \\gamma_1 + \\beta_2) Z + \\alpha_1 V + \\epsilon \\]\n\n\n68.1.4 Calcolo della Covarianza \\(\\text{Cov}(Y, X)\\)\n\\[ \\text{Cov}(Y, X) = \\text{Cov}(\\beta_1 X + \\beta_2 Z + \\epsilon, X) \\]\n\\[ \\text{Cov}(Y, X) = \\beta_1 \\text{Var}(X) + \\beta_2 \\text{Cov}(Z, X) \\]\ndove si usa che \\(\\text{Cov}(\\epsilon, X) = 0\\) poich√© \\(\\epsilon\\) √® indipendente da \\(X\\).\n\n\n68.1.5 Calcolo della Varianza di \\(X\\)\n\\[ \\text{Var}(X) = \\text{Var}(\\gamma_0 + \\gamma_1 Z + V) \\]\n\\[ \\text{Var}(X) = \\gamma_1^2 \\text{Var}(Z) + \\text{Var}(V) \\]\nAncora, \\(\\text{Cov}(Z, V) = 0\\) perch√© \\(V\\) √® definito come indipendente da \\(Z\\).\n\n\n68.1.6 Formula del Coefficiente Stimato \\(\\hat{\\alpha}_1\\)\n\\[ \\hat{\\alpha}_1 = \\frac{\\text{Cov}(Y, X)}{\\text{Var}(X)} \\]\n\\[ \\hat{\\alpha}_1 = \\beta_1 + \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} \\]\n\n\n68.1.7 Interpretazione del Bias\nIl bias nel coefficiente stimato \\(\\alpha_1\\), rispetto al vero coefficiente \\(\\beta_1\\), √® dato da:\n\\[ \\text{Bias}(\\hat{\\alpha}_1) = \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} \\]\nQuesto risultato dimostra che il bias √® direttamente proporzionale al coefficiente \\(\\beta_2\\) della variabile omessa \\(Z\\) e al rapporto di covarianza tra \\(Z\\) e \\(X\\) diviso per la varianza di \\(X\\). Questo bias pu√≤ essere positivo o negativo a seconda della direzione della correlazione tra \\(X\\) e \\(Z\\), e della grandezza di \\(\\beta_2\\).\n\n\n68.1.8 Conclusioni\nIn sintesi, l‚Äôomissione di \\(Z\\) introduce un bias nella stima di \\(\\alpha_1\\) che non riflette accuratamente \\(\\beta_1\\) se \\(Z\\) √® correlata sia con \\(Y\\) che con \\(X\\). Questo errore di specificazione pu√≤ portare a conclusioni errate sull‚Äôeffetto di \\(X\\) su \\(Y\\) e compromettere l‚Äôaccuratezza delle inferenze tratte dal modello di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_specification_error.html#un-esempio-numerico",
    "href": "chapters/linear_models/11_specification_error.html#un-esempio-numerico",
    "title": "68¬† Errore di specificazione",
    "section": "68.2 Un esempio numerico",
    "text": "68.2 Un esempio numerico\nImmaginiamo di analizzare l‚Äôimpatto di due variabili indipendenti, la motivazione e l‚Äôansia, sulla prestazione in un compito specifico. Supponiamo che l‚Äôansia influenzi negativamente la prestazione, mentre la motivazione abbia un effetto positivo.\nLa nostra simulazione evidenzia due scenari distinti:\n\nModello Completo: Quando sia la motivazione che l‚Äôansia sono incluse nel modello di regressione, il coefficiente di regressione per l‚Äôansia viene stimato correttamente come negativo, riflettendo il suo impatto negativo sulla prestazione. Questo conferma che, quando tutte le variabili rilevanti sono presenti, la stima dei loro effetti √® accurata e non distorta.\nModello Ridotto (omissione della motivazione): Se la motivazione, che √® positivamente correlata alla prestazione e positivamente correlata all‚Äôansia, viene omessa dal modello, osserviamo un cambiamento notevole nel coefficiente di regressione per l‚Äôansia. In questo modello ridotto, il coefficiente per l‚Äôansia pu√≤ addirittura diventare positivo, suggerendo erroneamente che l‚Äôansia abbia un effetto benefico sulla prestazione. Questo fenomeno si verifica perch√© l‚Äôeffetto indiretto e non osservato della motivazione sull‚Äôansia porta a una stima distorta quando la motivazione non √® controllata nel modello.\n\n\n# Generiamo dati casuali\nnp.random.seed(42)\nn = 100  # Numero di osservazioni\n\n# Variabili indipendenti con correlazione negativa tra loro\nmotivazione = np.random.normal(100, 10, n)\nansia = 200 + 0.75 * motivazione + np.random.normal(0, 5, n)\n\n# Variabile dipendente, con peso maggiore sulla motivazione rispetto all'ansia\nprestazione = 5 * motivazione - 1 * ansia + np.random.normal(0, 50, n)\n\n# Creazione DataFrame\ndata = pd.DataFrame(\n    {\"Motivazione\": motivazione, \"Ansia\": ansia, \"Prestazione\": prestazione}\n)\n\n\nmodel_full = bmb.Model(\"Prestazione ~ Motivazione + Ansia\", data=data)\nresults_full = model_full.fit(nuts_sampler=\"numpyro\")\n\n\naz.summary(results_full, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAnsia\n-1.12\n1.18\n-3.33\n1.01\n0.02\n0.02\n2347.49\n2341.41\n1.0\n\n\nIntercept\n-83.86\n250.01\n-521.27\n393.71\n4.87\n3.59\n2641.21\n2665.94\n1.0\n\n\nMotivazione\n6.21\n1.01\n4.38\n8.11\n0.02\n0.01\n2359.56\n2569.60\n1.0\n\n\nPrestazione_sigma\n54.19\n3.86\n47.05\n61.19\n0.06\n0.05\n3580.58\n2684.47\n1.0\n\n\n\n\n\n\n\n\n\n# Analisi di regressione con pingouin\nresults_full = pg.linear_regression(data[[\"Motivazione\", \"Ansia\"]], data[\"Prestazione\"])\nresults_full\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-84.058695\n244.261908\n-0.344133\n7.314908e-01\n0.467656\n0.456679\n-568.850966\n400.733576\n\n\n1\nMotivazione\n6.222523\n0.977770\n6.363994\n6.510176e-09\n0.467656\n0.456679\n4.281920\n8.163125\n\n\n2\nAnsia\n-1.122768\n1.143817\n-0.981597\n3.287403e-01\n0.467656\n0.456679\n-3.392928\n1.147393\n\n\n\n\n\n\n\n\n\nmodel_ansia_only = bmb.Model(\"Prestazione ~ Ansia\", data=data)\nresults_ansia_only = model_ansia_only.fit(nuts_sampler=\"numpyro\")\n\n\naz.summary(results_ansia_only, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAnsia\n4.66\n0.84\n3.01\n6.13\n0.01\n0.01\n3797.94\n2688.34\n1.0\n\n\nIntercept\n-1055.09\n229.27\n-1470.97\n-615.01\n3.71\n2.65\n3810.32\n2766.51\n1.0\n\n\nPrestazione_sigma\n64.14\n4.66\n55.82\n73.16\n0.08\n0.06\n3209.37\n2678.96\n1.0\n\n\n\n\n\n\n\n\n\nresults_ansia_only = pg.linear_regression(data[[\"Ansia\"]], data[\"Prestazione\"])\nresults_ansia_only\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-1052.984249\n226.249178\n-4.654091\n1.020933e-05\n0.245386\n0.237686\n-1501.968379\n-604.000119\n\n\n1\nAnsia\n4.653853\n0.824399\n5.645148\n1.608208e-07\n0.245386\n0.237686\n3.017861\n6.289846\n\n\n\n\n\n\n\n\nQuesta dimostrazione mette in luce l‚Äôimportanza di includere tutte le variabili rilevanti in un modello di regressione per evitare conclusioni fuorvianti e garantire che le stime dei coefficienti riflettano veramente le relazioni causali tra le variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_specification_error.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_specification_error.html#informazioni-sullambiente-di-sviluppo",
    "title": "68¬† Errore di specificazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.13.1\npymc      : 5.15.1\npingouin  : 0.5.4\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\narviz     : 0.18.0\nbambi     : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>68</span>¬† <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_causal_inference.html",
    "href": "chapters/linear_models/12_causal_inference.html",
    "title": "69¬† Inferenza causale",
    "section": "",
    "text": "Introduzione\nLo scopo di questo capitolo √® di introdurre il modello di regressione multipla e di discutere come esso si collega all‚Äôanalisi causale.\nIl modello di regressione offre indubitabili vantaggi: i coefficienti parziali di regressione consentono di isolare l‚Äôeffetto di una variabile, al netto dell‚Äôinfluenza delle altre variabili nel modello. Questo approccio permette di ottenere quello che viene chiamato ‚Äúcontrollo statistico‚Äù. Nel capitolo precedente, abbiamo introdotto il concetto di errore di specificazione: se escludiamo dal modello di regressione una variabile che ha un effetto causale su \\(Y\\) ed √® correlata con gli altri predittori, le stime degli effetti causali fornite dal modello di regressione saranno sistematicamente distorte. Questo potrebbe suggerire che sia meglio aggiungere al modello quanti pi√π predittori possibile, per massimizzare il controllo statistico e minimizzare la possibilit√† di un errore di specificazione.\nTuttavia, questo approccio, che McElreath (2020) chiama ‚Äúinsalata causale‚Äù, produce pi√π effetti negativi di quanti problemi risolva. In questo capitolo, esploreremo come la selezione delle variabili indipendenti da inserire nel modello di regressione richieda una conoscenza approfondita della struttura causale del fenomeno che si desidera descrivere. Senza una tale conoscenza, l‚Äôuso del modello di regressione pu√≤ risultare pi√π dannoso che utile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_causal_inference.html#confondimento",
    "href": "chapters/linear_models/12_causal_inference.html#confondimento",
    "title": "69¬† Inferenza causale",
    "section": "69.1 Confondimento",
    "text": "69.1 Confondimento\nIniziamo con una definizione del fenomeno del confondimento. Il confondimento si verifica quando l‚Äôassociazione tra un risultato \\(Y\\) e un predittore di interesse \\(X\\) differisce da quella che si osserverebbe se i valori di \\(X\\) fossero determinati sperimentalmente.\nAd esempio, consideriamo l‚Äôassociazione tra istruzione (\\(E\\)) e salario (\\(W\\)). Esistono variabili non osservate (\\(U\\)) che influenzano entrambe, come il luogo di residenza e lo status socioeconomico. Nel seguente grafo causale, ci sono due percorsi tra \\(E\\) e \\(W\\):\n\nf = graphviz.Digraph()\nwith f.subgraph() as s:\n    s.attr(rank='same')\n    s.node(\"E\")\n    s.node(\"W\")\n\nf.node(\"U\")\nf.edge(\"U\", \"E\")\nf.edge(\"U\", \"W\")\nf.edge(\"E\", \"W\")\n\nf\n\n\n\n\n\n\n\n\n\nPercorso causale diretto: \\(E \\rightarrow W\\)\nPercorso non causale indiretto: \\(E \\leftarrow U \\rightarrow W\\)\n\nSolo il primo percorso (\\(E \\rightarrow W\\)) rappresenta un effetto causale. Il secondo percorso (\\(E \\leftarrow U \\rightarrow W\\)) crea un‚Äôassociazione statistica ma non causale.\nPer isolare il percorso causale, la soluzione ideale √® condurre un esperimento randomizzato, assegnando i livelli di istruzione \\(E\\) casualmente, eliminando cos√¨ l‚Äôinfluenza di \\(U\\) su \\(E\\). L‚Äôassegnazione casuale dell‚Äôistruzione blocca il percorso \\(E \\leftarrow U \\rightarrow W\\), lasciando solo il percorso causale \\(E \\rightarrow W\\).\nTuttavia, questo esperimento non pu√≤ essere eseguito. In assenza di esperimenti, √® necessaria una soluzione statistica che blocchi il percorso non causale. In assenza di esperimenti, si pu√≤ condizionare su \\(U\\) aggiungendolo al modello statistico. Questo blocca il flusso di informazioni attraverso \\(U\\), isolando l‚Äôeffetto causale tra \\(E\\) e \\(W\\).\nAd esempio, se \\(U\\) √® la ricchezza media di una regione, conoscere \\(U\\) (la regione) elimina l‚Äôinfluenza indiretta su \\(W\\) attraverso \\(E\\). Dopo aver appreso \\(U\\), sapere \\(E\\) non aggiunge ulteriori informazioni su \\(W\\).\nIn sintesi, il confondimento pu√≤ distorcere l‚Äôassociazione tra due variabili a causa di percorsi indiretti attraverso variabili non osservate. La randomizzazione o il condizionamento su queste variabili pu√≤ isolare il percorso causale, permettendo di misurare accuratamente l‚Äôeffetto di una variabile sull‚Äôaltra.\nQuesta discussione ha un‚Äôimplicazione importante per il modello di regressione. Nel caso dell‚Äôesempio, solo se introduciamo nel modello di regressione la covariata \\(U\\), ovvero se condizioniamo su \\(U\\), possiamo stimare in maniera non distorta la relazione causale tra \\(E\\) e \\(W\\). Tuttavia, ci sono anche casi in cui introdurre la covariata sbagliata pu√≤ introdurre distorsioni nei risultati dell‚Äôanalisi di regressione. Senza una comprensione delle relazioni causali che legano le variabili, non √® possibile determinare quali siano le variabili da inserire o da escludere dal modello di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_causal_inference.html#confondimento-1",
    "href": "chapters/linear_models/12_causal_inference.html#confondimento-1",
    "title": "69¬† Inferenza causale",
    "section": "69.2 Confondimento",
    "text": "69.2 Confondimento\nIniziamo con una definizione del fenomeno del confondimento. Il confondimento si verifica quando l‚Äôassociazione tra un risultato \\(Y\\) e un predittore di interesse \\(X\\) differisce da quella che si osserverebbe se i valori di \\(X\\) fossero determinati sperimentalmente.\nAd esempio, consideriamo l‚Äôassociazione tra istruzione (\\(E\\)) e salario (\\(W\\)). Esistono variabili non osservate (\\(U\\)) che influenzano entrambe, come il luogo di residenza e lo status socioeconomico. Nel seguente grafo causale, ci sono due percorsi tra \\(E\\) e \\(W\\):\nimport graphviz\nf = graphviz.Digraph()\nwith f.subgraph() as s:\n    s.attr(rank='same')\n    s.node(\"E\")\n    s.node(\"W\")\nf.node(\"U\")\nf.edge(\"U\", \"E\")\nf.edge(\"U\", \"W\")\nf.edge(\"E\", \"W\")\nf\n\nPercorso causale diretto: \\(E \\rightarrow W\\)\nPercorso non causale indiretto: \\(E \\leftarrow U \\rightarrow W\\)\n\nSolo il primo percorso (\\(E \\rightarrow W\\)) rappresenta un effetto causale. Il secondo percorso (\\(E \\leftarrow U \\rightarrow W\\)) crea un‚Äôassociazione statistica ma non causale.\nPer isolare il percorso causale, la soluzione ideale √® condurre un esperimento randomizzato, assegnando i livelli di istruzione \\(E\\) casualmente, eliminando cos√¨ l‚Äôinfluenza di \\(U\\) su \\(E\\). L‚Äôassegnazione casuale dell‚Äôistruzione blocca il percorso \\(E \\leftarrow U \\rightarrow W\\), lasciando solo il percorso causale \\(E \\rightarrow W\\).\nTuttavia, questo esperimento non pu√≤ essere eseguito. In assenza di esperimenti, √® necessaria una soluzione statistica che blocchi il percorso non causale. Si pu√≤ condizionare su \\(U\\) aggiungendolo al modello statistico. Questo blocca il flusso di informazioni attraverso \\(U\\), isolando l‚Äôeffetto causale tra \\(E\\) e \\(W\\).\nAd esempio, se \\(U\\) √® la ricchezza media di una regione, conoscere \\(U\\) (la regione) elimina l‚Äôinfluenza indiretta su \\(W\\) attraverso \\(E\\). Dopo aver appreso \\(U\\), sapere \\(E\\) non aggiunge ulteriori informazioni su \\(W\\).\nIn sintesi, il confondimento pu√≤ distorcere l‚Äôassociazione tra due variabili a causa di percorsi indiretti attraverso variabili non osservate. La randomizzazione o il condizionamento su queste variabili pu√≤ isolare il percorso causale, permettendo di misurare accuratamente l‚Äôeffetto di una variabile sull‚Äôaltra.\nQuesta discussione ha un‚Äôimplicazione importante per il modello di regressione. Nel caso dell‚Äôesempio, solo se introduciamo nel modello di regressione la covariata \\(U\\), ovvero se condizioniamo su \\(U\\), possiamo stimare in maniera non distorta la relazione causale tra \\(E\\) e \\(W\\). Tuttavia, ci sono anche casi in cui introdurre la covariata sbagliata pu√≤ introdurre distorsioni nei risultati dell‚Äôanalisi di regressione. Senza una comprensione delle relazioni causali che legano le variabili, non √® possibile determinare quali siano le variabili da inserire o da escludere dal modello di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_causal_inference.html#bloccare-i-percorsi-backdoor",
    "href": "chapters/linear_models/12_causal_inference.html#bloccare-i-percorsi-backdoor",
    "title": "69¬† Inferenza causale",
    "section": "69.3 Bloccare i percorsi backdoor",
    "text": "69.3 Bloccare i percorsi backdoor\nBloccare i percorsi di confondimento tra un predittore \\(X\\) e un risultato \\(Y\\) √® noto come ‚Äúchiudere un percorso backdoor‚Äù. Non vogliamo che nessuna associazione spuria entri attraverso un percorso non causale che coinvolge il predittore \\(X\\). Nell‚Äôesempio sopra, il percorso \\(E \\leftarrow U \\rightarrow W\\) √® un percorso di backdoor, poich√© entra in \\(E\\) con una freccia e collega \\(E\\) a \\(W\\). Questo percorso non √® causale: intervenire su \\(E\\) non provocher√† un cambiamento in \\(W\\) attraverso questo percorso, ma produrr√† comunque un‚Äôassociazione tra \\(E\\) e \\(W\\).\nLa buona notizia √® che, dato un grafo aciclico diretto (DAG) causale, √® sempre possibile determinare quali variabili controllare per chiudere tutti i percorsi di backdoor. √à anche possibile identificare quali variabili non controllare per evitare di creare nuovi confondimenti. Esistono quattro tipi fondamentali di relazioni causali che combinano tutti i possibili percorsi: la biforcazione, la catena, il collider e il discendente. Pertanto, √® necessario comprendere solo questi quattro concetti e come fluisce l‚Äôinformazione in ciascuno di essi.\n\nConfondente: Una variabile \\(U\\) che causa sia il predittore \\(X\\) sia il risultato \\(Y\\). Aggiustare per un confondente (fork) √® necessario per ottenere stime non distorte.\n\nEsempio: \\(X \\leftarrow U \\rightarrow Y\\).\n\nCatena: Una sequenza di variabili in cui una causa l‚Äôaltra, formando un percorso diretto. Non si dovrebbe aggiustare per le variabili lungo questo percorso, poich√© rappresenta il percorso causale.\n\nEsempio: \\(X \\rightarrow Z \\rightarrow Y\\).\n\nCollider: Una variabile che √® causata da due altre variabili. Aggiustare per un collider pu√≤ introdurre confondimento, poich√© si crea un‚Äôassociazione spuria tra i due predittori.\n\nEsempio: \\(X \\rightarrow Z \\leftarrow Y\\).\n\nDiscendente: Una variabile che √® causata sia dal predittore \\(X\\) sia dal risultato \\(Y\\). Condizionare su un discendente pu√≤ introdurre un bias, distorcendo l‚Äôassociazione tra \\(X\\) e \\(Y\\).\n\nEsempio: \\(X \\rightarrow W \\leftarrow Y\\) con \\(W\\) che ha un effetto su \\(Z\\) (discendente).\n\n\nComprendere queste relazioni e sapere come intervenire su di esse √® fondamentale per costruire modelli di regressione che riflettano accuratamente le relazioni causali tra le variabili. Questo approccio permette di isolare gli effetti causali e di evitare le distorsioni introdotte da percorsi di backdoor.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_causal_inference.html#tipi-di-relazioni-elementari-nei-dag",
    "href": "chapters/linear_models/12_causal_inference.html#tipi-di-relazioni-elementari-nei-dag",
    "title": "69¬† Inferenza causale",
    "section": "69.4 Tipi di relazioni elementari nei DAG",
    "text": "69.4 Tipi di relazioni elementari nei DAG\nOgni DAG, per quanto grande e complicato, √® costruito sulle quattro relazioni elementari descritte in precedenza. Esaminiamole in dettaglio.\n\n69.4.1 Confondimento\nLa configurazione detta ‚Äúfork‚Äù rappresenta un classico caso di confondimento. Nel confondimento, una variabile \\(Z\\) √® una causa comune di due variabili \\(X\\) e \\(Y\\), generando una correlazione tra loro: \\(X \\leftarrow Z \\rightarrow Y\\). Se condiamo su \\(Z\\), allora \\(X\\) e \\(Y\\) diventano indipendenti.\n\nfork = Digraph(comment='Forchetta')\nfork.node('X', 'X', shape='plaintext')\nfork.node('Y', 'Y', shape='plaintext')\nfork.node('Z', 'Z', shape='plaintext')\nfork.edge('Z', 'X')\nfork.edge('Z', 'Y')\nfork\n\n\n\n\n\n\n\n\n\n69.4.1.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôistruzione (\\(X\\)) sul salario (\\(Y\\)) con \\(Z\\) che rappresenta lo status socioeconomico.\n\n\n69.4.1.2 Conseguenze del Controllo\n\nControllare \\(Z\\): Blocca il percorso non causale, isolando l‚Äôeffetto diretto di \\(X\\) su \\(Y\\).\nNon controllare \\(Z\\): Introduce confondimento, portando a una stima distorta dell‚Äôeffetto di \\(X\\) su \\(Y\\).\n\n\nn = 1000\nZ = np.random.normal(0, 1, n)\nX = 0.5 * Z + np.random.normal(0, 1, n)\nY = 0.8 * Z + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})\n\n# Modello senza controllo per Z\nmod1 = bmb.Model('Y ~ X', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.02\n0.04\n-0.09\n0.05\n0.0\n0.0\n6310.32\n3060.06\n1.0\n\n\nX\n0.30\n0.03\n0.23\n0.36\n0.0\n0.0\n5784.06\n2927.95\n1.0\n\n\nsigma\n1.23\n0.03\n1.18\n1.28\n0.0\n0.0\n6424.03\n3165.63\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per Z\nmod2 = bmb.Model('Y ~ X + Z', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.03\n0.03\n-0.08\n0.03\n0.0\n0.0\n5749.64\n3042.71\n1.0\n\n\nX\n-0.04\n0.03\n-0.10\n0.02\n0.0\n0.0\n3711.94\n3112.96\n1.0\n\n\nZ\n0.84\n0.04\n0.77\n0.90\n0.0\n0.0\n3850.83\n3388.92\n1.0\n\n\nsigma\n0.99\n0.02\n0.95\n1.03\n0.0\n0.0\n5593.71\n2941.94\n1.0\n\n\n\n\n\n\n\n\n\n\n\n69.4.2 Catena\nIn una catena, una variabile \\(X\\), influenza un mediatore \\(Z\\), che a sua volta influenza l‚Äôesito \\(Y\\): \\(X \\rightarrow Z \\rightarrow Y\\). Condizionare su \\(Z\\) blocca il percorso da \\(X\\) a \\(Y\\).\n\npipe = Digraph(comment='Tubo')\npipe.node('X', 'X', shape='plaintext')\npipe.node('Y', 'Y', shape='plaintext')\npipe.node('Z', 'Z', shape='plaintext')\npipe.edge('X', 'Z')\npipe.edge('Z', 'Y')\npipe\n\n\n\n\n\n\n\n\n\n69.4.2.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôapprendimento (\\(X\\)) sulla comprensione (\\(Y\\)) mediato dalla conoscenza (\\(Z\\)).\n\n\n69.4.2.2 Conseguenze del Controllo\n\nControllare \\(Z\\): Blocca il percorso causale, fornendo solo l‚Äôeffetto diretto di \\(X\\) su \\(Y\\).\nNon controllare \\(Z\\): Misura l‚Äôeffetto totale di \\(X\\) su \\(Y\\).\n\n\nX = np.random.normal(0, 1, n)\nZ = 5 * X + np.random.normal(0, 1, n)\nY = 3 * Z + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'X': X, 'Z': Z, 'Y': Y})\n\n# Modello senza controllo per Z\nmod1 = bmb.Model('Y ~ X', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.04\n0.10\n-0.15\n0.23\n0.0\n0.0\n6356.32\n2949.31\n1.0\n\n\nX\n14.95\n0.10\n14.77\n15.13\n0.0\n0.0\n6321.33\n3376.27\n1.0\n\n\nsigma\n3.20\n0.07\n3.06\n3.33\n0.0\n0.0\n6103.86\n2993.17\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per Z\nmod2 = bmb.Model('Y ~ X + Z', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.04\n0.03\n-0.03\n0.10\n0.0\n0.0\n3132.72\n2315.01\n1.0\n\n\nX\n0.23\n0.16\n-0.09\n0.52\n0.0\n0.0\n1234.56\n1621.51\n1.0\n\n\nZ\n2.95\n0.03\n2.89\n3.01\n0.0\n0.0\n1231.93\n1656.26\n1.0\n\n\nsigma\n1.03\n0.02\n0.99\n1.07\n0.0\n0.0\n2903.70\n2513.20\n1.0\n\n\n\n\n\n\n\n\n\n\n\n69.4.3 Collider\nIn un collider, due variabili \\(X\\) e \\(Y\\) influenzano una terza variabile \\(Z\\): \\(X \\rightarrow Z \\leftarrow Y\\). Condizionare su \\(Z\\) pu√≤ indurre una correlazione spuria tra \\(X\\) e \\(Y\\).\n\ncollider = Digraph(comment='Collider')\ncollider.node('X', 'X', shape='plaintext')\ncollider.node('Y', 'Y', shape='plaintext')\ncollider.node('Z', 'Z', shape='plaintext')\ncollider.edge('X', 'Z')\ncollider.edge('Y', 'Z')\ncollider\n\n\n\n\n\n\n\n\nIl bias di selezione si verifica quando il campione che analizziamo non √® rappresentativo della popolazione a causa del processo di selezione. Questo pu√≤ portare a correlazioni spurie perch√© il processo di selezione pu√≤ favorire involontariamente alcune caratteristiche.\nIl bias del collider (o bias di stratificazione del collider) si verifica quando due variabili, \\(X\\) e \\(Y\\), influenzano una terza variabile \\(Z\\) (il collider). Se ci condiamo su \\(Z\\), possiamo indurre un‚Äôassociazione spuria tra \\(X\\) e \\(Y\\), anche se queste variabili sono scorrelate nella popolazione.\nNell‚Äôesempio tratto da McElreath (2020)`, si suggerisce che sembra che gli studi scientifici pi√π degni di nota siano i meno affidabili. Pi√π √® probabile che uno studio sia interessante, se vero, meno √® probabile che sia vero. Pi√π noioso √® il tema, pi√π rigorosi sono i risultati. Come pu√≤ esistere questa correlazione negativa, ampiamente creduta da molti?\nIn realt√†, tutto ci√≤ che √® necessario affinch√© emerga una tale correlazione negativa √® che ci si preoccupin sia della rilevanza che dell‚Äôaffidabilit√†. Che si tratti di revisione di sovvenzioni o di riviste, se editori e revisori si preoccupano di entrambi gli aspetti, allora l‚Äôatto stesso della selezione √® sufficiente a rendere gli studi pi√π rilevanti i meno affidabili. Infatti, √® difficile immaginare come il processo di peer review possa evitare di creare questa correlazione negativa.\nEcco una semplice simulazione per illustrare il concetto. Supponiamo che un pannello di revisione delle sovvenzioni riceva 200 proposte di ricerca. Tra queste proposte, non vi √® alcuna correlazione tra affidabilit√† (rigore, erudizione, plausibilit√† del successo) e rilevanza (valore per il benessere sociale, interesse pubblico). Il pannello pesa in ugual misura l‚Äôaffidabilit√† e la rilevanza. Successivamente, classificano le proposte in base ai loro punteggi combinati e selezionano il 10% migliore per il finanziamento.\n\n# Numero di proposte da finanziare\nN = 200\n# Proporzione da selezionare\np = 0.1\n# Rilevanza non correlata\nnw = np.random.randn(N)\n# Affidabilit√† non correlata\ntw = np.random.randn(N)\ncorrelation = np.corrcoef(tw, nw)[0, 1]\nprint(correlation)\n\n0.026051430796600182\n\n\nNello script, il processo di selezione basato sul punteggio combinato s induce una correlazione spuria tra nw e tw. Sebbene nw e tw siano non correlati nell‚Äôintero dataset, essi appaiono correlati nel sottoinsieme selezionato.\n\n# Punteggio totale\ns = nw + tw\n# Soglia per il 10% migliore\nq = np.quantile(s, 1 - p)\n# Selezionati\nselected = s &gt;= q\n# Correlazione tra affidabilit√† e rilevanza nei selezionati\ncorrelation = np.corrcoef(tw[selected], nw[selected])[0, 1]\nprint(correlation)\n\n-0.7082917138754293\n\n\nSi noti che:\n\nIl punteggio combinato s agisce come un collider perch√© √® influenzato sia da nw che da tw.\nQuando selezioniamo le proposte basandoci su s (condizioniamo su s), introduciamo involontariamente una correlazione tra nw e tw nel sottoinsieme selezionato.\n\nIn altre parole, condizionando su una variabile (s) che √® influenzata sia da nw che da tw, induciamo una correlazione spuria tra queste due variabili non correlate. Questo √® un esempio specifico di bias del collider, dove il processo di selezione agisce come il collider.\nPer riassumere:\n\nBias di selezione: in questo esempio si verifica perch√© analizziamo solo il 10% delle proposte migliori.\nBias del collider: √® introdotto perch√© la variabile di selezione s (punteggio totale) √® influenzata sia da nw che da tw, portando a una correlazione spuria quando condiamo su s.\n\nQuindi, la correlazione spuria osservata nel sottoinsieme selezionato √® il risultato del bias del collider introdotto dal processo di selezione basato sul punteggio combinato.\nPerch√© la correlazione √® negativa nel sottoinsieme di dati selezionato? Perch√©, ad esempio, se una proposta selezionata ha una bassa affidabilit√† (tw), deve avere un‚Äôalta rilevanza (nw). Altrimenti, non sarebbe stata finanziata. Lo stesso vale al contrario: se una proposta ha una bassa rilevanza (nw), possiamo dedurre che deve avere un‚Äôaffidabilit√† superiore alla media. Altrimenti, non sarebbe stata selezionata per il finanziamento. Questo √® il concetto chiave da comprendere: quando condiamo su un collider, si creano associazioni statistiche, ma non necessariamente causali, tra le sue cause.\n\n\n69.4.4 Discendente\nUn discendente √® una variabile influenzata da un‚Äôaltra variabile. Condizionare su un discendente significa parzialmente condizionare sul suo genitore. Nel DAG seguente, condizionare su \\(D\\) condizioner√† anche, in una certa misura, su \\(Z\\).\n\ndescendant = Digraph(comment='Discendente')\ndescendant.node('X', 'X', shape='plaintext')\ndescendant.node('Y', 'Y', shape='plaintext')\ndescendant.node('Z', 'Z', shape='plaintext')\ndescendant.node('D', 'D', shape='plaintext')\ndescendant.edge('X', 'Z')\ndescendant.edge('Y', 'Z')\ndescendant.edge('Z', 'D')\ndescendant\n\n\n\n\n\n\n\n\nQuesto perch√© \\(D\\) contiene informazioni su \\(Z\\), che a sua volta √® un collider tra \\(X\\) e \\(Y\\). Condizionare su \\(D\\) pu√≤ aprire parzialmente il percorso da \\(X\\) a \\(Y\\) attraverso \\(Z\\), creando un‚Äôassociazione spuria tra \\(X\\) e \\(Y\\). Tuttavia, l‚Äôeffetto di condizionare su un discendente dipende dalla relazione tra il discendente e il suo genitore. I discendenti sono comuni nei modelli causali perch√© spesso non possiamo misurare una variabile direttamente e dobbiamo utilizzare un proxy per essa.\n\n69.4.4.1 Esempio\nConsideriamo l‚Äôeffetto dell‚Äôintelligenza (\\(X\\)) sul punteggio del test (\\(Y\\)) tramite il tempo di apprendimento (\\(Z\\)) e il punteggio in una simulazione (\\(D\\)).\n\n\n69.4.4.2 Conseguenze del Controllo\n\nControllare \\(D\\): Pu√≤ introdurre bias, creando un percorso non causale da \\(X\\) a \\(Y\\) attraverso \\(Z\\).\nNon controllare \\(D\\): Mantiene il percorso causale corretto da \\(X\\) a \\(Y\\).\n\n\nI = np.random.normal(100, 15, n)\nT = 200 - I + np.random.normal(0, 1, n)\nS = 0.5 * I + 0.1 * T + np.random.normal(0, 1, n)\nD = 0.7 * S + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'I': I, 'T': T, 'S': S, 'D': D})\n\n# Modello senza controllo per D\nmod1 = bmb.Model('S ~ T', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n99.39\n0.24\n98.92\n99.82\n0.0\n0.0\n5831.85\n3060.37\n1.0\n\n\nT\n-0.39\n0.00\n-0.40\n-0.39\n0.0\n0.0\n5879.01\n3269.97\n1.0\n\n\nsigma\n1.10\n0.02\n1.05\n1.14\n0.0\n0.0\n6041.49\n3081.54\n1.0\n\n\n\n\n\n\n\n\n\n# Modello con controllo per D\nmod2 = bmb.Model('S ~ T + D', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nD\n0.50\n0.02\n0.45\n0.54\n0.00\n0.00\n2526.07\n2095.97\n1.0\n\n\nIntercept\n64.78\n1.58\n61.69\n67.64\n0.03\n0.02\n2486.35\n2167.12\n1.0\n\n\nT\n-0.26\n0.01\n-0.27\n-0.24\n0.00\n0.00\n2490.85\n2271.87\n1.0\n\n\nsigma\n0.90\n0.02\n0.86\n0.94\n0.00\n0.00\n3237.43\n2629.65\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_causal_inference.html#come-aprire-o-chiudere-un-percorso-nei-dag",
    "href": "chapters/linear_models/12_causal_inference.html#come-aprire-o-chiudere-un-percorso-nei-dag",
    "title": "69¬† Inferenza causale",
    "section": "69.5 Come aprire o chiudere un percorso nei DAG",
    "text": "69.5 Come aprire o chiudere un percorso nei DAG\nPer determinare quali variabili includere o escludere nel modello di regressione, √® necessario seguire questa procedura:\n\nElencare tutti i percorsi che collegano \\(X\\) (la potenziale causa di interesse) e \\(Y\\) (il risultato).\nClassificare ciascun percorso come aperto o chiuso. Un percorso √® aperto a meno che non contenga un collider.\nIdentificare i percorsi di backdoor. Un percorso di backdoor ha una freccia che entra in \\(X\\).\nChiudere i percorsi di backdoor aperti: Se ci sono percorsi di backdoor aperti, decidere su quali variabili condizionare per chiuderli, se possibile.\n\nCondizionare su una variabile significa includerla nel modello di regressione. Per chiudere un percorso di backdoor, identifichiamo la variabile di confondimento che crea l‚Äôassociazione spuria e la includiamo nel modello. Questo bloccher√† il percorso, impedendo che l‚Äôassociazione spuria influenzi il risultato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_causal_inference.html#riflessioni-conclusive",
    "href": "chapters/linear_models/12_causal_inference.html#riflessioni-conclusive",
    "title": "69¬† Inferenza causale",
    "section": "69.6 Riflessioni conclusive",
    "text": "69.6 Riflessioni conclusive\nIn conclusione, le osservazioni precedenti dimostrano che l‚Äôinferenza causale non pu√≤ essere affrontata semplicemente applicando meccanicamente il modello statistico della regressione lineare. Senza ulteriori conoscenze, che non possono essere derivate esclusivamente dai dati osservati, non √® possibile ottenere stime non distorte degli effetti causali. L‚Äôinferenza causale va oltre le tecniche statistiche: essa richiede informazioni supplementari sulle caratteristiche del fenomeno studiato.\nPer trarre conclusioni corrette sui meccanismi causali, √® essenziale disporre di informazioni dettagliate sul processo generativo dei dati. Bench√© spesso queste informazioni non siano direttamente disponibili, i ricercatori possono adottare strategie per minimizzare il rischio di errori interpretativi. Un passo fondamentale consiste nell‚Äôidentificare ipotetici meccanismi causali prima di procedere con le stime degli effetti, utilizzando diagrammi causali come i grafici aciclici diretti per mappare le relazioni tra le variabili. Questo processo aiuta a determinare quali fattori includere nell‚Äôanalisi, seguendo il ‚Äúbackdoor criterion‚Äù proposto da Judea Pearl, per chiudere i percorsi indiretti tra esposizione ed esito che potrebbero introdurre confondimenti.\nIn assenza di una comprensione del fenomeno in esame, √® cruciale che i ricercatori prestino attenzione all‚Äôordine temporale dei fattori. Questo approccio, fondamentale per l‚Äôinferenza causale, implica che l‚Äôesposizione avvenga prima dell‚Äôesito per stabilire una relazione causale plausibile. Inoltre, √® importante che tutte le covariate considerate nell‚Äôanalisi precedano temporalmente l‚Äôesposizione per evitare potenziali bias di specificazione, specialmente nei contesti di collider e mediazione. Seguendo questi principi, i ricercatori possono ridurre il rischio di stime errate degli effetti causali.\n\n\n\n\n\n\n\nTermine Tecnico\nSpiegazione\n\n\n\n\n(1) Collider\nLa variabile \\(X\\), causa \\(Z\\), e l‚Äôesito, \\(Y\\), causa \\(Z\\). Aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene un risultato distorto. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Y = X + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\); \\(Z = 0.45X + 0.77Y + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\)\n\n\n(2) Confounder\nLa variabile \\(Z\\) causa sia la variabile indipendente \\(X\\), sia l‚Äôesito, \\(Y\\). Non aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene un risultato distorto. Meccanismo di generazione dei dati: \\(Z \\sim \\mathcal{N}(0,1)\\), \\(X = Z + \\varepsilon_x\\), \\(\\varepsilon_x \\sim \\mathcal{N}(0,1)\\); \\(Y = 0.5X + Z + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\)\n\n\n(3) Mediator\nLa variabile \\(X\\) causa \\(Z\\) che a sua volta causa l‚Äôesito \\(Y\\). Aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene l‚Äôeffetto diretto, non aggiustando per \\(Z\\) si ottiene l‚Äôeffetto totale di \\(X\\) su \\(Y\\). L‚Äôeffetto diretto rappresenta la relazione tra \\(X\\) e \\(Y\\) indipendentemente da qualsiasi mediatore, mentre l‚Äôeffetto totale include sia l‚Äôeffetto diretto sia qualsiasi effetto indiretto mediato dal mediatore potenziale. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Z = X + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\); \\(Y = Z + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\)\n\n\n(4) Discendente\nLa variabile \\(X\\) e l‚Äôesito \\(Y\\) hanno una variabile discendente comune \\(Z\\). Non aggiustando per \\(Z\\) quando si stima l‚Äôeffetto di \\(X\\) su \\(Y\\) si ottiene una stima non distorta. Tuttavia, aggiustando per \\(Z\\), si introduce un bias. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Y = X + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\); \\(Z = 0.5X + 0.5Y + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_causal_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/12_causal_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "69¬† Inferenza causale",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnetworkx   : 3.3\npandas     : 2.2.2\nbambi      : 0.14.0\nseaborn    : 0.13.2\ngraphviz   : 0.20.3\nnumpy      : 1.26.4\narviz      : 0.18.0\nmatplotlib : 3.9.1\nstatsmodels: 0.14.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>69</span>¬† <span class='chapter-title'>Inferenza causale</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html",
    "href": "chapters/linear_models/13_ate_att_atu.html",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "",
    "text": "70.1 Introduzione\nGli studi osservazionali svolgono un ruolo cruciale nella ricerca empirica, specialmente quando non √® possibile o etico condurre esperimenti randomizzati. Tuttavia, questi studi pongono notevoli sfide per l‚Äôinferenza causale, principalmente a causa del problema del confondimento. In questo capitolo, esploreremo la stima dell‚Äôeffetto del trattamento in contesti osservazionali, dove il confondimento si manifesta quando variabili non controllate influenzano sia la probabilit√† di ricevere il trattamento sia l‚Äôoutcome di interesse.\nPer comprendere meglio come il confondimento possa distorcere le stime degli effetti causali, √® utile esaminare come l‚Äôeffetto di un trattamento (o intervento) possa variare all‚Äôinterno di diverse popolazioni o gruppi. Tre concetti chiave in questo ambito sono l‚ÄôEffetto Medio del Trattamento (Average Treatment Effect, ATE), l‚ÄôEffetto Medio del Trattamento sui Trattati (Average Treatment Effect on the Treated, ATT), e l‚ÄôEffetto Medio del Trattamento sui Non Trattati (Average Treatment Effect on the Untreated, ATU). Questi concetti sono fondamentali per comprendere come un intervento possa influenzare non solo l‚Äôintera popolazione, ma anche specifici sottogruppi al suo interno.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#effetto-medio-del-trattamento-ate",
    "href": "chapters/linear_models/13_ate_att_atu.html#effetto-medio-del-trattamento-ate",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.2 Effetto Medio del Trattamento (ATE)",
    "text": "70.2 Effetto Medio del Trattamento (ATE)\nL‚ÄôATE rappresenta l‚Äôeffetto medio che un trattamento ha su tutta la popolazione, indipendentemente dal fatto che gli individui abbiano effettivamente ricevuto il trattamento o meno. Formalmente, l‚ÄôATE √® definito come la differenza media tra l‚Äôoutcome che si otterrebbe se tutti fossero trattati e l‚Äôoutcome che si otterrebbe se nessuno fosse trattato:\n\\[\n\\text{ATE} = E[Y^1 - Y^0]\n\\]\nDove \\(Y^1\\) rappresenta l‚Äôoutcome se un individuo riceve il trattamento e \\(Y^0\\) rappresenta l‚Äôoutcome se non lo riceve. L‚ÄôATE √® utile per politiche che interessano l‚Äôintera popolazione, come un programma sanitario nazionale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#effetto-medio-del-trattamento-sui-trattati-att",
    "href": "chapters/linear_models/13_ate_att_atu.html#effetto-medio-del-trattamento-sui-trattati-att",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.3 Effetto Medio del Trattamento sui Trattati (ATT)",
    "text": "70.3 Effetto Medio del Trattamento sui Trattati (ATT)\nL‚ÄôATT misura l‚Äôeffetto medio del trattamento solo per gli individui che hanno effettivamente ricevuto il trattamento. Questo concetto √® particolarmente utile quando si vuole capire l‚Äôimpatto del trattamento su coloro che lo hanno scelto o lo hanno ricevuto, ad esempio in uno studio osservazionale dove non tutti gli individui sono trattati:\n\\[\n\\text{ATT} = E[Y^1 - Y^0 \\mid X = 1]\n\\]\nDove \\(X = 1\\) indica che l‚Äôindividuo ha ricevuto il trattamento. L‚ÄôATT √® rilevante per valutare l‚Äôefficacia di un intervento sui partecipanti effettivi, come l‚Äôeffetto di un programma di formazione sui partecipanti iscritti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#effetto-medio-del-trattamento-sui-non-trattati-atu",
    "href": "chapters/linear_models/13_ate_att_atu.html#effetto-medio-del-trattamento-sui-non-trattati-atu",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.4 Effetto Medio del Trattamento sui Non Trattati (ATU)",
    "text": "70.4 Effetto Medio del Trattamento sui Non Trattati (ATU)\nL‚ÄôATU misura l‚Äôeffetto medio che il trattamento avrebbe avuto sugli individui che non hanno ricevuto il trattamento. √à particolarmente utile per prevedere cosa accadrebbe se il trattamento fosse esteso a una popolazione che attualmente non lo riceve:\n\\[\n\\text{ATU} = E[Y^1 - Y^0 \\mid X = 0]\n\\]\nDove \\(X = 0\\) indica che l‚Äôindividuo non ha ricevuto il trattamento. L‚ÄôATU √® utile per valutare l‚Äôeffetto potenziale dell‚Äôestensione di un trattamento a una popolazione che non √® stata precedentemente trattata.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#dati-ipotetici",
    "href": "chapters/linear_models/13_ate_att_atu.html#dati-ipotetici",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.5 Dati Ipotetici",
    "text": "70.5 Dati Ipotetici\nEcco una tabella di esempio che mostra i potenziali outcomes e gli effetti causali individuali (ICE) per un gruppo di individui:\n\n\n\n\n\n\n\n\n\n\n\n\nID\nEt√†\nTrattato\nOutcome con Trattamento (Y^1)\nOutcome senza Trattamento (Y^0)\nEffetto Causale Individuale (ICE, Œ¥)\nOutcome Osservato (Y)\n\n\n\n\n1\nAnziano\n1\n80\n60\n20\n80\n\n\n2\nAnziano\n1\n75\n70\n5\n75\n\n\n3\nAnziano\n1\n85\n80\n5\n85\n\n\n4\nAnziano\n0\n70\n60\n10\n60\n\n\n5\nGiovane\n1\n75\n70\n5\n75\n\n\n6\nGiovane\n0\n80\n80\n0\n80\n\n\n7\nGiovane\n0\n90\n100\n-10\n100\n\n\n8\nGiovane\n0\n85\n80\n5\n80",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#calcolo-di-ate-att-e-atu",
    "href": "chapters/linear_models/13_ate_att_atu.html#calcolo-di-ate-att-e-atu",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.6 Calcolo di ATE, ATT e ATU",
    "text": "70.6 Calcolo di ATE, ATT e ATU\nPossiamo calcolare i tre stimatori come segue:\n\nATE: Media degli effetti causali individuali per tutti gli individui.\nATT: Media degli effetti causali individuali solo per i trattati.\nATU: Media degli effetti causali individuali solo per i non trattati.\n\nUsando il seguente codice Python, possiamo calcolare questi valori dai dati della tabella.\n\nimport pandas as pd\n\n# Creazione del dataframe\ndata = {\n    \"ID\": [1, 2, 3, 4, 5, 6, 7, 8],\n    \"Et√†\": [\n        \"Anziano\",\n        \"Anziano\",\n        \"Anziano\",\n        \"Anziano\",\n        \"Giovane\",\n        \"Giovane\",\n        \"Giovane\",\n        \"Giovane\",\n    ],\n    \"Trattato\": [1, 1, 1, 0, 1, 0, 0, 0],\n    \"Y1\": [80, 75, 85, 70, 75, 80, 90, 85],\n    \"Y0\": [60, 70, 80, 60, 70, 80, 100, 80],\n}\n\ndf = pd.DataFrame(data)\ndf[\"ICE\"] = df[\"Y1\"] - df[\"Y0\"]\n\n# Calcolo di ATE, ATT, ATU\nATE = df[\"ICE\"].mean()\nATT = df[df[\"Trattato\"] == 1][\"ICE\"].mean()\nATU = df[df[\"Trattato\"] == 0][\"ICE\"].mean()\n\nATE, ATT, ATU\n\n(5.0, 8.75, 1.25)\n\n\nEseguendo il codice Python sopra, otteniamo:\n\nATE: 5\nATT: 8.75\nATU: 1.25\n\nQuesti valori illustrano come l‚Äôeffetto del trattamento vari a seconda del gruppo di interesse e offrono una comprensione pi√π granulare dell‚Äôimpatto di un intervento.\n\n70.6.1 La Differenza tra Dati Teorici ed Empirici nell‚ÄôInferenza Causale\nI dati presentati nella tabella precedente rappresentano una situazione solo teorica, in cui possiamo osservare direttamente l‚Äôeffetto che il trattamento avrebbe su ciascun individuo. Questo effetto √® noto come Effetto Causale Individuale (Individual Causal Effect, ICE). In un tale mondo ipotetico, possiamo confrontare per ogni individuo l‚Äôoutcome con e senza trattamento, calcolando esattamente quanto il trattamento abbia influenzato l‚Äôoutcome di quell‚Äôindividuo. Questo ci permette di calcolare l‚ÄôATE (Effetto Medio del Trattamento), l‚ÄôATT (Effetto Medio del Trattamento sui Trattati) e l‚ÄôATU (Effetto Medio del Trattamento sui Non Trattati) in modo preciso.\n\n\n70.6.2 La Natura Impossibile dei Dati Teorici\nTuttavia, questa situazione ideale √® impossibile da realizzarsi empiricamente. Non possiamo osservare contemporaneamente l‚Äôoutcome per un individuo sia con che senza trattamento. Questo perch√©, nella realt√†, un individuo pu√≤ trovarsi in una sola delle due condizioni: o riceve il trattamento o non lo riceve. Non possiamo tornare indietro nel tempo per osservare cosa sarebbe successo se un individuo che ha ricevuto il trattamento non l‚Äôavesse ricevuto, o viceversa. Questa impossibilit√† √® alla base di ci√≤ che viene chiamato il problema fondamentale dell‚Äôinferenza causale.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#dati-empirici-e-il-problema-della-confondimento",
    "href": "chapters/linear_models/13_ate_att_atu.html#dati-empirici-e-il-problema-della-confondimento",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.7 Dati Empirici e il Problema della Confondimento",
    "text": "70.7 Dati Empirici e il Problema della Confondimento\nIn un contesto empirico, i dati non sono costituiti da osservazioni teoriche come quelle della tabella precedente, ma piuttosto da due gruppi di individui: quelli che hanno ricevuto il trattamento e quelli che non l‚Äôhanno ricevuto. Non abbiamo accesso agli ICE per ciascun individuo; possiamo solo osservare i risultati degli individui che hanno ricevuto il trattamento e di quelli che non lo hanno ricevuto.\nUn esempio di questi dati empirici √® mostrato nella seguente tabella, dove vediamo solo il risultato osservato per ogni individuo e il fatto che essi abbiano o meno ricevuto il trattamento. Questo tipo di dati √® comune negli studi osservazionali, dove il trattamento non √® assegnato casualmente, ma piuttosto gli individui scelgono se partecipare o meno al trattamento, o sono selezionati per esso in base a determinati criteri.\n\n\n\nID\nEt√†\nTrattato\nOutcome Osservato (Y)\n\n\n\n\n1\nAnziano\n1\n80\n\n\n2\nAnziano\n1\n75\n\n\n3\nAnziano\n1\n85\n\n\n4\nAnziano\n0\n60\n\n\n5\nGiovane\n1\n75\n\n\n6\nGiovane\n0\n80\n\n\n7\nGiovane\n0\n100\n\n\n8\nGiovane\n0\n80\n\n\n\nIn questa tabella, l‚ÄôID identifica l‚Äôindividuo, Et√† indica la fascia d‚Äôet√† dell‚Äôindividuo (Anziano o Giovane), Trattato √® una variabile binaria che indica se l‚Äôindividuo ha ricevuto il trattamento (1 = s√¨, 0 = no), e Outcome Osservato (Y) √® il risultato osservato per ciascun individuo. Questa tabella riflette ci√≤ che sarebbe tipicamente disponibile in uno studio empirico, dove non possiamo osservare simultaneamente gli outcome con e senza trattamento per lo stesso individuo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#il-problema-della-non-equivalenza-dei-gruppi",
    "href": "chapters/linear_models/13_ate_att_atu.html#il-problema-della-non-equivalenza-dei-gruppi",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.8 Il Problema della Non Equivalenza dei Gruppi",
    "text": "70.8 Il Problema della Non Equivalenza dei Gruppi\nUno dei problemi principali negli studi osservazionali √® che i due gruppi‚Äîquelli che ricevono il trattamento e quelli che non lo ricevono‚Äînon sono equivalenti. Questa non equivalenza √® dovuta alla presenza di variabili di confondimento: fattori che influenzano sia la probabilit√† di ricevere il trattamento sia l‚Äôoutcome di interesse. Ad esempio, in uno studio che esamina l‚Äôeffetto di un programma di formazione sul reddito, l‚Äôet√† e il livello di istruzione potrebbero essere variabili di confondimento, poich√© influenzano sia la probabilit√† di partecipare al programma sia il reddito.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#limpossibilit√†-di-calcolare-diretamente-late",
    "href": "chapters/linear_models/13_ate_att_atu.html#limpossibilit√†-di-calcolare-diretamente-late",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.9 L‚ÄôImpossibilit√† di Calcolare Diretamente l‚ÄôATE",
    "text": "70.9 L‚ÄôImpossibilit√† di Calcolare Diretamente l‚ÄôATE\nA causa della presenza di queste variabili di confondimento, non possiamo semplicemente calcolare l‚ÄôATE come la differenza tra le medie dei due gruppi (trattati e non trattati). Se facessimo cos√¨, rischieremmo di ignorare l‚Äôinfluenza delle variabili di confondimento, ottenendo una stima distorta dell‚Äôeffetto del trattamento. Ad esempio, se il gruppo trattato √® composto da individui pi√π giovani e istruiti rispetto al gruppo non trattato, la differenza osservata nei risultati potrebbe essere dovuta in parte a queste caratteristiche, piuttosto che all‚Äôeffetto del trattamento stesso.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#strategie-per-superare-il-problema-del-confondimento",
    "href": "chapters/linear_models/13_ate_att_atu.html#strategie-per-superare-il-problema-del-confondimento",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.10 Strategie per Superare il Problema del Confondimento",
    "text": "70.10 Strategie per Superare il Problema del Confondimento\nPer stimare correttamente l‚ÄôEffetto Medio del Trattamento (ATE) o altri effetti del trattamento in studi osservazionali, √® fondamentale affrontare il problema del confondimento. Il confondimento si verifica quando una variabile non osservata o non controllata influenza sia la probabilit√† di ricevere il trattamento sia l‚Äôoutcome di interesse, rendendo difficile isolare l‚Äôeffetto puro del trattamento. Esistono diverse tecniche statistiche sviluppate per tenere conto delle variabili di confondimento, ognuna delle quali offre un approccio diverso per correggere le distorsioni che il confondimento pu√≤ introdurre.\n\n70.10.1 Matching\nIl matching √® una tecnica che mira a creare coppie o gruppi di individui trattati e non trattati che siano simili rispetto alle variabili di confondimento. L‚Äôidea alla base del matching √® che, confrontando individui che sono simili in tutte le caratteristiche rilevanti tranne che per il trattamento ricevuto, si possa isolare l‚Äôeffetto del trattamento stesso. Esistono diversi tipi di matching, tra cui:\n\nMatching 1:1: Ogni individuo trattato viene abbinato a un individuo non trattato che ha caratteristiche simili.\nMatching caliper: Gli individui sono abbinati solo se la distanza tra le loro variabili di confondimento √® inferiore a una certa soglia.\nPropensity Score Matching (PSM): Si calcola un punteggio di propensione (la probabilit√† di ricevere il trattamento data una serie di covariate) e si abbinano individui trattati e non trattati con punteggi di propensione simili.\n\nIl matching riduce il bias di confondimento, ma richiede un campione abbastanza grande per trovare corrispondenze adeguate e pu√≤ non eliminare completamente il confondimento, specialmente se alcune variabili importanti non sono osservate o misurate.\n\n\n70.10.2 Ponderazione Inversa della Probabilit√† (IPW)\nLa ponderazione inversa della probabilit√† (Inverse Probability Weighting, IPW) √® un‚Äôaltra tecnica per affrontare il confondimento, basata sull‚Äôassegnazione di pesi agli individui in base alla loro probabilit√† stimata di ricevere il trattamento. L‚ÄôIPW utilizza modelli statistici per calcolare la probabilit√† (o punteggio di propensione) che un individuo riceva il trattamento dato un insieme di variabili di confondimento.\n\nGli individui trattati che avevano una bassa probabilit√† di ricevere il trattamento ricevono un peso maggiore.\nGli individui non trattati che avevano una bassa probabilit√† di non ricevere il trattamento ricevono un peso maggiore.\n\nQuesto metodo bilancia le distribuzioni delle variabili di confondimento tra i gruppi trattati e non trattati, in modo che i gruppi possano essere confrontati in modo pi√π equo, come se fossero stati creati attraverso una randomizzazione.\nTuttavia, l‚ÄôIPW richiede un modello accurato per stimare i punteggi di propensione e pu√≤ essere sensibile ai pesi estremi, che possono amplificare le variazioni e introdurre instabilit√† nelle stime.\n\n\n70.10.3 Stratificazione\nLa stratificazione implica la divisione della popolazione in sottogruppi (o strati) omogenei rispetto a una o pi√π variabili di confondimento. Una volta creati questi strati, si pu√≤ calcolare l‚Äôeffetto del trattamento all‚Äôinterno di ciascun sottogruppo, riducendo il confondimento all‚Äôinterno degli strati.\n\nAd esempio, si potrebbe stratificare la popolazione per et√†, dividendo gli individui in fasce d‚Äôet√†, e poi calcolare l‚Äôeffetto del trattamento all‚Äôinterno di ciascuna fascia.\n\nLa stratificazione permette di controllare il confondimento senza la necessit√† di abbinare direttamente individui trattati e non trattati o di assegnare pesi. Tuttavia, la stratificazione pu√≤ diventare complessa se ci sono molte variabili di confondimento, e il numero di individui in ciascun strato potrebbe diventare troppo piccolo per produrre stime affidabili.\n\n\n70.10.4 Altre Tecniche\nOltre a queste tecniche, esistono anche altre metodologie avanzate per affrontare il confondimento negli studi osservazionali:\n\nRegressione con covariate: L‚Äôinclusione delle variabili di confondimento come covariate in un modello di regressione permette di stimare l‚Äôeffetto del trattamento al netto del confondimento.\nAnalisi delle variabili strumentali: Si utilizza una variabile strumentale che √® correlata con il trattamento ma non con l‚Äôoutcome, tranne che attraverso il trattamento, per isolare l‚Äôeffetto causale.\nPropensity Score Weighting: Una combinazione di matching e ponderazione basata sui punteggi di propensione per ottenere una distribuzione bilanciata delle covariate nei gruppi trattati e non trattati.\n\nQueste tecniche, se applicate correttamente, permettono di isolare l‚Äôeffetto causale del trattamento riducendo l‚Äôinfluenza delle variabili di confondimento. Tuttavia, √® importante scegliere la tecnica appropriata in base alla natura dei dati e alle ipotesi sottostanti, nonch√© considerare la possibilit√† che il confondimento residuo possa ancora influenzare le stime. In ogni caso, queste metodologie avanzate migliorano significativamente la nostra capacit√† di fare inferenze causali accurate in studi osservazionali, avvicinandoci a stime pi√π precise dell‚ÄôATE, ATT e ATU.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/13_ate_att_atu.html#conclusione",
    "href": "chapters/linear_models/13_ate_att_atu.html#conclusione",
    "title": "70¬† Concetti di ATE, ATT e ATU",
    "section": "70.11 Conclusione",
    "text": "70.11 Conclusione\nIn sintesi, mentre i dati teorici ci permettono di calcolare con precisione gli effetti causali individuali, i dati empirici raccolti in studi osservazionali presentano sfide significative a causa della non equivalenza dei gruppi e della presenza di variabili di confondimento. Per affrontare queste sfide, √® essenziale utilizzare metodi statistici avanzati che permettano di stimare correttamente gli effetti del trattamento, evitando di commettere errori di interpretazione che potrebbero derivare da stime non corrette.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>¬† <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_missing.html",
    "href": "chapters/linear_models/14_missing.html",
    "title": "71¬† Dati mancanti",
    "section": "",
    "text": "Introduzione\nNel campo della data science, la gestione dei dati mancanti rappresenta una sfida cruciale e una competenza fondamentale per gli analisti e i ricercatori. I dati mancanti non sono solo una comune occorrenza nei dataset reali, ma possono anche avere un impatto significativo sulla qualit√† delle analisi, sulle inferenze tratte e sulle decisioni basate su tali dati. L‚Äôimportanza di affrontare correttamente i dati mancanti risiede nella necessit√† di mantenere l‚Äôintegrit√† delle analisi statistiche e di evitare conclusioni errate o distorte. Una gestione appropriata dei dati mancanti permette di migliorare l‚Äôaccuratezza dei modelli predittivi, di aumentare la robustezza delle analisi e di garantire che le decisioni basate sui dati siano informate e affidabili. Pertanto, comprendere le cause dei dati mancanti, conoscere le diverse tipologie di assenza dei dati, come classificato nella tassonomia di Rubin, e applicare le tecniche di trattamento pi√π adeguate sono competenze essenziali nella data science per massimizzare il valore estratto dai dati disponibili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_missing.html#la-tassonomia-di-rubin",
    "href": "chapters/linear_models/14_missing.html#la-tassonomia-di-rubin",
    "title": "71¬† Dati mancanti",
    "section": "71.1 La tassonomia di Rubin",
    "text": "71.1 La tassonomia di Rubin\nLa tassonomia dei dati mancanti di Rubin introduce una classificazione che aiuta a comprendere e gestire le situazioni in cui i dati non sono completamente disponibili. Questa classificazione √® particolarmente rilevante in ambiti come la statistica, la ricerca scientifica e l‚Äôanalisi dei dati, dove la presenza di dati mancanti pu√≤ influenzare significativamente i risultati degli studi. La tassonomia identifica tre categorie principali: Dati Mancanti Completamente a Caso (MCAR), Dati Mancanti a Caso (MAR) e Dati Mancanti Non a Caso (MNAR). Ognuna di queste categorie si basa su specifiche assunzioni relative alla probabilit√† condizionata che un dato sia mancante. Vediamo nel dettaglio:\n\nDati Mancanti Completamente a Caso (MCAR): Questa categoria rappresenta la situazione meno problematica tra le tre. L‚Äôassunzione MCAR suggerisce che la mancanza di dati avviene in modo completamente casuale, senza alcuna relazione sia con i dati osservati che con quelli non osservati. La mancanza √® attribuibile a circostanze casuali e non legate alle caratteristiche dei dati stessi. In pratica, questo significa che la probabilit√† che un dato sia mancante √® la stessa per tutte le osservazioni. Quando i dati sono MCAR, le tecniche di analisi possono procedere senza introdurre distorsioni significative nei risultati.\nDati Mancanti a Caso (MAR): In questa categoria, la probabilit√† che un dato sia mancante pu√≤ dipendere dai dati osservati, ma non da quelli non osservati. Questo tipo di mancanza viene considerato ‚Äúignorabile‚Äù perch√©, conoscendo i dati osservati, √® possibile procedere con l‚Äôanalisi senza compromettere l‚Äôaffidabilit√† delle inferenze, sebbene possa esserci una perdita di precisione. Questa situazione si verifica quando la ragione della mancanza di dati √® correlata a qualche caratteristica osservabile nel dataset, permettendo di gestire la mancanza attraverso l‚Äôanalisi dei dati disponibili.\nDati Mancanti Non a Caso (MNAR): Questa √® la situazione pi√π complessa e potenzialmente problematica. I dati sono considerati MNAR quando la probabilit√† che un dato sia mancante dipende dalle informazioni non osservate. Ci√≤ significa che la mancanza di dati √® correlata a valori che non sono noti o osservabili, rendendo pi√π difficile l‚Äôimputazione e l‚Äôanalisi. Le tecniche standard di gestione dei dati mancanti potrebbero introdurre distorsioni significative nei risultati a causa del rischio di confondimento. La gestione dei dati MNAR richiede metodi avanzati e cautela nell‚Äôinterpretazione dei risultati.\n\nLe assunzioni su cui si basa questa tassonomia sono fondamentali per scegliere il metodo di trattamento dei dati mancanti pi√π appropriato. Tuttavia, √® importante notare che queste assunzioni sono intrinsecamente non verificabili. L‚Äôanalisi e le conclusioni di uno studio dipenderanno dalla plausibilit√† di queste assunzioni nel contesto specifico in cui vengono applicate. La scelta di come trattare i dati mancanti dovrebbe quindi essere attentamente considerata e giustificata nel contesto della ricerca.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_missing.html#un-esempio-empirico",
    "href": "chapters/linear_models/14_missing.html#un-esempio-empirico",
    "title": "71¬† Dati mancanti",
    "section": "71.2 Un Esempio Empirico",
    "text": "71.2 Un Esempio Empirico\nL‚Äôanalisi e il trattamento dei dati mancanti rivestono un ruolo cruciale nell‚Äôinterpretazione dei risultati di uno studio. Esaminiamo i diversi scenari di dati mancanti che hai delineato, prendendo spunto dall‚Äôesempio metaforico del ‚Äúcane che mangia i compiti‚Äù, presentato nel tutorial di Dustin Stansbury.\n\n71.2.1 1. Perdita di Dati Casuale e Indipendente dalle Cause\n\nEsempio: Il fenomeno del ‚Äúcane che mangia i compiti‚Äù avviene in maniera casuale.\nConseguenze: In questa situazione, la perdita di dati √® classificata come ‚ÄúMissing Completely At Random‚Äù (MCAR), ovvero l‚Äôassenza di dati non √® in alcun modo correlata n√© alle variabili osservate n√© a quelle non osservate.\nGestione: √à possibile eliminare i casi con dati mancanti senza introdurre distorsioni, bench√© ci√≤ possa ridurre l‚Äôefficienza dello studio a causa della diminuzione della dimensione del campione.\n\n\n# Helper function to plot regression line\ndef plot_regression_line(x, y, color, label, **plot_kwargs):\n    valid_idx = ~np.isnan(y)\n    \n    X = np.vstack((np.ones_like(x[valid_idx]), x[valid_idx])).T\n    intercept, slope = np.linalg.lstsq(X, y[valid_idx], rcond=None)[0]\n    \n    xs = np.linspace(x.min(), x.max(), 10)\n    ys = xs * slope + intercept\n    plt.plot(xs, ys, color=color, label=label, **plot_kwargs)\n\n# Function to plot dog homework data\ndef plot_dog_homework(S, H, Hstar, title=None):\n    \n    # Plot S vs H\n    plt.scatter(S, H, color='k', alpha=1, label='total', s=10)\n    plot_regression_line(S, H, label='total trend', color='k', alpha=.5)\n    \n    # Plot S vs Hstar\n    plt.scatter(S, Hstar, color='C0', alpha=.8, label='incomplete')\n    plot_regression_line(S, Hstar, label='incomplete trend', color='C0', alpha=.5)\n    \n    # Set labels and title\n    plt.xlabel(\"S\")\n    plt.ylabel(\"H\")\n    if title is not None:\n        plt.title(title)\n    plt.legend()\n\n    plt.show()  # Display the plot\n\n\nnp.random.seed(123)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Homework score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats 50% of of homework _at random_\nD = stats.bernoulli(0.5).rvs(size=n_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Random missing data\\ncauses loss of precision; little/no bias\")\n\n\n\n\n\n\n\n\nIn scenari di dati mancanti completamente a caso, si verifica una perdita di precisione, ma, mediamente, l‚Äôanalisi non risulta distorta.\n\n\n71.2.2 2. Perdita di Dati Condizionata dalle Cause\n\nEsempio: Il cane mangia i compiti in base alle abitudini di studio dello studente, ad esempio se lo studente trascura di nutrire il cane dopo aver studiato intensamente.\nConseguenze: Questo caso √® definito come ‚ÄúMissing At Random‚Äù (MAR), in cui la probabilit√† di perdita di dati √® correlata a variabili osservabili.\nGestione: √à necessario adeguare l‚Äôanalisi in base alla causa per prevenire distorsioni. L‚Äôimpiego di modelli statistici che considerano le variabili legate alla mancanza di dati pu√≤ risultare efficace.\n\nIn una prima simulazione, il trattamento (competenza dello studente) e l‚Äôeffetto (qualit√† del compito) hanno una relazione lineare. Questo scenario √® molto raro.\n\nnp.random.seed(12)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Linear association between student ability and homework score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats based on the student's ability\np_dog_eats_homework = np.where(S &gt; 0, 0.9, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data conditioned on common cause\\nmay work for linear relationships (rare) \")\n\n\n\n\n\n\n\n\nQuando l‚Äôassociazione tra abilit√† degli studenti e punteggio dei compiti √® lineare, l‚Äôadattamento dal campione completo e da quello incompleto pu√≤ risultare simile, con una perdita di precisione solo agli estremi del campione.\nConsideriamo ora il caso in cui il trattamento (capacit√† dello studente) e l‚Äôeffetto (caratteristiche del compito) non sono associati linearmente. Questo scenario √® molto pi√π comune.\n\nnp.random.seed(1)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Nonlinear association between student ability and homework score\nmu_score = 1 - np.exp(-0.7 * S)\nH = stats.norm.rvs(mu_score)\n\n# Dog eats all the homework of above-average students\np_dog_eats_homework = np.where(S &gt; 0, 1, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data based on common cause\\nvery bady for non-linear relationships (common)\")\n\n\n\n\n\n\n\n\nIn un tale scenario, l‚Äôadattamento dal campione completo e da quello incompleto sono molto diversi. In altre parole, l‚Äôanalisi del campione incompleto produce un risultato distorto.\n\n\n71.2.3 3. Perdita di Dati Condizionata dal Risultato\n\nEsempio: Il cane mangia i compiti in base al punteggio ottenuto.\nConseguenze: Questo scenario √® classificato come ‚ÄúMissing Not At Random‚Äù (MNAR), in cui la perdita di dati √® direttamente correlata al risultato mancante, complicando significativamente la gestione.\nGestione: Spesso, affrontare questa situazione richiede di modellare il processo causale alla base della perdita di dati, utilizzando tecniche come l‚Äôanalisi di sopravvivenza o l‚Äôimpiego di dati censurati.\n\n\nnp.random.seed(1)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Linear association between ability and score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats 90% of homework that is below average\np_dog_eats_homework = np.where(H &lt; 0, 0.9, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data conditioned on outcome state\\nusually not benign\")\n\n\n\n\n\n\n\n\nl‚Äôadattamento dal campione completo e da quello incompleto sono molto diversi. In altre parole, l‚Äôanalisi del campione incompleto produce un risultato distorto. La situazione √® simile a quella precedene in cui la relazione tra cause e risultati non era lineare.\nSenza conoscere la relazione causale tra il risultato e la perdita di dati, e le forme funzionali di come X √® associato con Y, √® difficile tenere conto di questo scenario.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_missing.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/linear_models/14_missing.html#commenti-e-considerazioni-conclusive",
    "title": "71¬† Dati mancanti",
    "section": "71.3 Commenti e considerazioni conclusive",
    "text": "71.3 Commenti e considerazioni conclusive\nIn conclusione, la strategia di gestione dei dati mancanti varia a seconda della loro relazione con le variabili nel modello causale. Comprendere la natura della perdita di dati √® vitale per scegliere l‚Äôapproccio analitico corretto e per interpretare con precisione i risultati dello studio. Solo nel caso di dati mancanti completamente a caso, l‚Äôanalisi che ignora la mancanza di dati produce risultati affidabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_missing.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/14_missing.html#informazioni-sullambiente-di-sviluppo",
    "title": "71¬† Dati mancanti",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib : 3.8.4\npandas     : 2.2.2\nstatsmodels: 0.14.2\narviz      : 0.18.0\nnumpy      : 1.26.4\nseaborn    : 0.13.2\nxarray     : 2024.5.0\nscipy      : 1.13.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>¬† <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/glm/introduction_glm.html",
    "href": "chapters/glm/introduction_glm.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo i modelli statistici che vanno oltre la regressione lineare, ossia quelli che fanno ipotesi distributive non gaussiane per la componente stocastica del modello, considerano una relazione non lineare tra il valore atteso della variabile di risposta e i predittori, e indeboliscono l‚Äôassunzione di indipendenza tra le osservazioni.",
    "crumbs": [
      "GLM",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html",
    "href": "chapters/glm/01_robust_regr.html",
    "title": "72¬† Regressione robusta",
    "section": "",
    "text": "Introduzione\nNell‚Äôambito della psicologia, la gestione efficace dei dati anomali √® cruciale per garantire l‚Äôintegrit√† e l‚Äôaffidabilit√† delle inferenze statistiche. La regressione robusta bayesiana rappresenta un approccio metodologico avanzato, specificamente progettato per affrontare le sfide poste da distribuzioni dei dati caratterizzate da deviazioni significative dalla norma, comuni nei dataset psicologici. Questo capitolo si dedica all‚Äôesplorazione dettagliata della regressione robusta bayesiana, con un focus particolare sull‚Äôimpiego della distribuzione Student-t come modello di errore per accrescere la tolleranza ai dati anomali e sul Pareto Smoothed Importance Sampling (PSIS) per individuare la presenza di dati anomali.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#introduzione-alla-gestione-degli-outlier-nelle-analisi-dati",
    "href": "chapters/glm/01_robust_regr.html#introduzione-alla-gestione-degli-outlier-nelle-analisi-dati",
    "title": "72¬† Regressione robusta",
    "section": "72.1 Introduzione alla Gestione degli Outlier nelle Analisi Dati",
    "text": "72.1 Introduzione alla Gestione degli Outlier nelle Analisi Dati\nLe osservazioni anomale, comunemente note come outlier, ovvero i valori che si situano ai margini della distribuzione complessiva dei dati, hanno un ruolo fondamentale nell‚Äôanalisi statistica. La loro presenza, infatti, pu√≤ seriamente compromettere l‚Äôintegrit√† e la validit√† predittiva di un modello statistico, evidenziando una potenziale inadeguatezza del modello stesso nel rappresentare con precisione l‚Äôeterogeneit√† intrinseca dei dati. Questi valori estremi sono indicativi di limitazioni nel modello, suggerendo che esso potrebbe non essere configurato correttamente o che possa non essere in grado di catturare tutte le dinamiche sottostanti i dati. Pertanto, l‚Äôidentificazione e l‚Äôanalisi approfondita degli outlier sono essenziali per garantire che le inferenze e le previsioni generate da un modello statistico siano robuste e affidabili.\nIgnorare o rimuovere gli outlier senza un‚Äôaccurata valutazione delle loro cause e caratteristiche pu√≤ portare a interpretazioni errate dei dati. Tale pratica pu√≤ essere paragonata a un tentativo di ‚Äúcorrezione‚Äù dei dati piuttosto che a un miglioramento del modello, nascondendo di fatto i veri problemi anzich√© risolverli. Di conseguenza, la sfida principale consiste nel comprendere l‚Äôimpatto degli outlier sul modello e nel trovare strategie per integrare queste informazioni anzich√© escluderle, considerandoli un elemento informativo cruciale nell‚Äôanalisi complessiva.\nPer affrontare gli outlier in modo efficace, √® essenziale adottare approcci statistici robusti. Questi possono includere la modifica della funzione di verosimiglianza per aumentare la tolleranza nei confronti di variazioni estreme dei dati, l‚Äôimpiego di distribuzioni a priori che ammettano esplicitamente la presenza di deviazioni significative, o l‚Äôutilizzo di metodi specifici per identificare e analizzare gli outlier.\nIn sintesi, gli outlier non dovrebbero essere visti come un problema da evitare, ma piuttosto come un‚Äôoccasione per affinare e perfezionare i modelli statistici. La rimozione degli outlier senza un‚Äôadeguata analisi pu√≤ condurre a conclusioni fuorvianti e a previsioni poco affidabili. Al contrario, un esame dettagliato e l‚Äôintegrazione consapevole degli outlier possono arricchire la nostra comprensione del fenomeno studiato, migliorando la precisione e l‚Äôaffidabilit√† delle previsioni del modello.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#mistura-di-gaussiane",
    "href": "chapters/glm/01_robust_regr.html#mistura-di-gaussiane",
    "title": "72¬† Regressione robusta",
    "section": "72.2 Mistura di Gaussiane",
    "text": "72.2 Mistura di Gaussiane\nNel presente capitolo, esploreremo una metodologia avanzata per mitigare l‚Äôeffetto degli outlier attraverso l‚Äôottimizzazione della funzione di verosimiglianza, incrementando cos√¨ la sua robustezza nei confronti di deviazioni estreme nei dati. Una tattica particolarmente efficace per raggiungere tale obiettivo implica l‚Äôutilizzo della distribuzione t di Student nella modellazione dei dati. In particolare, nel contesto dell‚Äôanalisi di regressione, √® stato evidenziato come gli outlier possano influenzare negativamente la retta di regressione, facendola deviare dalle zone di maggiore densit√† dei dati. Attraverso l‚Äôutilizzo della distribuzione t di Student, la quale presenta code pi√π pesanti rispetto alla distribuzione Gaussiana (Normale), √® possibile ridurre l‚Äôimpatto distorsivo degli outlier sulla retta di regressione. Questo rappresenta un esempio classico di regressione robusta.\nLa distribuzione t di Student pu√≤ essere compresa concettualmente come una composizione di diverse distribuzioni gaussiane, ognuna con la propria varianza specifica. Questa caratteristica conferisce alla distribuzione una maggiore flessibilit√† nel trattare dati con varianze estreme, rendendola particolarmente adatta per l‚Äôuso in modelli statistici che richiedono una notevole resistenza agli outlier. Utilizzare questa distribuzione facilita l‚Äôesecuzione di analisi pi√π robuste e la generazione di previsioni pi√π accurate, migliorando il livello di inferenza in situazioni dove sono presenti dati anomali.\n\n# Creazione dell'array di valori x\nxs = np.linspace(-6, 6, 100)\n\n# Inizializzazione dell'array per i PDF (Probability Density Function)\npdfs = []\n\n# Numero di gaussiane\nn_gaussians = 20\n\n# Ciclo per tracciare ogni gaussiana\nfor variance in np.linspace(.5, 5, n_gaussians):\n    label = \"Individual\\nGaussians\" if variance == .5 else None\n    pdf = stats.norm(0, variance).pdf(xs)\n    pdfs.append(pdf)\n    plt.plot(xs, pdf, color='k', label=label, alpha=.25)  # Usa matplotlib.pyplot.plot\n\n# Calcolo della somma dei PDFs\nsum_of_pdfs = np.array(pdfs).sum(axis=0)\nsum_of_pdfs /= sum_of_pdfs.max()\nsum_of_pdfs *= (1 - n_gaussians / 100)\n\n# Tracciare la somma dei PDFs\nplt.plot(xs, sum_of_pdfs, label='Mixture of\\nGaussian')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLa natura della distribuzione t di Student come mistura di Gaussiane porta con s√© importanti conseguenze analitiche.\nLa caratteristica di essere una somma di distribuzioni gaussiane con varianze eterogenee si riflette nella presenza di code pi√π pesanti rispetto a una distribuzione gaussiana singola. Ci√≤ significa che la distribuzione t √® in grado di gestire pi√π efficacemente osservazioni estreme, rendendola una scelta preferenziale per dati che si discostano dalla normalit√†, soprattutto in presenza di outlier.\nIn numerosi ambiti si osserva frequentemente la presenza di dati provenienti da popolazioni con caratteristiche eterogenee, talvolta non immediatamente identificabili. Questa diversit√† pu√≤ essere il risultato di una variet√† di meccanismi sottostanti con varianze distinte. Essendo composta da diverse gaussiane, la distribuzione t di Student incorpora implicitamente l‚Äôeterogeneit√† non osservabile nei dati, che pu√≤ derivare da diverse fonti con varianze distinte.\nUn‚Äôaltra caratteristica distintiva della distribuzione t di Student √® la sua ridotta sensibilit√† agli outlier rispetto alla distribuzione gaussiana. Grazie alle sue code pi√π pesanti, la distribuzione t attribuisce una maggiore probabilit√† alle osservazioni estreme, riducendo l‚Äôeffetto distorsivo degli outlier sull‚Äôanalisi statistica.\n\n# Creazione dell'array di valori x\nxs = np.linspace(-4, 4, 100)\n\n# Configurazione delle dimensioni del grafico\nplt.subplots(figsize=(6, 3))\n\n# Tracciare la distribuzione normale (Gaussiana)\nplt.plot(xs, stats.norm.pdf(xs), label='Gaussian')\n\n# Tracciare la distribuzione Student-t\nplt.plot(xs, stats.t(2).pdf(xs), color='C2', label='Student-t')\n\nplt.legend()\nplt.show()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#un-esempio-concreto",
    "href": "chapters/glm/01_robust_regr.html#un-esempio-concreto",
    "title": "72¬† Regressione robusta",
    "section": "72.3 Un esempio concreto",
    "text": "72.3 Un esempio concreto\nPer illustrare la capacit√† della distribuzione t di Student di mitigare l‚Äôeffetto degli outlier nell‚Äôanalisi di regressione, in questo capitolo considereremo un set di dati simulati, cos√¨ come illustrato nel tutorial fornito sul sito di Bambi.\n\nsize = 100\ntrue_intercept = 1\ntrue_slope = 2\n\nx = np.linspace(0, 1, size)\n# y = a + b*x\ntrue_regression_line = true_intercept + true_slope * x\n# add noise\ny = true_regression_line + np.random.normal(scale=0.5, size=size)\n\n# Add outliers\nx_out = np.append(x, [0.01, 0.1, 0.15])\ny_out = np.append(y, [12, 11, 13])\n\ndata = pd.DataFrame({\n    \"x\": x_out,\n    \"y\": y_out\n})\n\nSi noti che sono stati introdotti 3 valori anomali nel dataset, nonostante il vero meccanismo generativo dei dati implichi che la pendenza della retta di regressione sia pari a 2.\n\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot(111, xlabel=\"x\", ylabel=\"y\", title=\"Generated data and underlying model\")\nax.plot(x_out, y_out, \"x\", label=\"sampled data\")\nax.plot(x, true_regression_line, label=\"true regression line\", lw=2.0)\nplt.legend(loc=0);\n\n\n\n\n\n\n\n\nQueste anomalie possono essere soggette ad un‚Äôanalisi rigorosa mediante l‚Äôapplicazione di metodi statistici avanzati. Un approccio per valutare l‚Äôimpatto di tali outlier sull‚Äôanalisi √® l‚Äôutilizzo della statistica PSIS \\(k\\), una tecnica che permette di quantificare l‚Äôinfluenza delle osservazioni estreme su una distribuzione.\nImplementiamo un modello di regressione lineare per analizzare la relazione tra y (variabile dipendente) e x. In questa analisi iniziale, l‚Äôipotesi sottostante √® che gli errori (o residui), seguano una distribuzione normale (gaussiana).\n\ngauss_model = bmb.Model(\"y ~ x\", data, family=\"gaussian\")\n\n\ngauss_model.build()\ngauss_model.graph()\n\n\n\n\n\n\n\n\nAdattiamo il modello ai dati. Si noti che l‚Äôargomento idata_kwargs={\"log_likelihood\": True} passato alla funzione fit √® usato per specificare le opzioni per la creazione dell‚Äôoggetto InferenceData che sar√† restituito. In questo caso, stiamo indicando che vogliamo che il logaritmo della verosimiglianza sia incluso nell‚Äôoggetto InferenceData. Il logaritmo della verosimiglianza pu√≤ essere utilizzato per ulteriori analisi e diagnostica, come il calcolo del LOO (Leave-One-Out Cross-Validation).\n\ngauss_fitted = gauss_model.fit(\n    nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\nEsaminiamo visivamente i risultati dell‚Äôanalisi.\n\nax = bmb.interpret.plot_predictions(gauss_model, gauss_fitted, [\"x\"])\nplt.scatter(data['x'], data['y'], color='gray', alpha=0.5, label='Dati Grezzi')\nplt.show()\n\nDefault computed for conditional variable: x\n\n\n\n\n\n\n\n\n\nIpotizzando una distribuzione normale degli errori, l‚Äôanalisi produce una stima fortemente distorta della pendenza della retta di regressione.\n\n_ = az.plot_trace(gauss_fitted)\n\n\n\n\n\n\n\n\n\naz.summary(gauss_fitted, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n2.20\n0.34\n1.55\n2.82\n0.01\n0.00\n4349.92\n2742.88\n1.0\n\n\nsigma\n1.85\n0.13\n1.61\n2.09\n0.00\n0.00\n3745.05\n3016.41\n1.0\n\n\nx\n0.21\n0.61\n-0.88\n1.37\n0.01\n0.01\n4300.46\n2852.23\n1.0\n\n\n\n\n\n\n\n\n\nposterior_predictive = gauss_model.predict(gauss_fitted, kind=\"pps\")\nax = az.plot_ppc(gauss_fitted, num_pp_samples=100)\n_ = ax.set_xlabel(\"x\")\n\n\n\n\n\n\n\n\nIn un secondo modello assumiamo che gli errori seguano una distribuzione t di Student.\n\nt_model = bmb.Model(\"y ~ x\", data, family=\"t\")\n\n\nt_model.build()\nt_model.graph()\n\n\n\n\n\n\n\n\n\nt_fitted = t_model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\n\nax = bmb.interpret.plot_predictions(t_model, t_fitted, [\"x\"])\n_ = plt.scatter(data['x'], data['y'], color='gray', alpha=0.5, label='Dati Grezzi')\n\nDefault computed for conditional variable: x\n\n\n\n\n\n\n\n\n\nSi noti che, in questo caso, la presenza degli outlier non ha distorto in alcun modo la stima della pendenza della retta di regressione. Nella regressione lineare gaussiana classica, i valori anomali hanno l‚Äôeffetto di ‚Äúspingere‚Äù la distribuzione a posteriori di \\(\\beta\\) verso lo zero. Invece, il modello student-t √® pi√π robusto e meno influenzato dai valori anomali.\n\naz.summary(t_fitted, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.19\n0.11\n0.99\n1.40\n0.00\n0.00\n3551.59\n2916.33\n1.0\n\n\nnu\n2.14\n0.46\n1.35\n3.03\n0.01\n0.01\n3267.18\n3114.44\n1.0\n\n\nsigma\n0.41\n0.05\n0.32\n0.50\n0.00\n0.00\n3212.53\n3022.28\n1.0\n\n\nx\n1.58\n0.18\n1.23\n1.92\n0.00\n0.00\n3818.50\n2914.77\n1.0\n\n\n\n\n\n\n\n\n\nposterior_predictive = t_model.predict(t_fitted, kind=\"pps\")\nax = az.plot_ppc(t_fitted, num_pp_samples=100)\nplt.xlim(-2, 5)\n_ = ax.set_xlabel(\"x\")\n\n\n\n\n\n\n\n\nNella figura successiva, esaminiamo la stima a posteriori della pendenza della retta di regressione per entrambi i modelli.\n\naz.plot_dist(t_fitted.posterior[\"x\"], color=\"C1\", label=\"Student-t Model\")\naz.plot_dist(gauss_fitted.posterior[\"x\"], label=\"Gaussian Model\");\n\n\n\n\n\n\n\n\nSi noti che, in presenza di outlier, l‚Äôimpiego della distribuzione t di Student ha portato a un adattamento del modello pi√π accurato, come evidenziato dai valori diagnostici Pareto \\(k\\).\n\naz.loo(gauss_fitted)\n\nComputed from 4000 posterior samples and 103 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -218.24    29.86\np_loo       15.13        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100   97.1%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         1    1.0%\n   (1, Inf)   (very bad)    2    1.9%\n\n\n\naz.loo(t_fitted)\n\nComputed from 4000 posterior samples and 103 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -112.62    16.34\np_loo        5.44        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      103  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#waic-e-psis",
    "href": "chapters/glm/01_robust_regr.html#waic-e-psis",
    "title": "72¬† Regressione robusta",
    "section": "72.4 WAIC e PSIS",
    "text": "72.4 WAIC e PSIS\nNella sezione seguente, approfondiremo il legame tra i valori diagnostici di Pareto \\(k\\) e il Watanabe-Akaike Information Criterion (WAIC), una metrica essenziale per valutare la qualit√† di un modello statistico. A differenza del pi√π tradizionale criterio di informazione di Akaike (AIC), impiegato nei contesti frequentisti, il WAIC estende il concetto di valutazione della qualit√† di un modello incorporando sia la sua capacit√† di adattamento ai dati sia la sua complessit√† intrinseca. Lo scopo √® prevenire l‚Äôeccesso di adattamento (overfitting), dove il modello √® troppo specifico ai dati di addestramento, e l‚Äôinsufficiente adattamento (underfitting), dove il modello √® troppo semplice per catturare la struttura sottostante dei dati. In termini pi√π accessibili, il WAIC stima l‚Äôefficacia con cui un modello pu√≤ prevedere dati non ancora osservati, basandosi sulla log-verosimiglianza dei dati e correggendo per la dimensione effettiva del modello. Un valore WAIC inferiore segnala una maggiore capacit√† previsionale del modello.\nPer calcolare il WAIC, si fa spesso ricorso all‚Äôimportance sampling, una tecnica per approssimare propriet√† di una distribuzione di probabilit√† campionando da una distribuzione alternativa. Il PSIS (Pareto Smoothed Importance Sampling), che migliora questo metodo, e i valori diagnostici di Pareto \\(k\\) giocano un ruolo cruciale nell‚Äôevaluazione della qualit√† dell‚Äôapproximation impiegata per il calcolo del WAIC. Il valore di Pareto \\(k\\) funge da termometro dell‚Äôefficacia dell‚Äôimportance sampling per un determinato modello e insieme di dati. Valori elevati di Pareto \\(k\\) (solitamente oltre 0.7) segnalano potenziali inaffidabilit√† nell‚Äôapprossimazione, il che pu√≤ tradursi in stime del WAIC distorte. Questo fenomeno suggerisce che il modello potrebbe non essere adeguatamente equipaggiato per prevedere specifiche osservazioni nei dati, spesso a causa della presenza di dati anomali o di una scarsa adattabilit√† del modello.\nStabilire un collegamento tra WAIC e i valori di Pareto \\(k\\) √® fondamentale, poich√© offre una panoramica pi√π dettagliata e affidabile della performance di un modello. Se da un lato il WAIC valuta l‚Äôadattabilit√† generale del modello ai dati e la sua gestione della complessit√†, dall‚Äôaltro, il valore di Pareto \\(k\\) fornisce insight preziosi sull‚Äôaffidabilit√† dell‚Äôapprossimazione usata per il suo calcolo. Insieme, queste metriche consentono una valutazione pi√π completa della qualit√† di un modello.\nQuando il calcolo del WAIC viene eseguito in modo puntiforme (pointwise=True), significa che la valutazione √® condotta separatamente per ciascuna osservazione all‚Äôinterno del dataset. Questa modalit√† di calcolo permette di identificare come ogni dato contribuisca al valore globale del WAIC, facilitando l‚Äôindividuazione di potenziali dati anomali o punti critici per il modello, diversamente da un calcolo aggregato che fornirebbe un unico valore di WAIC per tutto il modello. Questa analisi dettagliata √® particolarmente utile per affinare la comprensione della performance modello e per guidare eventuali miglioramenti.\n\ndef plot_loocv(inference, title=None, outliers_idx=[], divorce=None):\n    plt.subplots(figsize=(6, 3))\n    pareto_k = az.loo(inference, pointwise=True).pareto_k\n    waic = -az.waic(inference, pointwise=True).waic_i\n\n    plt.scatter(pareto_k, waic, color='C0', label=None)\n\n    # Assicurati che outliers_idx e divorce siano definiti\n    for oi in outliers_idx:\n        if divorce is not None and oi in divorce.index:\n            plt.annotate(divorce.loc[oi, \"Location\"], (pareto_k[oi] + .01, waic[oi]), fontsize=14)\n\n    plt.xlabel(\"PSIS Pareto K\")\n    plt.ylabel(\"WAIC\")\n    plt.title(title)\n    plt.show()\n\nCreiamo un grafico che mostra i valori di WAIC in funzione dei valori Pareto \\(k\\). Con questa rappresentazione possiamo esaminare come ogni osservazione influisca sulla performance del modello e sulla sua affidabilit√†. Se un punto ha un alto valore di Pareto \\(k\\) e un elevato impatto negativo sul WAIC (indicato da un alto valore negativo di WAIC), potrebbe essere un candidato per un‚Äôulteriore revisione o esclusione dal modello.\n\nplot_loocv(gauss_fitted, title=\"Gaussian Likelihood Posterior\\nAffected by Outliers\")\n\n\n\n\n\n\n\n\n\nplot_loocv(t_fitted, title=\"Student Likelihood Posterior\\nAffected by Outliers\")\n\n\n\n\n\n\n\n\n√à evidente che, per i dati in esame, quando si utilizza un modello di regressione lineare che assume una distribuzione degli errori t di Student, sia il WAIC che i valori diagnostici Pareto \\(k\\) risultano essere inferiori. Questa riduzione indica una maggiore efficienza del modello nella previsione dei dati.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#confronto-tra-modelli",
    "href": "chapters/glm/01_robust_regr.html#confronto-tra-modelli",
    "title": "72¬† Regressione robusta",
    "section": "72.5 Confronto tra Modelli",
    "text": "72.5 Confronto tra Modelli\nEseguiamo ora un‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) per confrontare i due modelli statistici, il modello gaussiano e il modello basato sulla distribuzione t di Student. L‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) √® una tecnica di valutazione dei modelli statistici che consente di confrontare le loro prestazioni in termini di capacit√† previsionale. Questo metodo √® particolarmente utile per determinare quale modello possa generalizzare meglio a nuovi dati, non inclusi nel set di addestramento.\nL‚Äôanalisi di validazione incrociata Leave-One-Out (LOO) √® una tecnica di valutazione dei modelli statistici che consente di confrontare le loro prestazioni in termini di capacit√† previsionale. Questo metodo √® particolarmente utile per determinare quale modello possa generalizzare meglio a nuovi dati, non inclusi nel set di addestramento. Ecco una spiegazione dettagliata del processo e di come viene applicato per confrontare un modello gaussiano con un modello basato sulla distribuzione t di Student.\nNello specifico, la validazione incrociata LOO √® un caso particolare di validazione incrociata k-fold, dove \\(k\\) √® uguale al numero di osservazioni nel dataset. In pratica, questo significa che per un dataset di \\(n\\) osservazioni, il modello viene addestrato \\(n\\) volte, ogni volta usando \\(n-1\\) osservazioni come dati di addestramento e la singola osservazione restante come dato di test. Questo processo viene ripetuto per ogni osservazione nel dataset, permettendo cos√¨ di valutare la performance del modello su ogni punto dati una volta.\nUtilizzando az.compare, √® possibile confrontare i due modelli sulla base della loro performance previsionale, quantificata attraverso metriche specifiche derivate dalla validazione incrociata LOO. Queste metriche aiutano a determinare quale modello ha una migliore capacit√† di generalizzazione, prendendo in considerazione sia la qualit√† dell‚Äôadattamento ai dati che la complessit√† del modello.\n\ndf_comp_loo = az.compare({\"Gaussian Model\": gauss_fitted, \"Student t Model\": t_fitted})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nStudent t Model\n0\n-112.621991\n5.443246\n0.000000\n1.0\n16.341621\n0.00000\nFalse\nlog\n\n\nGaussian Model\n1\n-218.239844\n15.126661\n105.617853\n0.0\n29.860645\n16.48181\nTrue\nlog\n\n\n\n\n\n\n\n\n\naz.plot_compare(df_comp_loo, insample_dev=False);\n\n\n\n\n\n\n\n\nCome abbiamo visto in precedenza, la ELPD (Expected Log Predictive Density) √® una misura della performance predittiva di un modello statistico. Rappresenta il logaritmo della densit√† predittiva media attesa, calcolata attraverso la validazione incrociata LOO. Un valore pi√π alto di ELPD indica una migliore capacit√† del modello di adattarsi ai dati e di fare previsioni accurate su nuovi dati non visti.\n\nrank: Posizione del modello basata sull‚Äôelpd_loo.\nelpd_loo: Stima dell‚ÄôExpected Log Pointwise Predictive Density per LOO-CV. Valori pi√π alti indicano migliori capacit√† predittive.\np_loo: Stima della complessit√† effettiva del modello, che riflette il numero di parametri ‚Äúeffettivi‚Äù.\nelpd_diff: Differenza di elpd_loo tra il modello corrente e il miglior modello. Per il miglior modello, questo valore √® 0.\nweight: Peso basato sull‚Äôelpd_loo, indicando l‚Äôimportanza relativa del modello nel contesto di un ensemble di modelli.\nse (Standard Error): Errore standard dell‚Äôelpd_loo.\ndse (Differenza di Standard Error): Errore standard della differenza di elpd_loo tra due modelli.\nwarning: Se vero, indica potenziali problemi con la stima elpd_loo per il modello.\nscale: La scala utilizzata per misurare l‚Äôelpd_loo; in questo caso, ‚Äúlog‚Äù.\n\nIl modello Student t ha un elpd_loo di -102.284333, il che lo rende il modello con le migliori capacit√† predittive tra i due, poich√© ha il valore elpd_loo pi√π alto (meno negativo). Questo modello ha anche un p_loo di 5.894299, indicando una complessit√† inferiore rispetto al Gaussian Model. Non ci sono avvertimenti, il che suggerisce che la stima elpd_loo √® considerata affidabile. Ha ricevuto un peso di 1.000000, indicando che √® il modello preferito per le previsioni.\nIl modello gaussiano mostra un elpd_loo di -219.324176 con una differenza di elpd_loo (elpd_diff) di 117.039843 rispetto al miglior modello. Questo indica che ha prestazioni significativamente peggiori in termini di adattamento predittivo rispetto allo Student t Model. Il suo p_loo pi√π alto di 15.391340 riflette una maggiore complessit√† del modello, che non sembra tradursi in migliori capacit√† predittive in questo contesto. Il modello presenta anche un avvertimento, il che potrebbe indicare problemi con la stima LOO, suggerendo cautela nell‚Äôinterpretazione dei suoi risultati.\nBasandosi sull‚Äôoutput fornito, il modello Student t √® considerato il modello migliore tra i due per questi dati, dato il suo elpd_loo pi√π alto (meno negativo), la minore complessit√† (p_loo inferiore), e l‚Äôassenza di avvertimenti. Il Gaussian Model, nonostante una maggiore complessit√†, mostra prestazioni inferiori e problemi potenziali (come indicato dall‚Äôavvertimento), rendendolo meno preferibile per la predizione su questo set di dati.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/glm/01_robust_regr.html#commenti-e-considerazioni-conclusive",
    "title": "72¬† Regressione robusta",
    "section": "72.6 Commenti e considerazioni conclusive",
    "text": "72.6 Commenti e considerazioni conclusive\nNella pratica statistica, si incontrano spesso situazioni in cui l‚Äôeterogeneit√† non osservata - variazioni o differenze tra osservazioni in un insieme di dati che non sono spiegabili attraverso le variabili misurabili nel contesto dello studio - svolge un ruolo significativo. Questa eterogeneit√† si manifesta quando le differenze osservate tra i dati non possono essere attribuite completamente alle variabili note e misurabili. Al contrario, esistono fattori ignoti o non misurati che influenzano le osservazioni, che possono essere intrinseci alle unit√† di osservazione o dipendere da condizioni ambientali o contestuali non contemplate durante la progettazione dello studio o la raccolta dei dati.\nPer modellare questa eterogeneit√†, spesso si utilizzano miscele di distribuzioni gaussiane o Student-t. La scelta della distribuzione Student-t in particolare implica un modello che √® meno sensibile agli effetti dei valori estremi, o ‚Äúoutliers‚Äù, grazie alle sue code pi√π pesanti. Tuttavia, una sfida nella modellazione statistica risiede nel corretto posizionamento dei parametri dei gradi di libert√† della distribuzione Student-t, specialmente perch√© gli outliers sono eventi rari e quindi difficili da stimare accuratamente.\nIn assenza di una teoria solida per guidare la scelta del modello statistico, la regressione robusta, basata su una distribuzione Student-t, emerge come una strategia prudente. Questo approccio si contrappone alla metodologia gaussiana standard, che pu√≤ risultare inadeguata nel gestire gli effetti dei valori estremi e dell‚Äôeterogeneit√† non osservata.\n√à fondamentale, inoltre, valutare accuratamente la bont√† di adattamento del modello ai dati. Strumenti come il Pareto Smoothed Importance Sampling (PSIS) e i valori diagnostici Pareto $ k $ si rivelano preziosi in questo contesto. Il PSIS utilizza la stima di $ k $ per perfezionare l‚Äôadattamento del modello, mentre i valori di $ k $ funzionano come indicatori diagnostici per valutare la qualit√† dell‚Äôimportance sampling e l‚Äôadeguatezza del modello stesso. Questi metodi aiutano a sviluppare modelli pi√π robusti e precisi, specialmente quando si trattano dati complessi con caratteristiche quali outliers e eterogeneit√† non osservata.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/01_robust_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "72¬† Regressione robusta",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\npandas    : 2.2.2\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\nbambi     : 0.14.0\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>72</span>¬† <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html",
    "href": "chapters/glm/02_stan_binomial_regr.html",
    "title": "73¬† Regressione binomiale",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo i Modelli Lineari Generalizzati (GLM) e, in particolare, il modello di regressione binomiale, che √® un‚Äôapplicazione specifica dei GLM. Discuteremo anche come affrontare questo tipo di modelli utilizzando un approccio bayesiano e illustreremo come implementare la regressione binomiale con il software Stan.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Regressione binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#probabilit√†-odds-e-logit",
    "href": "chapters/glm/02_stan_binomial_regr.html#probabilit√†-odds-e-logit",
    "title": "73¬† Regressione binomiale",
    "section": "73.1 Probabilit√†, Odds e Logit",
    "text": "73.1 Probabilit√†, Odds e Logit\nNel contesto dei GLM, √® essenziale comprendere le relazioni tra probabilit√†, odds e logit. La probabilit√† \\(P\\) rappresenta la possibilit√† di successo di un evento ed √® un valore compreso tra 0 e 1. Gli odds (o rapporti di possibilit√†) rappresentano il rapporto tra la probabilit√† di successo e quella di insuccesso, calcolato come \\(O = \\frac{P}{1 - P}\\). Il logit √® il logaritmo naturale degli odds, dato dalla formula \\(L = \\ln(O) = \\ln\\left(\\frac{P}{1 - P}\\right)\\).\nQueste trasformazioni sono fondamentali nei GLM perch√© consentono di trattare probabilit√† che, per definizione, sono limitate all‚Äôintervallo (0, 1) trasformandole in un intervallo che pu√≤ coprire tutti i numeri reali. Ad esempio, quando la probabilit√† \\(P = 0.5\\), gli odds sono 1 e il logit √® 0. Logit negativi indicano probabilit√† inferiori a 0.5, mentre logit positivi indicano probabilit√† superiori a 0.5.\n\n\n\n\n\n\n\n\nProbabilit√† (P)\nOdds (O)\nLogit (L)\n\n\n\n\n0.01\n\\(\\frac{0.01}{0.99}\\) = 0.0101\n\\(\\ln\\left(\\frac{0.01}{0.99}\\right)\\) = -4.60\n\n\n0.05\n\\(\\frac{0.05}{0.95}\\) = 0.0526\n\\(\\ln\\left(\\frac{0.05}{0.95}\\right)\\) = -2.94\n\n\n0.10\n\\(\\frac{0.10}{0.90}\\) = 0.1111\n\\(\\ln\\left(\\frac{0.10}{0.90}\\right)\\) = -2.20\n\n\n0.30\n\\(\\frac{0.30}{0.70}\\) = 0.4286\n\\(\\ln\\left(\\frac{0.30}{0.70}\\right)\\) = -0.85\n\n\n0.50\n\\(\\frac{0.50}{0.50}\\) = 1\n\\(\\ln\\left(\\frac{0.50}{0.50}\\right)\\) = 0.00\n\n\n0.70\n\\(\\frac{0.70}{0.30}\\) = 2.3333\n\\(\\ln\\left(\\frac{0.70}{0.30}\\right)\\) = 0.85\n\n\n0.90\n\\(\\frac{0.90}{0.10}\\) = 9\n\\(\\ln\\left(\\frac{0.90}{0.10}\\right)\\) = 2.20\n\n\n0.95\n\\(\\frac{0.95}{0.05}\\) = 19\n\\(\\ln\\left(\\frac{0.95}{0.05}\\right)\\) = 2.94\n\n\n0.99\n\\(\\frac{0.99}{0.01}\\) = 99\n\\(\\ln\\left(\\frac{0.99}{0.01}\\right)\\) = 4.60\n\n\n\n\n73.1.1 Trasformazione Inversa del Logit\nLa trasformazione inversa del logit, nota anche come antilogit, consente di riconvertire un logit in una probabilit√†. Questa funzione √® definita come:\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}},\n\\]\ndove \\(\\eta_i\\) √® il predittore lineare. Questa trasformazione garantisce che la stima risultante, \\(\\pi_i\\), sia sempre compresa tra 0 e 1, rendendola interpretabile come una probabilit√†. Questo √® particolarmente utile nei modelli come la regressione binomiale, dove si cerca di modellare la probabilit√† di successo di un evento binario.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Regressione binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#modelli-lineari-generalizzati",
    "href": "chapters/glm/02_stan_binomial_regr.html#modelli-lineari-generalizzati",
    "title": "73¬† Regressione binomiale",
    "section": "73.2 Modelli Lineari Generalizzati",
    "text": "73.2 Modelli Lineari Generalizzati\nI Modelli Lineari Generalizzati (GLM) estendono i modelli di regressione lineare classica per gestire variabili dipendenti che non soddisfano le ipotesi del modello lineare standard, come la normalit√† degli errori e la linearit√† tra variabili indipendenti e dipendenti. Questa flessibilit√† consente ai GLM di adattarsi a una variet√† di tipi di dati, inclusi conteggi, proporzioni e dati categoriali.\nUn GLM √® costituito da tre componenti principali:\n\nComponente Aleatoria: Determina la distribuzione di probabilit√† della variabile risposta \\(Y\\). Per esempio, se \\(Y\\) √® un conteggio di eventi, potrebbe essere modellata come una variabile casuale con distribuzione di Poisson.\nComponente Sistematica: Definisce la combinazione lineare delle variabili indipendenti \\(X\\), che viene utilizzata per modellare la media attesa della variabile risposta. Questa combinazione lineare √® rappresentata dal predittore lineare \\(\\eta\\), espresso come \\(\\eta = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_k X_k\\), dove \\(\\beta_0, \\beta_1, \\dots, \\beta_k\\) sono i parametri del modello.\nFunzione di Legame: Stabilisce la relazione tra la media attesa della variabile risposta, \\(\\mathbb{E}(Y) = \\mu\\), e il predittore lineare \\(\\eta\\). La funzione di legame garantisce che questa relazione sia appropriata per la distribuzione specifica della variabile \\(Y\\). Nel caso della regressione binomiale, la funzione di legame pi√π comune √® il logit, definito come:\n\n\\[\ng(\\mu) = \\ln\\left(\\frac{\\mu}{1-\\mu}\\right).\n\\]\nQuesta funzione trasforma la proporzione media di successi \\(\\mu\\), che varia tra 0 e 1, in un valore \\(\\eta\\) che pu√≤ assumere qualsiasi numero reale. Questa trasformazione permette di modellare la probabilit√† di successo in funzione delle variabili indipendenti in modo lineare rispetto al logit.\n\n73.2.1 La Regressione Binomiale\nLa regressione binomiale √® un tipo specifico di GLM utilizzato quando la variabile dipendente rappresenta il numero di successi in una serie di prove binarie, ovvero situazioni in cui ogni osservazione pu√≤ essere un successo o un fallimento. Questo modello √® particolarmente utile per analizzare dati di proporzioni, come il numero di successi in una serie di tentativi.\nConsideriamo una variabile risposta \\(Y_i\\) che segue una distribuzione binomiale con parametri \\(n_i\\) (numero di prove) e \\(p_i\\) (probabilit√† di successo in ciascuna prova):\n\\[\nY_i \\sim \\text{Binomiale}(n_i, p_i),\n\\]\ndove \\(Y_i\\) rappresenta il numero di successi osservati per l‚Äô\\(i\\)-esima osservazione, \\(n_i\\) √® il numero totale di tentativi, e \\(p_i\\) √® la probabilit√† di successo per ciascun tentativo. L‚Äôobiettivo della regressione binomiale √® modellare la probabilit√† di successo \\(p_i\\) in funzione di una o pi√π variabili indipendenti.\n\n\n73.2.2 Funzione di Legame nella Regressione Binomiale\nNella regressione binomiale, la funzione di legame comunemente utilizzata √® il logit:\n\\[\n\\eta_i = g(p_i) = \\ln\\left(\\frac{p_i}{1 - p_i}\\right).\n\\]\nQuesta funzione converte la probabilit√† \\(p_i\\), limitata all‚Äôintervallo [0, 1], in un valore \\(\\eta_i\\) che pu√≤ variare su tutta la linea dei numeri reali. La funzione logistica inversa riconverte \\(\\eta_i\\) in \\(p_i\\):\n\\[\np_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}}\n\\]\no, in termini del predittore lineare:\n\\[\np_i = \\frac{e^{\\beta_0 + \\beta_1 X_1 + \\dots + \\beta_k X_k}}{1 + e^{\\beta_0 + \\beta_1 X_1 + \\dots + \\beta_k X_k}}.\n\\]\nQuesta rappresentazione garantisce che le probabilit√† stimate siano sempre comprese tra 0 e 1, permettendo una chiara interpretazione come probabilit√† di successo.\nIn conclusione, la regressione binomiale offre un potente strumento per analizzare dati di proporzioni e conteggi di successi, utilizzando la distribuzione binomiale e la funzione di legame logit per modellare la relazione tra variabili indipendenti e la probabilit√† di successo. Questo rende la regressione binomiale particolarmente utile in diverse applicazioni, dalla biostatistica alla psicologia, dove √® cruciale comprendere i fattori che influenzano la probabilit√† di un determinato esito binario.\nAdottando un approccio bayesiano, possiamo incorporare informazioni a priori sui parametri del modello, permettendo di aggiornare le nostre stime alla luce dei dati osservati e migliorando la robustezza e l‚Äôinterpretabilit√† delle conclusioni tratte dall‚Äôanalisi.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Regressione binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#un-esempio-concreto",
    "href": "chapters/glm/02_stan_binomial_regr.html#un-esempio-concreto",
    "title": "73¬† Regressione binomiale",
    "section": "73.3 Un esempio concreto",
    "text": "73.3 Un esempio concreto\nSeguiamo il tutorial fornito sul sito ufficiale di PyMC e generiamo dei dati sintetici dove \\(y\\) indica il numero di successi in \\(n = 20\\) prove e \\(x\\) √® un predittore.\n\n# true params\nbeta0_true = 0.7\nbeta1_true = 0.4\n# number of yes/no questions\nn = 20\n\nsample_size = 30\nx = np.linspace(-10, 20, sample_size)\n# Linear model\nmu_true = beta0_true + beta1_true * x\n# transformation (inverse logit function = expit)\np_true = expit(mu_true)\n# Generate data\ny = rng.binomial(n, p_true)\n# bundle data into dataframe\ndata = pd.DataFrame({\"x\": x, \"y\": y})\ndisplay(data)\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-10.000000\n1\n\n\n1\n-8.965517\n0\n\n\n2\n-7.931034\n1\n\n\n3\n-6.896552\n2\n\n\n4\n-5.862069\n6\n\n\n5\n-4.827586\n7\n\n\n6\n-3.793103\n4\n\n\n7\n-2.758621\n14\n\n\n8\n-1.724138\n14\n\n\n9\n-0.689655\n9\n\n\n10\n0.344828\n12\n\n\n11\n1.379310\n11\n\n\n12\n2.413793\n17\n\n\n13\n3.448276\n19\n\n\n14\n4.482759\n20\n\n\n15\n5.517241\n20\n\n\n16\n6.551724\n18\n\n\n17\n7.586207\n20\n\n\n18\n8.620690\n20\n\n\n19\n9.655172\n20\n\n\n20\n10.689655\n20\n\n\n21\n11.724138\n19\n\n\n22\n12.758621\n20\n\n\n23\n13.793103\n20\n\n\n24\n14.827586\n20\n\n\n25\n15.862069\n20\n\n\n26\n16.896552\n20\n\n\n27\n17.931034\n20\n\n\n28\n18.965517\n20\n\n\n29\n20.000000\n20\n\n\n\n\n\n\n\n\nPer questi dati, il modello di regressione binomiale pu√≤ essere descritto come segue:\n\nModello lineare: \\[\n\\eta_i = \\beta_0 + \\beta_1 x_i\n\\]\nProbabilit√† di successo: \\[\np_i = \\text{logit}^{-1}(\\eta_i) = \\frac{1}{1 + \\exp(-\\eta_i)}\n\\]\nLikelihood: \\[\ny_i \\mid p_i \\sim \\text{Binomiale}(n, p_i)\n\\]\nPriori: \\[\n\\beta_0 \\sim \\mathcal{N}(0, 1)\n\\] \\[\n\\beta_1 \\sim \\mathcal{N}(0, 1)\n\\]\n\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"binomial_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; sample_size;  // Numero totale di osservazioni\n  vector[sample_size] x;     // Variabile indipendente\n  array[sample_size] int&lt;lower=0&gt; y;  // Successi per ogni tentativo\n  int&lt;lower=0&gt; n;           // Numero di tentativi per osservazione\n}\nparameters {\n  real beta0;  // Intercetta\n  real beta1;  // Pendenza\n}\ntransformed parameters {\n  vector[sample_size] eta = beta0 + beta1 * x;  // Modello lineare\n  vector[sample_size] p = inv_logit(eta);       // Probabilit√† di successo\n}\nmodel {\n  // Priori\n  beta0 ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n\n  // Likelihood\n  y ~ binomial(n, p);\n}\n\n\n\nCreiamo un dizionario nel formato richiesto per l‚Äôinput a CmdStan:\n\nstan_data = {\n    \"sample_size\": data.shape[0],\n    \"x\": data[\"x\"],\n    \"y\": data[\"y\"],\n    \"n\": 20\n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nPer visualizzare e descrivere la distribuzione a posteriori dei parametri √® possibile utilizzare ArviZ dopo aver fittato il modello con cmdstanpy. ArviZ utilizza un formato di dati chiamato InferenceData, che √® un formato ad alto livello per la memorizzazione di risultati statistici. cmdstanpy restituisce un oggetto CmdStanMCMC, che pu√≤ essere convertito in InferenceData utilizzando la funzione az.from_cmdstanpy.\n\nidata = az.from_cmdstanpy(fit)\n\nOtteniamo un riassunto delle statistiche posteriori:\n\nsummary = az.summary(fit, var_names=([\"beta0\", \"beta1\"]), hdi_prob=0.94)\nprint(summary)\n\n        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nbeta0  0.934  0.174   0.603    1.257      0.003    0.002    4147.0    4717.0   \nbeta1  0.462  0.043   0.381    0.543      0.001    0.000    4247.0    4317.0   \n\n       r_hat  \nbeta0    1.0  \nbeta1    1.0  \n\n\nMostriamo le distribuzioni a posteriori e le tracce di campionamento per i parametri:\n\n_ = az.plot_trace(fit, var_names=([\"beta0\", \"beta1\"]))\n\n\n\n\n\n\n\n\nNel pannello superiore della figura seguente vediamo il modello lineare nella sua forma non trasformata. Come si pu√≤ osservare, questo modello lineare genera valori che escono dall‚Äôintervallo [0, 1], sottolineando quindi la necessit√† di una funzione di collegamento inversa. Questa funzione ha il compito di mappare i valori dal dominio dei numeri reali all‚Äôintervallo [0, 1]. Come abbiamo visto, questa trasformazione √® realizzata mediante la funzione logistica inversa.\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={\"width_ratios\": [2, 1]})\n\n# Data space plot ========================================================\naz.plot_hdi(\n    data[\"x\"],\n    idata.posterior.p,\n    hdi_prob=0.95,\n    fill_kwargs={\"alpha\": 0.25, \"linewidth\": 0},\n    ax=ax[0],\n    color=\"C1\",\n)\n# posterior mean\npost_mean = idata.posterior.p.mean((\"chain\", \"draw\"))\nax[0].plot(data[\"x\"], post_mean, label=\"posterior mean\", color=\"C1\")\n# plot truth\nax[0].plot(data[\"x\"], p_true, \"--\", label=\"true\", color=\"C2\")\n# formatting\nax[0].set(xlabel=\"x\", title=\"Data space\")\nax[0].set_ylabel(\"proportion successes\", color=\"C1\")\nax[0].tick_params(axis=\"y\", labelcolor=\"C1\")\nax[0].legend()\n# instantiate a second axes that shares the same x-axis\nfreq = ax[0].twinx()\nfreq.set_ylabel(\"number of successes\")\nfreq.scatter(data[\"x\"], data[\"y\"], color=\"k\", label=\"data\")\n# get y-axes to line up\ny_buffer = 1\nfreq.set(ylim=[-y_buffer, n + y_buffer])\nax[0].set(ylim=[-(y_buffer / n), 1 + (y_buffer / n)])\nfreq.grid(None)\n# set both y-axis to have 5 ticks\nax[0].set(yticks=np.linspace(0, 20, 5) / n)\nfreq.set(yticks=np.linspace(0, 20, 5))\n\n# Parameter space plot ===================================================\naz.plot_kde(\n    az.extract(idata, var_names=\"beta0\"),\n    az.extract(idata, var_names=\"beta1\"),\n    ax=ax[1],\n)\nax[1].plot(beta0_true, beta1_true, \"C2o\", label=\"true\")\nax[1].set(xlabel=r\"$\\beta_0$\", ylabel=r\"$\\beta_1$\", title=\"Parameter space\")\nax[1].legend(facecolor=\"white\", frameon=True)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_61676/1160461270.py:44: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Regressione binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/02_stan_binomial_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "73¬† Regressione binomiale",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>73</span>¬† <span class='chapter-title'>Regressione binomiale</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html",
    "href": "chapters/glm/03_stan_logistic_regr.html",
    "title": "74¬† Regressione logistica con Stan",
    "section": "",
    "text": "Introduzione\nLa regressione logistica √® un modello additivo utilizzato per dati binari, ossia dati \\(y\\) che assumono valori 0 o 1. Per modellare i dati binari, dobbiamo aggiungere due caratteristiche al modello base \\(y = a + bx\\): una trasformazione non lineare che vincola l‚Äôoutput tra 0 e 1 (a differenza di \\(a + bx\\), che √® illimitato), e un metodo per interpretare i numeri risultanti come probabilit√† che un evento si verifichi.\nIn questo capitolo, approfondiremo la regressione logistica bivariata, un modello statistico che ci consente di analizzare le relazioni tra una variabile di esito binaria e una singola variabile indipendente. Esploreremo il processo di stima dei coefficienti del modello attraverso un approccio bayesiano e forniremo un‚Äôinterpretazione dei risultati ottenuti. Mostreremo come i coefficienti influenzano la probabilit√† di successo della variabile binaria di esito, nonch√© come interpretare il loro segno e ampiezza.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.1 Modello di Regressione Logistica per Variabili Binarie",
    "text": "74.1 Modello di Regressione Logistica per Variabili Binarie\nIl modello di regressione logistica √® utilizzato per analizzare la relazione tra una variabile dipendente dicotomica, che assume i valori di ‚Äúsuccesso‚Äù e ‚Äúfallimento‚Äù, e una o pi√π variabili indipendenti, che possono essere sia quantitative che qualitative. Qui ci concentreremo sul caso di una sola variabile indipendente.\nConsideriamo \\(n\\) osservazioni i.i.d., dove \\(Y_i\\) indica l‚Äôosservazione \\(i\\)-esima della variabile risposta, per \\(i=1, \\dots, n\\). Ogni osservazione √® associata a un vettore di variabili esplicative \\((x_1, \\dots, x_p)\\). La relazione che vogliamo esaminare √® tra la probabilit√† di successo \\(\\pi_i\\) e la variabile esplicativa, espressa dalla formula:\n\\[\nP(Y=1 \\mid X=x_i) = \\pi_i.\n\\]\nIn questo contesto, la variabile dipendente \\(Y\\) segue una distribuzione di Bernoulli, con i seguenti possibili valori:\n\\[\ny_i =\n\\begin{cases}\n    1 & \\text{per un successo (per l'osservazione $i$-esima)},\\\\\n    0 & \\text{per un fallimento}.\n\\end{cases}\n\\]\nLe probabilit√† associate a questi valori sono rispettivamente \\(\\pi\\) per il successo e \\(1-\\pi\\) per il fallimento:\n\\[\n\\begin{aligned}\n    P(Y_i = 1) &= \\pi,\\\\\n    P(Y_i = 0) &= 1-\\pi.\n\\end{aligned}\n\\]\nQuesto modello permette di studiare come le variabili esplicative influenzino la probabilit√† di un evento binario, come il successo o il fallimento.\nLa media condizionata \\(\\mathbb{E}(Y \\mid X=x)\\) in una popolazione pu√≤ essere vista come la proporzione di valori 1 per un dato punteggio \\(x\\) sulla variabile esplicativa, ovvero la probabilit√† condizionata \\(\\pi_i\\) di osservare l‚Äôesito \\(Y = 1\\) in corrispondenza di un certo livello \\(X\\):\n\\[\n\\pi_i \\equiv P(Y = 1 \\mid X = x).\n\\]\nIl valore atteso diventa:\n\\[\n\\mathbb{E}(Y \\mid x) = \\pi_i.\n\\]\nSe \\(X\\) √® una variabile discreta, possiamo calcolare la proporzione di \\(Y=1\\) per ogni valore di \\(X=x\\) nel campione. Queste proporzioni rappresentano una stima non parametrica della funzione di regressione di \\(Y\\) su \\(X\\), e possono essere stimate tramite tecniche di smoothing.\nPer valori bassi della variabile \\(X\\), la proporzione condizionata di valori \\(Y=1\\) sar√† prossima allo 0. Per valori alti di \\(X\\), la proporzione di valori \\(Y=1\\) sar√† prossima a 1. A livelli intermedi di \\(X\\), la curva di regressione non parametrica gradualmente approssima i valori 0 e 1 seguendo un andamento sigmoidale.\nPer illustrare, generiamo dei dati simulati con una variabile dicotomica \\(Y\\) e una variabile discreta \\(X\\) nei quali la probabilit√† che \\(Y=1\\) aumenta con il valore di \\(X\\).\n\n# Simulate data\nnp.random.seed(42)  # For reproducibility\nn = 1000  # Number of samples\nX = np.random.randint(0, 10, size=n)  # Discrete independent variable with levels from 0 to 9\n\n# Define the logistic model\ndef logistic(x, beta0, beta1):\n    return expit(beta0 + beta1 * x)\n\nbeta0 = -2\nbeta1 = 1  # Increase the steepness of the curve\np = logistic(X, beta0, beta1)\n\n# Generate dichotomous outcome variable Y\nY = np.random.binomial(1, p, size=n)\n\n# Compute mean success rate and standard error for each level of X\ndf = pd.DataFrame({'X': X, 'Y': Y})\nmean_success_rate = df.groupby('X')['Y'].mean()\nstandard_error = df.groupby('X')['Y'].sem()\n\n# Plot mean success rates with standard errors\nsns.pointplot(x=mean_success_rate.index, y=mean_success_rate.values, capsize=0.1, linestyle='none')  # Use linestyle='none' to avoid connecting lines\nplt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr=standard_error.values, fmt='o', color='blue')\n\n# Fit a non-parametric smoother (LOESS) and plot the curve\nlowess_smoothed = lowess(mean_success_rate.values, mean_success_rate.index, frac=0.3)\n\nplt.plot(lowess_smoothed[:, 0], lowess_smoothed[:, 1], color='red', label='Non-parametric Smoother')\n\n# Customizing the plot\nplt.xlabel('X')\nplt.ylabel('Mean Success Rate')\nplt.grid(True)\n\n# Display the plot\nplt.show()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.2 Modello Lineare nelle Probabilit√†",
    "text": "74.2 Modello Lineare nelle Probabilit√†\nPotremmo pensare di usare una funzione lineare per rappresentare la dipendenza di \\(Y\\) da \\(X\\). Introduciamo un modello lineare con le seguenti assunzioni standard:\n\\[\nY_i = \\alpha + \\beta X_i + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) segue una distribuzione normale con media 0 e varianza 1 (\\(\\varepsilon_i \\sim \\mathcal{N}(0, 1)\\)) e gli errori \\(\\varepsilon_i\\) e \\(\\varepsilon_j\\) sono indipendenti per ogni \\(i \\neq j\\). Il valore atteso di \\(Y_i\\) √® quindi \\(\\mathbb{E}(Y_i) = \\alpha + \\beta X_i\\), portando a:\n\\[\n\\pi_i = \\alpha + \\beta X_i.\n\\]\nQuesto √® noto come modello lineare nelle probabilit√† (linear probability model). Tuttavia, questo approccio presenta una limitazione significativa: non garantisce che i valori predetti di \\(\\pi_i\\) siano confinati nell‚Äôintervallo [0,1], come richiesto per le probabilit√†.\n\n74.2.1 Problemi di Normalit√†\nConsiderando che \\(Y_i\\) pu√≤ assumere solo i valori 0 o 1, i residui \\(\\varepsilon_i\\) risultano anch‚Äôessi dicotomici e quindi non possono seguire una distribuzione normale. Ad esempio, se \\(Y_i=1\\) con probabilit√† \\(\\pi_i\\), il residuo sar√†:\n\\[\n\\varepsilon_i = 1 - \\mathbb{E}(Y_i) = 1 - (\\alpha + \\beta X_i) = 1 - \\pi_i.\n\\]\nSe, invece, \\(Y_i=0\\) con probabilit√† \\(1-\\pi_i\\), il residuo sar√†:\n\\[\n\\varepsilon_i = 0 - \\mathbb{E}(Y_i) = 0 - (\\alpha + \\beta X_i) = - \\pi_i.\n\\]\nTuttavia, se la dimensione del campione √® grande, il teorema del limite centrale pu√≤ mitigare l‚Äôimportanza dell‚Äôassunzione di normalit√† per le stime dei minimi quadrati.\n\n\n74.2.2 Problematiche di Eteroschedasticit√†\nUtilizzare il metodo dei minimi quadrati pu√≤ essere inappropriato in questo contesto poich√© la varianza dei residui non √® costante ma dipende dalla media, e quindi dalla variabile \\(X\\). Assumendo che il modello sia lineare, abbiamo che \\(\\mathbb{E}(\\varepsilon_i)=0\\). Sfruttando le relazioni discusse in precedenza, la varianza dei residui si calcola come:\n\\[\n\\mathbb{V}(\\varepsilon_i) = (1-\\pi_i)\\pi_i.\n\\]\nConsideriamo che la varianza dei residui \\(\\varepsilon_i\\) pu√≤ essere espressa come:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2,\n\\]\ndove \\(\\mathbb{E}(\\varepsilon_i^2)\\) √® il valore atteso del quadrato dei residui e \\(\\mathbb{E}(\\varepsilon_i)^2\\) √® il quadrato del valore atteso dei residui.\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i^2) &= \\mathbb{E}[(Y_i - \\mathbb{E}(Y_i))^2] \\\\\n&= \\mathbb{E}[(Y_i - \\pi_i)^2] \\\\\n&= \\mathbb{E}[(Y_i^2 - 2Y_i\\pi_i + \\pi_i^2)] \\\\\n&= \\mathbb{E}(Y_i^2) - 2\\mathbb{E}(Y_i\\pi_i) + \\mathbb{E}(\\pi_i^2) \\\\\n&= \\mathbb{E}(Y_i) - 2\\mathbb{E}(Y_i\\pi_i) + \\pi_i^2 \\\\\n&= \\pi_i - 2\\pi_i^2 + \\pi_i^2 \\\\\n&= \\pi_i - \\pi_i^2 \\\\\n&= \\pi_i(1 - \\pi_i)\n\\end{align*}\n\\]\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i)^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i)^2 &= (\\mathbb{E}(Y_i - \\mathbb{E}(Y_i)))^2 \\\\\n&= (\\mathbb{E}(Y_i - \\pi_i))^2 \\\\\n&= (0)^2 \\\\\n&= 0\n\\end{align*}\n\\]\nQuindi, sostituendo questi risultati nella formula della varianza dei residui, otteniamo:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2 = \\pi_i(1 - \\pi_i)\n\\]\nQuindi, abbiamo dimostrato che la varianza dei residui nel modello lineare nelle probabilit√† pu√≤ essere espressa come \\((1-\\pi_i)\\pi_i\\).\nDato che \\(\\pi_i\\) dipende da \\(x\\), ci√≤ significa che la varianza non √® costante in funzione di \\(x\\). Questa eteroschedasticit√† dei residui rappresenta un problema per le stime dei minimi quadrati nel modello lineare, specialmente quando le probabilit√† \\(\\pi_i\\) sono vicine a 0 o 1.\n\n\n74.2.3 Linearit√†\nIl maggiore inconveniente connesso all‚Äôadozione del modello lineare nelle probabilit√† deriva dal fatto che la stima della probabilit√† di successo, \\(P(\\hat{Y}_i=1)=\\hat{\\pi}_i\\), non √® necessariamente compresa nell‚Äôintervallo \\((0,1)\\), ma pu√≤ essere sia negativa sia maggiore di 1. Nel caso dell‚Äôesempio in discussione, ci√≤ significa che la retta dei minimi quadrati produce valori attesi \\(\\hat{\\pi}\\) inferiori a 0 per bassi valori della variabile \\(X\\) e valori \\(\\hat{\\pi}\\) superiori a 1 per valori di \\(X\\) alti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†-vincolato",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilit√†-vincolato",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.3 Modello Lineare nelle Probabilit√† Vincolato",
    "text": "74.3 Modello Lineare nelle Probabilit√† Vincolato\nUna soluzione per mantenere \\(\\pi\\) all‚Äôinterno dell‚Äôintervallo (0, 1) √® la seguente specificazione del modello:\n\\[\n\\pi=\n\\begin{cases}\n  0                           &\\text{se $\\alpha + \\beta X &lt; 0$},\\\\\n  \\alpha + \\beta X           &\\text{se $0 \\leq \\alpha + \\beta X \\leq 1$},\\\\\n  1 &\\text{se $\\alpha + \\beta X &gt; 1$}.\n\\end{cases}\n\\]\nQuesto modello lineare nelle probabilit√† vincolato mostra alcune instabilit√†, soprattutto a causa della sua dipendenza critica dai valori estremi di \\(\\pi\\), dove assume i valori 0 o 1. La linearit√† di \\(\\pi = \\alpha + \\beta X\\) si basa fortemente sui punti in cui si verificano questi estremi. In particolare, la stima di \\(\\pi = 0\\) pu√≤ essere influenzata dal valore minimo di \\(X\\) associato a \\(Y=1\\), mentre la stima di \\(\\pi = 1\\) pu√≤ dipendere dal valore massimo di \\(X\\) per cui \\(Y=0\\). Questi valori estremi tendono a variare significativamente tra diversi campioni e possono diventare pi√π estremi all‚Äôaumentare della dimensione del campione.\nLa presenza di pi√π variabili esplicative (\\(k \\geq 2\\)) complica ulteriormente la stima dei parametri del modello. Inoltre, il modello mostra un cambiamento brusco nella pendenza della curva di regressione ai punti estremi (0 e 1 di \\(\\pi\\)), risultando poco realistico in molte situazioni pratiche. Questo rende il modello meno adatto a descrivere relazioni complesse e gradualmente variabili tra \\(\\pi\\) e \\(X\\).\nUna funzione che modella una relazione pi√π fluida e continua tra \\(\\pi\\) e \\(X\\) sarebbe pi√π realistica e rappresentativa delle dinamiche osservate. Questo motiva la preferenza per modelli alternativi, come il modello di regressione logistica, che tende a fornire una rappresentazione pi√π accurata e realistica delle interazioni tra variabili dicotomiche e esplicative.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.4 Regressione Logistica",
    "text": "74.4 Regressione Logistica\nUn metodo efficace per gestire il problema del vincolo sulle probabilit√† √® specificare modelli non direttamente per le probabilit√† stesse, ma per una loro trasformazione che elimina tale vincolo. Invece di definire un modello lineare per la probabilit√† condizionata \\(\\pi_i\\), si pu√≤ specificare un modello lineare per il logaritmo degli odds (logit):\n\\[\n\\eta_i = \\log_e \\frac{\\pi_i}{1-\\pi_i} = \\alpha + \\beta x_i,\n\\]\nQuesto approccio non presenta problemi poich√© il logit \\(\\eta_i\\) √® sempre un numero reale, permettendo di modellare una trasformazione lineare di \\(\\pi_i\\). La trasformazione inversa, che ci permette di ottenere \\(\\pi_i\\) da \\(\\eta_i\\), √® data dalla funzione logistica:\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}}.\n\\]\n\n74.4.1 Vantaggi della Regressione Logistica\nLa regressione logistica presenta diversi vantaggi rispetto al modello lineare delle probabilit√†:\n\nVincolo delle Probabilit√†: La trasformazione logistica assicura che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell‚Äôintervallo [0,1].\nInterpretabilit√† degli Odds Ratio: Il coefficiente \\(\\beta\\) pu√≤ essere interpretato come il cambiamento logaritmico negli odds di successo associato a un incremento unitario di \\(X\\). In altre parole, \\(e^\\beta\\) rappresenta il fattore di aumento (o diminuzione) degli odds per un incremento unitario della variabile indipendente.\nGestione dell‚ÄôEteroschedasticit√†: La forma funzionale della varianza del modello di regressione logistica \\(\\pi_i (1 - \\pi_i)\\) √® intrinsecamente considerata nel processo di stima tramite il metodo della massima verosimiglianza.\n\n\n\n74.4.2 Esempio Pratico\nPer illustrare l‚Äôapplicazione della regressione logistica, consideriamo nuovamente i dati simulati precedentemente. Applichiamo il modello di regressione logistica ai dati e tracciamo la curva logistica risultante:\n\n# Plot mean success rates with standard errors\nsns.pointplot(x=mean_success_rate.index, y=mean_success_rate.values, capsize=0.1, linestyle='none')  # Use linestyle='none' to avoid connecting lines\nplt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr=standard_error.values, fmt='o', color='blue')\n\n# Fit logistic regression model and plot logistic curve\nX_design = sm.add_constant(X)\nlogit_model = sm.Logit(Y, X_design).fit()\nx_vals = np.linspace(X.min(), X.max(), 100)\ny_vals = logit_model.predict(sm.add_constant(x_vals))\n\nplt.plot(x_vals, y_vals, color='red', label='Logistic Regression Curve')\n\n# Customizing the plot\nplt.xlabel('X')\nplt.ylabel('Mean Success Rate')\nplt.grid(True)\n\n# Display the plot\nplt.show()\n\nOptimization terminated successfully.\n         Current function value: 0.289256\n         Iterations 8\n\n\n\n\n\n\n\n\n\nQuesto esempio dimostra come la regressione logistica possa essere utilizzata per modellare una variabile dicotomica in funzione di una variabile indipendente. La curva logistica risultante rappresenta adeguatamente la relazione tra \\(X\\) e la probabilit√† di successo \\(Y\\), garantendo che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell‚Äôintervallo [0,1].\nNelle sezioni seguenti, descriveremo in dettaglio il modello di regressione logistica utilizzato per generare la curva logistica mostrata nella figura precedente. Inizieremo chiarendo i concetti di odds e logit e la loro relazione con le probabilit√†.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#componente-sistematica",
    "href": "chapters/glm/03_stan_logistic_regr.html#componente-sistematica",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.5 Componente Sistematica",
    "text": "74.5 Componente Sistematica\nLa componente sistematica mette in relazione un vettore (\\(\\eta_1, \\eta_2, \\dots, \\eta_k\\)) con le variabili esplicative mediante un modello lineare. Sia \\(X_{ij}\\) il valore della \\(j\\)-esima variabile esplicativa (\\(j=1, 2, \\dots, p\\)) per l‚Äô\\(i\\)-esima osservazione (\\(i=1, \\dots, k\\)). Allora\n\\[\n\\eta_i = \\sum_j \\beta_j X_{ij}.\n\\]\nQuesta combinazione lineare di variabili esplicative √® chiamata il predittore lineare. Un \\(X_{ij}=1, \\forall i\\) viene utilizzato per il coefficiente dell‚Äôintercetta del modello (talvolta denotata da \\(\\alpha\\)).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#componente-aleatoria",
    "href": "chapters/glm/03_stan_logistic_regr.html#componente-aleatoria",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.6 Componente Aleatoria",
    "text": "74.6 Componente Aleatoria\nLa componente aleatoria del modello suppone l‚Äôesistenza di \\(k\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_k\\), ciascuna delle quali viene trattata come la realizzazione di una variabile casuale \\(Y_i\\). Si assume che \\(Y_i\\) abbia una distribuzione binomiale:\n\\[\nY_i \\sim Bin(n_i, \\pi_i)\n\\]\ncon parametri \\(n_i\\) e \\(\\pi_i\\). Per dati individuali (uno per ciascun valore \\(x_i\\)), \\(n_i=1,\n    \\forall i\\).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#funzione-legame",
    "href": "chapters/glm/03_stan_logistic_regr.html#funzione-legame",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.7 Funzione Legame",
    "text": "74.7 Funzione Legame\nLa funzione legame \\(g(\\cdot)\\) mette in relazione il valore atteso della variabile risposta \\(Y_i\\) con la componente sistematica \\(\\eta_i\\) del modello. Abbiamo visto che \\(\\mathbb{E}(Y_i)=\\pi_i\\). Che relazione c‚Äô√® tra \\(\\pi_i\\) e il predittore lineare \\(\\eta_i= \\alpha + \\sum_j  \\beta_j X_{ij}\\)? La risposta a questa domanda √® data dalla funzione legame:\n\\[\n\\eta_i = g(\\pi_i) = \\ln{\\frac{\\pi_i}{1-\\pi_i}}\n\\]\nSi noti che la funzione legame non trasforma la variabile risposta \\(Y_i\\) ma bens√¨ il suo valore atteso \\(\\pi_i\\).\nLa funzione legame √® invertibile: anzich√© trasformare il valore atteso nel predittore lineare si pu√≤ trasformare il predittore lineare nel valore atteso \\(\\pi_i\\):\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}} =  \\frac{e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}{1+e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}.\n\\]\nSi ottiene cos√¨ un modello non lineare per le probabilit√† \\(\\pi_i\\).\nIn conclusione, la regressione logistica estende il concetto di regressione lineare per modellare le probabilit√† condizionate di esiti Bernoulliani $ Y \\(, adoperando la funzione logistica come collegamento per trasformare relazioni lineari tra predittori (\\) _i = _0 + 1 X{i} $) in probabilit√† nell‚Äôintervallo [0,1]. Questo metodo permette di passare dalla modellazione diretta della probabilit√† $ p $ alla modellazione di una funzione di tale probabilit√† attraverso una relazione lineare, impiegando la funzione logit come funzione di collegamento.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione",
    "href": "chapters/glm/03_stan_logistic_regr.html#coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.8 Coefficienti del Modello nella Regressione Logistica e la loro Interpretazione",
    "text": "74.8 Coefficienti del Modello nella Regressione Logistica e la loro Interpretazione\nUn aspetto cruciale per comprendere la relazione tra le variabili predittive e una variabile di risposta binaria √® l‚Äôinterpretazione dei coefficienti del modello.\n\n74.8.1 Interpretazione sui Logit\nNella regressione logistica, ogni coefficiente \\(\\beta_j\\) del modello pu√≤ essere interpretato direttamente in termini di log-odds, che sono i logaritmi delle probabilit√† di ottenere un evento con esito positivo (\\(y=1\\)). Quando interpretiamo i coefficienti:\n\nCoefficienti Positivi (\\(\\beta_j &gt; 0\\)): Un coefficiente positivo indica che c‚Äô√® una relazione diretta tra il predittore e l‚Äôaumento dei log-odds di osservare l‚Äôevento di interesse. Questo significa che all‚Äôaumentare del valore del predittore, la probabilit√† dell‚Äôevento di interesse aumenta.\nCoefficienti Negativi (\\(\\beta_j &lt; 0\\)): Al contrario, un coefficiente negativo indica una relazione inversa tra il predittore e la probabilit√† logistica dell‚Äôevento. Con l‚Äôaumentare del predittore, i log-odds e quindi la probabilit√† dell‚Äôevento diminuiscono.\n\n\n\n74.8.2 Interpretazione sugli Odds Ratio (OR)\nL‚Äôinterpretazione dei coefficienti nella regressione logistica pu√≤ estendersi agli odds ratio (OR), che forniscono informazioni sulla relazione tra i predittori e la probabilit√† dell‚Äôevento di interesse. Per esempio, consideriamo un modello con un predittore continuo \\(X\\) e un coefficiente \\(\\beta_1 = 0.50\\). Il logaritmo naturale dell‚Äôodds ratio, \\(\\log(OR) = 0.50\\), viene esponenziato per ottenere:\n\\[\nOR = e^{0.50} \\approx 1.65.\n\\]\nQuesto risultato indica che per un‚Äôunit√† di incremento in \\(X\\), l‚Äôodds di sperimentare l‚Äôevento di interesse √® circa 1.65 volte maggiore. In altre parole, l‚Äôincremento di una unit√† nel predittore \\(X\\) aumenta l‚Äôodds di sperimentare l‚Äôevento di interesse di circa il 65%. Viceversa, un coefficiente negativo indicherebbe una diminuzione dell‚Äôodds per un incremento di una unit√† in \\(X\\).\n\n\n74.8.3 Interpretazione sulla Scala delle Probabilit√†\nLa regressione logistica consente di interpretare i coefficienti non solo in termini di log-odds, ma anche relativamente alle variazioni di probabilit√†. Consideriamo un modello che predice la probabilit√† di superare un esame basandosi sul numero di ore di studio (\\(X\\)).\nSupponiamo che il coefficiente associato alle ore di studio sia \\(\\beta_1 = 0.5\\). Questo valore indica che ogni ora aggiuntiva di studio incrementa i log-odds di successo nell‚Äôesame. Per comprendere l‚Äôimpatto di un‚Äôora in pi√π di studio sulla probabilit√† di successo, possiamo utilizzare la seguente formula:\n\\[\n\\Delta p = \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot (X_1 + 1))}} - \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot X_1)}}.\n\\]\nQuesta formula calcola la differenza tra la probabilit√† di successo dopo aver aggiunto un‚Äôora di studio e la probabilit√† di successo prima di tale aggiunta. In termini pratici, \\(\\Delta p\\) rappresenta l‚Äôincremento della probabilit√† di superare l‚Äôesame attribuibile a un‚Äôora supplementare di studio. Questa interpretazione √® cruciale per valutare quantitativamente l‚Äôeffetto delle ore di studio sulla probabilit√† di superare l‚Äôesame.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#un-esempio-concreto",
    "href": "chapters/glm/03_stan_logistic_regr.html#un-esempio-concreto",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.9 Un esempio concreto",
    "text": "74.9 Un esempio concreto\nConsideriamo nuovamente i dati simulati in precedenza\n\ndf.head()\n\n\n\n\n\n\n\n\n\nX\nY\n\n\n\n\n0\n6\n1\n\n\n1\n3\n1\n\n\n2\n7\n1\n\n\n3\n4\n1\n\n\n4\n6\n1\n\n\n\n\n\n\n\n\nStimeremo ora i coefficienti del modello di regressione logistica usando Stan. Definiamo i dati nel formato atteso da Stan:\n\nstan_data = {\n    \"N\" : df.shape[0],\n    \"y\" : df[\"Y\"],\n    \"x\" : df[\"X\"] \n}\n\nCompiliamo il modello di regressione logistica e stampiamo lo script Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"logistic_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:47:02 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression\n12:47:13 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression\n\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] x;\n  array[N] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  real alpha;\n  real beta;\n}\nmodel {\n  y ~ bernoulli_logit(alpha + beta * x);\n}\n\n\n\nEseguiamo il campionamento MCMC:\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n12:47:36 - cmdstanpy - INFO - CmdStan start processing\n12:47:36 - cmdstanpy - INFO - Chain [1] start processing\n12:47:36 - cmdstanpy - INFO - Chain [2] start processing\n12:47:36 - cmdstanpy - INFO - Chain [3] start processing\n12:47:36 - cmdstanpy - INFO - Chain [4] start processing\n12:47:37 - cmdstanpy - INFO - Chain [3] done processing\n12:47:37 - cmdstanpy - INFO - Chain [2] done processing\n12:47:37 - cmdstanpy - INFO - Chain [4] done processing\n12:47:37 - cmdstanpy - INFO - Chain [1] done processing\n\n\nEsaminiamo le tracce:\n\n_ = az.plot_trace(fit)\n\n\n\n\n\n\n\n\nOtteniamo le stime a posteriori dei parametri:\n\naz.summary(fit, var_names=([\"alpha\", \"beta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-1.778\n0.18\n-2.132\n-1.436\n0.004\n0.003\n2261.0\n2634.0\n1.0\n\n\nbeta\n1.004\n0.07\n0.869\n1.144\n0.001\n0.001\n2305.0\n2682.0\n1.0\n\n\n\n\n\n\n\n\nCreiamo un nuovo DataFrame con 100 valori \\(x\\) nell‚Äôintervallo [0, 9]:\n\nnew_data = pd.DataFrame({\n    \"x\": np.linspace(0, 9, 100)\n})\nnew_data\n\n\n\n\n\n\n\n\n\nx\n\n\n\n\n0\n0.000000\n\n\n1\n0.090909\n\n\n2\n0.181818\n\n\n3\n0.272727\n\n\n4\n0.363636\n\n\n...\n...\n\n\n95\n8.636364\n\n\n96\n8.727273\n\n\n97\n8.818182\n\n\n98\n8.909091\n\n\n99\n9.000000\n\n\n\n\n100 rows √ó 1 columns\n\n\n\n\nOtteniamo le medie a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\nalpha = fit.stan_variable('alpha').mean()\nbeta = fit.stan_variable('beta').mean() \nprint(alpha, beta)\n\n-1.7784477 1.003503126\n\n\nCalcoliamo i logit per ogni valore $ x $ nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilit√† √® una funzione lineare di $ x $:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\n\nlogit_p = alpha + new_data['x'] * beta\nlogit_p\n\n0    -1.778448\n1    -1.687220\n2    -1.595993\n3    -1.504765\n4    -1.413537\n        ...   \n95    6.888170\n96    6.979398\n97    7.070625\n98    7.161853\n99    7.253080\nName: x, Length: 100, dtype: float64\n\n\nEsaminiamo graficamente la relazione tra il logit \\(\\log \\left( \\frac{p}{1-p} \\right)\\) e \\(x\\):\n\nnew_data['logit_p'] = logit_p\n\nplt.plot(new_data['x'], new_data['logit_p'], linestyle='-', color='blue')  # Plot con marcatori e linea\n\nplt.title('Logit Predetti in Funzione di X')  # Titolo del grafico\nplt.xlabel('X')  # Etichetta asse x\nplt.ylabel('Logit')  # Etichetta asse y\nplt.show() \n\n\n\n\n\n\n\n\nCalcoliamo i logit per ogni valore $ x $ nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilit√† √® una funzione lineare di $ x $. Per ottenere la probabilit√† $ p $ dalla trasformazione del logit, possiamo utilizzare la funzione logistica inversa. Svolgiamo la conversione:\n\nCalcoliamo il logit per ogni valore di $ x $:\n\\[\n\\text{logit}_p = \\alpha + \\beta x\n\\]\nApplichiamo la funzione logistica inversa (antilogit) per ottenere la probabilit√† $ p $:\n\\[\np = \\frac{e^{\\text{logit}_p}}{1 + e^{\\text{logit}_p}} = \\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}\n\\]\n\nQuesta formula ci permette di trasformare il logit in una probabilit√† compresa tra 0 e 1 per ogni valore di $ x $ nel dataset new_data.\n\nprob = np.exp(logit_p) / (1 + np.exp(logit_p))\n# Aggiungi le probabilit√† calcolate a `new_data`\nnew_data['prob'] = prob\nnew_data.head()\n\n\n\n\n\n\n\n\n\nx\nlogit_p\nprob\n\n\n\n\n0\n0.000000\n-1.778448\n0.144495\n\n\n1\n0.090909\n-1.687220\n0.156142\n\n\n2\n0.181818\n-1.595993\n0.168542\n\n\n3\n0.272727\n-1.504765\n0.181716\n\n\n4\n0.363636\n-1.413537\n0.195677\n\n\n\n\n\n\n\n\n\nplt.plot(new_data['x'], new_data['prob'], linestyle='-', color='blue')  # Plot con marcatori e linea\n\nplt.title('Probabilit√† Predetta in Funzione di X')  # Titolo del grafico\nplt.xlabel('X')  # Etichetta asse x\nplt.ylabel('Probabilit√† Predetta')  # Etichetta asse y\nplt.show() \n\n\n\n\n\n\n\n\n\n74.9.1 Interpretazione dei Coefficienti nella Regressione Logistica\nAbbiamo stimato i coefficienti \\(\\alpha\\) e \\(\\beta\\) dal modello di regressione logistica con i seguenti valori: - \\(\\alpha = -1.7784477\\) - \\(\\beta = 1.003503126\\)\nEsamineremo ora l‚Äôinterpretazione di questi coefficienti sulla scala dei logit, dell‚Äôodds ratio e delle probabilit√†.\n\n74.9.1.1 La regola del dividere per 4\nLa regola del dividere per 4 √® un metodo utile per interpretare i coefficienti della regressione logistica. Dividendo il coefficiente \\(\\beta\\) per 4, si ottiene un‚Äôapprossimazione della massima variazione nella probabilit√† \\(\\Pr(y = 1)\\) per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.\nLa curva logistica √® pi√π ripida al centro, dove $ + x = 0 $ e quindi $ ^{-1}(+ x) = 0.5 $. In questo punto, la pendenza della curva, ovvero la derivata della funzione logistica, √® massima e raggiunge il valore $ / 4 $.\nPer esempio, nel modello con $ = -1.778 $ e $ = 1.003 $, dividendo \\(\\beta\\) per 4 otteniamo circa 0.25. Questo valore rappresenta l‚Äôaumento massimo, in termini di probabilit√†, che possiamo aspettarci per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.\nIn sintesi, la regola del dividere per 4 semplifica l‚Äôinterpretazione dei coefficienti della regressione logistica, fornendo un‚Äôindicazione intuitiva di come la variabile indipendente influisce sulla probabilit√† dell‚Äôevento di interesse.\n\n\n74.9.1.2 Scala dei Logit\nNella regressione logistica, la funzione logit rappresenta una relazione lineare tra il logit della probabilit√† di successo e la variabile indipendente \\(X\\):\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\nCon i coefficienti stimati, la funzione logit diventa:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot x\n\\]\n\n\\(\\alpha = -1.7784477\\): Questo √® l‚Äôintercetta del modello, il valore del logit quando \\(x = 0\\). Indica che, quando \\(x\\) √® 0, il logit della probabilit√† di successo √® \\(-1.7784477\\).\n\\(\\beta = 1.003503126\\): Questo √® il coefficiente di \\(x\\) e rappresenta il cambiamento nel logit per ogni incremento unitario in \\(x\\). In altre parole, per ogni incremento di 1 unit√† in \\(x\\), il logit della probabilit√† di successo aumenta di circa \\(1.003503126\\).\n\n\n\n74.9.1.3 Odds Ratio\nL‚Äôodds ratio (OR) misura il cambiamento relativo nelle odds di successo per un incremento unitario in \\(x\\). √à ottenuto esponenziando il coefficiente \\(\\beta\\):\n\\[\n\\text{OR} = e^{\\beta} = e^{1.003503126} \\approx 2.728\n\\]\nUn odds ratio di circa \\(2.728\\) indica che, per ogni incremento unitario in \\(x\\), le odds di successo aumentano di circa \\(172.8\\%\\). In altre parole, l‚Äôodds di successo √® circa \\(2.728\\) volte maggiore per ogni unit√† aggiuntiva di \\(x\\).\n\n\n74.9.1.4 Scala delle Probabilit√†\nPer interpretare l‚Äôeffetto di \\(\\beta\\) sulla scala delle probabilit√†, possiamo considerare come la probabilit√† \\(p\\) cambia in corrispondenza di specifici valori di \\(x\\).\n\nQuando \\(x = 0\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-1.7784477}}{1 + e^{-1.7784477}} \\approx \\frac{0.169} {1 + 0.169} \\approx 0.144\n\\]\nQuindi, la probabilit√† di successo quando \\(x = 0\\) √® circa \\(14.4\\%\\).\n\nPer un incremento unitario in \\(x\\), diciamo \\(x = 1\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot 1 \\approx -0.774944574\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-0.774944574}}{1 + e^{-0.774944574}} \\approx \\frac{0.461} {1 + 0.461} \\approx 0.316\n\\]\nQuindi, la probabilit√† di successo quando \\(x = 1\\) √® circa \\(31.6\\%\\). Tuttavia questo incremento non √® costante per i diversi livelli \\(x\\) e il modo pi√π semplice per mostrare la relazione tra probabilit√† di successo e la variabile \\(X\\) √® quella di generare un grafico come quello che abbimo prodotto in precedenza.\n\n\n\n74.9.2 Riassunto\n\nScala dei Logit: Un incremento unitario in \\(x\\) aumenta il logit della probabilit√† di successo di \\(1.003503126\\).\nOdds Ratio: Le odds di successo aumentano di circa \\(2.728\\) volte per ogni incremento unitario in \\(x\\).\nScala delle Probabilit√†: Quando \\(x\\) passa da 0 a 1, la probabilit√† di successo aumenta da circa \\(14.4\\%\\) a \\(31.6\\%\\). Per la relazione tra ciascun livello \\(x\\) e la probabilit√† di successo √® necessario generare un grafico.\n\nQuesta analisi dimostra come i coefficienti del modello di regressione logistica possono essere interpretati su diverse scale, fornendo un quadro completo della relazione tra la variabile indipendente e la probabilit√† di successo.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-solo-lintercetta",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-solo-lintercetta",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.10 Regressione logistica con solo l‚Äôintercetta",
    "text": "74.10 Regressione logistica con solo l‚Äôintercetta\nLa regressione lineare con solo l‚Äôintercetta √® equivalente a stimare una media e la regressione lineare con un singolo predittore binario √® equivalente a stimare una differenza tra medie. Allo stesso modo, la regressione logistica con solo l‚Äôintercetta √® equivalente alla stima di una proporzione.\nEcco un esempio. Un campione casuale di 50 persone viene testato e 10 di loro manifestano una certa caratteristica psicologica. La proporzione √® 0.20 con errore standard $ = 0.06 $. In alternativa, possiamo impostare questo come regressione logistica usando Bambi in Python:\n\n# Dati\ny = [0]*40 + [1]*10\ndf = pd.DataFrame({'y': y})\n\n# Modello\nmodel = bmb.Model('y ~ 1', data=df, family='bernoulli')\nfit = model.fit(nuts_sampler=\"numpyro\", random_seed=123)\n\nModeling the probability that y==1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(fit, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.39\n0.35\n-2.05\n-0.73\n0.01\n0.01\n1524.26\n1636.18\n1.0\n\n\n\n\n\n\n\n\nPossiamo trasformare la previsione nella scala delle probabilit√† e ottenere un risultato che √® essenzialmente lo stesso della stima classica con incertezza di 0.20 ¬± 0.06.\n\n# Given values\nintercept = -1.4\nerror = 0.35\n\n# Calculate logit^-1(-1.41)\np_hat = expit(intercept)\n\n# Calculate logit^-1(-1.41 ¬± 0.36)\nlower_bound = expit(intercept - error)\nupper_bound = expit(intercept + error)\n\nprint(f'p_hat: {p_hat:.3f}, Lower bound: {lower_bound:.3f}, Upper bound: {upper_bound:.3f}')\n\np_hat: 0.198, Lower bound: 0.148, Upper bound: 0.259\n\n\nLe stime classiche e quelle della regressione logistica differiscono leggermente, in parte perch√© Bambi usa una distribuzione a priori e in parte perch√© l‚Äôerrore standard classico √® solo un‚Äôapprossimazione all‚Äôincertezza inferenziale derivante dai dati discreti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "title": "74¬† Regressione logistica con Stan",
    "section": "74.11 Regressione logistica con un singolo predittore binario",
    "text": "74.11 Regressione logistica con un singolo predittore binario\nLa regressione logistica su una variabile indicatrice √® equivalente a un confronto di proporzioni. Per un esempio semplice, consideriamo i test per una malattia su campioni provenienti da due popolazioni diverse, dove 10 su 50 individui della popolazione A risultano positivi, rispetto a 20 su 60 della popolazione B. La stima classica √® 0.13 con errore standard di 0.08. Ecco come impostare questo caso come regressione logistica utilizzando Bambi in Python:\n\n# Dati\nx = [0] * 50 + [1] * 60\ny = [0] * 40 + [1] * 10 + [0] * 40 + [1] * 20\ndf = pd.DataFrame({'x': x, 'y': y})\n\n# Definire il modello\nmodel = bmb.Model('y ~ x', data=df, family='bernoulli')\n\n# Adattare il modello con un seed\nfit = model.fit(nuts_sampler=\"numpyro\", random_seed=123)\n\nModeling the probability that y==1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Visualizzare i risultati del fit\naz.summary(fit, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.41\n0.36\n-2.07\n-0.74\n0.01\n0.01\n2661.46\n2476.84\n1.0\n\n\nx\n0.71\n0.45\n-0.09\n1.60\n0.01\n0.01\n3115.18\n2554.46\n1.0\n\n\n\n\n\n\n\n\nPer ottenere l‚Äôinferenza per la differenza di probabilit√†, confrontiamo le previsioni sulla scala delle probabilit√† per $ x = 0 $ e $ x = 1 $:\n\n# Given values\nintercept = -1.41\nslope = 0.71\n\n# Calculate probabilities for x = 0 and x = 1\nlogit_0 = intercept\nlogit_1 = intercept + slope\n\nprob_0 = expit(logit_0)\nprob_1 = expit(logit_1)\n\n# Calculate the difference in probabilities\ndiff = prob_1 - prob_0\n\nprob_0, prob_1, diff\nprint(f'prob_0: {prob_0:.3f}, prob_1: {prob_1:.3f}, difference: {diff:.3f}')\n\nprob_0: 0.196, prob_1: 0.332, difference: 0.136\n\n\nPer l‚Äôerrore standard possiamo eseguire la seguente simulazione:\n\n# Given values\nintercept_mean = -1.41\nslope_mean = 0.71\nintercept_sd = 0.36\nslope_sd = 0.45\n\n# Number of simulations\nnum_simulations = 10000\n\n# Generate samples of the coefficients\nintercept_samples = np.random.normal(intercept_mean, intercept_sd, num_simulations)\nslope_samples = np.random.normal(slope_mean, slope_sd, num_simulations)\n\n# Calculate the corresponding probabilities\nprob_0_samples = expit(intercept_samples)\nprob_1_samples = expit(intercept_samples + slope_samples)\n\n# Calculate the difference in probabilities for each sample\ndiff_samples = prob_1_samples - prob_0_samples\n\n# Calculate the mean and standard deviation of the differences\nmean_diff = np.mean(diff_samples)\nstd_diff = np.std(diff_samples)\n\nmean_diff, std_diff\nprint(f'difference: {mean_diff:.3f}, standard error: {std_diff:.3f}')\n\ndifference: 0.140, standard error: 0.096\n\n\nSebbene abbiamo ottenuto un errore standard di circa 0.095, che √® leggermente diverso dall‚Äôerrore standard di 0.08 menzionato inizialmente, questo valore riflette l‚Äôincertezza nelle stime dei coefficienti fornite. Potrebbero esserci delle variazioni dovute al metodo di campionamento utilizzato. Tuttavia, questi calcoli dimostrano l‚Äôapproccio corretto per stimare l‚Äôerrore standard utilizzando la simulazione Monte Carlo con le deviazioni standard dei coefficienti stimati. ‚Äã",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/03_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "74¬† Regressione logistica con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanp\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanp: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz      : 0.18.0\nseaborn    : 0.13.2\nmatplotlib : 3.9.1\nscipy      : 1.14.0\nstatsmodels: 0.14.2\npandas     : 2.2.2\nnumpy      : 1.26.4\nbambi      : 0.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>74</span>¬† <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html",
    "href": "chapters/glm/04_stan_poisson_regr.html",
    "title": "75¬† Regressione di Poisson con Stan",
    "section": "",
    "text": "Introduzione\nIn questo tutorial, approfondiremo l‚Äôutilizzo di CmdStanPy per condurre un‚Äôanalisi di regressione di Poisson. La regressione di Poisson rappresenta una forma di modello lineare generalizzato impiegato nell‚Äôanalisi di regressione per modellare dati di conteggio. Essa si basa sull‚Äôassunzione che la variabile di risposta Y segua una distribuzione di Poisson, con il logaritmo del suo valore atteso modellabile attraverso una combinazione lineare di parametri sconosciuti.\nIn questo capitolo, dopo aver investigato il calcolo della media a posteriori e dell‚Äôincertezza correlata al tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, ci interrogheremo se vi siano evidenze di una tendenza all‚Äôaumento di tale tasso nel corso del tempo.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html#introduzione-alla-regressione-di-poisson",
    "href": "chapters/glm/04_stan_poisson_regr.html#introduzione-alla-regressione-di-poisson",
    "title": "75¬† Regressione di Poisson con Stan",
    "section": "75.1 Introduzione alla Regressione di Poisson",
    "text": "75.1 Introduzione alla Regressione di Poisson\nUna variabile casuale di Poisson viene utilizzata per modellare conteggi. Poich√© una variabile casuale di Poisson √® un conteggio, il suo valore minimo √® zero e, in teoria, il massimo √® illimitato. L‚Äôobiettivo √® modellare il parametro principale, Œª, il numero medio di occorrenze per unit√† di tempo o spazio, come funzione di una o pi√π covariate.\nIl modello di regressione di Poisson si basa sulla distribuzione di Poisson, una distribuzione probabilistica che descrive eventi con una probabilit√† costante di occorrenza in un intervallo di tempo o spazio definito. La funzione di probabilit√† della distribuzione di Poisson √® definita come:\n\\[ Pr(Y = y) = \\frac{\\mu^y e^{-\\mu}}{y!}, \\]\ndove \\(\\mu\\) rappresenta il numero atteso di eventi nell‚Äôintervallo considerato e \\(y\\) i possibili conteggi di eventi, assumendo valori interi non negativi (0, 1, 2, ‚Ä¶). √à importante notare che in questa distribuzione, il valore atteso \\(\\mu\\) coincide anche con la varianza.\nNel modello di regressione di Poisson, si cerca di collegare il valore atteso di un conteggio, \\(\\mu_i\\), a un insieme di variabili esplicative (come et√†, sesso, sintomi di depressione, ecc.) tramite una relazione funzionale. A differenza dei modelli lineari tradizionali, che possono produrre stime di conteggi negative e quindi non sensate, la regressione di Poisson utilizza una funzione di legame esponenziale per garantire che le stime dei conteggi siano sempre non negative. La relazione √® espressa come segue:\n\\[ \\mu_i = e^{\\beta_0 + \\beta_1 x_i}, \\]\ndove \\(\\beta_0\\) e \\(\\beta_1\\) sono i parametri del modello che devono essere stimati. Questi parametri quantificano l‚Äôeffetto delle variabili esplicative sui conteggi previsti. L‚Äôutilizzo della funzione esponenziale come legame assicura che il valore atteso \\(\\mu_i\\) sia sempre positivo.\nPer costruire il modello di regressione di Poisson:\n\nSi assume che il conteggio degli eventi per un dato livello della variabile esplicativa segua una distribuzione di Poisson, con un parametro di tasso (\\(\\mu_i\\)) specifico per ciascuna osservazione.\nSi definisce un predittore lineare, \\(\\eta_i\\), come una combinazione lineare dei coefficienti del modello (\\(\\beta\\)) e delle variabili esplicative (\\(x_i\\)).\nSi applica la funzione di legame esponenziale per stabilire che il tasso medio di eventi, \\(\\mu_i\\), sia determinato dal predittore lineare, cos√¨ che \\(\\mu_i = e^{\\eta_i} = e^{\\alpha + \\beta x_i}\\).\n\nQuesti passaggi consentono di costruire un modello che non solo predice accuratamente i conteggi, ma offre anche insight significativi sull‚Äôeffetto delle variabili esplicative studiate.\nConsideriamo il seguente esempio. Supponiamo di voler studiare il numero medio di episodi di comportamento aggressivo tra adolescenti in una scuola. In questo caso, il parametro \\(\\lambda_i\\) rappresenta il numero medio di episodi di comportamento aggressivo per lo studente \\(i\\), e ci aspettiamo di mostrare che la variabilit√† tra gli studenti di \\(\\lambda_i\\) pu√≤ essere spiegata da variabili come il livello di stress, il supporto familiare, o la presenza di sintomi depressivi. Utilizzando la regressione di Poisson, possiamo modellare il numero medio di episodi di comportamento aggressivo come:\n\\[ \\lambda_i = e^{\\beta_0 + \\beta_1 \\text{Stress}_i + \\beta_2 \\text{SupportoFamiliare}_i + \\beta_3 \\text{Depressione}_i}, \\]\ndove \\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\) e \\(\\beta_3\\) sono i parametri del modello che quantificano l‚Äôeffetto delle rispettive variabili esplicative sui conteggi di comportamenti aggressivi previsti.\n\n75.1.1 Assunzioni della Regressione di Poisson\nAnalogamente alla regressione lineare, l‚Äôuso della regressione di Poisson per fare inferenze richiede delle assunzioni sul modello:\n\nRisposta di Poisson: La variabile di risposta √® un conteggio per unit√† di tempo o spazio, descritta da una distribuzione di Poisson.\nIndipendenza: Le osservazioni devono essere indipendenti l‚Äôuna dall‚Äôaltra.\nMedia = Varianza: Per definizione, la media di una variabile casuale di Poisson deve essere uguale alla sua varianza.\nLinearit√†: Il logaritmo del tasso medio, log(Œª), deve essere una funzione lineare di \\(x\\).\n\n\n\n75.1.2 Un Esempio con Stan\nPer fare un esempio, consideriamo nuovamente i dati corrispondenti alle sparatorie mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1¬∞ gennaio 2015.\nImportiamo i dati.\n\nurl = \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat = pd.read_csv(url)\nfps_dat.head()\n\n\n\n\n\n\n\n\n\nid\ndate\nthreat_type\nflee_status\narmed_with\ncity\ncounty\nstate\nlatitude\nlongitude\nlocation_precision\nname\nage\ngender\nrace\nrace_source\nwas_mental_illness_related\nbody_camera\nagency_ids\n\n\n\n\n0\n3\n2015-01-02\npoint\nnot\ngun\nShelton\nMason\nWA\n47.246826\n-123.121592\nnot_available\nTim Elliot\n53.0\nmale\nA\nnot_available\nTrue\nFalse\n73\n\n\n1\n4\n2015-01-02\npoint\nnot\ngun\nAloha\nWashington\nOR\n45.487421\n-122.891696\nnot_available\nLewis Lee Lembke\n47.0\nmale\nW\nnot_available\nFalse\nFalse\n70\n\n\n2\n5\n2015-01-03\nmove\nnot\nunarmed\nWichita\nSedgwick\nKS\n37.694766\n-97.280554\nnot_available\nJohn Paul Quintero\n23.0\nmale\nH\nnot_available\nFalse\nFalse\n238\n\n\n3\n8\n2015-01-04\npoint\nnot\nreplica\nSan Francisco\nSan Francisco\nCA\n37.762910\n-122.422001\nnot_available\nMatthew Hoffman\n32.0\nmale\nW\nnot_available\nTrue\nFalse\n196\n\n\n4\n9\n2015-01-04\npoint\nnot\nother\nEvans\nWeld\nCO\n40.383937\n-104.692261\nnot_available\nMichael Rodriguez\n39.0\nmale\nH\nnot_available\nFalse\nFalse\n473\n\n\n\n\n\n\n\n\n\n# Convert date\nfps_dat[\"date\"] = pd.to_datetime(fps_dat[\"date\"])\n\n# Create a new column 'year' to store the year information from the 'date' column\nfps_dat[\"year\"] = fps_dat[\"date\"].dt.year\n\nfps_dat.columns\n\nIndex(['id', 'date', 'threat_type', 'flee_status', 'armed_with', 'city',\n       'county', 'state', 'latitude', 'longitude', 'location_precision',\n       'name', 'age', 'gender', 'race', 'race_source',\n       'was_mental_illness_related', 'body_camera', 'agency_ids', 'year'],\n      dtype='object')\n\n\n\n# Filter out rows with year equal to 2024\nfps = fps_dat[fps_dat[\"year\"] != 2024]\n\n# Count occurrences of each year in fps\nyear_counts = fps[\"year\"].value_counts()\nprint(year_counts)\n\nyear\n2023    1161\n2022    1095\n2021    1050\n2020    1020\n2019     996\n2015     995\n2018     992\n2017     984\n2016     959\nName: count, dtype: int64\n\n\n\nyears = year_counts.index.to_numpy()\nyear = years - 2019\nyear\n\narray([ 4,  3,  2,  1,  0, -4, -1, -2, -3], dtype=int32)\n\n\n\ncounts = year_counts.values\ncounts\n\narray([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959])\n\n\nCreiamo un dizionario con i dati nel formato richiesto per CmdStan.\n\nstan_data = {\n    \"N\" : len(year),\n    \"y\" : counts,\n    \"x\" : year \n}\nstan_data\n\n{'N': 9,\n 'y': array([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959]),\n 'x': array([ 4,  3,  2,  1,  0, -4, -1, -2, -3], dtype=int32)}\n\n\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;  // Numero di osservazioni\n  array[N] int&lt;lower=0&gt; y;  // Dati di conteggio (frequenze)\n  vector[N] x;  // Variabile predittore (anni, gi√† standardizzata)\n}\n\nparameters {\n  real alpha;  // Intercetta\n  real beta;  // Pendenza\n}\n\nmodel {\n  // Priors debolmente informativi\n  alpha ~ normal(0, 10);\n  beta ~ normal(0, 10);\n\n  // Modello di regressione di Poisson\n  y ~ poisson_log(alpha + beta * x);\n}\n\ngenerated quantities {\n  array[N] int&lt;lower=0&gt; y_pred = poisson_log_rng(alpha + beta * x);\n}\n\n\n\nQuesto modello Stan specifica una regressione di Poisson per dati di conteggio, dove l‚Äôobiettivo √® modellare il numero di eventi (espressi dalla variabile y) in funzione di una variabile predittiva x (in questo caso, anni standardizzati). Il modello √® strutturato in quattro blocchi principali: data, parameters, model, e generated quantities. Ecco una panoramica dettagliata di ciascuna sezione e il suo ruolo nel contesto del modello:\n\n\n75.1.3 Blocco data\n\nN: Un intero che specifica il numero totale di osservazioni nel dataset. Serve a definire le dimensioni degli array e dei vettori utilizzati nel modello.\ny: Un array di interi che rappresenta i dati di conteggio osservati. Ogni elemento in y corrisponde al numero di eventi registrati in ciascuna delle N unit√† di osservazione.\nx: Un vettore di lunghezza N che contiene i valori della variabile predittiva (ad esempio, anni).\n\n\n\n75.1.4 Blocco parameters\n\nalpha: Un parametro reale che rappresenta l‚Äôintercetta del modello. In un contesto di regressione di Poisson, alpha corrisponde al logaritmo del tasso atteso di eventi quando la variabile predittiva x √® zero.\nbeta: Un parametro reale che rappresenta la pendenza o il coefficiente della variabile predittiva x. Questo parametro indica come il logaritmo del tasso atteso di eventi cambia in risposta a variazioni di una unit√† in x.\n\n\n\n75.1.5 Blocco model\nI priors per alpha e beta sono definiti come distribuzioni normali con media 0 e deviazione standard 10, rappresentando priors debolmente informativi che permettono ai dati di guidare principalmente l‚Äôinferenza sui parametri.\nNella tradizionale regressione di Poisson, il parametro \\(\\mu_i\\) (il tasso medio di eventi per l‚Äôunit√† osservata) √® collegato alle variabili esplicative tramite una funzione esponenziale: \\(\\mu_i = e^{\\eta_i} = e^{\\beta_0 + \\beta_1 x_i}\\). Questa trasformazione assicura che il valore predetto di \\(\\mu_i\\) sia sempre positivo, indipendentemente dai valori assunti dalle variabili esplicative, una necessit√† quando si modellano conteggi che non possono essere negativi.\nLa funzione poisson_log, invece di lavorare direttamente con \\(\\mu_i\\) come nella forma esponenziale \\(e^{\\eta_i}\\), opera sul logaritmo di \\(\\mu_i\\). Questo significa che la funzione specifica il logaritmo del tasso medio di eventi come lineare rispetto ai predittori. In altre parole, anzich√© modellare \\(\\mu_i\\) direttamente e poi trasformarlo, si modella il logaritmo di \\(\\mu_i\\) (che √® \\(\\log(\\mu_i)\\)) come funzione lineare delle variabili esplicative: \\(\\log(\\mu_i) = \\eta_i = \\beta_0 + \\beta_1 x_i\\).\nQuesta specificazione ha diversi vantaggi:\n\nStabilit√† numerica: Lavorare con il logaritmo di \\(\\mu_i\\) pu√≤ ridurre i problemi di stabilit√† numerica che talvolta emergono quando si lavora con valori estremamente grandi o piccoli di \\(\\mu_i\\).\nInterpretazione diretta dei parametri: Poich√© si modella il logaritmo di \\(\\mu_i\\), i coefficienti (come \\(\\beta_1\\)) possono essere interpretati in termini di variazione percentuale. Un incremento di una unit√† in \\(x_i\\) √® associato a un moltiplicatore esponenziale di \\(e^{\\beta_1}\\) sul tasso medio di eventi.\n\nNel codice Stan, la linea y ~ poisson_log(alpha + beta * x); specifica quindi che i dati di conteggio y seguono una distribuzione di Poisson, con il logaritmo del parametro di tasso (\\(\\log(\\mu_i)\\)) modellato come una funzione lineare di x attraverso alpha + beta * x.\n\n\n75.1.6 Blocco generated quantities\n\ny_pred: Un array di interi che contiene valori predetti generati dalla distribuzione di Poisson. Per ogni osservazione, poisson_log_rng genera un valore di conteggio casuale basato sul tasso atteso calcolato come alpha + beta * x. Questi valori predetti possono essere utilizzati per verifiche predittive posteriori o per ottenere una distribuzione predittiva degli eventi.\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo un sommario della distribuzione a posteriori per i parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n6.934\n0.011\n6.911\n6.954\n0.0\n0.0\n2461.0\n2201.0\n1.0\n\n\nbeta\n0.020\n0.004\n0.012\n0.028\n0.0\n0.0\n4171.0\n3115.0\n1.0\n\n\n\n\n\n\n\n\nL‚Äôess_bulk (Effective Sample Size per il bulk dell‚Äôestimatore) e ess_tail (Effective Sample Size per la coda dell‚Äôestimatore) sono relativamente alti per entrambi i parametri, indicando che il campionamento ha fornito una buona approssimazione della distribuzione a posteriori. Inoltre, il valore di r_hat vicino a 1.0 per entrambi i parametri suggerisce che il campionamento ha raggiunto la convergenza, indicando che i risultati sono affidabili.\n\n\n75.1.7 Interpretazione del Parametro alpha\nIl parametro alpha √® una stima del logaritmo del tasso atteso di eventi (frequenze) quando il valore della variabile esplicativa x √® zero, ossia quando si trova nella sua media, che in questo contesto √® stata standardizzata e centrata sull‚Äôanno 2019. Il valore medio di alpha √® 6.934, indicando che il logaritmo naturale del tasso atteso di eventi quando x = 0 √® circa 6.934.\nL‚Äôintervallo di alta densit√† (HDI) del 95% per alpha va da 6.912 a 6.954, fornendo un intervallo di stime plausibili per il valore di alpha con un alto grado di certezza statistica.\nPer interpretare alpha in termini di tasso atteso di eventi, usiamo exp(alpha). Questo trasforma il logaritmo del tasso di eventi nel tasso effettivo. Ad esempio, exp(6.934) d√† il tasso atteso di eventi per l‚Äôanno di riferimento 2019.\n\nnp.exp(6.934)\n\n1026.5921464104808\n\n\n\n\n75.1.8 Interpretazione del Parametro beta\nIl parametro beta rappresenta la variazione logaritmica attesa nelle frequenze per ogni incremento unitario in x (l‚Äôanno, in questo caso). Un valore medio di beta pari a 0.020, con un HDI del 95% che va da 0.012 a 0.028, suggerisce una tendenza positiva: all‚Äôaumentare degli anni, ci si aspetta un incremento nelle frequenze degli eventi.\nUtilizzando il link logaritmico del modello, l‚Äôeffetto di un incremento di un anno su x si traduce in una moltiplicazione del tasso di frequenza per exp(beta). Quindi, un aumento di un anno implica che il tasso di frequenza sar√† moltiplicato per exp(0.020), che √® approssimativamente 1.02, indicando un aumento previsto del 2% nelle frequenze per ogni anno successivo.\n\nnp.exp([0.020, 0.012, 0.028])\n\narray([1.02020134, 1.01207229, 1.02839568])\n\n\n\n\n75.1.9 Calcolo dell‚ÄôAumento Effettivo in Frequenza\nPer calcolare l‚Äôaumento effettivo in frequenza per ogni anno, utilizziamo la seguente formula:\n\\[ \\text{Aumento atteso} = \\exp(\\alpha) \\times (\\exp(\\beta) - 1) \\]\n\nCalcolo del Fattore di Moltiplicazione: exp(beta) √® il fattore di moltiplicazione che descrive come cambia il tasso di frequenza con un incremento di un anno. Con beta = 0.020, exp(beta) √® circa 1.0202.\nDeterminazione dell‚ÄôAumento Attuale in Frequenza: exp(alpha) fornisce il tasso di base delle frequenze quando x = 0. Moltiplicando questo tasso di base per (\\exp(\\beta) - 1), otteniamo l‚Äôaumento effettivo in frequenza per ogni anno aggiuntivo. Sottraendo 1 a exp(beta), otteniamo l‚Äôincremento percentuale dovuto solamente all‚Äôaumento di un anno.\n\nQuesta metodologia fornisce un modo intuitivo e statistico per quantificare come le variabili nel tempo influenzano la frequenza degli eventi, permettendo di fare previsioni basate su modelli storici e tendenze osservate.\n\n# Parametri del modello\nalpha_mean = 6.934\nbeta_mean = 0.020\n\n# Calcolo del tasso di frequenza base per l'anno centrato (exp(alpha))\ntasso_base = np.exp(alpha_mean)\n\n# Calcolo del fattore di moltiplicazione per l'aumento (exp(beta))\nfattore_moltiplicazione = np.exp(beta_mean)\n\n# Aumento atteso in frequenza per un anno\naumento_atteso = tasso_base * (fattore_moltiplicazione - 1)\naumento_atteso\n\n20.738537018435174\n\n\nBasandosi sul modello di regressione di Poisson, si stima un incremento medio di circa 20.74 nel numero di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno aggiuntivo. In altre parole, il modello prevede che, anno dopo anno, il numero di tali incidenti potrebbe crescere di circa 21 casi. Questa previsione riflette una dinamica esponenziale tra il passare degli anni e l‚Äôaumento della frequenza assoluta di sparatorie fatali, come evidenziato dai dati analizzati.\n\n\n75.1.10 Posterior-Predictive Check\nEsaminiamo il posterior-predictive check per il modello esaminato:\n\ny_observed = stan_data[\"y\"]\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive='y_pred',\n    observed_data={'y': y_observed}\n)\n\n\n_ = az.plot_ppc(idata, data_pairs={'y': 'y_pred'}, kind='cumulative')",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/04_stan_poisson_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "75¬† Regressione di Poisson con Stan",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\nscipy     : 1.14.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>75</span>¬† <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_simchon_2023.html",
    "href": "chapters/glm/05_simchon_2023.html",
    "title": "76¬† Tweets",
    "section": "",
    "text": "76.1 Introduzione\nIl rapporto tra linguaggio e pensiero √® stato a lungo un argomento di grande interesse per studiosi e artisti. Una delle voci pi√π influenti in questo dibattito √® stata quella di George Orwell, che, attraverso il suo romanzo 1984, ha rappresentato una distopia in cui un regime totalitario utilizza il linguaggio per limitare la capacit√† di pensiero della popolazione. In particolare, Orwell suggeriva nel suo saggio ‚ÄúPolitics and the English Language‚Äù che alcune strutture linguistiche, come l‚Äôuso della forma passiva, possono facilitare ideologie oppressive, riducendo la percezione di agenzia dell‚Äôindividuo.\nOrwell osservava che le frasi in forma attiva e passiva, pur descrivendo la stessa azione, differiscono per l‚Äôenfasi posta sul soggetto dell‚Äôazione: la forma attiva lo evidenzia, mentre la forma passiva tende a nasconderlo o eliminarlo. Questo utilizzo del linguaggio non agentivo, secondo Orwell, potrebbe essere strumentalizzato per diminuire l‚Äôautonomia e il potere delle persone. Nonostante le sue critiche alla forma passiva, Orwell stesso ha revisionato le prime versioni di 1984 per includere numerose costruzioni passive, presumibilmente per enfatizzare l‚Äôidea di un mondo in cui gli individui non hanno controllo sulle proprie vite.\nOltre al suo utilizzo letterario, diversi studiosi sociali hanno sostenuto che l‚Äôuso del linguaggio passivo, e pi√π in generale del linguaggio non agentivo, √® strettamente correlato al livello di agenzia personale percepito. L‚Äôagenzia personale si riferisce alla capacit√† degli individui di esercitare il controllo sul mondo esterno e su se stessi, e si manifesta in tre aspetti principali: il controllo delle proprie azioni, il controllo dei risultati e delle risorse (come il potere sociale), e la percezione soggettiva di possedere questi controlli.\nStudi psicologici precedenti hanno dimostrato che la formulazione linguistica pu√≤ influenzare il livello di agenzia attribuito agli altri. Molti di questi studi si sono basati su analisi discorsive qualitative. In questo contesto, il presente studio si propone di esplorare se l‚Äôuso del linguaggio agentivo √® un riflesso dell‚Äôagenzia personale degli individui. In particolare, si √® esaminato se diversi fattori, come il potere sociale, il rango sociale e la partecipazione a un forum sulla depressione, influenzano l‚Äôuso della forma passiva.\nNel Studio 3, che qui verr√† analizzato ulteriormente, Simchon, Hadar, e Gilead (2023) hanno investigato se il linguaggio utilizzato in un forum dedicato alla depressione fosse caratterizzato da una maggiore frequenza di uso della forma passiva, ipotizzando che ci√≤ fosse un riflesso della perdita di agenzia che molte persone con depressione sperimentano. La depressione √® una condizione mentale debilitante associata a episodi ricorrenti di umore depresso, anedonia, bassa autostima e disperazione, spesso accompagnata da un senso di mancanza di controllo sugli eventi negativi della propria vita.\nNel contesto di comunit√† online, le persone che soffrono di depressione spesso cercano supporto emotivo e condivisione delle esperienze. Di conseguenza, Simchon, Hadar, e Gilead (2023) hanno analizzato grandi dataset provenienti da Reddit per testare se i partecipanti a forum sulla depressione utilizzano la forma passiva pi√π frequentemente rispetto a utenti di altre comunit√†. I risultati hanno mostrato che il linguaggio usato nel forum sulla depressione era significativamente meno agentivo rispetto a quello di altri forum, supportando l‚Äôipotesi di una correlazione tra depressione e ridotta agentivit√† linguistica.\nQuesti risultati non solo replicano la relazione tra l‚Äôuso di pronomi personali e depressione, ma suggeriscono anche che livelli inferiori di agenzia linguistica possono essere indicativi di una salute mentale deteriorata. Pertanto, comprendere come l‚Äôagenzia personale influenzi l‚Äôuso del linguaggio agentivo pu√≤ fornire nuove prospettive sia per la ricerca psicologica sia per gli interventi clinici.\nQui ci concentreremo sull‚Äôanalisi dell‚ÄôEsperimento 3. La variabile dipendente √® passive_count. Questa rappresenta il numero di verbi passivi utilizzati da ciascun partecipante. Essendo una variabile che corrisponde ad una frequenza assoluta (conteggio), il modello di regressione utilizzato dagli autori √® una regressione binomiale negativa, che √® adatta per i dati di conteggio con overdispersione (varianza maggiore della media). Il modello utilizzato dagli autori include le seguenti variabili indipendenti.\nNell‚Äôanalisi considerata qui, I_c e wc_c sono state standardizzate.\nIl modello include anche l‚Äôinterazione groupdep:I_c. L‚Äôinterazione verifica se l‚Äôeffetto del linguaggio autoreferenziale (I_c) sull‚Äôuso dei verbi passivi varia tra i gruppi (controllo vs.¬†depressione).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Tweets</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_simchon_2023.html#introduzione",
    "href": "chapters/glm/05_simchon_2023.html#introduzione",
    "title": "76¬† Tweets",
    "section": "",
    "text": "group: Questa √® una variabile categorica che rappresenta il gruppo di appartenenza dei partecipanti. Esistonodue livelli per questa variabile: control (gruppo di controllo) e dep (gruppo con depressione). Questa variabile viene utilizzata per verificare se ci sono differenze nell‚Äôuso dei verbi passivi tra i due gruppi.\nI_c: Questa √® una variabile continua che rappresenta l‚Äôintensit√† dell‚Äôuso di un linguaggio autoreferenziale. Valori pi√π alti indicano un uso maggiore.\nwc_c √® un‚Äôaltra variabile continua,che sembra fornisce una misura della frequenza di parole in ciascun post. Viene utilizzata per controllare gli effetti del numero totale di parole prodotte dai partecipanti.\n\n\n\n\n76.1.1 Interpretazione dei risultati del modello\nIl modello considerato ha la forma passive_count ~ group * I_c + wc_c. L‚Äôanalisi bayesiana dei dati indica che:\n\nEffetto principale di groupdep: L‚Äôanalisi suggerisce che, quando si controlla per il numero totale di parole (wc_c), il gruppo ‚Äúdep‚Äù tende ad avere un conteggio pi√π alto di verbi passivi rispetto al gruppo di controllo. Questo √® supportato dalla distribuzione posteriore che mostra una maggiore concentrazione di valori positivi per il parametro associato a groupdep.\nEffetto di I_c: L‚Äôeffetto di I_c (linguaggio autoreferenziale) sul conteggio dei verbi passivi, una volta controllato per wc_c, non appare chiaramente delineato. La distribuzione posteriore del parametro associato a I_c √® centrata attorno a zero, suggerendo che non ci sono evidenze forti per un effetto positivo o negativo di I_c.\nEffetto di wc_c: Il numero totale di parole (wc_c) sembra avere un impatto consistente sul conteggio dei verbi passivi. La distribuzione posteriore del parametro associato a wc_c mostra una chiara concentrazione verso valori positivi, suggerendo che un maggiore numero di parole √® associato a un maggiore uso di verbi passivi.\nInterazione groupdep:I_c: L‚Äôinterazione tra group e I_c non mostra un effetto evidente sul conteggio dei verbi passivi quando si controlla per wc_c. La distribuzione posteriore del parametro dell‚Äôinterazione √® anch‚Äôessa centrata attorno a zero, indicando che non ci sono evidenze per un‚Äôinterazione sostanziale tra il gruppo e il linguaggio autoreferenziale.\n\nQuesti risultati indicano che l‚Äôuso dei verbi passivi √® influenzato da una combinazione di fattori, tra cui il gruppo di appartenenza e il numero totale di parole utilizzate.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Tweets</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_simchon_2023.html#bayesian-model-building-interface",
    "href": "chapters/glm/05_simchon_2023.html#bayesian-model-building-interface",
    "title": "76¬† Tweets",
    "section": "76.2 BAyesian Model-Building Interface",
    "text": "76.2 BAyesian Model-Building Interface\nLeggiamo i dati utilizzati nel capitolo precedente.\n\ndata_file = os.path.join(project_directory, \"data\", \"simchon_2023_study3a.csv\")\nd = pd.read_csv(data_file)\n\n\ndf = d[d[\"passive_count\"] &lt; 11]\n\n# Rimuovi le colonne 'I_c' e 'wc_c'\ndf.drop([\"I_c\", \"wc_c\"], axis=1, inplace=True)\n\n# Verifica il risultato\nprint(df.head())\n\n       id group  passive_count  word_count  I_liwc\n0  hzx393   dep              1          67       5\n1  hzx265   dep              1         126      23\n2  hzx1c8   dep              0         149      14\n3  hzx0be   dep              1          74       4\n4  hzwyua   dep              1          56       5\n\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/3816525779.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df.drop([\"I_c\", \"wc_c\"], axis=1, inplace=True)\n\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Seleziona le colonne da standardizzare\ncolumns_to_standardize = [\"word_count\", \"I_liwc\"]\n\n# Crea un'istanza di StandardScaler\nscaler = StandardScaler()\n\n# Applica la standardizzazione solo sulle colonne selezionate\ndf[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n\n# Rinomina la colonna 'I_liwc' a 'self_ref_lang'\ndf.rename(columns={\n    \"I_liwc\": \"I_c\",\n    \"word_count\": \"wc_c\"\n    }, inplace=True)\n\n# Verifica il risultato\nprint(df.head())\n\n       id group  passive_count      wc_c       I_c\n0  hzx393   dep              1 -0.524040 -0.549527\n1  hzx265   dep              1 -0.203384  0.351386\n2  hzx1c8   dep              0 -0.078382 -0.099071\n3  hzx0be   dep              1 -0.485996 -0.599578\n4  hzwyua   dep              1 -0.583824 -0.549527\n\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/2844295889.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/2844295889.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df.rename(columns={\n\n\n\n# Define the model using Bambi\nmodel = bmb.Model(\"passive_count ~ group * I_c + wc_c\", data=df, family=\"negativebinomial\")\n\nSul lato sinistro della tilde (‚àº), abbiamo la variabile dipendente, e sul lato destro, le variabili indipendenti. Con questa sintassi, stiamo semplicemente specificando la media (Œº nel modello lm di PyMC). Per impostazione predefinita, Bambi assume che la verosimiglianza sia gaussiana; √® possibile modificarla con l‚Äôargomento family. La sintassi della formula non specifica la distribuzione delle priors, ma solo come sono associate le variabili dipendenti e indipendenti. Bambi definir√† automaticamente delle priors (molto) debolmente informative per noi. Possiamo ottenere ulteriori informazioni stampando il modello Bambi.\n\nprint(model)\n\n       Formula: passive_count ~ group * I_c + wc_c\n        Family: negativebinomial\n          Link: mu = log\n  Observations: 8645\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 4.2886)\n            group ~ Normal(mu: 0.0, sigma: 5.2627)\n            I_c ~ Normal(mu: 0.0, sigma: 2.5)\n            group:I_c ~ Normal(mu: 0.0, sigma: 2.8047)\n            wc_c ~ Normal(mu: 0.0, sigma: 2.5)\n        \n        Auxiliary parameters\n            alpha ~ HalfCauchy(beta: 1.0)\n\n\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nSe vogliamo procedere con un‚Äôispezione visiva dei prior dei parametri del modello usiamo:\nEseguiamo il campionamento MCMC.\n\ntrace = model.fit(\n    tune=2000,\n    draws=1000,\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(trace, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI_c\n-0.07\n0.05\n-0.16\n0.03\n0.0\n0.0\n1778.50\n1930.11\n1.0\n\n\nIntercept\n-0.39\n0.03\n-0.45\n-0.32\n0.0\n0.0\n2320.60\n2365.65\n1.0\n\n\nalpha\n2.10\n0.10\n1.91\n2.28\n0.0\n0.0\n2987.03\n2463.13\n1.0\n\n\ngroup[dep]\n0.21\n0.04\n0.13\n0.28\n0.0\n0.0\n2508.87\n2688.34\n1.0\n\n\ngroup:I_c[dep]\n-0.05\n0.05\n-0.14\n0.03\n0.0\n0.0\n2053.27\n2463.19\n1.0\n\n\nwc_c\n0.76\n0.03\n0.70\n0.81\n0.0\n0.0\n2611.69\n2458.39\n1.0\n\n\n\n\n\n\n\n\nIl modello specificato √®:\n[ * I_c + wc_c ]\ncon una distribuzione binomiale negativa. Questo modello ha lo scopo di prevedere il passive_count (il numero di verbi ausiliari passivi usati dai partecipanti) in base a:\n\ngroup: Una variabile categorica che indica il gruppo di appartenenza dei partecipanti (ad esempio, controllo vs.¬†depressione, rappresentato qui come group[dep]).\nI_c: Una variabile continua che rappresenta il linguaggio autoreferenziale.\nwc_c: Una variabile continua che rappresenta il conteggio delle parole, centrata.\ngroup:I_c: Un termine di interazione tra group e I_c, che indica come la relazione tra I_c e passive_count varia tra i gruppi.\n\nLa distribuzione binomiale negativa √® scelta perch√© passive_count √® una variabile di conteggio, e questa distribuzione √® appropriata quando i dati mostrano sovradispersione (cio√®, la varianza √® maggiore della media).\n\n76.2.1 Interpretazione dei Coefficienti\nI coefficienti del modello di regressione sono riassunti con la loro media a posteriori, deviazione standard (sd), intervallo ad alta densit√† (HDI) al 3% e 97%, errore standard Monte Carlo della media (mcse_mean), errore standard Monte Carlo della deviazione standard (mcse_sd), dimensione campionaria efficace per il bulk (ess_bulk), dimensione campionaria efficace per la coda (ess_tail) e statistica R-hat (r_hat).\nEcco cosa rappresenta ciascun coefficiente e come interpretarli:\n\nIntercetta (Intercept):\n\nMedia: -0.39\nInterpretazione: L‚Äôintercetta rappresenta il logaritmo del conteggio atteso di verbi ausiliari passivi (passive_count) quando tutte le variabili predittive (group[dep], I_c, wc_c, e group:I_c[dep]) sono pari a zero. Poich√© questo valore √® su scala logaritmica (a causa della funzione di collegamento logaritmica del modello binomiale negativo), un valore di -0.39 indica un conteggio logaritmico di base che corrisponde a exp(-0.39) in termini di conteggi reali.\nHDI 3% a 97%: L‚Äôintervallo [-0.45, -0.32] suggerisce che c‚Äô√® il 94% di probabilit√† che il vero valore dell‚Äôintercetta si trovi in questo intervallo.\n\nLinguaggio Autoreferenziale (I_c):\n\nMedia: -0.07\nInterpretazione: Questo coefficiente indica che, per ogni aumento di una unit√† in I_c (linguaggio autoreferenziale), il logaritmo del conteggio atteso dei verbi ausiliari passivi diminuisce di 0.07 unit√†, mantenendo costanti le altre variabili. Questo suggerisce una relazione leggermente negativa, ma l‚Äôintervallo HDI dal 3% al 97% (-0.16, 0.03) indica incertezza sul fatto che questo effetto sia effettivamente diverso da zero.\n\nEffetto del Gruppo (group[dep]):\n\nMedia: 0.21\nInterpretazione: Questo coefficiente indica che, per i partecipanti nel gruppo ‚Äúdep‚Äù (gruppo depressione), il logaritmo del conteggio atteso dei verbi ausiliari passivi √® superiore di 0.21 unit√† rispetto ai partecipanti nel gruppo di riferimento (ad esempio, controllo), mantenendo costanti le altre variabili. Questo valore positivo suggerisce che il gruppo depressione tende a utilizzare pi√π verbi ausiliari passivi rispetto al gruppo di controllo.\nHDI 3% a 97%: L‚Äôintervallo [0.13, 0.28] mostra una forte certezza che l‚Äôeffetto √® positivo.\n\nInterazione tra Gruppo e Linguaggio Autoreferenziale (group:I_c[dep]):\n\nMedia: -0.05\nInterpretazione: Questo coefficiente rappresenta come l‚Äôeffetto del linguaggio autoreferenziale (I_c) sul logaritmo del conteggio dei verbi ausiliari passivi differisce per il gruppo ‚Äúdep‚Äù rispetto al gruppo di riferimento. Una media di -0.05 suggerisce che nel gruppo ‚Äúdep‚Äù, la relazione tra I_c e passive_count √® leggermente negativa rispetto al gruppo di controllo. Tuttavia, poich√© l‚Äôintervallo HDI dal 3% al 97% (-0.14, 0.03) include zero, non c‚Äô√® una chiara evidenza di un effetto differenziale significativo.\n\nConteggio delle Parole (wc_c):\n\nMedia: 0.76\nInterpretazione: Questo coefficiente indica che, per ogni aumento di una unit√† nel conteggio delle parole centrato (wc_c), il logaritmo del conteggio atteso dei verbi ausiliari passivi aumenta di 0.76 unit√†, mantenendo costanti le altre variabili. Ci√≤ suggerisce che un maggiore numero di parole √® associato a un maggiore uso di verbi ausiliari passivi.\nHDI 3% a 97%: L‚Äôintervallo [0.70, 0.81] indica che c‚Äô√® una forte evidenza di un effetto positivo del conteggio delle parole.\n\nParametro di Dispersione (alpha):\n\nMedia: 2.10\nInterpretazione: Il parametro alpha rappresenta la dispersione del modello binomiale negativo. Un valore di alpha maggiore di 1 indica che i dati mostrano sovradispersione, ovvero la varianza √® maggiore della media, il che √® tipico dei modelli di conteggio.\n\n\n\n\n76.2.2 Conclusione\nIn sintesi, questo modello suggerisce che il gruppo di appartenenza (dep vs.¬†controllo) e il conteggio delle parole hanno effetti evidenti sul numero di verbi ausiliari passivi utilizzati. L‚Äôeffetto del linguaggio autoreferenziale e della sua interazione con il gruppo √® meno chiaro, suggerendo una necessit√† di ulteriore esplorazione o considerazione di altri fattori.\n\n# Extract posterior samples\nposterior = az.extract(trace)\n\n# Create a grid of I_c values (using IQR as in your R code)\nI_c_q1, I_c_q3 = np.percentile(df[\"I_c\"], [25, 75])\nI_c_values = np.linspace(I_c_q1, I_c_q3, 100)\n\n# Get unique groups\ngroups = df[\"group\"].unique()\n\n# Ensure 'dep' is treated as the non-reference group\nis_dep_reference = groups[0] == \"dep\"\n\n\n# Helper function to safely get posterior values\ndef get_posterior_values(posterior, key):\n    values = posterior[key].values  # Convert DataArray to NumPy array\n    if values.ndim == 3:\n        values = values.squeeze(axis=1)  # Remove the singleton dimension\n    return values\n\n\n# Calculate posterior predictions\nposterior_preds = {}\n\nfor group in groups:\n    # Create design matrix\n    X = pd.DataFrame(\n        {\n            \"Intercept\": 1,\n            \"group\": (group == \"dep\") if is_dep_reference else (group != \"dep\"),\n            \"I_c\": I_c_values,\n            \"wc_c\": 0,  # Set to 0 as per zero_it in your R code\n            \"group:I_c\": ((group == \"dep\") if is_dep_reference else (group != \"dep\"))\n            * I_c_values,\n        }\n    )\n\n    # Safely reshape group-related posteriors\n    group_values = get_posterior_values(posterior, \"group\").flatten()\n    group_I_c_values = get_posterior_values(posterior, \"group:I_c\").flatten()\n\n    # Calculate linear predictor\n    linear_pred = (\n        get_posterior_values(posterior, \"Intercept\")[:, np.newaxis]\n        + group_values[:, np.newaxis] * X[\"group\"].values\n        + get_posterior_values(posterior, \"I_c\")[:, np.newaxis] * X[\"I_c\"].values\n        + get_posterior_values(posterior, \"wc_c\")[:, np.newaxis] * X[\"wc_c\"].values\n        + group_I_c_values[:, np.newaxis] * X[\"group:I_c\"].values\n    )\n\n    # Transform to response scale\n    posterior_preds[group] = np.exp(linear_pred)\n\n# Plot\ncolors = {\"control\": \"blue\", \"dep\": \"red\"}\n\nfor group, preds in posterior_preds.items():\n    mean = preds.mean(axis=0)\n    ci = np.percentile(preds, [2.5, 97.5], axis=0)\n    plt.plot(I_c_values, mean, label=group, color=colors[group])\n    plt.fill_between(I_c_values, ci[0], ci[1], alpha=0.2, color=colors[group])\n\nplt.xlabel(\"Self-Referential Language (I_c)\")\nplt.ylabel(\"Predicted Number of Passive Auxiliary Verbs\")\nplt.title(\"Interaction Effect: group * I_c\\n(with wc_c held at zero)\")\nplt.legend(title=\"Condition\")\nplt.grid(True, alpha=0.3)\n\n# Adjust x-axis to show more interpretable values\nplt.xlim(I_c_q1, I_c_q3)\nxticks = plt.gca().get_xticks()\nplt.gca().set_xticklabels([f\"{x:.2f}\" for x in xticks])\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63000/1234253612.py:73: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  plt.gca().set_xticklabels([f\"{x:.2f}\" for x in xticks])\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63000/1234253612.py:75: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nmodel2 = bmb.Model(\n    \"passive_count ~ group * I_c + wc_c\", data=df, family=\"poisson\"\n)\n\n\ntrace2 = model2.fit(\n    tune=2000, draws=1000, nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(trace2, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI_c\n-0.09\n0.02\n-0.14\n-0.05\n0.0\n0.0\n2012.27\n2012.51\n1.0\n\n\nIntercept\n-0.35\n0.02\n-0.39\n-0.31\n0.0\n0.0\n2527.49\n2424.84\n1.0\n\n\ngroup[dep]\n0.30\n0.03\n0.25\n0.35\n0.0\n0.0\n2801.92\n2775.68\n1.0\n\n\ngroup:I_c[dep]\n0.01\n0.02\n-0.03\n0.04\n0.0\n0.0\n2428.61\n2259.45\n1.0\n\n\nwc_c\n0.46\n0.01\n0.44\n0.49\n0.0\n0.0\n2376.84\n2675.49\n1.0\n\n\n\n\n\n\n\n\n\n# Extract posterior samples\nposterior = az.extract(trace2)\n\n# Create a grid of I_c values (using IQR as in your R code)\nI_c_q1, I_c_q3 = np.percentile(df[\"I_c\"], [25, 75])\nI_c_values = np.linspace(I_c_q1, I_c_q3, 100)\n\n# Get unique groups\ngroups = df[\"group\"].unique()\n\n# Ensure 'dep' is treated as the non-reference group\nis_dep_reference = groups[0] == \"dep\"\n\n\n# Helper function to safely get posterior values\ndef get_posterior_values(posterior, key):\n    values = posterior[key].values  # Convert DataArray to NumPy array\n    if values.ndim == 3:\n        values = values.squeeze(axis=1)  # Remove the singleton dimension\n    return values\n\n\n# Calculate posterior predictions\nposterior_preds = {}\n\nfor group in groups:\n    # Create design matrix\n    X = pd.DataFrame(\n        {\n            \"Intercept\": 1,\n            \"group\": (group == \"dep\") if is_dep_reference else (group != \"dep\"),\n            \"I_c\": I_c_values,\n            \"wc_c\": 0,  # Set to 0 as per zero_it in your R code\n            \"group:I_c\": ((group == \"dep\") if is_dep_reference else (group != \"dep\"))\n            * I_c_values,\n        }\n    )\n\n    # Safely reshape group-related posteriors\n    group_values = get_posterior_values(posterior, \"group\").flatten()\n    group_I_c_values = get_posterior_values(posterior, \"group:I_c\").flatten()\n\n    # Calculate linear predictor\n    linear_pred = (\n        get_posterior_values(posterior, \"Intercept\")[:, np.newaxis]\n        + group_values[:, np.newaxis] * X[\"group\"].values\n        + get_posterior_values(posterior, \"I_c\")[:, np.newaxis] * X[\"I_c\"].values\n        + get_posterior_values(posterior, \"wc_c\")[:, np.newaxis] * X[\"wc_c\"].values\n        + group_I_c_values[:, np.newaxis] * X[\"group:I_c\"].values\n    )\n\n    # Transform to response scale\n    posterior_preds[group] = np.exp(linear_pred)\n\n# Plot\ncolors = {\"control\": \"blue\", \"dep\": \"red\"}\n\nfor group, preds in posterior_preds.items():\n    mean = preds.mean(axis=0)\n    ci = np.percentile(preds, [2.5, 97.5], axis=0)\n    plt.plot(I_c_values, mean, label=group, color=colors[group])\n    plt.fill_between(I_c_values, ci[0], ci[1], alpha=0.2, color=colors[group])\n\nplt.xlabel(\"Self-Referential Language (I_c)\")\nplt.ylabel(\"Predicted Number of Passive Auxiliary Verbs\")\nplt.title(\"Interaction Effect: group * I_c\\n(with wc_c held at zero)\")\nplt.legend(title=\"Condition\")\nplt.grid(True, alpha=0.3)\n\n# Adjust x-axis to show more interpretable values\nplt.xlim(I_c_q1, I_c_q3)\nxticks = plt.gca().get_xticks()\nplt.gca().set_xticklabels([f\"{x:.2f}\" for x in xticks])\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/4242554425.py:73: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  plt.gca().set_xticklabels([f\"{x:.2f}\" for x in xticks])\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/4242554425.py:75: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nmodel2.predict(trace2, kind=\"response\")\n\n\naz.plot_ppc(trace2)\n\n\n\n\n\n\n\n\n\nmodel.predict(trace, kind=\"response\")\n\n\naz.plot_ppc(trace)\n\n\n\n\n\n\n\n\n\n# Compute LOO\nloo_result = az.loo(trace)\n\n# Print the LOO and ELPD results\nprint(loo_result)\n\nComputed from 4000 posterior samples and 8645 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -10494.67    93.09\np_loo        8.27        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     8645  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\n\n# Compute LOO\nloo2_result = az.loo(trace2)\n\n# Print the LOO and ELPD results\nprint(loo2_result)\n\n/opt/anaconda3/envs/cmdstan_env/lib/python3.12/site-packages/arviz/stats/stats.py:789: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n\n\nComputed from 4000 posterior samples and 8645 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -11267.62   148.51\np_loo       54.61        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     8643  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    2    0.0%\n\n\n\n\ndf_comp_loo = az.compare({\"neg_bin_model\": loo_result, \"poisson _model\": loo2_result})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nneg_bin_model\n0\n-10494.665380\n8.268416\n0.000000\n0.95484\n93.094047\n0.000000\nFalse\nlog\n\n\npoisson _model\n1\n-11267.624222\n54.610578\n772.958842\n0.04516\n148.505078\n96.512308\nTrue\nlog\n\n\n\n\n\n\n\n\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Tweets</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_simchon_2023.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/05_simchon_2023.html#informazioni-sullambiente-di-sviluppo",
    "title": "76¬† Tweets",
    "section": "76.3 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "76.3 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Aug 14 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\ncmdstanpy : 1.2.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\npandas    : 2.2.2\nnumpy     : 1.26.4\nlogging   : 0.5.1.2\nbambi     : 0.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nSimchon, Almog, Britt Hadar, e Michael Gilead. 2023. ¬´A computational text analysis investigation of the relation between personal and linguistic agency¬ª. Communications Psychology 1 (1): 23.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>76</span>¬† <span class='chapter-title'>Tweets</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html",
    "href": "chapters/glm/06_stan_rct.html",
    "title": "77¬† Incorporare dati storici di controllo in una RCT",
    "section": "",
    "text": "Introduzione\nQuesto capitolo fornisce una trattazione semplificata di un importante problema affrontato da Frank Harrell in un suo intervento intitolato Incorporating Historical Control Data Into an RCT.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html#studi-controllati-randomizzati",
    "href": "chapters/glm/06_stan_rct.html#studi-controllati-randomizzati",
    "title": "77¬† Incorporare dati storici di controllo in una RCT",
    "section": "77.1 Studi Controllati Randomizzati",
    "text": "77.1 Studi Controllati Randomizzati\nNella ricerca psicologica, ci troviamo di fronte a notevoli ostacoli nel reclutare un numero sufficiente di partecipanti per condurre studi controllati randomizzati (RCT), un problema che si acuisce quando si prevede l‚Äôassegnazione dei partecipanti a gruppi di controllo che ricevono trattamenti standard. Un‚Äôaltra difficolt√† sorge quando i potenziali partecipanti sono riluttanti a iscriversi agli studi a causa della possibilit√† di non ricevere il trattamento sperimentale. In questo contesto, l‚Äôutilizzo di Dati Storici (HD) per informare su possibili esiti nei gruppi di controllo assume un‚Äôimportanza vitale. Tuttavia, l‚Äôintegrazione di tali dati richiede strategie sofisticate per adeguare i bias e le disparit√† tra i diversi disegni di studio.\nStuart Pocock ha proposto un metodo nel quadro frequentista che valorizza la dimensione campionaria degli HD, pur ammettendo che questi possano riflettere realt√† diverse rispetto agli esiti attesi nei gruppi di controllo degli RCT prospettici. La discrepanza include sia la vera performance sconosciuta del gruppo di controllo sia il bias inerente agli HD.\nBj√∂rn Holzhauer ha ampliato questa visione attraverso lo sviluppo di approcci Bayesiani per l‚Äôappropriazione di dati, in particolare riguardo ai tassi di pericolo esponenziali, mediante l‚Äôutilizzo di simulazioni MCMC Bayesiane. Queste metodologie consentono l‚Äôelaborazione parallela di pi√π modelli e l‚Äôinclusione diretta dei dati grezzi degli HD nell‚Äôanalisi di nuovi dati sperimentali, affrontando direttamente le possibili discrepanze negli oggetti di stima tra HD e RCT.\nUna caratteristica fondamentale di queste tecniche √® l‚Äôaggregazione di dati grezzi da diverse fonti, facilitando un‚Äôanalisi pi√π precisa che considera l‚Äôintero spettro delle incertezze. Questo si contrappone agli approcci tradizionali, che spesso si basano su statistiche riassuntive e tendono a trascurare importanti variabilit√†, conferendo una fiducia ingiustificata nei dati storici. √à, inoltre, cruciale l‚Äôajustamento per covariate al fine di gestire l‚Äôeterogeneit√† degli esiti tra i trattamenti, aumentando cos√¨ l‚Äôaffidabilit√† e l‚Äôaccuratezza delle stime dell‚Äôeffetto del trattamento.\nProcedendo senza dati diretti per valutare il bias, ci affidiamo a una distribuzione a priori gaussiana con media zero e deviazione standard sigma per descriverlo. Un valore di sigma nullo implica l‚Äôassenza di bias, permettendo di integrare gli HD nell‚Äôanalisi allo stesso livello dei dati di controllo dello studio. Al contrario, un sigma infinito indica una completa ignoranza riguardo al bias, rendendo gli HD non informativi e pertanto trascurabili.\nIl focus principale, l‚Äôeffetto del trattamento delta, viene esaminato pi√π efficacemente attraverso l‚Äôanalisi di sigma. Un sigma inferiore a 2 rende lo studio informativo su delta, mentre un sigma superiore a 2 pu√≤ portare a conclusioni errate, specialmente quando gli HD hanno una media artificiosamente gonfiata. Questo sottolinea l‚Äôimportanza di una scelta accurata dei parametri analitici, in particolare nell‚Äôintegrazione dei dati storici con quelli dei nuovi studi clinici, per fornire una rappresentazione equilibrata e critica dell‚Äôintegrazione di tali dati nell‚Äôanalisi statistica contemporanea.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html#creazione-di-un-braccio-di-controllo-con-hd",
    "href": "chapters/glm/06_stan_rct.html#creazione-di-un-braccio-di-controllo-con-hd",
    "title": "77¬† Incorporare dati storici di controllo in una RCT",
    "section": "77.2 Creazione di un Braccio di Controllo con HD",
    "text": "77.2 Creazione di un Braccio di Controllo con HD\nNel contesto di uno studio RCT condotto con un unico braccio sperimentale, dove i dati di controllo derivano unicamente da controlli storici non contemporanei, la sfida si amplifica. In queste circostanze, il bias intrinseco negli HD non pu√≤ essere quantificato direttamente. Invece, ci si affida completamente alla distribuzione di incertezza prescelta per il bias. Questo approccio offre un‚Äôanalisi che, pur essendo paragonabile a una verifica di sensibilit√†, si avvale del rigoroso quadro analitico Bayesiano. Quest‚Äôultimo, per sua natura flessibile, permette un‚Äôestensione naturale a include la meta-analisi di dati individuali dei pazienti e l‚Äôadeguamento per covariate, arricchendo cos√¨ la robustezza e l‚Äôaffidabilit√† delle inferenze tratte dallo studio.\nImportiamo e compiliamo il modello.\n\nstan_file = os.path.join(project_directory, \"stan\", \"rct.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:00:16 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/rct.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/rct\n12:00:26 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/rct\n\n\ndata {\n  int&lt;lower=0&gt; Nb;  // # obs in RCT treatment B\n  int&lt;lower=0&gt; Nh;  // # obs in historical control data\n  vector[Nb] yb;    // vector of tx=B data\n  vector[Nh] yh;    // vector of historical data\n  real&lt;lower=0&gt; sigma;  // standard deviation of prior for bias\n}\nparameters {\n  real mua;  // unknown mean for tx=A\n  real mub;  // unknown mean for tx=B\n  real bias; // unknown bias\n}\ntransformed parameters {\n  real delta;\n  delta = mua - mub;\n}\nmodel {\n  yb   ~ normal(mub, 1.0);\n  yh   ~ normal(mua + bias, 1.0);\n  bias ~ normal(0., sigma);\n}\n\n\n\n\nCreiamo il dizionario che contiene i dati richiesti dal modello.\n\nNa = 20\nNb = 40\nNh = 500\nya = rng.normal(loc=10, scale=1, size=Na)\nyb = rng.normal(loc=5, scale=1, size=Nb)\nyh = rng.normal(loc=20, scale=1, size=Nh)\n\nstan_data = {\"Nb\": Nb, \"Nh\": Nh, \"yb\": yb, \"yh\": yh, \"sigma\": 1.0}\n\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo i risultati ottenuti.\n\nprint(fit.summary())\n\n             Mean      MCSE    StdDev         5%         50%        95%  \\\nlp__  -252.847000  0.035606  1.225860 -255.33900 -252.524000 -251.48100   \nmua     20.034200  0.028866  1.027280   18.35000   20.040900   21.69820   \nmub      5.216960  0.004029  0.160862    4.94483    5.216310    5.47481   \nbias    -0.044748  0.028869  1.026390   -1.71126   -0.042136    1.62836   \ndelta   14.817300  0.029354  1.038220   13.10640   14.832900   16.49740   \n\n         N_Eff  N_Eff/s    R_hat  \nlp__   1185.29  1727.83  1.00003  \nmua    1266.49  1846.20  1.00055  \nmub    1594.19  2323.89  1.00245  \nbias   1264.05  1842.64  1.00058  \ndelta  1250.95  1823.54  1.00088  \n\n\n\naz.summary(fit, var_names=([\"bias\", \"delta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbias\n-0.045\n1.026\n-1.990\n1.917\n0.029\n0.021\n1265.0\n1491.0\n1.0\n\n\ndelta\n14.817\n1.038\n12.911\n16.837\n0.029\n0.021\n1251.0\n1285.0\n1.0\n\n\n\n\n\n\n\n\n\n_ = az.plot_trace(fit, var_names=([\"bias\", \"delta\"]))\n\n\n\n\n\n\n\n\nSi noti l‚Äôutilit√† dei dati storici nella riduzione dell‚Äôincertezza associata a delta. Quando diminuisce sigma, diminuisce anche l‚Äôincertezza associata all‚Äôeffetto del trattamento.\n\nstan_data = {\n    \"Nb\" : Nb, \n    \"Nh\" : Nh, \n    \"yb\" : yb, \n    \"yh\" : yh,\n    \"sigma\" : 0.25\n}\n\n\nfit1 = model.sample(data=stan_data)\n\n\naz.summary(fit1, var_names=([\"bias\", \"delta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbias\n-0.006\n0.250\n-0.505\n0.468\n0.007\n0.005\n1337.0\n1404.0\n1.0\n\n\ndelta\n14.782\n0.304\n14.161\n15.335\n0.008\n0.006\n1483.0\n1538.0\n1.0",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html#conclusioni",
    "href": "chapters/glm/06_stan_rct.html#conclusioni",
    "title": "77¬† Incorporare dati storici di controllo in una RCT",
    "section": "77.3 Conclusioni",
    "text": "77.3 Conclusioni\nPer stabilire la distribuzione a priori del bias, √® fondamentale considerare le informazioni disponibili riguardanti l‚Äôevoluzione delle pratiche terapeutiche, il bias di selezione dei pazienti e l‚Äôandamento della patologia di interesse. L‚Äôapproccio Bayesiano ci libera dalla necessit√† di conoscere con precisione l‚Äôentit√† del bias, indirizzandoci invece a definire la sua distribuzione di incertezza. In caso questa distribuzione sia modellata come gaussiana, ci si avvale dell‚Äôipotesi di simmetria per focalizzarsi sulla deviazione standard, sigma. Un metodo efficace per determinare sigma consiste nel fissarlo in modo che, per esempio, la probabilit√† che il bias si collochi entro un intervallo di \\([-c, c]\\) sia del 95%, per poi calcolare retrospettivamente il valore di sigma necessario a soddisfare questa condizione. Questo approccio garantisce una gestione pi√π mirata e scientificamente fondata dell‚Äôincertezza legata al bias, fondamentale per l‚Äôintegrazione ottimale dei dati storici nelle analisi statistiche avanzate.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/06_stan_rct.html#informazioni-sullambiente-di-sviluppo",
    "title": "77¬† Incorporare dati storici di controllo in una RCT",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nscipy     : 1.14.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>77</span>¬† <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html",
    "href": "chapters/glm/07_stan_mediation.html",
    "title": "78¬† Modello di mediazione con Stan",
    "section": "",
    "text": "78.1 Preparazione del Notebook\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\nimport networkx as nx\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"stan_mediation\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"\nIl presente capitolo fornisce un riassunto della trattazione dei modelli misti fornita da {cite:t}sorensen2015bayesian, a cui si rimanda per gli approfondimenti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html#domanda-della-ricerca",
    "href": "chapters/glm/07_stan_mediation.html#domanda-della-ricerca",
    "title": "78¬† Modello di mediazione con Stan",
    "section": "78.2 Domanda della Ricerca",
    "text": "78.2 Domanda della Ricerca\nLa questione scientifica riguarda la comprensione delle frasi nel caso di proposizioni relative di soggetto e di oggetto. Una proposizione relativa di soggetto √® una frase in cui un sostantivo (ad esempio, ‚Äúsenatore‚Äù) viene modificato da una proposizione relativa (ad esempio, ‚Äúche ha interrogato il giornalista‚Äù), e il sostantivo modificato √® il soggetto grammaticale della proposizione relativa. In una proposizione relativa di oggetto, il sostantivo modificato dalla proposizione relativa √® l‚Äôoggetto grammaticale della proposizione (per esempio, ‚ÄúIl senatore che il giornalista ha interrogato si √® dimesso‚Äù). In entrambi i casi, il sostantivo modificato (‚Äúsenatore‚Äù) √® chiamato il sostantivo principale.\nUn risultato comune per l‚Äôinglese √® che le proposizioni relative di soggetto sono pi√π facili da elaborare rispetto a quelle di oggetto. Le lingue naturali in generale includono proposizioni relative, e fino a poco tempo fa il vantaggio delle proposizioni di soggetto √® stato considerato valido a livello cross-linguistico. Tuttavia, le proposizioni relative in cinese rappresentano un interessante controesempio a questa generalizzazione; ricerche recenti condotte da Hsiao e Gibson (2003) hanno suggerito che in cinese, le proposizioni relative di oggetto sono pi√π facili da elaborare rispetto a quelle di soggetto in un punto specifico della frase (il sostantivo principale della proposizione relativa). Viene presentata un‚Äôanalisi di un insieme di dati successivamente pubblicata {cite:p}gibson2013processing che valuta questa affermazione.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html#i-dati",
    "href": "chapters/glm/07_stan_mediation.html#i-dati",
    "title": "78¬† Modello di mediazione con Stan",
    "section": "78.3 I Dati",
    "text": "78.3 I Dati\nLa variabile dipendente dell‚Äôesperimento di {cite:t}gibson2013processing era il tempo di lettura (rt) in millisecondi del sostantivo principale della proposizione relativa. Questo √® stato registrato in due condizioni (proposizione relativa di soggetto e proposizione relativa di oggetto), con 37 soggetti e 15 item, presentati in un disegno standard a quadrato latino. Originariamente c‚Äôerano 16 item, ma uno √® stato rimosso, risultando in 37 √ó 15 = 555 punti dati. Tuttavia, otto punti dati da un soggetto (id 27) erano mancanti. Di conseguenza, abbiamo un totale di 555 - 8 = 547 punti dati. La condizione (object relative / subject relative) √® codificata dalla variabile so.\n\nhowell_data = pd.read_csv(\"../data/Howell1.csv\", sep=';')\nhowell_data.head()\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\n\n\nhowell_data.tail()\n\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n539\n145.415\n31.127751\n17.0\n1\n\n\n540\n162.560\n52.163080\n31.0\n1\n\n\n541\n156.210\n54.062497\n21.0\n0\n\n\n542\n71.120\n8.051258\n0.0\n1\n\n\n543\n158.750\n52.531624\n68.0\n1\n\n\n\n\n\n\n\n\n\nhowell_data.shape\n\n(544, 4)\n\n\n\n_ = sns.kdeplot(data=howell_data, x='weight', hue='male', fill=True, common_norm=False, alpha=0.5)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html#pensare-scientificamente-prima-di-tutto",
    "href": "chapters/glm/07_stan_mediation.html#pensare-scientificamente-prima-di-tutto",
    "title": "78¬† Modello di mediazione con Stan",
    "section": "78.4 Pensare scientificamente prima di tutto",
    "text": "78.4 Pensare scientificamente prima di tutto\nDesideriamo prevedere il peso a partire da due predittori: genere e altezza. Pertanto, potremmo prevedere il peso utilizzando queste due variabili mediante un modello di regressione. {cite:t}McElreath_rethinking ci ricorda che il modello di regressione √® un ‚ÄúGolem‚Äù: √® potente e stupido. Se il nostro unico obiettivo √® ‚Äúprevedere‚Äù il valore del peso senza attribuire interpretazioni ai coefficienti del modello, questo potrebbe essere adeguato se funziona effettivamente. Tuttavia, il modello di regressione non considera la struttura causale sottostante il meccanismo di generazione dei dati. Se desideriamo comprendere qualcosa sulla struttura causale che lega questi dati, dobbiamo prima pensare in termini scientifici.\n\nCome sono causalmente correlati altezza, peso e sesso?\nCome sono statisticamente correlati altezza, peso e sesso?\n\n\n78.4.1 Le cause non sono nei dati\nL‚Äôaltezza dovrebbe influenzare il peso, e non il contrario: - ‚úÖ \\(H \\rightarrow W\\) - ‚ùå \\(W \\rightarrow H\\)\nIl sesso dovrebbe influenzare l‚Äôaltezza, e non il contrario: - ‚ùå \\(S \\rightarrow H\\) - ‚úÖ \\(H \\rightarrow S\\)\nQuesto ci porta a un modello di mediazione. In tale modello, il sesso influisce sul peso (\\(S \\rightarrow W\\)) cos√¨ come sull‚Äôaltezza (\\(S \\rightarrow H\\)). Inoltre, l‚Äôaltezza influisce sul peso (\\(H \\rightarrow W\\)). In questa struttura causale, possiamo distinguere tra effetti diretti, indiretti e l‚Äôeffetto totale.\nL‚Äôeffetto diretto del genere sul peso √® dato dal coefficiente del percorso \\(S \\rightarrow W\\). Questa √® la nostra principale questione di interesse. Tuttavia, c‚Äô√® un altro effetto diretto che influisce sul peso: \\(H \\rightarrow W\\). Se confrontiamo questi due effetti diretti, quale √® il pi√π significativo? In aggiunta, abbiamo l‚Äôeffetto diretto \\(S \\rightarrow H\\). Possiamo anche definire l‚Äôeffetto indiretto del sesso sul peso come \\(S \\rightarrow H \\rightarrow W\\). Infine, l‚Äôeffetto totale √® dato dalla somma degli effetti diretti e indiretti.\nTutto ci√≤ viene ignorato in un modello di regressione semplice. Solo quando disponiamo di un modello plausibile che descrive le relazioni causali tra le variabili possiamo costruire un modello statistico in grado di rappresentare adeguatamente la struttura causale ipotizzata, permettendoci di rispondere alle domande di interesse. In questo caso, quale √® l‚Äôeffetto pi√π rilevante sul peso? Altezza o genere? Per rispondere a questa domanda, possiamo implementare il modello di mediazione in Stan nel seguente modo.\n\n# Creazione del Directed Acyclic Graph (DAG) per il modello di mediazione\nG = nx.DiGraph()\n\n# Aggiunta dei nodi\nG.add_nodes_from([\"S\", \"W\", \"H\"])\n\n# Aggiunta degli archi che rappresentano le relazioni causali\nG.add_edges_from([(\"S\", \"W\"), (\"S\", \"H\"), (\"H\", \"W\")])\n\n# Posizionamento dei nodi usando il layout 'planar'\npos = nx.planar_layout(G)\n\n# Impostazioni per i nodi pi√π grandi e le dimensioni globali pi√π piccole\noptions = {\n    \"font_size\": 12,\n    \"node_size\": 2000,\n    \"node_color\": \"skyblue\",\n    \"edgecolors\": \"black\",\n    \"linewidths\": 2,\n    \"width\": 2,\n}\n\nplt.figure(figsize=(6, 4))  # Dimensioni globali pi√π piccole\nnx.draw(G, pos, **options, with_labels=True, arrowsize=20)\n\nplt.title(\"Mediation Model DAG\")\nplt.show()\n\n/opt/anaconda3/envs/stan_env/lib/python3.12/site-packages/IPython/core/pylabtools.py:152: UserWarning: There are no gridspecs with layoutgrids. Possibly did not call parent GridSpec with the \"figure\" keyword\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\nRileggiamo il modello Stan. √à da notare che i dati sono stati standardizzati per agevolare il campionamento e permettere un confronto diretto tra i diversi coefficienti.\n\nstan_file = os.path.join('stan', 'mediation_model.stan')\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of observations\n  array[N] int S; // Sex indicator (0 for F, 1 for M), Predictor\n  array[N] real H; // Height, Mediator\n  array[N] real W; // Weight, Outcome\n}\n\nparameters {\n  real alphaH; // Intercept for height model\n  real betaH; // Effect of sex on height\n  real alphaW; // Intercept for weight model\n  real betaW_H; // Effect of height on weight\n  real betaW_S; // Direct effect of sex on weight\n  real&lt;lower=0&gt; sigmaH; // Std dev for height model\n  real&lt;lower=0&gt; sigmaW; // Std dev for weight model\n}\n\nmodel {\n  // Priors\n  alphaH ~ normal(0, 1); // Less restrictive priors for intercepts and effects\n  betaH ~ normal(0, 1);\n  alphaW ~ normal(0, 1);\n  betaW_H ~ normal(0, 1);\n  betaW_S ~ normal(0, 1);\n  sigmaH ~ cauchy(0, 1); // Using a Cauchy distribution for sigma, more appropriate for std devs\n  sigmaW ~ cauchy(0, 1);\n  \n  // Mediation Model\n  for (i in 1:N) {\n    // A path: Effect of sex on height\n    H[i] ~ normal(alphaH + betaH * S[i], sigmaH);\n    \n    // B and C' path: Effect of height (and sex) on weight\n    W[i] ~ normal(alphaW + betaW_H * H[i] + betaW_S * S[i], sigmaW);\n  }\n}\n\n\n\nCreiamo un dizionario che include i dati nel formato atteso dal precedente codice Stan.\n\nhowell_data['H_standardized'] = (howell_data['height'] - howell_data['height'].mean()) / howell_data['height'].std()\nhowell_data['W_standardized'] = (howell_data['weight'] - howell_data['weight'].mean()) / howell_data['weight'].std()\n\nstan_data = {\n    \"N\": howell_data.shape[0],\n    \"S\": howell_data[\"male\"].to_numpy(),  # Ensuring this is an array if not already\n    \"H\": howell_data[\"H_standardized\"].to_numpy(),  # Use the standardized height\n    \"W\": howell_data[\"W_standardized\"].to_numpy()   # Use the standardized weight\n}\n\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model)\n\nCmdStanModel: name=mediation_model\n     stan_file=/Users/corradocaudek/_repositories/ds4p/chapter_5/stan/mediation_model.stan\n     exe_file=/Users/corradocaudek/_repositories/ds4p/chapter_5/stan/mediation_model\n     compiler_options=stanc_options={}, cpp_options={}\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data, adapt_delta = 0.95)\n\n\nprint(fit.diagnose())\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nEsaminiamo le tracce.\n\n_ = az.plot_trace(fit, var_names=([\"betaH\", \"betaW_H\", \"betaW_S\"]))\n\n\n\n\n\n\n\n\nEsaminiamo le medie a posteriori e gli intervalli di credibilit√† dei parametri.\n\naz.summary(fit, var_names=([\"betaH\", \"betaW_H\", \"betaW_S\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbetaH\n0.28\n0.09\n0.11\n0.44\n0.0\n0.0\n3139.90\n2705.84\n1.0\n\n\nbetaW_H\n0.94\n0.01\n0.91\n0.97\n0.0\n0.0\n4113.00\n2834.41\n1.0\n\n\nbetaW_S\n0.05\n0.03\n-0.01\n0.11\n0.0\n0.0\n2796.52\n2773.80\n1.0\n\n\n\n\n\n\n\n\nIl genere ha scarso o addirittura nullo impatto diretto sul peso. Piuttosto, √® principalmente l‚Äôaltezza ad avere un effetto causale sul peso.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/07_stan_mediation.html#informazioni-sullambiente-di-sviluppo",
    "title": "78¬† Modello di mediazione con Stan",
    "section": "78.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "78.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Wed May 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.2\nIPython version      : 8.22.2\n\ncmdstanpy: 1.2.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.13.0\nnetworkx  : 3.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>78</span>¬† <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/introduction_entropy.html",
    "href": "chapters/entropy/introduction_entropy.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esploreremo il tema cruciale della validazione di un modello statistico e del confronto tra modelli. Vedremo come sia necessario trovare un equilibrio tra due dimensioni: la capacit√† del modello di predire accuratamente i dati osservati nel campione e la sua capacit√† di generalizzarsi a campioni diversi.",
    "crumbs": [
      "Entropia",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html",
    "href": "chapters/entropy/01_entropy.html",
    "title": "79¬† Entropia",
    "section": "",
    "text": "Introduzione\nNel contesto della statistica bayesiana, √® cruciale confrontare diversi modelli predittivi per identificare quello che meglio si adatta ai dati disponibili. Una metrica essenziale in questo confronto √® la Expected Log Predictive Density (ELPD), che misura l‚Äôaccuratezza con cui un modello pu√≤ prevedere nuovi dati. Non essendo possibile calcolare direttamente l‚ÄôELPD, a causa della necessit√† di conoscere il meccanismo generatore dei dati \\(p_t(y)\\), ci affidiamo a una stima approssimativa fornita dalla distribuzione predittiva a posteriori del modello, \\(p(\\tilde{y} | y)\\).\nPer ottenere una stima pi√π accurata della capacit√† di generalizzazione di un modello su futuri set di dati, utilizziamo metodi di stima dell‚ÄôELPD basati sulla validazione incrociata. Questa tecnica consiste nell‚Äôaddestrare il modello su un sottoinsieme di dati e testarlo su un altro, isolando cos√¨ le prestazioni del modello dalle variazioni casuali presenti nei dati. Il risultato di questo processo √® l‚Äôindice di Leave-One-Out Cross-Validation (LOO-CV), fondamentale per comparare diversi modelli.\nLa differenza nei valori di Leave-One-Out Cross-Validation (LOO-CV) tra due modelli, accompagnata dal calcolo dell‚Äôerrore standard associato a questa differenza, ci consente di determinare se esiste una differenza robusta nelle prestazioni tra i due modelli. Se il rapporto tra questa differenza di LOO-CV e il relativo errore standard supera il valore di 2, possiamo concludere che i modelli mostrano differenze sostanziali. Questo indica che le variazioni osservate non sono casuali ma riflettono una superiorit√† effettiva di un modello rispetto all‚Äôaltro.\nIn questo capitolo, esploreremo il concetto di entropia, essenziale per quantificare l‚Äôincertezza nelle distribuzioni di probabilit√†. L‚Äôentropia di una variabile casuale rappresenta la media della sua imprevedibilit√†. Approfondiremo anche il modo in cui l‚Äôentropia pu√≤ essere impiegata per misurare la ‚Äúdistanza‚Äù tra un modello teorico e i dati osservati, introducendo il concetto di divergenza di Kullback-Leibler (\\(\\mathbb{KL}\\)). Questa metrica quantifica le discrepanze tra due distribuzioni probabilistiche, fornendo una misura di quanto efficacemente un modello rappresenti le osservazioni empiriche. Il capitolo successivo presenter√† un‚Äôanalisi della tecnica di Validazione Incrociata Leave-One-Out, impiegata per calcolare un‚Äôapprossimazione della divergenza \\(\\mathbb{KL}\\), nota come LOO-CV.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-generalizzabilit√†-dei-modelli-e-il-metodo-scientifico",
    "href": "chapters/entropy/01_entropy.html#la-generalizzabilit√†-dei-modelli-e-il-metodo-scientifico",
    "title": "79¬† Entropia",
    "section": "79.1 La Generalizzabilit√† dei Modelli e il Metodo Scientifico",
    "text": "79.1 La Generalizzabilit√† dei Modelli e il Metodo Scientifico\nLa generalizzabilit√† dei modelli √® un concetto chiave nella scienza, essendo uno dei fondamenti del metodo scientifico. Questo principio si riferisce alla capacit√† di un modello di applicarsi e produrre risultati validi oltre il contesto specifico o il set di dati in cui √® stato originariamente sviluppato o testato. Il valore scientifico di un modello √® quindi fortemente influenzato dalla sua capacit√† di generalizzarsi a nuovi dati.\nNella pratica, la generalizzabilit√† di un modello pu√≤ essere minacciata da due problemi principali: il sotto-adattamento e il sovra-adattamento. Il sotto-adattamento si verifica quando un modello √® troppo semplice per catturare adeguatamente la complessit√† dei dati, portando a prestazioni insoddisfacenti sia sui dati di addestramento che su nuovi insiemi di dati. Questo limita gravemente la sua utilit√† in applicazioni pratiche. Al contrario, il sovra-adattamento si manifesta quando un modello √® eccessivamente complesso, adattandosi troppo fedelmente al rumore o alle peculiarit√† specifiche del set di dati di addestramento a discapito della capacit√† di generalizzare a nuovi dati.\nL‚Äôapproccio bayesiano alla modellazione consente di gestire in modo efficace la necessit√† di un compromesso tra complessit√† del modello e adattamento ai dati. La selezione di modelli, come descritto da McElreath (2020), √® un processo che richiede di mediare tra la semplicit√† del modello e la sua capacit√† di rappresentare fedelmente la realt√† dei dati.\nUna pratica comune nella scelta tra modelli alternativi si basa sul principio del rasoio di Ockham, che predilige le spiegazioni pi√π semplici in presenza di multiple teorie equivalenti per un fenomeno. Tuttavia, questo principio da solo non √® sufficiente: √® essenziale che il modello scelto descriva accuratamente i dati.\nLa metodologia prevalente nella selezione dei modelli √® spesso centrata sull‚Äôuso dei valori-p, ma come evidenziato da McElreath (2020), questo approccio √® problematico e privo di una solida giustificazione teorica.\nUn metodo pi√π robusto e fondato scientificamente impiega invece la divergenza di Kullback-Leibler, una misura che valuta quanto un modello approssimi efficacemente la distribuzione reale dei dati, offrendo una stima quantitativa della sua aderenza al processo generativo sottostante. Questo capitolo pone le basi per comprendere il concetto di entropia, essenziale per affrontare nel prossimo capitolo la divergenza di Kullback-Leibler e le sue implicazioni nella selezione di modelli.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#cos√®-lentropia-dellinformazione",
    "href": "chapters/entropy/01_entropy.html#cos√®-lentropia-dellinformazione",
    "title": "79¬† Entropia",
    "section": "79.2 Cos‚Äô√® l‚ÄôEntropia dell‚ÄôInformazione?",
    "text": "79.2 Cos‚Äô√® l‚ÄôEntropia dell‚ÄôInformazione?\nL‚Äôentropia dell‚Äôinformazione, un concetto introdotto da Claude Shannon, rappresenta uno dei fondamenti della teoria dell‚Äôinformazione. Questa grandezza matematica quantifica l‚Äôincertezza o la sorpresa associata alla ricezione di un messaggio, misurando quanto sia sorprendente un evento in base alla sua probabilit√†. Gli eventi che si verificano con alta probabilit√† sono considerati meno sorprendenti perch√© prevedibili; al contrario, quelli meno probabili, essendo inaspettati, trasmettono pi√π sorpresa.\nLa sorpresa di un evento, determinata dalla sua probabilit√† \\(p\\), si calcola con la formula:\n\\[ H(p) = -\\log_2(p) = \\log_2 \\left(\\frac{1}{p}\\right). \\]\nL‚Äôuso del logaritmo in questa formula ha diverse giustificazioni:\n\nIl logaritmo converte la moltiplicazione delle probabilit√† in una somma. Questo semplifica l‚Äôanalisi di eventi complessi formati da pi√π eventi indipendenti.\nLa base del logaritmo (in questo caso, 2) corrisponde all‚Äôunit√† di misura dell‚Äôinformazione. La base 2 √® utilizzata perch√© l‚Äôinformazione viene misurata in bit, che rappresentano decisioni binarie.\nLa scala logaritmica riflette meglio la percezione umana dell‚Äôinformazione e della sorpresa. Eventi con probabilit√† molto basse hanno un impatto informativo molto maggiore rispetto a variazioni di probabilit√† in range pi√π alti.\n\n√à importante notare che la base del logaritmo pu√≤ variare: non ci sono unit√† intrinseche per misurare la sorpresa. Ad esempio, l‚Äôuso della base 2, comune nelle telecomunicazioni, porta a misurare l‚Äôinformazione in ‚Äúbit‚Äù. Al contrario, l‚Äôadozione della base \\(e\\), tipica nella fisica statistica, porta a misurazioni in ‚Äúnats‚Äù, o ‚Äúcifre naturali‚Äù.\nPer illustrare, consideriamo alcuni esempi pratici.\n\ndef calcola_entropia(p):\n    if p == 0 or p == 1:\n        return 0  # Non c'√® incertezza se l'evento √® certo o impossibile\n    else:\n        return -p * math.log2(p)\n\n# Esempi di probabilit√†\nprobabilit√† = [0.0, 0.1, 0.5, 0.9, 1.0]\n\n# Calcolo dell'entropia per ciascuna probabilit√†\nentropie = {p: calcola_entropia(p) for p in probabilit√†}\n\nprint(entropie)\n\n{0.0: 0, 0.1: 0.33219280948873625, 0.5: 0.5, 0.9: 0.13680278410054494, 1.0: 0}\n\n\nL‚Äôoutput di questo script mostra che l‚Äôentropia √® massima per eventi con probabilit√† intermedia (0.5) e minima (zero) per eventi certi o impossibili.\nIn generale, possiamo dunque dire che l‚Äôentropia raggiunge il suo valore massimo in condizioni di completa equiprobabilit√†, ovvero quando ogni esito possibile di un evento ha esattamente la stessa probabilit√† di verificarsi. Questa condizione rappresenta il massimo grado di imprevedibilit√†, poich√© non esistono indizi che possano aiutare a prevedere quale esito si verificher√†.\nAl contrario, l‚Äôentropia √® minima, assumendo un valore di zero, quando l‚Äôesito di un evento √® completamente certo. Questo avviene quando uno degli esiti possibili ha una probabilit√† di 1, eliminando qualsiasi forma di incertezza o sorpresa. In pratica, ci√≤ significa che non c‚Äô√® alcuna informazione da guadagnare nell‚Äôosservare l‚Äôevento, poich√© l‚Äôesito √® gi√† noto in anticipo.\n\n79.2.1 Additivit√† dell‚ÄôEntropia per Eventi Indipendenti\nL‚Äôentropia mostra una propriet√† di additivit√† nel caso di eventi indipendenti. Questo significa che, se due o pi√π eventi indipendenti si verificano, l‚Äôentropia totale associata alla loro combinazione √® uguale alla somma delle entropie di ciascun evento preso singolarmente. Questa caratteristica deriva dalla propriet√† additiva dei logaritmi, che permette di sommare le entropie individuali per ottenere l‚Äôentropia complessiva.\n\n\n79.2.2 Entropia di Variabili Casuali\nL‚Äôinformazione di Shannon misura la sorpresa di un singolo evento, ma √® possibile estendere questo concetto al caso di una distribuzione di probabilit√†, ovvero al caso di una variabile casuale discreta o continua. L‚Äôentropia fornisce una misura complessiva dell‚Äôincertezza o della sorpresa associata a una variabile casuale.\n\n79.2.2.1 Entropia di una Variabile Casuale Discreta\nConsideriamo una variabile casuale discreta \\(X\\) che pu√≤ assumere i valori \\(a_1, a_2, \\ldots, a_n\\) con le relative probabilit√† \\(p_1, p_2, \\ldots, p_n\\), dove la somma totale delle probabilit√† √® 1. L‚Äôentropia di $ X $ √® calcolata come la somma pesata delle entropie di ciascun possibile esito:\n\\[ H(X) = -\\sum_{i=1}^{n} p_i \\log_2(p_i). \\]\nLa formula somma le informazioni di tutti i possibili esiti, pesando ciascun termine con la probabilit√† \\(p_i\\) dell‚Äôesito stesso. Questo significa che gli esiti pi√π probabili influenzano maggiormente l‚Äôentropia totale rispetto a quelli meno probabili.\nIl logaritmo converte la moltiplicazione delle probabilit√† in una somma, semplificando i calcoli per eventi indipendenti.\nIl segno negativo √® necessario perch√© i logaritmi delle probabilit√†, essendo numeri minori di 1, sono negativi. Il segno negativo inverte questi valori, trasformandoli in quantit√† positive che rappresentano correttamente l‚Äôinformazione o la sorpresa. Inoltre, esiti pi√π probabili, avendo \\(p_i\\) maggiori, producono logaritmi negativi meno estremi, riflettendo la loro minore sorpresa.\nIn sintesi, l‚Äôentropia \\(H(X)\\) misura l‚Äôincertezza complessiva di una variabile casuale discreta, tenendo conto delle probabilit√† di tutti i suoi possibili esiti. Ogni termine della somma \\(-p_i \\log_2(p_i)\\) rappresenta la quantit√† di sorpresa o informazione associata a ciascun esito, ponderata dalla probabilit√† di quell‚Äôesito.\n\n\n79.2.2.2 Entropia di una Variabile Casuale Continua\nNel caso delle variabili casuali continue, il concetto di entropia viene generalizzato sostituendo la somma con un integrale. Questo √® necessario perch√© le variabili continue possono assumere un numero infinito di valori all‚Äôinterno di un intervallo.\nPer una variabile casuale continua \\(X\\) con una funzione di densit√† di probabilit√† \\(p(x)\\), l‚Äôentropia (nota anche come entropia differenziale) √® definita dalla seguente formula:\n\\[ H(X) = -\\int p(x) \\log_2(p(x)) \\, dx, \\]\ndove:\n\n\\(p(x)\\) √® la funzione di densit√† di probabilit√† di \\(X\\),\nl‚Äôintegrale √® calcolato su tutto il dominio di \\(X\\).\n\nL‚Äôentropia di una variabile casuale continua fornisce una misura dell‚Äôincertezza o della sorpresa associata alla distribuzione della variabile. Come nel caso discreto, l‚Äôentropia continua quantifica l‚Äôincertezza associata a \\(X\\). Una PDF molto concentrata (ad esempio, una distribuzione con picchi stretti) implica bassa entropia, poich√© l‚Äôevento √® pi√π prevedibile. Una PDF distribuita uniformemente implica alta entropia, poich√© l‚Äôevento √® meno prevedibile.\nIl segno negativo assicura che l‚Äôentropia sia una quantit√† positiva, in quanto \\(\\log_2(p(x))\\) √® negativo per \\(p(x)\\) compreso tra 0 e 1.\n\n\n\n79.2.3 Applicazioni Psicologiche\nL‚Äôentropia dell‚Äôinformazione trova applicazioni anche in psicologia, per esempio nello studio dell‚Äôeffetto della sorpresa sull‚Äôumore. La sorpresa, o entropia, √® stata documentata sia in laboratorio che in contesti naturali come un fattore significativo che influenza le emozioni.\nAd esempio, Spector (1956) osserv√≤ l‚Äôeffetto della probabilit√† a priori sulla soddisfazione dei soggetti in risposta a una promozione lavorativa. I risultati indicano che gli esiti meno probabili a priori (e quindi pi√π sorprendenti quando si verificano) hanno un impatto maggiore sull‚Äôumore. In altre parole, quando un evento inatteso e sorprendente si verifica, esso tende a influenzare l‚Äôumore in modo pi√π forte rispetto a eventi previsti e probabili.\n\n\n79.2.4 Divergenza di Kullback-Leibler: Uno Strumento per Confrontare Distribuzioni Probabilistiche\nLa divergenza \\(\\mathbb{KL}\\), introdotta da Kullback e Leibler nel 1951, estende il concetto di entropia di Shannon. Mentre l‚Äôentropia misura l‚Äôincertezza di una singola distribuzione di probabilit√†, la divergenza \\(\\mathbb{KL}\\) valuta quanto una distribuzione di probabilit√† \\(Q\\) differisca da un‚Äôaltra distribuzione di riferimento \\(P\\). Entrambe le distribuzioni devono descrivere la stessa variabile aleatoria \\(X\\).\n\n79.2.4.1 Calcolo della Divergenza \\(\\mathbb{KL}\\)\nSupponiamo che la variabile casuale \\(X\\) segua la distribuzione \\(P\\). L‚Äôentropia di Shannon, che quantifica la sorpresa media risultante dall‚Äôosservazione di esiti distribuiti secondo \\(P\\), si calcola come:\n\\[\nH(P) = -\\sum_x p(x) \\log(p(x)).\n\\]\nPer valutare quanto sarebbe sorprendente osservare \\(P\\) attraverso la lente di una distribuzione diversa \\(Q\\), calcoliamo l‚Äôentropia incrociata, definita come:\n\\[\nH(P, Q) = -\\sum_x p(x) \\log(q(x)).\n\\]\nQuesta misura rappresenta la sorpresa attesa se utilizzassimo \\(Q\\) anzich√© \\(P\\) per descrivere la variabile aleatoria \\(X\\).\nLa divergenza \\(\\mathbb{KL}\\), che √® la differenza tra l‚Äôentropia di \\(P\\) e l‚Äôentropia incrociata tra \\(P\\) e \\(Q\\), si esprime come:\n\\[\nD_{\\mathbb{KL}}(P \\parallel Q) = \\sum_x p(x) \\big(\\log(p(x)) - \\log(q(x))\\big).\n\\]\nAlternativamente, la formula precedente pu√≤ essere riscritta utilizzando il rapporto tra i logaritmi:\n\\[\nD_{\\mathbb{KL}}(P \\parallel Q) = \\sum_x p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right).\n\\]\nIn queste formule\n\\[\\log(p(x)) - \\log(q(x))\\]\nrappresenta il ‚Äúcosto‚Äù di sorpresa per ciascun esito \\(x\\), ponderato dalla probabilit√† \\(p(x)\\) di tale esito secondo la distribuzione originale \\(P\\). Questo costo quantifica quanto \\(Q\\) sia inadeguata a modellare o descrivere \\(P\\).\nLa divergenza \\(\\mathbb{KL}\\) quantifica ‚Äúquanto siamo sorpresi‚Äù nell‚Äôutilizzare \\(Q\\) per prevedere eventi distribuiti secondo \\(P\\) e riflette l‚Äôinformazione che viene ‚Äúpersa‚Äù quando \\(Q\\) √® usata al posto di \\(P\\).\nIn conclusione, la divergenza \\(\\mathbb{KL}\\) si basa su due misure fondamentali:\n\nEntropia di \\(P\\): Misura l‚Äôincertezza interna di \\(P\\).\nEntropia incrociata tra \\(P\\) e \\(Q\\): Quantifica l‚Äôincertezza quando \\(Q\\) √® utilizzata per stimare \\(P\\).\n\nCos√¨, la divergenza \\(\\mathbb{KL}\\) rappresenta la differenza tra l‚Äôentropia di \\(P\\) e l‚Äôentropia incrociata tra \\(P\\) e \\(Q\\), e mette in evidenza quanto l‚Äôuso di \\(Q\\) al posto di \\(P\\) incrementi l‚Äôincertezza o la sorpresa.\n\nEsempio 79.1 Per fare un esempio, supponiamo che \\(P\\) e \\(Q\\) siano due distribuzioni di probabilit√† su un insieme finito di possibili esiti, ad esempio {0, 1, 2}. Per semplicit√†, consideriamo che \\(P\\) e \\(Q\\) siano definite come segue:\n\n\\(P\\) √® la distribuzione ‚Äúvera‚Äù: \\(P = [0.1, 0.6, 0.3]\\);\n\\(Q\\) √® una distribuzione alternativa che usiamo per la stima: \\(Q = [0.2, 0.5, 0.3]\\).\n\n\n# Definizione delle distribuzioni\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.2, 0.5, 0.3])\n\n# Calcolo della divergenza KL da P a Q\nKL_divergence = np.sum(kl_div(P, Q))\n\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.0401\n\n\nNel codice precedente, kl_div(P, Q) calcola la divergenza \\(\\mathbb{KL}\\) elemento per elemento dell‚Äôarray. Essa calcola \\(\\sum_x p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)\\) per ogni esito \\(x\\), che √® esattamente il termine \\(p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)\\) descritto nella formula della divergenza \\(\\mathbb{KL}\\). Utilizziamo poi np.sum per sommare tutti i contributi individuali e ottenere il valore totale della divergenza \\(\\mathbb{KL}\\).\nQuesto esempio fornisce un calcolo diretto della divergenza \\(\\mathbb{KL}\\) tra due distribuzioni, mostrando come una distribuzione \\(Q\\) possa essere inadeguata nel modellare una distribuzione \\(P\\), con un focus sul ‚Äúcosto‚Äù di sorpresa per ogni esito.\n\n\nEsempio 79.2 In un due altri esempi, rendiamo via via \\(Q\\) pi√π diverso da \\(P\\). Notiamo come la divergenza \\(\\mathbb{KL}\\) aumenta.\n\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.35, 0.3, 0.35])\nKL_divergence = np.sum(kl_div(P, Q))\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.2444\n\n\n\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.6, 0.3, 0.1])\nKL_divergence = np.sum(kl_div(P, Q))\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.5663\n\n\n\n\n\n\n79.2.5 Applicazione della Divergenza \\(\\mathbb{KL}\\) nella Selezione di Modelli\nLa divergenza \\(\\mathbb{KL}\\) √® un indice fondamentale nella selezione di modelli statistici. L‚Äôobiettivo √® identificare il modello \\(Q\\) che minimizza \\(D_{\\mathbb{KL}}(P \\parallel Q)\\), ovvero ridurre al minimo la differenza \\(H(P) - H(P, Q)\\). Questo significa minimizzare l‚Äôerrore introdotto nell‚Äôapprossimare la distribuzione vera \\(P\\) con il modello \\(Q\\).\n\n79.2.5.1 Propriet√† Importanti\n\nNon-negativit√†: \\(D_{\\mathbb{KL}}(P \\parallel Q) \\geq 0\\). Il valore √® zero solamente quando \\(P\\) e \\(Q\\) sono identiche, indicando una perfetta corrispondenza.\nAsimmetria: \\(D_{\\mathbb{KL}}(P \\parallel Q) \\neq D_{\\mathbb{KL}}(Q \\parallel P)\\). Questa propriet√† evidenzia che la ‚Äúdistanza‚Äù percepita dal modello \\(Q\\) verso \\(P\\) non √® equivalente se misurata nella direzione inversa.\n\n\n\n79.2.5.2 Selezione dei Modelli Statistici\nNella selezione dei modelli statistici, l‚Äôobiettivo principale √® scegliere il modello \\(Q\\) che minimizzi la divergenza \\(\\mathbb{KL}\\) rispetto alla distribuzione ‚Äúvera‚Äù \\(P\\) dei dati. Tuttavia, \\(P\\) √® spesso sconosciuta o non direttamente osservabile.\nA causa di questa incertezza, i ricercatori e gli statistici utilizzano criteri approssimativi per stimare indirettamente la divergenza \\(\\mathbb{KL}\\). Nel capitolo successivo, esploreremo come questi criteri valutano sia la bont√† di adattamento del modello che la sua complessit√†.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "href": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "title": "79¬† Entropia",
    "section": "79.3 Riflessioni Conclusive",
    "text": "79.3 Riflessioni Conclusive\nIn questo capitolo, abbiamo esaminato il concetto di entropia, evidenziando il suo ruolo fondamentale nel quantificare l‚Äôincertezza all‚Äôinterno delle distribuzioni di probabilit√†. Abbiamo anche affrontato la questione di come l‚Äôentropia possa essere impiegata per valutare la ‚Äúdistanza‚Äù tra un modello teorico e i dati reali. A tale scopo, abbiamo introdotto la divergenza \\(\\mathbb{KL}\\), una misura che quantifica le discrepanze tra due distribuzioni di probabilit√†.\nNel capitolo successivo, approfondiremo ulteriormente il tema della divergenza \\(\\mathbb{KL}\\). Esploreremo come questo strumento possa essere utilizzato per confrontare modelli teorici con dati empirici e ci concentreremo su come possa fornirci una comprensione pi√π dettagliata dell‚Äôadattamento di un modello alla realt√† che intende rappresentare. Questa esplorazione ci permetter√† di valutare pi√π accuratamente la validit√† e la generalizzabilit√† dei modelli scientifici nel loro tentativo di catturare e interpretare la complessit√† dei fenomeni oggetto di studio.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#esercizi",
    "href": "chapters/entropy/01_entropy.html#esercizi",
    "title": "79¬† Entropia",
    "section": "79.4 Esercizi",
    "text": "79.4 Esercizi\n\nEsercizio 79.1 Cosideriamo due distribuzioni di probabilit√† discrete, \\(p\\) e \\(q\\):\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.1, 0.2, 0.7])\nSi calcoli l‚Äôentropia di \\(p\\), l‚Äôentropia incrociata tra \\(p\\) e \\(q\\), la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).\nSi consideri q = np.array([0.2, 0.55, 0.25]) e si calcoli di nuovo a divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). Si confronti con il risultato precedente e si interpreti.\n\n\nEsercizio 79.2 Sia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\). Sia \\(q_1\\) una approssimazione a \\(p\\): q1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01]). Sia \\(q_2\\) una distribuzione uniforme: q2 = [0.2] * 5. Si calcoli la divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) e da \\(q_2\\) da \\(p\\) e si interpretino i risultati.\n\n\nEsercizio 79.3 La Divergenza \\(\\mathbb{KL}\\) √® spesso paragonata a una ‚Äúdistanza‚Äù tra due distribuzioni di probabilit√†, ma √® fondamentale capire che non √® simmetrica. Questo significa che la misura di quanto \\(p\\) √® diversa da \\(q\\) non √® la stessa di quanto \\(q\\) √® diversa da \\(p\\). Questa asimmetria riflette la differenza nella perdita di informazione quando si sostituisce una distribuzione con l‚Äôaltra.\nPer le seguenti distribuzioni\np = np.array([0.01, 0.99])\nq = np.array([0.7, 0.3])\nsi calcoli l‚Äôentropia di p, l‚Äôentropia incrociata da p a q, la divergenza KL da p a q, l‚Äôentropia di q, l‚Äôentropia incrociata da q a p, e la divergenza KL da q a p.¬†Si commenti.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "title": "79¬† Entropia",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nscipy     : 1.14.0\npandas    : 2.2.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nSpector, Aaron J. 1956. ¬´Expectations, fulfillment, and morale¬ª. The Journal of Abnormal and Social Psychology 52 (1): 51‚Äì56.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>79</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html",
    "href": "chapters/entropy/02_kl.html",
    "title": "80¬† Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esamineremo in dettaglio quattro concetti fondamentali per la valutazione e il confronto di modelli statistici nel contesto bayesiano: la distribuzione predittiva posteriore, la Divergenza di Kullback-Leibler (\\(\\mathbb{KL}\\)), il Log-Pointwise-Predictive-Density (LPPD) e la Densit√† Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD). Questi strumenti ci permettono di quantificare l‚Äôadattamento dei modelli ai dati e la loro capacit√† predittiva.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#distribuzione-predittiva-posteriore",
    "href": "chapters/entropy/02_kl.html#distribuzione-predittiva-posteriore",
    "title": "80¬† Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "80.1 Distribuzione Predittiva Posteriore",
    "text": "80.1 Distribuzione Predittiva Posteriore\nLa distribuzione predittiva posteriore \\(q(\\tilde{y} \\mid y)\\) rappresenta la distribuzione dei possibili nuovi dati \\(\\tilde{y}\\), alla luce dei dati osservati \\(y\\). Essa si ottiene combinando:\n\nla distribuzione del modello per i nuovi dati data una configurazione dei parametri \\(\\theta\\): \\(q(\\tilde{y} \\mid \\theta)\\);\nla distribuzione posteriore dei parametri dati i dati osservati: \\(p(\\theta \\mid y)\\).\n\nMatematicamente, la distribuzione predittiva posteriore pu√≤ essere scritta come:\n\\[\nq(\\tilde{y} \\mid y) = \\int q(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta espressione si legge come l‚Äôintegrale della distribuzione predittiva \\(q(\\tilde{y} \\mid \\theta)\\) pesata dalla distribuzione posteriore dei parametri \\(p(\\theta \\mid y)\\). In altre parole, stiamo ‚Äúmediando‚Äù le previsioni del modello su tutte le possibili configurazioni dei parametri, tenendo conto della loro probabilit√† posteriore. La distribuzione predittiva posteriore √® stata descritta nella Sezione 47.1.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#divergenza-di-kullback-leibler-kl",
    "href": "chapters/entropy/02_kl.html#divergenza-di-kullback-leibler-kl",
    "title": "80¬† Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "80.2 Divergenza di Kullback-Leibler (KL)",
    "text": "80.2 Divergenza di Kullback-Leibler (KL)\nLa divergenza di Kullback-Leibler \\(\\mathbb{KL}(p \\parallel q)\\) misura la distanza tra due distribuzioni, \\(p\\) e \\(q\\). √à definita come:\n\\[\n\\mathbb{KL}(p \\parallel q) = \\mathbb{E}_p[\\log p(X)] - \\mathbb{E}_p[\\log q(X)].\n\\]\nIl termine \\(\\mathbb{E}_p[\\log p(X)]\\) √® il valore atteso del logaritmo della distribuzione \\(p(X)\\) sotto \\(p\\) stessa, cio√®:\n\\[\n\\mathbb{E}_p[\\log p(X)] = \\sum_{i=1}^n p_i \\log p_i.\n\\]\nPer distribuzioni continue, l‚Äôespressione diventa:\n\\[\n\\mathbb{E}_p[\\log p(X)] = \\int p(x) \\log p(x) \\, dx.\n\\]\nQuesto termine rappresenta l‚Äôentropia negativa della distribuzione \\(p\\).\nIl termine \\(\\mathbb{E}_p[\\log q(X)]\\) √® il valore atteso del logaritmo della distribuzione \\(q(X)\\) sotto la distribuzione \\(p(X)\\):\n\\[\n\\mathbb{E}_p[\\log q(X)] = \\sum_{i=1}^n p_i \\log q_i.\n\\]\nPer variabili continue:\n\\[\n\\mathbb{E}_p[\\log q(X)] = \\int p(x) \\log q(x) \\, dx.\n\\]\nQuesto rappresenta l‚Äôentropia incrociata tra \\(p\\) e \\(q\\).\nLa divergenza KL √® quindi:\n\\[\n\\mathbb{KL}(p \\parallel q) = \\sum_{i=1}^n p_i (\\log p_i - \\log q_i)\n\\]\no, in forma continua:\n\\[\n\\mathbb{KL}(p \\parallel q) = \\int p(x) (\\log p(x) - \\log q(x)) \\, dx\n\\]\nUn punto importante √® che la divergenza KL non √® simmetrica, il che significa che \\(\\mathbb{KL}(q \\parallel q) \\neq \\mathbb{KL}(q \\parallel p)\\). Questa divergenza misura quanta ‚Äúinformazione‚Äù si perde usando \\(q\\) al posto di \\(p\\).\n\nEsempio 80.1 Per rendere pi√π chiaro il concetto di divergenza KL nel caso discreto, consideriamo un esempio semplice. Immaginiamo di avere due distribuzioni di probabilit√† discrete, \\(p\\) e \\(q\\), su un insieme di eventi \\(\\{A, B, C\\}\\). Supponiamo che le probabilit√† associate a ciascun evento sotto le distribuzioni \\(p\\) e \\(q\\) siano le seguenti:\n\ndistribuzione \\(p\\): \\(p(A) = 0.5\\), \\(p(B) = 0.3\\), \\(p(C) = 0.2\\);\ndistribuzione \\(q\\): \\(q(A) = 0.4\\), \\(q(B) = 0.4\\), \\(q(C) = 0.2\\).\n\nLa divergenza KL \\(\\mathbb{KL}(p \\parallel q)\\) √® definita come:\n\\[\n\\mathbb{KL}(p \\parallel q) = \\sum_{i} p(i) \\log \\frac{p(i)}{q(i)},\n\\]\ndove \\(i\\) scorre su tutti gli eventi possibili \\(\\{A, B, C\\}\\). Quindi, dobbiamo calcolare \\(p(A) \\log \\frac{p(A)}{q(A)}\\), \\(p(B) \\log \\frac{p(B)}{q(B)}\\) e \\(p(C) \\log \\frac{p(C)}{q(C)}\\), ovvero,\n\\[\n   p(A) \\log \\frac{p(A)}{q(A)} = 0.5 \\log \\frac{0.5}{0.4} 0.11155,\n   \\]\n\\[\n   p(B) \\log \\frac{p(B)}{q(B)} = 0.3 \\log \\frac{0.3}{0.4} = -0.08631,\n   \\]\n\\[\n   p(C) \\log \\frac{p(C)}{q(C)} = 0.2 \\log \\frac{0.2}{0.2} = 0.\n   \\]\nOra sommiamo tutti i termini:\n\\[\n\\mathbb{KL}(p \\parallel q) = 0.11155 + (-0.08631) + 0 = 0.02524.\n\\]\nLa divergenza KL \\(\\mathbb{KL}(p \\parallel q) \\approx 0.025\\) indica che la distribuzione \\(q\\) non √® troppo lontana dalla distribuzione \\(p\\), ma c‚Äô√® una piccola discrepanza tra le due. Se il valore fosse maggiore, significherebbe che la distribuzione \\(q\\) si discosta maggiormente da \\(p\\), indicando una maggiore perdita di informazione se si usa \\(q\\) al posto di \\(p\\).\n\n\n80.2.1 Problema con \\(p\\) sconosciuto\nIl problema √® che in pratica non conosciamo \\(p\\), la ‚Äúverit√†‚Äù sottostante. Se conoscessimo \\(p\\), non avremmo bisogno di fare inferenza statistica. Tuttavia, vogliamo comunque confrontare diversi modelli \\(q\\) e \\(r\\) per capire quale si avvicina di pi√π a \\(p\\).\n\n\n80.2.2 L‚Äôidea della divergenza relativa\nFortunatamente, per confrontare due modelli \\(q\\) e \\(r\\), non √® necessario conoscere \\(p\\) esattamente. Possiamo confrontare i modelli in termini di divergenza relativa da \\(p\\). In pratica, molte delle componenti di \\(p\\) si annullano quando confrontiamo \\(q\\) e \\(r\\), perch√© la differenza tra le divergenze \\(\\mathbb{KL}(p \\parallel q)\\) e \\(\\mathbb{KL}(p \\parallel r)\\) non dipende da \\(p\\) in s√©, ma solo dalla differenza tra \\(q\\) e \\(r\\).\n\n\n80.2.3 Log-Probability Score (Log-Score)\nIl log-probability score (o log-score) √® una misura pratica che possiamo usare per valutare modelli in assenza della conoscenza di \\(p\\). Per ogni modello \\(q\\), si calcola:\n\\[\nS(q) = \\sum_{i} \\log(q_i).\n\\]\nQuesto score rappresenta una stima di \\(\\mathbb{E}[\\log(q_i)]\\), ovvero dell‚Äôaspettativa del logaritmo delle probabilit√† predette dal modello \\(q\\) rispetto ai dati osservati. Pi√π alto √® il log-score, migliore √® il modello in termini di accuratezza predittiva.\n\nEsempio 80.2 Consideriamo un semplice esempio numerico per illustrare il calcolo del log-probability score (o log-score) per un modello \\(q\\). Immaginiamo di avere un piccolo dataset con 3 osservazioni, e che il modello \\(q\\) predica le probabilit√† per ciascuna osservazione come segue:\n\nOsservazione 1: \\(q_1 = 0.8\\),\nOsservazione 2: \\(q_2 = 0.6\\),\nOsservazione 3: \\(q_3 = 0.7\\).\n\nIl log-score si calcola sommando i logaritmi delle probabilit√† predette:\n\\[\nS(q) = \\log(0.8) + \\log(0.6) + \\log(0.7) \\approx -0.2231 + (-0.5108) + (-0.3567) = -1.0906.\n\\]\nIl log-score totale per questo modello \\(q\\) √® \\(-1.0906\\). Poich√© un log-score pi√π alto (meno negativo) indica una migliore accuratezza predittiva, questo risultato suggerisce che \\(q\\) ha una discreta accuratezza per le osservazioni date. Un modello \\(r\\) con un log-score pi√π alto sarebbe preferibile in termini di accuratezza predittiva rispetto a \\(q\\).\n\n\nEsempio 80.3 Per chiarire ulteriormente il concetto di log-probability score, possiamo applicarlo al caso di un modello di regressione. In questo contesto, il calcolo del log-probability score implica la valutazione della probabilit√† che il modello assegna a ciascuna osservazione, considerando la distribuzione degli errori associata al modello.\nConsideriamo un modello di regressione lineare semplice:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i,\n\\]\ndove \\(y_i\\) √® la variabile dipendente, \\(x_i\\) √® la variabile indipendente, \\(\\beta_0\\) e \\(\\beta_1\\) sono i coefficienti del modello, e \\(\\epsilon_i\\) √® l‚Äôerrore, tipicamente assunto come distribuito secondo una normale \\(\\mathcal{N}(0, \\sigma^2)\\).\nPer calcolare la probabilit√† di ciascuna osservazione \\(y_i\\) data la predizione del modello, usiamo la distribuzione degli errori. Se \\(y_i\\) √® distribuito secondo una normale con media \\(\\hat{y}_i = \\beta_0 + \\beta_1 x_i\\) e varianza \\(\\sigma^2\\), allora la probabilit√† di osservare \\(y_i\\) √®:\n\\[\np(y_i \\mid x_i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\hat{y}_i)^2}{2\\sigma^2}\\right).\n\\]\nIl log-score per ciascuna osservazione √® il logaritmo della probabilit√† predetta:\n\\[\n\\log p(y_i \\mid x_i) = -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(y_i - \\hat{y}_i)^2}{2\\sigma^2}.\n\\]\nIl log-score totale del modello √® la somma dei log-score su tutte le osservazioni:\n\\[\nS(q) = \\sum_{i=1}^n \\log p(y_i \\mid x_i) = -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2.\n\\]\n\nPrimo termine: \\(-\\frac{n}{2} \\log(2\\pi\\sigma^2)\\) √® una costante che dipende dal numero di osservazioni \\(n\\) e dalla varianza degli errori \\(\\sigma^2\\).\nSecondo termine: \\(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\) √® proporzionale alla somma dei quadrati degli errori (SSE), che misura quanto le predizioni si discostano dai valori osservati.\n\nIl log-score fornisce quindi una misura dell‚Äôaccuratezza del modello di regressione, con valori pi√π alti (meno negativi) che indicano un modello migliore. In pratica, poich√© il primo termine √® una costante, la differenza nei log-score tra modelli diversi sar√† determinata principalmente dal secondo termine, legato alla SSE.\nIn sintesi, nel contesto di un modello di regressione, la probabilit√† di ciascuna osservazione si basa sulla distribuzione normale degli errori, e il log-score riflette quanto bene il modello predice i dati osservati, penalizzando modelli con errori pi√π grandi.\n\n\n\n80.2.4 Log-Pointwise-Predictive-Density (LPPD)\nIl Log-Pointwise-Predictive-Density (LPPD) √® una versione bayesiana del log-score, che tiene conto dell‚Äôincertezza sui parametri del modello. In un contesto bayesiano, non abbiamo un solo set di parametri \\(\\theta_s\\), ma una distribuzione posteriore su di essi. Pertanto, il log-score viene calcolato come una media logaritmica su questa distribuzione. Il LPPD √® una misura che deriva direttamente dalla distribuzione predittiva posteriore e rappresenta la somma delle densit√† predittive logaritmiche calcolate per ogni osservazione, mediate sulla distribuzione posteriore dei parametri. Formalmente, si definisce come:\n\\[\n\\text{LPPD} = \\sum_{i=1}^n \\log \\left(\\frac{1}{S} \\sum_{s=1}^{S} p(y_i \\mid \\theta_s)\\right),\n\\]\ndove:\n\n\\(y_i\\) √® l‚Äôi-esima osservazione,\n\\(S\\) √® il numero di campioni dalla distribuzione posteriore,\n\\(\\theta_s\\) √® un campione di parametri dalla distribuzione posteriore.\n\nIl LPPD tiene conto dell‚Äôincertezza nei parametri, calcolando il logaritmo della densit√† predittiva media per ogni punto dati, mediata su tutte le possibili configurazioni dei parametri posteriore. Questo approccio √® fondamentale per catturare la reale capacit√† predittiva di un modello, tenendo conto della variabilit√† nei parametri.\nIn conclusione, il log-score e il LPPD sono metodi per stimare la bont√† di un modello rispetto ai dati osservati, senza richiedere la conoscenza esatta di \\(p\\). Anche se non possiamo calcolare direttamente la divergenza di KL perch√© \\(p\\) √® sconosciuto, possiamo comunque confrontare diversi modelli basandoci su queste misure. La differenza tra i log-score (o LPPD) di due modelli \\(q\\) e \\(r\\) ci d√† un‚Äôinformazione su quale modello √® ‚Äúpi√π vicino‚Äù alla verit√†, analogamente a come useremmo la divergenza di KL se conoscessimo \\(p\\).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#expected-log-predictive-density-elpd",
    "href": "chapters/entropy/02_kl.html#expected-log-predictive-density-elpd",
    "title": "80¬† Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "80.3 Expected Log Predictive Density (ELPD)",
    "text": "80.3 Expected Log Predictive Density (ELPD)\nL‚ÄôExpected Log Predictive Density (ELPD) √® una misura che valuta la capacit√† predittiva di un modello utilizzando la tecnica della cross-validation. Si definisce come:\n\\[\n\\text{ELPD} = \\sum_{i=1}^n \\log p(y_i \\mid \\mathbf{y}_{-i}),\n\\]\ndove:\n\n\\(y_i\\) √® l‚Äôi-esima osservazione,\n\\(\\mathbf{y}_{-i}\\) rappresenta tutte le osservazioni eccetto \\(y_i\\).\n\nL‚ÄôELPD utilizza la Leave-One-Out Cross-Validation (LOO-CV) per stimare la densit√† predittiva logaritmica di ogni osservazione, escludendo quella stessa osservazione dal training. Questo metodo permette di evitare l‚Äôoverfitting, valutando la performance del modello su dati non visti.\n\nEsempio 80.4 Per illustrare il calcolo dell‚ÄôELPD, vediamo un esempio semplice con un set di dati molto piccolo. Supponiamo di avere un dataset di tre osservazioni: \\(y_1, y_2, y_3\\). Supponiamo che il nostro modello stimi le probabilit√† per ciascuna osservazione in base a tutte le altre osservazioni, cio√® utilizziamo la leave-one-out cross-validation (LOO-CV) per calcolare \\(p(y_i \\mid \\mathbf{y}_{-i})\\).\nImmaginiamo che il modello produca le seguenti probabilit√† condizionali per ogni osservazione \\(y_i\\):\n\n\\(p(y_1 \\mid y_2, y_3) = 0.6\\),\n\\(p(y_2 \\mid y_1, y_3) = 0.7\\),\n\\(p(y_3 \\mid y_1, y_2) = 0.5\\).\n\nL‚ÄôELPD si calcola sommando i logaritmi di queste probabilit√†:\n\\[\n\\text{ELPD} = \\log p(y_1 \\mid y_2, y_3) + \\log p(y_2 \\mid y_1, y_3) + \\log p(y_3 \\mid y_1, y_2).\n\\]\nCalcoliamo i logaritmi naturali di ciascuna probabilit√†:\n\n\\(\\log p(y_1 \\mid y_2, y_3) = \\log 0.6 \\approx -0.5108\\),\n\\(\\log p(y_2 \\mid y_1, y_3) = \\log 0.7 \\approx -0.3567\\),\n\\(\\log p(y_3 \\mid y_1, y_2) = \\log 0.5 \\approx -0.6931\\).\n\nSommiamo i logaritmi per ottenere l‚ÄôELPD:\n\\[\n\\text{ELPD} = -0.5108 + (-0.3567) + (-0.6931) = -1.5606.\n\\]\nL‚ÄôELPD ottenuto √® \\(-1.5606\\). In generale, valori pi√π vicini a 0 o positivi indicano una migliore capacit√† predittiva del modello, poich√© suggeriscono che le probabilit√† condizionali assegnate dal modello alle osservazioni lasciate fuori non sono troppo basse. Valori molto negativi indicherebbero che il modello ha assegnato probabilit√† molto basse alle osservazioni effettivamente osservate, suggerendo una scarsa capacit√† predittiva. L‚ÄôELPD √® un modo efficace per valutare quanto bene un modello generalizza a nuovi dati, evitando l‚Äôoverfitting.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#collegamento-tra-divergenza-kl-e-elpd",
    "href": "chapters/entropy/02_kl.html#collegamento-tra-divergenza-kl-e-elpd",
    "title": "80¬† Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "80.4 Collegamento tra Divergenza KL e ELPD",
    "text": "80.4 Collegamento tra Divergenza KL e ELPD\nEntrambe le misure (Divergenza KL e ELPD) valutano la qualit√† del modello, ma da prospettive diverse:\n\nla divergenza KL misura quanto la distribuzione predittiva del modello \\(Q\\) si avvicina alla ‚Äúvera‚Äù distribuzione \\(P\\);\nl‚ÄôELPD valuta direttamente la capacit√† del modello di prevedere nuovi dati, utilizzando la tecnica leave-one-out.\n\nL‚ÄôELPD tende a favorire modelli che non solo si adattano bene ai dati osservati, ma che sono anche robusti rispetto all‚Äôoverfitting, grazie alla sua enfasi sulla capacit√† predittiva su dati non osservati.\nIn sintesi, la distribuzione predittiva posteriori, la divergenza di Kullback-Leibler e l‚ÄôELPD sono strumenti matematici che ci permettono di valutare la bont√† di un modello statistico. La divergenza KL fornisce una misura teoricamente ideale di quanto un modello approssima la vera distribuzione dei dati, mentre l‚ÄôELPD offre un‚Äôalternativa praticabile che valuta la capacit√† del modello di fare previsioni su nuovi dati. Questi concetti sono fondamentali nell‚Äôinferenza bayesiana, dove √® importante non solo adattarsi ai dati esistenti, ma anche generalizzare bene su dati futuri.\n\nEsempio 80.5 Consideriamo un secondo esempio per illustrare il concetto di ELPD utilizzando la distribuzione binomiale. Immaginiamo di condurre un esperimento in cui lanciamo una moneta 10 volte e contiamo il numero di volte in cui otteniamo testa. Supponiamo che la vera probabilit√† di ottenere testa sia 0.6.\n\nDistribuzione reale dei dati: Segue una distribuzione binomiale con 10 lanci e probabilit√† di successo pari a 0.6: \\(y \\sim \\text{Binomiale}(10, 0.6).\\)\nDistribuzione stimata dal modello: Il nostro modello ipotizza che la probabilit√† di ottenere testa sia 0.5, cio√® considera la moneta come equa: \\(p(y \\mid \\theta) = \\text{Binomiale}(10, 0.5).\\)\n\nOra procediamo al calcolo dell‚ÄôELPD.\n\n# Parametri\nn = 10  # numero di lanci\np = 0.6  # vera probabilit√† di testa\nq = 0.5  # probabilit√† stimata dal modello\n\n# Calcolo ELPD\nelpd = 0\nfor y in range(n + 1):\n    # Probabilit√† di y secondo la vera distribuzione\n    p_y = binom.pmf(y, n, p)\n\n    # Log della densit√† predittiva del modello\n    log_q_y = binom.logpmf(y, n, q)\n\n    # Somma pesata\n    elpd += p_y * log_q_y\n\nprint(f\"ELPD del modello che stima p=0.5: {elpd:.4f}\")\n\n# Per confronto, calcoliamo l'ELPD per il modello \"vero\"\nelpd_true = 0\nfor y in range(n + 1):\n    p_y = binom.pmf(y, n, p)\n    log_p_y = binom.logpmf(y, n, p)\n    elpd_true += p_y * log_p_y\n\nprint(f\"ELPD del modello vero (con p=0.6): {elpd_true:.4f}\")\n\nELPD del modello che stima p=0.5: -2.0549\nELPD del modello vero (con p=0.6): -1.8536\n\n\nLa conclusione √® che l‚ÄôELPD del modello vero √® maggiore (meno negativo) rispetto a quello del nostro modello stimato, il che riflette una capacit√† predittiva superiore del modello vero.\nQuesto esempio dimostra come l‚ÄôELPD quantifica la capacit√† predittiva di un modello:\n\nSi considerano tutti i possibili risultati dell‚Äôesperimento (da 0 a 10 teste).\nPer ciascun risultato, si calcola:\n\nLa probabilit√† di osservare quel risultato secondo la distribuzione reale.\nIl logaritmo della densit√† predittiva del modello stimato \\(q\\) per lo stesso risultato.\n\nSi moltiplicano questi due valori e si sommano i risultati per tutti i possibili esiti.\n\nIn sintesi, l‚ÄôELPD permette di confrontare l‚Äôefficacia predittiva di diversi modelli: un valore pi√π alto (meno negativo) indica una migliore capacit√† del modello di prevedere i dati osservati. Nell‚Äôesempio presentato, il modello vero (con \\(p = 0.6\\)) ha un ELPD superiore rispetto al modello stimato (con \\(p = 0.5\\)), confermando che il primo ha una capacit√† predittiva migliore.\n\n\n80.4.1 Collegamento tra LPPD e ELPD\nIl LPPD e l‚ÄôELPD sono strettamente collegati e forniscono una valutazione robusta della capacit√† predittiva di un modello statistico. Il LPPD fornisce una stima del log-score basata sull‚Äôintera distribuzione posteriore dei parametri, mentre l‚ÄôELPD utilizza la cross-validation per stimare la capacit√† predittiva del modello su nuovi dati.\nSebbene il LPPD sia una buona misura, esso tende a migliorare con l‚Äôaumentare della complessit√† del modello, a causa del fenomeno dell‚Äôoverfitting. Il modello, infatti, potrebbe adattarsi perfettamente ai dati di addestramento, ma non generalizzare bene ai nuovi dati, catturando il ‚Äúrumore‚Äù presente nei dati piuttosto che il vero segnale sottostante.\n\n\n80.4.2 Leave-One-Out Cross-Validation (LOO-CV)\nLa cross-validation, in particolare la Leave-One-Out Cross-Validation (LOO-CV), √® una tecnica per affrontare questo problema. La LOO-CV valuta un modello lasciando fuori una sola osservazione dal dataset, addestrando il modello sul resto dei dati e poi testandolo sull‚Äôosservazione esclusa. Questo processo viene ripetuto per ogni osservazione nel dataset, e il risultato finale √® una media delle prestazioni del modello su tutte le osservazioni lasciate fuori.\nCome la divergenza KL, anche il calcolo dell‚ÄôELPD richiede, in teoria, la conoscenza della vera distribuzione \\(p\\), che √® ignota. Tuttavia, a differenza della divergenza KL, disponiamo di metodi pratici per approssimare l‚ÄôELPD senza la necessit√† di conoscere la vera distribuzione dei dati. Uno dei metodi pi√π robusti e comunemente utilizzati per questa stima √® la Leave-One-Out Cross-Validation (LOO-CV). Questo metodo consiste nel rimuovere una singola osservazione dal dataset, adattare il modello sui dati rimanenti, e poi valutare la densit√† predittiva per l‚Äôosservazione esclusa. Questa procedura viene ripetuta per ogni osservazione, e i risultati vengono sommati per ottenere una stima complessiva dell‚ÄôELPD.\nLa LOO-CV √® considerata uno dei metodi migliori per la selezione del modello perch√© fornisce una stima dell‚Äôaccuratezza predittiva del modello su dati che non sono stati utilizzati per addestrarlo. Questo approccio riduce il rischio di overfitting, poich√© misura come il modello si comporta su dati effettivamente ‚Äúnuovi‚Äù.\nQuindi, sebbene il log-probability score sia una buona misura, il suo miglioramento con l‚Äôaumentare della complessit√† del modello pu√≤ essere mitigato utilizzando tecniche di cross-validation, come la LOO-CV. Questo metodo fornisce una stima accurata della performance del modello su dati non visti, evitando cos√¨ il problema dell‚Äôoverfitting.\n\n\n80.4.3 Criteri di Informazione come Approssimazioni alla Divergenza KL\nOltre al LOO-CV, sono stati proposti altri metodi per approssimare l‚ÄôELPD, che derivano direttamente dal concetto di divergenza KL. Tra questi, i pi√π noti sono i criteri di informazione, come l‚Äôerrore quadratico medio (MSE), l‚ÄôAkaike Information Criterion (AIC), il Bayesian Information Criterion (BIC) e il Widely Applicable Information Criterion (WAIC). Questi criteri forniscono approcci alternativi per valutare i modelli, bilanciando la bont√† di adattamento del modello ai dati osservati con la sua complessit√†.\n\n80.4.3.1 Errore Quadratico Medio (MSE)\nL‚ÄôErrore Quadratico Medio (Mean Squared Error o MSE) misura la discrepanza media tra le previsioni del modello e i valori reali:\n\\[ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2, \\]\ndove:\n\n\\(n\\) √® il numero totale di osservazioni,\n\\(y_i\\) sono i valori reali,\n\\(\\hat{y}_i\\) sono i valori previsti dal modello.\n\nUn MSE inferiore indica un migliore adattamento del modello ai dati.\n\n\n80.4.3.2 Criterio di Informazione di Akaike (AIC)\nIl Criterio di Informazione di Akaike (AIC) va oltre l‚ÄôMSE, considerando sia l‚Äôadattamento del modello che la sua complessit√†:\n\\[ AIC = -2 \\sum \\log p(y_i \\mid \\hat{\\theta}_{\\text{mle}}) + 2k, \\]\ndove:\n\n\\(\\hat{\\theta}_{\\text{mle}}\\) sono i parametri stimati del modello,\n\\(k\\) √® il numero di parametri del modello.\n\nL‚ÄôAIC bilancia la bont√† di adattamento (primo termine) con la complessit√† del modello (secondo termine). Un valore pi√π basso di AIC indica una minor perdita di informazione, suggerendo un modello preferibile.\nVantaggi e limitazioni:\n\nfacile e veloce da calcolare;\npu√≤ essere meno accurato per campioni piccoli o modelli complessi;\nfornisce un‚Äôapprossimazione asintoticamente corretta dell‚ÄôELPD per modelli regolari e campioni grandi.\n\n\n\n80.4.3.3 Criterio di Informazione Bayesiano (BIC)\nIl Criterio di Informazione Bayesiano (BIC) √® definito come:\n\\[\nBIC = \\ln(n)k - 2\\ln(L),\n\\]\ndove:\n\n\\(n\\) √® il numero di osservazioni,\n\\(k\\) √® il numero di parametri del modello,\n\\(L\\) √® il valore massimo della funzione di verosimiglianza del modello.\n\nIl termine \\(\\ln(L)\\) rappresenta il logaritmo naturale della verosimiglianza massima, che indica quanto bene il modello si adatta ai dati osservati.\nIl BIC impone una penalit√† maggiore per l‚Äôincremento dei parametri, rendendolo particolarmente adeguato per dataset di grandi dimensioni.\n\n\n80.4.3.4 Widely Applicable Information Criterion (WAIC)\nIl WAIC √® una versione avanzata dell‚ÄôAIC, particolarmente utile nel contesto bayesiano. Considera l‚Äôintera distribuzione a posteriori dei parametri anzich√© solo la stima puntuale:\n\\[\nWAIC = -2\\left[ \\sum_{i=1}^{n} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p(y_i \\mid \\theta^{(s)}) \\right) - \\sum_{i=1}^{n} \\text{Var}_{\\theta^{(s)}} \\left( \\log p(y_i \\mid \\theta^{(s)}) \\right) \\right],\n\\]\ndove:\n\n\\(S\\) √® il numero di campioni dalla distribuzione a posteriori,\n\\(\\text{Var}_{\\theta^{(s)}}\\) √® la varianza della log-verosimiglianza.\n\nCaratteristiche del WAIC:\n\ncalcola il logaritmo della densit√† predittiva per ogni punto dati;\npenalizza la complessit√† del modello basandosi sulla variabilit√† delle sue predizioni;\nla somma delle varianze a posteriori del logaritmo della densit√† predittiva converge al numero effettivo di parametri del modello.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#considerazioni-conclusive",
    "href": "chapters/entropy/02_kl.html#considerazioni-conclusive",
    "title": "80¬† Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "80.5 Considerazioni Conclusive",
    "text": "80.5 Considerazioni Conclusive\nLa valutazione dei modelli statistici √® fondamentale per garantirne l‚Äôaffidabilit√† e la capacit√† di generalizzazione. Quando si sviluppano modelli, √® essenziale disporre di strumenti che permettano di confrontare diverse alternative e selezionare quella pi√π adatta ai dati, assicurando previsioni accurate.\nIl LPPD (Log Pointwise Predictive Density) e l‚ÄôELPD (Expected Log Pointwise Predictive Density) sono due importanti strumenti per la valutazione dei modelli statistici in ambito bayesiano. Sebbene la divergenza KL (Kullback-Leibler) rappresenti una misura ideale per quantificare la distanza tra la distribuzione di probabilit√† reale dei dati e quella stimata dal modello, la sua applicazione pratica √® limitata in quanto richiede la conoscenza della distribuzione vera dei dati, che √® generalmente sconosciuta.\nA differenza della divergenza KL, il LPPD offre un approccio praticabile per valutare la capacit√† predittiva dei modelli. Tuttavia, il LPPD soffre del problema dell‚Äôoverfitting. Per superare questo ostacolo, si utilizza l‚ÄôELPD, che stima la capacit√† predittiva del modello su nuovi dati, ovvero la sua abilit√† di generalizzare oltre i dati di addestramento.\nL‚ÄôELPD e la divergenza KL sono pertanto strumenti complementari per la valutazione dei modelli statistici. L‚ÄôELPD misura la capacit√† predittiva su nuovi dati, con valori pi√π alti che indicano previsioni migliori e una maggiore capacit√† di generalizzazione. La divergenza KL, invece, quantifica la differenza tra la distribuzione vera dei dati e quella stimata dal modello, con valori pi√π bassi che indicano una migliore approssimazione della distribuzione reale da parte del modello.\nEsiste una relazione diretta tra ELPD e divergenza KL: massimizzare l‚ÄôELPD equivale a minimizzare la divergenza KL. Entrambi gli approcci mirano a sviluppare modelli in grado di catturare al meglio la realt√† rappresentata dai dati.\nIn pratica, la divergenza KL valuta l‚Äôadattamento del modello ai dati osservati, mentre l‚ÄôELPD e i suoi metodi di approssimazione (come LOO-CV) misurano la capacit√† del modello di generalizzare su dati futuri, offrendo una valutazione pi√π completa della qualit√† del modello.\nLa selezione del modello ottimale richiede quindi un equilibrio tra adattamento ai dati e semplicit√†. L‚Äôuso combinato di tecniche di validazione incrociata (come il LOO-CV) e criteri di informazione (come AIC, BIC e WAIC) permette di costruire modelli che si adattano bene ai dati osservati, forniscono previsioni affidabili su nuovi dati e catturano le tendenze rilevanti senza essere eccessivamente influenzati dal rumore.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/02_kl.html#informazioni-sullambiente-di-sviluppo",
    "title": "80¬† Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nscipy     : 1.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>80</span>¬† <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_loo.html",
    "href": "chapters/entropy/03_loo.html",
    "title": "81¬† Validazione Incrociata Leave-One-Out",
    "section": "",
    "text": "Introduzione\nLa capacit√† di generalizzazione di un modello statistico, ossia la sua abilit√† di fare previsioni accurate su nuovi dati, √® un aspetto cruciale nella modellazione statistica (per uno studio recente, si veda, ad esempio, Chekroud et al. (2024)). Per valutare quantitativamente questa capacit√†, sono state sviluppate diverse metriche. Tra queste, la Densit√† Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD) √® particolarmente apprezzata per la sua efficacia. L‚ÄôELPD fornisce una stima diretta della capacit√† di un modello di prevedere nuovi dati, rendendola un indicatore fondamentale della sua capacit√† di generalizzazione.\nUno dei metodi pi√π efficaci e comunemente utilizzati per stimare l‚ÄôELPD √® la validazione incrociata Leave-One-Out (LOO-CV), come discusso nella sezione Capitolo 80. Questo metodo simula uno scenario di previsione su nuovi dati escludendo sistematicamente ogni singola osservazione dal set di addestramento e valutando la capacit√† del modello di predire l‚Äôosservazione esclusa. In questo capitolo, approfondiremo la metodologia LOO-CV e mostreremo come essa venga applicata per valutare e selezionare modelli statistici in base alla loro capacit√† di generalizzare.\nNegli esempio successivi, mostreremo come applicare questi concetti utilizzando cmdstan. Questo approccio pratico illustrer√† l‚Äôintero processo di selezione e valutazione del modello, fornendo un metodo robusto per scegliere il modello pi√π appropriato, tenendo conto sia della sua capacit√† predittiva che della sua adeguatezza ai dati osservati.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_loo.html#il-problema-del-sovra-adattamento",
    "href": "chapters/entropy/03_loo.html#il-problema-del-sovra-adattamento",
    "title": "81¬† Validazione Incrociata Leave-One-Out",
    "section": "81.1 Il Problema del Sovra-adattamento",
    "text": "81.1 Il Problema del Sovra-adattamento\nUno dei problemi pi√π comuni che emerge durante la costruzione di un modello statistico √® il sovra-adattamento, o overfitting. Questo fenomeno si verifica quando un modello si adatta eccessivamente ai dati di addestramento, catturando non solo le tendenze generali, ma anche le fluttuazioni casuali e gli errori presenti nei dati.\n\n81.1.1 Perch√© il Sovra-adattamento √® un Problema?\nUn modello sovra-adattato pu√≤ mostrare prestazioni eccellenti sui dati di addestramento, ma tende a fallire quando applicato a nuovi dati. In altre parole, il modello ‚Äúimpara a memoria‚Äù i dati di addestramento piuttosto che apprendere le regole generali che li governano. Questo compromette la sua capacit√† di generalizzazione, rendendolo inaffidabile per previsioni future.\nPer evitare il sovra-adattamento, √® necessario bilanciare la capacit√† del modello di adattarsi ai dati di addestramento con la sua capacit√† di generalizzare a nuovi dati. Questo equilibrio √® noto come il ‚Äútrade-off‚Äù tra bias e varianza.\n\n\n81.1.2 Tecniche di Validazione\nPer prevenire il sovra-adattamento, si utilizzano tecniche di validazione, che permettono di valutare quanto bene un modello si comporter√† su dati non visti. Una delle tecniche pi√π importanti in questo contesto √® la validazione incrociata (cross-validation).\n\n\n81.1.3 Validazione Incrociata (Cross-Validation)\nLa validazione incrociata √® una metodologia che consente di testare il modello su dati che non ha mai visto durante l‚Äôaddestramento. Esistono diverse varianti di validazione incrociata, tra cui:\n\nK-fold cross-validation:\n\nI dati vengono divisi in K gruppi (o ‚Äúfold‚Äù).\nSi addestra il modello su K-1 gruppi e si testa sull‚Äôultimo gruppo.\nQuesto processo viene ripetuto K volte, utilizzando ogni volta un gruppo diverso per il test.\nI risultati vengono poi mediati per ottenere una stima complessiva della performance del modello.\n\nAd esempio, con K = 5, i dati vengono suddivisi in 5 parti; il modello viene addestrato su 4 parti e testato sulla quinta, ripetendo il processo 5 volte.\nLeave-one-out cross-validation (LOO-CV):\n\n√à una forma estrema di K-fold in cui K √® pari al numero totale di osservazioni.\nOgni volta, si esclude una singola osservazione dal set di addestramento e si utilizza il modello per prevedere quell‚Äôosservazione.\nQuesto processo viene ripetuto per ogni osservazione nel dataset.\n\nIl LOO-CV √® particolarmente utile per ottenere una stima precisa della capacit√† del modello di generalizzare, ma pu√≤ essere computazionalmente intensivo.\n\nQueste tecniche di validazione forniscono una misura accurata della capacit√† di un modello di generalizzare su nuovi dati.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_loo.html#applicazioni-pratiche",
    "href": "chapters/entropy/03_loo.html#applicazioni-pratiche",
    "title": "81¬† Validazione Incrociata Leave-One-Out",
    "section": "81.2 Applicazioni Pratiche",
    "text": "81.2 Applicazioni Pratiche\nNel contesto dell‚Äôinferenza bayesiana, la selezione del modello si basa principalmente sul confronto delle stime dell‚ÄôELPD ottenute tramite la Leave-One-Out Cross-Validation (LOO-CV). Questo processo pu√≤ essere implementato in modo efficiente utilizzando le funzioni del pacchetto ArviZ.\n√à importante notare che l‚Äôaffidabilit√† di questi confronti dipende dalla qualit√† dei dati e dall‚Äôadeguatezza dei modelli. Per ottenere valutazioni accurate, √® essenziale che i modelli si adattino in modo appropriato ai dati disponibili. Un aspetto cruciale di questa valutazione √® rappresentato dal calcolo dei valori diagnostici di Pareto \\(k\\).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_loo.html#valori-diagnostici-pareto-k",
    "href": "chapters/entropy/03_loo.html#valori-diagnostici-pareto-k",
    "title": "81¬† Validazione Incrociata Leave-One-Out",
    "section": "81.3 Valori Diagnostici Pareto \\(k\\)",
    "text": "81.3 Valori Diagnostici Pareto \\(k\\)\nI valori diagnostici di Pareto \\(k\\) sono fondamentali per valutare la stabilit√† e l‚Äôaffidabilit√† delle stime ottenute tramite la Leave-One-Out Cross-Validation (LOO-CV). In particolare, essi misurano l‚Äôinfluenza di singoli punti dati sulle stime del modello. Valori di \\(k\\) elevati possono indicare che alcune osservazioni hanno un‚Äôinfluenza eccessiva, il che pu√≤ compromettere la validit√† delle stime fornite dalla LOO-CV.\nIl valore di Pareto \\(k\\) fornisce un‚Äôindicazione dell‚Äôaffidabilit√† della stima:\n\n\\(k &lt; 0.5\\): L‚Äôapprossimazione √® eccellente e l‚Äôerrore nella stima dell‚ÄôELPD √® trascurabile.\n\\(0.5 \\leq k &lt; 0.7\\): L‚Äôapprossimazione √® accettabile, ma potrebbe essere utile esaminare pi√π attentamente il modello e i dati.\n\\(0.7 \\leq k &lt; 1\\): L‚Äôapprossimazione diventa mediocre, rendendo i risultati della LOO-CV meno affidabili e potenzialmente inadeguati.\n\\(k \\geq 1\\): Un valore cos√¨ elevato segnala un‚Äôapprossimazione inadeguata, suggerendo che i risultati ottenuti potrebbero essere significativamente distorti, evidenziando problemi nel modello o nella metodologia.\n\nIl valore di Pareto \\(k\\) si basa sulla distribuzione di Pareto per valutare le discrepanze nelle log-verosimiglianze, cio√® le differenze tra la log-verosimiglianza calcolata escludendo un dato e quella ottenuta utilizzando l‚Äôintero dataset. Valori alti di \\(k\\) indicano code pi√π pesanti del previsto nella distribuzione delle discrepanze, suggerendo che l‚Äôapprossimazione potrebbe non essere accurata.\nIn sintesi, i valori di Pareto \\(k\\) forniscono un indicatore chiave dell‚Äôaccuratezza dell‚Äôapprossimazione fornita dalla LOO-CV e aiutano a identificare eventuali problemi nel modello statistico o nella metodologia utilizzata.\n\nEsempio 81.1 Per fare un esempio relativo al calcolo dei valore di Pareto \\(k\\), generiamo un set di dati artificiali seguendo una distribuzione normale con una media di 5 e una deviazione standard di 2. Scegliamo una dimensione del campione di 100.\n\ny = np.random.normal(loc=5, scale=2, size=100)\nprint(y[0:10])\n\n[ 3.55144618  7.24614848  3.17600124 10.48005661  0.24404946  3.9483861\n  3.47263944  1.50310884  4.7620044   6.45235628]\n\n\nInseriamo i dati in un dizionario nel formato atteso da Stan.\n\nstan_data = {\"N\": len(y), \"y\": y}\n\nAdattiamo ai dati un modello normale stimando la media (mu) e la deviazione standard (sigma) del modello attraverso il campionamento MCMC.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'gaussian-mod-log-lik.stan')\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // Priors\n  mu ~ normal(5, 2);         // Prior for mu, centered around the known mean with some uncertainty\n  sigma ~ normal(0, 2);      // Half-normal prior for sigma (implying positive values)\n  \n  // Likelihood\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  for (n in 1:N)\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma);\n}\n\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False, \n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori.\n\naz.summary(fit, var_names=['mu', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n4.73\n0.21\n4.33\n5.12\n0.0\n0.0\n6461.15\n5090.21\n1.0\n\n\nsigma\n2.12\n0.15\n1.84\n2.40\n0.0\n0.0\n6389.72\n5247.38\n1.0\n\n\n\n\n\n\n\n\nConvertiamo l‚Äôoggetto creato da cmdstanpy nella classe InferenceData richiesta da ArviZ:\n\nfit_az = az.from_cmdstanpy(posterior=fit)\n\nEseguiamo la LOO-CV usando ArviZ:\n\nloo_result = az.loo(fit_az)\nprint(loo_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -217.79     6.76\np_loo        1.92        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nPoich√© il modello si adatta bene a questi dati, tutti i valori di Pareto \\(k\\) sono molto bassi, indicando che nessuna osservazione ha un‚Äôinfluenza eccessiva sulle stime del modello. Di conseguenza, non vi √® alcuna evidenza che la stima dell‚ÄôELPD, che in questo caso √® pari a -217.79, possa essere distorta. Questo suggerisce che la stima √® affidabile e rappresenta accuratamente la capacit√† predittiva del modello.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_loo.html#il-ruolo-dellelpd-nella-valutazione-comparativa-dei-modelli",
    "href": "chapters/entropy/03_loo.html#il-ruolo-dellelpd-nella-valutazione-comparativa-dei-modelli",
    "title": "81¬† Validazione Incrociata Leave-One-Out",
    "section": "81.4 Il Ruolo dell‚ÄôELPD nella Valutazione Comparativa dei Modelli",
    "text": "81.4 Il Ruolo dell‚ÄôELPD nella Valutazione Comparativa dei Modelli\nL‚ÄôELPD svolge un ruolo cruciale nel confronto tra diversi modelli statistici. Grazie a metodologie come la Leave-One-Out Cross-Validation (LOO-CV), √® possibile stimare l‚ÄôELPD e ottenere una valutazione oggettiva dell‚Äôadeguatezza di ciascun modello rispetto ai dati. Questo √® particolarmente importante quando si tratta di scegliere il modello pi√π appropriato tra diverse opzioni o di valutare se un modello pi√π complesso offre un vantaggio significativo rispetto a uno pi√π semplice.\nIn sintesi, l‚ÄôELPD fornisce un indicatore affidabile della capacit√† predittiva di un modello. La LOO-CV, a sua volta, rappresenta un metodo efficace per stimare questa metrica, consentendo un‚Äôanalisi precisa e robusta delle prestazioni dei diversi modelli. L‚Äôautomazione di queste procedure attraverso software come PyMC e Arviz rende l‚Äôintero processo ancora pi√π pratico e accessibile, consolidando l‚ÄôELPD come uno strumento essenziale per la selezione e la validazione dei modelli statistici.\n\n81.4.1 Simulazione\nPer dimostrare come confrontare i modelli utilizzando la LOO-CV, procediamo con una simulazione. Genereremo dati sintetici in cui esiste una relazione lineare tra le variabili \\(x\\) e \\(y\\). In questo contesto, confronteremo un modello lineare con un modello pi√π semplice che considera solo il termine dell‚Äôintercetta. Utilizzeremo la LOO-CV per determinare quale dei due modelli si adatta meglio ai dati. La stima dell‚ÄôELPD sar√† il criterio quantitativo che guider√† la scelta del modello pi√π appropriato.\n\n# Generate synthetic data\nnp.random.seed(42)\nx = np.linspace(0, 10, 100)\ny_true = 3 + 2 * x\ny_obs = y_true + np.random.normal(scale=3, size=100)\nzx = stats.zscore(x)\nzy = stats.zscore(y_obs)\nprint(np.mean(zy), np.std(zy))\n\n-2.19824158875781e-16 1.0\n\n\nAdattiamo ai dati un modello che rispecchia il vero meccanismo generativo dei dati.\nSi noti che, per calcolare LOO e WAIC, ArviZ ha bisogno di accedere alla log-likelihood per ogni campione posteriore. Possiamo trovarla tramite compute_log_likelihood(). In alternativa, possiamo passare idata_kwargs={\"log_likelihood\": True} a sample() per farla calcolare automaticamente alla fine del campionamento.\n\nstan_lin_reg_file = os.path.join(\n    project_directory, 'stan', 'linear-regression.stan'\n)\n\nmodel_lin_reg = CmdStanModel(stan_file=stan_lin_reg_file)\nprint(model_lin_reg.code())\n\n// all data should be scaled to mean 0 and std 1:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  vector[N] y_rep;\n  for (n in 1:N) {\n    log_lik[n] = normal_lpdf(y[n] | alpha + beta * x[n], sigma);\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\nInseriamo i dati simulati in un dizionario.\n\n# Prepare the stan_data dictionary\nstan_data = {\n    'N': len(zx),\n    'x': zx,\n    'y': zy\n}\n\nEseguiamo il campionamento.\n\nfit2 = model_lin_reg.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False, \n    show_console=False\n)\n\nEsaminiamo le stime a posteriori dei parametri del modello.\n\naz.summary(fit2, var_names=['beta', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta\n0.91\n0.04\n0.83\n0.99\n0.0\n0.0\n7484.76\n6278.45\n1.0\n\n\nsigma\n0.42\n0.03\n0.37\n0.48\n0.0\n0.0\n7021.01\n5523.71\n1.0\n\n\n\n\n\n\n\n\nReplichiamo i risultati usando le funzioni di pingouin:\n\n# Create a DataFrame\ndf = pd.DataFrame({\n    \"x\": zx,\n    \"y\": zy\n})\n\n# Perform linear regression using pingouin\nregression_results = pg.linear_regression(df[['x']], df['y'])\n\n# Print the regression results\nprint(regression_results)\n\n       names          coef        se             T          pval        r2  \\\n0  Intercept -2.220446e-16  0.041834 -5.307754e-15  1.000000e+00  0.828492   \n1          x  9.102152e-01  0.041834  2.175778e+01  2.661609e-39  0.828492   \n\n     adj_r2  CI[2.5%]  CI[97.5%]  \n0  0.826742 -0.083018   0.083018  \n1  0.826742  0.827197   0.993233  \n\n\nCalcoliamo l‚ÄôELPD con il metodo LOO-CV.\n\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit2_az = az.from_cmdstanpy(posterior=fit2)\n\n# Perform LOO-CV using ArviZ\nloo2_result = az.loo(fit2_az)\nprint(loo2_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -56.70     6.89\np_loo        2.78        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nAdattiamo ora ai dati un secondo modello che non tiene conto della relazione lineare tra \\(x\\) e \\(y\\), ovvero contiene solo l‚Äôintercetta.\n\nstan_lin_reg_file_only_alpha = os.path.join(\n    project_directory, 'stan', 'linear-regression-only-alpha.stan')\n\nmodel_lin_reg_only_alpha = CmdStanModel(stan_file=stan_lin_reg_file_only_alpha)\nprint(model_lin_reg_only_alpha.code())\n\n// all data should be scaled to mean 0 and std 1:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha, sigma);\n  alpha ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  vector[N] y_rep;\n  for (n in 1:N) {\n    log_lik[n] = normal_lpdf(y[n] | alpha, sigma);\n    y_rep[n] = normal_rng(alpha, sigma);\n  }\n}\n\n\n\nEseguiamo il campionamento.\n\nfit3 = model_lin_reg_only_alpha.sample(\n    data=stan_data,\n    iter_warmup = 2_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n\naz.summary(fit3, var_names=['alpha', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.00\n0.10\n-0.19\n0.20\n0.0\n0.0\n5474.54\n4913.19\n1.0\n\n\nsigma\n1.02\n0.07\n0.89\n1.16\n0.0\n0.0\n5742.53\n4496.71\n1.0\n\n\n\n\n\n\n\n\nStimiamo l‚ÄôELPD con il metodo LOO-CV per il modello che ignora la relazione lineare.\n\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit3_az = az.from_cmdstanpy(posterior=fit3)\n\n# Perform LOO-CV using ArviZ\nloo3_result = az.loo(fit3_az)\nprint(loo3_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -143.65     4.52\np_loo        1.43        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nInfine, calcoliamo la differenza tra le stime dell‚ÄôELPD (elpd_diff) dei due modelli. L‚Äôincertezza associata a questa differenza √® espressa dal suo errore standard (dse). Se il rapporto tra elpd_diff e dse √® pari o superiore a 2, possiamo concludere che esiste una differenza significativa e credibile tra i due modelli.\nNell‚Äôoutput del comando az.compare(), il modello con il valore di elpd_loo pi√π alto (indicativo di una migliore capacit√† predittiva) viene elencato per primo.\n\ndf_comp_loo = az.compare({\"linear_model\": loo2_result, \"intercept_model\": loo3_result})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nlinear_model\n0\n-56.814716\n2.873961\n0.000000\n1.000000e+00\n6.890641\n0.000000\nFalse\nlog\n\n\nintercept_model\n1\n-143.633507\n1.403145\n86.818792\n2.428635e-11\n4.516124\n7.956892\nFalse\nlog\n\n\n\n\n\n\n\n\nNel caso attuale, il modello linear_model riflette accuratamente il modo in cui i dati sono stati generati. Questo √® confermato dal fatto che viene preferito in base al valore di elpd_loo. Inoltre, il rapporto tra elpd_diff e il suo errore standard √® notevolmente superiore a 2, il che indica chiaramente che, per questi dati, il modello lineare √® nettamente preferibile rispetto al modello che include solo l‚Äôintercetta.\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_loo.html#riflessioni-conclusive",
    "href": "chapters/entropy/03_loo.html#riflessioni-conclusive",
    "title": "81¬† Validazione Incrociata Leave-One-Out",
    "section": "81.5 Riflessioni Conclusive",
    "text": "81.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato in dettaglio il metodo della Validazione Incrociata Leave-One-Out (LOO-CV) e il suo utilizzo nel framework cmdstan, sottolineando la sua importanza nella pratica della modellazione statistica.\nUn punto centrale della discussione √® stato il ruolo fondamentale della LOO-CV nel confronto tra diversi modelli. Questo metodo non solo consente di valutare la capacit√† predittiva di un singolo modello, ma si rivela anche indispensabile quando si tratta di scegliere il modello pi√π adeguato tra diverse alternative. La LOO-CV fornisce infatti una base di confronto oggettiva e affidabile, permettendo di identificare il modello che meglio si adatta ai dati e che possiede la maggiore capacit√† di generalizzazione.\nInoltre, abbiamo approfondito l‚Äôimportanza dei valori diagnostici Pareto \\(k\\) nell‚Äôinterpretazione delle stime ottenute tramite LOO-CV. Questi valori diagnostici sono cruciali per valutare l‚Äôaffidabilit√† delle stime dell‚ÄôELPD derivate dalla LOO-CV, poich√© forniscono un‚Äôindicazione sulla precisione e robustezza di queste stime. Valori di Pareto \\(k\\) elevati possono segnalare che alcune osservazioni influenzano eccessivamente le stime, indicando possibili problemi di modellizzazione che potrebbero compromettere la validit√† delle conclusioni.\nIn sintesi, la combinazione di LOO-CV e dei valori diagnostici Pareto \\(k\\) offre un approccio robusto e affidabile per la valutazione e selezione dei modelli statistici, garantendo che le scelte effettuate siano basate su criteri solidi e verificabili. Questo metodo si dimostra quindi essenziale non solo per valutare la qualit√† di un singolo modello, ma anche per assicurare che la selezione del modello ottimale sia supportata da una rigorosa analisi quantitativa.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_loo.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/03_loo.html#informazioni-sullambiente-di-sviluppo",
    "title": "81¬† Validazione Incrociata Leave-One-Out",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sat Jul 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\npingouin  : 0.5.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nChekroud, Adam M, Matt Hawrilenko, Hieronimus Loho, Julia Bondar, Ralitza Gueorguieva, Alkomiet Hasan, Joseph Kambeitz, et al. 2024. ¬´Illusory generalizability of clinical prediction models¬ª. Science 383 (6679): 164‚Äì67.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>81</span>¬† <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_cognitive_modeling.html",
    "href": "chapters/entropy/04_cognitive_modeling.html",
    "title": "82¬† Dall‚Äôanalisi descrittiva alla modellazione cognitiva",
    "section": "",
    "text": "82.1 Introduzione\nNell‚Äôanalisi dei dati psicologici, l‚Äôapproccio tradizionale si basa spesso su confronti descrittivi, come la differenza tra le medie di due condizioni sperimentali. Sebbene questo approccio possa fornire informazioni utili, √® limitato nella sua capacit√† di rivelare la complessit√† dei processi psicologici sottostanti. Un‚Äôanalisi che si fermi a questo livello rischia di non cogliere la ricchezza dei meccanismi psicologici che realmente generano i dati osservati. Come sottolineato da McElreath (2020), un vero avanzamento nella comprensione dei fenomeni richiede l‚Äôadozione di modelli che siano esplicitamente formulati in termini di processi generativi sottostanti.\nUn modello generativo non si limita a descrivere i dati; piuttosto, esso riflette un‚Äôipotesi teorica su come i dati vengano effettivamente prodotti. Questo tipo di modellizzazione consente di testare ipotesi teoriche complesse e di confrontare l‚Äôadeguatezza di diversi modelli esplicativi. In questo modo, la ricerca non solo quantifica differenze osservate, ma esplora le cause e i processi che le determinano, permettendo un‚Äôinterpretazione pi√π profonda e teoricamente informata dei risultati.\nIn questo tutorial, vengono confrontati due approcci modellistici diversi: un modello semplice e descrittivo, e un modello processuale pi√π complesso, che incorpora una teoria esplicita del processo cognitivo sottostante. Il primo modello rappresenta un approccio tradizionale, che si limita a distinguere tra due condizioni senza tener conto del meccanismo generativo che potrebbe differenziarle. Il secondo modello, invece, √® costruito su un‚Äôipotesi teorica che descrive come il processo cognitivo operi in ciascuna delle due condizioni. Attraverso questo confronto, mostreremo come un modello che incorpora esplicitamente il processo cognitivo possa fornire un‚Äôinterpretazione pi√π ricca e accurata dei dati, rispetto a un modello che si limita a descrivere differenze superficiali.\nL‚Äôobiettivo di questo capitolo √® quindi dimostrare l‚Äôimportanza di adottare modelli generativi nella ricerca psicologica, evidenziando come essi possano superare le limitazioni degli approcci descrittivi tradizionali e fornire intuizioni pi√π profonde sul funzionamento dei fenomeni psicologici.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_cognitive_modeling.html#modello-process",
    "href": "chapters/entropy/04_cognitive_modeling.html#modello-process",
    "title": "82¬† Dall‚Äôanalisi descrittiva alla modellazione cognitiva",
    "section": "82.2 Modello ‚ÄúProcess‚Äù",
    "text": "82.2 Modello ‚ÄúProcess‚Äù\nIl modello ‚Äúprocess‚Äù ipotizza un meccanismo cognitivo in cui l‚Äôaccuratezza delle risposte di un soggetto in un compito pu√≤ variare in base a due condizioni sperimentali: una condizione di ‚Äúalto apprendimento‚Äù e una condizione di ‚Äúbasso apprendimento‚Äù. L‚Äôidea di base √® che nella condizione di alto apprendimento, il soggetto non solo apprende dalle risposte precedenti, migliorando gradualmente la sua accuratezza, ma subisce anche un decadimento di tale apprendimento nel tempo. Nella condizione di basso apprendimento, invece, il soggetto non migliora nel tempo, mantenendo un livello costante di accuratezza.\nQuesta dinamica riflette un processo di apprendimento che √® modulato da due forze opposte: un tasso di apprendimento che permette al soggetto di migliorare la sua performance in base agli errori commessi, e un tasso di decadimento che riduce gradualmente l‚Äôeffetto dell‚Äôapprendimento nel tempo. Questo modello √® pi√π complesso rispetto a un modello descrittivo semplice perch√© tenta di catturare il processo dinamico di come l‚Äôaccuratezza evolve durante il compito, piuttosto che limitarsi a descrivere una differenza fissa tra due condizioni.\nImplementazione del Modello\n\nDati di Input\n\nN: Il numero totale di prove (trials) a cui il soggetto √® sottoposto.\ny: Un array binario (0 o 1) che rappresenta l‚Äôaccuratezza di ciascuna risposta. Un valore di 1 indica una risposta corretta, mentre un valore di 0 indica una risposta errata.\ncondition: Un array binario che indica la condizione sperimentale per ciascuna prova: 1 se il soggetto √® nella condizione di ‚Äúalto apprendimento‚Äù e 0 se √® nella condizione di ‚Äúbasso apprendimento‚Äù.\n\nParametri del Modello\n\ntheta_initial: Rappresenta l‚Äôaccuratezza iniziale del soggetto, prima che qualsiasi apprendimento o decadimento abbia avuto luogo.\nlearning_rate: Rappresenta il tasso di apprendimento, ovvero quanto rapidamente il soggetto migliora in risposta agli errori precedenti.\ndecay_rate: Rappresenta il tasso di decadimento, ovvero quanto velocemente l‚Äôeffetto dell‚Äôapprendimento diminuisce nel tempo.\n\nDistribuzioni A Priori\n\nI parametri theta_initial, learning_rate e decay_rate sono tutti modellati come variabili aleatorie con distribuzioni beta. La distribuzione beta √® spesso utilizzata per modellare probabilit√†, poich√© √® limitata tra 0 e 1 e pu√≤ assumere varie forme in base ai parametri scelti.\n\nImplementazione del Processo Cognitivo\n\nIl modello si sviluppa in modo iterativo per ciascuna prova, a partire dalla seconda (la prima prova √® gestita separatamente perch√© non ha una risposta precedente da cui apprendere).\nPer ogni prova successiva:\n\nViene calcolata la probabilit√† di risposta corretta (p) in base alla condizione corrente.\nSe la condizione √® di ‚Äúalto apprendimento‚Äù (condition[n] == 1), la probabilit√† di risposta corretta viene aggiornata in base a una combinazione di decadimento e apprendimento:\n\nLa parte (1 - decay_rate) * theta_initial riduce l‚Äôinfluenza dell‚Äôaccuratezza iniziale, simulando il decadimento.\nLa parte learning_rate * (1 - y[n - 1]) aumenta la probabilit√† di una risposta corretta se la prova precedente √® stata errata, simulando l‚Äôapprendimento dagli errori.\n\nLa funzione fmin e fmax sono utilizzate per assicurarsi che la probabilit√† p rimanga all‚Äôinterno dell‚Äôintervallo [0, 1].\n\nSe la condizione √® di ‚Äúbasso apprendimento‚Äù (condition[n] == 0), la probabilit√† di risposta corretta rimane invariata a theta_initial.\n\nGenerazione dei Dati Simulati\n\nNella sezione generated quantities, il modello genera dati simulati (y_rep) e calcola la log-verosimiglianza (log_lik) per ciascuna prova. Questo √® utile per confrontare la bont√† di adattamento del modello rispetto ai dati osservati.\nPer ogni prova, viene calcolata la probabilit√† di una risposta corretta e quindi viene generato un valore simulato usando la funzione bernoulli_rng. Il valore di log-verosimiglianza viene calcolato utilizzando bernoulli_lpmf.\n\n\nIl modello ‚Äúprocess‚Äù cerca di rappresentare un meccanismo cognitivo complesso, in cui l‚Äôaccuratezza delle risposte varia dinamicamente in base a un processo di apprendimento e decadimento. Questo approccio permette di testare ipotesi pi√π articolate sui dati, andando oltre una semplice descrizione delle differenze tra condizioni e cercando di catturare la struttura cognitiva che guida il comportamento osservato.\n\nstan_file = os.path.join(project_directory, \"stan\", \"cognitive_process_model.stan\")\nprocess_model = CmdStanModel(stan_file=stan_file)\nprint(process_model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of trials\n  array[N] int&lt;lower=0, upper=1&gt; y; // accuracy (0 or 1)\n  array[N] int&lt;lower=0, upper=1&gt; condition; // 1 if high learning, 0 if low learning\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta_initial; // initial accuracy\n  real&lt;lower=0, upper=1&gt; learning_rate; // learning rate\n  real&lt;lower=0, upper=1&gt; decay_rate; // decay rate\n}\nmodel {\n  // Priors\n  theta_initial ~ beta(2, 2);\n  learning_rate ~ beta(2, 2);\n  decay_rate ~ beta(2, 2);\n  \n  for (n in 2 : N) {\n    real p = condition[n]\n             * fmin(fmax((1 - decay_rate) * theta_initial\n                         + learning_rate * (1 - y[n - 1]), 0),\n                    1)\n             + (1 - condition[n]) * theta_initial;\n    y[n] ~ bernoulli(p);\n  }\n}\ngenerated quantities {\n  array[N] int&lt;lower=0, upper=1&gt; y_rep;\n  array[N] real log_lik;\n  \n  y_rep[1] = bernoulli_rng(theta_initial); // First trial based on initial theta\n  log_lik[1] = bernoulli_lpmf(y[1] | theta_initial);\n  \n  for (n in 2 : N) {\n    real p = condition[n]\n             * fmin(fmax((1 - decay_rate) * theta_initial\n                         + learning_rate * (1 - y[n - 1]), 0),\n                    1)\n             + (1 - condition[n]) * theta_initial;\n    \n    y_rep[n] = bernoulli_rng(p);\n    log_lik[n] = bernoulli_lpmf(y[n] | p);\n    \n    // Optional diagnostic print statement\n    print(\"n: \", n, \" p: \", p, \" y_rep[n]: \", y_rep[n]);\n  }\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_cognitive_modeling.html#modello-simpler",
    "href": "chapters/entropy/04_cognitive_modeling.html#modello-simpler",
    "title": "82¬† Dall‚Äôanalisi descrittiva alla modellazione cognitiva",
    "section": "82.3 Modello ‚ÄúSimpler‚Äù",
    "text": "82.3 Modello ‚ÄúSimpler‚Äù\nIl modello ‚Äúsimpler‚Äù √® un approccio pi√π basilare per modellare i dati, in cui si assume che l‚Äôaccuratezza delle risposte in ciascuna prova dipenda esclusivamente dalla condizione sperimentale (alta o bassa) in cui si trova il soggetto. A differenza del modello ‚Äúprocess‚Äù, che tiene conto di come l‚Äôaccuratezza possa evolvere dinamicamente in funzione dell‚Äôapprendimento e del decadimento, il modello ‚Äúsimpler‚Äù presuppone che l‚Äôaccuratezza sia costante all‚Äôinterno di ciascuna condizione e non cambi nel tempo.\nIn altre parole, il modello ‚Äúsimpler‚Äù cerca di cogliere solo la differenza di accuratezza tra due condizioni, senza considerare l‚Äôevoluzione della performance nel corso delle prove. Questo approccio √® pi√π limitato e descrittivo, e non tenta di spiegare il processo sottostante che potrebbe dare origine ai dati osservati.\nImplementazione del Modello\n\nDati di Input\n\nN: Il numero totale di prove (trials) a cui il soggetto √® sottoposto.\ny: Un array binario (0 o 1) che rappresenta l‚Äôaccuratezza di ciascuna risposta. Un valore di 1 indica una risposta corretta, mentre un valore di 0 indica una risposta errata.\ncondition: Un array binario che indica la condizione sperimentale per ciascuna prova: 1 se il soggetto √® nella condizione di ‚Äúalto apprendimento‚Äù e 0 se √® nella condizione di ‚Äúbasso apprendimento‚Äù.\n\nParametri del Modello\n\ntheta_high: Rappresenta l‚Äôaccuratezza nelle prove in cui il soggetto √® nella condizione di ‚Äúalto apprendimento‚Äù.\ntheta_low: Rappresenta l‚Äôaccuratezza nelle prove in cui il soggetto √® nella condizione di ‚Äúbasso apprendimento‚Äù.\n\nDistribuzioni A Priori\n\nI parametri theta_high e theta_low sono modellati come variabili aleatorie con distribuzioni beta. Come nel modello ‚Äúprocess‚Äù, la distribuzione beta √® scelta perch√© √® limitata tra 0 e 1, rendendola adatta per modellare probabilit√†.\n\nImplementazione del Modello\n\nIl modello assume che per ogni prova ci sia una probabilit√† p di ottenere una risposta corretta, che dipende dalla condizione in cui si trova il soggetto.\nSe il soggetto √® nella condizione di ‚Äúalto apprendimento‚Äù (condition[n] == 1), la probabilit√† p √® semplicemente uguale a theta_high.\nSe il soggetto √® nella condizione di ‚Äúbasso apprendimento‚Äù (condition[n] == 0), la probabilit√† p √® uguale a theta_low.\nIn pratica, per ogni prova, il modello stima la probabilit√† di risposta corretta in base alla condizione sperimentale senza considerare alcuna evoluzione dinamica della performance.\n\nGenerazione dei Dati Simulati\n\nNella sezione generated quantities, il modello genera dati simulati (y_rep) e calcola la log-verosimiglianza (log_lik) per ciascuna prova.\nPer ogni prova, viene calcolata la probabilit√† di una risposta corretta e quindi viene generato un valore simulato usando la funzione bernoulli_rng. Il valore di log-verosimiglianza viene calcolato utilizzando bernoulli_lpmf.\n\n\nIl modello ‚Äúprocess‚Äù e il modello ‚Äúsimpler‚Äù differiscono in modo sostanziale nel modo in cui cercano di spiegare i dati:\n\nDinamica dell‚Äôapprendimento vs.¬†Accuratezza fissa:\n\nProcess Model: Tiene conto che l‚Äôaccuratezza possa variare nel tempo in risposta agli errori e al decadimento, catturando la complessit√† del processo di apprendimento influenzato dalla condizione sperimentale.\nSimpler Model: Assume un‚Äôaccuratezza costante all‚Äôinterno di ciascuna condizione, senza considerare variazioni dinamiche dovute all‚Äôapprendimento o al decadimento.\n\nComplessit√† del Meccanismo Cognitivo:\n\nProcess Model: Rappresenta in modo dettagliato il meccanismo cognitivo che guida la performance, considerando l‚Äôevoluzione della performance basata sulle esperienze precedenti.\nSimpler Model: Fornisce una descrizione statica e limitata alle differenze medie tra condizioni, senza approfondire il processo sottostante.\n\nCapacit√† Predittiva:\n\nProcess Model: Dovrebbe predire meglio i dati quando l‚Äôapprendimento o il decadimento sono rilevanti, grazie alla sua considerazione delle dinamiche temporali.\nSimpler Model: Potrebbe non cogliere adeguatamente la struttura dei dati in presenza di tali dinamiche, risultando meno preciso nelle predizioni.\n\n\nIn sintesi, il modello ‚Äúsimpler‚Äù non riesce a catturare i cambiamenti dinamici nell‚Äôaccuratezza legati al compito, offrendo solo una descrizione media delle differenze tra condizioni. Pertanto, quando i dati seguono un processo di apprendimento o decadimento, il modello ‚Äúsimpler‚Äù tende a essere meno efficace rispetto al modello ‚Äúprocess‚Äù.\n\nstan_simpler_file = os.path.join(\n    project_directory, \"stan\", \"cognitive_simpler_model.stan\"\n)\nsimpler_model = CmdStanModel(stan_file=stan_simpler_file)\nprint(simpler_model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of trials\n  array[N] int&lt;lower=0, upper=1&gt; y; // accuracy (0 or 1)\n  array[N] int&lt;lower=0, upper=1&gt; condition; // 1 if high learning, 0 if low learning\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta_high; // accuracy in condition 1\n  real&lt;lower=0, upper=1&gt; theta_low; // accuracy in condition 0\n}\nmodel {\n  // Priors\n  theta_high ~ beta(2, 2);\n  theta_low ~ beta(2, 2);\n  \n  for (n in 1 : N) {\n    real p = condition[n] * theta_high + (1 - condition[n]) * theta_low;\n    y[n] ~ bernoulli(p);\n  }\n}\ngenerated quantities {\n  array[N] int&lt;lower=0, upper=1&gt; y_rep;\n  array[N] real log_lik;\n  \n  for (n in 1 : N) {\n    real p = condition[n] * theta_high + (1 - condition[n]) * theta_low;\n    y_rep[n] = bernoulli_rng(p);\n    log_lik[n] = bernoulli_lpmf(y[n] | p);\n  }\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_cognitive_modeling.html#simulazione-dei-dati",
    "href": "chapters/entropy/04_cognitive_modeling.html#simulazione-dei-dati",
    "title": "82¬† Dall‚Äôanalisi descrittiva alla modellazione cognitiva",
    "section": "82.4 Simulazione dei Dati",
    "text": "82.4 Simulazione dei Dati\nI dati sono stati simulati in base al meccanismo generativo ipotizzato dal modello ‚Äúprocess‚Äù. Questo modello assume che l‚Äôaccuratezza delle risposte non sia costante nel tempo, ma che evolva dinamicamente in funzione dell‚Äôapprendimento e del decadimento. In altre parole, il modello ‚Äúprocess‚Äù riflette un processo cognitivo in cui i soggetti possono migliorare la loro performance attraverso l‚Äôapprendimento, o al contrario, possono mostrare un calo di prestazioni a causa della fatica o della perdita di concentrazione.\nNel processo di simulazione, quindi, i dati generati riflettono queste dinamiche: l‚Äôaccuratezza non √® semplicemente una funzione statica delle condizioni sperimentali, ma cambia in risposta alle prove precedenti. Questo √® in contrasto con il modello ‚Äúsimpler‚Äù, che non tiene conto di queste dinamiche e assume che l‚Äôaccuratezza sia fissa e immutabile all‚Äôinterno di ciascuna condizione sperimentale. Di conseguenza, i dati simulati seguono il processo cognitivo ipotizzato dal modello ‚Äúprocess‚Äù, che si basa su un‚Äôaccuratezza variabile e influenzata dall‚Äôapprendimento e dal decadimento, fornendo una base per confrontare l‚Äôadattamento dei due modelli ai dati.\n\n# Parameters for data generation\nN = 5000  # Number of trials\ncondition = np.random.binomial(\n    1, 0.5, N\n)  # 50% chance of being in the high-learning condition\n\ntheta_initial = 0.6  # Initial accuracy\nlearning_rate_high = (\n    0.3  # Higher learning rate in the process model for high-learning condition\n)\nlearning_rate_low = (\n    0.1  # Lower learning rate in the process model for low-learning condition\n)\ndecay_rate_high = (\n    0.05  # Lower decay rate in the process model for high-learning condition\n)\ndecay_rate_low = (\n    0.15  # Higher decay rate in the process model for low-learning condition\n)\n\naccuracies = np.zeros(N)\nvalue = theta_initial\n\nfor n in range(N):\n    if condition[n] == 1:  # High-learning condition\n        if n &gt; 0:\n            # Enhanced learning effect when previous trial was incorrect\n            value = (1 - decay_rate_high) * value + learning_rate_high * (\n                1 - accuracies[n - 1]\n            )\n        # Ensure that value remains within [0, 1]\n        value = np.clip(value, 0, 1)\n        accuracies[n] = np.random.binomial(1, value)\n    else:  # Low-learning condition\n        if n &gt; 0:\n            # Weaker learning effect and higher decay rate\n            value = (1 - decay_rate_low) * value + learning_rate_low * (\n                1 - accuracies[n - 1]\n            )\n        # Ensure that value remains within [0, 1]\n        value = np.clip(value, 0, 1)\n        accuracies[n] = np.random.binomial(1, value)\n\n# Prepare data for Stan\nstan_data = {\n    \"N\": N,\n    \"y\": accuracies.astype(int).tolist(),\n    \"condition\": condition.astype(int).tolist(),\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_cognitive_modeling.html#campionamento",
    "href": "chapters/entropy/04_cognitive_modeling.html#campionamento",
    "title": "82¬† Dall‚Äôanalisi descrittiva alla modellazione cognitiva",
    "section": "82.5 Campionamento",
    "text": "82.5 Campionamento\nEseguiamo il campionamento per i due modelli.\n\nfit_process = process_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n07:54:25 - cmdstanpy - INFO - CmdStan start processing\n07:54:25 - cmdstanpy - INFO - Chain [1] start processing\n07:54:25 - cmdstanpy - INFO - Chain [2] start processing\n07:54:25 - cmdstanpy - INFO - Chain [3] start processing\n07:54:25 - cmdstanpy - INFO - Chain [4] start processing\n07:55:41 - cmdstanpy - INFO - Chain [1] done processing\n07:55:42 - cmdstanpy - INFO - Chain [3] done processing\n07:55:42 - cmdstanpy - INFO - Chain [4] done processing\n07:55:42 - cmdstanpy - INFO - Chain [2] done processing\n\n\n\n_ = az.plot_trace(fit_process, var_names=(\"learning_rate\", \"decay_rate\"))\n\n\n\n\n\n\n\n\n\naz.summary(fit_process, var_names=[\"learning_rate\", \"decay_rate\"])\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nlearning_rate\n0.214\n0.015\n0.187\n0.241\n0.0\n0.0\n4908.0\n5214.0\n1.0\n\n\ndecay_rate\n0.009\n0.006\n0.000\n0.020\n0.0\n0.0\n4692.0\n3553.0\n1.0\n\n\n\n\n\n\n\n\n\nfit_simpler = simpler_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n07:57:33 - cmdstanpy - INFO - CmdStan start processing\n07:57:33 - cmdstanpy - INFO - Chain [1] start processing\n07:57:33 - cmdstanpy - INFO - Chain [2] start processing\n07:57:33 - cmdstanpy - INFO - Chain [3] start processing\n07:57:33 - cmdstanpy - INFO - Chain [4] start processing\n07:57:44 - cmdstanpy - INFO - Chain [2] done processing\n07:57:44 - cmdstanpy - INFO - Chain [4] done processing\n07:57:44 - cmdstanpy - INFO - Chain [1] done processing\n07:57:45 - cmdstanpy - INFO - Chain [3] done processing",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_cognitive_modeling.html#confronto-dei-modelli",
    "href": "chapters/entropy/04_cognitive_modeling.html#confronto-dei-modelli",
    "title": "82¬† Dall‚Äôanalisi descrittiva alla modellazione cognitiva",
    "section": "82.6 Confronto dei Modelli",
    "text": "82.6 Confronto dei Modelli\nPer confrontare i modelli, √® necessario convertire l‚Äôoggetto fit in un formato compatibile con ArviZ.\n\nidata_process = az.from_cmdstanpy(posterior=fit_process)\nidata_simpler = az.from_cmdstanpy(posterior=fit_simpler)\n\nCalcoliamo il criterio LOO (Leave-One-Out) per confrontare i due modelli.\n\nloo_process = az.loo(idata_process)\nloo_simpler = az.loo(idata_simpler)\n\nConfrontiamo i due modelli utilizzando il criterio LOO.\n\nloo_comparison = az.compare(\n    {\"Process Model\": loo_process, \"Simpler Model\": loo_simpler}\n)\nprint(loo_comparison)\n\n               rank     elpd_loo     p_loo  elpd_diff    weight         se  \\\nProcess Model     0 -3123.273484  2.008705   0.000000  0.685872  24.569185   \nSimpler Model     1 -3149.844801  1.991303  26.571317  0.314128  24.127268   \n\n                     dse  warning scale  \nProcess Model   0.000000    False   log  \nSimpler Model  12.069884    False   log  \n\n\nL‚Äôoutput di loo_comparison() confronta i due modelli utilizzando il criterio di Leave-One-Out Cross-Validation (LOO) basato sull‚ÄôExpected Log Predictive Density (ELPD). Ogni colonna nell‚Äôoutput fornisce informazioni diverse sul confronto tra i modelli. Vediamo cosa significa ciascuna colonna:\n\nrank: Questa colonna indica la posizione del modello in base all‚ÄôELPD. Il modello con il valore pi√π alto di ELPD √® classificato al primo posto.\nelpd_loo: Questo valore rappresenta la Expected Log Pointwise Predictive Density calcolata usando il metodo LOO. In parole semplici, misura quanto bene il modello predice i dati osservati, tenendo conto della complessit√† del modello per evitare l‚Äôoverfitting. Un valore pi√π alto indica che il modello ha una migliore capacit√† predittiva.\np_loo: Questa colonna stima il numero effettivo di parametri del modello, cio√® quanti ‚Äúgradi di libert√†‚Äù effettivi il modello sta usando per adattarsi ai dati. Un valore pi√π alto indica un modello pi√π complesso.\nelpd_diff: Questa colonna mostra la differenza di ELPD tra il modello migliore (quello al primo posto) e gli altri modelli. Per il modello migliore, questo valore √® 0. Gli altri modelli avranno valori positivi, che indicano quanto peggio si comportano rispetto al modello migliore.\nweight: Questo valore rappresenta la probabilit√† normalizzata che ciascun modello sia il migliore per fare previsioni su nuovi dati. I pesi sono normalizzati in modo che la somma sia pari a 1. Per esempio, un peso di 0.685872 indica che c‚Äô√® il 68.6% di probabilit√† che quel modello sia il migliore nel predire nuovi dati.\nse: Questo √® l‚Äôerrore standard dell‚ÄôELPD stimato, che rappresenta l‚Äôincertezza associata a questa stima. Un errore standard pi√π basso indica maggiore fiducia nell‚ÄôELPD calcolato.\ndse: Significa ‚Äúerrore standard della differenza dell‚ÄôELPD‚Äù. Indica l‚Äôincertezza nella differenza di ELPD tra il miglior modello e un altro modello. Un valore basso di dse suggerisce che siamo abbastanza sicuri che la differenza osservata non sia dovuta al caso.\nwarning: Questa colonna indica se ci sono stati avvertimenti durante il calcolo. Se il valore √® False, significa che non ci sono stati problemi.\nscale: Indica la scala utilizzata per il confronto tra modelli. In questo caso, si usa la scala logaritmica (log), che √® comune quando si analizzano log-verosimiglianze.\n\nInterpretazione\n\nClassifica dei Modelli: Il Process Model √® classificato al primo posto, il che significa che ha l‚ÄôELPD pi√π alto e, quindi, si adatta meglio ai dati rispetto al Simpler Model.\nDifferenza in ELPD (elpd_diff): La differenza tra i due modelli √® significativa (135,85), il che suggerisce che il Process Model offre una capacit√† predittiva notevolmente migliore.\nPesi: Il Process Model ha un peso di 0.686, il che indica che, secondo il confronto LOO, c‚Äô√® una probabilit√† del 68.6% che sia il miglior modello per fare previsioni su nuovi dati, mentre il Simpler Model ha solo il 31.4% di probabilit√†.\nErrore Standard della Differenza (dse): La dse relativamente bassa rispetto all‚Äôelpd_diff conferma che la differenza tra i modelli √® significativa e non √® dovuta a variazioni casuali.\n\nIn conclusione, questo output suggerisce chiaramente che il Process Model, che incorpora un processo cognitivo pi√π complesso, √® nettamente superiore al Simpler Model per quanto riguarda l‚Äôadattamento ai dati. Questa superiorit√† √® supportata sia dal confronto delle stime di ELPD sia dai pesi associati ai modelli.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_cognitive_modeling.html#considerazioni-conclusive",
    "href": "chapters/entropy/04_cognitive_modeling.html#considerazioni-conclusive",
    "title": "82¬† Dall‚Äôanalisi descrittiva alla modellazione cognitiva",
    "section": "82.7 Considerazioni Conclusive",
    "text": "82.7 Considerazioni Conclusive\nI risultati ottenuti dimostrano chiaramente l‚Äôimportanza di implementare un modello che rifletta il processo generativo dei dati (McElreath (2020)). Il modello ‚Äúprocess,‚Äù che cattura la complessit√† delle dinamiche di apprendimento e decadimento, ha mostrato una performance superiore rispetto al modello pi√π semplice, che si limita a distinguere tra due condizioni. Questo sottolinea come un‚Äôanalisi basata su un modello che incorpora le ipotesi sul processo sottostante possa portare a una migliore comprensione dei dati e, in ultima analisi, a risultati pi√π solidi.\n√à fondamentale eseguire simulazioni preliminari prima di raccogliere dati empirici. Queste simulazioni permettono di valutare l‚Äôadeguatezza della numerosit√† campionaria necessaria a rilevare gli effetti ipotizzati, tenendo conto del processo generativo dei dati. Nel caso presente, l‚Äôanalisi √® stata semplificata concentrandosi su un singolo campione di osservazioni indipendenti. Tuttavia, in un contesto pi√π realistico, sarebbe opportuno considerare dati provenienti da pi√π soggetti e riformulare il modello in modo gerarchico per catturare la variabilit√† tra individui. Lo scopo qui era limitato al confronto tra i due modelli per evidenziare l‚Äôimportanza di modellare il processo generativo.\nL‚Äôapproccio bayesiano, e in particolare l‚Äôuso di Stan, offre un vantaggio notevole in questo contesto, consentendo di implementare in modo relativamente semplice modelli complessi che riflettono fedelmente il processo generativo ipotizzato. Questo tipo di modellazione risulta molto pi√π difficile, se non impossibile, utilizzando metodi non bayesiani, che spesso non permettono di catturare con la stessa flessibilit√† le dinamiche sottostanti ai dati.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_cognitive_modeling.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/04_cognitive_modeling.html#informazioni-sullambiente-di-sviluppo",
    "title": "82¬† Dall‚Äôanalisi descrittiva alla modellazione cognitiva",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Aug 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>82</span>¬† <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_inductive_inference.html",
    "href": "chapters/entropy/05_inductive_inference.html",
    "title": "83¬† Limiti dell‚Äôinferenza induttiva",
    "section": "",
    "text": "Introduzione\nLa selezione delle ipotesi attraverso il teorema di Bayes e l‚Äôuso di strumenti come l‚ÄôExpected Log Predictive Density (ELPD) per il confronto tra modelli costituiscono approcci potenti, ma non risolvono completamente il problema dell‚Äôinferenza statistica. Come sottolineato da McElreath (2020), queste metodologie operano all‚Äôinterno di un ‚Äúpiccolo mondo‚Äù teorico, e non √® sempre chiaro come tali soluzioni si estendano al ‚Äúgrande mondo‚Äù complesso e variabile che desideriamo realmente comprendere. Questo capitolo si propone di esplorare questa disconnessione, esaminando la distanza tra la teoria empirica dei fenomeni e i modelli statistici semplificati che possiamo effettivamente testare.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_inductive_inference.html#inferenza-statistica",
    "href": "chapters/entropy/05_inductive_inference.html#inferenza-statistica",
    "title": "83¬† Limiti dell‚Äôinferenza induttiva",
    "section": "83.1 Inferenza Statistica",
    "text": "83.1 Inferenza Statistica\nL‚Äôinferenza statistica √® un processo induttivo in cui i dati osservati non forniscono informazioni sufficienti per determinare con certezza il processo che li ha generati. La regola di Bayes offre una soluzione ottimale per aggiornare le nostre convinzioni alla luce di nuovi dati. McElreath (2020) introduce il concetto di ‚ÄúGrande Mondo,‚Äù un universo infinito di processi che potrebbero spiegare le nostre osservazioni. Poich√© √® impossibile considerare tutte le possibilit√† di questo ‚ÄúGrande Mondo,‚Äù ci concentriamo sul ‚ÄúPiccolo Mondo,‚Äù una rappresentazione semplificata che limita l‚Äôanalisi a un insieme finito di modelli e parametri pertinenti.\nAd esempio, consideriamo l‚Äôanalisi dell‚Äôaltezza umana utilizzando un modello probabilistico in cui l‚Äôaltezza segue una distribuzione normale, caratterizzata da una media (¬µ) e una deviazione standard (œÉ). L‚Äôobiettivo √® stimare questi parametri sconosciuti. La funzione di verosimiglianza, derivata dalle distribuzioni di probabilit√† nel Piccolo Mondo, rappresenta questo insieme di possibilit√†. Tuttavia, questo insieme pu√≤ essere troppo vasto per essere gestito in modo efficace, quindi utilizziamo la nostra conoscenza pregressa per restringere il campo.\nNell‚Äôinferenza bayesiana, queste conoscenze preesistenti vengono espresse tramite una distribuzione di probabilit√† a priori, che riflette le nostre convinzioni iniziali sui parametri del modello. La regola di Bayes permette di aggiornare queste convinzioni alla luce dei nuovi dati, producendo una distribuzione a posteriori che offre una stima pi√π accurata dei parametri che descrivono il processo generativo dei dati.\nIn sintesi, l‚Äôinferenza statistica ci avvicina alla comprensione di fenomeni complessi attraverso la modellazione semplificata nel ‚ÄúPiccolo Mondo‚Äù. L‚Äôinferenza bayesiana integra le conoscenze pregresse con i nuovi dati per perfezionare le nostre stime, con l‚Äôobiettivo di individuare modelli del ‚ÄúPiccolo Mondo‚Äù che, pur non essendo perfetti, siano efficaci nel fare previsioni e nel migliorare la nostra comprensione del fenomeno in esame.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_inductive_inference.html#sec-poetic-validity",
    "href": "chapters/entropy/05_inductive_inference.html#sec-poetic-validity",
    "title": "83¬† Limiti dell‚Äôinferenza induttiva",
    "section": "83.2 Validit√† Poetica",
    "text": "83.2 Validit√† Poetica\nAbbiamo esplorato il teorema di Bayes come metodo per valutare la plausibilit√† di un‚Äôipotesi, uno dei motivi principali della sua importanza. Tuttavia, √® cruciale riconoscere che quantificare la plausibilit√† di un‚Äôipotesi non risolve pienamente il problema scientifico dell‚Äôinferenza. Come illustrato da Navarro (2019), usando una metafora di Box (1976):\n\nSince all models are wrong, the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.\n\nIn questa metafora, i ‚Äútopi‚Äù rappresentano i dettagli del nostro modello statistico, mentre la ‚Äútigre‚Äù √® la disconnessione tra i dati osservati, modellizzati con il teorema di Bayes, e la teoria del fenomeno, che √® al centro del nostro interesse.\nPaul Meehl ha ulteriormente articolato questo problema distinguendo tre livelli: la teoria sostanziale (A), l‚Äôipotesi statistica testabile (T) e le osservazioni (O). La relazione tra questi tre livelli solleva difficolt√† significative:\n\nThe map from substantive theory (A) to testable statistical hypothesis (T) goes through a derivation chain involving auxiliary theories, instruments, ceteris paribus assertions, and experimental conditions. The map from hypothesis to observation is through the statistical model manufactured by the derivation chain.\n\nLa teoria statistica offre vari strumenti per inferire la veridicit√† di T da O, spesso utilizzando la regola di Bayes. Tuttavia, anche se possiamo concludere che T √® altamente probabile dato O, non risolviamo il problema di calcolare la probabilit√† di A da T. Meehl sosteneva che non esiste una procedura formale capace di tradurre rigorosamente le osservazioni empiriche (O) nella teoria scientifica (A).\nIl concetto di ‚Äúvalidit√† poetica‚Äù descrive questa disconnessione. La validit√† poetica si riferisce alla capacit√† di un‚Äôidea di risuonare con l‚Äôintelletto umano e con l‚Äôesperienza, anche quando non pu√≤ essere rigorosamente validata scientificamente o statisticamente. Sottolinea l‚Äôimportanza dell‚Äôintuizione e della comprensione qualitativa nella teoria scientifica, completando l‚Äôapproccio puramente quantitativo e formale (Hardt e Recht 2022).\nLa dicotomia tra concetti teorici ed empirici, manifestata nel processo di operazionalizzazione, chiarisce ulteriormente questa problematica (Hempel 1970). L‚Äôoperazionalizzazione dei concetti teorici in concetti empirici √® un processo arbitrario e comporta un mapping uno-a-molti, che comporta diverse implicazioni:\n\nSottodeterminazione delle teorie: Nessun test di ipotesi pu√≤ essere considerato un test diretto di una teoria, poich√© l‚Äôoperazionalizzazione introduce un elemento di arbitrariet√†.\nFlessibilit√† teorica: La relazione uno-a-molti tra concetti teorici ed empirici consente un raffinamento progressivo delle teorie.\nAmbiguit√† empirica: Operazionalizzazioni diverse possono portare a risultati contraddittori rispetto alla stessa teoria.\nNecessit√† di formalizzazione: Le teorie psicologiche devono essere espresse in termini formali per permettere predizioni quantitative.\n\nIn conclusione, il problema della demarcazione tra teoria e osservazione in psicologia rimane un tema aperto e cruciale. La consapevolezza di queste limitazioni epistemologiche dovrebbe guidare la pratica della ricerca empirica e l‚Äôinterpretazione dei suoi risultati, promuovendo un approccio pi√π critico alla costruzione, validazione e interpretazione delle teorie psicologiche.\n\n83.2.1 Tra il Diavolo e il Mare Aperto\nNel campo della selezione dei modelli, ci troviamo spesso di fronte a teorie concorrenti, ognuna rappresentata da modelli computazionali che offrono interpretazioni diverse degli stessi dati. La questione cruciale √®: come decidere quale modello sia meglio supportato dai dati? Questo √® un problema centrale dell‚Äôinferenza statistica, e la cross-validation √® uno dei metodi utilizzati per cercare una risposta, come abbiamo visto nel Capitolo 81.\nTuttavia, Navarro (2019) sottolinea che, sebbene la selezione dei modelli sia un passaggio importante, applicare questa procedura a problemi semplificati non √® sufficiente per affrontare le complesse questioni inferenziali che gli scienziati devono affrontare. Gli scienziati sono consapevoli che tutti i modelli sono, in una certa misura, errati; non comprendiamo pienamente i fenomeni che studiamo, e ogni descrizione formale √® inevitabilmente approssimativa e soggetta a errori sistematici. Pertanto, devono navigare tra il diavolo della decisione statistica e il mare aperto delle questioni scientifiche sostanziali.\nUn approccio pi√π utile potrebbe essere quello di concentrarsi su come i pattern qualitativi emergano dai dati empirici attraverso un modello computazionale di un processo psicologico, piuttosto che limitarsi a presentare misure quantitative delle prestazioni del modello. Dato quanto poco ancora sappiamo sul comportamento e sulla cognizione umana, e considerando l‚Äôartificialit√† di molti studi sperimentali, √® lecito chiedersi quale sia il reale valore di quantificare la capacit√† di un modello di prevedere ogni dettaglio dei dati. In pratica, una selezione dei modelli basata esclusivamente su misure quantitative tende a privilegiare modelli che fanno affidamento su assunzioni accessorie, senza necessariamente risolvere i problemi scientifici fondamentali.\nLa vera forza di una teoria scientifica, quindi, non risiede solo nella sua capacit√† di prevedere nuovi dati derivati da esperimenti passati, ma soprattutto nel suo potenziale di aprire la strada a nuove esplorazioni e scoperte.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_inductive_inference.html#riflessioni-conclusive",
    "href": "chapters/entropy/05_inductive_inference.html#riflessioni-conclusive",
    "title": "83¬† Limiti dell‚Äôinferenza induttiva",
    "section": "83.3 Riflessioni Conclusive",
    "text": "83.3 Riflessioni Conclusive\nIn questo capitolo, abbiamo esaminato le complessit√† e le sfide dell‚Äôinferenza statistica e della selezione dei modelli attraverso una lente bayesiana. Sebbene il teorema di Bayes e i suoi strumenti derivati, come l‚ÄôExpected Log Predictive Density (ELPD), siano potenti per aggiornare e confrontare modelli, essi operano principalmente in un ‚ÄúPiccolo Mondo‚Äù semplificato. Questo limita la nostra capacit√† di trarre conclusioni definitive sul ‚ÄúGrande Mondo‚Äù reale che ci interessa.\nLa ‚Äúvalidit√† poetica‚Äù sottolinea l‚Äôimportanza di riconoscere le limitazioni intrinseche delle nostre rappresentazioni statistiche e di valorizzare l‚Äôintuizione e la comprensione qualitativa nel contesto scientifico. La distinzione tra concetti teorici e osservazioni empiriche ci ricorda che, nonostante i progressi metodologici, rimane una disconnessione fondamentale tra la teoria e le osservazioni empiriche.\nInfine, la capacit√† di un modello di generalizzare, piuttosto che di prevedere perfettamente i dati osservati, emerge come un criterio cruciale per la sua utilit√† scientifica. L‚Äôesempio del modello di Rescorla-Wagner illustra come un buon modello possa stimolare nuove esplorazioni e approfondimenti, dimostrando che il vero valore di una teoria scientifica risiede nella sua capacit√† di guidare l‚Äôindagine futura piuttosto che semplicemente adattarsi ai dati esistenti.\nIn sintesi, le riflessioni presentate in questo capitolo ci invitano a mantenere un equilibrio tra rigore quantitativo e intuizione qualitativa, riconoscendo i limiti delle nostre tecniche e cercando continuamente di migliorare le nostre rappresentazioni del mondo reale.\n\n\n\n\nBox, George EP. 1976. ¬´Science and statistics¬ª. Journal of the American Statistical Association 71 (356): 791‚Äì99.\n\n\nHardt, Moritz, e Benjamin Recht. 2022. Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton, NJ: Princeton University Press.\n\n\nHempel, Carl Gustav. 1970. La formazione dei concetti e delle teorie nella scienza empirica. Feltrinelli.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nNavarro, Danielle J. 2019. ¬´Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection¬ª. Computational Brain & Behavior 2 (1): 28‚Äì34.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>83</span>¬† <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/introduction_dynamic_models.html",
    "href": "chapters/dynamic_models/introduction_dynamic_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Uno degli sviluppi pi√π importanti della psicologia contemporanea √® l‚Äôapplicazione di teorie formali per formulare ipotesi sui meccanismi sottostanti i fenomeni psicologici oggetto di studio. In questa sezione, introdurremo una classe significativa di modelli statistici particolarmente utili per la psicologia: i modelli che descrivono i processi dinamici.\nLa teoria dei sistemi dinamici (Dynamic Systems Theory, DST) offre un quadro concettuale per comprendere i fenomeni psicologici come processi complessi, non lineari e spesso auto-organizzanti che evolvono nel tempo. In psicologia, la DST sottolinea come il comportamento e la cognizione emergano dalle interazioni di molteplici componenti all‚Äôinterno di un individuo e tra l‚Äôindividuo e il suo ambiente. Di seguito sono riportati alcuni esempi di fenomeni psicologici che possono essere compresi come sistemi dinamici.\nApprendimento per rinforzo. L‚Äôapprendimento per rinforzo √® un processo attraverso cui gli individui apprendono a modificare il proprio comportamento in base alle conseguenze che ne derivano. In termini di sistemi dinamici, l‚Äôapprendimento per rinforzo pu√≤ essere visto come un processo adattativo in cui le decisioni di un individuo vengono continuamente aggiornate e migliorate attraverso l‚Äôinterazione con l‚Äôambiente. In questo contesto, le ricompense (o rinforzi positivi) e le punizioni (o rinforzi negativi) giocano un ruolo cruciale nel modellare il comportamento futuro, creando un ciclo di feedback che rafforza o indebolisce determinate azioni. Ad esempio, un comportamento che porta a una ricompensa tende a essere ripetuto, mentre un comportamento che porta a una punizione tende a essere evitato. Questo meccanismo di apprendimento, che pu√≤ essere descritto matematicamente attraverso modelli probabilistici, permette di predire come un individuo possa modificare il proprio comportamento in situazioni diverse, sulla base delle esperienze passate e delle aspettative future. I modelli di apprendimento per rinforzo, come il modello di Rescorla-Wagner, sono stati ampiamente utilizzati in psicologia per spiegare non solo comportamenti semplici come il condizionamento classico e operante, ma anche fenomeni pi√π complessi come la dipendenza, i disturbi d‚Äôansia e i disturbi dell‚Äôumore. In questi casi, le aspettative disadattive e i bias cognitivi possono essere visti come il risultato di un apprendimento per rinforzo anomalo, in cui le associazioni tra stimoli e conseguenze sono distorte o esagerate. Studi recenti in psichiatria computazionale utilizzano questi modelli per sviluppare interventi terapeutici pi√π efficaci, mirati a ristrutturare le associazioni disfunzionali e promuovere schemi di apprendimento pi√π adattivi.\nRegolazione delle emozioni. La regolazione delle emozioni implica l‚Äôinterazione dinamica di processi fisiologici, cognitivi e comportamentali. Ad esempio, il modo in cui una persona regola le proprie emozioni in risposta a un evento stressante pu√≤ essere influenzato da diversi fattori, come esperienze precedenti, contesto attuale, stati fisiologici (come frequenza cardiaca o livelli ormonali) e valutazioni cognitive. Nel tempo, questi componenti possono interagire in modo non lineare, creando circuiti di retroazione. Ad esempio, una persona potrebbe inizialmente cercare di sopprimere le proprie emozioni, il che potrebbe portare a un aumento dell‚Äôeccitazione fisiologica, intensificando cos√¨ l‚Äôemozione che stava cercando di regolare.\nAttaccamento e relazioni sociali. Anche gli stili di attaccamento e le relazioni sociali sono sistemi dinamici. La teoria dell‚Äôattaccamento descrive come le prime relazioni con i caregiver influenzino le dinamiche interpersonali per tutta la vita. Queste relazioni possono essere viste come sistemi in cui i comportamenti, le emozioni e le cognizioni di una persona influenzano continuamente e sono influenzati da quelli degli altri. Ad esempio, in una relazione genitore-figlio, il comportamento del bambino pu√≤ influenzare le risposte del genitore, che a loro volta modellano il comportamento e gli stati emotivi futuri del bambino, creando un ciclo di retroazione che evolve nel tempo.\nSviluppo cognitivo. Lo sviluppo cognitivo, soprattutto nei bambini, viene spesso modellato come un sistema dinamico. La teoria dello sviluppo cognitivo di Jean Piaget, sebbene non esplicitamente in termini di DST, pu√≤ essere reinterpretata in questo modo. Ad esempio, il processo di raggiungimento dell‚Äôequilibrio cognitivo comporta interazioni continue tra le strutture di conoscenza esistenti del bambino (schemi) e le nuove esperienze. Questo processo √® dinamico perch√© il sistema cognitivo del bambino si adatta e si riorganizza costantemente in risposta a nuove informazioni, il che pu√≤ portare a cambiamenti qualitativi nel pensiero.\nControllo motorio e coordinazione. Lo sviluppo e il controllo delle azioni motorie, come camminare o afferrare, sono esempi classici di sistemi dinamici. Il controllo motorio coinvolge il coordinamento di numerosi muscoli, circuiti di retroazione sensoriale e aggiustamenti basati sull‚Äôambiente. L‚Äôapproccio dei sistemi dinamici allo sviluppo motorio enfatizza come i comportamenti motori emergano dall‚Äôauto-organizzazione di molteplici sistemi interagenti, come componenti neurali, muscolari e percettivi. Imparare a camminare, ad esempio, non √® solo un‚Äôaccumulazione lineare di forza ed equilibrio, ma comporta cambiamenti non lineari nel coordinamento muscolare, nell‚Äôintegrazione sensoriale e nei processi di retroazione.\nDecision making e problem solving. Il processo decisionale e la risoluzione dei problemi coinvolgono l‚Äôintegrazione di molteplici fattori cognitivi ed emotivi che cambiano nel tempo. La natura dinamica di questi processi √® evidente in come le decisioni iniziali possano portare a cambiamenti negli obiettivi, nel comportamento di ricerca delle informazioni e negli stati emotivi, che a loro volta influenzano le decisioni successive. Ad esempio, quando si prende una decisione in condizioni di incertezza, i livelli di fiducia di una persona, le reazioni emotive e le interpretazioni di nuove informazioni possono interagire dinamicamente, creando un modello fluttuante di comportamento decisionale.\nSalute mentale e psicopatologia. La salute mentale e la psicopatologia possono essere comprese anche da una prospettiva di sistemi dinamici. I disturbi come la depressione o l‚Äôansia non sono visti come entit√† statiche, ma come schemi dinamici di cognizione, emozione e comportamento che evolvono nel tempo. Ad esempio, i sintomi depressivi possono creare un ciclo di retroazione in cui i pensieri negativi portano a una ridotta attivit√†, che a sua volta porta a pensieri ed emozioni ancora pi√π negativi, perpetuando il ciclo. Comprendere la psicopatologia come un sistema dinamico aiuta a sviluppare interventi che mirano a questi cicli di retroazione e promuovono schemi pi√π adattivi.\nSviluppo del linguaggio. Lo sviluppo del linguaggio √® un altro ambito in cui la teoria dei sistemi dinamici √® applicabile. L‚Äôacquisizione del linguaggio nei bambini implica l‚Äôinterazione di molteplici fattori, come la conoscenza fonologica, sintattica e semantica, nonch√© l‚Äôinterazione sociale e le esperienze percettive. Lo sviluppo del linguaggio non √® un‚Äôaccumulazione lineare di vocabolario e regole grammaticali; piuttosto, emerge dall‚Äôinterazione dinamica di questi fattori mentre i bambini interagiscono con il loro ambiente e i caregiver, portando a cambiamenti qualitativi nelle capacit√† linguistiche nel tempo.\nDinamiche di gruppo e influenza sociale. Il comportamento di gruppo e l‚Äôinfluenza sociale sono fenomeni che possono essere modellati come sistemi dinamici. Nei gruppi sociali, i comportamenti e gli atteggiamenti individuali possono influenzare gli altri, portando a cambiamenti nelle norme e nelle dinamiche di gruppo. Questi cambiamenti possono quindi influenzare di nuovo i comportamenti individuali, creando un ciclo di retroazione. Ad esempio, in un contesto di gruppo, l‚Äôemergere di un leader o la diffusione di una particolare opinione pu√≤ portare a cambiamenti nel comportamento del gruppo che sono dinamici e talvolta imprevedibili.\nAutoregolazione e funzioni esecutive. L‚Äôautoregolazione e le funzioni esecutive coinvolgono la capacit√† di controllare l‚Äôattenzione, le emozioni e i comportamenti per raggiungere obiettivi a lungo termine. Questi processi sono dinamici perch√© implicano il monitoraggio continuo e l‚Äôaggiustamento delle azioni sulla base del feedback dall‚Äôambiente. Ad esempio, rimanere concentrati su un compito implica regolare dinamicamente l‚Äôattenzione in risposta alle distrazioni, il che richiede l‚Äôintegrazione di molteplici processi cognitivi come la memoria di lavoro, l‚Äôinibizione e la pianificazione.\nApprendimento e memoria. L‚Äôapprendimento e la memoria sono anche processi intrinsecamente dinamici. La codifica, l‚Äôimmagazzinamento e il recupero dei ricordi coinvolgono l‚Äôinterazione di molteplici sistemi neurali e cognitivi che cambiano nel tempo. Ad esempio, il processo di consolidamento della memoria, in cui i ricordi a breve termine vengono stabilizzati in ricordi a lungo termine, √® dinamico e pu√≤ essere influenzato da vari fattori come il sonno, lo stato emotivo e le esperienze successive.\nIn questa sezione della dispensa, forniremo un‚Äôintroduzione ai modelli dinamici, con particolare attenzione ai modelli di apprendimento per rinforzo. Questi modelli sono utilizzati in psicologia per spiegare i bias cognitivi in varie patologie, tra cui la depressione, i disturbi alimentari e il disturbo ossessivo-compulsivo. Questo campo di studio all‚Äôavanguardia, noto come psichiatria computazionale, non si limita agli esempi citati ma esplora una vasta gamma di applicazioni. In particolare, introdurremo uno dei modelli pi√π famosi in questo contesto: il modello di apprendimento associativo di Rescorla-Wagner. Questo modello descrive come gli organismi apprendano a prevedere eventi attraverso l‚Äôassociazione tra stimoli, fornendo una spiegazione quantitativa di come si sviluppano e si modificano le aspettative basate sull‚Äôesperienza. In psicologia, il modello di Rescorla-Wagner √® utilizzato per comprendere come gli individui apprendano dalle conseguenze delle loro azioni e come questo apprendimento possa essere influenzato da fattori cognitivi e affettivi, contribuendo cos√¨ alla nostra comprensione dei meccanismi alla base di diverse condizioni psicopatologiche.",
    "crumbs": [
      "Dinamiche",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/01_canoeing.html",
    "href": "chapters/dynamic_models/01_canoeing.html",
    "title": "84¬† Dinamiche post-errore",
    "section": "",
    "text": "84.1 Introduzione\nIn questo capitolo introdurremo i modelli dinamici utilizzando un semplice processo di Markov di primo livello. Utilizzeremo un esempio specifico per spiegare come questi modelli possano essere applicati per testare teorie psicologiche. In particolare, ci concentreremo su due diverse teorie psicologiche del controllo cognitivo che spiegano la prestazione dopo un errore. Le teorie del controllo cognitivo e della performance post-errore rappresentano un‚Äôarea di ricerca importante e dibattuta nella psicologia cognitiva e nelle neuroscienze cognitive. Le principali correnti teoriche proposte ‚Äî le teorie funzionali e non funzionali ‚Äî offrono interpretazioni contrastanti su come gli individui rispondono agli errori in compiti cognitivi.\nLe teorie funzionali, come quella proposta da Botvinick et al. (2001), si basano sul concetto di ‚Äúmonitoraggio del conflitto‚Äù. Secondo questo modello, quando si verifica un errore, il sistema cognitivo rileva un conflitto tra la risposta data e quella corretta, innescando un aumento del controllo cognitivo che migliora la performance nelle prove successive. L‚Äôarea cingolata anteriore (ACC) √® considerata cruciale in questo processo, fungendo da ‚Äúrilevatore di conflitto‚Äù e segnalando la necessit√† di un maggiore controllo cognitivo, mediato dalla corteccia prefrontale dorsolaterale (DLPFC). Studi successivi, come quello di Kerns et al.¬†(2004) utilizzando la risonanza magnetica funzionale (fMRI), hanno supportato questa teoria mostrando che l‚Äôattivit√† nell‚ÄôACC durante una prova con errore predice un aumento dell‚Äôattivit√† nella DLPFC e un miglioramento della performance nella prova successiva.\nAl contrario, le teorie non funzionali, come quelle proposte da Notebaert et al. (2009), suggeriscono che la performance post-errore sia peggiore rispetto a quella post-corretta. Queste teorie si basano sul concetto di ‚Äúorientamento attenzionale‚Äù o ‚Äúdisturbo‚Äù del sistema cognitivo. Secondo la teoria dell‚Äô‚Äúorientamento post-errore‚Äù, gli errori, essendo eventi infrequenti e salienti, catturano l‚Äôattenzione del soggetto, distogliendola dal compito in corso, e portano a un rallentamento e peggioramento della performance nelle prove successive.\n√à importante notare che entrambe le teorie hanno trovato supporto empirico in diversi studi. Ad esempio, Dutilh et al.¬†(2012) hanno trovato evidenze sia di rallentamento post-errore (coerente con le teorie non funzionali) sia di aumento dell‚Äôaccuratezza post-errore (coerente con le teorie funzionali). Danielmeier e Ullsperger (2011) hanno proposto una sintesi di questi punti di vista, suggerendo che la risposta agli errori potrebbe coinvolgere pi√π meccanismi operanti su scale temporali diverse: un rallentamento immediato dovuto a un orientamento attenzionale, seguito da un miglioramento della performance dovuto all‚Äôaumento del controllo cognitivo.\nLa maggior parte di questi studi si √® basata su compiti di laboratorio altamente controllati, utilizzando paradigmi di scelta forzata a due alternative (2AFC) ripetuti molte volte. Mentre questi paradigmi offrono un alto grado di controllo sperimentale, possono mancare di validit√† ecologica e non riflettere accuratamente il comportamento in situazioni reali, dove gli errori hanno conseguenze significative.\nIn questo tutorial, esamineremo il comportamento post-errore e post-prova corretta in situazioni reali, analizzando la performance di atleti durante competizioni di canoa slalom a livello mondiale ed europeo. Utilizzeremo i video degli atleti che attraversano correttamente la linea tra i pali, codificati da due giudici indipendenti, per analizzare la probabilit√† di commettere un errore dopo un attraversamento corretto o errato di una porta.\nStudiando il comportamento in contesti reali, possiamo testare queste previsioni opposte in condizioni in cui gli errori hanno conseguenze significative per l‚Äôindividuo. Questo approccio offre diversi vantaggi che sono elencati di seguito.\nStudiando il comportamento in una situazione reale di competizione, possiamo osservare come le teorie del controllo cognitivo si applicano in contesti ad alta posta in gioco. Gli atleti di alto livello sono intrinsecamente motivati a performare al meglio, il che potrebbe portare a risposte agli errori pi√π intense e rilevanti rispetto a quelle osservate in laboratorio. Gli atleti di √©lite hanno una vasta esperienza nel loro sport, che pu√≤ influenzare i loro meccanismi di controllo cognitivo in modi interessanti e diversi dai partecipanti tipici degli studi di laboratorio. Il canoa slalom richiede l‚Äôintegrazione di abilit√† motorie complesse con processi decisionali rapidi, offrendo una visione pi√π completa del controllo cognitivo rispetto ai tipici compiti di laboratorio. I risultati potrebbero avere implicazioni dirette per l‚Äôallenamento e la preparazione degli atleti, aumentando la rilevanza pratica della ricerca.\nI risultati di questo studio potrebbero fornire importanti indicazioni per le teorie del controllo cognitivo:\nIn conclusione, studiare il controllo cognitivo e la performance post-errore in un contesto sportivo di alto livello offre un‚Äôopportunit√† unica per testare e ampliare le teorie esistenti in un ambiente ecologicamente valido. I risultati possono non solo contribuire alla comprensione teorica del controllo cognitivo, ma anche fornire indicazioni pratiche per migliorare le prestazioni in contesti ad alta posta in gioco.\nIniziamo ad importare i dati.\ndata_file = os.path.join(project_directory, \"data\", \"canoeing_data.csv\")\ncanoeing_data = pd.read_csv(data_file)\ncanoeing_data.head()\n\n\n\n\n\n\n\n\n\nathlete\nboat_craft\nnation\nsex\nrank\ntime\nrun\ncity\nyear\nrunf\ngate\naccuracy\nNGATES\nacc\nn_gate\nlagged_accuracy\nsequence_id\n\n\n\n\n0\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG1\n1.0\n23\n1.0\n1\nNaN\n1.0\n\n\n1\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG2\n1.0\n23\n1.0\n2\n1.0\n1.0\n\n\n2\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG3\n1.0\n23\n1.0\n3\n1.0\n1.0\n\n\n3\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG4\n1.0\n23\n1.0\n4\n1.0\n1.0\n\n\n4\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG5\n1.0\n23\n1.0\n5\n1.0\n1.0\nCalcoliamo alcune statistiche descrittive.\n# Numero totale di prove\nnum_prove = len(canoeing_data)\n\n# Numero di atleti unici\nnum_atleti = canoeing_data[\"athlete\"].nunique()\n\n# Numero di competizioni uniche\nnum_competizioni = canoeing_data[\"city\"].nunique()\n\n# Anni in cui sono stati raccolti i dati\nanni_raccolti = canoeing_data[\"year\"].unique()\n\n# Stampa dei risultati\nprint(f\"Numero totale di prove: {num_prove}\")\nprint(f\"Numero di atleti: {num_atleti}\")\nprint(f\"Numero di competizioni: {num_competizioni}\")\nprint(f\"Anno in cui sono stati raccolti i dati: {anni_raccolti}\")\n\nNumero totale di prove: 66413\nNumero di atleti: 459\nNumero di competizioni: 20\nAnno in cui sono stati raccolti i dati: [2017]\nCreiamo la variabile is_error, assegnandole il valore 1 se la prova √® un errore e 0 altrimenti. Convertiamo inoltre il tipo di variabile in un numero intero, come richiesto dal codice Stan.\ncanoeing_data[\"accuracy\"] = canoeing_data[\"accuracy\"].fillna(1).astype(int)\ncanoeing_data[\"is_error\"] = canoeing_data[\"accuracy\"].apply(\n    lambda x: 1 if x == 0 else 0\n)\nInseriamo i dati in un dizionario nel formato atteso da Stan.\nstan_data = {\n    \"N\": len(canoeing_data[\"accuracy\"]), \n    \"y\": canoeing_data[\"is_error\"]\n}\nCompiliamo e stampiamo il codice Stan che assume che i dati seguano una distribuzione di Poisson, considerando che le prove siano indipendenti tra loro.\nstan_file = os.path.join(\n    project_directory, 'stan', 'canoeing_poisson_model.stan')\n\npoisson_model = CmdStanModel(stan_file=stan_file)\nprint(poisson_model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of trials\n  array[N] int&lt;lower=0&gt; y; // Number of errors in each trial (could be 0 or 1)\n}\nparameters {\n  real&lt;lower=0&gt; lambda; // Rate parameter for the Poisson distribution\n}\nmodel {\n  // Weak prior on lambda\n  lambda ~ normal(0, 10);\n  \n  // Likelihood: Poisson distribution\n  y ~ poisson(lambda);\n}\ngenerated quantities {\n  vector[N] log_lik; // Log-likelihood for each observation\n  for (n in 1 : N) {\n    log_lik[n] = poisson_lpmf(y[n] | lambda);\n  }\n}\nNella sezione model, l‚Äôistruzione lambda ~ normal(0, 10); definisce un prior per il parametro lambda, che √® il parametro della distribuzione di Poisson. Viene assunto un priore normale debole con media 0 e deviazione standard 10, che riflette l‚Äôipotesi che lambda possa prendere qualsiasi valore positivo con una leggera preferenza per valori vicini a zero.\nL‚Äôistruzione y ~ poisson(lambda); definisce la likelihood, ovvero la probabilit√† di osservare i dati y dati i parametri del modello. In questo caso, si assume che i dati seguano una distribuzione di Poisson con parametro lambda, che rappresenta la media (e varianza) del numero di errori nelle prove. L‚Äôassunzione qui √® che ogni prova sia indipendente dalle altre e che il numero di errori in ciascuna prova sia distribuito secondo una Poisson.\nNella sezione generated quantities, l‚Äôistruzione vector[N] log_lik; crea un vettore per memorizzare i valori del log-likelihood per ciascuna delle N osservazioni.\nL‚Äôistruzione for (n in 1:N) { log_lik[n] = poisson_lpmf(y[n] | lambda); }, mediante un ciclo for calcola la log-verosimiglianza per ogni singola osservazione y[n] rispetto alla distribuzione di Poisson con il parametro lambda. La funzione poisson_lpmf calcola la log-probability mass function (log-PMF) della distribuzione di Poisson per un dato valore y[n] e un parametro lambda. Il risultato √® un vettore log_lik che contiene la log-verosimiglianza di ciascuna osservazione. Questo √® richiesto per effettuare confronti tra modelli usando la Leave-One-Out Cross-Validation (LOO).\nEseguiamo il campionamento.\nfit_poisson = poisson_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False, \n    show_console=False\n)\nEsaminiamo le distribuzioni a posteriori.\naz.summary(fit_poisson, var_names=[\"lambda\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nlambda\n0.09\n0.0\n0.09\n0.09\n0.0\n0.0\n3036.8\n3682.58\n1.0\nConvertiamo l‚Äôoggetto creato da cmdstanpy nella classe InferenceData richiesta da ArviZ:\nfit_poisson_az = az.from_cmdstanpy(posterior=fit_poisson)\nEseguiamo la validazione incrociata Leave-One-Out (LOO-CV) utilizzando ArviZ:\nloo_poisson_result = az.loo(fit_poisson_az)\nprint(loo_poisson_result)\n\nComputed from 8000 posterior samples and 66413 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -20564.93   177.70\np_loo        0.92        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     66413  100.0%\n (0.5, 0.7]   (ok)           0    0.0%\n   (0.7, 1]   (bad)          0    0.0%\n   (1, Inf)   (very bad)     0    0.0%\nTutti i valori di Pareto \\(k\\) sono molto bassi, indicando che nessuna osservazione ha un‚Äôinfluenza eccessiva sulle stime del modello. Di conseguenza, non vi √® alcuna evidenza che la stima dell‚ÄôELPD, che in questo caso √® pari a -20564.93, possa essere distorta.\nOra calcoleremo l‚ÄôELPD per il modello che assume un processo di Markov di primo ordine. Questo modello considera una dipendenza temporale tra le prove, in cui la probabilit√† di commettere un errore dipende dal risultato della prova precedente. In particolare, il modello stabilisce che la probabilit√† di una risposta errata in una prova dipende dal fatto che la risposta precedente sia stata corretta o errata.\nCompiliamo e stampiamo il modello canoeing_markov_model.stan.\nstan_file = os.path.join(project_directory, \"stan\", \"canoeing_markov_model.stan\")\n\nmarkov_model = CmdStanModel(stan_file=stan_file)\nprint(markov_model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of trials\n  array[N] int&lt;lower=0, upper=1&gt; y; // Sequence of errors (0 = correct, 1 = error)\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p_error_given_error; // Probability of error given previous error\n  real&lt;lower=0, upper=1&gt; p_error_given_correct; // Probability of error given previous correct\n  real&lt;lower=0, upper=1&gt; p_initial_error; // Initial probability of error\n}\nmodel {\n  // Implicit weak priors on parameters\n  \n  // Likelihood for the first trial\n  y[1] ~ bernoulli(p_initial_error);\n  \n  // Likelihood for the rest of the trials\n  for (n in 2 : N) {\n    if (y[n - 1] == 1) {\n      y[n] ~ bernoulli(p_error_given_error);\n    } else {\n      y[n] ~ bernoulli(p_error_given_correct);\n    }\n  }\n}\ngenerated quantities {\n  vector[N] log_lik; // Log-likelihood for each observation\n  log_lik[1] = bernoulli_lpmf(y[1] | p_initial_error);\n  for (n in 2 : N) {\n    if (y[n - 1] == 1) {\n      log_lik[n] = bernoulli_lpmf(y[n] | p_error_given_error);\n    } else {\n      log_lik[n] = bernoulli_lpmf(y[n] | p_error_given_correct);\n    }\n  }\n}\nQuesto codice Stan modella una sequenza di prove in cui ogni prova pu√≤ essere corretta (0) o errata (1). Questo modello assume una dipendenza temporale tra le prove, basata su un processo di Markov di primo ordine. Ci√≤ significa che la probabilit√† di errore in una prova dipende solo dal risultato della prova precedente.\nNella sezione model, i parametri p_error_given_error, p_error_given_correct e p_initial_error hanno priors impliciti deboli poich√© sono definiti con limiti tra 0 e 1. Non sono stati specificati priors espliciti, quindi Stan utilizzer√† prior uniformi su questi parametri.\nIl primo elemento della sequenza y[1] rappresenta la prima prova. Qui, viene modellata la probabilit√† che questa prova sia un errore utilizzando una distribuzione di Bernoulli con probabilit√† p_initial_error.\nPer tutte le prove successive (dal secondo elemento in poi), il modello assume che la probabilit√† di errore (y[n] = 1) dipenda dal risultato della prova precedente:\nQuesto riflette l‚Äôidea che l‚Äôesito di una prova sia condizionato dallo stato immediatamente precedente, tipico di un processo di Markov di primo ordine.\nLa sezione generated quantities viene utilizzata per calcolare quantit√† derivate dai parametri stimati, in questo caso, il log-likelihood per ogni osservazione.\nI valori del log-likelihood sono memorizzati nel vettore log_lik che verr√† usato per valutare il modello attraverso la validazione incrociata LOO.\nIn sintesi, il modello rappresenta un processo di Markov di primo ordine in cui l‚Äôesito di una prova dipende dall‚Äôesito della prova precedente. La sezione generated quantities calcola il log-likelihood per ciascuna osservazione, consentendo di valutare e confrontare il modello utilizzando la tecnica bayesiana della validazione incrociata LOO.\nEseguiamo il campionamento.\nfit_markov = markov_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\nEsaminiamo le stime a posteriori dei parametri del modello.\naz.summary(\n    fit_markov, var_names=[\"p_error_given_error\", \"p_error_given_correct\"], round_to=2\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\np_error_given_error\n0.18\n0.0\n0.17\n0.19\n0.0\n0.0\n7522.48\n5864.69\n1.0\n\n\np_error_given_correct\n0.08\n0.0\n0.08\n0.08\n0.0\n0.0\n7353.13\n5562.07\n1.0\nCalcoliamo l‚ÄôELPD con il metodo LOO-CV.\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit_markov_az = az.from_cmdstanpy(posterior=fit_markov)\n\n# Perform LOO-CV using ArviZ\nloo_markov_result = az.loo(fit_markov_az)\nprint(loo_markov_result)\n\nComputed from 8000 posterior samples and 66413 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -20035.74   169.65\np_loo        2.33        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     66413  100.0%\n (0.5, 0.7]   (ok)           0    0.0%\n   (0.7, 1]   (bad)          0    0.0%\n   (1, Inf)   (very bad)     0    0.0%\nInfine, calcoliamo la differenza tra le stime dell‚ÄôELPD (elpd_diff) dei due modelli. L‚Äôincertezza associata a questa differenza √® espressa dal suo errore standard (dse). Se il rapporto tra elpd_diff e dse √® pari o superiore a 2, possiamo concludere che esiste una differenza credibile tra i due modelli.\ndf_comp_loo = az.compare({\n    \"poisson_model\": loo_poisson_result, \n    \"markov_model\": loo_markov_result\n})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmarkov_model\n0\n-20035.737644\n2.332125\n0.000000\n1.0\n169.648636\n0.000000\nFalse\nlog\n\n\npoisson_model\n1\n-20564.931364\n0.924353\n529.193719\n0.0\n177.702690\n25.801837\nFalse\nlog\n_ = az.plot_compare(df_comp_loo, insample_dev=False)\nLa differenza tra le stime dell‚ÄôELPD dei due modelli indica chiaramente che il modello che assume una dipendenza temporale tra le prove, qui modellizzata nei termini di un semplice processo di Markov di primo grado, √® pi√π adatto per i dati presenti che un modello di Poisson che assume che le prove siano tra loro indipendenti.\nUna volta stabilito che le prove mostrano una dipendenza temporale, si tratta di capire se la prestazione post-errore sia migliore o peggiore rispetto alla prestazione post-corretta.\nIl modello di Markov di primo ordine assume che la probabilit√† di commettere un errore in una prova dipenda dall‚Äôesito della prova precedente. Qui abbiamo due parametri principali:\nDai dati ottenuti:\nQuesta differenza tra p_error_given_error e p_error_given_correct suggerisce che gli atleti hanno una probabilit√† maggiore di commettere un errore se hanno appena commesso un errore rispetto a quando hanno eseguito correttamente la prova precedente. Questo √® un chiaro segnale che esiste una dipendenza temporale tra le prove, che il modello di Markov cattura meglio rispetto al modello di Poisson.\nDal riepilogo dei dati si ottiene:\n# Step 1: Ordinare per atleta, run, e n_gate per garantire un corretto lagging\ncanoeing_data = canoeing_data.sort_values(by=[\"athlete\", \"run\", \"n_gate\"])\n\n# Creare la colonna lagged_accuracy\ncanoeing_data[\"lagged_accuracy\"] = canoeing_data.groupby([\"athlete\", \"run\"])[\n    \"accuracy\"\n    ].shift(1)\n\n# Step 2: Riassumere la proporzione di prove corrette dopo una risposta corretta o un errore\n# Rimuovere le righe dove lagged_accuracy √® NaN (ad esempio, la prima prova di ogni run)\ndf_filtered = canoeing_data.dropna(subset=[\"lagged_accuracy\"])\n\n# Raggruppare per lagged_accuracy e calcolare le proporzioni\nproportions = (\n    df_filtered.groupby(\"lagged_accuracy\")\n    .agg(correct_trials=(\"accuracy\", \"sum\"), total_trials=(\"accuracy\", \"size\"))\n    .reset_index()\n)\n\nproportions[\"proportion_correct\"] = (\n    proportions[\"correct_trials\"] / proportions[\"total_trials\"]\n).round(3)\n\n# Stampare il risultato\nprint(proportions)\n\n   lagged_accuracy  correct_trials  total_trials  proportion_correct\n0              0.0            4828          5898               0.819\n1              1.0           54368         59338               0.916\nQuesta differenza indica chiaramente che la prestazione dell‚Äôatleta peggiora dopo aver commesso un errore: √® infatti pi√π probabile che l‚Äôatleta commetta un altro errore subito dopo.\nIn conclusione, l‚Äôaccuratezza dell‚Äôatleta tende a diminuire dopo un errore. Questo √® meglio rappresentato dal modello di Markov, che evidenzia una probabilit√† maggiore di commettere un errore dopo un errore precedente rispetto a dopo una prova corretta. Al contrario, il modello di Poisson, che presuppone l‚Äôindipendenza tra le prove, non riesce a catturare adeguatamente questa dinamica, risultando quindi meno adatto per descrivere i tuoi dati.\nInoltre, l‚Äôintervallo di credibilit√† al 94% dei parametri p_error_given_error e p_error_given_correct non si sovrappone, il che supporta l‚Äôidea che queste due condizioni siano credibilmente diverse.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Dinamiche post-errore</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/01_canoeing.html#introduzione",
    "href": "chapters/dynamic_models/01_canoeing.html#introduzione",
    "title": "84¬† Dinamiche post-errore",
    "section": "",
    "text": "Se si osserva un miglioramento della performance post-errore, questo supporterebbe le teorie funzionali, suggerendo che i meccanismi di controllo cognitivo proposti da Botvinick et al. (2001) si applicano anche in contesti reali ad alta posta in gioco.\nSe si rileva un peggioramento della performance post-errore, ci√≤ potrebbe supportare le teorie non funzionali e indicare che l‚Äôorientamento attenzionale verso gli errori √® particolarmente pronunciato in situazioni di competizione reale.\nPotrebbe emergere un pattern pi√π complesso, come un peggioramento iniziale seguito da un miglioramento, che supporterebbe modelli integrativi come quello proposto da Danielmeier e Ullsperger (2011).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe la prova precedente (y[n-1]) √® stata un errore (1), allora la probabilit√† di errore nella prova attuale √® p_error_given_error.\nSe la prova precedente √® stata corretta (0), allora la probabilit√† di errore nella prova attuale √® p_error_given_correct.\n\n\n\n\nPrimo Log-Likelihood: Per la prima prova (y[1]), il log-likelihood √® calcolato usando p_initial_error, poich√© questa prova non ha una dipendenza da prove precedenti.\nLog-Likelihood delle Prove Successive: Per tutte le prove successive, il log-likelihood √® calcolato in base all‚Äôesito della prova precedente, utilizzando p_error_given_error o p_error_given_correct a seconda che la prova precedente sia stata un errore o un successo. Il calcolo del log-likelihood utilizza la funzione bernoulli_lpmf, che restituisce il logaritmo della probabilit√† della funzione di massa della distribuzione Bernoulli per i dati osservati.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_error_given_error: La probabilit√† di commettere un errore dato che l‚Äôultima prova √® stata un errore.\np_error_given_correct: La probabilit√† di commettere un errore dato che l‚Äôultima prova √® stata corretta.\n\n\n\np_error_given_error = 0.18: Significa che, se un atleta ha commesso un errore nella prova precedente, la probabilit√† di commettere un altro errore nella prova successiva √® del 18%.\np_error_given_correct = 0.08: Significa che, se un atleta ha eseguito correttamente la prova precedente, la probabilit√† di commettere un errore nella prova successiva √® dell‚Äô8%.\n\n\n\n\nProporzione di risposte corrette dopo un errore: 0.819.\nProporzione di risposte corrette dopo una prova corretta: 0.916.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Dinamiche post-errore</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/01_canoeing.html#riflessioni-conclusive",
    "href": "chapters/dynamic_models/01_canoeing.html#riflessioni-conclusive",
    "title": "84¬† Dinamiche post-errore",
    "section": "84.2 Riflessioni Conclusive",
    "text": "84.2 Riflessioni Conclusive\nQuesto esercizio ci ha permesso di introdurre i modelli dinamici attraverso l‚Äôutilizzo di un processo di Markov di primo ordine per confrontare due teorie psicologiche che descrivono la prestazione post-errore: le teorie funzionali (Botvinick et al. (2001)), che prevedono un miglioramento della prestazione dopo un errore, e le teorie non funzionali (Notebaert et al. (2009)), che suggeriscono un peggioramento della prestazione in seguito a un errore.\nAbbiamo utilizzato dati relativi alle prestazioni di atleti in eventi sportivi ufficiali per mettere alla prova queste teorie. Questi dati sono particolarmente interessanti rispetto a quelli raccolti in ambienti di laboratorio, poich√© riflettono il comportamento reale degli individui in situazioni in cui gli errori hanno conseguenze significative.\nIn questo tutorial, abbiamo inizialmente considerato l‚Äôipotesi che non vi fosse dipendenza temporale nelle prestazioni degli atleti, assumendo che gli errori fossero indipendenti nella sequenza delle prove. Questa ipotesi, che contrasta con entrambe le teorie funzionali e non funzionali, √® stata implementata nel modello di Poisson, il quale presuppone l‚Äôindipendenza tra le prove.\nConfrontando i modelli tramite la differenza nell‚ÄôELPD (Expected Log Predictive Density), abbiamo dimostrato che il modello semplice di Poisson pu√≤ essere respinto e che i dati sono descritti in modo molto pi√π accurato da un modello che assume una dipendenza temporale nelle prestazioni degli atleti. Il modello che incorpora questa ipotesi √® un processo di Markov di primo ordine, che tiene conto dell‚Äôinfluenza della prova precedente sulla performance successiva.\nPer confrontare le teorie funzionali e non funzionali post-errore, √® stato fondamentale determinare la direzione della differenza nella prestazione post-errore: questa differenza indica un miglioramento o un peggioramento delle prestazioni?\nLe statistiche descrittive hanno mostrato un peggioramento della prestazione post-errore. L‚Äôinferenza bayesiana, calcolando l‚Äôintervallo di credibilit√† al 94% per i parametri p_error_given_error e p_error_given_correct, ha confermato che questa differenza √® credibile.\nPossiamo quindi concludere che i dati relativi agli atleti nelle competizioni di alto livello di canoa slalom supportano le teorie non funzionali post-errore.\n√à importante, tuttavia, considerare alcune limitazioni di questa analisi.\nInnanzitutto, il modello di Markov di primo ordine che abbiamo utilizzato non tiene conto del clustering delle prove, cio√® del fatto che i dati provengono da atleti diversi. Ogni atleta ha caratteristiche uniche, e le prove all‚Äôinterno della sequenza di un singolo atleta sono pi√π simili tra loro rispetto a quelle di atleti diversi. Per semplicit√†, questo aspetto dei dati non √® stato modellizzato. Un‚Äôanalisi pi√π approfondita richiederebbe l‚Äôuso di un modello gerarchico bayesiano, che, sebbene non necessario per gli scopi di questo tutorial, sarebbe pi√π appropriato per un‚Äôanalisi completa.\nInoltre, i dati presentano una questione pi√π complessa. Abbiamo utilizzato questi dati per testare modelli psicologici che assumono che l‚Äôelaborazione delle informazioni e il comportamento restino coerenti dopo una prova corretta o un errore nella prova precedente. Tuttavia, questa assunzione potrebbe non essere valida nel contesto del canoa slalom. Se un atleta commette un errore, ci√≤ potrebbe influenzare la posizione della canoa, rendendo pi√π difficile o pi√π facile superare la porta successiva. Questo potrebbe aumentare la probabilit√† di commettere un ulteriore errore o, in alcuni casi, ridurla. Per esplorare ulteriormente questo aspetto, sarebbe necessario analizzare i video delle prove, ma tale indagine va oltre gli obiettivi di questo tutorial.\nInfine, non abbiamo analizzato schemi pi√π complessi, come un peggioramento iniziale seguito da un successivo miglioramento, che potrebbero sostenere modelli integrativi come quello proposto da Danielmeier e Ullsperger (2011).\nIn conclusione, nonostante le potenziali limitazioni di questo studio, i dati raccolti offrono un supporto maggiore alle teorie non funzionali rispetto a quelle funzionali della performance post-errore, specialmente quando si considerano dati reali sulle prestazioni di atleti di alto livello. Inoltre, indicano chiaramente che, almeno nel contesto esaminato, esiste una marcata dipendenza temporale tra le prove di una competizione atletica di alto livello.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Dinamiche post-errore</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/01_canoeing.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/01_canoeing.html#informazioni-sullambiente-di-sviluppo",
    "title": "84¬† Dinamiche post-errore",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sat Jul 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\npingouin  : 0.5.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBotvinick, Matthew M, Todd S Braver, Deanna M Barch, Cameron S Carter, e Jonathan D Cohen. 2001. ¬´Conflict monitoring and cognitive control.¬ª Psychological review 108 (3): 624‚Äì52.\n\n\nDanielmeier, Claudia, e Markus Ullsperger. 2011. ¬´Post-error adjustments¬ª. Frontiers in psychology 2: 233.\n\n\nNotebaert, Wim, Femke Houtman, Filip Van Opstal, Wim Gevers, Wim Fias, e Tom Verguts. 2009. ¬´Post-error slowing: an orienting account¬ª. Cognition 111 (2): 275‚Äì79.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>84</span>¬† <span class='chapter-title'>Dinamiche post-errore</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html",
    "href": "chapters/dynamic_models/02_change_across_time.html",
    "title": "85¬† Modellare il cambiamento nel tempo",
    "section": "",
    "text": "85.1 Introduzione\nL‚Äôobiettivo di questo capitolo √® introdurre i modelli che descrivono i processi dinamici, seguendo un tutorial proposto da Knight et al. (2023). In molti ambiti della psicologia, come la psicologia sociale, dello sviluppo, clinica e organizzativa, si studiano fenomeni che cambiano nel tempo e sono quindi dinamici. Tuttavia, questi processi dinamici sono spesso difficili da osservare o misurare direttamente, poich√© possono essere il risultato di diverse combinazioni di processi che si manifestano in modi variabili a seconda del contesto e delle persone coinvolte. Inoltre, i processi dinamici possono operare su diversi livelli e svilupparsi su scale temporali differenti.\nPer verificare una teoria dinamica, un ricercatore deve adottare un disegno di ricerca longitudinale che consenta di osservare i processi psicologici nel loro sviluppo nel tempo, e utilizzare un modello statistico che traduca in termini operativi i processi descritti dalla teoria. Un approccio particolarmente utile per modellare i processi dinamici √® l‚Äôapproccio bayesiano, che offre maggiore flessibilit√† rispetto ad altre alternative, come i modelli di curve di crescita latenti e i modelli di punteggi dei cambiamento latenti, nei quali la complessit√† aumenta drasticamente con l‚Äôaumentare del numero di variabili e dei punti temporali.\nLa flessibilit√† di questo approccio consente di costruire modelli statistici che si allineano pi√π direttamente alla teoria psicologica. Ci√≤ permette una connessione pi√π stretta tra teoria e modello, e consente una verifica pi√π chiara della teoria stessa.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#comprendere-i-processi-dinamici",
    "href": "chapters/dynamic_models/02_change_across_time.html#comprendere-i-processi-dinamici",
    "title": "85¬† Modellare il cambiamento nel tempo",
    "section": "85.2 Comprendere i Processi Dinamici",
    "text": "85.2 Comprendere i Processi Dinamici\nI processi dinamici sono solitamente rappresentati come sistemi a ciclo chiuso, in cui gli output del sistema influenzano gli input, determinando cos√¨ cambiamenti continui nei componenti del sistema nel tempo. Una caratteristica fondamentale di un processo dinamico √® che almeno una delle variabili mantiene una ‚Äúmemoria‚Äù del suo valore nei momenti temporali precedenti. Questo tipo di variabile, spesso chiamata ‚Äúvariabile dinamica‚Äù, cambia il suo valore nel tempo in modo coerente con il suo stato passato. Pu√≤ aumentare o diminuire, ma non pu√≤ assumere valori che sarebbero incompatibili o illogici rispetto al suo stato precedente.\nI modelli bayesiani che descrivono i processi dinamici sono spesso utilizzati in psicologia cognitiva. Questi includono modelli di apprendimento per rinforzo, che catturano come le persone interagiscono con l‚Äôambiente per massimizzare la ricompensa cumulativa, e modelli di diffusione, che rappresentano come le persone prendono decisioni rapide.\nNel loro tutorial, Knight et al. (2023) utilizzano un esempio di regolazione degli obiettivi per illustrare un processo dinamico rilevante in molte aree della psicologia. La regolazione degli obiettivi √® un meccanismo attraverso il quale le persone valutano e modificano i loro obiettivi nel tempo, basandosi sulle loro performance passate.\nPer spiegare il processo dinamico di regolazione degli obiettivi, vengono utilizzati dati reali provenienti da uno studio di simulazione del controllo del traffico aereo condotto da Gee, Neal, e Vancouver (2018). In questo studio, 60 partecipanti hanno completato dieci prove di 10 minuti ciascuna, durante le quali dovevano classificare coppie di aeromobili come in conflitto o non in conflitto in base alla loro distanza minima di separazione. Prima di ogni prova, i partecipanti fissavano un obiettivo riguardo al numero di coppie di aeromobili che intendevano classificare correttamente o erroneamente. L‚Äôobiettivo dello studio era esaminare come le persone rivedessero i loro obiettivi nel tempo sulla base delle loro performance.\nIl modello utilizzato per descrivere questo processo predice che una persona modifica il proprio obiettivo in funzione della discrepanza tra l‚Äôobiettivo precedente e la performance ottenuta. Questo modello incorpora una componente auto-regressiva che conserva una ‚Äúmemoria‚Äù del passaggio temporale precedente. Formalmente, il processo √® descritto dall‚Äôequazione:\n\\[\nG_t = G_{t-1} + \\alpha(P_{t-1} - G_{t-1}) + \\beta,\n\\]\ndove \\(G\\) rappresenta il livello dell‚Äôobiettivo e \\(P\\) la performance effettiva. Il parametro \\(\\alpha\\) rappresenta il tasso di apprendimento: valori pi√π alti di \\(\\alpha\\) indicano che la revisione dell‚Äôobiettivo √® pi√π sensibile alla discrepanza tra l‚Äôobiettivo precedente e la performance precedente. Il parametro \\(\\beta\\) rappresenta un aggiustamento dell‚Äôobiettivo che avviene indipendentemente dalla discrepanza tra obiettivo e performance.\nPer rappresentare adeguatamente questo modello, √® necessario considerare il livello dell‚Äôobiettivo come una variabile dinamica che conserva una ‚Äúmemoria‚Äù del suo stato precedente. Questo tipo di processo dinamico √® complesso da rappresentare utilizzando approcci statistici tradizionali, ma √® facilmente implementabile all‚Äôinterno del framework bayesiano.\nQuesta struttura dinamica √® concettualmente simile a un modello di Markov di primo ordine, come quello descritto in precedenza. Nel modello di Markov discusso nel Capitolo 84, la probabilit√† di commettere un errore alla prova attuale (\\(y[n]\\)) dipende esclusivamente dallo stato immediatamente precedente (\\(y[n-1]\\)), caratterizzandolo come un processo senza memoria a lungo termine ma con dipendenza temporale di primo ordine.\nEntrambi i modelli condividono l‚Äôidea di dipendenza dal passato immediato: nel modello dinamico utilizzato da Gee, Neal, e Vancouver (2018), l‚Äôobiettivo viene aggiornato in base alla discrepanza tra l‚Äôobiettivo e la performance passata, mentre nel modello di Markov del Capitolo 84 la probabilit√† di errore successivo √® determinata dallo stato dell‚Äôerrore precedente. In entrambi i casi, le transizioni sono influenzate solo dallo stato o dalla condizione immediatamente precedente, una caratteristica fondamentale dei processi di Markov di primo ordine. Tuttavia, mentre il modello del Capitolo 84 considera esclusivamente uno stato binario (errore o non errore), il modello dinamico attuale prende in considerazione una variabile continua e la discrepanza tra obiettivo e performance, permettendo una rappresentazione pi√π dettagliata dei cambiamenti nel comportamento.\nIniziamo ad importare i dati dello studio di Gee, Neal, e Vancouver (2018).\n\ndata_file = os.path.join(project_directory, \"data\", \"goal_data.csv\")\ngoal_data = pd.read_csv(data_file)\ngoal_data.head()\n\n\n\n\n\n\n\n\n\nsubject\ncondition\ngoal\nperformance\ntrial\n\n\n\n\n0\n1\napproach\n2\n0\n1\n\n\n1\n1\napproach\n2\n2\n2\n\n\n2\n1\napproach\n2\n2\n3\n\n\n3\n1\napproach\n4\n4\n4\n\n\n4\n1\napproach\n4\n2\n5\n\n\n\n\n\n\n\n\nCalcoliamo alcune statistiche descrittive.\n\n# Numero totale di prove\nnum_trials = len(goal_data)\n\n# Numero di atleti unici\nnum_subj = goal_data[\"subject\"].nunique()\n\n# Stampa dei risultati\nprint(f\"Numero totale di prove: {num_trials}\")\nprint(f\"Numero di partecipanti: {num_subj}\")\n\nNumero totale di prove: 600\nNumero di partecipanti: 60\n\n\nOrganizziamo i dati in un dizionario nel formato richiesto da Stan per i modelli presentati da Knight et al. (2023), che discuteremo qui.\n\nstan_data = {\n    \"subject\": goal_data[\"subject\"].tolist(),\n    \"condition\": pd.factorize(goal_data[\"condition\"])[0]\n    + 1,  # 1 = approach, 2 = avoidance\n    \"observed_goal\": goal_data[\"goal\"].tolist(),\n    \"trial\": goal_data[\"trial\"].tolist(),\n    \"performance\": goal_data[\"performance\"].tolist(),\n    \"Nsubj\": goal_data[\"subject\"].nunique(),\n    \"Ntotal\": len(goal_data[\"subject\"]),\n}\n\nAnalizziamo ogni elemento del dizionario. Questo passaggio ci sar√† utile pi√π avanti per comprendere il funzionamento del codice Stan.\n\n# Iterate through each element in the dictionary and print the length and first 15 elements\nfor key, value in stan_data.items():\n    if (\n        isinstance(value, list)\n        or isinstance(value, pd.Series)\n        or isinstance(value, np.ndarray)\n    ):\n        print(f\"{key}: Length = {len(value)}\")\n        print(f\"First 15 elements of {key}: {value[:15]}\")\n    else:\n        print(f\"{key}: {value}\")\n\nsubject: Length = 600\nFirst 15 elements of subject: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\ncondition: Length = 600\nFirst 15 elements of condition: [1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\nobserved_goal: Length = 600\nFirst 15 elements of observed_goal: [2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 6, 6, 6]\ntrial: Length = 600\nFirst 15 elements of trial: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5]\nperformance: Length = 600\nFirst 15 elements of performance: [0, 2, 2, 4, 2, 0, 4, 2, 4, 4, 3, 5, 7, 5, 6]\nNsubj: 60\nNtotal: 600",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#modello-a-livello-di-campione",
    "href": "chapters/dynamic_models/02_change_across_time.html#modello-a-livello-di-campione",
    "title": "85¬† Modellare il cambiamento nel tempo",
    "section": "85.3 Modello a livello di campione",
    "text": "85.3 Modello a livello di campione\nIl primo modello presentato da Knight et al. (2023) √® il 1_sample_level_model.stan. Questo modello include due parametri teoricamente rilevanti: Œ± e Œ≤. Per implementare il modello di revisione degli obiettivi come modello statistico, si aggiunge un terzo parametro, œÉ, che rappresenta la deviazione standard residua del livello degli obiettivi.\nNel modello proposto, questi parametri vengono stimati a livello di campione, ovvero il comportamento dell‚Äôintero campione viene descritto utilizzando un unico set di parametri. Il modello assume quindi che il processo di revisione degli obiettivi sia identico per tutti i partecipanti.\nProcediamo ora con la compilazione e la stampa del codice Stan di questo modello.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"change_models\", \"1_sample_level_model.stan\"\n)\n\nsample_level_model = CmdStanModel(stan_file=stan_file)\nprint(sample_level_model.code())\n\ndata {\n  int&lt;lower=1&gt; Ntotal; //Total number of trials in the dataset (600)\n  array[Ntotal] real&lt;lower=1&gt; trial; //Trial number\n  array[Ntotal] real observed_goal; //Goal level for each trial\n  array[Ntotal] real performance; //Performance for each trial\n}\nparameters {\n  real alpha; //initialize single alpha parameter for entire sample\n  real beta; //initialize single beta parameter for entire sample\n  real&lt;lower=0&gt; sigma; //initialize single sigma parameter for entire sample and set lower bound at 0.\n}\nmodel {\n  real predicted_goal; //initialize predicted goal level object to store predictions\n  \n  //PRIORS\n  alpha ~ normal(0, 1); //set weakly informative prior on alpha\n  beta ~ normal(0, 1); //set weakly informative prior on beta\n  sigma ~ normal(0, 1); //set weakly informative prior on sigma\n  \n  //LIKELIHOOD\n  //loop through all trials in the dataset performing bracketed operations on each one\n  for (i in 1 : Ntotal) {\n    //if the trial being considered is the first trial for that subject...\n    if (trial[i] == 1) {\n      //set predicted_goal to be equal to observed_goal for that trial\n      predicted_goal = observed_goal[i];\n    }\n    //if the trial being considered is not the first trial for that subject...\n    if (trial[i] &gt; 1) {\n      //increment predicted_goal according to the theory of change\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n    }\n    //evaluate likelihood of observed goal given a normal distribution with mean = predicted_goal and sd = sigma\n    observed_goal[i] ~ normal(predicted_goal, sigma);\n  }\n}\n//NOTE: The generated quantities block (below) is NOT needed for the model to run. However, it can be useful for generating posterior predictives from the model. The posterior predictives from this model were presented in the \"model evalutation\" section of the paper.\n\ngenerated quantities {\n  real predicted_goal; // Initialize object to store goal level predicted by the model\n  array[Ntotal] real&lt;lower=1&gt; sampled_goal; // Initialize object to store set of goal level samples (i.e., the posterior predictives)\n  array[Ntotal] real log_lik; // Initialize array to store the log likelihood for each data point\n  \n  // Loop through all trials in the dataset generating predictions in the same way as above\n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    }\n    if (trial[i] &gt; 1) {\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n    }\n    \n    // Sample a goal level from the distribution of the predicted goal\n    sampled_goal[i] = normal_rng(predicted_goal, sigma);\n    \n    // Calculate the log likelihood for the observed goal\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal, sigma);\n  }\n}\n\n\n\nNel modello 1_sample_level_model.stan, i dati sono rappresentati da una serie di variabili, tra cui il numero totale di prove (Ntotal), il numero di ciascuna prova (trial), il livello di obiettivo osservato in ciascuna prova (observed_goal), e la performance in ciascuna prova (performance).\nI parametri principali del modello sono alpha, beta e sigma:\n\nalpha e beta: sono parametri a cui vengono assegnate prior distribuzioni normali con media 0 e deviazione standard 1. Questi sono noti come ‚Äúpriori debolmente informativi‚Äù perch√© non esprimono una forte convinzione a priori su una particolare regione dello spazio dei parametri.\nsigma: √® un altro parametro che rappresenta la deviazione standard residua del livello degli obiettivi. Anche sigma ha un priore distribuito normalmente, ma con un vincolo aggiuntivo: deve essere positivo (da qui real&lt;lower=0&gt; sigma). Questo significa che l‚Äôalgoritmo campioner√† solo valori positivi da questa distribuzione.\n\nIl ‚Äúmodello‚Äù in questo contesto si riferisce alla sequenza di operazioni necessarie per determinare la verosimiglianza dei dati dati i valori campionati dei parametri. Il modello √® costruito utilizzando un ciclo for che esegue operazioni per ogni punto dati.\n\nCiclo for: La linea for (i in 1 : Ntotal) inizializza un ciclo che itera attraverso tutti i punti dati, da 1 fino a Ntotal. Durante ogni iterazione, la variabile di ciclo i assume il valore dell‚Äôindice corrente.\n\nPrima prova: Se i rappresenta il primo trial per un soggetto (trial[i] == 1), il livello di obiettivo previsto (predicted_goal) √® impostato uguale all‚Äôobiettivo osservato (observed_goal[i]). Questo √® perch√© non ci sono prove precedenti per determinare un obiettivo previsto basato sulla performance passata. Questo comportamento √® definito alle linee 25-27 del modello.\nProve successive: Per tutte le prove successive alla prima (trial[i] &gt; 1), il livello di obiettivo previsto viene aggiornato secondo una teoria del cambiamento: predicted_goal viene incrementato in base alla differenza tra la performance della prova precedente e il livello di obiettivo previsto attuale, aggiungendo anche il parametro beta specifico per l‚Äôindividuo. Questo √® implementato alle linee 28-30. L‚Äôoperatore += aggiorna il valore corrente di predicted_goal aggiungendo il risultato del calcolo.\n\nVerosimiglianza: Dopo aver calcolato predicted_goal, il modello confronta questo valore con observed_goal. La linea 31 utilizza l‚Äôoperatore ~ per specificare che observed_goal √® trattato come una variabile dipendente. Qui, si assume che observed_goal[i] provenga da una distribuzione normale con una media uguale a predicted_goal e una deviazione standard uguale a sigma. L‚Äôalgoritmo quindi valuta la verosimiglianza dell‚Äôobiettivo osservato dato i valori attuali dei parametri e aggiorna di conseguenza la distribuzione a posteriori.\n\nIn altre parole, il modello effettua una regressione dell‚Äôobiettivo osservato sull‚Äôobiettivo previsto, fissando l‚Äôintercetta a 0 e la pendenza a 1, con sigma che rappresenta la deviazione standard residua dell‚Äôobiettivo osservato. Questo permette al modello di adattarsi dinamicamente ai dati e di descrivere come gli obiettivi si modificano nel tempo in funzione delle performance passate.\nEseguiamo il campionamento.\n\nfit_sample = sample_level_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nConvertiamo l‚Äôoggetto fit_sample in un formato compatibile con ArviZ.\n\nfit_sample_az = az.from_cmdstanpy(posterior=fit_sample)\n\nEsaminiamo le distribuzioni a posteriori dei paraemtri.\n\naz.summary(fit_sample_az, var_names=[\"alpha\", \"beta\", \"sigma\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.51\n0.03\n0.45\n0.57\n0.0\n0.0\n6395.60\n5448.32\n1.0\n\n\nbeta\n0.17\n0.03\n0.11\n0.23\n0.0\n0.0\n6646.13\n5931.03\n1.0\n\n\nsigma\n1.29\n0.04\n1.22\n1.36\n0.0\n0.0\n6400.46\n5046.39\n1.0\n\n\n\n\n\n\n\n\nI risultati ottenuti per il modello a livello di campione mostrano i valori stimati per i parametri alpha, beta e sigma:\n\nAlpha: Il valore pi√π probabile per alpha si trova nel range tra 0.45 e 0.57, con una media stimata di 0.51. Questo intervallo suggerisce che i tassi di apprendimento si trovano principalmente in questa gamma, indicando che le persone tendono ad aggiornare il loro obiettivo basandosi sulla differenza tra la performance passata e l‚Äôobiettivo previsto in modo moderato.\nBeta: I valori pi√π probabili per beta sono compresi tra 0.11 e 0.23, con una media di 0.17. Questo risultato suggerisce che, indipendentemente dalla discrepanza tra l‚Äôobiettivo precedente e la performance precedente, le persone tendono ad aumentare il loro obiettivo di una piccola quantit√† aggiuntiva.\nSigma: La deviazione standard residua sigma √® stimata con una media di 1.29, con un intervallo credibile del 94% che va da 1.22 a 1.36. Questo parametro rappresenta la variabilit√† residua nei livelli degli obiettivi osservati che non √® spiegata dal modello.\n\nNel modello attuale, i parametri alpha e beta rappresentano i valori medi dei parametri per tutti i partecipanti del campione. Questo implica che il modello considera che il processo di revisione degli obiettivi avvenga nello stesso modo per ogni partecipante, utilizzando un unico set di parametri per descrivere il comportamento dell‚Äôintero campione. Tuttavia, questo modello non ci fornisce informazioni su come questi parametri possano variare tra i singoli individui.\nPer esaminare le differenze a livello individuale, sarebbe necessario un modello a livello di persona, dove vengono stimati parametri unici per ogni partecipante. Un tale modello permetterebbe di considerare le variazioni individuali, assumendo che il processo di revisione degli obiettivi possa funzionare in modo diverso per ciascuna persona.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#modello-a-livello-di-persona",
    "href": "chapters/dynamic_models/02_change_across_time.html#modello-a-livello-di-persona",
    "title": "85¬† Modellare il cambiamento nel tempo",
    "section": "85.4 Modello a livello di persona",
    "text": "85.4 Modello a livello di persona\nUn modello a livello di persona √® fornito nel codice 2_person_level_model.stan. Tale modello pu√≤ essere facilmente implementato apportando alcune modifiche al modello precedente:\n\nNuove variabili nel blocco dati: Sono necessarie due nuove variabili: Nsubj, che rappresenta il numero totale di partecipanti (ad esempio, Nsubj = 60), e subject, una colonna di numeri interi che rappresentano il numero del partecipante.\nParametri come array: Nel blocco dei parametri, alpha e beta devono essere dichiarati come array di dimensione Nsubj anzich√© come valori scalari. Questo implica che ci sar√† un parametro alpha e un parametro beta unici stimati per ogni partecipante, permettendo di modellare la variabilit√† individuale.\nModifiche nel blocco del modello: Nel blocco del modello, i parametri alpha e beta devono essere indicizzati con subject[i] per far s√¨ che il punteggio previsto sia calcolato in base ai parametri associati al partecipante i-esimo, in base ai dati situati nella riga i-esima del dataset.\n\nQueste modifiche permettono di passare da un modello che descrive il comportamento medio del campione a uno che pu√≤ catturare le differenze individuali, fornendo un‚Äôanalisi pi√π dettagliata e precisa delle dinamiche di revisione degli obiettivi.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"change_models\", \"2_person_level_model.stan\"\n)\n\nperson_level_model = CmdStanModel(stan_file=stan_file)\nprint(person_level_model.code())\n\ndata {\n  int&lt;lower=0&gt; Ntotal; // Total number of trials in the dataset (600)\n  array[Ntotal] int&lt;lower=1&gt; trial; // Trial number\n  array[Ntotal] real observed_goal; // Goal level for each trial\n  array[Ntotal] real performance; // Performance for each trial\n  int&lt;lower=1&gt; Nsubj; // Number of subjects\n  array[Ntotal] int&lt;lower=1, upper=Nsubj&gt; subject; // Subject number\n}\nparameters {\n  vector[Nsubj] alpha; // Unique alpha parameter for each subject\n  vector[Nsubj] beta; // Unique beta parameter for each subject\n  real&lt;lower=0&gt; sigma; // Single sigma parameter for entire sample\n}\nmodel {\n  vector[Ntotal] predicted_goal; // Vector to store predictions\n  \n  // Priors\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n  \n  // Likelihood\n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      predicted_goal[i] = predicted_goal[i - 1]\n                          + alpha[subject[i]]\n                            * (performance[i - 1] - predicted_goal[i - 1])\n                          + beta[subject[i]];\n    }\n  }\n  \n  observed_goal ~ normal(predicted_goal, sigma);\n}\ngenerated quantities {\n  vector[Ntotal] predicted_goal;\n  array[Ntotal] real sampled_goal;\n  array[Ntotal] real log_lik;\n  \n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      predicted_goal[i] = predicted_goal[i - 1]\n                          + alpha[subject[i]]\n                            * (performance[i - 1] - predicted_goal[i - 1])\n                          + beta[subject[i]];\n    }\n    \n    sampled_goal[i] = normal_rng(predicted_goal[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal[i], sigma);\n  }\n}\n\n\n\nEseguiamo il campionamento.\n\nfit_person = person_level_model.sample(\n    data=stan_data,\n    iter_warmup=10_000,\n    iter_sampling=20_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nQuesto modello produce un insieme di campioni posteriori di alpha e beta per ogni partecipante.\n\nfit_person_az = az.from_cmdstanpy(posterior=fit_person)\naz.summary(fit_person_az, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha[0]\n0.61\n0.24\n0.16\n1.04\n0.00\n0.00\n4791.24\n3205.07\n1.00\n\n\nalpha[1]\n0.19\n0.21\n-0.21\n0.60\n0.00\n0.00\n5696.38\n23355.82\n1.01\n\n\nalpha[2]\n0.14\n0.20\n-0.21\n0.57\n0.01\n0.01\n482.28\n131.39\n1.01\n\n\nalpha[3]\n0.36\n0.32\n-0.22\n0.96\n0.01\n0.01\n1292.01\n13071.55\n1.00\n\n\nalpha[4]\n0.37\n0.17\n0.05\n0.68\n0.00\n0.00\n1673.29\n27077.52\n1.00\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nsampled_goal[596]\n6.23\n0.96\n4.43\n8.04\n0.01\n0.00\n25829.93\n72786.03\n1.00\n\n\nsampled_goal[597]\n6.88\n0.96\n5.07\n8.66\n0.00\n0.00\n44329.67\n75437.97\n1.00\n\n\nsampled_goal[598]\n6.40\n0.98\n4.55\n8.23\n0.01\n0.01\n17989.62\n68475.72\n1.00\n\n\nsampled_goal[599]\n6.28\n0.98\n4.40\n8.07\n0.01\n0.00\n19943.05\n65972.11\n1.00\n\n\nsigma\n0.90\n0.04\n0.83\n0.98\n0.01\n0.01\n8.79\n25.62\n1.36\n\n\n\n\n1321 rows √ó 9 columns\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\n\n# Extract the alpha parameters only\nalpha_params = fit_person_az.posterior[\"alpha\"]\n\n# Plot forest plot for alpha parameters\n_ = az.plot_forest(\n    alpha_params,\n    hdi_prob=0.94,  # Set the credible interval to 94%\n    combined=True,  # Combine the chains if there are multiple\n    r_hat=False,  # Display the r_hat values\n    figsize=(10, 6),\n)\n\n\n\n\n\n\n\n\n\n# Extract the beta parameters only\nbeta_params = fit_person_az.posterior[\"beta\"]\n\n# Plot forest plot for beta parameters\n_ = az.plot_forest(\n    beta_params,\n    hdi_prob=0.94,  # Set the credible interval to 94%\n    combined=True,  # Combine the chains if there are multiple\n    r_hat=False,  # Display the r_hat values\n    figsize=(10, 6),\n)\n\n\n\n\n\n\n\n\nCome si pu√≤ vedere, c‚Äô√® eterogeneit√† tra i partecipanti sia per Œ± che per Œ≤. Il pannello di destra mostra i parametri Œ± e Œ≤ di ciascun partecipante rappresentati graficamente l‚Äôuno contro l‚Äôaltro, con le croci che indicano gli intervalli credibili per ciascun parametro.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#modello-gerarchico",
    "href": "chapters/dynamic_models/02_change_across_time.html#modello-gerarchico",
    "title": "85¬† Modellare il cambiamento nel tempo",
    "section": "85.5 Modello Gerarchico",
    "text": "85.5 Modello Gerarchico\nSebbene la stima dei parametri a livello individuale offra vantaggi rispetto al modello a livello di campione, presenta anche alcune limitazioni. Un problema del modello a livello di persona √® che rende difficile fare inferenze sulla popolazione da cui provengono i partecipanti. Analizzare un modello a livello individuale √® simile a eseguire un‚Äôanalisi separata per ciascun partecipante del campione. Questo approccio ha una potenza inferiore perch√© considera i dati di un solo partecipante alla volta, ignorando il resto del campione. Inoltre, non riesce a catturare le somiglianze tra gli individui che potrebbero derivare dal fatto che i partecipanti appartengono alla stessa popolazione.\nSpesso i ricercatori desiderano esaminare la variazione tra i partecipanti e, al contempo, fare inferenze sulla popolazione nel suo complesso. Un approccio di modellizzazione gerarchica √® estremamente utile a questo scopo. I modelli bayesiani gerarchici permettono ai ricercatori di modellare simultaneamente i livelli individuali e quello di popolazione.\nCome nel modello a livello individuale, il modello gerarchico stima parametri unici per ogni individuo. Tuttavia, a differenza del modello a livello individuale, l‚Äôapproccio gerarchico modella anche la distribuzione dei parametri a livello individuale nella popolazione generale. Di conseguenza, i parametri a livello individuale sono influenzati non solo dai dati di quel singolo individuo, ma anche dalla distribuzione a livello di popolazione del parametro rilevante, riducendo l‚Äôinfluenza degli outlier sulle stime dei parametri.\nCompiliamo e stampiamo il modello 3_hierarchical_model.stan.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"change_models\", \"3_hierarchical_model.stan\"\n)\n\nhierarchical_model = CmdStanModel(stan_file=stan_file)\nprint(hierarchical_model.code())\n\ndata {\n  int&lt;lower=0&gt; Ntotal; // Total number of trials in the dataset (600)\n  array[Ntotal] int&lt;lower=1&gt; trial; // Trial number\n  array[Ntotal] real observed_goal; // Goal level for each trial\n  array[Ntotal] real performance; // Performance for each trial\n  int&lt;lower=1&gt; Nsubj; // Number of subjects\n  array[Ntotal] int&lt;lower=1, upper=Nsubj&gt; subject; // Subject number\n}\nparameters {\n  vector[Nsubj] alpha; // Unique alpha parameter for each subject\n  vector[Nsubj] beta; // Unique beta parameter for each subject\n  real&lt;lower=0&gt; sigma; // Single sigma parameter for entire sample\n  real alpha_mean; // Population mean parameter for the alpha distribution\n  real&lt;lower=0&gt; alpha_sd; // Population sd parameter for the alpha distribution\n  real beta_mean; // Population mean parameter for the beta distribution\n  real&lt;lower=0&gt; beta_sd; // Population sd parameter for the beta distribution\n}\nmodel {\n  vector[Ntotal] predicted_goal; // Vector to store predictions\n  \n  // Priors\n  alpha ~ normal(alpha_mean, alpha_sd);\n  beta ~ normal(beta_mean, beta_sd);\n  sigma ~ normal(0, 1);\n  alpha_mean ~ normal(0, 1);\n  alpha_sd ~ normal(0, 1);\n  beta_mean ~ normal(0, 1);\n  beta_sd ~ normal(0, 1);\n  \n  // Likelihood\n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      predicted_goal[i] = predicted_goal[i - 1]\n                          + alpha[subject[i]]\n                            * (performance[i - 1] - predicted_goal[i - 1])\n                          + beta[subject[i]];\n    }\n  }\n  \n  observed_goal ~ normal(predicted_goal, sigma);\n}\ngenerated quantities {\n  vector[Ntotal] predicted_goal;\n  array[Ntotal] real log_lik;\n  \n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      predicted_goal[i] = predicted_goal[i - 1]\n                          + alpha[subject[i]]\n                            * (performance[i - 1] - predicted_goal[i - 1])\n                          + beta[subject[i]];\n    }\n    \n    // Calculate the log likelihood for each observation\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal[i], sigma);\n  }\n}\n\n\n\nNel modello gerarchico, aggiungiamo nuovi parametri per catturare meglio la variabilit√† tra i partecipanti e fare inferenze pi√π robuste sulla popolazione. I parametri alpha_mean e alpha_sd descrivono la distribuzione di alpha a livello di popolazione, mentre beta_mean e beta_sd fanno lo stesso per beta. Questo approccio ci permette di non trattare ogni partecipante isolatamente, ma di considerare anche come i loro parametri individuali si distribuiscono all‚Äôinterno della popolazione.\nI priori in questo modello differiscono dagli altri perch√©, anzich√© essere generici e non informativi, si basano sui parametri a livello di popolazione. Quindi, ogni parametro a livello individuale viene stimato tenendo conto della distribuzione a livello di popolazione, rendendo le stime meno sensibili a dati estremi o anomali. Questo approccio ci fornisce una comprensione pi√π dettagliata e accurata di come i parametri variano sia tra gli individui che nella popolazione complessiva.\nEseguiamo il campionamento.\n\nfit_hierarchical = hierarchical_model.sample(\n    data=stan_data,\n    iter_warmup=5_000,\n    iter_sampling=10_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\nfit_hierarchical_az = az.from_cmdstanpy(posterior=fit_hierarchical)\naz.summary(fit_hierarchical_az, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha[0]\n0.54\n0.14\n0.28\n0.80\n0.0\n0.0\n48765.44\n31528.85\n1.0\n\n\nalpha[1]\n0.38\n0.13\n0.13\n0.63\n0.0\n0.0\n44672.18\n29684.11\n1.0\n\n\nalpha[2]\n0.33\n0.12\n0.10\n0.56\n0.0\n0.0\n30957.20\n30389.86\n1.0\n\n\nalpha[3]\n0.47\n0.15\n0.20\n0.75\n0.0\n0.0\n49280.74\n29994.33\n1.0\n\n\nalpha[4]\n0.36\n0.12\n0.14\n0.58\n0.0\n0.0\n29036.20\n28050.90\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\npredicted_goal[596]\n6.28\n0.30\n5.73\n6.86\n0.0\n0.0\n61708.74\n29589.38\n1.0\n\n\npredicted_goal[597]\n6.87\n0.30\n6.29\n7.43\n0.0\n0.0\n63110.37\n31074.04\n1.0\n\n\npredicted_goal[598]\n6.51\n0.32\n5.91\n7.13\n0.0\n0.0\n58823.98\n28862.76\n1.0\n\n\npredicted_goal[599]\n6.38\n0.33\n5.76\n7.01\n0.0\n0.0\n58004.34\n29837.65\n1.0\n\n\nsigma\n0.90\n0.03\n0.84\n0.95\n0.0\n0.0\n37177.28\n31703.27\n1.0\n\n\n\n\n725 rows √ó 9 columns\n\n\n\n\nEsaminiamo le stime a posteriori di \\(\\alpha\\) e \\(\\beta\\) per ciascun partecipante.\n\n# Extract the alpha parameters only\nalpha_params = fit_hierarchical_az.posterior[\"alpha\"]\n\n# Plot forest plot for alpha parameters\naz.plot_forest(\n    alpha_params,\n    hdi_prob=0.94,  # Set the credible interval to 94%\n    combined=True,  # Combine the chains if there are multiple\n    r_hat=False,  # Display the r_hat values\n    figsize=(10, 6),\n)\n\narray([&lt;Axes: title={'center': '94.0% HDI'}&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\n\n# Extract the alpha parameters only\nbeta_params = fit_hierarchical_az.posterior[\"beta\"]\n\n# Plot forest plot for alpha parameters\naz.plot_forest(\n    beta_params,\n    hdi_prob=0.94,  # Set the credible interval to 94%\n    combined=True,  # Combine the chains if there are multiple\n    r_hat=False,  # Display the r_hat values\n    figsize=(10, 6),\n)\n\narray([&lt;Axes: title={'center': '94.0% HDI'}&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\nSi osserva che gli intervalli credibili dei parametri a livello individuale sono meno dispersi nel modello gerarchico rispetto al modello a livello individuale. Questo avviene perch√©, nel modello gerarchico, la distribuzione a livello di popolazione impone un vincolo aggiuntivo sui parametri a livello individuale, spingendo questi parametri verso la media del gruppo. Questo fenomeno √® noto come ‚Äúshrinkage‚Äù o ‚Äúcontrazione‚Äù.\nOltre ai parametri \\(\\alpha\\) e \\(\\beta\\) per ciascun soggetto, il modello gerarchico stima anche gli iperparametri alpha_mean e beta_mean, oltre a alpha_sd, beta_sd e sigma.\n\n_ = az.plot_posterior(fit_hierarchical, var_names=[\"alpha_mean\", \"beta_mean\"])\n\n\n\n\n\n\n\n\nIl modello gerarchico utilizza alpha_mean e beta_mean per rappresentare le tendenze generali a livello di popolazione. Questi parametri ci danno un‚Äôidea di come, mediamente, i partecipanti aggiornano i loro obiettivi sulla base delle performance passate e indipendentemente da esse.\n\nalpha_mean riflette quanto i partecipanti, in media, siano influenzati dalla differenza tra la performance passata e l‚Äôobiettivo previsto quando aggiornano il loro obiettivo.\nbeta_mean riflette l‚Äôincremento medio fisso che i partecipanti aggiungono al loro obiettivo, indipendentemente da altri fattori.\n\nLa stima di alpha_mean √® 0.49, con un intervallo credibile del 94% che va da 0.42 a 0.55. Questo parametro rappresenta la media della distribuzione di alpha a livello di popolazione. In altre parole, alpha_mean √® il valore medio del parametro alpha considerando tutti i partecipanti del campione. In questo modello, alpha rappresenta la sensibilit√† di ogni partecipante alla differenza tra la performance precedente e l‚Äôobiettivo previsto. Un valore di alpha_mean di 0.49 suggerisce che, mediamente, i partecipanti tendono ad aggiornare il loro obiettivo basandosi per circa il 49% sulla differenza tra la performance precedente e l‚Äôobiettivo precedente. L‚Äôintervallo credibile, che va da 0.42 a 0.55, indica che c‚Äô√® un‚Äôalta probabilit√† che la vera media della popolazione per alpha si trovi in questo range.\nLa stima di beta_mean √® 0.18, con un intervallo credibile del 94% che va da 0.048 a 0.3. beta_mean rappresenta la media della distribuzione di beta a livello di popolazione. In questo contesto, beta indica un incremento additivo costante nell‚Äôobiettivo del partecipante, indipendentemente dalla differenza tra la performance precedente e l‚Äôobiettivo previsto. Un valore di beta_mean di 0.18 suggerisce che, mediamente, i partecipanti tendono ad aumentare il loro obiettivo di un piccolo valore fisso (circa 0.18) in ogni prova, indipendentemente dalle altre variabili. L‚Äôintervallo credibile da 0.048 a 0.3 indica che c‚Äô√® un‚Äôalta probabilit√† che il vero valore medio di beta nella popolazione si trovi in questo intervallo.\nIn sintesi, questi parametri aiutano a comprendere il comportamento generale dei partecipanti rispetto all‚Äôaggiornamento degli obiettivi, catturando sia l‚Äôadattamento dinamico in base alle performance precedenti che un aggiustamento incrementale costante.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#valutazione-e-confronto-di-modelli",
    "href": "chapters/dynamic_models/02_change_across_time.html#valutazione-e-confronto-di-modelli",
    "title": "85¬† Modellare il cambiamento nel tempo",
    "section": "85.6 Valutazione e Confronto di Modelli",
    "text": "85.6 Valutazione e Confronto di Modelli\nUna volta che il ricercatore ha specificato un modello appropriato e verificato che il modello ottiene la convergenza, pu√≤ valutare se il modello descrive adeguatamente i dati. Le stime dei parametri sono interpretabili solo nella misura in cui il modello rappresenta accuratamente il fenomeno che si sta indagando. Se il modello approssima male i dati, le informazioni contenute nelle stime dei parametri potrebbero non essere rappresentative del processo che il ricercatore sta cercando di analizzare. In tali casi, potrebbe essere necessario riformulare il modello per migliorare la sua capacit√† di spiegare le osservazioni empiriche.\n\n# Run diagnostics and print results\ndiagnostic_info = fit_sample.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/1_sample_level_modelh2kv1c5m/1_sample_level_model-20240824092852_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/1_sample_level_modelh2kv1c5m/1_sample_level_model-20240824092852_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/1_sample_level_modelh2kv1c5m/1_sample_level_model-20240824092852_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/1_sample_level_modelh2kv1c5m/1_sample_level_model-20240824092852_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_person.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/2_person_level_model3rm_zhgj/2_person_level_model-20240824085216_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/2_person_level_model3rm_zhgj/2_person_level_model-20240824085216_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/2_person_level_model3rm_zhgj/2_person_level_model-20240824085216_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/2_person_level_model3rm_zhgj/2_person_level_model-20240824085216_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\n11074 of 80000 (13.84%) transitions ended with a divergence.\nThese divergent transitions indicate that HMC is not fully able to explore the posterior distribution.\nTry increasing adapt delta closer to 1.\nIf this doesn't remove all divergences, try to reparameterize the model.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nThe E-BFMI, 0.16, is below the nominal threshold of 0.30 which suggests that HMC may have trouble exploring the target distribution.\nIf possible, try to reparameterize the model.\n\nThe following parameters had fewer than 0.001 effective draws per transition:\n  alpha[22], beta[22], sigma, predicted_goal[212], predicted_goal[213], predicted_goal[214], predicted_goal[215], predicted_goal[216], predicted_goal[217], predicted_goal[218], predicted_goal[219], predicted_goal[220], sampled_goal[212], sampled_goal[213], sampled_goal[214], sampled_goal[215], sampled_goal[216], sampled_goal[217], sampled_goal[218], sampled_goal[219], sampled_goal[220], log_lik[1], log_lik[3], log_lik[10], log_lik[11], log_lik[12], log_lik[14], log_lik[15], log_lik[21], log_lik[22], log_lik[26], log_lik[31], log_lik[35], log_lik[36], log_lik[41], log_lik[42], log_lik[43], log_lik[44], log_lik[51], log_lik[54], log_lik[57], log_lik[61], log_lik[63], log_lik[71], log_lik[72], log_lik[81], log_lik[82], log_lik[88], log_lik[91], log_lik[95], log_lik[100], log_lik[101], log_lik[111], log_lik[113], log_lik[116], log_lik[121], log_lik[129], log_lik[131], log_lik[136], log_lik[137], log_lik[138], log_lik[141], log_lik[144], log_lik[146], log_lik[148], log_lik[149], log_lik[151], log_lik[154], log_lik[155], log_lik[156], log_lik[157], log_lik[161], log_lik[164], log_lik[165], log_lik[171], log_lik[172], log_lik[175], log_lik[176], log_lik[179], log_lik[181], log_lik[182], log_lik[183], log_lik[184], log_lik[185], log_lik[186], log_lik[191], log_lik[201], log_lik[202], log_lik[203], log_lik[207], log_lik[209], log_lik[211], log_lik[212], log_lik[213], log_lik[214], log_lik[215], log_lik[216], log_lik[217], log_lik[218], log_lik[219], log_lik[220], log_lik[221], log_lik[224], log_lik[225], log_lik[226], log_lik[229], log_lik[230], log_lik[231], log_lik[233], log_lik[236], log_lik[241], log_lik[244], log_lik[245], log_lik[247], log_lik[251], log_lik[255], log_lik[256], log_lik[257], log_lik[258], log_lik[259], log_lik[261], log_lik[271], log_lik[272], log_lik[274], log_lik[275], log_lik[278], log_lik[281], log_lik[282], log_lik[287], log_lik[290], log_lik[291], log_lik[292], log_lik[293], log_lik[295], log_lik[297], log_lik[299], log_lik[301], log_lik[302], log_lik[304], log_lik[306], log_lik[309], log_lik[311], log_lik[314], log_lik[321], log_lik[324], log_lik[330], log_lik[331], log_lik[341], log_lik[342], log_lik[347], log_lik[349], log_lik[351], log_lik[354], log_lik[355], log_lik[356], log_lik[361], log_lik[371], log_lik[374], log_lik[375], log_lik[376], log_lik[378], log_lik[381], log_lik[391], log_lik[398], log_lik[400], log_lik[401], log_lik[408], log_lik[409], log_lik[411], log_lik[412], log_lik[418], log_lik[421], log_lik[423], log_lik[425], log_lik[431], log_lik[434], log_lik[441], log_lik[443], log_lik[444], log_lik[445], log_lik[446], log_lik[447], log_lik[448], log_lik[449], log_lik[451], log_lik[452], log_lik[457], log_lik[458], log_lik[461], log_lik[467], log_lik[471], log_lik[473], log_lik[477], log_lik[478], log_lik[481], log_lik[482], log_lik[487], log_lik[488], log_lik[491], log_lik[493], log_lik[501], log_lik[505], log_lik[511], log_lik[514], log_lik[518], log_lik[521], log_lik[522], log_lik[523], log_lik[524], log_lik[531], log_lik[534], log_lik[537], log_lik[538], log_lik[541], log_lik[546], log_lik[547], log_lik[551], log_lik[553], log_lik[555], log_lik[560], log_lik[561], log_lik[564], log_lik[571], log_lik[581], log_lik[588], log_lik[590], log_lik[591], log_lik[594], log_lik[597]\nSuch low values indicate that the effective sample size estimators may be biased high and actual performance may be substantially lower than quoted.\n\nThe following parameters had split R-hat greater than 1.05:\n  alpha[22], beta[22], sigma, predicted_goal[212], predicted_goal[213], predicted_goal[214], predicted_goal[215], predicted_goal[216], predicted_goal[217], predicted_goal[218], predicted_goal[219], predicted_goal[220], sampled_goal[212], sampled_goal[213], sampled_goal[214], sampled_goal[215], sampled_goal[217], sampled_goal[218], sampled_goal[219], sampled_goal[220], log_lik[1], log_lik[11], log_lik[21], log_lik[22], log_lik[26], log_lik[31], log_lik[35], log_lik[41], log_lik[43], log_lik[51], log_lik[61], log_lik[71], log_lik[81], log_lik[82], log_lik[91], log_lik[101], log_lik[111], log_lik[121], log_lik[131], log_lik[141], log_lik[151], log_lik[154], log_lik[155], log_lik[156], log_lik[157], log_lik[161], log_lik[164], log_lik[171], log_lik[181], log_lik[182], log_lik[183], log_lik[185], log_lik[191], log_lik[201], log_lik[202], log_lik[211], log_lik[213], log_lik[214], log_lik[215], log_lik[216], log_lik[217], log_lik[218], log_lik[219], log_lik[220], log_lik[221], log_lik[224], log_lik[231], log_lik[233], log_lik[241], log_lik[251], log_lik[256], log_lik[257], log_lik[258], log_lik[259], log_lik[261], log_lik[271], log_lik[281], log_lik[282], log_lik[291], log_lik[292], log_lik[293], log_lik[295], log_lik[301], log_lik[311], log_lik[314], log_lik[321], log_lik[331], log_lik[341], log_lik[342], log_lik[351], log_lik[354], log_lik[361], log_lik[371], log_lik[381], log_lik[391], log_lik[398], log_lik[400], log_lik[401], log_lik[411], log_lik[421], log_lik[423], log_lik[425], log_lik[431], log_lik[434], log_lik[441], log_lik[444], log_lik[445], log_lik[446], log_lik[447], log_lik[451], log_lik[461], log_lik[471], log_lik[478], log_lik[481], log_lik[482], log_lik[491], log_lik[501], log_lik[511], log_lik[521], log_lik[522], log_lik[523], log_lik[531], log_lik[534], log_lik[541], log_lik[551], log_lik[561], log_lik[571], log_lik[581], log_lik[590], log_lik[591]\nSuch high values indicate incomplete mixing and biased estimation.\nYou should consider regularizating your model with additional prior information or a more effective parameterization.\n\nProcessing complete.\n\n\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_hierarchical.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/3_hierarchical_modelq19mwkng/3_hierarchical_model-20240824085700_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/3_hierarchical_modelq19mwkng/3_hierarchical_model-20240824085700_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/3_hierarchical_modelq19mwkng/3_hierarchical_model-20240824085700_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/3_hierarchical_modelq19mwkng/3_hierarchical_model-20240824085700_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\n27 of 40000 (0.07%) transitions ended with a divergence.\nThese divergent transitions indicate that HMC is not fully able to explore the posterior distribution.\nTry increasing adapt delta closer to 1.\nIf this doesn't remove all divergences, try to reparameterize the model.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete.\n\n\n\nSi noti che sia il modello a livello di persona che il modello gerarchico mostrano dei problemi indicati dalla presenza di transizioni divergenti, anche se il modello gerarchico √® meno problematico di quello basato sulle stime dei coefficienti delle persone soltanto.\nEseguiamo comunque il calcolo dei valori k di Pareto e la validazione incrociata Leave-One-Out (LOO-CV) utilizzando ArviZ.\n\nloo_person_result = az.loo(fit_person_az)\nprint(loo_person_result)\n\nComputed from 80000 posterior samples and 600 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -920.94    57.89\np_loo      201.15        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      543   90.5%\n (0.5, 0.7]   (ok)         39    6.5%\n   (0.7, 1]   (bad)        12    2.0%\n   (1, Inf)   (very bad)    6    1.0%\n\n\n\n\nloo_hierarchical_result = az.loo(fit_hierarchical_az)\nprint(loo_hierarchical_result)\n\nComputed from 40000 posterior samples and 600 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -842.54    36.72\np_loo       95.53        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      583   97.2%\n (0.5, 0.7]   (ok)         13    2.2%\n   (0.7, 1]   (bad)         2    0.3%\n   (1, Inf)   (very bad)    2    0.3%\n\n\n\nC‚Äô√® un piccolo numero di valori di Pareto \\(k\\) problematici, i quali indicando che vi sono delle osservazioni che hanno un‚Äôinfluenza eccessiva sulle stime del modello. Tali problemi andrebbero affrontati prima di calcolare l‚ÄôELPD. Per gli scopi di questo tutorial, tuttavia, procediamo tenendo comunque a mente la possibilit√† che la stima dell‚ÄôELPD possa essere distorta.\nInfine, calcoliamo la differenza tra le stime dell‚ÄôELPD (elpd_diff) dei due modelli. L‚Äôincertezza associata a questa differenza √® espressa dal suo errore standard (dse). Se il rapporto tra elpd_diff e dse √® pari o superiore a 2, possiamo concludere che esiste una differenza credibile tra i due modelli.\n\ndf_comp_loo = az.compare({\n    \"person_model\": loo_person_result, \n    \"hierarchical_model\": loo_hierarchical_result\n})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nhierarchical_model\n0\n-842.541615\n95.525862\n0.000000\n0.907237\n36.718759\n0.000000\nTrue\nlog\n\n\nperson_model\n1\n-920.935304\n201.145350\n78.393688\n0.092763\n57.891756\n43.516941\nTrue\nlog\n\n\n\n\n\n\n\n\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)\n\n\n\n\n\n\n\n\nIl rapporto tra elpd_diff e dse √® leggermente inferiore a 2, il che suggerisce una debole evidenza a favore del modello gerarchico rispetto al modello non gerarchico, basandosi sul confronto dell‚ÄôELPD dei due modelli. Tuttavia, il modello non gerarchico presenta notevoli problemi con i valori di Pareto \\(k\\), portando alla conclusione che, complessivamente, il modello gerarchico sia da preferire.\nPrima di giungere a una conclusione definitiva, ci sarebbero vari problemi da affrontare. Tuttavia, per gli scopi di questo tutorial, non √® necessario entrare nei dettagli, poich√© l‚Äôobiettivo principale √® introdurre un modello dinamico, mostrare come questo modello possa rappresentare le differenze individuali e spiegare perch√© un modello gerarchico possa essere pi√π appropriato rispetto a un modello che stima i parametri dei partecipanti separatamente.\nKnight et al. (2023) approfondiscono ulteriormente la descrizione di questi dati discutendo due ulteriori modelli: un modello che distingue l‚Äôappartenenza a gruppi distinti identificabili in modo esplicito e un modello a mescolanza. A volte, il ricercatore conosce in anticipo il gruppo a cui appartiene ogni partecipante. Tuttavia, ci√≤ non √® sempre il caso. In alcune situazioni, il ricercatore potrebbe voler identificare sottogruppi di partecipanti che mostrano comportamenti simili, senza alcuna conoscenza preliminare dell‚Äôappartenenza ai gruppi. Per fare ci√≤, si pu√≤ utilizzare un modello a mescolanza, un modello che serve a catturare comportamenti risultanti da processi differenti. Ad esempio, potrebbe esserci un sottogruppo di partecipanti che si comporta secondo un processo e un altro sottogruppo il cui comportamento √® governato da un processo diverso. Questi diversi processi sono definiti ‚Äúmescolanze‚Äù. L‚Äôobiettivo dell‚Äôanalisi √® determinare i parametri che meglio caratterizzano ciascuna mescolanza e fare inferenze sull‚Äôinfluenza relativa di ciascuna mescolanza sul comportamento di ogni partecipante.\nAnche se questi modelli migliorano la descrizione dei dati di questo campione, per gli scopi del presente tutorial non sono necessari.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#riflessioni-conclusive",
    "href": "chapters/dynamic_models/02_change_across_time.html#riflessioni-conclusive",
    "title": "85¬† Modellare il cambiamento nel tempo",
    "section": "85.7 Riflessioni Conclusive",
    "text": "85.7 Riflessioni Conclusive\nLe teorie dinamiche, pur essendo influenti in psicologia, sono spesso difficili da verificare. Testare una teoria dinamica richiede un modello statistico che rifletta accuratamente i processi descritti dalla teoria stessa. In questo capitolo, seguendo il tutorial di Knight et al. (2023), abbiamo esaminato un approccio bayesiano alla modellizzazione dei processi dinamici. Per illustrare questa flessibilit√†, Knight et al. (2023) considerano un modello di revisione degli obiettivi pubblicato da Gee, Neal, e Vancouver (2018). Una caratteristica importante di questo modello, comune a molte teorie dinamiche, √® l‚Äôassunzione che alcune variabili abbiano una sorta di ‚Äúmemoria‚Äù. La capacit√† di rappresentare variabili dinamiche come queste √® fondamentale per testare teorie che presumono processi di feedback ricorsivi, tipici di molte teorie influenti.\nL‚Äôapproccio bayesiano affronta questo problema e offre un modo intuitivo per implementare modelli complessi di processi dinamici. In questo capitolo abbiamo iniziato con un modello a livello di campione, che quantifica l‚Äôincertezza nei valori medi dei parametri del modello di revisione degli obiettivi per tutti i partecipanti. Successivamente, abbiamo mostrato come estendere questo framework per creare modelli pi√π sofisticati che catturano la variabilit√† tra individui e gruppi. Il modello a livello individuale quantifica i componenti del processo di revisione degli obiettivi separatamente per ogni individuo. Infine, il modello gerarchico combina i modelli a livello di campione e a livello individuale in un unico framework, consentendo di quantificare i componenti separatamente per ogni individuo e di fare inferenze a livello di popolazione.\nKnight et al. (2023) discutono altri modelli qui non considerati, come il modello a gruppi multipli, che quantifica le differenze nei componenti del processo tra gruppi noti (ad esempio, diversi livelli di una manipolazione sperimentale) e il modello a mescolanza, che consente al ricercatore di identificare sottogruppi latenti di partecipanti per i quali il processo dinamico si svolge in modo simile.\nI modelli che abbiamo introdotto in questo capitolo rappresentano solo una piccola parte della vasta gamma di modelli che possono essere implementati utilizzando questo framework. La flessibilit√† di questo approccio permette di creare modelli con praticamente qualsiasi forma funzionale, offrendo ai ricercatori la possibilit√† di sviluppare modelli personalizzati che rappresentano pi√π accuratamente la teoria che si sta testando rispetto ai modelli generici disponibili.\nIn conclusione, le teorie dinamiche, comuni in psicologia, possono essere difficili da testare perch√© i processi che le sottendono sono spesso troppo complessi per essere adeguatamente rappresentati nei modelli statistici tradizionali. L‚Äôapproccio bayesiano che Knight et al. (2023) illustrano nel loro tutorial consente di superare queste sfide, offrendo un modo flessibile per sviluppare, testare e confrontare modelli dinamici. Questo approccio offre ai ricercatori la possibilit√† di rappresentare meglio fenomeni dinamici o gerarchici, in cui i processi possono variare nel tempo, a diversi livelli e in diversi contesti e per diverse persone.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/02_change_across_time.html#informazioni-sullambiente-di-sviluppo",
    "title": "85¬† Modellare il cambiamento nel tempo",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sat Jul 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\npingouin  : 0.5.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGee, Phillip, Andrew Neal, e Jeffrey B Vancouver. 2018. ¬´A formal model of goal revision in approach and avoidance contexts¬ª. Organizational Behavior and Human Decision Processes 146: 51‚Äì61.\n\n\nKnight, Emma, Andrew Neal, Hector Palada, e Timothy Ballard. 2023. ¬´A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups¬ª. Computational Brain & Behavior 6 (4): 697‚Äì718.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>85</span>¬† <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "",
    "text": "Introduzione\nNel Capitolo 85 abbiamo introdotto l‚Äôapproccio bayesiano per descrivere i processi dinamici. In questo capitolo, presenteremo un altro esempio di questo approccio implementando uno dei modelli psicologici dinamici pi√π influenti: il modello di apprendimento di Rescorla-Wagner. Dopo una breve introduzione storica, esamineremo la definizione del modello, il significato dei suoi parametri e i metodi per stimarli dai dati osservati, con un focus particolare sull‚Äôuso del linguaggio di programmazione probabilistica Stan.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#apprendimento-per-rinforzo",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#apprendimento-per-rinforzo",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.1 Apprendimento per Rinforzo",
    "text": "86.1 Apprendimento per Rinforzo\nNegli anni ‚Äô50, uno dei concetti fondamentali nell‚Äôintelligenza artificiale (AI) era quello dell‚Äôapprendimento per rinforzo, che sosteneva l‚Äôimportanza di incoraggiare le azioni che avevano avuto successo in passato. Questo approccio ha portato allo sviluppo di algoritmi avanzati per il gioco. Nei decenni successivi, l‚Äôapprendimento per rinforzo ha visto un‚Äôevoluzione significativa, applicandosi con successo a giochi complessi come il Go e al controllo di sistemi robotici altamente sofisticati.\nUn aspetto centrale dell‚Äôapprendimento per rinforzo √® la capacit√† di bilanciare l‚Äôacquisizione di conoscenza sull‚Äôambiente con l‚Äôazione all‚Äôinterno di esso. Questo equilibrio rappresenta una sfida complessa, anche in situazioni in cui le azioni non comportano un cambiamento nell‚Äôambiente stesso. Nel contesto del machine learning, il processo di esplorazione, ovvero compiere un‚Äôazione e osservarne l‚Äôeffetto, √® fondamentale per apprendere. Tuttavia, l‚Äôesplorazione comporta il rischio di non sfruttare un‚Äôazione che gi√† si conosce come vantaggiosa. Esiste quindi un inevitabile compromesso tra l‚Äôesplorazione di nuove opzioni e lo sfruttamento di quelle gi√† note.\nQuesto concetto di apprendimento basato sul bilanciamento tra esplorazione e sfruttamento trova un‚Äôinteressante applicazione anche nel campo della psicologia, in particolare attraverso il modello di Rescorla-Wagner. Sviluppato negli anni ‚Äô70 da Robert Rescorla e Allan Wagner, questo modello √® ampiamente utilizzato per spiegare come animali e esseri umani apprendano le associazioni tra stimoli e conseguenze delle azioni (Rescorla e Wagner 1972). Questo modello √® alla base di molti approcci pi√π recenti nell‚Äôapprendimento per rinforzo e nelle neuroscienze computazionali.\nIl modello di Rescorla-Wagner si basa sull‚Äôidea che l‚Äôapprendimento avvenga in funzione della discrepanza tra ci√≤ che un individuo si aspetta e ci√≤ che effettivamente accade. In altre parole, l‚Äôapprendimento √® guidato dall‚Äôerrore di previsione: quando l‚Äôesito di una situazione differisce da ci√≤ che ci si aspettava, le associazioni mentali tra gli eventi coinvolti vengono aggiornate. Il modello suggerisce che la forza dell‚Äôapprendimento dipende dall‚Äôintensit√† della sorpresa generata dall‚Äôesito osservato.\nPer esempio, immagina di partecipare a un esperimento in cui, ogni volta che compi una specifica azione, si verifica un evento che ti sorprende. All‚Äôinizio, non ti aspetti che quell‚Äôevento segua l‚Äôazione, quindi apprendi rapidamente l‚Äôassociazione tra l‚Äôazione e l‚Äôevento. Con il tempo, man mano che ti abitui a questa sequenza, l‚Äôapprendimento rallenta, perch√© diventi pi√π bravo a prevedere l‚Äôesito e la sorpresa diminuisce.\nQuesto modello ha avuto un impatto significativo nello studio dell‚Äôapprendimento e continua a essere un punto di riferimento per comprendere i meccanismi attraverso i quali formiamo associazioni basate sulle nostre esperienze.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#concetti-fondamentali",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#concetti-fondamentali",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.2 Concetti Fondamentali",
    "text": "86.2 Concetti Fondamentali\nConsideriamo ora la specifica terminologia utilizzata nella letteratura sull‚Äôapprendimento associativo.\nNell‚Äôapprendimento per rinforzo, si immagina un ‚Äúagente‚Äù che interagisce con un ‚Äúambiente‚Äù, simile a un giocatore che esplora un nuovo videogioco. L‚Äôagente compie una serie di azioni per imparare quali siano le migliori per ottenere il massimo punteggio o ‚Äúricompensa‚Äù. Questo processo avviene in diversi turni, durante i quali l‚Äôagente fa delle scelte e riceve feedback sotto forma di ricompense (Sutton e Barto 2018).\nAd ogni turno, l‚Äôagente seleziona un‚Äôazione tra quelle disponibili. Nel caso pi√π semplice, potrebbe avere solo due opzioni, come scegliere tra due porte in un gioco. Dopo aver fatto la sua scelta, l‚Äôagente riceve una ricompensa, che pu√≤ essere positiva o negativa. Per comprendere meglio questo concetto, possiamo pensare a uno psicologo che cerca il miglior trattamento per un paziente. In questo scenario, ogni ‚Äúazione‚Äù rappresenterebbe un diverso approccio terapeutico, e la ‚Äúricompensa‚Äù sarebbe il miglioramento del benessere del paziente.\n√à importante notare che le ricompense sono stocastiche, ovvero, non sono sempre le stesse per una data azione, ma sono probabilistiche. Le ricompense vengono generate indipendentemente secondo la distribuzione \\(r_t \\sim M^\\star(\\cdot | \\pi_t)\\), dove \\(M^\\star(\\cdot | \\cdot)\\) √® il modello sottostante.\nDefiniamo \\(f(\\pi) := \\mathbb{E}[r | \\pi]\\) come la funzione di ricompensa media sotto \\(r \\sim M^\\star(\\cdot | \\pi)\\). Ad esempio, l‚Äôazione A potrebbe essere associata a una probabilit√† di ricompensa positiva dell‚Äô80% e a una probabilit√† di ricompensa negativa del 20%. Questa probabilit√† pu√≤ rimanere costante nel corso dei tentativi, oppure variare nel tempo.\nNel contesto dell‚Äôapprendimento per rinforzo, definiamo la ‚Äústoria‚Äù \\(\\mathcal{H}^t\\) come la sequenza delle scelte e delle ricompense ottenute fino al momento t. Matematicamente, la rappresentiamo come \\(\\mathcal{H}^t = (\\pi^1, r^1), \\ldots, (\\pi^t, r^t)\\). Questa storia √® essenzialmente l‚Äôelenco delle scelte fatte e delle ricompense ottenute fino a quel momento, fornendo un quadro completo del percorso di apprendimento dell‚Äôagente.\nL‚Äôobiettivo principale dell‚Äôagente √® trovare l‚Äôazione che, in media, d√† la ricompensa migliore. Per valutare l‚Äôefficacia dell‚Äôapprendimento dell‚Äôagente, si utilizza il concetto di ‚Äúregret‚Äù. Il regret misura quanto l‚Äôagente sta perdendo rispetto a quello che avrebbe potuto ottenere se avesse sempre scelto l‚Äôazione migliore.\nMatematicamente, il regret (\\(\\text{Reg}\\)) viene calcolato come la differenza cumulativa tra la ricompensa massima possibile (ottenuta scegliendo sempre l‚Äôopzione migliore) e la ricompensa effettivamente ottenuta seguendo le nostre scelte:\n\\[\n\\text{Reg} := \\sum_{t=1}^{T} f^\\star(\\pi^\\star) - \\sum_{t=1}^{T} \\mathbb{E}[f(\\pi^t)].\n\\]\nIn questa formula, \\(f^\\star(\\pi^\\star)\\) rappresenta la ricompensa media massima ottenibile scegliendo la politica ottimale \\(\\pi^\\star\\), cio√® quella che massimizza la ricompensa media. Ad esempio, se \\(f^\\star(A) = 0.75\\) e \\(f^\\star(B) = 0.25\\), il simbolo \\(\\pi^\\star\\) rappresenta la scelta che massimizza la ricompensa media, in questo caso l‚Äôazione A, che ha la probabilit√† pi√π alta di ricompensa (0.75).\nIl termine ‚Äúpolitica‚Äù (\\(\\pi\\)) √® un concetto cruciale che rappresenta una strategia o una regola che ci guida nella scelta in ciascuna prova. Ad esempio, una politica potrebbe essere scegliere sempre A, scegliere sempre B, o basarsi su una regola specifica determinata dalle informazioni disponibili.\nUn approccio semplice ma spesso inefficace √® la strategia ‚Äúgreedy‚Äù. Questa strategia sceglie sempre l‚Äôazione che finora sembra la migliore, basandosi solo sulle esperienze passate. √à come se un giocatore, dopo aver trovato un buon posto dove raccogliere monete in un gioco, continuasse a tornare sempre l√¨ senza mai esplorare il resto del livello. Il problema di questa strategia √® che l‚Äôagente potrebbe rimanere ‚Äúbloccato‚Äù su un‚Äôazione che sembra buona, ma non √® la migliore in assoluto. Potrebbe esserci un‚Äôazione ancora migliore che non √® stata provata abbastanza.\nPer superare questo limite, gli algoritmi pi√π avanzati cercano di bilanciare due aspetti fondamentali: l‚Äôesplorazione e lo sfruttamento. L‚Äôesplorazione consiste nel provare azioni nuove o poco testate per scoprire se sono migliori, mentre lo sfruttamento si concentra sullo scegliere le azioni che finora hanno dato i risultati migliori. Questo dilemma tra esplorazione e sfruttamento √® centrale nell‚Äôapprendimento per rinforzo. Possiamo paragonarlo alla scelta tra ordinare sempre il nostro piatto preferito al ristorante (sfruttamento) o provare qualcosa di nuovo dal menu (esplorazione).\nSono stati proposti diversi algoritmi che possono essere usati per trovare un equilibrio tra esplorazione e sfruttamento.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#modello-di-rescorla-wagner",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#modello-di-rescorla-wagner",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.3 Modello di Rescorla-Wagner",
    "text": "86.3 Modello di Rescorla-Wagner\nIl modello di Rescorla-Wagner propone che le scelte siano basate su ‚ÄòQ-values‚Äô, che approssimano la ricompensa attesa associata a ciascuna azione. Questi valori sono tipicamente calcolati applicando ripetutamente una regola di apprendimento incrementale che confronta l‚Äôesito effettivo con la sua stima precedente.\nNel modello, l‚Äôaspettativa di valore (cio√® la ricompensa attesa) per un‚Äôazione scelta viene aggiornata secondo la seguente formula:\n\\[ \\Delta Q = \\alpha (R - Q), \\]\ndove:\n\n\\(\\Delta Q\\) rappresenta la variazione del valore atteso,\n\\(\\alpha\\) √® il tasso di apprendimento (un valore tra 0 e 1),\n\\(R\\) √® la ricompensa effettivamente ottenuta,\n\\(Q\\) √® il valore atteso attuale.\n\nIl parametro \\(\\alpha\\) (alpha) rappresenta il tasso di apprendimento ed √® un valore compreso tra 0 e 1. Questo parametro determina quanto rapidamente il modello aggiorna le sue stime in risposta a nuove informazioni. Un valore di \\(\\alpha\\) pi√π alto (vicino a 1) indica un apprendimento pi√π rapido, dove le nuove informazioni hanno un impatto maggiore sull‚Äôaggiornamento del valore Q. Al contrario, un valore di \\(\\alpha\\) pi√π basso (vicino a 0) indica un apprendimento pi√π lento, dove le nuove informazioni hanno un impatto minore e il modello si basa maggiormente sulle stime precedenti. La scelta del valore ottimale di \\(\\alpha\\) dipende spesso dal contesto specifico e dalla natura del problema di apprendimento.\nLa nuova aspettativa di valore \\(Q\\) viene quindi aggiornata come segue:\n\\[ Q(t+1) = Q(t) + \\Delta Q. \\]\nSostituendo \\(\\Delta Q\\) nella formula, otteniamo:\n\\[ Q(t+1) = Q(t) + \\alpha (R - Q(t)). \\]\nIl funzionamento del modello pu√≤ essere descritto nel modo seguente:\n\nL‚Äôagente ha un‚Äôaspettativa iniziale \\(Q(t)\\) riguardo alla ricompensa associata a uno stimolo o a un‚Äôazione.\nL‚Äôagente sperimenta lo stimolo o compie l‚Äôazione, ricevendo una ricompensa effettiva \\(R\\).\nLa differenza tra la ricompensa attesa e quella ottenuta \\((R - Q(t))\\) costituisce l‚Äôerrore di previsione.\nQuesto errore viene moltiplicato per il tasso di apprendimento \\(\\alpha\\) per determinare l‚Äôaggiornamento dell‚Äôaspettativa \\(\\Delta Q\\).\nL‚Äôaspettativa di valore per il prossimo turno viene aggiornata secondo la formula \\(Q(t+1) = Q(t) + \\alpha (R - Q(t))\\).\n\nIn parole semplici, il modello Rescorla-Wagner descrive come le aspettative di ricompensa vengono aggiornate sulla base dell‚Äôerrore di previsione. Se la ricompensa ottenuta \\(R\\) √® maggiore del valore previsto \\(Q(t)\\), il valore dell‚Äôazione \\(Q(t)\\) aumenta. Se la ricompensa √® minore del previsto, il valore dell‚Äôazione diminuisce. La velocit√† con cui questi aggiornamenti avvengono √® regolata dal tasso di apprendimento \\(\\alpha\\).\n\n86.3.1 Bilanciare Sfruttamento ed Esplorazione con la Regola Softmax\nIl modello di Rescorla-Wagner di per s√© non crea un equilibrio diretto tra sfruttamento ed esplorazione. Per bilanciare questi due aspetti, √® possibile integrare il modello con una regola di selezione delle azioni, come la regola softmax.\nLa formula della regola softmax √®:\n\\[ P(\\pi_k) = \\frac{e^{Q_k(t) / \\tau}}{\\sum_{j} e^{Q_j(t) / \\tau}}, \\]\ndove:\n\n\\(P(\\pi_k)\\) √® la probabilit√† di scegliere l‚Äôazione \\(k\\),\n\\(Q_k(t)\\) √® il valore atteso dell‚Äôazione \\(k\\) al tempo \\(t\\),\n\\(\\tau\\) √® il parametro di temperatura che controlla il grado di esplorazione (un valore alto di \\(\\tau\\) porta a una maggiore esplorazione, mentre un valore basso favorisce lo sfruttamento).\n\nL‚Äôntegrazione del Modello di Rescorla-Wagner con la Regola Softmax avviene nel modo seguente.\n\nDopo ogni turno, aggiornare le aspettative di valore \\(Q_k(t)\\) per tutte le azioni \\(k\\) utilizzando il modello di Rescorla-Wagner.\nCalcolare le probabilit√† di selezione per ciascuna azione utilizzando la regola softmax.\nScegliere un‚Äôazione \\(\\pi_k\\) in modo probabilistico in base alle probabilit√† \\(P(\\pi_k)\\).\n\nIn sintesi, il modello di Rescorla-Wagner viene utilizzato per aggiornare le aspettative di valore basate sull‚Äôerrore di previsione, mentre la regola softmax bilancia esplorazione e sfruttamento selezionando le azioni in modo probabilistico. Questa integrazione permette di migliorare l‚Äôapprendimento dell‚Äôagente attraverso un processo iterativo e adattivo.\nNonostante la sua ampia applicabilit√† e influenza, √® importante riconoscere che il modello di Rescorla-Wagner ha alcune limitazioni. Ad esempio, non √® in grado di spiegare alcuni fenomeni pi√π complessi dell‚Äôapprendimento associativo, come il blocco retrospettivo o l‚Äôapprendimento latente.\nIl blocco retrospettivo √® un fenomeno in cui l‚Äôapprendimento di un‚Äôassociazione tra uno stimolo e una conseguenza pu√≤ essere inibito retrospettivamente dall‚Äôintroduzione di un nuovo stimolo predittivo. In altre parole, se un agente ha gi√† appreso che uno stimolo A predice una ricompensa, e successivamente gli viene presentato uno stimolo composto AB seguito dalla stessa ricompensa, l‚Äôagente potrebbe non imparare l‚Äôassociazione tra B e la ricompensa, anche se B √® in realt√† un predittore altrettanto valido.\nL‚Äôapprendimento latente, d‚Äôaltra parte, si riferisce all‚Äôacquisizione di conoscenze che non si manifestano immediatamente nel comportamento, ma possono emergere in un secondo momento quando diventano rilevanti. Un esempio classico √® quello di agenti che esplorano un labirinto senza ricompense: sembrano non imparare nulla, ma quando viene introdotta una ricompensa, mostrano rapidamente di aver gi√† appreso la struttura del labirinto.\nIl modello di Rescorla-Wagner, basandosi esclusivamente sull‚Äôerrore di previsione immediato, non riesce a catturare questi fenomeni pi√π sottili dell‚Äôapprendimento. Modelli pi√π recenti hanno cercato di superare queste limitazioni, pur mantenendo la semplicit√† e l‚Äôeleganza del modello originale.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#algoritmi-upper-confidence-bound-ucb-e-thompson-sampling",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#algoritmi-upper-confidence-bound-ucb-e-thompson-sampling",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.4 Algoritmi Upper Confidence Bound (UCB) e Thompson Sampling",
    "text": "86.4 Algoritmi Upper Confidence Bound (UCB) e Thompson Sampling\nGli algoritmi UCB e Thompson Sampling sono maggiormente utilizzati nel campo dell‚Äôintelligenza artificiale.\n\n86.4.1 Upper Confidence Bound (UCB)\nL‚Äôalgoritmo UCB (Upper Confidence Bound) bilancia esplorazione e sfruttamento per scegliere le azioni migliori in un contesto di apprendimento per rinforzo. Per ogni azione \\(\\pi\\), l‚Äôalgoritmo UCB calcola un valore chiamato ‚Äúlimite superiore di confidenza‚Äù che tiene conto sia della ricompensa stimata sia dell‚Äôincertezza di tale stima. La formula √®:\n\\[ \\text{UCB}(\\pi) = \\hat{r}(\\pi) + \\sqrt{\\frac{2 \\log t}{n(\\pi)}} \\]\ndove:\n\n\\(\\hat{r}(\\pi)\\) √® la ricompensa stimata per l‚Äôazione \\(\\pi\\).\n\\(t\\) √® il turno corrente.\n\\(n(\\pi)\\) √® il numero di volte che l‚Äôazione \\(\\pi\\) √® stata scelta.\n\nIl termine \\(\\sqrt{\\frac{2 \\log t}{n(\\pi)}}\\) rappresenta l‚Äôincertezza della stima. Pi√π un‚Äôazione viene scelta, pi√π diminuisce l‚Äôincertezza, e quindi il termine di esplorazione si riduce.\nL‚Äôalgoritmo seleziona l‚Äôazione con il valore UCB pi√π alto. Questo approccio permette di esplorare nuove azioni ma anche di sfruttare quelle che sembrano offrire le migliori ricompense, garantendo un buon equilibrio tra esplorazione e sfruttamento.\n\n\n86.4.2 Thompson Sampling\nL‚Äôalgoritmo Thompson Sampling bilancia esplorazione e sfruttamento scegliendo probabilisticamente le azioni in base alla loro probabilit√† di essere ottimali. Per ogni azione \\(\\pi\\), una ricompensa viene campionata dalla distribuzione a posteriori della sua ricompensa attesa. L‚Äôazione con il valore campionato pi√π alto viene scelta. Questo approccio bilancia efficacemente esplorazione (provando azioni meno certe) e sfruttamento (scegliendo l‚Äôazione che attualmente sembra la migliore).",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#contextual-bandits",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#contextual-bandits",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.5 Contextual Bandits",
    "text": "86.5 Contextual Bandits\nI contextual bandits rappresentano un‚Äôevoluzione rispetto ai tradizionali problemi multi-armed bandit, offrendo un framework pi√π realistico per il processo decisionale interattivo in scenari complessi. Mentre i multi-armed bandits si concentrano sulla scelta ripetuta tra diverse opzioni fisse, i contextual bandits introducono un nuovo elemento: il contesto. In questo scenario, prima di prendere una decisione, l‚Äôagente osserva informazioni contestuali che possono influenzare la scelta ottimale.\n\n86.5.1 Il Protocollo dei Contextual Bandits\nIl processo decisionale nei contextual bandits si svolge come segue:\n\nL‚Äôagente osserva un contesto \\(x_t\\) (ad esempio, le caratteristiche di una situazione sociale per una persona con anoressia nervosa).\nBasandosi su questo contesto, l‚Äôagente seleziona un‚Äôazione \\(\\pi_t\\) (ad esempio, la scelta di mangiare o meno in quella situazione).\nL‚Äôagente riceve una ricompensa \\(r_t\\) (ad esempio, il livello di ansia o controllo percepito dopo la scelta).\n\nQuesto processo si ripete per \\(T\\) turni.\n\n\n86.5.2 Modello Matematico\n\nLe ricompense sono generate secondo una distribuzione condizionale \\(r_t \\sim \\mathcal{M}^*(\\cdot | x_t, \\pi_t)\\), il che significa che la ricompensa \\(r_t\\) √® distribuita secondo una certa legge \\(\\mathcal{M}^*\\) che varia a seconda del contesto e dell‚Äôazione.\nLa funzione di ricompensa media \\(f^*(x, \\pi)\\) rappresenta il valore atteso della ricompensa data un certo contesto \\(x\\) e una certa azione \\(\\pi\\).\nLa politica ottimale \\(\\pi^*(x) = \\arg\\max_{\\pi} f^*(x, \\pi)\\) indica che, per ogni contesto \\(x\\), cerchiamo l‚Äôazione \\(\\pi\\) che d√† la ricompensa media pi√π alta.\n\nL‚Äôobiettivo di un agente che utilizza contextual bandits √® minimizzare il ‚Äúregret‚Äù. Il ‚Äúregret‚Äù √® la differenza tra la ricompensa che avremmo ottenuto se avessimo sempre scelto l‚Äôazione ottimale e la ricompensa che abbiamo effettivamente ottenuto.\n\n\n86.5.3 Esempio: Anoressia Nervosa\nConsideriamo un esempio legato all‚Äôanoressia nervosa (AN). L‚Äôapproccio dei contextual bandits pu√≤ spiegare perch√© le persone affette da AN mostrano un apprendimento per rinforzo (RL) compromesso in contesti legati al cibo e al corpo, mentre mostrano un RL adeguato in contesti non legati al cibo e al corpo.\nImmaginiamo due scenari distinti:\nScenario 1: Contesto legato al cibo\n\nContesto (\\(x_t\\)): Una persona con AN si trova a una cena con amici dove √® presente una variet√† di cibi.\nAzione (\\(\\pi_t\\)): La persona deve decidere se mangiare un certo cibo.\nRicompensa (\\(r_t\\)): La ricompensa potrebbe essere misurata in termini di ansia percepita, con alti livelli di ansia che indicano una bassa ricompensa.\n\nIn questo contesto, la persona con AN potrebbe avere una funzione di ricompensa media \\(f^*(x, \\pi)\\) che penalizza fortemente le azioni legate al consumo di cibo, a causa delle elevate preoccupazioni legate al peso e all‚Äôimmagine corporea. Di conseguenza, l‚Äôapprendimento per rinforzo sar√† compromesso perch√© la ricompensa attesa per le azioni legate al cibo √® molto bassa.\nScenario 2: Contesto non legato al cibo\n\nContesto (\\(x_t\\)): La stessa persona con AN si trova in una situazione di lavoro dove deve decidere come completare un compito.\nAzione (\\(\\pi_t\\)): La persona deve decidere quale strategia usare per completare il compito.\nRicompensa (\\(r_t\\)): La ricompensa potrebbe essere misurata in termini di successo o soddisfazione per il compito completato, con alti livelli di successo che indicano una alta ricompensa.\n\nIn questo contesto, la funzione di ricompensa media \\(f^*(x, \\pi)\\) non √® influenzata dalle preoccupazioni legate al cibo o al corpo. Pertanto, la persona con AN pu√≤ imparare efficacemente quale azione porta alla ricompensa massima, mostrando un apprendimento per rinforzo adeguato.\nQuesto esempio mostra come i contextual bandits possano spiegare le differenze nell‚Äôapprendimento per rinforzo in base al contesto, fornendo un quadro pi√π completo e realistico delle dinamiche decisionali nelle persone con anoressia nervosa.\nIn sintesi, i contextual bandits sono un framework di RL che considera il contesto (o stato) quando si sceglie un‚Äôazione, ma non considera gli effetti a lungo termine delle azioni o come le azioni influenzano gli stati futuri.\n\n\n86.5.4 Rigidit√† Cognitiva e Difficolt√† di RL nell‚ÄôAnoressia Nervosa\nLa rigidit√† cognitiva nelle decisioni legate a cibo e corpo pu√≤ essere spiegata in termini di RL come segue:\n\nSovrastima delle ricompense immediate: Le azioni che portano a sensazioni di controllo o riduzione dell‚Äôansia a breve termine (es. restrizione calorica) ricevono un ‚Äúpeso‚Äù eccessivo nel processo decisionale.\nSottostima delle ricompense a lungo termine: Le conseguenze positive di un‚Äôalimentazione sana o di un‚Äôimmagine corporea pi√π realistica vengono sottovalutate o ignorate.\nEsplorazione limitata: La persona potrebbe evitare di esplorare nuove azioni (es. mangiare cibi temuti) a causa dell‚Äôansia associata, limitando cos√¨ l‚Äôapprendimento.\nAggiornamento selettivo del modello: Nel caso di apprendimento model-based, la persona potrebbe aggiornare selettivamente il suo modello interno, dando pi√π peso alle informazioni che confermano le sue convinzioni sulla necessit√† di controllo sul cibo e sul corpo.\n\n\n\n86.5.5 Contextual Bandits nel Contesto dell‚ÄôAnoressia Nervosa\nUtilizzando il framework dei contextual bandits, possiamo vedere come una persona con anoressia possa mostrare un apprendimento per rinforzo adeguato in alcuni contesti, ma un apprendimento per rinforzo alterato e rigido in situazioni legate al cibo e al corpo. In contesti legati al cibo, l‚Äôansia e la preoccupazione per il controllo del peso e dell‚Äôimmagine corporea influenzano negativamente la percezione delle ricompense, portando a decisioni che evitano il cibo e rafforzano comportamenti dannosi.\nAl contrario, in contesti non legati al cibo, dove queste preoccupazioni non sono presenti, la persona con anoressia pu√≤ fare scelte basate su un‚Äôanalisi pi√π razionale delle ricompense, mostrando un apprendimento per rinforzo normale. Questo dualismo nell‚Äôapprendimento decisionale evidenzia come il contesto giochi un ruolo cruciale nelle scelte di una persona con anoressia, spiegando perch√© possa avere una rigida resistenza al cambiamento in situazioni legate al cibo e al corpo, ma decisioni pi√π flessibili e adeguate in altri ambiti della vita.\nQuesta prospettiva aiuta a spiegare perch√© le persone con anoressia possono mostrare capacit√† decisionali normali in molti ambiti della vita, ma una marcata rigidit√† e resistenza al cambiamento quando si tratta di decisioni legate all‚Äôalimentazione e all‚Äôimmagine corporea.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#simulare-lapprendimento",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#simulare-lapprendimento",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.6 Simulare l‚ÄôApprendimento",
    "text": "86.6 Simulare l‚ÄôApprendimento\nI modelli precedenti sono spesso chiamati semplicemente ‚Äòmodelli RL‚Äô e costituiscono la base di molti studi sulla psicologia e neuroscienza dell‚Äôapprendimento guidato dalla ricompensa. In questo tutorial, simuleremo il processo decisionale di un partecipante che sceglie tra due slot machine, utilizzando il modello di apprendimento di Rescorla-Wagner. Questa simulazione ci aiuter√† a comprendere come le persone apprendono e prendono decisioni in situazioni di incertezza.\nConfigurazione della simulazione:\n\nNumero di tentativi: \\(T = 100\\). Significa che il partecipante far√† 100 scelte consecutive.\nNumero di slot machine: \\(K = 2\\). Il partecipante sceglier√† tra due slot machine ad ogni tentativo.\nProbabilit√† di ricompensa: \\(\\mu = [0.2, 0.8]\\). Ci√≤ significa che la Slot machine 1 ha yna probabilit√† pari a 0.2 di offrire una ricompensa, mentre la Slot machine 2 ha una probabilit√† pari a 0.8 di offrire una ricompensa.\n\nAttraverso questa simulazione, osserveremo come il partecipante inizialmente esplora entrambe le opzioni, come gradualmente apprende quale slot machine offre ricompense pi√π frequenti e come adatta le proprie scelte per massimizzare le vincite complessive.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#esempio-di-calcolo-della-softmax",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#esempio-di-calcolo-della-softmax",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.7 Esempio di Calcolo della Softmax",
    "text": "86.7 Esempio di Calcolo della Softmax\nPer capire come funziona la softmax, consideriamo due valori di \\(Q\\) (aspettativa di ricompensa) e un valore fisso di \\(\\theta\\).\nLa funzione softmax trasforma i valori \\(Q\\) e \\(\\theta\\) in una distribuzione di probabilit√†, mostrando come la probabilit√† di scelta cambia al variare di \\(\\theta\\).\n\ndef softmax(Q, theta):\n    p = np.exp(theta * Q) / np.sum(np.exp(theta * Q))\n    return p\n\nConsideriamo una situazione in cui la seconda scelta ha un‚Äôaspettativa di valore tre volte maggiore la prima.\n\nQ = np.array([0.25, 0.75])\n\nEsaminiamo il caso di un valore \\(\\theta\\) alto.\n\ntheta = 3.5\n\n\nprint(softmax(Q, theta))\n\n[0.1480472 0.8519528]\n\n\nIn tali circostanze, la probabilit√† di scegliere la seconda azione √® quasi sei volte maggiore quella di scegliere la prima azione.\n\n0.8519528 / 0.1480472\n\n5.754602586202238\n\n\nConsideriamo ora il caso in cui il valore \\(\\theta\\) √® basso.\n\ntheta = 0.5\nprint(softmax(Q, theta))\n\n[0.4378235 0.5621765]\n\n\nIn tali circostanze, la probabilit√† di scegliere la seconda azione √® appena maggiore di quella di scegliere la prima azione. Quando \\(\\theta\\) √® zero, la probabilit√† di scegliere una delle due azioni √® 0.5, indipendentemente dall‚Äôaspettativa di ricompensa delle due azioni.\n\ntheta = 0.0\nprint(softmax(Q, theta))\n\n[0.5 0.5]\n\n\nOra manteniamo fisso il valore di \\(Q\\) e facciamo variare \\(\\theta\\).\n\nQ = np.array([0.25, 0.75])\ntheta_values = np.linspace(0, 5, 100)\n\nprobabilities_list = []\nfor theta in theta_values:\n    probabilities = softmax(Q, theta)\n    probabilities_list.append(probabilities)\n\nprobabilities_array = np.array(probabilities_list).T\n\noption_labels = ['Opzione 1: Q = 0.25', 'Opzione 2: Q = 0.75']\n\nplt.figure()\nfor i in range(len(option_labels)):\n    plt.plot(theta_values, probabilities_array[i], label=option_labels[i])\nplt.xlabel('Theta')\nplt.ylabel('Probabilit√†')\nplt.title('Funzione Softmax - Modello Rescorla-Wagner')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico risultante mostra come le probabilit√† di scelta cambiano al variare del parametro \\(\\theta\\). Quando \\(\\theta\\) √® vicino a zero, la scelta √® quasi casuale. Quando \\(\\theta\\) √® molto grande, la scelta √® quasi sempre l‚Äôopzione con il valore pi√π alto.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#simulazione-del-modello-di-rescorla-wagner",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#simulazione-del-modello-di-rescorla-wagner",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.8 Simulazione del Modello di Rescorla-Wagner",
    "text": "86.8 Simulazione del Modello di Rescorla-Wagner\nCombiniamo la regola di apprendimento e la regola decisionale per simulare il comportamento del partecipante:\n\ndef simulate_RescorlaWagner(params, T, mu, noisy_choice=True):\n\n    alpha, theta = params\n    \n    # Un array di zeri di lunghezza T\n    c = np.zeros((T), dtype=int)\n    r = np.zeros((T), dtype=int)\n\n    # Un array multidimensionale di zeri di dimensione 2xT\n    Q_stored = np.zeros((2, T), dtype=float)\n    \n    # Inizializza Q per t == 0\n    Q = [0.5, 0.5]\n\n    for t in range(T):\n\n        # Salva i valori Q per Q_{t+1}\n        Q_stored[:, t] = Q\n\n        # Calcola le probabilit√† di scelta\n        p0 = np.exp(theta*Q[0]) / (np.exp(theta*Q[0]) + np.exp(theta*Q[1]))\n        p1 = 1 - p0\n        \n        # Se noisy_choice √® vero, viene simulato un comportamento di scelta rumoroso in \n        # cui l'opzione 0 √® scelta con probabilit√† p0, mentre l'opzione 1 √® scelta con \n        # probabilit√† 1-p0.\n        if noisy_choice:\n            if np.random.random_sample(1) &lt; p0:\n                c[t] = 0\n            else:\n                c[t] = 1\n        else:  # la scelta viene effettuata senza rumore\n            c[t] = np.argmax([p0, p1])\n\n        # Genera la ricompensa sulla base delle probabilit√† di ricompensa\n        r[t] = np.random.rand() &lt; mu[c[t]]\n\n        # Aggiorna le aspettative di valore\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    return c, r, Q_stored\n\nSimuliamo T = 100 prove utilizzando il modello generativo dei dati definito in precedenza.\n\nT = 100\nK = 2\nmu = [0.2, 0.8]\n\n\nc, r, Q = simulate_RescorlaWagner([.1, 2.5], T=T, mu=mu)\n\nRappresentiamo graficamente i risultati ottenuti dalla simulazione.\n\nplt.plot(range(T), r, 'r--', alpha=.6)\nplt.plot(range(T), c, '+', label='scelta')\nplt.xlabel('Prove')\nplt.ylabel('Feedback (1=Ricompensa,\\n 0=Nessuna ricompensa)')\nplt.title(f'Apprendimento di Rescorla-Wagner')\nplt.show()\n\n\n\n\n\n\n\n\nCome possiamo osservare, le scelte per la slot machine che produce meno ricompense diventano meno frequenti nel corso delle prove.\nIl diagramma seguente illustra l‚Äôaggiornamento del valore \\(Q\\), mostrando come l‚Äôaspettativa di ricompensa delle due slot machine venga aggiornata in base all‚Äôerrore di predizione nel corso delle prove.\n\nplt.plot(range(T), Q[1, :], \"r--\", alpha=0.6, label=\"80% machine\")\nplt.plot(range(T), Q[0, :], 'm-', alpha=.6, label='20% machine')\nplt.plot(range(T), c, 'b+', label='choice')\nplt.xlabel('trials')\nplt.ylabel('value')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSi noti come nel corso delle prove i valori delle slot macchine convergano lentamente verso le probabilit√† di ricompensa (20% e 80%).\nIn sintesi, il modello di Rescorla-Wagner ci permette di simulare come le persone apprendono e prendono decisioni basate su ricompense. Utilizzando la regola di apprendimento (\\(\\delta\\)-rule) e la regola decisionale softmax, possiamo vedere come le aspettative di valore e le scelte cambiano nel tempo in risposta alle ricompense ottenute.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#adattamento-del-modello",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#adattamento-del-modello",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.9 Adattamento del Modello",
    "text": "86.9 Adattamento del Modello\nDopo aver compreso il funzionamento del modello di Rescorla-Wagner, il passo successivo consiste nello stimare i parametri del modello a partire dai dati osservati. Questo processo √® cruciale nella modellazione computazionale poich√© ci permette di determinare quali valori dei parametri descrivono meglio il comportamento osservato. Esistono diversi metodi per stimare i parametri. La sezione Appendice T mostra come implementare l‚Äôapproccio della Massima Verosimiglianza. Qui illustreremo la stima dei parametri del modello Rescorla-Wagner utilizzando un metodo bayesiano, attraverso l‚Äôuso di Stan. Procediamo quindi a compilare il modello e a stampare il codice Stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"rescorla_wagner.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; nTrials; // numero di tentativi\n  array[nTrials] int&lt;lower=1, upper=2&gt; choice; // scelte effettuate (1 o 2)\n  array[nTrials] real&lt;lower=0, upper=1&gt; reward; // ricompense ricevute (0 o 1)\n}\ntransformed data {\n  vector[2] initV; // valori iniziali per V\n  initV = rep_vector(0.5, 2); // inizializzati a 0.5\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; alpha; // tasso di apprendimento\n  real&lt;lower=0&gt; theta; // temperatura\n}\nmodel {\n  vector[2] v; // valori attesi\n  real delta; // errore di previsione\n  \n  // Priori\n  alpha ~ beta(1, 1); // prior uniforme su [0, 1]\n  theta ~ normal(0, 10); // prior normale con media 0 e deviazione standard 10\n  \n  v = initV;\n  \n  for (t in 1 : nTrials) {\n    // Calcolo delle probabilit√† di scelta usando la funzione softmax con limitazione\n    vector[2] logits;\n    logits = theta * v;\n    logits = fmin(logits, 20); // Limita i valori massimi per evitare overflow\n    logits = fmax(logits, -20); // Limita i valori minimi per evitare underflow\n    \n    choice[t] ~ categorical_logit(logits);\n    \n    // Errore di previsione\n    delta = reward[t] - v[choice[t]];\n    \n    // Aggiornamento dei valori attesi (apprendimento)\n    v[choice[t]] = v[choice[t]] + alpha * delta;\n  }\n}\n\n\n\n\n86.9.1 Sezione data\nQuesta sezione definisce i dati che vengono forniti al modello:\n\nnTrials: Il numero totale di tentativi o scelte effettuate dal partecipante.\nchoice: Un array che contiene le scelte effettuate dal partecipante in ciascun tentativo (1 o 2).\nreward: Un array che contiene le ricompense ricevute per ciascun tentativo (0 o 1).\n\n\n\n86.9.2 Sezione transformed data\nQuesta sezione prepara alcuni dati iniziali trasformati per il modello. Qui initV √® un vettore di lunghezza 2 che rappresenta i valori iniziali delle aspettative di ricompensa per le due opzioni, entrambi inizializzati a 0.5.\n\n\n86.9.3 Sezione parameters\nQuesta sezione definisce i parametri del modello che Stan cercher√† di stimare:\n\nalpha: Il tasso di apprendimento, che determina quanto rapidamente il partecipante aggiorna le proprie aspettative. Questo valore √® compreso tra 0 e 1.\ntheta: La temperatura, che controlla il livello di esplorazione (quanto spesso il partecipante sceglie l‚Äôopzione con il valore atteso pi√π alto rispetto a esplorare altre opzioni). Questo valore √® positivo.\n\n\n\n86.9.4 Sezione model\nLa sezione model del codice Stan √® il cuore del modello, dove avviene il processo di stima e aggiornamento dei valori attesi in base ai dati osservati. Vediamo passo passo come funziona.\n\nInizializzazione.\n\nPartiamo con valori attesi uguali per entrambe le opzioni (v = [0.5, 0.5]).\nScegliamo valori casuali iniziali per alpha e theta.\n\nPer ogni tentativo dell‚Äôesperimento:\n\nCalcolo delle probabilit√† di scelta:\n\nlogits = theta * v;\nlogits = fmin(logits, 20);\nlogits = fmax(logits, -20);\n\nMoltiplichiamo i valori attesi per la temperatura.\nLimitiamo i risultati tra -20 e 20 per evitare problemi numerici.\n\nEsempio:\nSe v = [0.3, 0.7] e theta = 2:\n\nlogits = 2 * [0.3, 0.7] = [0.6, 1.4]\nNessun cambiamento dopo fmin e fmax perch√© i valori sono gi√† tra -20 e 20.\n\n\nModellazione della scelta:\n\nchoice[t] ~ categorical_logit(logits);\n\nUsiamo i logits per calcolare le probabilit√† di scelta.\nLa funzione softmax converte i logits in probabilit√†.\n\nEsempio (continuazione):\n\nsoftmax([0.6, 1.4]) ‚âà [0.38, 0.62]\nC‚Äô√® il 38% di probabilit√† di scegliere la prima opzione e il 62% per la seconda.\n\n\nCalcolo dell‚Äôerrore di previsione:\n\ndelta = reward[t] - v[choice[t]];\n\nConfrontiamo la ricompensa ricevuta con quanto ci aspettavamo.\nSe positivo, siamo stati piacevolmente sorpresi; se negativo, delusi.\n\nEsempio:\nSe scegliamo la seconda opzione e riceviamo una ricompensa di 1:\n\ndelta = 1 - 0.7 = 0.3\n\nSiamo stati leggermente sorpresi in positivo.\n\nAggiornamento dei valori attesi:\n\nv[choice[t]] = v[choice[t]] + alpha * delta;\n\nAggiorniamo la nostra aspettativa per l‚Äôopzione scelta.\nalpha determina quanto peso diamo alla nuova esperienza.\n\nEsempio (continuazione):\nSe alpha = 0.2:\n\nNuovo valore per la seconda opzione: 0.7 + 0.2 * 0.3 = 0.76\n\nLa nostra aspettativa per la seconda opzione √® leggermente aumentata.\nRipetizione.\n\n\nRipetiamo i passaggi 2a-2d per ogni tentativo dell‚Äôesperimento.\nAd ogni iterazione, affiniamo le nostre stime di alpha e theta.\n\n\n\n86.9.5 Inferenza\nConsidereremo qui i dati di un singolo partecipante che esegue 300 prove. Definiamo i parametri della simulazione:\n\nparams = [0.1, 2.5]  # alpha, theta\nT = 300  # numero di tentativi\nmu = [0.2, 0.8]  # probabilit√† di ricompensa per le due opzioni\n\nSimuliamo i dati:\n\nchoices, rewards, Q_stored = simulate_RescorlaWagner(params, T, mu)\n\nPrepariamo i dati per Stan. Si noti che abbiamo sommato 1 a choices per adattarsi agli indici di Stan che partono da 1.\n\nc = choices + 1\n\nstan_data = {\n    'nTrials': T,\n    'choice': c.tolist(),\n    'reward': rewards.tolist()\n}\nprint(stan_data)\n\n{'nTrials': 300, 'choice': [2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1], 'reward': [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0]}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n21:15:55 - cmdstanpy - INFO - CmdStan start processing\n21:15:55 - cmdstanpy - INFO - Chain [1] start processing\n21:15:55 - cmdstanpy - INFO - Chain [2] start processing\n21:15:55 - cmdstanpy - INFO - Chain [3] start processing\n21:15:55 - cmdstanpy - INFO - Chain [4] start processing\n21:15:59 - cmdstanpy - INFO - Chain [3] done processing\n21:15:59 - cmdstanpy - INFO - Chain [2] done processing\n21:15:59 - cmdstanpy - INFO - Chain [1] done processing\n21:15:59 - cmdstanpy - INFO - Chain [4] done processing\n\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell‚Äôinferenza insieme alle loro tracce (cio√® i vettori dei campioni dei parametri \\(\\alpha\\) e \\(\\theta\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\n\n\n86.9.6 Interpretazione delle Stime dei Parametri\nUtilizzando az.summary(trace, hdi_prob=0.94, round_to=2), otteniamo un riassunto delle stime dei parametri del modello, che include la media, la deviazione standard, gli intervalli di credibilit√† (HDI) e altre statistiche diagnostiche:\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.13\n0.08\n0.02\n0.27\n0.00\n0.00\n1973.89\n1757.85\n1.0\n\n\ntheta\n2.70\n0.41\n2.01\n3.46\n0.01\n0.01\n2095.86\n1581.69\n1.0\n\n\n\n\n\n\n\n\nCon 300 prove, le stime dei parametri fornite dal modello sono adeguate:\n\nL‚Äôintervallo di credibilit√† al 94% (hdi_3% - hdi_97%) include il valore simulato del parametro. Questo significa che le stime del modello sono coerenti con i parametri originali usati nella simulazione.\nLa deviazione standard della stima a posteriori √® relativamente piccola, indicando che le stime sono precise.\nI valori di r_hat sono vicini a 1, indicando che le catene di campionamento sono ben mescolate e hanno ottenuto la convergenza.\n\nQuesti risultati suggeriscono che il modello di apprendimento di Rescorla-Wagner ha stimato correttamente i parametri \\(\\alpha\\) e \\(\\theta\\) dai dati simulati.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#apprendimento-probabilistico-e-reversal-learning",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#apprendimento-probabilistico-e-reversal-learning",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.10 Apprendimento Probabilistico e Reversal Learning",
    "text": "86.10 Apprendimento Probabilistico e Reversal Learning\nUn paradigma sperimentale particolarmente interessante per indagare i meccanismi dell‚Äôapprendimento umano √® il Probabilistic Reversal Learning (Caudek et al. 2020, 2021). In questo compito, le associazioni tra stimoli e outcomes vengono invertite a met√† della procedura sperimentale. Ad esempio, se inizialmente lo stimolo A era associato a una ricompensa, in seguito questa associazione pu√≤ essere invertita, rendendo lo stimolo A svantaggioso.\nL‚Äôapprendimento per rinforzo offre un solido quadro teorico per comprendere come gli individui si adattano a tali cambiamenti. Modelli computazionali come quello di Rescorla-Wagner possono essere impiegati per simulare questo tipo di apprendimento e per studiare i processi cognitivi sottostanti.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#commenti-e-considerazioni-finali",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#commenti-e-considerazioni-finali",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.11 Commenti e considerazioni finali",
    "text": "86.11 Commenti e considerazioni finali\nIn precedenza abbiamo esaminato il modello di regressione. Sebbene il modello di regressione sia estremamente popolare in psicologia e nelle scienze sociali, presenta dei limiti sostanziali. √à utile per descrivere le associazioni tra variabili, ma non √® adatto per scoprire nessi causali, che rappresentano l‚Äôobiettivo principale delle teorie scientifiche. Come afferma Richard McElreath:\n\nLe persone una volta facevano teoria. Ora fanno solo regressioni.\n\nTrovare associazioni nei dati osservazionali non √® un buon metodo per costruire teorie. Abbiamo bisogno di una motivazione per esaminare determinate variabili, poich√© le associazioni tra variabili non sono rare, ma raramente ci informano sulle relazioni causali.\nUn approccio preferibile √® utilizzare una teoria formale per sviluppare aspettative sui dati osservati, misurare le variabili rilevanti e utilizzare modelli statistici specifici per testare la teoria.\nL‚Äôapprendimento per rinforzo offre un potente framework per studiare come gli organismi apprendono dall‚Äôinterazione con l‚Äôambiente. Modelli come quello di Rescorla-Wagner e algoritmi come UCB e Thompson Sampling forniscono strumenti utili per comprendere i processi cognitivi sottostanti l‚Äôapprendimento associativo e per sviluppare agenti intelligenti. Questi modelli hanno raggiunto un notevole successo, fornendo spiegazioni computazionali sia per fenomeni di apprendimento di base che complessi (M. K. Eckstein e Collins 2020; Frank e Badre 2012).\nTuttavia, √® importante riconoscere alcune limitazioni di questi modelli di apprendimento per rinforzo. La letteratura scientifica ha infatti accumulato una serie di osservazioni che questi modelli faticano a spiegare adeguatamente (M. Eckstein et al., s.d.). In primo luogo, eventi singoli del passato possono influenzare il comportamento in modo sproporzionato (Duncan e Shohamy 2016; Schulz e Gershman 2019; Bornstein e Norman 2017). Questo suggerisce che la memoria rilevante per il compito contiene pi√π che semplici statistiche riassuntive come i Q-values. In altre parole, le esperienze passate possono avere un impatto duraturo e significativo sulle decisioni future, anche se non riflesse nei valori medi appresi. In secondo luogo, il comportamento √® spesso sensibile a statistiche globali del passato, come l‚Äôintervallo di ricompense ricevute o il raggruppamento delle opzioni di scelta (Palminteri et al. 2015; Khaw, Glimcher, e Louie 2017). Questi aspetti non sono facilmente catturati dai modelli standard di apprendimento per rinforzo, che tendono a concentrarsi su valori specifici per ogni azione piuttosto che su pattern pi√π ampi. Infine, i segnali neurali precedentemente ritenuti direttamente correlati ai Q-values hanno mostrato una marcata diversit√† che √® in contrasto con le previsioni dei modelli standard di apprendimento per rinforzo (Yaple e Yu 2019). Questa variabilit√† suggerisce che i processi neurali sottostanti alle decisioni basate su ricompense sono pi√π complessi di quanto inizialmente si pensasse.\nNell‚Äôinsieme, questi risultati indicano che le rappresentazioni mnemoniche utilizzate da esseri umani e animali per prendere decisioni basate su ricompense vanno oltre le semplici statistiche riassuntive apprese in modo incrementale e associate a singole azioni. √à probabile che queste decisioni si basino su una variet√† di meccanismi di memoria interni aggiuntivi, che permettono una rappresentazione pi√π ricca e sfumata delle esperienze passate e del contesto decisionale. Questa complessit√† sottolinea la necessit√† di sviluppare modelli pi√π sofisticati che possano catturare la ricchezza dei processi decisionali osservati negli organismi biologici, integrando aspetti di memoria episodica, sensibilit√† al contesto e variabilit√† nei segnali neurali.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#esercizi",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#esercizi",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "86.12 Esercizi",
    "text": "86.12 Esercizi\n\nEsercizio 86.1 Implementa una funzione Python softmax che prende in input un array di valori attesi Q per ciascuna azione e un parametro di temperatura theta. La funzione deve restituire un array di probabilit√† che rappresenta la probabilit√† di selezione di ciascuna azione.\nLa formula della regola softmax √® la seguente:\n\\[ p_i = \\frac{e^{\\theta Q_i}}{\\sum_{j} e^{\\theta Q_j}}, \\]\ndove \\(p_i\\) √® la probabilit√† di selezionare l‚Äôazione \\(i\\), \\(Q_i\\) √® il valore atteso dell‚Äôazione \\(i\\), \\(\\theta\\) √® il parametro di temperatura che controlla il livello di esplorazione.\nUtilizza:\nQ = np.array([0.25, 0.75])\ntheta_values = [0.1, 1, 2, 5]\nQuesto esercizio fornisce una comprensione pratica di come la regola softmax bilancia esplorazione e sfruttamento nei modelli di apprendimento per rinforzo.\n\n\nEsercizio 86.2 L‚Äôobiettivo di questo esercizio √® implementare il calcolo dell‚Äôerrore di previsione nel modello di Rescorla-Wagner. Implementa una funzione Python update_value(Q, R, alpha) che prende in input il valore atteso attuale Q, la ricompensa ricevuta R, il tasso di apprendimento alpha, e restituisce il nuovo valore atteso aggiornato. La funzione deve anche restituire l‚Äôerrore di previsione.\nIl valore atteso \\(Q\\) viene aggiornato secondo la seguente formula:\n\\[ \\Delta Q = \\alpha (R - Q), \\]\ndove \\(\\Delta Q\\) √® la variazione del valore atteso, \\(\\alpha\\) √® il tasso di apprendimento, \\(R\\) √® la ricompensa ricevuta, \\(Q\\) √® il valore atteso attuale.\nIl nuovo valore atteso \\(Q'\\) √® dato da \\(Q' = Q + \\Delta Q\\).\nUsa:\nQ = 0.5  # Valore atteso iniziale\nR_values = [1, 0, 1, 1, 0]  # Sequenza di ricompense ricevute\nalpha = 0.1  # Tasso di apprendimento\nQuesto esercizio fornisce una comprensione pratica di come il modello di Rescorla-Wagner utilizza l‚Äôerrore di previsione per aggiornare le aspettative di ricompensa.\n\n\nEsercizio 86.3 L‚Äôobiettivo di questo esercizio √® comprendere e interpretare i parametri del modello di apprendimento di Rescorla-Wagner. Considera i seguenti scenari in cui un agente sta apprendendo a fare delle scelte basate sulle ricompense ricevute. Per ciascuno scenario, descrivi come il tasso di apprendimento (alpha) e il valore iniziale atteso (Q_0) potrebbero influenzare il comportamento dell‚Äôagente.\n\nScenario 1: Apprendimento Rapido in un Ambiente Stabile Un cane sta imparando a eseguire un nuovo trucco e riceve sempre una ricompensa (un bocconcino) ogni volta che esegue il trucco correttamente.\nScenario 2: Apprendimento Lento in un Ambiente Stabile Un bambino sta imparando a risolvere puzzle semplici. Ogni volta che completa un puzzle, riceve una stella adesiva come ricompensa.\nScenario 3: Apprendimento in un Ambiente Variabile Un giocatore di un videogioco sta cercando di capire quale arma √® la migliore contro diversi nemici. Le ricompense (punteggi) per l‚Äôuso delle armi variano in modo imprevedibile.\nScenario 4: Apprendimento con Informazioni Iniziali Parziali Un ricercatore che ha una conoscenza preliminare su quale farmaco potrebbe funzionare meglio sta conducendo un esperimento per confermare la sua ipotesi.\n\n\n\nEsercizio 86.4 L‚Äôobiettivo di questo esercizio √® analizzare come il modello di Rescorla-Wagner pu√≤ essere applicato in diversi contesti di apprendimento e come le variazioni nelle condizioni ambientali e nelle caratteristiche dell‚Äôagente possono influenzare l‚Äôefficacia dell‚Äôapprendimento.\nPer ciascuno dei seguenti contesti di apprendimento, descrivi come l‚Äôerrore di previsione e l‚Äôaggiornamento del valore atteso influenzerebbero il comportamento dell‚Äôagente. Discuti anche eventuali limitazioni del modello di Rescorla-Wagner nel catturare tutti gli aspetti del processo di apprendimento in quel contesto.\n\nContesto 1: Addestramento di un Animale Domestico Un cane viene addestrato a eseguire un comando specifico, come ‚Äúseduto‚Äù. Ogni volta che il cane esegue correttamente il comando, riceve una ricompensa.\nContesto 2: Apprendimento Scolastico Uno studente sta imparando una nuova materia a scuola. Riceve un feedback positivo o negativo (es. voti) in base alle sue prestazioni nei compiti e nelle verifiche.\nContesto 3: Terapia Comportamentale Un terapeuta utilizza tecniche di rinforzo per aiutare un paziente a superare una fobia. Il paziente riceve rinforzi positivi ogni volta che riesce ad affrontare la situazione temuta senza evitare.\nContesto 4: Apprendimento nelle Organizzazioni Un‚Äôazienda implementa un sistema di premi per i dipendenti che raggiungono determinati obiettivi di performance. I dipendenti ricevono bonus e riconoscimenti in base ai risultati raggiunti.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "title": "86¬† Apprendimento per rinforzo",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Aug 18 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBornstein, Aaron M, e Kenneth A Norman. 2017. ¬´Reinstated episodic context guides sampling-based decisions for reward¬ª. Nature Neuroscience 20 (7): 997‚Äì1003.\n\n\nCaudek, Corrado, Claudio Sica, Silvia Cerea, Ilaria Colpizzi, e Debora Stendardi. 2021. ¬´Susceptibility to eating disorders is associated with cognitive inflexibility in female university students¬ª. Journal of Behavioral and Cognitive Therapy 31 (4): 317‚Äì28.\n\n\nCaudek, Corrado, Claudio Sica, Igor Marchetti, Ilaria Colpizzi, e Debora Stendardi. 2020. ¬´Cognitive inflexibility specificity for individuals with high levels of obsessive-compulsive symptoms¬ª. Journal of Behavioral and Cognitive Therapy 30 (2): 103‚Äì13.\n\n\nDuncan, Katherine D, e Daphna Shohamy. 2016. ¬´Memory states influence value-based decisions.¬ª Journal of Experimental Psychology: General 145 (11): 1420.\n\n\nEckstein, Maria K, e Anne GE Collins. 2020. ¬´Computational evidence for hierarchically structured reinforcement learning in humans¬ª. Proceedings of the National Academy of Sciences 117 (47): 29381‚Äì89.\n\n\nEckstein, Maria, Christopher Summerfield, Nathaniel Daw, e Kevin J Miller. s.d. ¬´Hybrid Neural-Cognitive Models Reveal How Memory Shapes Human Reward Learning¬ª.\n\n\nFrank, Michael J, e David Badre. 2012. ¬´Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis¬ª. Cerebral Cortex 22 (3): 509‚Äì26.\n\n\nKhaw, Mel W, Paul W Glimcher, e Kenway Louie. 2017. ¬´Normalized value coding explains dynamic adaptation in the human valuation process¬ª. Proceedings of the National Academy of Sciences 114 (48): 12696‚Äì701.\n\n\nPalminteri, Stefano, Mehdi Khamassi, Mateus Joffily, e Giorgio Coricelli. 2015. ¬´Contextual modulation of value signals in reward and punishment learning¬ª. Nature Communications 6 (1): 8096.\n\n\nRescorla, Robert A, e A. R. Wagner. 1972. ¬´A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and non-reinforcement¬ª. Classical conditioning II, Current research and theory 2: 64‚Äì69.\n\n\nSchulz, Eric, e Samuel J Gershman. 2019. ¬´The algorithmic architecture of exploration in the human brain¬ª. Current Opinion in Neurobiology 55: 7‚Äì14.\n\n\nSutton, Richard S, e Andrew G Barto. 2018. ¬´Reinforcement Learning: an introduction, second edi¬ª. The MIT Press.\n\n\nYaple, Zachary A, e Rongjun Yu. 2019. ¬´Fractionating adaptive learning: A meta-analysis of the reversal learning paradigm¬ª. Neuroscience & Biobehavioral Reviews 102: 85‚Äì94.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>86</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html",
    "href": "chapters/dynamic_models/04_affect.html",
    "title": "87¬† Le emozioni influenzano le emozioni",
    "section": "",
    "text": "87.1 Introduzione\nL‚Äôobiettivo di questo capitolo √® implmentare e commenatare la proposta di Cipresso, Borghesi, e Chirico (2023) relativa all‚Äôuso delle catene di Markov per lo studio degli stati affettivi.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#la-modellizzazione-degli-stati-affettivi",
    "href": "chapters/dynamic_models/04_affect.html#la-modellizzazione-degli-stati-affettivi",
    "title": "87¬† Le emozioni influenzano le emozioni",
    "section": "87.2 La Modellizzazione degli Stati Affettivi",
    "text": "87.2 La Modellizzazione degli Stati Affettivi\nNegli studi di psicologia, il termine ‚Äúaffetto‚Äù √® utilizzato per descrivere uno stato globale che comprende una vasta gamma di fenomeni, tra cui emozioni, sentimenti e stati d‚Äôanimo. Gli stati affettivi, in particolare, si riferiscono allo stato emotivo o umore attuale di un individuo in relazione ai suoi obiettivi adattativi. Un‚Äôimportante contribuzione alla comprensione degli stati affettivi √® stata fornita dal modello circomplesso di Russell (1980), che rappresenta le emozioni su un piano bidimensionale, con ‚Äúattivazione‚Äù (arousal) su un asse e ‚Äúvalenza‚Äù (valence) sull‚Äôaltro. Questo modello permette di caratterizzare ogni emozione in base all‚Äôintensit√† dell‚Äôesperienza emotiva e alla sua natura positiva o negativa.\nAd esempio, la tristezza √® considerata un‚Äôemozione con valenza negativa e bassa attivazione, mentre la gioia √® vista come un‚Äôemozione con valenza positiva e attivazione medio-alta. Negli ultimi vent‚Äôanni, sono stati sviluppati numerosi stimoli per studiare questi stati affettivi in modo dettagliato, utilizzando immagini, video, suoni, narrazioni, situazioni reali, realt√† virtuale e musica.\nTuttavia, trattare gli affetti come stati indipendenti pu√≤ non rappresentare accuratamente la complessit√† della vita reale, dove gli stati emotivi influenzano quelli successivi. Per esempio, uno studente che si sente stressato all‚Äôinizio di un esame pu√≤ continuare a sentirsi stressato durante le fasi successive, rendendo difficile concentrarsi e rispondere alle domande. In questo contesto, √® fondamentale riconoscere come gli stati affettivi siano interconnessi e come uno stato possa influenzare quello successivo.\nQuesto ha portato alla necessit√† di utilizzare modelli matematici pi√π complessi, come il modello di Markov, per rappresentare le transizioni tra stati affettivi. Questi modelli permettono di analizzare in modo pi√π realistico le dinamiche degli stati affettivi, prendendo in considerazione la continuit√† e l‚Äôinfluenza reciproca degli stati emotivi nel tempo.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#un-processo-stocastico-per-le-dinamiche-degli-stati-affettivi",
    "href": "chapters/dynamic_models/04_affect.html#un-processo-stocastico-per-le-dinamiche-degli-stati-affettivi",
    "title": "87¬† Le emozioni influenzano le emozioni",
    "section": "87.3 Un Processo Stocastico per le Dinamiche degli Stati Affettivi",
    "text": "87.3 Un Processo Stocastico per le Dinamiche degli Stati Affettivi\nUna catena di Markov √® un processo stocastico utilizzato per modellare le dinamiche degli stati affettivi. In termini semplici, √® un modello matematico in cui la probabilit√† di passare da uno stato a un altro dipende solo dallo stato attuale, e non dalla sequenza di eventi precedenti. Questo significa che il futuro stato del sistema √® determinato solo dalla sua situazione presente.\n\n87.3.1 Matrice di Transizione\nPer descrivere matematicamente le transizioni tra stati affettivi, utilizziamo una matrice di transizione. Questa matrice rappresenta le probabilit√† di passaggio da uno stato all‚Äôaltro. Ad esempio, se abbiamo quattro stati affettivi (rilassato, stressato, impegnato e annoiato), la matrice di transizione mostrer√† le probabilit√† di passare da uno di questi stati a un altro. La somma delle probabilit√† in ogni riga della matrice deve essere pari a 1, poich√© il sistema deve sempre trovarsi in uno degli stati.\nLa matrice di transizione pu√≤ essere utilizzata per calcolare la probabilit√† che il sistema si trovi in un determinato stato dopo un certo numero di passaggi. Ad esempio, se la probabilit√† di essere nello stato A √® 0.6 e la probabilit√† di passare da A a B √® 0.3, la probabilit√† di essere nello stato B dopo un passaggio sar√† 0.18 (0.3 * 0.6).\n\n\n87.3.2 Stato Stazionario e Grafici Diretti\nDopo un certo numero di passaggi, la catena di Markov pu√≤ raggiungere uno stato stazionario, in cui le probabilit√† di essere in ciascuno stato non cambiano pi√π. Questo stato stazionario pu√≤ essere utilizzato per capire il comportamento a lungo termine del sistema.\nLe transizioni tra stati affettivi possono anche essere rappresentate graficamente tramite un grafo diretto, dove ogni stato √® un nodo e ogni transizione √® un arco diretto. Questo aiuta a visualizzare la struttura della catena di Markov e le relazioni tra gli stati.\n\n\n87.3.3 Espansione del Modello: Modelli di Markov Nascosti\nLe catene di Markov possono essere estese con i modelli di Markov nascosti (Hidden Markov Models, HMM) per includere livelli nascosti, ovvero stati che non possono essere osservati direttamente ma possono essere dedotti dai risultati osservabili. In termini di stati affettivi, questi modelli aiutano a comprendere stati latenti sottostanti che danno origine agli stati affettivi osservati, permettendo di tenere conto delle differenze individuali nell‚Äôesperienza e nell‚Äôespressione degli stati affettivi, cos√¨ come della possibilit√† che questi stati possano essere mal classificati o ambigui.\nQuesti modelli sono utili per analizzare le dinamiche degli stati affettivi e prevedere comportamenti, offrendo un potente strumento per comprendere fenomeni comportamentali specifici, come quelli osservati in gruppi di individui con particolari condizioni psicologiche.\n\n87.3.3.1 Rappresentazione degli Stati Affettivi\nPer modellare gli stati affettivi con una catena di Markov, utilizziamo una matrice di transizione in cui ogni elemento rappresenta la probabilit√† di passare da uno stato affettivo a un altro. Ad esempio, Cipresso, Borghesi, e Chirico (2023) considerano quattro stati affettivi: rilassato, stressato, impegnato e annoiato. Possiamo assegnare a ogni transizione possibile tra questi stati una probabilit√†, creando cos√¨ la seguente matrice di transizione:\n\n\n\nDa ¬†A\nAnnoiato\nRilassato\nStressato\nImpegnato\n\n\n\n\nAnnoiato\n0.60\n0.15\n0.15\n0.10\n\n\nRilassato\n0.10\n0.20\n0.40\n0.30\n\n\nStressato\n0.20\n0.10\n0.20\n0.50\n\n\nImpegnato\n0.30\n0.10\n0.20\n0.40\n\n\nStato iniziale (S0)\n0.10\n0.20\n0.40\n0.30\n\n\n\nVettore dello stato stazionario: Dopo un certo numero di passi, le probabilit√† di essere in ciascuno stato non cambiano pi√π, raggiungendo quello che viene chiamato stato stazionario. Ad esempio, dopo 10 passi, la probabilit√† di essere nello stato ‚Äúannoiato‚Äù √® 0.361351, nello stato ‚Äúrilassato‚Äù √® 0.131186, nello stato ‚Äústressato‚Äù √® 0.20817 e nello stato ‚Äúimpegnato‚Äù √® 0.299293.\n\n\n87.3.3.2 Vincoli e Modello Grafico\nLa matrice di transizione deve rispettare alcuni vincoli: tutte le probabilit√† devono essere non negative e la somma delle probabilit√† di transizione da uno stato a tutti gli altri deve essere 1, poich√© il sistema deve sempre trovarsi in uno degli stati possibili.\nPer rappresentare graficamente gli stati affettivi e le transizioni tra di essi, si pu√≤ usare un grafo diretto in cui ogni stato √® un nodo e ogni transizione √® rappresentata da un arco diretto. Questo tipo di rappresentazione aiuta a visualizzare la struttura della catena di Markov e le relazioni tra gli stati.\n\n\n\nRelazioni tra quattro stati affettivi ipotizzata da Cipresso, Borghesi, e Chirico (2023).\n\n\n\n\n87.3.3.3 Calcolo delle Probabilit√† nel Tempo\nLe catene di Markov sono un metodo matematico utilizzato per prevedere l‚Äôevoluzione nel tempo di un sistema che pu√≤ trovarsi in uno di diversi stati. Consideriamo un esempio con quattro stati affettivi: rilassato, stressato, impegnato, e annoiato. Utilizzeremo una catena di Markov per modellare come una persona possa passare da uno stato affettivo all‚Äôaltro nel tempo.\nImmaginiamo che inizialmente la persona si trovi nello stato rilassato. Questa situazione pu√≤ essere rappresentata da un vettore iniziale \\(x_0\\), che indica la probabilit√† di essere in ciascuno dei quattro stati:\n\nRilassato: 100%;\nStressato: 0%;\nImpegnato: 0%;\nAnnoiato: 0%.\n\nIl vettore \\(x_0\\) sar√† quindi:\n\\[\nx_0 = [1, 0, 0, 0].\n\\]\nSe invece la probabilit√† iniziale fosse del 50% di essere rilassato e del 50% di essere impegnato, il vettore diventerebbe:\n\\[\nx_0 = [0.5, 0, 0.5, 0].\n\\]\nSuccessivamente, definiamo una matrice di transizione \\(P\\) che descrive le probabilit√† di transizione da uno stato all‚Äôaltro in un singolo intervallo di tempo (ad esempio, un‚Äôora o un giorno). Ogni riga della matrice rappresenta lo stato attuale, mentre ogni colonna rappresenta lo stato futuro.\n\\[\nP = \\begin{bmatrix}\n0.60 & 0.15 & 0.15 & 0.10 \\\\\n0.10 & 0.20 & 0.40 & 0.30 \\\\\n0.20 & 0.10 & 0.20 & 0.50 \\\\\n0.30 & 0.10 & 0.20 & 0.40\n\\end{bmatrix}\n\\]\nLe probabilit√† di transizione per ogni stato sono le seguenti:\n\nAnnoiato: il 60% delle volte rimane annoiato, il 15% delle volte passa a rilassato o stressato, e il 10% delle volte diventa impegnato.\nRilassato: il 10% delle volte diventa annoiato, il 20% delle volte rimane rilassato, il 40% delle volte diventa stressato, e il 30% delle volte diventa impegnato.\nStressato: il 20% delle volte diventa annoiato, il 10% delle volte diventa rilassato, il 20% delle volte rimane stressato, e il 50% delle volte diventa impegnato.\nImpegnato: il 30% delle volte diventa annoiato, il 10% delle volte diventa rilassato, il 20% delle volte diventa stressato, e il 40% delle volte rimane impegnato.\n\nRiconsideriamo il caso in cui la persona sia inizialmente rilassata. Il vettore iniziale \\(x_0\\) sar√† quindi:\n\\[\nx_0 = [0, 1, 0, 0].\n\\]\nQuesto vettore indica una probabilit√† del 100% di essere nello stato ‚Äúrilassato‚Äù all‚Äôinizio.\nPer calcolare le probabilit√† degli stati dopo un giorno, moltiplichiamo il vettore iniziale \\(x_0\\) per la matrice di transizione \\(P\\):\n\\[\nx_1 = x_0 \\cdot P = [0, 1, 0, 0] \\cdot \\begin{bmatrix}\n0.60 & 0.15 & 0.15 & 0.10 \\\\\n0.10 & 0.20 & 0.40 & 0.30 \\\\\n0.20 & 0.10 & 0.20 & 0.50 \\\\\n0.30 & 0.10 & 0.20 & 0.40\n\\end{bmatrix}\n\\]\nCalcoliamo il prodotto per determinare il nuovo vettore delle probabilit√†:\n\\[\nx_1 = [0.10, 0.20, 0.40, 0.30].\n\\]\nDopo un giorno, le probabilit√† di essere in ciascuno stato sono le seguenti:\n\n10% probabilit√† di essere annoiato,\n20% probabilit√† di essere rilassato,\n40% probabilit√† di essere stressato,\n30% probabilit√† di essere impegnato.\n\nPer calcolare le probabilit√† dopo due giorni, moltiplichiamo il vettore \\(x_1\\) per la matrice \\(P\\):\n\\[\nx_2 = x_1 \\cdot P = [0.10, 0.20, 0.40, 0.30] \\cdot \\begin{bmatrix}\n0.60 & 0.15 & 0.15 & 0.10 \\\\\n0.10 & 0.20 & 0.40 & 0.30 \\\\\n0.20 & 0.10 & 0.20 & 0.50 \\\\\n0.30 & 0.10 & 0.20 & 0.40\n\\end{bmatrix}\n\\]\nEseguendo questo calcolo, otteniamo:\n\\[\nx_2 = [0.225, 0.105, 0.245, 0.425].\n\\]\nDopo due giorni, le probabilit√† di essere in ciascuno stato sono:\n\n22.5% probabilit√† di essere annoiato,\n10.5% probabilit√† di essere rilassato,\n24.5% probabilit√† di essere stressato,\n42.5% probabilit√† di essere impegnato.\n\nRipetendo questo processo, possiamo monitorare come le probabilit√† evolvono nel tempo, permettendoci di modellare l‚Äôevoluzione degli stati affettivi di una persona. Continuando a moltiplicare il vettore stato per la matrice di transizione, possiamo raggiungere uno stato stazionario, in cui le probabilit√† non cambiano pi√π di passo in passo. Questo √® utile per prevedere il comportamento a lungo termine di una persona nei diversi stati affettivi.\nIn conclusione, l‚Äôapproccio basato sulle catene di Markov offre un metodo rigoroso e flessibile per analizzare sistemi complessi che evolvono nel tempo. Questa tecnica non solo permette di modellare dinamiche probabilistiche, ma fornisce anche una base solida per lo sviluppo di modelli predittivi pi√π sofisticati in vari campi di applicazione.\n\n\n\n87.3.4 Un processo di Markov applicato agli stati affettivi\nUtilizzare i modelli di catene di Markov √® fondamentale per comprendere le dinamiche degli stati affettivi. Questi modelli catturano accuratamente le probabilit√† di transizione tra stati affettivi, fornendo uno strumento potente per analizzare le dinamiche sottostanti. Studiando tali modelli, i ricercatori possono ottenere informazioni preziose su come le nostre emozioni e reazioni possono cambiare nel tempo.\nAd esempio, un modello di catena di Markov potrebbe rivelare che un‚Äôemozione positiva ha maggiori probabilit√† di passare a uno stato neutro piuttosto che a uno negativo. Un ricercatore potrebbe scoprire che la felicit√† tende a trasformarsi pi√π facilmente in un sentimento di soddisfazione piuttosto che di tristezza. Per esempio, la probabilit√† di passare dalla gioia alla soddisfazione potrebbe essere 0.72, mentre quella di passare dalla gioia alla tristezza potrebbe essere 0.28.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#implementazione",
    "href": "chapters/dynamic_models/04_affect.html#implementazione",
    "title": "87¬† Le emozioni influenzano le emozioni",
    "section": "87.4 Implementazione",
    "text": "87.4 Implementazione\nNelle sezioni seguenti, ci proponiamo di simulare un set di dati basato sul meccanismo generativo dei dati descritto da Cipresso, Borghesi, e Chirico (2023), utilizzando la matrice di transizione illustrata in precedenza. Successivamente, implementeremo questo meccanismo in Stan per generare i dati simulati e utilizzeremo tali dati per effettuare inferenze sulla matrice di transizione utilizzata nella loro generazione.\nInoltre, svilupperemo in Stan un secondo modello che assume che gli stati affettivi siano indipendenti tra loro, ovvero che non si influenzino reciprocamente. Adatteremo questo secondo modello ai dati simulati e, attraverso l‚Äôutilizzo delle tecniche di validazione incrociata LOO, cercheremo di determinare quale modello descrive meglio i dati.\n\n87.4.1 Simulazione dei Dati\nSimuliamo i dati in base al modello generativo ipotizzato da Cipresso, Borghesi, e Chirico (2023). Per gli scopi presenti, non √® necessario capire nei dettagli come questo viene ottenuto.\n\n# Define the states\nstates = [\"Bored\", \"Relaxed\", \"Stressed\", \"Engaged\"]\n\n# Define the transition matrix\ntransition_matrix = np.array(\n    [\n        [0.60, 0.15, 0.15, 0.10],  # Bored\n        [0.10, 0.20, 0.40, 0.30],  # Relaxed\n        [0.20, 0.10, 0.20, 0.50],  # Stressed\n        [0.30, 0.10, 0.20, 0.40],  # Engaged\n    ]\n)\n\n\n# Function to generate the next state\ndef next_state(current_state):\n    return np.random.choice(states, p=transition_matrix[current_state])\n\n\n# Function to simulate a sequence of states\ndef simulate_markov_chain(start_state, num_steps):\n    current_state = states.index(start_state)\n    state_sequence = [start_state]\n\n    for _ in range(num_steps - 1):\n        current_state = states.index(next_state(current_state))\n        state_sequence.append(states[current_state])\n\n    return state_sequence\n\n\n# Simulate data\nstart_state = \"Bored\"\nnum_steps = 2000  # Number of steps to simulate\nsimulated_data = simulate_markov_chain(start_state, num_steps)\n\nSistemiamo i dati in un dizionario come richiesto da Stan.\n\n# Convert states to numerical indices for Stan\nstate_to_index = {\"Bored\": 1, \"Relaxed\": 2, \"Stressed\": 3, \"Engaged\": 4}\nstan_data_markov = {\n    \"N\": len(simulated_data),\n    \"states\": [state_to_index[state] for state in simulated_data],\n}\n\n\nprint(stan_data_markov[\"states\"][0:20])\n\n[1, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 3, 4, 4, 4, 4, 1, 2, 3, 1]\n\n\nPer qualche ragione, il posterior predictive check per il modello di Markov porta alla perdita di un‚Äôosservazione, mentre il modello che assume l‚Äôindipendenza no. Dato che il confronto tra i due modelli mediante ArviZ deve essere basato sullo stesso numero di dati, per semplicit√† sottraggo un dato dal campione analizzato dal modello che assume l‚Äôindipendenza.\n\nstan_data_independence = {\n    \"N\": len(simulated_data) - 1,\n    \"states\": [state_to_index[state] for state in simulated_data[:-1]],\n}\n\nprint(stan_data_independence[\"states\"][0:20])\n\n[1, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 3, 4, 4, 4, 4, 1, 2, 3, 1]\n\n\n\n\n87.4.2 Modello Markov\nImplementiamo ora in Stan il modello ipotizzato da Cipresso, Borghesi, e Chirico (2023).\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"cipresso_model.stan\"\n)\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // number of transitions\n  array[N] int states; // sequence of observed states\n}\nparameters {\n  array[4] simplex[4] trans_matrix; // 4x4 transition matrix with simplex constraints\n}\nmodel {\n  // Prior distribution for the transition matrix (Dirichlet prior)\n  for (i in 1 : 4) \n    trans_matrix[i] ~ dirichlet(rep_vector(1.0, 4));\n  \n  // Likelihood of the observed data\n  for (n in 1 : (N - 1)) \n    states[n + 1] ~ categorical(trans_matrix[states[n]]);\n}\ngenerated quantities {\n  array[N - 1] real log_lik; // array per la log likelihood\n  array[N] int&lt;lower=1, upper=4&gt; y_rep; // dati simulati per posterior predictive checks\n  \n  // Calcolo della log likelihood per ogni osservazione\n  for (n in 1 : (N - 1)) {\n    log_lik[n] = categorical_lpmf(states[n + 1] | trans_matrix[states[n]]);\n  }\n  \n  // Generazione di dati simulati per posterior predictive checks\n  y_rep[1] = states[1]; // il primo stato simulato √® lo stesso dello stato osservato\n  for (n in 1 : (N - 1)) {\n    y_rep[n + 1] = categorical_rng(trans_matrix[y_rep[n]]);\n  }\n}\n\n\n\nIn questo modello incontriamo due concetti nuovi. Il primo concetto √® quello di simplex.\nIn Stan, il comando array[4] simplex[4] trans_matrix; definisce una matrice di transizione 4x4 per un modello di catena di Markov.\nUn simplex in Stan √® un vettore di numeri positivi che sommano a 1. Nel contesto di una catena di Markov, un simplex rappresenta le probabilit√† di transizione da uno stato ad altri stati, garantendo che la somma delle probabilit√† di transizione da un particolare stato sia sempre uguale a 1.\nPer esempio, se consideriamo un vettore simplex di dimensione 4, [p1, p2, p3, p4], allora dobbiamo avere:\n\\[\np1 + p2 + p3 + p4 = 1\n\\]\ne \\(p_i \\geq 0\\) per ogni \\(i\\).\nLa dichiarazione array[4] simplex[4] in Stan crea un array di 4 vettori simplex, ciascuno di dimensione 4. Questo array rappresenta la matrice di transizione per una catena di Markov con 4 stati.\nNel codice, trans_matrix √® la matrice di transizione. L‚Äôarray trans_matrix pu√≤ essere visto come una matrice 4x4 in cui:\n\nogni riga rappresenta uno stato corrente nella catena di Markov;\nogni colonna rappresenta uno stato successivo possibile;\ngli elementi della matrice rappresentano le probabilit√† di transizione da uno stato corrente (indicato dalla riga) a uno stato successivo (indicato dalla colonna).\n\nPoich√© ogni riga di trans_matrix √® un simplex, la somma delle probabilit√† di ogni riga sar√† sempre pari a 1, il che √® coerente con le propriet√† di una matrice di transizione di Markov.\nConsideriamo un esempio per capire meglio:\n\\[\n\\text{trans\\_matrix} = \\begin{bmatrix}\n0.60 & 0.15 & 0.15 & 0.10 \\\\\n0.10 & 0.20 & 0.40 & 0.30 \\\\\n0.20 & 0.10 & 0.20 & 0.50 \\\\\n0.30 & 0.10 & 0.20 & 0.40\n\\end{bmatrix}\n\\]\nIn questo esempio:\n\nLa prima riga [0.60, 0.15, 0.15, 0.10] rappresenta le probabilit√† di transizione dallo stato 1 a ciascuno dei quattro stati. La somma √® 1.\nLa seconda riga [0.10, 0.20, 0.40, 0.30] rappresenta le probabilit√† di transizione dallo stato 2 a ciascuno degli stati, e cos√¨ via.\n\nUsiamo simplex[4] per garantire che le probabilit√† di transizione da uno stato a tutti gli altri stati sommino a 1. Questa √® una propriet√† fondamentale di una catena di Markov e assicura che il sistema rimanga all‚Äôinterno degli stati definiti, senza probabilit√† negative o somme maggiori di 1.\nIn conclusione, l‚Äôuso di array[4] simplex[4] in Stan per definire trans_matrix √® un modo per rappresentare una matrice di transizione di una catena di Markov. Ogni riga della matrice √® un vettore simplex che rappresenta le probabilit√† di transizione da un dato stato a tutti gli altri stati, rispettando le propriet√† di base delle probabilit√† in un sistema discreto di stati.\nIl secondo concetto nuovo che viene usato qui √® la distribuzione di Dirichlet. In Stan, l‚Äôespressione trans_matrix[i] ~ dirichlet(rep_vector(1.0, 4)); rappresenta una dichiarazione di prior per la riga i della matrice di transizione trans_matrix in un modello di catena di Markov. Per capire questa dichiarazione, vediamo cosa significa ogni parte.\nLa distribuzione di Dirichlet √® una distribuzione di probabilit√† continua definita su un simplex. In altre parole, √® una distribuzione utilizzata per modellare probabilit√† che devono sommare a 1, come le righe della matrice di transizione di una catena di Markov.\n\nSimplex: Un simplex di dimensione \\(K\\) √® un vettore di \\(K\\) elementi, ognuno dei quali √® maggiore o uguale a 0, e la somma di tutti questi elementi √® 1. La distribuzione di Dirichlet √® una distribuzione su questi vettori simplex.\nDirichlet Prior: Un prior di Dirichlet √® spesso utilizzato quando si desidera specificare una distribuzione di probabilit√† su vettori di probabilit√†. √à particolarmente utile nei modelli bayesiani quando si lavora con probabilit√† che devono sommare a 1 (come le righe di una matrice di transizione).\n\nNel contesto di una catena di Markov, ogni riga della matrice di transizione trans_matrix rappresenta un vettore di probabilit√† per le transizioni da uno stato specifico agli altri stati. Queste probabilit√† devono sommare a 1, il che rende la distribuzione di Dirichlet un‚Äôottima scelta per modellare queste probabilit√†.\nNell‚ÄôEspressione trans_matrix[i] ~ dirichlet(rep_vector(1.0, 4));\n\ntrans_matrix[i]: Questa √® la riga i-esima della matrice di transizione. Poich√© trans_matrix √® dichiarata come array[4] simplex[4], trans_matrix[i] √® un vettore simplex di dimensione 4, il che significa che √® un vettore di quattro probabilit√† che sommano a 1.\ndirichlet(rep_vector(1.0, 4)): Questa √® una distribuzione di Dirichlet con parametri pari a rep_vector(1.0, 4), che √® un vettore di 4 elementi tutti uguali a 1.\n\nrep_vector(1.0, 4): Questa funzione crea un vettore di dimensione 4 con tutti gli elementi uguali a 1.\ndirichlet(...): La distribuzione di Dirichlet prende questo vettore come parametro, il che significa che assegna una probabilit√† uguale a tutte le possibili configurazioni delle probabilit√†, a patto che sommino a 1. Questo tipo di Dirichlet con parametri uguali a 1 √® noto come Dirichlet uniforme, che rappresenta un prior non informativo. Non assume preferenze particolari per alcuna configurazione delle probabilit√†.\n\n\nIn pratica, l‚Äôistruzione trans_matrix[i] ~ dirichlet(rep_vector(1.0, 4)); assegna una prior uniforme a ogni riga i della matrice di transizione trans_matrix. In altre parole, prima di osservare qualsiasi dato, assumiamo che tutte le possibili configurazioni di probabilit√† di transizione siano ugualmente probabili. Questa √® una scelta comune quando non si ha una conoscenza a priori su quali transizioni siano pi√π probabili.\nQuesto prior permette alla stima della matrice di transizione di essere guidata interamente dai dati osservati, senza imporre vincoli iniziali. In un contesto bayesiano, l‚Äôuso di un prior di Dirichlet uniforme consente di aggiornare le stime della matrice di transizione in base ai dati, mantenendo un punto di partenza neutrale.\nIn conclusione, l‚Äôuso della distribuzione di Dirichlet con rep_vector(1.0, 4) come prior per ogni riga della matrice di transizione in un modello di catena di Markov √® un modo di modellare le probabilit√† di transizione che sono inizialmente considerate ugualmente probabili, consentendo al modello di apprendere le probabilit√† specifiche dai dati osservati senza pregiudizi forti.\nEseguiamo il campionamento utilizzando in input i dati simulati in precedenza.\n\nfit = model.sample(\n    data=stan_data_markov,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nConvertiamo l‚Äôoggetto fit_sample in un formato compatibile con ArviZ.\n\nfit_az = az.from_cmdstanpy(posterior=fit)\n\nEsaminiamo le distribuzioni a posteriori dei paraemtri.\n\naz.summary(fit_az,var_names=\"trans_matrix\", round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntrans_matrix[0, 0]\n0.60\n0.02\n0.57\n0.64\n0.0\n0.0\n17525.12\n6012.02\n1.0\n\n\ntrans_matrix[0, 1]\n0.16\n0.01\n0.13\n0.18\n0.0\n0.0\n17361.50\n6448.52\n1.0\n\n\ntrans_matrix[0, 2]\n0.14\n0.01\n0.11\n0.16\n0.0\n0.0\n15645.66\n6427.68\n1.0\n\n\ntrans_matrix[0, 3]\n0.10\n0.01\n0.08\n0.12\n0.0\n0.0\n17950.00\n5836.37\n1.0\n\n\ntrans_matrix[1, 0]\n0.09\n0.02\n0.06\n0.12\n0.0\n0.0\n15644.09\n6035.12\n1.0\n\n\ntrans_matrix[1, 1]\n0.22\n0.02\n0.18\n0.27\n0.0\n0.0\n17114.35\n6048.90\n1.0\n\n\ntrans_matrix[1, 2]\n0.39\n0.03\n0.33\n0.44\n0.0\n0.0\n18574.00\n5861.02\n1.0\n\n\ntrans_matrix[1, 3]\n0.30\n0.03\n0.25\n0.35\n0.0\n0.0\n16896.79\n5880.78\n1.0\n\n\ntrans_matrix[2, 0]\n0.20\n0.02\n0.16\n0.24\n0.0\n0.0\n14592.28\n6281.19\n1.0\n\n\ntrans_matrix[2, 1]\n0.11\n0.02\n0.08\n0.14\n0.0\n0.0\n15605.08\n5885.06\n1.0\n\n\ntrans_matrix[2, 2]\n0.19\n0.02\n0.15\n0.23\n0.0\n0.0\n18919.38\n5698.41\n1.0\n\n\ntrans_matrix[2, 3]\n0.49\n0.03\n0.44\n0.54\n0.0\n0.0\n16742.89\n6018.64\n1.0\n\n\ntrans_matrix[3, 0]\n0.27\n0.02\n0.24\n0.31\n0.0\n0.0\n20091.50\n5499.41\n1.0\n\n\ntrans_matrix[3, 1]\n0.13\n0.01\n0.10\n0.15\n0.0\n0.0\n17810.08\n6013.07\n1.0\n\n\ntrans_matrix[3, 2]\n0.19\n0.02\n0.16\n0.22\n0.0\n0.0\n17741.60\n5769.42\n1.0\n\n\ntrans_matrix[3, 3]\n0.41\n0.02\n0.37\n0.45\n0.0\n0.0\n18131.15\n6396.45\n1.0\n\n\n\n\n\n\n\n\nNotiamo come il modello sia stato in grado di recuperare in modo accurato i valori della matrice di transizione utilizzata per simulare i dati.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#modello-indipendenza",
    "href": "chapters/dynamic_models/04_affect.html#modello-indipendenza",
    "title": "87¬† Le emozioni influenzano le emozioni",
    "section": "87.5 Modello Indipendenza",
    "text": "87.5 Modello Indipendenza\nConsideriamo ora un modello di base che presuppone l‚Äôindipendenza tra gli stati affettivi. Se questo modello si adatta ai dati altrettanto bene del modello che considera le influenze reciproche tra stati affettivi, secondo il principio del rasoio di Occam, non sarebbe necessario ipotizzare tali influenze tra gli stati.\n\nstan_ind_file = os.path.join(project_directory, \"stan\", \"cipresso_ind_model.stan\")\n\nmodel_ind = CmdStanModel(stan_file=stan_ind_file)\nprint(model_ind.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero di osservazioni\n  array[N] int&lt;lower=1, upper=4&gt; states; // sequenza degli stati osservati\n}\nparameters {\n  simplex[4] state_probs; // vettore delle probabilit√† di ciascuno stato\n}\nmodel {\n  // Distribuzione a priori uniforme per le probabilit√† degli stati (Dirichlet(1))\n  state_probs ~ dirichlet(rep_vector(1.0, 4));\n  \n  // Verosimiglianza dei dati osservati trattati come indipendenti\n  for (n in 1 : N) \n    states[n] ~ categorical(state_probs);\n}\ngenerated quantities {\n  array[N] real log_lik; // array per la log likelihood\n  array[N] int&lt;lower=1, upper=4&gt; y_rep; // dati simulati per posterior predictive checks\n  \n  // Calcolo della log likelihood per ogni osservazione\n  for (n in 1 : N) {\n    log_lik[n] = categorical_lpmf(states[n] | state_probs);\n  }\n  \n  // Generazione di dati simulati per posterior predictive checks\n  for (n in 1 : N) {\n    y_rep[n] = categorical_rng(state_probs);\n  }\n}\n\n\n\nPer generare il modello di ‚Äúindipendenza‚Äù rispetto al modello ‚ÄúMarkov‚Äù, sono state introdotte diverse modifiche chiave. Vediamo quali sono queste modifiche e come differenziano i due modelli.\nNel modello di Markov, ogni stato successivo dipende dal precedente, con le probabilit√† di transizione definite da una matrice di transizione. Questo significa che la probabilit√† di essere in un dato stato al tempo \\(t+1\\) √® condizionata dallo stato al tempo \\(t\\).\nNel modello di Indipendenza, gli stati affettivi sono considerati indipendenti tra loro. Ogni osservazione √® trattata come un evento separato, senza dipendenza dal precedente. Le probabilit√† degli stati sono modellate da un vettore di probabilit√† di stato (state_probs), e non da una matrice di transizione.\nIl modello di Markov utilizza una matrice di transizione (trans_matrix), dove ogni riga √® un vettore simplex che rappresenta le probabilit√† di transizione da uno stato a tutti gli altri stati possibili.\nIl modello di Indipendenza utilizza un singolo vettore simplex di dimensione 4 (state_probs), che rappresenta le probabilit√† di ciascuno stato indipendentemente dagli altri stati. Qui, non c‚Äô√® una matrice di transizione perch√© non ci sono dipendenze tra stati consecutivi.\nNel modello di Markov, la verosimiglianza dei dati √® calcolata in base alla probabilit√† di transizione tra stati consecutivi. Ogni stato dipende dallo stato precedente, quindi la verosimiglianza riflette questa dipendenza.\nNel modello di Indipendenza, la verosimiglianza √® calcolata assumendo che ogni stato osservato sia indipendente dagli altri. La funzione di verosimiglianza usa una distribuzione categorica per ogni stato, basata sul vettore state_probs. Non c‚Äô√® alcuna relazione tra stati consecutivi.\nIn sintesi, le principali modifiche per passare dal modello ‚ÄúMarkov‚Äù al modello ‚Äúindipendenza‚Äù sono:\n\nnon esiste dipendenza tra stati successivi;\nutilizza un vettore di probabilit√† di stato (state_probs) anzich√© una matrice di transizione;\ntratta ogni osservazione come indipendente, utilizzando una distribuzione categorica basata su state_probs.\n\nEseguiamo il campionamento.\n\nfit_ind = model_ind.sample(\n    data=stan_data_independence,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\nfit_ind_az = az.from_cmdstanpy(posterior=fit_ind)\naz.summary(fit_ind_az, var_names=\"state_probs\", round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nstate_probs[0]\n0.34\n0.01\n0.32\n0.36\n0.0\n0.0\n8456.90\n5927.18\n1.0\n\n\nstate_probs[1]\n0.13\n0.01\n0.12\n0.15\n0.0\n0.0\n7911.11\n5710.21\n1.0\n\n\nstate_probs[2]\n0.22\n0.01\n0.21\n0.24\n0.0\n0.0\n8078.80\n6115.46\n1.0\n\n\nstate_probs[3]\n0.30\n0.01\n0.28\n0.32\n0.0\n0.0\n8308.59\n6358.41\n1.0\n\n\n\n\n\n\n\n\nUna volta che il ricercatore ha specificato un modello appropriato e verificato che il modello ottiene la convergenza, pu√≤ valutare se il modello descrive adeguatamente i dati. Le stime dei parametri sono interpretabili solo nella misura in cui il modello rappresenta accuratamente il fenomeno che si sta indagando. Se il modello approssima male i dati, le informazioni contenute nelle stime dei parametri potrebbero non essere rappresentative del processo che il ricercatore sta cercando di analizzare. In tali casi, potrebbe essere necessario riformulare il modello per migliorare la sua capacit√† di spiegare le osservazioni empiriche.\n\n# Run diagnostics and print results\ndiagnostic_info = fit_ind.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpprjn35f_/cipresso_ind_model8sljhpd5/cipresso_ind_model-20240825085942_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpprjn35f_/cipresso_ind_model8sljhpd5/cipresso_ind_model-20240825085942_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpprjn35f_/cipresso_ind_model8sljhpd5/cipresso_ind_model-20240825085942_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpprjn35f_/cipresso_ind_model8sljhpd5/cipresso_ind_model-20240825085942_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#valutazione-e-confronto-di-modelli",
    "href": "chapters/dynamic_models/04_affect.html#valutazione-e-confronto-di-modelli",
    "title": "87¬† Le emozioni influenzano le emozioni",
    "section": "87.6 Valutazione e Confronto di Modelli",
    "text": "87.6 Valutazione e Confronto di Modelli\nEseguiamo il calcolo dei valori k di Pareto e la validazione incrociata Leave-One-Out (LOO-CV) utilizzando ArviZ.\n\nloo_result = az.loo(fit_az)\nprint(loo_result)\n\nComputed from 8000 posterior samples and 1999 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -2406.20    26.49\np_loo       12.10        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1999  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\n\nloo_ind_result = az.loo(fit_ind_az)\nprint(loo_ind_result)\n\nComputed from 8000 posterior samples and 1999 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -2661.47    14.10\np_loo        3.01        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1999  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\n\ndf_comp_loo = az.compare({\n    \"markov_model\": loo_result, \n    \"independence_model\": loo_ind_result\n})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmarkov_model\n0\n-2406.195318\n12.103452\n0.000000\n0.799907\n26.494244\n0.000000\nFalse\nlog\n\n\nindependence_model\n1\n-2661.468120\n3.011688\n255.272802\n0.200093\n14.098377\n29.877077\nFalse\nlog\n\n\n\n\n\n\n\n\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)\n\n\n\n\n\n\n\n\nIl risultato ottenuto mostra chiaramente che la tecnica di validazione incrociata LOO permette di concludere che il modello ‚ÄúMarkov‚Äù rappresenta i dati in modo molto pi√π accurato rispetto al modello che presuppone l‚Äôindipendenza tra gli stati affettivi. Questo √® prevedibile, dato che i dati sono stati generati in base alla verosimiglianza implementata nel modello ‚ÄúMarkov‚Äù. Tuttavia, questa dimostrazione evidenzia come, utilizzando metodi bayesiani, sia possibile recuperare facilmente la matrice di transizione tra stati, a condizione che i dati siano stati generati da un processo coerente con il modello implementato in Stan.\nStudi di simulazione possono essere condotti per determinare quale dimensione del campione sia necessaria per consentire un recupero accurato dei valori della matrice di transizione. Inoltre, il modello pu√≤ essere ulteriormente sviluppato per distinguere tra diversi gruppi (ad esempio, pazienti e controlli) o per stimare le caratteristiche individuali dei partecipanti utilizzando un modello gerarchico.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#riflessioni-conclusive",
    "href": "chapters/dynamic_models/04_affect.html#riflessioni-conclusive",
    "title": "87¬† Le emozioni influenzano le emozioni",
    "section": "87.7 Riflessioni Conclusive",
    "text": "87.7 Riflessioni Conclusive\nSecondo Cipresso, Borghesi, e Chirico (2023), le catene di Markov offrono diversi vantaggi rispetto ai metodi tradizionali per modellare le dinamiche temporali e le interdipendenze degli stati emotivi.\n\nLe catene di Markov sono una strategia di modellazione adattabile che pu√≤ essere utilizzata per simulare diversi sistemi a stati discreti, inclusi gli stati emotivi. Questa flessibilit√† consente ai ricercatori di modellare solo gli stati emotivi e le loro connessioni rilevanti per il loro specifico studio.\nLe dinamiche temporali delle emozioni possono essere analizzate in modo semplice e comprensibile utilizzando le catene di Markov. √à possibile fare previsioni sugli stati futuri analizzando le probabilit√† di transizione tra stati diversi.\nLe catene di Markov permettono ai ricercatori di valutare la stabilit√† degli stati emotivi nel tempo, stimando le probabilit√† di passaggio da uno stato all‚Äôaltro sia a breve che a lungo termine.\nLe catene di Markov possono essere facilmente create utilizzando software statistici convenzionali, offrendo un ulteriore vantaggio rispetto ad altri metodi.\n\nOltre a questi vantaggi pratici, c‚Äô√® un aspetto interessante nell‚Äôusare le catene di Markov per rappresentare gli stati affettivi: richiedono un approccio innovativo nel considerare le transizioni tra stati emotivi. I ricercatori devono rivedere le loro ipotesi preliminari sugli affetti e considerare le transizioni in modo diverso, cercando nuovi tipi di disegni sperimentali.\nAd esempio, sarebbe utile evocare stati affettivi in base alla valenza e all‚Äôattivazione, mantenendo i partecipanti in uno stato per un tempo sufficiente a evocare esclusivamente lo stato desiderato. Successivamente, si dovrebbe passare a un altro stato, mantenendo anche questo per un periodo simile per evocare realmente i nuovi stati nei partecipanti.\nUna delle sfide principali √® definire una misura della probabilit√† di transizione da uno stato all‚Äôaltro. Questa potrebbe essere una funzione del tempo di latenza necessario per raggiungere un nuovo stato affettivo una volta presentati nuovi stimoli o una misura psicologica o fisiologica durante le transizioni. Attualmente, non esiste una risposta univoca a questo problema, il che rappresenta un invito all‚Äôazione per i ricercatori nel raccogliere nuovi dati per comprendere meglio le dinamiche degli stati affettivi utilizzando vari stimoli (foto, video, suoni, ecc.) e strumenti.\nCipresso, Borghesi, e Chirico (2023) propongono che i modelli di catene di Markov possono essere utilizzati per capire come diversi gruppi di individui (ad esempio, pazienti vs.¬†controlli) mostrino diverse matrici di transizione, evidenziando fenotipi comportamentali specifici e una comprensione approfondita dell‚Äôevoluzione della salute mentale basata sulle dinamiche degli affetti.\nAnalizzando questi modelli, potrebbe essere possibile capire come certi disturbi mentali progrediscono e come gli individui esprimono diversi schemi comportamentali basati sui loro stati affettivi. Comprendendo gli affetti nei vari stati, possiamo determinare con maggiore precisione le possibili cause dei disturbi mentali e sviluppare piani di trattamento pi√π efficaci. Ad esempio, i dati possono essere utilizzati per identificare quali emozioni sono pi√π comunemente associate alla depressione, permettendo di focalizzare quelle emozioni come parte del piano di trattamento di un paziente.\nInoltre, i dati possono aiutare a capire quali tipi di interventi e terapie producono i migliori risultati per le persone con malattie mentali, consentendo lo sviluppo di approcci basati sull‚Äôevidenza per gestire meglio le condizioni di salute mentale.\nIn conclusione, secondo Cipresso, Borghesi, e Chirico (2023), lo studio delle catene di Markov applicato alle dinamiche degli affetti pu√≤ fornire nuove intuizioni sui comportamenti fenotipici legati agli stati emotivi attraverso le propriet√† matematiche dei dati raccolti in disegni sperimentali. Questo permette di evidenziare le transizioni di stato e calcolare le probabilit√† correlate. Le limitazioni future riguardano il modo in cui le probabilit√† vengono stimate e la possibile struttura delle catene di Markov, soprattutto quando lo stato del sistema non √® direttamente osservabile ma pu√≤ essere dedotto da una sequenza di osservazioni. In questi casi, possono essere considerati i modelli di Markov nascosti, che estendono ulteriormente il modello di transizione. Pi√π in generale, il potenziale di questi processi matematici potrebbe chiarire le dinamiche affettive e la misura in cui queste dinamiche spiegano i processi di salute mentale a un livello pi√π alto, portando a una migliore comprensione e interventi.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/04_affect.html#informazioni-sullambiente-di-sviluppo",
    "title": "87¬† Le emozioni influenzano le emozioni",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sun Aug 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nbambi     : 0.14.0\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\npandas    : 2.2.2\narviz     : 0.18.0\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nCipresso, Pietro, Francesca Borghesi, e Alice Chirico. 2023. ¬´Affects affect affects: A Markov chain¬ª. Frontiers in Psychology 14: 1162655.\n\n\nRussell, James A. 1980. ¬´A circumplex model of affect.¬ª Journal of Personality and Social Psychology 39 (6): 1161‚Äì78.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>87</span>¬† <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html",
    "href": "chapters/dynamic_models/05_sequential_learning.html",
    "title": "88¬† Analisi dinamica delle sequenze di apprendimento",
    "section": "",
    "text": "88.1 Introduzione\nL‚Äôobiettivo di questo capitolo √® implementare il modello basato sulle catene di Markov proposto da Paxinou et al. (2021) per valutare l‚Äôefficacia di tre diverse strategie di insegnamento.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>88</span>¬† <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#la-modellizzazione-delle-sequenze-dellapprendimento",
    "href": "chapters/dynamic_models/05_sequential_learning.html#la-modellizzazione-delle-sequenze-dellapprendimento",
    "title": "88¬† Analisi dinamica delle sequenze di apprendimento",
    "section": "88.2 La Modellizzazione delle Sequenze dell‚ÄôApprendimento",
    "text": "88.2 La Modellizzazione delle Sequenze dell‚ÄôApprendimento\nLa ricerca di Paxinou et al. (2021) si concentra sull‚Äôacquisizione di competenze pratiche dopo l‚Äôaddestramento attraverso una metodologia specifica. In particolare, i partecipanti vengono addestrati a utilizzare un microscopio fotonico, lo strumento di base in un laboratorio di biologia. Vengono formati attraverso tre diversi metodi di insegnamento. Il T-Group ha partecipato a una dimostrazione tradizionale in presenza dell‚Äôesperimento di microscopia, il V-Group ha guardato un video didattico sull‚Äôesperimento di microscopia, e il VR-Group ha interagito con il microscopio simulato in un ambiente VR per eseguire l‚Äôesperimento di microscopia.\nNel presente tutorial considereremo solo i due metodi che producono i risultati pi√π estremi nello studio di Paxinou et al. (2021): il T-Group, che qui sar√† chiamato condizione 1, e il VR-Group, che corrisponde alla condizione 2.\nNello studio di Paxinou et al. (2021), ogni studente doveva eseguire individualmente l‚Äôesperimento di microscopia, che era suddiviso in 13 fasi. Non sapere come eseguire un passaggio portava al fallimento della prova, poich√© non era possibile passare al passaggio successivo senza aver completato quello corrente. Fortunatamente, i supervisori di laboratorio, negli ambienti di laboratorio fisici, o gli avatar e i pulsanti di aiuto/suggerimento, nei sistemi di tutoraggio intelligente come gli ambienti VR, offrivano agli studenti una seconda possibilit√† e la capacit√† di andare avanti. Basandosi su ci√≤, nello studio di Paxinou et al. (2021), la performance di ogni studente in ciascuno dei 13 passaggi veniva valutata secondo 3 categorie: A corrisponde all‚Äôazione ‚ÄúHo completato il passaggio facilmente‚Äù; B corrisponde all‚Äôazione ‚ÄúHo eventualmente completato il passaggio, ma con difficolt√†‚Äù; C corrisponde all‚Äôazione ‚ÄúNon sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto (al supervisore o a un compagno di studi)‚Äù. Queste 3 diverse valutazioni della performance in ogni passaggio definiscono i tre stati che costituiranno la catena di Markov.\nI dati corrispondono dunque alla sequenza di 13 stati per ogni studente. Nella presente analisi, lo stato A √® codificato come 1, lo stato B come 2, e lo stato C come 3. Quindi, per esempio, per un ipotetico studente, la sequenza delle valutazioni registrate nei 13 passaggi potrebbe dare origine alla seguente catena di Markov: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1].\nLo scopo dello studio, e in questo tutorial, √® determinare se esiste una differenza nell‚Äôapprendimento tra il T-Group (condizione 1) e il VR-Group (condizione 2) e, in caso affermativo, se l‚Äôapprendimento procede in modo pi√π fluido in una di queste due condizioni.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>88</span>¬† <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#implementazione",
    "href": "chapters/dynamic_models/05_sequential_learning.html#implementazione",
    "title": "88¬† Analisi dinamica delle sequenze di apprendimento",
    "section": "88.3 Implementazione",
    "text": "88.3 Implementazione\nDai dati empirici raccolti, Paxinou et al. (2021) stima tre matrici di transizione. Qui considereremo solo le matrici di transizione relative ai gruppi T e VR.\nUtilizzando queste due matrici di transizione, genereremo le sequenze di stati di 50 studenti nella condizione T e di 50 studenti nella condizione VR. Analizzeremo i dati con due modelli. Il modello paxinou_single_transition_model.stan ignora la differenza tra i due gruppi e stima una singola matrice di transizione per gli stati A, B e C dai dati dei 100 soggetti. Il modello paxinou_separate_transition_matrices_model.stan stima due matrici di transizione per gli stati A, B e C, una per ciascun gruppo (T e VR). Attraverso l‚Äôutilizzo delle tecniche di validazione incrociata LOO, determineremo quale modello descrive meglio i dati.\n\n88.3.1 Simulazione dei Dati\nSimuliamo i dati ipotizzando la presenza di tre stati (A, B, C) e utilizzando le matrici di transizione per le condizioni T e VR riportate da Paxinou et al. (2021). Per gli scopi presenti, non √® necessario capire nei dettagli come questo viene ottenuto.\n\ndef generate_markov_chain_data(transition_matrix, initial_state, steps, subjects):\n    states = [\"A\", \"B\", \"C\"]\n    data = []\n\n    for _ in range(subjects):\n        current_state = initial_state\n        state_sequence = [\n            states.index(current_state) + 1\n        ]  # Convert state to integer (1-based index)\n\n        for _ in range(steps - 1):\n            current_state = np.random.choice(\n                states, p=transition_matrix[states.index(current_state)]\n            )\n            state_sequence.append(states.index(current_state) + 1)\n\n        data.append(state_sequence)\n\n    return data\n\n\n# Transition matrices for the two conditions\ntransition_matrix_condition1 = [\n    [0.776, 0.128, 0.096],  # Probabilities for transitions from state A\n    [0.738, 0.167, 0.095],  # Probabilities for transitions from state B\n    [0.630, 0.259, 0.111],  # Probabilities for transitions from state C\n]\n\ntransition_matrix_condition2 = [\n    [0.866, 0.086, 0.048],  # Probabilities for transitions from state A\n    [0.516, 0.452, 0.032],  # Probabilities for transitions from state B\n    [0.900, 0.100, 0.000],  # Probabilities for transitions from state C\n]\n\n# Number of steps (trials) in the experiment\nsteps = 13\n# Number of subjects\nsubjects = 50\n\n# Initial state for each subject\ninitial_state = \"A\"\n\n# Generate data for both conditions\ndata_condition1 = generate_markov_chain_data(\n    transition_matrix_condition1, initial_state, steps, subjects\n)\ndata_condition2 = generate_markov_chain_data(\n    transition_matrix_condition2, initial_state, steps, subjects\n)\n\nSistemiamo i dati in un dizionario come richiesto da Stan.\n\n# Create the data dictionary for the Stan models\nstan_data = {\n    \"N\": 3,  # Number of states (A, B, C)\n    \"M1\": len(data_condition1),  # Number of subjects in condition 1\n    \"M2\": len(data_condition2),  # Number of subjects in condition 2\n    \"L\": steps,  # Length of each sequence (number of trials)\n    \"y1\": data_condition1,  # Data for condition 1\n    \"y2\": data_condition2,  # Data for condition 2\n}\n\nStampiamo i dati di due soggetti simulati nella condizione 1.\n\nprint(stan_data[\"y1\"][0:2])\n\n[[1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1], [1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n\n\n\n\n88.3.2 Modello Baseline\nImplementiamo ora in Stan il modello che non distingue tra le condizioni T e VR.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"paxinou_single_condition_model.stan\"\n)\n\nmodel_single = CmdStanModel(stan_file=stan_file)\nprint(model_single.code())\n\ndata {\n  int&lt;lower=1&gt; N; // number of states\n  int&lt;lower=1&gt; M1; // number of subjects in condition 1\n  int&lt;lower=1&gt; M2; // number of subjects in condition 2\n  int&lt;lower=1&gt; L; // length of each sequence\n  array[M1, L] int&lt;lower=1, upper=N&gt; y1; // observed sequences for condition 1\n  array[M2, L] int&lt;lower=1, upper=N&gt; y2; // observed sequences for condition 2\n}\nparameters {\n  array[N] simplex[N] P; // shared transition matrix for all data\n}\nmodel {\n  for (m in 1 : M1) {\n    for (l in 2 : L) {\n      y1[m, l] ~ categorical(P[y1[m, l - 1]]);\n    }\n  }\n  for (m in 1 : M2) {\n    for (l in 2 : L) {\n      y2[m, l] ~ categorical(P[y2[m, l - 1]]);\n    }\n  }\n}\ngenerated quantities {\n  array[M1 * (L - 1) + M2 * (L - 1)] real log_lik; // combined log likelihoods for all observations\n  \n  int idx = 1;\n  \n  // Compute log likelihoods for condition 1\n  for (m in 1 : M1) {\n    for (l in 2 : L) {\n      log_lik[idx] = categorical_lpmf(y1[m, l] | P[y1[m, l - 1]]);\n      idx += 1;\n    }\n  }\n  \n  // Compute log likelihoods for condition 2\n  for (m in 1 : M2) {\n    for (l in 2 : L) {\n      log_lik[idx] = categorical_lpmf(y2[m, l] | P[y2[m, l - 1]]);\n      idx += 1;\n    }\n  }\n}\n\n\n\nQuesto modello utilizza una catena di Markov per analizzare il progresso degli studenti attraverso diversi stati di apprendimento sotto due differenti condizioni di insegnamento. L‚Äôobiettivo √® stimare una singola matrice di transizione che rappresenti come gli studenti si spostano tra vari stati di apprendimento, indipendentemente dalla condizione di insegnamento.\nLe componenti principali del modello sono:\n\nStati di Apprendimento: A: ‚ÄúHo completato il passaggio facilmente‚Äù; B: ‚ÄúHo eventualmente completato il passaggio, ma con difficolt√†‚Äù; C: ‚ÄúNon sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto‚Äù.\nSequenze di Apprendimento: Serie di stati attraversati da ciascuno studente durante l‚Äôesperimento.\nMatrice di Transizione: Descrive le probabilit√† di passare da uno stato all‚Äôaltro.\n\nI dati in input hanno la seguente struttura:\n\nN: Numero di stati di apprendimento possibili.\nM1 e M2: Numero di studenti per ciascuna condizione di insegnamento.\nL: Numero di passi dell‚Äôesperimento che ogni studente deve completare.\ny1 e y2: Sequenze osservate di stati per gli studenti nelle due condizioni di insegnamento.\n\nEsaminiamo ora il funzionamento del modello. La matrice di transizione P √® la componente chiave. Ogni riga di P rappresenta uno stato attuale, con i valori che indicano le probabilit√† di passare agli altri stati. Il modello presuppone che queste probabilit√† siano uguali per entrambe le condizioni di insegnamento.\nIl processo inizia con una stima iniziale di P. Il modello esamina le sequenze di stati di ogni studente per entrambe le condizioni, calcolando la probabilit√† di ogni transizione osservata usando P. Successivamente, aggiorna P per massimizzare la probabilit√† complessiva di tutte le sequenze osservate. Questo processo iterativo continua fino a trovare la migliore stima possibile di P.\nLa matrice P √® costituita da righe che rappresentano distribuzioni categoriali per ciascuno stato attuale. La distribuzione categorical √® una generalizzazione della distribuzione binomiale per pi√π categorie, permettendo di modellare esiti con pi√π di due possibili risultati (come A, B, C), mantenendo la somma delle probabilit√† pari a 1.\nIl cuore del modello √® costituito dall‚Äôistruzione y1[m, l] ~ categorical(P[y1[m, l - 1]]);. Questa istruzione modella la probabilit√† di osservare una determinata transizione di stato all‚Äôinterno di una sequenza di apprendimento:\n\ny1[m, l]: Stato osservato per lo studente m al passo l.\ncategorical: Distribuzione di probabilit√† discreta per modellare eventi con diversi esiti.\nP[y1[m, l - 1]]: Seleziona la riga della matrice P corrispondente allo stato precedente, contenente le probabilit√† di transizione agli altri stati.\n\nL‚Äôistruzione y1[m, l] ~ categorical(P[y1[m, l - 1]]);:\n\nSimula la probabilit√† che lo studente m passi da uno stato all‚Äôaltro tra il passo l-1 e l.\nUsa la riga di P corrispondente allo stato precedente per determinare le probabilit√† di transizione.\nValuta quanto √® probabile osservare la sequenza di stati y1 data la matrice P.\n\nQuesta istruzione assegna una probabilit√† alla transizione osservata, che Stan utilizza per aggiornare le stime dei parametri del modello, migliorando l‚Äôaccuratezza complessiva della matrice P stimata.\nUna volta chiarito il modello, eseguiamo il campionamento.\n\nfit_single = model_single.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_single.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_single_condition_modeli6rc4wxk/paxinou_single_condition_model-20240826095506_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_single_condition_modeli6rc4wxk/paxinou_single_condition_model-20240826095506_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_single_condition_modeli6rc4wxk/paxinou_single_condition_model-20240826095506_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_single_condition_modeli6rc4wxk/paxinou_single_condition_model-20240826095506_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nConvertiamo l‚Äôoggetto fit_sample in un formato compatibile con ArviZ.\n\nfit_single_az = az.from_cmdstanpy(posterior=fit_single)\n\nEsaminiamo la matrice di transizione stimata dal modello.\n\n# Access posterior samples for the shared transition matrix 'P'\nP_samples = fit_single_az.posterior[\"P\"].values\n\n# P_samples likely have the shape: (chains, draws, N, N)\n# where 'chains' is the number of chains, 'draws' is the number of samples, and N is the number of states (3 in this case)\n\n# First, average over the chains axis (axis=0)\nP_samples_mean_over_chains = np.mean(P_samples, axis=0)\n\n# Then, average over the draws axis (axis=0)\nP_mean = np.mean(P_samples_mean_over_chains, axis=0)\n\n# The result is a 3x3 matrix\nprint(\"Estimated Transition Matrix (Mean):\")\nprint(P_mean.round(2))\n\nEstimated Transition Matrix (Mean):\n[[0.83 0.1  0.07]\n [0.6  0.35 0.05]\n [0.75 0.2  0.05]]",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>88</span>¬† <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#modello-per-gruppi-separati",
    "href": "chapters/dynamic_models/05_sequential_learning.html#modello-per-gruppi-separati",
    "title": "88¬† Analisi dinamica delle sequenze di apprendimento",
    "section": "88.4 Modello per Gruppi Separati",
    "text": "88.4 Modello per Gruppi Separati\nEsaminiamo ora il modello che assume diverse matrici di transizioni per i due gruppi.\n\nstan_sep_tran_mat_file = os.path.join(\n    project_directory, \"stan\", \"paxinou_separate_transition_matrices_model.stan\"\n)\n\nmodel_separate = CmdStanModel(stan_file=stan_sep_tran_mat_file)\nprint(model_separate.code())\n\ndata {\n  int&lt;lower=1&gt; N; // number of states\n  int&lt;lower=1&gt; M1; // number of subjects in condition 1\n  int&lt;lower=1&gt; M2; // number of subjects in condition 2\n  int&lt;lower=1&gt; L; // length of each sequence\n  array[M1, L] int&lt;lower=1, upper=N&gt; y1; // observed sequences for condition 1\n  array[M2, L] int&lt;lower=1, upper=N&gt; y2; // observed sequences for condition 2\n}\nparameters {\n  array[N] simplex[N] P1; // transition matrix for condition 1\n  array[N] simplex[N] P2; // transition matrix for condition 2\n}\nmodel {\n  // Likelihood for condition 1 using P1\n  for (m in 1 : M1) {\n    for (l in 2 : L) {\n      y1[m, l] ~ categorical(P1[y1[m, l - 1]]);\n    }\n  }\n  \n  // Likelihood for condition 2 using P2\n  for (m in 1 : M2) {\n    for (l in 2 : L) {\n      y2[m, l] ~ categorical(P2[y2[m, l - 1]]);\n    }\n  }\n}\ngenerated quantities {\n  array[M1 * (L - 1) + M2 * (L - 1)] real log_lik; // combined log likelihoods for all observations\n  int idx = 1; // Index for combined log likelihoods array\n  \n  // Compute log likelihoods for condition 1\n  for (m in 1 : M1) {\n    for (l in 2 : L) {\n      log_lik[idx] = categorical_lpmf(y1[m, l] | P1[y1[m, l - 1]]);\n      idx += 1;\n    }\n  }\n  \n  // Compute log likelihoods for condition 2\n  for (m in 1 : M2) {\n    for (l in 2 : L) {\n      log_lik[idx] = categorical_lpmf(y2[m, l] | P2[y2[m, l - 1]]);\n      idx += 1;\n    }\n  }\n}\n\n\n\nA differenza del modello precedente, che stima una singola matrice di transizione per entrambe le condizioni, questo modello stima due matrici di transizione distinte: una per ciascuna condizione di insegnamento. L‚Äôobiettivo √® vedere se e come le dinamiche di apprendimento differiscono tra le due condizioni.\nRispetto al modello con una singola matrice di transizione, il codice Stan per il modello con due matrici di transizione presenta alcune differenze fondamentali:\n\nDefinisce due matrici di transizione distinte, P1 e P2, per rappresentare separatamente le probabilit√† di transizione per ciascuna condizione.\nLa verosimiglianza √® calcolata separatamente per ciascuna condizione\n\nEseguiamo il campionamento.\n\nfit_separate = model_separate.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_separate.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_separate_transition_matrices_model782l5f79/paxinou_separate_transition_matrices_model-20240826092027_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_separate_transition_matrices_model782l5f79/paxinou_separate_transition_matrices_model-20240826092027_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_separate_transition_matrices_model782l5f79/paxinou_separate_transition_matrices_model-20240826092027_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_separate_transition_matrices_model782l5f79/paxinou_separate_transition_matrices_model-20240826092027_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\n\nfit_separate_az = az.from_cmdstanpy(posterior=fit_separate)\n\nEsaminiamo le due matrici di transizione stimate dal modello.\n\n# Access posterior samples for the transition matrices 'P1' and 'P2'\nP1_samples = fit_separate_az.posterior[\"P1\"].values\nP2_samples = fit_separate_az.posterior[\"P2\"].values\n\n# P1_samples and P2_samples likely have the shape: (chains, draws, N, N)\n# where 'chains' is the number of chains, 'draws' is the number of samples, and N is the number of states (3 in this case)\n\n# First, average over the chains axis (axis=0) for both P1 and P2\nP1_samples_mean_over_chains = np.mean(P1_samples, axis=0)\nP2_samples_mean_over_chains = np.mean(P2_samples, axis=0)\n\n# Then, average over the draws axis (axis=0) for both P1 and P2\nP1_mean = np.mean(P1_samples_mean_over_chains, axis=0)\nP2_mean = np.mean(P2_samples_mean_over_chains, axis=0)\n\n# The result for each is a 3x3 matrix\nprint(\"Estimated Transition Matrix for Condition 1 (Mean):\")\nprint(P1_mean.round(2))\n\nprint(\"\\nEstimated Transition Matrix for Condition 2 (Mean):\")\nprint(P2_mean.round(2))\n\nEstimated Transition Matrix for Condition 1 (Mean):\n[[0.77 0.13 0.1 ]\n [0.75 0.15 0.1 ]\n [0.55 0.32 0.12]]\n\nEstimated Transition Matrix for Condition 2 (Mean):\n[[0.85 0.08 0.07]\n [0.57 0.42 0.01]\n [0.8  0.17 0.03]]\n\n\nSi noti la buona corrispondenza tra i valori stimati e i valori usati nella simulazione dei dati.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>88</span>¬† <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#valutazione-e-confronto-di-modelli",
    "href": "chapters/dynamic_models/05_sequential_learning.html#valutazione-e-confronto-di-modelli",
    "title": "88¬† Analisi dinamica delle sequenze di apprendimento",
    "section": "88.5 Valutazione e Confronto di Modelli",
    "text": "88.5 Valutazione e Confronto di Modelli\nEseguiamo il calcolo dei valori k di Pareto e la validazione incrociata Leave-One-Out (LOO-CV) utilizzando ArviZ per il modello di baseline.\n\nloo_single = az.loo(fit_single_az)\nprint(loo_single)\n\nComputed from 8000 posterior samples and 1200 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -728.89    28.51\np_loo        5.79        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1200  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nRipetiamo il processo per il modello che distingue tra i gruppi.\n\nloo_separate = az.loo(fit_separate_az)\nprint(loo_separate)\n\nComputed from 8000 posterior samples and 1200 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -709.93    28.46\np_loo       10.55        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1200  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nEseguiamo un confronto tra i due modelli.\n\ndf_comp_loo = az.compare({\n    \"single_model\": loo_single, \n    \"separate_model\": loo_separate\n})\ndf_comp_loo\n\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nseparate_model\n0\n-709.926886\n10.545689\n0.000000\n0.903335\n28.458712\n0.00000\nFalse\nlog\n\n\nsingle_model\n1\n-728.893768\n5.791815\n18.966882\n0.096665\n28.513270\n6.79972\nFalse\nlog\n\n\n\n\n\n\n\n\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)\n\n\n\n\n\n\n\n\nSi noti che il rapporto tra elpd_diff e dse √® maggiore di 2 e che il modello preferito √® quello che distingue tra i gruppi. Questo indica che il modello che distingue tra i gruppi si adatta meglio ai dati. Nuovamente, questo non √® sorprendente dato che i dati sono stati generati in questo modo. Ma la simulazione indica che, se questo fosse il meccanismo generatore dei dati, con 50 soggetti per gruppo sarebbe possibile distinguere tra i due modelli.\nLa prossima domanda √® stabilire quale metodo d‚Äôinsegnamento funzioni meglio. Per rispondere a questa domanda, calcoliamo la probabilit√† che transitare allo stato A sia maggiore nella condizione VR che nella condizione T.\n\n# Extract posterior samples for transition matrices P1 and P2\nP1_samples = fit_separate_az.posterior[\n    \"P1\"\n].values  # Transition matrix for condition 1 (T-Group)\nP2_samples = fit_separate_az.posterior[\n    \"P2\"\n].values  # Transition matrix for condition 2 (VR-Group)\n\n# Number of states (assumed to be 3)\nnum_states = 3\n\n# Initialize lists to store the probabilities for each state transition\nprob_better_performance = []\nprob_worse_performance = []\n\n# Check transitions to state A and from any state to state C\nfor i in range(num_states):\n    # Transition to state A (index 0)\n    P1_to_A = P1_samples[\n        :, :, i, 0\n    ]  # Probability of transitioning to state A in T-Group\n    P2_to_A = P2_samples[\n        :, :, i, 0\n    ]  # Probability of transitioning to state A in VR-Group\n\n    # Compute probability that the VR condition has a higher probability of transitioning to state A\n    prob_to_A_better = np.mean(P2_to_A &gt; P1_to_A)\n    prob_better_performance.append(prob_to_A_better)\n\n    # Transition to state C (index 2)\n    P1_to_C = P1_samples[\n        :, :, i, 2\n    ]  # Probability of transitioning to state C in T-Group\n    P2_to_C = P2_samples[\n        :, :, i, 2\n    ]  # Probability of transitioning to state C in VR-Group\n\n    # Compute probability that the VR condition has a lower probability of transitioning to state C\n    prob_to_C_worse = np.mean(P2_to_C &lt; P1_to_C)\n    prob_worse_performance.append(prob_to_C_worse)\n\n# Print the results\nprint(\n    \"Probability that VR condition has a higher probability of transitioning to state A:\"\n)\nfor i in range(num_states):\n    print(f\"From state {i+1} to state A: {prob_better_performance[i]:.2f}\")\n\nprint(\n    \"\\nProbability that VR condition has a lower probability of transitioning to state C:\"\n)\nfor i in range(num_states):\n    print(f\"From state {i+1} to state C: {prob_worse_performance[i]:.2f}\")\n\nProbability that VR condition has a higher probability of transitioning to state A:\nFrom state 1 to state A: 1.00\nFrom state 2 to state A: 0.00\nFrom state 3 to state A: 0.89\n\nProbability that VR condition has a lower probability of transitioning to state C:\nFrom state 1 to state C: 1.00\nFrom state 2 to state C: 0.77\nFrom state 3 to state C: 0.81\n\n\n\n88.5.1 Interpretazione\nBasandosi sui risultati ottenuti, vediamo di interpretare il significato di ogni probabilit√† nel contesto della simulazione e dello studio originale.\n\nDallo stato 1 allo stato A: 1.00. La probabilit√† √® 1.00, il che indica che, in tutti i campioni posteriori, la condizione VR (Condizione 2) ha una probabilit√† pi√π alta di passare dallo stato 1 (‚ÄúHo completato il passaggio facilmente‚Äù) allo stato A (‚ÄúHo completato il passaggio facilmente‚Äù) rispetto alla condizione T-Group (Condizione 1). Questo suggerisce che, una volta che i partecipanti nella condizione VR hanno completato con successo un passaggio, √® pi√π probabile che continuino a completare facilmente i passaggi successivi.\nDallo stato 2 allo stato A: 0.00. La probabilit√† √® 0.00, il che indica che la condizione VR non ha una probabilit√† pi√π alta di passare dallo stato 2 (‚ÄúHo finalmente completato il passaggio, ma con difficolt√†‚Äù) allo stato A rispetto alla condizione T-Group. Questo suggerisce che quando i partecipanti stanno affrontando delle difficolt√† (stato 2), nella condizione VR non sono pi√π propensi rispetto alla condizione T-Group a passare a completare facilmente il passaggio successivo (stato A).\nDallo stato 3 allo stato A: 0.89. La probabilit√† √® 0.89, il che indica che c‚Äô√® l‚Äô89% di possibilit√† che la condizione VR abbia una probabilit√† pi√π alta di passare dallo stato 3 (‚ÄúNon sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto‚Äù) allo stato A rispetto alla condizione T-Group. Questo suggerisce che, anche quando i partecipanti chiedono aiuto (stato 3), √® pi√π probabile che nella condizione VR completino facilmente il passaggio successivo (stato A) rispetto alla condizione T-Group.\n\nCalcoliamo la probabilit√† che la condizione VR abbia una probabilit√† pi√π bassa di passare allo stato C:\n\nDallo stato 1 allo stato C: 1.00. La probabilit√† √® 1.00, indicando che la condizione VR ha una probabilit√† costantemente pi√π bassa di passare dallo stato 1 (‚ÄúHo completato il passaggio facilmente‚Äù) allo stato C (‚ÄúNon sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto‚Äù) rispetto alla condizione T-Group. Questo suggerisce che i partecipanti nella condizione VR sono molto meno propensi a regredire dal completare facilmente un passaggio a dover chiedere aiuto.\nDallo stato 2 allo stato C: 0.77. La probabilit√† √® 0.77, indicando una probabilit√† del 77% che la condizione VR abbia una probabilit√† pi√π bassa di passare dallo stato 2 (‚ÄúHo finalmente completato il passaggio, ma con difficolt√†‚Äù) allo stato C rispetto alla condizione T-Group. Questo suggerisce che i partecipanti nella condizione VR sono generalmente meno propensi a passare dal trovarsi in difficolt√† al dover chiedere aiuto rispetto a quelli nella condizione T-Group.\nDallo stato 3 allo stato C: 0.81. La probabilit√† √® 0.81, il che indica una probabilit√† dell‚Äô81% che la condizione VR abbia una probabilit√† pi√π bassa di rimanere nello stato C o di passare a esso (‚ÄúNon sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto‚Äù) rispetto alla condizione T-Group. Questo suggerisce che, anche quando i partecipanti chiedono aiuto, √® meno probabile che continuino a dover chiedere aiuto nella condizione VR rispetto alla condizione T-Group.\n\nI risultati mostrano che, complessivamente, i partecipanti nella condizione VR (Condizione 2) tendono ad avere risultati di performance migliori rispetto a quelli nella condizione T-Group (Condizione 1). In particolare:\n\nMaggiore probabilit√† di completamento facile (Stato A): La condizione VR mostra una forte tendenza (probabilit√† 1.00 e 0.89) a portare a una performance migliore (passaggio allo stato A) rispetto alla condizione T-Group, specialmente dallo stato 3 (richiesta di aiuto) allo stato A (completamento facile).\nMinore probabilit√† di necessit√† di aiuto (Stato C): La condizione VR mostra anche una tendenza (probabilit√† 1.00, 0.77 e 0.81) ad avere una minore probabilit√† di necessit√† di aiuto (passaggio allo stato C) in diversi scenari. Questo suggerisce che i partecipanti nella condizione VR sono meno propensi a finire per aver bisogno di aiuto, indicando una performance complessivamente migliore.\n\nQuesti risultati sono in linea con la conclusione dello studio originale che la condizione VR migliora la performance riducendo la probabilit√† di dover chiedere aiuto e aumentando le possibilit√† di completare facilmente i compiti.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>88</span>¬† <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#riflessioni-conclusive",
    "href": "chapters/dynamic_models/05_sequential_learning.html#riflessioni-conclusive",
    "title": "88¬† Analisi dinamica delle sequenze di apprendimento",
    "section": "88.6 Riflessioni Conclusive",
    "text": "88.6 Riflessioni Conclusive\nIn questo tutorial abbiamo esplorato l‚Äôutilizzo di modelli a catena di Markov per valutare la performance degli studenti in esperimenti scientifici. Attraverso una simulazione basata sui dati di Paxinou et al. (2021), abbiamo confrontato l‚Äôefficacia di due diverse metodologie di insegnamento: il tradizionale tutorial in laboratorio e l‚Äôinterazione con un software educativo in realt√† virtuale (VR).\nI risultati empirici ottenuti da Paxinou et al. (2021) indicano che la metodologia di apprendimento basata sulla realt√† virtuale √® pi√π efficace nell‚Äôaiutare gli studenti ad acquisire le competenze sperimentali necessarie. Gli studenti del gruppo VR hanno dimostrato una maggiore probabilit√† di completare i passaggi dell‚Äôesperimento facilmente e senza bisogno di assistenza rispetto agli studenti del gruppo T (tradizionale) e del gruppo V (video). In questo tutorial, abbiamo mostrato come sia possibile analizzare dati simili a quelli discussi da Paxinou et al. (2021) utilizzando modelli di catene di Markov di primo livello.\nPaxinou et al. (2021) commentano i loro risultati affermando che i modelli basati sulle catene di Markov sono strumenti utili non solo per valutare le performance e costruire funzioni di punteggio, ma anche per l‚Äôanalisi delle competenze acquisite. Inoltre, questi modelli possono essere impiegati per prevedere e intervenire efficacemente durante il processo educativo. I risultati suggeriscono che l‚Äôanalisi delle catene di Markov pu√≤ fornire valutazioni dinamiche e personalizzate delle competenze degli studenti, permettendo agli educatori di intervenire in modo mirato e fornire feedback tempestivi ed efficaci.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>88</span>¬† <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#esercizi",
    "href": "chapters/dynamic_models/05_sequential_learning.html#esercizi",
    "title": "88¬† Analisi dinamica delle sequenze di apprendimento",
    "section": "88.7 Esercizi",
    "text": "88.7 Esercizi\n\nEsercizio 88.1 Un altro studio interessante che utilizza questo approccio √® quello di Zanesco (2020). I flussi di pensiero variano nel contenuto da un momento all‚Äôaltro, e questi schemi temporali sono ritenuti fondamentali per comprendere il mind wandering. Tuttavia, sono stati proposti pochi metodi analitici in grado di considerare sia il contenuto sia l‚Äôordine temporale delle risposte categoriche che possono essere campionate relativamente a questa esperienza nel tempo. Il flusso di pensiero raramente segue lo stesso percorso per un individuo, ma mostra comunque con una certa prevedibilit√† nel contesto di un compito cognitivo. In questo studio, i partecipanti hanno selezionato tra 8 opzioni possibili per descrivere se la loro attenzione fosse attualmente concentrata sul ‚Äúcompito‚Äù (opzione 1); se stessero sperimentando pensieri rivolti alla ‚Äúperformance e valutazione del compito‚Äù (opzione 2); pensieri riguardanti le ‚Äúpreoccupazioni quotidiane‚Äù (opzione 3); pensieri sul proprio stato ‚Äúfisico, cognitivo o emotivo‚Äù (opzione 4); pensieri su ‚Äúpreoccupazioni personali‚Äù (opzione 5); pensieri fantasiosi e ‚Äúsogni a occhi aperti‚Äù (opzione 6); pensieri sugli stimoli presenti nell‚Äô‚Äúambiente esterno‚Äù (opzione 7); e ‚Äúaltri‚Äù pensieri non descritti dalle altre categorie (opzione 8). Zanesco (2020) ha applicato metodi di analisi sequenziale, utilizzando il modello di Markov di primo ordine, a questi campioni di pensiero categoriale, e i risultati hanno rivelato una certa misura di ordine e coerenza nei flussi di pensiero degli individui.\nUn possibile esercizio consiste nel simulare i dati utilizzando gli 8 stati considerati da Zanesco (2020) e la matrice di transizione riportata nel suo studio. Successivamente, si pu√≤ applicare il modello di Markov di primo ordine per stimare la matrice di transizione dai dati simulati. Seguendo l‚Äôapproccio di Zanesco (2020), i risultati ottenuti possono poi essere interpretati per approfondire la comprensione del fenomeno del mind wandering.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>88</span>¬† <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/05_sequential_learning.html#informazioni-sullambiente-di-sviluppo",
    "title": "88¬† Analisi dinamica delle sequenze di apprendimento",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sun Aug 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nbambi     : 0.14.0\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\npandas    : 2.2.2\narviz     : 0.18.0\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nPaxinou, Evgenia, Dimitrios Kalles, Christos T Panagiotakopoulos, e Vassilios S Verykios. 2021. ¬´Analyzing sequence data with Markov chain models in scientific experiments¬ª. SN Computer Science 2 (5): 385.\n\n\nZanesco, Anthony P. 2020. ¬´Quantifying streams of thought during cognitive task performance using sequence analysis¬ª. Behavior Research Methods 52 (6): 2417‚Äì37.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>88</span>¬† <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Introduzione ai Modelli Computazionali della Cognizione\nComprendere la cognizione umana √® stato uno dei principali obiettivi della ricerca psicologica per oltre un secolo. Gli approcci matematici allo studio della cognizione risalgono gi√† al XIX secolo, quando ricercatori come Ernst Heinrich Weber svilupparono modelli matematici per descrivere fenomeni percettivi, come l‚Äôeffetto della ‚Äúdifferenza appena percepibile‚Äù, che descrive il modo in cui gli esseri umani percepiscono le differenze tra gli oggetti (Raymond & Rutherford, 2012). Tuttavia, fu solo con l‚Äôavvento dell‚Äôinformatica teorica e dei computer digitali nel XX secolo che la psicologia computazionale emerse come un campo a s√© stante. La nascita del computer digitale permise agli psicologi cognitivi di sviluppare formalismi matematici e modelli computazionali che descrivevano la cognizione come un fenomeno di elaborazione delle informazioni, in modo simile a come operano i computer digitali. Ricercatori come George Miller, Allen Newell, Herbert Simon e Frank Rosenblatt applicarono metodi computazionali allo studio della percezione, del linguaggio e della risoluzione dei problemi, gettando le basi per questo campo emergente (Boden 2008). La psicologia computazionale ha offerto un approccio alternativo allo studio della mente, basato su algoritmi e simulazioni al computer, anzich√© su correlazioni e sperimentazioni in laboratorio, i paradigmi predominanti all‚Äôepoca, come osservato dal presidente dell‚ÄôAmerican Psychological Association, Lee Cronbach (Cronbach 1957).\nNel primo quarto del XXI secolo, il campo dei modelli computazionali della cognizione sta vivendo una crescita rapida in un mondo dove nazioni e giganti tecnologici competono per scoprire i segreti dell‚Äôintelligenza umana e artificiale. In questa introduzione, offro una panoramica storica degli approcci computazionali in scienza cognitiva, evidenziando l‚Äôimportanza e la prospettiva unica di questi metodi nello studio del pensiero e del comportamento umano. Adotter√≤ una prospettiva storica, concentrandomi su una narrazione ad alto livello dell‚Äôevoluzione del campo, piuttosto che su numerosi esempi individuali di modelli computazionali (Boden 2008).",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#introduzione-ai-modelli-computazionali-della-cognizione",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#introduzione-ai-modelli-computazionali-della-cognizione",
    "title": "Introduzione",
    "section": "",
    "text": "La Scienza Cognitiva Computazionale\nNonostante l‚Äôimportanza dei modelli computazionali, la scienza cognitiva computazionale ha impiegato molto tempo a consolidarsi tra i paradigmi principali nello studio della mente e del comportamento. Durante la prima met√† del XX secolo, lo studio della mente era visto con sospetto da molti, data la nostra incapacit√† di accedere direttamente ai suoi contenuti (Skinner 1965; Watson 1913). Concetti come ‚Äúcoscienza‚Äù o ‚Äúmemoria‚Äù sono entit√† che i ricercatori possono misurare solo indirettamente osservando il comportamento delle persone, ma non esiste un modo per ‚Äútoccare‚Äù o ‚Äúvedere‚Äù un frammento di memoria nella mente di qualcuno. Questi sono eventi privati, esperienze soggettive, entit√† inaccessibili di costituzione eterea. Sebbene all‚Äôepoca fossimo in grado di osservare e misurare i pattern di attivit√† elettrica nel cervello, trovare una corrispondenza diretta tra tali pattern e un particolare frammento di memoria era quanto mai ambiguo.\nL‚Äôinvenzione del computer digitale √® stata quindi rivoluzionaria per gli psicologi cognitivi, poich√© ha fornito un esempio fisico di qualcosa che poteva fare molte delle cose che fa la mente umana: aritmetica, logica, memorizzazione di informazioni, e altro ancora. Dopo tutto, √® possibile costruire, toccare e vedere un computer digitale. Si sa esattamente dove un‚Äôinformazione viene elaborata e memorizzata. √à difficile osservare un computer digitale in azione e non notare la somiglianza con i meccanismi interni della mente umana.\n\n\nOltre le Reti Neurali\nSebbene le reti neurali abbiano avuto un ruolo di primo piano nello sviluppo della scienza cognitiva computazionale, i modelli computazionali della cognizione non si limitano a queste. In realt√†, esistono diversi approcci modellistici, ciascuno con le proprie specificit√† e aree di applicazione. I modelli simbolici, ad esempio, descrivono la cognizione umana come il risultato della manipolazione di simboli, basandosi su logica formale e linguistica. I modelli probabilistici, invece, utilizzano la teoria delle probabilit√† per descrivere il ragionamento umano in condizioni di incertezza.\nNel corso degli anni, questi approcci si sono evoluti e spesso integrati tra loro, portando allo sviluppo di modelli ibridi che combinano elementi simbolici, connessionisti e probabilistici. La psichiatria computazionale, in particolare, ha tratto vantaggio da questo approccio integrato, utilizzando modelli che possono adattarsi a diverse scale di analisi, dai circuiti neuronali ai comportamenti osservabili, per fornire una visione pi√π completa dei disturbi mentali.\n\n\nLa Psichiatria Computazionale\nLa psichiatria computazional √® un campo emergente utilizza modelli matematici e computazionali per comprendere i meccanismi mentali e comportamentali che stanno alla base dei disturbi mentali. L‚Äôapproccio computazionale in psichiatria cerca di modellare in modo preciso le alterazioni nei processi cognitivi e decisionali che possono caratterizzare patologie come la schizofrenia, la depressione e i disturbi d‚Äôansia.\nUn esempio emblematico di questo approccio √® il lavoro di Michael Frank, che ha sviluppato modelli computazionali per comprendere i processi di apprendimento e decisione nei disturbi mentali. Frank ha esplorato come i modelli computazionali possano essere utilizzati per comprendere il funzionamento dei circuiti neuronali associati al rinforzo e alla punizione, e come alterazioni in questi circuiti possano contribuire a diverse manifestazioni psicopatologiche (Hitchcock, Fried, e Frank 2022). Ad esempio, i suoi studi sui meccanismi di rinforzo e sulla modulazione dopaminergica hanno fornito nuove prospettive sul funzionamento della malattia di Parkinson e sui disturbi compulsivi, mettendo in luce come alterazioni nei circuiti di rinforzo possano influenzare le decisioni e i comportamenti.\n\n\nConclusioni\nI modelli computazionali della cognizione hanno una lunga tradizione, iniziata nella prima met√† del XX secolo come un intreccio di teoria computazionale e psicologia cognitiva. Nel tempo, sono emersi quattro principali approcci all‚Äôinterno di questa prospettiva: modelli basati su simboli, modelli basati su connessionismi, modelli ibridi e modelli basati su probabilit√†. L‚Äôapproccio computazionale ha contribuito a migliorare e ampliare la nostra comprensione della cognizione e del comportamento umano. Le recenti avanzate nella disponibilit√† di risorse computazionali e di dati, insieme all‚Äôinteresse pubblico e privato nello sviluppo di tecnologie di intelligenza artificiale, forniscono un contesto fertile per la crescita e il consolidamento della prospettiva computazionale nelle scienze cognitive e nella psichiatria.\n\n\n\n\nBoden, Margaret A. 2008. ¬´An evaluation of computational modeling in cognitive science.¬ª\n\n\nCronbach, Lee J. 1957. ¬´The two disciplines of scientific psychology.¬ª American psychologist 12 (11): 671‚Äì84.\n\n\nHitchcock, Peter F, Eiko I Fried, e Michael J Frank. 2022. ¬´Computational psychiatry needs time and context¬ª. Annual review of psychology 73 (1): 243‚Äì70.\n\n\nSkinner, Burrhus Frederic. 1965. Science and human behavior. 92904. Simon; Schuster.\n\n\nWatson, John B. 1913. ¬´Psychology as the behaviorist views it.¬ª Psychological review 20 (2): 158.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html",
    "href": "chapters/cognitive_models/01_ddm.html",
    "title": "89¬† Drift Diffusion Model",
    "section": "",
    "text": "89.1 Introduzione\nUn importante ambito di studio nella psicologia cognitiva e nelle neuroscienze cognitive √® quello della presa di decisioni (decision making). Questo processo include il riconoscimento delle caratteristiche della situazione in cui ci troviamo, la considerazione di molteplici possibili alternative di risposta, la selezione e l‚Äôesecuzione di una risposta, l‚Äôosservazione dei risultati e l‚Äôadattamento del comportamento in base a questi. Compromissioni in qualsiasi fase di questo processo possono influenzare negativamente la capacit√† di prendere decisioni, con conseguenze tangibili nella vita reale. Esempi di ci√≤ includono l‚Äôadattamento, in cui le persone scelgono di sacrificare la salute a lungo termine per ottenere benefici a breve termine derivanti da una sostanza o comportamento adittivo (Bechara, 2005; Balodis e Potenza, 2020). Anomalie nel processo di presa di decisioni sono state riscontrate anche in disturbi che vanno dalla depressione e i disturbi d‚Äôansia (Chen, 2022), ai disturbi di personalit√† borderline (Hallquist et al., 2018), fino alla suicidalit√† (Jollant et al., 2011; Brenner et al., 2015; Dombrovski e Hallquist, 2017).\nUn approccio per comprendere la presa di decisioni √® l‚Äôutilizzo di modelli computazionali, come il Drift Diffusion Model (DDM; Ratcliff, 1978; Ratcliff e McKoon, 2008; Ratcliff et al., 2016), sviluppato originariamente per descrivere come partecipanti prendano decisioni rapide tra due alternative di risposta (Myers, Interian, e Moustafa 2022). Tali modelli cercano di inferire informazioni sui processi cognitivi soggiacenti basandosi su comportamenti osservabili nella presa di decisioni. Fornendo un quadro matematico per descrivere il comportamento, i modelli computazionali permettono ai ricercatori di chiarire i processi meccanistici sottostanti che portano alle azioni osservabili.\nSebbene il DDM sia stato descritto per la prima volta oltre 50 anni fa, ha recentemente visto un uso sempre pi√π diffuso, in parte grazie allo sviluppo di algoritmi che implementano il modello, e in parte grazie a una crescente letteratura che dimostra come il DDM possa realmente aiutare a comprendere i sui processi cognitivi soggiacenti che sono difficili da descrivere mediante i tradizionali metodi di analisi dei dati.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#stima-dei-parametri",
    "href": "chapters/cognitive_models/01_ddm.html#stima-dei-parametri",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.6 Stima dei Parametri",
    "text": "89.6 Stima dei Parametri\nSono stati proposti diversi metodi per stimare i parametri del DDM. Un approccio iniziale per la stima dei parametri del DDM √® il metodo del œá¬≤ (ad esempio, Ratcliff e Tuerlinckx, 2002), che confronta un istogramma delle distribuzioni dei tempi di reazione (RT) nei dati empirici con quelli previsti dal modello sotto un dato insieme di valori dei parametri.\nI principali vantaggi del metodo œá¬≤ sono la velocit√† computazionale e la relativa robustezza agli RT anomali. Tuttavia, il metodo œá¬≤ richiede un gran numero di prove per produrre una stima affidabile (ad esempio, almeno 500 prove) e pu√≤ risultare problematico se ci sono relativamente poche risposte errate (ad esempio, meno di 12 prove in qualsiasi intervallo quantile; Voss et al., 2015). Per queste ragioni, l‚Äôapproccio del œá¬≤ per l‚Äôadattamento dei parametri √® diventato meno utilizzato negli ultimi anni, poich√© sono stati resi disponibili altri metodi e la potenza di calcolo √® aumentata.\nUn metodo popolare per stimare i parametri del DDM utilizza la stima di massima verosimiglianza (MLE) per generare stime per ciascun parametro. Formalmente, la MLE cerca di trovare un insieme di valori dei parametri che, insieme, massimizzino la probabilit√† che il risultato del modello corrisponda ai dati empirici su tutte le prove. Gli approcci MLE sono stati utilizzati con successo in un gran numero di studi sul DDM e possono essere utilizzati anche quando sono disponibili relativamente poche prove (ad esempio, meno di 50) per ciascun partecipante (Lerche et al., 2017). Tuttavia, la MLE pu√≤ essere molto sensibile agli RT anomali (soprattutto RT molto rapidi), quindi √® necessario prestare molta attenzione alla pulizia dei dati. Inoltre, gli algoritmi MLE sono vulnerabili ai minimi locali, il che significa che possono convergere su un insieme di valori dei parametri in cui nessuna piccola perturbazione pu√≤ migliorare ulteriormente la LLE, anche se questa potrebbe non essere la soluzione ottimale. Per questo motivo, i ricercatori che usano questo metodo eseguono la procedura MLE pi√π volte, con diversi valori di partenza, per assicurarsi che la stessa soluzione venga trovata ogni volta.\nRecentemente, sono stati proposti diversi approcci bayesiani per stimare i valori dei parametri del DDM. Questi metodi, partono da stime iniziali (cio√® ‚Äúdistribuzioni a priori‚Äù) su valori ragionevoli per ciascun parametro, e tali stime vengono aggiornate iterativamente per produrre le ‚Äúdistribuzioni posteriori‚Äù per quei parametri. Il calcolo delle distribuzioni posteriori √® estremamente intensivo dal punto di vista computazionale e la soluzione diretta √® generalmente intrattabile (non esiste un modo matematico noto per calcolare direttamente i posteriori dai priori e dai dati). Invece, si cercano soluzioni approssimate usando i metodi Markov Chain Monte Carlo (MCMC). Gli approcci bayesiani al DDM possono essere pi√π robusti nel recupero dei parametri del modello rispetto ad altri metodi, come la MLE e il metodo œá¬≤, quando √® disponibile un numero limitato di prove (Wiecki et al., 2013). Gli approcci bayesiani forniscono non solo stime dei parametri (media o mediana delle distribuzioni posteriori), ma quantificano anche l‚Äôincertezza in queste stime (deviazione standard o intervallo di confidenza al 95% delle distribuzioni posteriori).\nI metodi sopra descritti per stimare i parametri del DDM presuppongono che i parametri siano adattati ai dati di ciascun partecipante in modo indipendente. Un approccio alternativo √® la modellizzazione gerarchica, che affronta le differenze individuali mentre raccoglie informazioni tra individui per generare stime dei parametri a livello di gruppo (Vandekerckhove et al., 2011; Wiecki et al., 2013; Johnson et al., 2017). Gli approcci gerarchici possono essere particolarmente utili quando la variabilit√† all‚Äôinterno del gruppo √® molto inferiore rispetto alla variabilit√† tra gruppi, o quando √® disponibile solo un numero ridotto di prove per ciascun partecipante.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/cognitive_models/01_ddm.html#informazioni-sullambiente-di-sviluppo",
    "title": "89¬† Drift Diffusion Model",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Aug 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMyers, Catherine E, Alejandro Interian, e Ahmed A Moustafa. 2022. ¬´A practical introduction to using the drift diffusion model of decision-making in cognitive psychology, neuroscience, and health sciences¬ª. Frontiers in Psychology 13: 1039172.\n\n\nWilliams, W Craig, Eisha Haque, Becky Mai, e Vinod Venkatraman. 2023. ¬´Face masks influence emotion judgments of facial expressions: a drift‚Äìdiffusion model¬ª. Scientific Reports 13 (1): 8842.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Nell‚Äôinferenza statistica esistono due approcci principali: la statistica frequentista e la statistica bayesiana. Entrambi i metodi permettono di trarre conclusioni sulla popolazione di interesse analizzando i dati, stimare quantit√† sconosciute, fare previsioni e testare ipotesi. Tuttavia, differiscono nell‚Äôinterpretazione della probabilit√† e nell‚Äôintegrazione di conoscenze precedenti ed evidenze.\nLa statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica utilizzando il teorema di Bayes. In questo contesto, il valore vero di un parametro della popolazione √® trattato come una variabile casuale, che viene costantemente aggiornata man mano che nuovi dati vengono raccolti. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, utilizzabile per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nD‚Äôaltra parte, la statistica frequentista interpreta la probabilit√† come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute dai dati osservati utilizzando varie tecniche statistiche e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nIn questa sezione della dispensa esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "90¬† Introduzione all‚Äôinferenza frequentista",
    "section": "",
    "text": "Introduzione\nCi sono due approcci principali per l‚Äôinferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l‚Äôanalisi dei dati. Entrambi gli approcci sono usati per stimare quantit√† sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilit√† e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilit√† viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull‚Äôidea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l‚Äôutilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD‚Äôaltra parte, la statistica bayesiana interpreta la probabilit√† come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell‚Äôanalisi statistica attraverso l‚Äôuso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione √® trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ci√≤ porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che pu√≤ essere utilizzata per fare previsioni probabilistiche e quantificare l‚Äôincertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell‚Äôinferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle propriet√† probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste propriet√† sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell‚Äôinferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "90¬† Introduzione all‚Äôinferenza frequentista",
    "section": "90.1 I Frequentisti sono Razzisti?",
    "text": "90.1 I Frequentisti sono Razzisti?\nNel Capitolo 23, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all‚Äôinterpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il ‚Äúlato luminoso‚Äù del liberalismo moderno.\nLe origini culturali dell‚Äôapproccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la ‚Äúparte oscura‚Äù della modernit√†. Si potrebbe dire che l‚Äôavversione per la soggettivit√† abbia guidato l‚Äôascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, eredit√≤ una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplor√≤ l‚ÄôAfrica, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli ‚Äúanticicloni‚Äù. Tuttavia, il suo contributo pi√π significativo riguard√≤ l‚Äôuso della statistica nello studio degli esseri umani, in particolare nell‚Äôanalisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all‚ÄôUniversity College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come ‚Äúregressione verso la media‚Äù, da lui chiamato ‚Äúregressione verso la mediocrit√†‚Äù.\nIl suo interesse per l‚Äôereditariet√† del talento lo port√≤ a scrivere il libro ‚ÄúHereditary Genius‚Äù, in cui esaminava come i pensatori brillanti spesso si concentrassero in determinate famiglie. Coni√≤ l‚Äôespressione ‚Äúnature and nurture‚Äù per riferirsi ai due fattori che influenzano lo sviluppo umano: l‚Äôereditariet√† (quello che oggi chiamiamo genetica) e l‚Äôambiente.\nTuttavia, Galton non si limit√≤ a osservare e documentare fatti sulla distribuzione dell‚Äôintelligenza. Il suo obiettivo era creare una scienza dell‚Äôallevamento umano, che egli denomin√≤ ‚Äúeugenetica‚Äù. Egli sosteneva l‚Äôincoraggiamento della riproduzione tra le famiglie di maggior successo e lo scoraggiamento tra quelle meno fortunate.\nGalton era anche estremamente razzista. In una lettera al Times di Londra, defin√¨ gli africani ‚Äúinferiori‚Äù e ‚Äúselvaggi pigri e chiacchieroni‚Äù, descrisse gli arabi come ‚Äúpoco pi√π che consumatori della produzione altrui‚Äù e sostenne che l‚ÄôAfrica orientale dovesse essere consegnata ai cinesi, poich√© questi, nonostante fossero ‚Äúinclini alla menzogna e alla servilit√†‚Äù, erano per natura ‚Äúindustriosi e amanti dell‚Äôordine‚Äù. Per Galton, gli anglosassoni erano la migliore razza esistente, sebbene ritenesse che gli antichi ateniesi fossero stati i migliori di tutti i tempi.\nIl lavoro di Galton ispir√≤ una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, un poliedrico studioso, divenne professore di matematica applicata all‚ÄôUCL nel 1885, seguendo le orme di Galton. Alla morte di quest‚Äôultimo, eredit√≤ la cattedra di eugenismo finanziata da Galton stesso. Pearson fond√≤ la rivista di statistica ‚ÄúBiometrika‚Äù e svilupp√≤ il test del chi quadrato, oltre a coniare il termine ‚Äúdeviazione standard‚Äù.\nRonald Fisher, pi√π giovane, succedette a Pearson come professore di eugenismo all‚ÄôUCL. Fisher √® considerato un gigante della teoria statistica, avendo inventato o esteso numerosi strumenti statistici moderni, tra cui l‚Äôanalisi della varianza (ANOVA), il concetto di ‚Äúsignificativit√† statistica‚Äù e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall‚Äôapproccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell‚Äôeugenismo.\n√à interessante chiedersi se le idee di Galton, Pearson e Fisher sull‚Äôeugenismo abbiano influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e dell‚Äôeugenismo sono strettamente intrecciate. Fisher e, in misura minore, Pearson respingevano l‚Äôidea del bayesianesimo perch√© cercavano di assegnare un fondamento ‚Äúoggettivo‚Äù alle loro idee eugenetiche. Se fosse stata la scienza a stabilire che alcune razze erano inferiori e altre superiori, o che si dovesse scoraggiare la riproduzione tra i poveri, allora queste idee sarebbero state incontestabili. Il bayesianesimo, con la sua intrinseca soggettivit√†, minava questa pretesa di oggettivit√†.\nQuanto di tutto ci√≤ dobbiamo tenere a mente quando esaminiamo la statistica frequentista? Chivers (2024) risponde in questo modo. √à certo che parte dell‚Äôideologia razziale nazista pu√≤ essere ricondotta senza troppe difficolt√† a Galton. Tuttavia, questa considerazione, per quanto estremamente importante dal punto di vista storico ed etico, non √® direttamente rilevante in ambito statistico. La domanda cruciale in termini statistici rimane: ‚ÄúQuale approccio √® corretto?‚Äù o, pi√π accuratamente, ‚ÄúQuale √® pi√π utile?‚Äù, piuttosto che ‚ÄúQuale ha avuto i sostenitori pi√π disgustosi?‚Äù.\nD‚Äôaltra parte, personalmente ritengo che la risposta di Chivers (2024) sia fondamentalmente inadeguata. Consideriamo uno scenario ipotetico: all‚Äôinterno di una ‚Äútorre d‚Äôavorio‚Äù - che sia la statistica, l‚Äôaccademia o la scienza in generale - la teoria A si dimostra pi√π efficace della teoria B. Tuttavia, al di fuori di questo ambito ristretto, la teoria A, a differenza della B, comporta implicazioni etiche inaccettabili.\nDobbiamo davvero accettare A solo perch√© funziona meglio all‚Äôinterno di questo microcosmo artificiale? Assolutamente no.\nInnanzitutto, le cosiddette ‚Äútorri d‚Äôavorio‚Äù sono mere costruzioni ideologiche. Non esiste una vera demarcazione tra ‚Äúdentro‚Äù e ‚Äúfuori‚Äù questi ambiti. La scienza e l‚Äôetica non operano in compartimenti stagni, ma si influenzano reciprocamente in un continuo dialogo.\nInoltre, nel caso specifico del frequentismo, √® evidente - come dimostreremo in seguito - che questo metodo √® intrinsecamente fallace, indipendentemente dal contesto in cui lo si applichi. La sua presunta efficacia all‚Äôinterno di un ambito ristretto √® illusoria e non giustifica in alcun modo le sue implicazioni problematiche. Non possiamo e non dobbiamo separare l‚Äôefficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce non solo sul piano morale, ma anche su quello scientifico, rendendo la sua difesa insostenibile su tutti i fronti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "90¬† Introduzione all‚Äôinferenza frequentista",
    "section": "90.2 Stime, stimatori e parametri",
    "text": "90.2 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si √® interessati a una quantit√† a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantit√† sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore √® una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune propriet√† della popolazione di cui il campione √® rappresentativo. Il parametro rappresenta la misura di tali propriet√†, ma spesso non √® possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima √® quindi l‚Äôapprossimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore √® la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilit√† del campionamento. In questo capitolo esamineremo come l‚Äôapproccio frequentista quantifica l‚Äôincertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "90¬† Introduzione all‚Äôinferenza frequentista",
    "section": "90.3 Distribuzione campionaria",
    "text": "90.3 Distribuzione campionaria\nIn questo capitolo, affronteremo il problema dell‚Äôutilizzo della media di un campione casuale per stimare il parametro \\(\\mu\\) corrispondente alla media della popolazione da cui √® stato estratto il campione. Per caratterizzare l‚Äôincertezza della stima di un parametro, l‚Äôapproccio frequentista utilizza lo strumento statistico della distribuzione campionaria.\nPer comprendere il concetto di distribuzione campionaria, considereremo il caso di una popolazione finita di dimensioni ridotte. Tuttavia, le stesse propriet√† che esamineremo si applicano alle popolazioni di qualsiasi dimensione.\nIn questa simulazione, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL‚Äôistogramma sottostante descrive la distribuzione di frequenza della popolazione.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(\n    x,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nPrendiamo ora in considerazione l‚Äôestrazione di tutti i campioni possibili di dimensione \\(n\\) = 2 dalla popolazione.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nPer ottenere un array con tutte le possibili coppie di valori estratti dall‚Äôarray x, possiamo utilizzare la funzione product del modulo itertools. Impostiamo l‚Äôargomento repeat a 2 per indicare che vogliamo coppie di valori. Successivamente, convertiamo la lista di tuple risultante in un array NumPy utilizzando la funzione np.array, e infine stampiamo il risultato. L‚Äôoutput ottenuto sar√† un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie di valori che possono essere estratti dall‚Äôarray x.\nCalcoliamo il numero totale di campioni di ampiezza \\(n\\) = 2.\n\nlen(list(itertools.product(x, x)))\n\n16\n\n\nOra procediamo al calcolo della media per ciascun campione. Questo insieme di valori rappresenta la distribuzione campionaria delle medie dei campioni con dimensione \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), utilizziamo la funzione mean del modulo NumPy e la applichiamo lungo l‚Äôasse delle colonne dell‚Äôarray di coppie di valori. In questo modo otteniamo un array unidimensionale contenente la media di ciascuna coppia di valori.\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x √® fornita qui sotto.\n\nplt.hist(\n    means,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x. Sappiamo che, se la variabile aleatoria \\(X\\) √® distribuita con media \\(\\mu\\) e varianza \\(\\sigma^2\\), allora la media della distribuzione dei campioni casuali indipendenti di ampiezza \\(n\\) = 2 sar√†:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu.\n\\]\nVerifichiamo che ci√≤ sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\nVerifichiamo che la varianza della distribuzione dei campioni casuali indipendenti di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione \\(X\\) con varianza \\(\\sigma^2\\) sia \\(\\mathbb{V}(\\bar{X})=\\sigma^2/n\\).\nConsiderando la definizione di varianza, possiamo scrivere:\n\\[\n\\begin{aligned}\n\\mathbb{V}(\\bar{X}) &= \\mathbb{E}[(\\bar{X}-\\mu_{\\bar{X}})^2] \\\\\n&= \\mathbb{E}[(\\bar{X} - \\mu)^2] \\\\\n&= \\mathbb{E}[(X_1+X_2)/2 - \\mu)^2] \\\\\n&= \\mathbb{E}[((X_1 - \\mu) + (X_2 - \\mu))/2)^2] \\\\\n&= \\mathbb{E}[(X_1 - \\mu)^2/4 + (X_2 - \\mu)^2/4 + (X_1 - \\mu)(X_2 - \\mu)/2)] \\\\\n&= \\frac{1}{4}\\mathbb{E}[(X_1 - \\mu)^2] + \\frac{1}{4}\\mathbb{E}[(X_2 - \\mu)^2] + \\frac{1}{2}\\mathbb{E}[(X_1 - \\mu)(X_2 - \\mu)] \\\\\n&= \\frac{1}{4}\\mathbb{V}(X_1) + \\frac{1}{4}\\mathbb{V}(X_2) + \\frac{1}{2}\\mathbb{C}(X_1,X_2) \\\\\n&= \\frac{\\sigma^2}{4} + \\frac{\\sigma^2}{4} + 0 \\\\\n&= \\frac{\\sigma^2}{2}\n\\end{aligned}\n\\]\nDove \\(\\mu_{\\bar{X}}\\) √® la media della distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) e \\(\\mathbb{C}(X_1,X_2)\\) √® la covarianza tra \\(X_1\\) e \\(X_2\\). In questo caso, dato che i campioni sono estratti in modo casuale e indipendente, la covarianza tra \\(X_1\\) e \\(X_2\\) √® 0. Pertanto, abbiamo dimostrato che \\(\\mathbb{V}(\\bar{X})=\\sigma^2/n\\) per \\(n=2\\).\nIl valore teorico della varianza delle medie dei campioni √® dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione √® diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione √® diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, si presti attenzione a due aspetti importanti:\n\nla media della distribuzione delle medie campionarie √® uguale alla media della popolazione,\nla varianza della distribuzione delle medie campionarie √® minore della varianza della popolazione, ovvero √® pari alla varianza della popolazione divisa per l‚Äôampiezza campionaria.\n\nQuesti due risultati che abbiamo ottenuto empiricamente nella simulazione possono essere espressi in maniera formale dicendo che la media di campioni casuali estratti con ripetizione da una popolazione finita (oppure da una popolazione infinita) di media \\(\\mu\\) e varianza \\(\\sigma^2\\) ha valore atteso $ ({X}_n) = $ e varianza $ ({X}_n) = . $\nInoltre, se la popolazione segue una distribuzione normale, allora per le propriet√† della distribuzione normale, anche la distribuzione delle medie dei campioni seguir√† una distribuzione normale. Al contrario, se la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all‚Äôaumentare delle dimensioni del campione, la distribuzione delle medie dei campioni tender√† a una distribuzione normale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "90¬† Introduzione all‚Äôinferenza frequentista",
    "section": "90.4 Teorema del Limite Centrale",
    "text": "90.4 Teorema del Limite Centrale\nEsaminiamo ora pi√π in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostr√≤ il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 90.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tender√† a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC pu√≤ essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l‚Äôaltezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalit√† della distribuzione risultante. Questa √® la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\nPer illustrare il TLC, utilizziamo una simulazione. Consideriamo una popolazione iniziale fortemente asimmetrica, come una distribuzione Beta(2, 1). Estraiamo da questa popolazione 50,000 campioni di ampiezza \\(n\\) e costruiamo la distribuzione campionaria di tali campioni.\n\n# parameters of the beta\na=2\nb=1\n\ndef plotSamples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n          v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together \n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(sample_means)\n    ax2 = ax.twinx()\n    sns.lineplot(x=x,y=y, ax=ax2, color='black')\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l‚Äôampiezza campionaria √® 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplotSamples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non √® certamente Normale, inizia ad avvicinarsi alla gaussianit√†.\n\nplotSamples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c‚Äô√® ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l‚Äôapprossimazione migliora.\n\nplotSamples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplotSamples(30)\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) mostra che, salvo per campioni molto piccoli, la distribuzione campionaria della media dei campioni pu√≤ essere ben approssimata dalla Normale, indipendentemente dalla forma della distribuzione della popolazione. Ci√≤ significa che, per campioni sufficientemente grandi, il TLC ci fornisce una formula esplicita per la forma della distribuzione campionaria della media dei campioni, anche in assenza di conoscenze sulla popolazione di media \\(\\mu\\) e deviazione standard \\(\\sigma\\): \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).\nIl risultato del TLC ha una grande utilit√† in molti ambiti. Infatti, ci aiuta a comprendere perch√© i risultati degli esperimenti con un grande numero di osservazioni sono pi√π affidabili rispetto a quelli con un numero ridotto di osservazioni. Inoltre, il TLC ci fornisce una formula esplicita per l‚Äôerrore standard (\\(\\sigma/\\sqrt{n}\\)), che ci consente di valutare l‚Äôaffidabilit√† degli esperimenti al variare della dimensione del campione.\nNegli esperimenti psicologici, molti dei fenomeni che vogliamo misurare sono in realt√† medie di molteplici variabili (ad esempio, l‚Äôintelligenza ‚Äúgenerale‚Äù misurata dal QI √® una media di un gran numero di abilit√† specifiche), e in questi casi la quantit√† media segue una distribuzione normale. Questa legge matematica ci permette di osservare spesso la distribuzione normale nei dati degli esperimenti psicologici e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "90¬† Introduzione all‚Äôinferenza frequentista",
    "section": "90.5 Distribuzioni campionarie di altre statistiche",
    "text": "90.5 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente √® possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l‚Äôapprossimazione empirica della distribuzione campionaria del valore massimo del campione. √à chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sar√† maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax)\nax2 = ax.twinx()\n_ = sns.lineplot(x=x, y=y, ax=ax2, color=\"black\")\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni √® particolarmente interessante. Per calcolare la varianza, iniziamo usando la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCreiamo ora un grafico che rappresenta l‚Äôapprossimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza, usando la procedura descritta in precedenza.\nSappiamo che la varianza della popolazione √® uguale a \\(15^2 = 225\\). Tuttavia, calcolando la varianza con la formula della statistica descrittiva otteniamo, in media, un valore minore. Dunque, l‚Äôutilizzo della formula precedente conduce a una stima troppo piccola della varianza della popolazione. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n176.76365773544788\n\n\n\n\n\n\n\n\n\nQuesta dimostrazione ci fa dunque capire come\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nnon sia uno stimatore adeguato per la varianza della popolazione.\nAbbiamo gi√† visto per√≤ che questo problema trova una semplice soluzione nel momento in cui usiamo usiamo il seguente stimatore per la varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\nVerifichiamo.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n224.19924816630638\n\n\n\n\n\n\n\n\n\nLa discrepanza tra la stima di un parametro e il suo vero valore √® definita come errore di stima. Uno stimatore √® considerato non distorto (unbiased) se, in media, le sue stime su diversi campioni ipotetici coincidono con il valore del parametro che si intende stimare, ossia se l‚Äôerrore medio di stima √® nullo.\nNel corso di questo capitolo, abbiamo osservato che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) costituisce uno stimatore non distorto di \\(\\mu\\), mentre \\(\\frac{\\sum_{i=1}^n{(X_i - \\bar{X})^2}}{n-1}\\) √® uno stimatore non distorto di \\(\\sigma^2\\). Questo implica che lo stimatore \\(\\frac{\\sum_{i=1}^n{(X_i - \\bar{X})^2}}{n-1}\\) presenta una distribuzione campionaria centrata sul vero valore del parametro \\(\\sigma^2\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#considerazioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#considerazioni-conclusive",
    "title": "90¬† Introduzione all‚Äôinferenza frequentista",
    "section": "90.6 Considerazioni conclusive",
    "text": "90.6 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantit√† note e sconosciute nel contesto dell‚Äôinferenza statistica. Questo ci aiuter√† a tenere traccia di ci√≤ che sappiamo e ci√≤ che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\n√à qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nS√¨, ma non √® uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nS√¨, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nS√¨, ma non √® uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione √® la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione √®:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "90¬† Introduzione all‚Äôinferenza frequentista",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv \n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nseaborn   : 0.13.2\narviz     : 0.18.0\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\n\n\n\n\n\n\nChivers, Tom. 2024. Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, Edwin T. 2003. Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>90</span>¬† <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "91¬† Intervallo di confidenza",
    "section": "",
    "text": "Introduzione\nGli intervalli di confidenza sono un pilastro nell‚Äôapproccio frequentista all‚Äôinferenza statistica, fornendo un mezzo per gestire l‚Äôincertezza associata ai risultati delle analisi statistiche. Questo capitolo si propone di esplorare in profondit√† gli intervalli di confidenza, analizzandone il calcolo e la loro interpretazione dal punto di vista frequentista. Sar√† messa in luce la sfida nell‚Äôinterpretare correttamente tali intervalli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>91</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-lintervallo-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-lintervallo-di-confidenza",
    "title": "91¬† Intervallo di confidenza",
    "section": "91.1 Inferenza Statistica Frequentista: L‚ÄôIntervallo di Confidenza",
    "text": "91.1 Inferenza Statistica Frequentista: L‚ÄôIntervallo di Confidenza\nL‚Äôintervallo di confidenza √® un concetto fondamentale nell‚Äôapproccio frequentista alla statistica. Questo strumento √® impiegato per valutare la variabilit√† della stima di un parametro di interesse all‚Äôinterno di una popolazione, partendo da un campione di essa.\nAl centro di questo metodo si trova l‚Äôerrore standard, che misura la deviazione standard della distribuzione campionaria di uno stimatore. Questo indice quantifica quanto la stima del parametro si discosta, in media, dal valore effettivo del parametro nella popolazione. Gli statistici frequentisti sfruttano l‚Äôerrore standard per definire l‚Äôintervallo di confidenza, che rappresenta un intervallo di valori entro cui si ritiene si trovi il vero valore del parametro, come ad esempio la media della popolazione.\nPer comprendere l‚Äôintervallo di confidenza da una prospettiva frequentista √® essenziale il concetto di ‚Äúprocedura di stima‚Äù. In base a questo approccio, l‚Äôintervallo di confidenza viene costruito in modo che, se la medesima procedura fosse ripetuta su diversi campioni della stessa popolazione, una determinata percentuale degli intervalli di confidenza (ad esempio, il 95%) includerebbe il vero valore del parametro della popolazione.\nIn terminologia frequentista, quindi, non si afferma che un dato intervallo di confidenza possieda una probabilit√† del 95% di contenere il vero valore del parametro. Piuttosto, si sostiene che, seguendo lo stesso metodo di stima, il 95% degli intervalli di confidenza derivati da campioni differenti racchiuderebbe il vero valore del parametro.\nIn questo quadro, l‚Äôintervallo di confidenza non √® una dichiarazione sulla probabilit√† che un particolare intervallo includa il valore del parametro, ma piuttosto un‚Äôaffermazione sulla regolarit√† con cui gli intervalli calcolati in un determinato modo riescono a catturare il valore del parametro quando si ripete il medesimo processo su vari campioni. Questa distinzione √® cruciale per una corretta comprensione dell‚Äôapproccio frequentista all‚Äôinferenza statistica.\nMentre quest‚Äôinterpretazione dell‚Äôintervallo di confidenza pu√≤ apparire controintuitiva e talvolta poco pratica, riflette il contrasto con l‚Äôapproccio bayesiano, il quale enfatizza l‚Äôaggiornamento delle probabilit√† sulla base di nuove informazioni, a differenza dell‚Äôapproccio frequentista, che si basa sulla ripetizione degli esperimenti e sulla valutazione della variabilit√† campionaria.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>91</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#determinazione-dellintervallo-di-confidenza-per-una-media",
    "href": "chapters/frequentist_inference/02_conf_interv.html#determinazione-dellintervallo-di-confidenza-per-una-media",
    "title": "91¬† Intervallo di confidenza",
    "section": "91.2 Determinazione dell‚Äôintervallo di Confidenza per una Media",
    "text": "91.2 Determinazione dell‚Äôintervallo di Confidenza per una Media\nNei casi in cui la distribuzione delle statistiche campionarie si avvicina a una distribuzione Normale, l‚Äôintervallo di confidenza al 95% √® calcolato come:\n\\[\n\\hat{\\theta} \\pm 1.96 \\cdot \\text{SE},\n\\]\ndove \\(\\hat{\\theta}\\) rappresenta la stima del parametro e SE l‚Äôerrore standard.\n\n91.2.1 Derivazione dell‚ÄôIntervallo di Confidenza per una Popolazione Normale con Varianza Nota\nConsideriamo una popolazione che segue una distribuzione normale con una media nota \\(\\mu\\) e varianza \\(\\sigma^2\\). Prendiamo un campione casuale di dimensione \\(n\\) da questa popolazione, indicato come \\(X_1, X_2, \\dots, X_n\\). Grazie alle propriet√† delle distribuzioni normali, la media campionaria \\(\\bar{X}\\) segue anch‚Äôessa una distribuzione normale, nello specifico \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)\\).\n\n91.2.1.1 Passo 1: Standardizzazione della Media Campionaria\n\nPer standardizzare la media campionaria in una variabile distribuita normalmente standard, sottraiamo la media della popolazione \\(\\mu\\) e dividiamo per lo scarto standard della media campionaria \\(\\sigma/\\sqrt{n}\\). Ci√≤ porta alla seguente trasformazione:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim \\mathcal{N}(0, 1).\n\\]\n\n\n\n91.2.1.2 Passo 2: Stabilire il Livello di Confidenza\n\nDefiniamo un livello di confidenza \\(\\gamma = 1 - \\alpha\\), ad esempio \\(\\gamma = 0.95\\) per un livello di confidenza del 95%.\nIdentifichiamo il valore critico \\(z\\), corrispondente al quantile \\((1 - \\alpha/2)\\) della distribuzione normale standard. Il valore \\(z\\) rappresenta il punto di taglio alle estremit√† della distribuzione:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\n\n\n\n91.2.1.3 Passo 3: Formulazione dell‚ÄôIntervallo di Confidenza\n\nCon il valore \\(z\\) definito, formuliamo l‚Äôintervallo di confidenza per la media della popolazione:\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\n\n\n\n91.2.1.4 Passo 4: Manipolazione Algebrica per Definire i Limiti\n\nRielaboriamo la disuguaglianza per esporre i limiti dell‚Äôintervallo di confidenza:\n\\[\n\\begin{align}\nP\\bigg(-z \\leq &\\frac{ \\bar{X} - \\mu } {\\sigma} \\sqrt{n} \\leq z\\bigg) = \\gamma\\notag\\\\\nP\\bigg(-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq  &\\bar{X} - \\mu \\leq z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\nP\\bigg(-\\bar{X}-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq &-\\mu \\leq -\\bar{X} + z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\nP\\bigg(\\bar{X}+z \\frac{\\sigma}{\\sqrt{n}} \\geq &\\mu \\geq  \\bar{X} -z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma.\\notag\n\\end{align}\n\\]\n\n\n\n91.2.1.5 Passo 5: Specificazione dei Limiti dell‚ÄôIntervallo\n\nDefiniamo i limiti dell‚Äôintervallo di confidenza, \\(\\hat{a}\\) e \\(\\hat{b}\\), come segue:\n\\[\n\\hat{a} = \\bar{X} - z \\frac{\\sigma}{\\sqrt{n}},\n\\quad \\hat{b} = \\bar{X} + z \\frac{\\sigma}{\\sqrt{n}},\n\\]\ncon \\(P(\\hat{a} \\leq \\mu \\leq \\hat{b}) = \\gamma\\).\n\n\n\n91.2.1.6 Conclusione:\n\nL‚Äôintervallo di confidenza \\((\\hat{a}, \\hat{b})\\) racchiude il vero valore della media della popolazione \\(\\mu\\) con una probabilit√† \\(\\gamma\\).\n\n\n\n\n91.2.2 Stima dell‚ÄôIntervallo di Confidenza per Popolazioni Normali con Varianza Incognita\nIn contesti reali, quando si preleva un campione \\(X_1, \\dots, X_n\\) da una popolazione, la varianza \\(\\sigma^2\\) della popolazione √® spesso incognita. Questo aggiunge incertezza riguardo alla media della popolazione \\(\\mu\\), che √® il parametro di interesse. In questi casi, si adotta la distribuzione t di Student per la stima dell‚Äôintervallo di confidenza della media \\(\\mu\\), a causa della varianza incognita.\n\n91.2.2.1 Passo 1: Impiego della Distribuzione t di Student\n\nApplichiamo la formula seguente per calcolare l‚Äôintervallo:\n\\[\nP\\left(‚àít^{\\ast} \\leq \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}} \\leq t^{\\ast}\\right) = \\gamma,\n\\]\ndove \\(\\gamma = 1 - \\alpha\\) √® il livello di confidenza, \\(s\\) √® la stima della deviazione standard \\(\\sigma\\) della popolazione, e \\(t^{\\ast}\\) √® il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione t con \\(n‚àí1\\) gradi di libert√†.\n\n\n\n91.2.2.2 Passo 2: Determinazione dei Limiti dell‚ÄôIntervallo di Confidenza\n\nCalcoliamo i limiti inferiore \\(\\hat{a}\\) e superiore \\(\\hat{b}\\) dell‚Äôintervallo di confidenza cos√¨:\n\\[\n\\hat{a} = \\bar{X} - t^{\\ast} \\frac{s}{\\sqrt{n}},\n\\quad \\hat{b} = \\bar{X} + t^{\\ast} \\frac{s}{\\sqrt{n}}.\n\\]\n\nIn queste circostanze, si sostituisce la varianza sconosciuta \\(\\sigma^2\\) con la sua stima \\(s\\) e si utilizza la distribuzione t di Student invece della normale.\nApplicabilit√† e Limitazioni:\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e √® valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non √® normalmente distribuita e la dimensione del campione √® ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell‚Äôintervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>91</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "91¬† Intervallo di confidenza",
    "section": "91.3 Livello di Copertura",
    "text": "91.3 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia √® fondamentale considerare il concetto di ‚Äúlivello di copertura‚Äù. Questo livello indica la frequenza con cui l‚Äôintervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura: - Se il livello di copertura √® del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterr√† il valore vero del parametro. - Importante: Questo non implica che ci sia una probabilit√† del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione √® un valore fisso e non soggetto a probabilit√†; piuttosto, l‚Äôincertezza risiede nell‚Äôintervallo di fiducia stesso.\nCome Funziona la Copertura: - Nel contesto frequentista, la ‚Äúprobabilit√†‚Äù si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell‚Äôesperimento. - Nel caso degli intervalli di fiducia, l‚Äô‚Äúesperimento‚Äù √® l‚Äôestrazione di un campione dalla popolazione, e l‚Äô‚Äúevento‚Äù √® la generazione di un intervallo di fiducia che contiene il valore vero del parametro. - Il livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilit√† a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n91.3.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm¬≤.\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l‚Äôintervallo di fiducia al 95% usando la formula:\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) √® la media campionaria, \\(s\\) √® la deviazione standard campionaria e \\(t\\) √® il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libert√† al livello di significativit√† \\(\\alpha/2 = 0.025\\).\nRegistriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\n\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIniziamo generando 1000 campioni casuali di dimensione \\(n=30\\) da una distribuzione normale con media \\(175\\) e deviazione standard \\(7\\).\n\nmu = 175\nsigma = 7\nn = 30\nn_samples = 1000\n\nsamples = np.stack([np.random.normal(loc=mu, scale=sigma, size=n) for i in range(n_samples)])\nsamples.shape\n\n(1000, 30)\n\n\nIl primo campione di ampiezza \\(n\\) = 30 che abbiamo ottenuto √® il seguente.\n\nprint(samples[1, :])\n\n[164.73077142 178.36458698 178.37872685 174.13939428 171.93750167\n 183.62660835 166.47855379 166.14290722 190.11028319 178.59315899\n 171.1696638  173.70591366 170.78474733 175.70917764 168.69153018\n 177.18965061 184.68306022 180.57048893 182.54977759 179.74984648\n 167.07981468 185.24317632 176.86968895 177.70411011 171.09097822\n 166.88189761 176.52572538 175.31383448 173.88320882 169.05527411]\n\n\nStampiamo qui di seguito le medie dei primi dieci campioni.\n\nxbar = samples.mean(axis=1)\nprint(xbar[0:10])\n\n[176.37407572 175.23180193 174.58152045 176.40365999 176.74312635\n 174.17121749 174.48572499 174.18025492 175.07399899 176.36952714]\n\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con (30-1) gradi di libert√†.\n\nalpha = 0.05\nt = st.t.ppf(1 - alpha/2, n-1)\nt\n\n2.0452296421327034\n\n\nUtilizzando le informazioni precedenti, calcoliamo 1000 intervalli di confidenza per la media della popolazione.\n\ninterval_width = t * samples.std(axis=1, ddof=1) / np.sqrt(n)\nCI_low = samples.mean(axis=1) - interval_width\nCI_high = samples.mean(axis=1) + interval_width\n\nTroviamo ora il livello di copertura, ovvero il numero di volte in cui l‚Äôintervallo di confidenza calcolato contiene il vero valore del parametro.\n\ncoverage_p = np.sum(np.logical_and(CI_low &lt; mu, mu &lt; CI_high)) / samples.shape[0]\ncoverage_p\n\n0.958\n\n\nIn conclusione, ripetendo la simulazione per 1000 volte, abbiamo ottenuto una proporzione di intervalli di confidenza del 95% che contengono il parametro (ovvero il livello di copertura) molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\).\n\n\n91.3.2 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l‚Äôapproccio frequentista, l‚Äôintervallo di confidenza si deve considerare come una metodologia: - Se ripetiamo l‚Äôesperimento (estrarre un campione e calcolare l‚Äôintervallo di confidenza) molte volte, il metodo produce un intervallo che coprir√† il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n91.3.3 Un Malinteso Comune nell‚ÄôInterpretazione degli Intervalli di Confidenza\n√à inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilit√† del 95%. Questo √® un errore diffuso, persino tra i ricercatori, che spesso interpretano l‚Äôintervallo di confidenza come indicativo della probabilit√† che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all‚Äôinterno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta √® la seguente: - ‚ÄúLa metodologia impiegata per calcolare l‚Äôintervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilit√† di generare un intervallo che include il vero valore del parametro‚Äù. - Ci√≤ significa che l‚Äôintervallo di confidenza non esprime una probabilit√† circa la posizione precisa del parametro, ma riflette la probabilit√† che la procedura adottata per determinarlo generi un intervallo che lo includa.\nIn conclusione, l‚Äôintervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilit√† del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n\n91.3.4 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, {cite}hoekstra2014robust evidenziano come, nonostante l‚Äôampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l‚Äôinferenza statistica. Anche l‚ÄôAmerican Psychological Association (APA) suggerisce che gli intervalli di confidenza siano ‚Äúin generale, la migliore strategia di reportistica‚Äù. Tuttavia, {cite}hoekstra2014robust sottolineano che queste raccomandazioni non considerano la difficolt√† nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l‚Äôinterpretazione degli intervalli di confidenza, Hoekstra et al.¬†hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL‚Äôesperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, {cite}hoekstra2014robust ricordano qual √® l‚Äôinterpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, {cite:t}hoekstra2014robust hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l‚Äôinterpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: ‚ÄúThe 95% confidence interval for the mean ranges from 0.1 to 0.4.‚Äù Please mark each of the statements below as ‚Äòtrue‚Äô or ‚Äòfalse‚Äô.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe ‚Äúnull hypothesis‚Äù that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non √® stata rilevata una differenza di rilievo nell‚Äôinterpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l‚Äôesperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l‚Äôesperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull‚Äôefficacia degli intervalli di confidenza frequentisti e suggerisce che gli ‚Äúintervalli di credibilit√†‚Äù bayesiani possano rappresentare un‚Äôalternativa pi√π vantaggiosa. Quest‚Äôultimi tendono ad essere pi√π intuitivi e di pi√π facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>91</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "91¬† Intervallo di confidenza",
    "section": "91.4 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "91.4 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l‚Äôintervallo di confidenza frequentista e l‚Äôintervallo di credibilit√† bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo √® stimare la media della popolazione da cui sono state tratte queste osservazioni. Per farlo, simuliamo 20 valori casuali da una popolazione che segue una distribuzione normale con media 50 e deviazione standard 10, rappresentata da \\(\\mathcal{N}(50, 10)\\).\n\nsample_size = 20\nmu = 50\nsigma = 10\nsample_data = np.random.normal(loc=mu, scale=sigma, size=n)\nprint(sample_data)\n\n[40.13038118 67.14138507 58.15372819 61.87080597 70.28823876 58.64307551\n 55.41941724 67.9643939  42.76867878 58.37573589 51.38804991 46.78454195\n 36.63322195 44.69934389 56.11884628 40.82879678 45.90438324 45.45382291\n 40.89898539 49.55213524 64.12932274 50.47661058 53.19291531 52.46171204\n 47.98108743 41.26631945 66.63886733 58.25433261 50.31265781 60.7856227 ]\n\n\n\n_ = plt.hist(sample_data, density=True)\n\n\n\n\n\n\n\n\n\n91.4.1 Intervallo di Confidenza Frequentista\nQuando ci si avvicina al problema di stimare la media della popolazione, \\(\\mu\\), attraverso un approccio frequentista, uno dei metodi pi√π comuni √® la stima puntuale. Questo metodo consiste nell‚Äôutilizzare un unico valore, solitamente la media del campione, per rappresentare il parametro della popolazione che non conosciamo.\nLa media campionaria, indicata come \\(\\hat{\\mu}\\), √® una scelta frequente per la stima puntuale della media della popolazione, \\(\\mu\\). Si calcola sommando tutti i valori osservati nel campione, ovvero \\(X_1, X_2, ..., X_n\\), e dividendo questa somma per il numero totale di osservazioni nel campione, \\(n\\):\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nApplicando questa formula ai dati del nostro esempio, otteniamo\n\nsample_mean = np.mean(sample_data)\nsample_mean\n\n52.81724720110726\n\n\nMentre le stime puntuali offrono un valore specifico per rappresentare il parametro della popolazione, non riescono da sole a descrivere completamente l‚Äôincertezza associata a questa stima. Per affrontare questa lacuna, l‚Äôapproccio frequentista si avvale degli intervalli di confidenza. Un intervallo di confidenza fornisce una gamma di valori all‚Äôinterno dei quali si presume che il vero parametro della popolazione cada, basandosi sui dati osservati. Questo intervallo viene definito aggiungendo e sottraendo un margine di errore alla stima puntuale:\n\\[\\hat{\\mu} \\pm m = [\\hat{\\mu} - m, \\hat{\\mu} + m].\\]\nIl margine di errore, che riflette la variabilit√† dei dati del campione, dipende sia dal livello di confidenza scelto, indicato come \\(1-\\alpha\\), sia dalla dimensione del campione, \\(n\\). Ad esempio, un intervallo di confidenza del 95% significa che ci si aspetta che l‚Äôintervallo includa il vero parametro della popolazione nel 95% delle applicazioni di questa procedura.\nIl margine di errore si calcola normalmente attraverso l‚Äôerrore standard (SE) della stima puntuale, e viene definito da:\n\\[m = t_{1-\\frac{\\alpha}{2}, n-1} \\times SE,\\]\ndove \\(t_{1-\\frac{\\alpha}{2}, n-1}\\) rappresenta il valore critico dalla distribuzione t per il livello di confidenza desiderato e \\(n-1\\) gradi di libert√†.\nL‚Äôerrore standard della media campionaria si ottiene dividendo la deviazione standard del campione, \\(\\sigma\\), per la radice quadrata della dimensione del campione:\n\\[SE = \\frac{\\sigma}{\\sqrt{n}}.\\]\nApplicando questa formula ai dati del nostro esempio, la deviazione standard del campione risulta\n\nsample_stddev = np.std(sample_data, ddof=1)\nsample_stddev\n\n9.359341680068068\n\n\nL‚Äôerrore standard della media √®\n\nstandard_error = sample_stddev / np.sqrt(sample_size)\nprint(standard_error)\n\n2.092812422127929\n\n\nL‚Äôerrore standard della media rappresenta una stima della deviazione standard della distribuzione delle medie campionarie per campioni di dimensione \\(n\\) (in questo caso, \\(n\\) = 20).\nSupponiamo di voler avere un livello di confidenza del 95%. Per trovare il valore critico della distribuzione \\(t\\) di Student, dobbiamo trovare il valore della statistica \\(T\\) che lascia il 2.5% dell‚Äôarea sotto la coda a sinistra e il 2.5% dell‚Äôarea sotto la coda a destra della distribuzione \\(t\\) di Student con 19 gradi di libert√†.\n\ndegrees_of_freedom = sample_size - 1\nt_val = st.t.ppf(0.975, degrees_of_freedom)\nprint(t_val)\n\n2.093024054408263\n\n\nIl margine d‚Äôerrore √® uguale a\n\\[t \\cdot SE\\]\novvero\n\nmargin_of_error = t_val * standard_error\nprint(margin_of_error)\n\n4.380306740878175\n\n\nL‚Äôintervallo di confidenza frequentista √® uguale a\n\\[\\text{stima del parametro} \\pm \\text{margine d'errore}\\]\novvero\n\\[\\bar{x} \\pm t_{\\text{critico}} \\frac{s}{\\sqrt{n}}.\\]\nPer i dati dell‚Äôesempio otteniamo\n\nconfidence_interval_lower = sample_mean - margin_of_error\nconfidence_interval_upper = sample_mean + margin_of_error\nconfidence_interval = [confidence_interval_lower, confidence_interval_upper]\nprint(confidence_interval)\n\n[48.43694046022908, 57.19755394198543]\n\n\nInterpretiamo questo risultato dicendo che la procedura utilizzata per calcolare l‚Äôintervallo \\([42.99, 53.23]\\) include \\(\\mu\\) nel 95% dei casi.\nLa figura successiva mostra la distribuzione dei dati, la stima di \\(\\mu\\) (ovvero, la media del campione) e l‚Äôintervalli di confidenza al 95%.\n\ndef visualize_output(sample_data, sample_mean, interval, type_interval):\n    plt.hist(sample_data, density=True, alpha=0.5)\n    plt.axvline(x=sample_mean, linestyle='dashed', linewidth=2)\n    plt.axvline(x=interval[0], linewidth=2)\n    plt.axvline(x=interval[1], linewidth=2)\n    plt.legend(['Sample Mean', f'{type_interval} interval'])\n\n\nvisualize_output(sample_data, sample_mean, confidence_interval, 'confidence')\n\n\n\n\n\n\n\n\n\n\n91.4.2 Intervallo di Credibilit√† Bayesiano\nPer determinare l‚Äôintervallo di credibilit√† bayesiano, impieghiamo un modello statistico basato sulla distribuzione Normale, integrando distribuzioni a priori che forniscono informazioni iniziali limitate sui parametri. Questa strategia ci consente di inserire delle conoscenze preliminari, pur essendo vaghe, nell‚Äôanalisi statistica.\nDettagli sulle scelte delle distribuzioni a priori: - Per il parametro \\(\\mu\\), impostiamo una distribuzione a priori centrata intorno allo zero, con una deviazione standard piuttosto ampia. Come alternativa, si potrebbe considerare di centrare la distribuzione a priori sulla media campionaria. - Per il parametro \\(\\sigma\\), adottiamo una distribuzione Normale troncata, posizionata anch‚Äôessa intorno allo zero, ma con una deviazione standard notevolmente grande.\nLa scelta di centrare le distribuzioni a priori sullo zero √® volta a evitare l‚Äôintroduzione di bias nell‚Äôanalisi, tendendo verso una stima conservativa, ossia una stima del parametro incline allo zero. La decisione di usare deviazioni standard molto ampie riflette la debolezza delle informazioni preliminari che abbiamo incorporato nel modello.\nCi√≤ detto, abbiamo introdotto alcune conoscenze iniziali nell‚Äôanalisi: in particolare, l‚Äôassunzione che valori eccessivamente elevati, sia positivi che negativi, per la media del campione siano improbabili. Questa considerazione riflette una cautela nell‚Äôestimare il parametro, evitando di considerare valori estremi come plausibili.\n\nmodel = pm.Model()\n\nwith model:\n    mu = pm.Normal(\"mu\", mu=0, sigma=200)\n    sigma = pm.HalfNormal(\"sigma\", 100)\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=sample_data)\n\n\nwith model:\n    idata = pm.sample(nuts_sampler=\"numpyro\")\n\n\naz.summary(idata, hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n52.89\n1.84\n49.26\n56.53\n0.04\n0.03\n2432.99\n2087.60\n1.0\n\n\nsigma\n9.77\n1.31\n7.47\n12.45\n0.03\n0.02\n2652.84\n2492.04\n1.0\n\n\n\n\n\n\n\n\nSi noti che, dati i dati specifici e la formulazione del modello bayesiano in uso, l‚Äôintervallo di credibilit√† ottenuto si mostra molto simile all‚Äôintervallo di confidenza calcolato secondo l‚Äôapproccio frequentista. Tuttavia, l‚Äôinterpretazione di questi due intervalli differisce in maniera sostanziale.\nNel caso dell‚Äôintervallo di credibilit√† bayesiano, possiamo affermare che, in base al nostro grado di credenza soggettiva del 95%, la media della popolazione si trova all‚Äôinterno dell‚Äôintervallo specificato. Questo √® un‚Äôaffermazione diretta sulla probabilit√† che la media della popolazione rientri in un determinato intervallo, basata sulle informazioni priori e sui dati osservati.\nIn contrasto, l‚Äôintervallo di confidenza frequentista non permette un‚Äôinterpretazione diretta riguardo alla probabilit√† della media della popolazione di cadere in un dato intervallo. Invece, l‚Äôinterpretazione frequentista indica che, se ripetessimo il processo di campionamento molte volte, il 95% degli intervalli di confidenza calcolati conterrebbe la vera media della popolazione.\nQuindi, mentre l‚Äôintervallo di credibilit√† bayesiano fornisce una misura diretta della credenza nella posizione della media della popolazione, l‚Äôintervallo di confidenza frequentista fornisce una misura di affidabilit√† del processo di stima nel lungo termine.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>91</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "91¬† Intervallo di confidenza",
    "section": "91.5 Riflessioni Conclusive",
    "text": "91.5 Riflessioni Conclusive\nCome sottolineato da {cite:t}hoekstra2014robust, √® comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il ‚Äúlivello di confidenza del 95%‚Äù √® da interpretarsi come la probabilit√† a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non √® possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all‚Äôinterno di un dato intervallo di fiducia non √® garantita per ogni singolo caso analizzato.\n√à inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia pi√π ristretto implichi maggiore precisione. Nella prospettiva frequentista, la ‚Äúprecisione‚Äù √® strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realt√† essere significativamente lontano dal valore vero del parametro non noto.\n√à importante sottolineare che l‚Äôapproccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell‚Äôintervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\n\nIntervallo di confidenza per la differenza tra due medie:\nSe abbiamo due campioni indipendenti di dimensione $ n_1 $ e $ n_2 $, con medie $ {x}_1 $ e $ {x}_2 $ e deviazioni standard $ s_1 $ e $ s_2 $, l‚Äôintervallo di confidenza per la differenza tra le medie √® calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n\\]\nDove $ t_{/2} $ √® il valore critico della distribuzione t di Student con $ /2 $ di probabilit√† di coda e gradi di libert√† $ df = n_1 + n_2 - 2 $.\nIntervallo di confidenza per una proporzione:\nPer stimare l‚Äôintervallo di confidenza per una proporzione $ p $ in un campione binomiale di dimensione $ n $, la formula √®:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nDove $ $ √® la proporzione campionaria e $ z_{/2} $ √® il valore critico della distribuzione normale standard con $ /2 $ di probabilit√† di coda.\nIntervallo di confidenza per la differenza tra due proporzioni:\nPer stimare l‚Äôintervallo di confidenza per la differenza tra due proporzioni $ p_1 $ e $ p_2 $ in due campioni binomiali di dimensioni $ n_1 $ e $ n_2 $, la formula √®:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}}\n\\]\nDove $ _1 $ e $ 2 $ sono le proporzioni campionarie e $ z{/2} $ √® il valore critico della distribuzione normale standard con $ /2 $ di probabilit√† di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>91</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "91¬† Intervallo di confidenza",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun May 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.8.4\narviz     : 0.18.0\nnumpy     : 1.26.4\nscipy     : 1.13.0\npandas    : 2.2.2\npymc      : 5.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>91</span>¬† <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html",
    "title": "92¬† Significativit√† statistica",
    "section": "",
    "text": "Introduzione\nIl test di ipotesi √® un metodo ampiamente utilizzato nella ricerca per fare inferenze sui parametri della popolazione basandosi sui dati campionari. Nel contesto della psicologia, questo metodo √® spesso impiegato per valutare l‚Äôefficacia di interventi psicologici, confrontare diverse teorie o approcci, esplorare le influenze di variabili psicologiche su comportamenti e processi cognitivi, e comprendere meglio i meccanismi sottostanti a fenomeni psicologici complessi come l‚Äôapprendimento, la memoria e le emozioni.\nIn questo capitolo, ci concentreremo sul test di ipotesi frequentista, una procedura ancora comunemente utilizzata. Tuttavia, √® fondamentale sottolineare che la comunit√† statistica sconsiglia l‚Äôuso esclusivo del test di ipotesi frequentista come criterio decisionale per stabilire la validit√† di un risultato sperimentale.\nTradizionalmente, un risultato √® considerato ‚Äústatisticamente significativo‚Äù se √® improbabile che sia dovuto al caso, suggerendo che il risultato sia stabile o reale. Al contrario, i risultati ‚Äúnon significativi‚Äù vengono spesso etichettati come rumorosi e visti con scetticismo. Questa visione semplificata della significativit√† statistica pu√≤ portare a fraintendimenti e conclusioni errate.\nAnalizzeremo come l‚Äôapproccio frequentista, in pratica, non mantenga sempre la sua ‚Äúpromessa‚Äù e come l‚Äôuso della procedura della significativit√† statistica, nella pratica scientifica, possa spesso produrre risultati opposti a quelli desiderati. La significativit√† statistica dipende fortemente dalle dimensioni del campione e da altri fattori. Un risultato non significativo non implica necessariamente che l‚Äôeffetto osservato sia nullo o irrilevante. Inoltre, la significativit√† statistica pu√≤ essere influenzata dalla scelta dei livelli di confidenza e dai test statistici utilizzati, portando a interpretazioni soggettive dei risultati che possono essere fuorvianti.\nPertanto, anzich√© concentrarsi esclusivamente sulla significativit√† statistica, √® preferibile valutare l‚Äôeffetto osservato nel contesto scientifico pi√π ampio e alla luce dei risultati di altre analisi, utilizzando un approccio pi√π completo e critico.\nInfine, in questo capitolo esamineremo il caso specifico della media del campione come stimatore della media della popolazione, esplorando i suoi limiti e le sue applicazioni nella statistica inferenziale di tipo frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi",
    "title": "92¬† Significativit√† statistica",
    "section": "92.1 Il Test di Ipotesi",
    "text": "92.1 Il Test di Ipotesi\nIl test di ipotesi √® un metodo statistico utilizzato per valutare se i dati sono coerenti con l‚Äôipotesi nulla (\\(H_0\\)). L‚Äôipotesi nulla solitamente afferma che non vi √® alcun effetto o differenza significativa, mentre l‚Äôipotesi alternativa (\\(H_1\\)) rappresenta l‚Äôaffermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l‚Äôipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n92.1.1 La procedura di Test di Ipotesi\nPasso 1: Formulare l‚Äôipotesi nulla (\\(H_0\\)) e l‚Äôipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nNOTA: Decidiamo un‚Äôipotesi non direzionale (nota anche come ipotesi bilaterale) quando testiamo effetti in entrambe le direzioni (la pi√π comune), altrimenti un‚Äôipotesi direzionale (nota anche come ipotesi unilaterale).\nPasso 2: Stabilire un livello di significativit√†, Œ± (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nNOTA: Esistono due tipi fondamentali di test statistici, parametrici e non parametrici. I test parametrici (ad esempio, t-test, ANOVA) dipendono da assunzioni sulla distribuzione del parametro studiato. I test non parametrici (ad esempio, test di Mann-Whitney U, test di Kruskal-Wallis) utilizzano un metodo di ordinamento delle misure e non richiedono tali assunzioni. Tuttavia, i test non parametrici sono tipicamente meno potenti dei test parametrici.\nPasso 4: Decidere se il risultato √® ‚Äústatisticamente significativo‚Äù secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL‚Äôapproccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto √® un insieme di valori per il test statistico per i quali l‚Äôipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l‚Äôipotesi nulla.\nL‚Äôapproccio del valore-p.¬†Il valore-p √® la probabilit√† di ottenere i risultati osservati, o risultati ancora pi√π estremi, se l‚Äôipotesi nulla √® vera.\n\nConfrontiamo il valore-p calcolato con il livello di significativit√† Œ±:\n\nSe il valore-p &lt; Œ±, si rifiuta l‚Äôipotesi nulla (\\(H_0\\)).\nSe il valore-p ‚â• Œ±, non si rifiuta l‚Äôipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "92¬† Significativit√† statistica",
    "section": "92.2 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "92.2 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, √® essenziale chiarire cosa si intende per valore-p.\nL‚ÄôAmerican Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione pu√≤ risultare difficile da comprendere perch√© contiene concetti complessi come ‚Äúprobabilit√†‚Äù e ‚Äúmodello statistico specificato‚Äù. Per capire meglio cosa rappresenta un valore-p, √® necessario esaminare attentamente entrambi questi concetti. Questo ci porter√† anche a una comprensione pi√π profonda di altri concetti fondamentali per l‚Äôinferenza frequentista e ci aiuter√† a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l‚Äôapproccio frequentista e quello bayesiano riguarda l‚Äôinterpretazione della probabilit√†: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla ‚Äúcertezza soggettiva‚Äù o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilit√† assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilit√† sia implicita nella definizione del valore-p fornita dall‚ÄôASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell‚ÄôASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o pi√π grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l‚Äôapproccio frequentista pu√≤ essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "92¬† Significativit√† statistica",
    "section": "92.3 Applicazione alla Media Campionaria",
    "text": "92.3 Applicazione alla Media Campionaria\nIn questo capitolo, esploreremo come applicare il processo del test di ipotesi frequentista alla media campionaria. Analizzeremo come utilizzare la media di un campione per fare inferenze sulla media della popolazione, discutendo i limiti e le applicazioni di questo approccio nell‚Äôinferenza statistica frequentista.\nPer comprendere meglio il concetto di valori-p e l‚Äôapplicazione della verifica del test di ipotesi, √® utile ricorrere a delle simulazioni. Queste permettono di replicare condizioni sperimentali ipotetiche e osservare la variabilit√† dei risultati.\n\n92.3.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo gi√† dimostrato che, se la popolazione √® normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguir√† una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) √® la deviazione standard della popolazione e \\(n\\) √® la dimensione del campione).\n\n\n92.3.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall‚Äôipotesi nulla. Questo processo ci permette di valutare la plausibilit√† di \\(\\mu_0\\) come vera media della popolazione.\n\n\n92.3.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall‚Äôipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata √® incompatibile con \\(\\mu_0\\), portando al rigetto dell‚Äôipotesi nulla.\n\n92.3.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l‚Äôevento \\(\\bar{X} &gt; 105\\).\nLa simulazione pu√≤ essere eseguita come segue:\n\n# To make the simulation reproducible\nnp.random.seed(123)\n\nmu_0 = 100\nsigma = 15\nn = 30\nn_sim = 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means = np.random.normal(loc=mu_0, scale=sigma / np.sqrt(n), size=n_sim)\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value = np.sum(sample_means &gt; 105) / n_sim\n\n# Print the p-value\nprint(p_value)\n\n0.0348\n\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l‚Äôipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l‚Äôevento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilit√† di osservare un valore di \\(\\bar{X}\\) cos√¨ estremo (o pi√π estremo) se l‚Äôipotesi nulla fosse vera.\nIl risultato della simulazione pu√≤ essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) √® calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l‚Äôarea sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\nZ = (105 - 100) / (15 / np.sqrt(30))\nprint(Z)\n\n1.8257418583505538\n\n\n\n# Calculate the upper tail probability\nupper_tail_prob = stats.norm.sf(Z)\n\nprint(upper_tail_prob)\n\n0.033944577430914495\n\n\nOppure, in maniera equivalente\n\nupper_tail_prob = 1 - stats.norm.cdf(105, loc=100, scale=15 / np.sqrt(30))\nprint(upper_tail_prob)\n\n0.0339445774309145\n\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 √® 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l‚Äôipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione pu√≤ essere quantificata dalla ‚Äúsorpresa‚Äù indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l‚Äôesperimento viene ripetuto numerose volte sotto l‚Äôipotesi nulla. Questo suggerisce che un risultato del genere √® altamente improbabile se l‚Äôipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#applicazioni-pratiche",
    "title": "92¬† Significativit√† statistica",
    "section": "92.4 Applicazioni pratiche",
    "text": "92.4 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poich√© di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo cos√¨ la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi pu√≤ dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† se il campione casuale √® stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un‚Äôipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† e un livello di significativit√† predefinito, possiamo determinare se i dati osservati supportano o respingono l‚Äôipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-statistiche",
    "title": "92¬† Significativit√† statistica",
    "section": "92.5 Ipotesi statistiche",
    "text": "92.5 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l‚Äôipotesi statistica come una dichiarazione riguardante la distribuzione di probabilit√† di una variabile casuale. Tale ipotesi pu√≤ riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l‚Äôipotesi che riguarda i parametri di una o pi√π popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l‚Äôipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) √® un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L‚Äôipotesi nulla pu√≤ essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene pi√π di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "92¬† Significativit√† statistica",
    "section": "92.6 I passi di un test di ipotesi",
    "text": "92.6 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l‚Äôipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un‚Äôipotesi riguardante una propriet√† di una popolazione di interesse e si pu√≤ descrivere nel modo seguente.\nIniziamo formulando l‚Äôipotesi nulla \\(H_0\\), che rappresenta un‚Äôaffermazione specifica sulla popolazione. L‚Äôipotesi alternativa \\(H_1\\) viene formulata come l‚Äôevento complementare rispetto all‚Äôevento specificato dall‚Äôipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l‚Äôipotesi nulla √® vera.\nSuccessivamente, suddividiamo l‚Äôinsieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la ‚Äúregione di accettazione‚Äù \\(\\mathcal{A}\\) e la sua regione complementare, la ‚Äúregione di rifiuto‚Äù \\(\\mathcal{R}\\). La regione di accettazione rappresenta l‚Äôinsieme dei valori che la statistica pu√≤ assumere sotto l‚Äôipotesi nulla, mentre la regione di rifiuto rappresenta l‚Äôinsieme dei valori che la statistica pu√≤ assumere se l‚Äôipotesi nulla √® falsa.\nInfine, selezioniamo un livello di significativit√† \\(\\alpha\\), che rappresenta la massima probabilit√† di respingere erroneamente l‚Äôipotesi nulla quando questa √® vera. Se l‚Äôosservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l‚Äôipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell‚Äôipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l‚Äôipotesi nulla a favore dell‚Äôipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-alternativa",
    "title": "92¬† Significativit√† statistica",
    "section": "92.7 Ipotesi alternativa",
    "text": "92.7 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l‚Äôipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative pi√π comuni si suddividono in tre tipi:\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\\(H_1: \\theta &gt; \\theta_0\\),\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell‚Äôipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell‚Äôipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell‚Äôipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell‚Äôintervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell‚Äôintervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#valore-p",
    "title": "92¬† Significativit√† statistica",
    "section": "92.8 Valore-p",
    "text": "92.8 Valore-p\nIl valore-p √® definito come la probabilit√† che la statistica del test assuma un valore uguale o pi√π estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l‚Äôipotesi nulla. La significativit√† statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l‚Äôevidenza osservata √® improbabile da ottenere se l‚Äôipotesi nulla √® vera. Se il risultato osservato non raggiunge la significativit√† statistica, significa che la stima non √® statisticamente significativa e che il valore osservato pu√≤ essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#un-esempio-motivante",
    "title": "92¬† Significativit√† statistica",
    "section": "92.9 Un esempio motivante",
    "text": "92.9 Un esempio motivante\nPer esplorare il concetto di significativit√† statistica, possiamo prendere in considerazione uno studio svolto da Mehr, Song, e Spelke (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica √® una forma d‚Äôarte presente in molte attivit√† quotidiane e pu√≤ trasmettere informazioni relative alla cultura e all‚Äôappartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr, Song, e Spelke (2016) √® emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale √® un elemento chiave nella preferenza dei bambini, oltre alla familiarit√† con la canzone.\n\n92.9.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr, Song, e Spelke (2016) si √® concentrata sullo studio dell‚Äôinfluenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l‚Äôipotesi principale non pu√≤ essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l‚Äôipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l‚Äôesperimento condotto sui bambini da Mehr, Song, e Spelke (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video ‚Äúfamiliare‚Äù rispetto al tempo di fissazione totale. Poich√© l‚Äôipotesi principale non pu√≤ essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoich√© nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr, Song, e Spelke (2016), l‚Äôipotesi della ricerca non pu√≤ essere valutata direttamente, √® necessario stabilire una connessione tra l‚Äôipotesi della ricerca e l‚Äôipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sar√† uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l‚Äôipotesi statistica sar√† \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilit√† casuale.\nInfine, una terza possibilit√† √® che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l‚Äôipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell‚Äôesperimento di Mehr, Song, e Spelke (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di et√†. Ogni bambino avr√† una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video ‚Äúfamiliare‚Äù. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video ‚Äúfamiliare‚Äù e possono essere messi in relazione con il modello statistico.\n\n\n92.9.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l‚Äôipotesi della ricerca e l‚Äôipotesi statistica √® cruciale durante il test delle ipotesi. L‚Äôipotesi della ricerca riguarda l‚Äôaffermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l‚Äôipotesi statistica riguarda il modello generativo dei dati, ovvero le propriet√† della popolazione. Nel caso dell‚Äôesperimento condotto da Mehr e colleghi, l‚Äôipotesi della ricerca afferma che la preferenza sociale dei bambini √® influenzata dalla musica e, in particolare, dalla familiarit√† con i materiali musicali. L‚Äôipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video ‚Äúfamiliare‚Äù sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ci√≤ significa che se l‚Äôesperimento non viene condotto nella maniera appropriata, il collegamento tra l‚Äôipotesi statistica e la domanda della ricerca pu√≤ essere spezzato. Ad esempio, se l‚Äôattore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l‚Äôaltro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell‚Äôipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video ‚Äúfamiliare‚Äù √® maggiore di 0.5, ma ci√≤ non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "92¬† Significativit√† statistica",
    "section": "92.10 Ipotesi nulla e ipotesi alternativa",
    "text": "92.10 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento √® stato semplice: il ricercatore ha un‚Äôipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un‚Äôipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le propriet√† suggerite dall‚Äôipotesi della ricerca, allora il ricercatore pu√≤ aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, per√≤, il ragionamento diventa contro-intuitivo perch√© non √® possibile verificare direttamente l‚Äôipotesi statistica che corrisponde alla domanda della ricerca.\n\n92.10.1 Apagogia\nIn linea di principio, non √® mai possibile dimostrare direttamente la verit√† di una proposizione. Tuttavia, possiamo dimostrare la sua verit√† in modo indiretto, ovvero provando la falsit√† della sua proposizione complementare.\nL‚Äôesempio classico √® il seguente. Consideriamo la seguente proposizione: ‚ÄúTutti i cigni sono bianchi‚Äù (questo √® l‚Äôesempio ornitologico preferito da Popper). L‚Äôosservazione di un numero qualsiasi di cigni bianchi non √® sufficiente a dimostrare la verit√† di questa proposizione ‚Äì infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c‚Äô√®). D‚Äôaltra parte, invece, l‚Äôosservazione di un solo cigno che non sia bianco (ovvero, per esempio, l‚Äôosservazione di un cigno nero proveniente dall‚ÄôAustralia) pu√≤ falsificare la proposizione considerata. Questa √® la logica del falsificazionismo di Popper.\nQuesto modo di pensare √® stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l‚Äôipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l‚Äôobiettivo di dimostrare falso l‚Äôevento complementare a quello specificato dall‚Äôipotesi statistica associata alla domanda della ricerca. L‚Äôipotesi statistica che vorremmo falsificare si chiama ‚Äúipotesi nulla‚Äù e viene denotata con \\(H_0\\). Nel caso dell‚Äôesempio che stiamo discutendo, l‚Äôipotesi nulla √®: \\(\\mu \\leq 0.5\\). Si noti che l‚Äôipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che √® associata all‚Äôipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ci√≤ che stiamo facendo √® dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l‚Äôipotesi della ricerca (ovvero, i valori che specificano l‚Äôipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l‚Äôipotesi della ricerca (ovvero, i valori che specificano l‚Äôipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere √® che l‚Äôobiettivo di un test di ipotesi frequentista non √® quello di dimostrare che l‚Äôipotesi alternativa √® (probabilmente) vera; l‚Äôobiettivo √® mostrare che l‚Äôipotesi nulla √® (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n\n92.10.2 La similitudine del processo penale\nUn test di ipotesi √® spesso comparato ad un processo penale, dove l‚Äôipotesi nulla rappresenta l‚Äôimputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Cos√¨ come in un processo penale, anche in un test di ipotesi c‚Äô√® una presunzione di innocenza, dove l‚Äôipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di l√† di ogni ragionevole dubbio, che √® falsa. Il ricercatore progetta l‚Äôesperimento in modo da massimizzare la possibilit√† che i dati producano una condanna dell‚Äôipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l‚Äôipotesi nulla. In particolare, sono studiate per garantire che la probabilit√† di una condanna sia bassa se l‚Äôipotesi nulla √® effettivamente vera. √à importante sottolineare che l‚Äôipotesi nulla deve essere protetta, poich√© il ricercatore sta cercando di dimostrare che essa √® falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#due-tipi-di-errori",
    "title": "92¬† Significativit√† statistica",
    "section": "92.11 Due tipi di errori",
    "text": "92.11 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico √® utile capire la logica su cui esso √® basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere pi√π espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, per√≤, questo non √® possibile: a volte il ricercatore √® sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, pu√≤ succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ci√≤ sembra fornire una prova molto forte del fatto che la moneta √® sbilanciata, ma c‚Äô√® una possibilit√† su 1024 che ci√≤ accada anche se la moneta √® equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilit√† che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l‚Äôobiettivo dei test delle ipotesi statistiche non √® quello di eliminare completamente gli errori (questo √® impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per ‚Äúerrori‚Äù. Iniziamo con il rendere esplicito quello che √® ovvio: l‚Äôipotesi nulla pu√≤ essere vera o falsa, e il nostro test ci pu√≤ condurre a rifiutare l‚Äôipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l‚Äôipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L‚Äôerrore di I tipo, denotato con \\(\\alpha\\), √® quello che commettiamo se rigettiamo l‚Äôipotesi nulla quando essa √® vera; l‚Äôerrore di II tipo, denotato con \\(\\beta\\), √® quello che commettiamo se accettiamo l‚Äôipotesi nulla mentre invece √® vera l‚Äôipotesi alternativa.\n\n\n92.11.1 Errore di I tipo: la protezione dei diritti dell‚Äôimputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell‚Äôimputato ‚Äúoltre ogni ragionevole dubbio‚Äù. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilit√† di condannare ingiustamente un imputato innocente: il processo penale √® progettato (almeno in teoria) per proteggere i diritti dell‚Äôimputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L‚Äôerrore che consiste nel punire un innocente viene considerato assai pi√π grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilit√† di un errore di I tipo, con l‚Äôobiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilit√†, denotata con \\(\\alpha\\), viene chiamata ‚Äúlivello di significativit√† del test‚Äù. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significativit√† \\(\\alpha\\) se il tasso di errore di I tipo non √® pi√π grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n\n92.11.2 Errore di II tipo: l‚Äôasimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realt√†, vorremmo tenere anche quello sotto controllo e denotiamo la probabilit√† di un errore di II tipo con \\(\\beta\\). Il livello d‚Äôerrore \\(\\beta\\) viene raramente discusso ed √® molto pi√π comune fare riferimento alla potenza del test, che √® la probabilit√† dell‚Äôevento complementare, ovvero la probabilit√† con cui rifiutiamo l‚Äôipotesi nulla quando √® realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto ‚Äúpotente‚Äù quando √® caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilit√† prefissata.\nSi noti l‚Äôasimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente √® preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) ‚Äì questo si ottiene utilizzando un campione sufficientemente grande ‚Äì ma nella logica della costruzione del test di ipotesi questo aspetto √® secondario rispetto alla necessit√† di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "92¬† Significativit√† statistica",
    "section": "92.12 Come si costruisce un test di ipotesi?",
    "text": "92.12 Come si costruisce un test di ipotesi?\nRitorniamo all‚Äôesempio relativo allo studio di Mehr, Song, e Spelke (2016). In questo caso, sulla base all‚Äôipotesi della ricerca, l‚Äôipotesi nulla pu√≤ essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di et√† media pari a 5.6 mesi, Mehr, Song, e Spelke (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video ‚Äúfamiliare‚Äù nel 56% del tempo totale di fissazione. Dunque, la media campionaria √® \\(\\bar{X} = 0.56\\) Questo √® il valore campionario rilevante per il test dell‚Äôipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall‚Äôipotesi nulla. Nel caso presente, l‚Äôipotesi nulla non specifica un unico valore \\(\\mu\\) ma bens√¨ un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non √® incluso nell‚Äôintervallo specificato da \\(H_0\\). Questo √® incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient‚Äôaltro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c‚Äô√® bisogno di eseguire alcun test statistico ‚Äì abbiamo gi√† trovato la risposta alla domanda della ricerca.\n\n92.12.1 La variabilit√† campionaria\nNel caso dell‚Äôesperimento di Mehr, Song, e Spelke (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell‚Äôintervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) √® falsa? Non cos√¨ presto. Non √® sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cio√® positiva, nel nostro caso). √à anche necessario tenere in considerazione il fenomeno della variabilit√† campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) √® una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumer√† un valore diverso da campione a campione. Le statistiche campionarie ‚Äì nel nostro caso la media \\(\\bar{X}\\) ‚Äì sono di necessit√† diverse dai parametri. Ci√≤ a cui noi siamo interessati √® la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non pu√≤ essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, √® ragionevole pensare che, indipendentemente dal fatto che l‚Äôipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sar√† positive mentre in altri campioni sar√† negativa. Dobbiamo dunque trovare una procedura che riduca la possibilit√† di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n\n92.12.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall‚Äôapproccio frequentista per affrontare questo problema √® quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l‚Äôipotesi nulla. Questo √® il concetto pi√π contro-intuitivo di tutta la procedura di test di ipotesi dell‚Äôapproccio frequentista. Esaminiamolo pi√π in dettaglio.\nLo scopo della procedura di test statistici dell‚Äôapproccio frequentista non √® quello di verificare l‚Äôipotesi alternativa: questo non √® logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all‚Äôipotesi nulla, l‚Äôapproccio frequentista si pone l‚Äôobiettivo di determinare se ci siano indizi sufficienti per ‚Äúcondannare‚Äù l‚Äôipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la ‚Äúpresunzione di innocenza‚Äù di \\(H_0\\) corrisponde all‚Äôidea che dobbiamo assumere come vera l‚Äôipotesi nulla fino a prova contraria.\nNell‚Äôesempio che stiamo discutendo, assumere come vera l‚Äôipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell‚Äôesempio presente, √® possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, √® possibile stabilire quanto sia ‚Äúdistante‚Äù dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) √® la media del campione (nel nostro caso, 0.56), \\(s\\) √® la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) √® l‚Äôampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT = (0.56 - 0.50) / (0.179 / np.sqrt(32))\nprint(T)\n\n1.8961522623996823\n\n\n\n\n92.12.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l‚Äôinsieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) √® sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n\n92.12.4 Quando rifiutare l‚Äôipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l‚Äôipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l‚Äôipotesi nulla in favore dell‚Äôipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto √® costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale √® stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto √® situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l‚Äôipotesi alternativa non √® menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cio√® sulla probabilit√† della statistica test condizionata all‚Äôipotesi nulla \\(H_0\\). L‚Äôipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n\n\n92.12.5 Specificazione delle regioni di rifiuto\nL‚Äôipotesi alternativa \\(H_1\\) pu√≤ assumere forme diverse e ci√≤ conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell‚Äôipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell‚Äôipotesi alternativa \\(H_1\\).\n\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) √® un generico parametro e \\(\\theta_0\\) √® uno specifico valore del parametro), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell‚Äôintervallo \\([-\\infty, \\theta_0]\\) e l‚Äôintera regione di rifiuto \\(\\mathcal{R}\\) √® collocata nella coda di sinistra della distribuzione.\nSe l‚Äôipotesi alternativa √® \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l‚Äôipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell‚Äôintervallo \\([\\theta_0, \\infty]\\) e l‚Äôintera regione di rifiuto \\(\\mathcal{R}\\) √® collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilit√† pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilit√† pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n\n92.12.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il ‚Äúrisultato osservato‚Äù ha una ‚Äòpiccola‚Äô probabilit√† subordinatamente all‚Äôipotesi assunta, respingiamo l‚Äôipotesi. (p.¬†441)\n\nOvviamente l‚Äôipotesi a cui von Mises fa riferimento √® l‚Äôipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l‚Äôipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) ‚Äì i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilit√† di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l‚Äôipotesi nulla √® vera. Se il valore-\\(p\\) √® minore del livello di significativit√† \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ci√≤ conduce al rifiuto dell‚Äôipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l‚Äôesempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libert√†. Il valore-p corrisponde dunque all‚Äôarea sottesa ad una \\(t_{31}\\) nell‚Äôintervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\np = 1 - stats.t.cdf(T, 31)\nprint(p)\n\n0.033647093369739034\n\n\nDato che il valore-p √® minore di \\(\\alpha = 0.05\\), Mehr, Song, e Spelke (2016) rifiutano \\(H_0\\) (cio√® che la proporzione media del tempo di fissazione dei bambini nei confronti del video ‚Äúfamiliare‚Äù sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#potenza-del-test",
    "title": "92¬† Significativit√† statistica",
    "section": "92.13 Potenza del test",
    "text": "92.13 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significativit√† e la potenza del test vengono usati per quantificare la qualit√† dell‚Äôinferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa √® vera e dovrebbe respingere \\(H_0\\) in favore dell‚Äôalternativa quando \\(H_1\\) √® vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilit√† indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all‚Äôipotesi che descrive l‚Äôevento ‚Äúnulla di interessante sta succedendo‚Äù ‚Äì ad esempio, ‚Äúla moneta √® bilanciata‚Äù, ‚Äúil trattamento non √® migliore del placebo‚Äù, ecc. ‚Äì e pensare ad \\(H_1\\) come al caso contrario, ovvero: ‚Äústa accadendo qualcosa di interessante‚Äù. Quindi la potenza del test, ovvero la probabilit√† \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa √® falsa, corrisponde alla probabilit√† di rilevare qualcosa di interessante, quando qualcosa di interessante √® effettivamente successo, mentre il livello di significativit√† corrisponde alla probabilit√† di affermare che qualcosa di interessante si √® verificato, quando in realt√† non √® successo nulla di interessante.\nIl calcolo della potenza di un test √® spesso difficile, perch√© richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando √® vera l‚Äôipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosit√† del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale √® importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n92.13.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non √® lineare, poich√© Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una ‚Äúverit√† definitiva‚Äù su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un‚Äôunica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilit√† di osservare, sotto l‚Äôipotesi nulla, il risultato ottenuto o uno ancora pi√π estremo. Se il valore-\\(p\\) √® piccolo, Fisher rifiutava l‚Äôipotesi nulla. Tuttavia, poich√© non venivano formulate altre ipotesi, non c‚Äôera modo di ‚Äúaccettare l‚Äôalternativa‚Äù.\nAl contrario, Neyman adottava un approccio pi√π formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l‚Äôipotesi nulla o l‚Äôalternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l‚Äôipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilit√† del risultato del test o di uno pi√π estremo sotto l‚Äôipotesi nulla, ma forniva una descrizione astratta dei ‚Äúpossibili test‚Äù che portavano all‚Äôaccettazione dell‚Äôipotesi nulla o dell‚Äôalternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un‚Äôipotesi nulla e un‚Äôipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l‚Äôipotesi alternativa, mentre altri sono pi√π vaghi in merito, adottando l‚Äôapproccio di Fisher. Inoltre, c‚Äô√® disaccordo tra i ricercatori riguardo alla possibilit√† di ‚Äúaccettare l‚Äôalternativa‚Äù, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il ‚Äúpeccato originale‚Äù della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi pi√π specifici per cui questo approccio, noto come significativit√† statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilit√† dei risultati della ricerca in psicologia e in altri campi. Nel capitolo Capitolo 97 esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "92¬† Significativit√† statistica",
    "section": "92.14 La Storia del Test dell‚ÄôIpotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "92.14 La Storia del Test dell‚ÄôIpotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l‚Äôanalisi della procedura dei test di ipotesi statistici esaminando l‚Äôevento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell‚Äôinferenza statistica, focalizzata sul test dell‚Äôipotesi nulla. Questo episodio √® descritto dettagliatamente da Etz et al. (2018). L‚Äôaneddoto riguarda un t√® che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contest√≤ il metodo adottato da Fisher, asserendo che il t√® avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell‚Äôacqua bollente. Per verificare l‚Äôaffermazione della Dr.ssa Bristol, Fisher ide√≤ un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del t√® in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalit√† di preparazione? Per risolvere questa questione, Fisher elabor√≤ la sua metodologia per il test dell‚Äôipotesi nulla. Utilizz√≤ un valore-\\(p\\) calcolato sulla base della probabilit√† dell‚Äôevento osservato, nonch√© di qualsiasi altro evento pi√π estremo che potrebbe verificarsi sotto l‚Äôipotesi nulla.\nTuttavia, √® stato fatto notare che l‚Äôapproccio di Fisher al test dell‚Äôipotesi nulla pu√≤ essere insufficiente e portare a conclusioni errate Etz et al. (2018). Una delle questioni fondamentali riguarda la definizione di un evento ‚Äúpi√π estremo‚Äù rispetto a quello osservato. Ad esempio, se Fisher avesse preparato esattamente sei t√® e la Dr.¬†Bristol ne avesse identificati correttamente cinque, il valore-\\(p\\) calcolato sarebbe stato 0.109, che non √® statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l‚Äôipotesi nulla che la Dr.¬†Bristol stesse semplicemente indovinando.\nTuttavia, se Fisher avesse continuato a servire t√® fino a quando la Dr.¬†Bristol non avesse raggiunto cinque risposte corrette (un risultato che, per coincidenza, si √® verificato dopo sei tentativi), il valore-\\(p\\) calcolato sarebbe stato 0.031, che √® statisticamente significativo. In quest‚Äôultimo caso, l‚Äôipotesi nulla sarebbe stata respinta.\nQuello che emerge √® che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni diverse a causa delle diverse modalit√† di campionamento impiegate. Questa variabilit√† √® problematica poich√© il valore-\\(p\\), e quindi la nostra valutazione delle capacit√† discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell‚Äôipotesi nulla come strumento fondamentale per l‚Äôinferenza scientifica.\nPer risolvere il problema discusso in precedenza, utilizzeremo due specifiche distribuzioni statistiche: la distribuzione binomiale e la distribuzione geometrica negativa. L‚Äôanalisi sar√† condotta utilizzando Python come strumento di calcolo.\n\n92.14.1 Distribuzione Binomiale\nLa distribuzione binomiale diventa pertinente quando il numero di tentativi √® prefissato e conosciuto a priori. Nel contesto dell‚Äôesempio del t√®, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilit√† di registrare esattamente $ k $ successi in $ n $ tentativi √® la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) √® la probabilit√† di un singolo successo (ossia di indovinare correttamente la preparazione del t√®), e \\((1-p)\\) √® la probabilit√† di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilit√† di ottenere un risultato di 5 o pi√π successi su un totale di 6 tentativi.\n\n\n92.14.2 Distribuzione Geometrica Negativa\nNel caso in cui continuiamo a servire t√® fino a quando non vengono raggiunti cinque successi, utilizziamo una variante della distribuzione geometrica chiamata distribuzione geometrica negativa. In questo contesto, il valore-\\(p\\) √® calcolato considerando la probabilit√† di avere un certo numero di fallimenti \\(k\\) prima di ottenere cinque successi. In particolare, abbiamo sommato le probabilit√† per \\(k\\) che varia da 0 a \\((6 - 5)\\).\nLa formula per la probabilit√† in una distribuzione geometrica negativa di avere $ k $ fallimenti prima di $ n $ successi √® la seguente:\n\\[\nP(X = k) = \\binom{k+n-1}{k} \\times (1-p)^{k} \\times p^n\n\\]\nDove \\(k\\) rappresenta il numero di fallimenti e \\(n\\) il numero di successi. Il valore-\\(p\\) √® stato calcolato sommando queste probabilit√†.\nQuesto approccio ci permette di calcolare un valore-\\(p\\) che tiene conto del numero di fallimenti prima del quinto successo.\n\n# Parametri\nn_binomial = 6  # Numero fisso di tentativi per la distribuzione binomiale\nn_success = 5  # Numero di successi desiderato\np = 0.5  # Probabilit√† di successo (indovinare la tazza di t√®)\n\n# Calcolo del p-value per la distribuzione binomiale\np_value_binomial = 1 - binom.cdf(n_success - 1, n_binomial, p)\n\n# Calcolo del p-value per la distribuzione geometrica negativa\np_value_geom_corrected = 0\nfor k in range(n_binomial - n_success):  # Numero di fallimenti prima del 5¬∞ successo\n    p_value_geom_corrected += (\n        comb(k + n_success - 1, k) * ((1 - p) ** k) * (p**n_success)\n    )\n\np_value_binomial, p_value_geom_corrected\n\n(0.109375, 0.03125)\n\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value √® \\(0.109\\), che non √® statisticamente significativo (dato che √® maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l‚Äôipotesi nulla che Dr.¬†Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value √® \\(0.031\\), che √® statisticamente significativo (dato che √® minore di 0.05); in questo caso, dovremmo rigettare l‚Äôipotesi nulla, suggerendo che Dr.¬†Bristol non sta semplicemente indovinando.\n\nLa presente discussione dimostra che, in base alla procedura del test dell‚Äôipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) pu√≤ portare a conclusioni diverse a seconda delle ipotesi sul processo di campionamento.\n\n\n92.14.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un‚Äôalternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire ‚Äúrisultati pi√π estremi‚Äù che non sono stati osservati. L‚Äôapproccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilit√† iniziali (o ‚Äúa priori‚Äù) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilit√† a Priori: Iniziamo assegnando una distribuzione di probabilit√† a priori a tutti i possibili tassi di successo che la Dr.¬†Bristol potrebbe avere. Questo include una probabilit√† specifica per l‚Äôipotesi nulla, che suggerisce che la Dr.¬†Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilit√† con Dati Osservati: Utilizziamo i dati raccolti nell‚Äôesperimento per aggiornare le nostre probabilit√† a priori. Questo aggiornamento √® fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilit√† delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l‚Äôipotesi alternativa rispetto all‚Äôipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato √® risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto pi√π compatibili con l‚Äôipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del t√®, piuttosto che con l‚Äôipotesi che stia indovinando.\nEtz et al. (2018) concludono che l‚Äôapproccio bayesiano offre un quadro pi√π robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di ‚Äúrisultati pi√π estremi‚Äù non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l‚Äôapproccio bayesiano una soluzione pi√π solida per valutare le ipotesi scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "92¬† Significativit√† statistica",
    "section": "92.15 Malintesi sul valore-p",
    "text": "92.15 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p.¬†Ne esaminiamo qui quelli pi√π comuni.\nMalinteso 1: Un valore p non significativo significa che l‚Äôipotesi nulla √® vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l‚Äôassenza di effetto o la verit√† dell‚Äôipotesi nulla √® diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilit√† dei dati osservati sotto l‚Äôipotesi nulla, e non la probabilit√† dell‚Äôipotesi stessa. Un valore p elevato non dimostra che l‚Äôipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l‚Äôipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significativit√† statistica.\nInvece di concludere affrettatamente l‚Äôassenza di effetto da un valore p non significativo, dovremmo riconoscere l‚Äôambiguit√† e considerare altre possibilit√†. Dichiarazioni come ‚Äúnon c‚Äôera differenza‚Äù dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell‚Äôesistenza di un effetto reale.\nL‚Äôapproccio bayesiano offre una prospettiva diversa che pu√≤ essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilit√† dei dati sotto l‚Äôipotesi nulla, l‚Äôinferenza bayesiana permette di calcolare direttamente la probabilit√† delle ipotesi date i dati.\nL‚Äôapproccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l‚Äôipotesi nulla, ma quantifica la forza dell‚Äôevidenza a favore di un‚Äôipotesi rispetto all‚Äôaltra, fornendo una conclusione pi√π informativa rispetto al semplice ‚Äúnon posso rifiutare l‚Äôipotesi nulla‚Äù.\nMalintesto 2: Un valore p significativo significa che l‚Äôipotesi nulla √® falsa.\nCome spiegato in precedenza, il valore-p quantifica la ‚Äúsorpresa‚Äù suscitata dai dati, alla luce dell‚Äôipotesi nulla. Non ci dice niente sull‚Äôipotesi che abbiamo assunto per quantificare la ‚Äúsorpresa‚Äù.\nMalinteso 3: Un valore p significativo significa che √® stato scoperto un effetto importante.\nLa distinzione tra ‚Äúsignificativit√† statistica‚Äù e ‚Äúrilevanza pratica‚Äù √® fondamentale: mentre la prima indica semplicemente che un risultato √® improbabile sotto l‚Äôipotesi nulla, la seconda valuta l‚Äôeffetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l‚Äôeffetto abbia un impatto pratico notevole o utile.\nInoltre, al di l√† della significativit√† pratica, l‚Äôabitudine di molti psicologi di escludere i predittori che non risultano ‚Äústatisticamente significativi‚Äù √® un grossolano errore: la significativit√† statistica non pu√≤ essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l‚Äôipotesi nulla √® vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perch√© i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. √à principalmente l‚Äôetichetta verbale ‚Äúsignificativo‚Äù che causa confusione qui: in un contesto frequentista, un effetto ‚Äúsignificativo‚Äù √® un effetto ‚Äúsorprendente‚Äù alla luce di \\(H_0\\), non √® necessariamente un effetto ‚Äúimportante‚Äù.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilit√† che abbiate commesso un errore di Tipo 1 (un falso positivo) √® del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilit√† del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilit√† del 5% si riferisce al tasso di errore di Tipo 1, che √® la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l‚Äôipotesi nulla se questa fosse vera, su molteplici ripetizioni dell‚Äôesperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l‚Äôipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che ‚Äúla probabilit√† che questo particolare risultato sia un errore di Tipo 1 √® del 5%‚Äù. In realt√†, in quel momento specifico, l‚Äôevento (commettere un errore di Tipo 1) √® gi√† accaduto o non √® accaduto; la probabilit√† associata a quel singolo risultato non √® pi√π applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato √®, per cos√¨ dire, una realt√† fissa: o abbiamo rilevato un effetto che in realt√† non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione √® cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l‚Äôimportanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p √® la probabilit√† che l‚Äôeffetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilit√† di replicazione di un effetto √® un malinteso diffuso. In realt√†, la probabilit√† di replicazione di un effetto non pu√≤ essere direttamente calcolata dal valore p di un singolo studio a causa della complessit√† dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell‚Äôeffetto, dalla dimensione del campione e dal livello di significativit√† Œ±, fornisce una stima della probabilit√† di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilit√† del 97% che tale effetto si replichi in studi futuri. La possibilit√† di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilit√† di un effetto √® influenzata da molti fattori e non pu√≤ essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l‚Äôinterpretazione corrette della replicabilit√† richiedono un‚Äôanalisi dettagliata della potenza statistica e della dimensione dell‚Äôeffetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "92¬† Significativit√† statistica",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon May 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy : 1.13.0\nxarray: 2024.3.0\nnumpy : 1.26.4\narviz : 0.18.0\npymc  : 5.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nEtz, Alexander, Quentin F Gronau, Fabian Dablander, Peter A Edelsbrunner, e Beth Baribault. 2018. ¬´How to become a Bayesian in eight easy steps: An annotated reading list¬ª. Psychonomic bulletin & review 25 (1): 219‚Äì34.\n\n\nMehr, S. A., L. A. Song, e E. S. Spelke. 2016. ¬´For 5-month-old infants, melodies are social¬ª. Psychological Science 27 (4): 486‚Äì501.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>92</span>¬† <span class='chapter-title'>Significativit√† statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html",
    "title": "93¬† Test t di Student per campioni indipendenti",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esamineremo il test \\(t\\) di Student per campioni indipendenti, uno dei test statistici frequentisti pi√π ampiamente utilizzati nella pratica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>93</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "93¬† Test t di Student per campioni indipendenti",
    "section": "93.1 Applicazioni del Test t di Student",
    "text": "93.1 Applicazioni del Test t di Student\nIl test t di Student per due campioni indipendenti √® un metodo statistico utilizzato per determinare se le medie di due campioni indipendenti sono significativamente diverse. Questo test si applica quando i due campioni sono estratti da popolazioni diverse e non vi √® alcuna correlazione tra le osservazioni di un campione e quelle dell‚Äôaltro.\nPer condurre il test t di Student per due campioni indipendenti, calcoliamo la differenza tra le medie dei due campioni e le stime delle varianze campionarie delle rispettive popolazioni. L‚Äôipotesi nulla del test √® che le medie dei due campioni siano uguali, mentre l‚Äôipotesi alternativa a due code √® che le medie dei due campioni siano diverse. La statistica del test t viene calcolata come il rapporto tra la differenza delle medie campionarie e la deviazione standard media campionaria.\nSuccessivamente, confrontiamo la statistica t con la distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libert√†, dove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni. Calcoliamo quindi il valore-p dalla distribuzione t per determinare la significativit√† del test.\nEsistono due approcci per stimare la varianza. Se assumiamo che le due popolazioni abbiano la stessa varianza (omoschedasticit√†), utilizziamo una stima pooled della varianza. Questo metodo √® considerato efficiente quando l‚Äôomoschedasticit√† √® verificata (argomento correction = False in pg.ttest()). Invece, se supponiamo che le due popolazioni abbiano varianze diverse, utilizziamo due stime separate delle varianze per i due campioni, chiamato test di Welch (argomento correction = True in pg.ttest()). Questo approccio √® pi√π robusto quando le varianze dei due gruppi sono significativamente diverse.\nLe principali assunzioni del test t di Student per due campioni indipendenti sono l‚Äôindipendenza dei due campioni e la normalit√† della distribuzione delle popolazioni da cui sono stati estratti i campioni.\nDi seguito √® riportato il calcolo della stima della deviazione standard pooled, utilizzata per standardizzare la differenza tra le medie dei due campioni quando l‚Äôassunzione di omoschedasticit√† √® verificata:\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(s_p\\) √® la deviazione standard pooled, \\(n\\) e \\(m\\) sono le dimensioni dei due campioni, \\(s^2_0\\) e \\(s^2_1\\) sono le varianze campionarie dei due gruppi.\nLa statistica del test t √® quindi calcolata come:\n\\[\nt = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{1/n_1 + 1/n_2}},\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie campionarie dei due gruppi.\n\n93.1.1 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, supponiamo di avere due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\) che sono estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da: \\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j\n\\]\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono entrambe stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono date da:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\n\\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m}\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le propriet√† di varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y})\n\\]\ndato che i termini incrociati si annullano per l‚Äôindipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\) abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m}\n\\]\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right)\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie √® una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti dobbiamo considerare l‚Äôincertezza aggiuntiva che deriva dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore di stimare \\(\\sigma\\) √® quello di utilizzare le due deviazioni standard dei campioni (calcolate come stimatori della varianza della popolazione) ponderate per i rispettivi gradi di libert√†, come indicato in precedenza per la deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosit√† dei due campioni.\n\n\n93.1.2 Un esempio concreto\nEsaminiamo un esempio concreto. Supponiamo di disporre di nove misure del peso per un gruppo di donne e di nove misure di peso per un gruppo di uomini. Ci chiediamo se, nella popolazione, la media del peso dei due gruppi sia diversa.\nCreiamo due array con i dati e li inseriamo in un DataFrame.\n\nwomen_weight = np.array([38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5])\nmen_weight = np.array([67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4])\n\nweight = np.concatenate((women_weight, men_weight))\nprint(weight)\n\n[38.9 61.2 73.3 21.8 63.4 64.6 48.4 48.8 48.5 67.8 60.  63.4 76.  89.4\n 73.3 67.3 61.3 62.4]\n\n\nCreaiamo una variabile che specifica l‚Äôappartenenza al gruppo.\n\nis_female = np.repeat([1, 0], 9)\nis_female\n\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\ndf = pd.DataFrame({\"is_female\": is_female, \"weight\": weight})\ndf\n\n\n\n\n\n\n\n\n\nis_female\nweight\n\n\n\n\n0\n1\n38.9\n\n\n1\n1\n61.2\n\n\n2\n1\n73.3\n\n\n3\n1\n21.8\n\n\n4\n1\n63.4\n\n\n5\n1\n64.6\n\n\n6\n1\n48.4\n\n\n7\n1\n48.8\n\n\n8\n1\n48.5\n\n\n9\n0\n67.8\n\n\n10\n0\n60.0\n\n\n11\n0\n63.4\n\n\n12\n0\n76.0\n\n\n13\n0\n89.4\n\n\n14\n0\n73.3\n\n\n15\n0\n67.3\n\n\n16\n0\n61.3\n\n\n17\n0\n62.4\n\n\n\n\n\n\n\n\nQui sotto √® riportato un KDE plot per i dati di tutto il campione.\n\ndensity = gaussian_kde(df[\"weight\"])\nx_vals = np.linspace(min(df[\"weight\"]), max(df[\"weight\"]), 1000)\ndensity = density.evaluate(x_vals)\n\nplt.plot(x_vals, density)\nplt.xlabel('Weight')\n_ = plt.ylabel('Density')\n\n\n\n\n\n\n\n\nDal DataFrame estraiamo due array contenenti i valori dei pesi dei due gruppi.\n\nweight_f = df.loc[df[\"is_female\"] == 1, \"weight\"]\nweight_m = df.loc[df[\"is_female\"] == 0, \"weight\"]\n\nCalcoliamo la deviazione standard pooled.\n\ns_pool_num = np.sum(\n    [\n        (len(weight_f) - 1) * np.std(weight_f, ddof=1) ** 2,\n        (len(weight_m) - 1) * np.std(weight_m, ddof=1) ** 2,\n    ]\n)\ns_pool_denom = len(weight_f) + len(weight_m) - 2\n\ns_pool = np.sqrt(np.divide(s_pool_num, s_pool_denom))\ns_pool\n\n12.86771368796942\n\n\nCalcoliamo la statistica test.\n\nt_num = np.mean(weight_f) - np.mean(weight_m)\nt_denom = s_pool * np.sqrt(1 / len(weight_f) + 1 / len(weight_m))\nT = np.divide(t_num, t_denom)\nT\n\n-2.7842353699254567\n\n\nI gradi di libert√† sono:\n\nlen(weight_f) + len(weight_m) - 2\n\n16\n\n\nIl valore-p √® uguale a\n\nstats.t.cdf(T, df=16) * 2\n\n0.013265602643801042\n\n\nRifacciamo ora i calcoli usando la funzione ttest del pacchatto pingouin. L‚Äôargomento paired = False specifica che i due campioni sono indipendenti; l‚Äôargomento correction=False specifica che non verr√† usata la correzione di Welch per varianze separate.\n\nres = pg.ttest(weight_m, weight_f, paired=False, correction=False)\nprint(res)\n\n               T  dof alternative     p-val          CI95%   cohen-d   BF10  \\\nT-test  2.784235   16   two-sided  0.013266  [4.03, 29.75]  1.312501  4.251   \n\n           power  \nT-test  0.743519  \n\n\nIl risultato conferma quanto trovato in precedenza attraverso i calcoli effettuati. Il valore-\\(p\\) indica che possiamo rifiutare l‚Äôipotesi nulla di uguaglianza delle medie delle due popolazioni. Quindi, possiamo concludere con un livello di confidenza del 95% che la media del peso dei maschi nella popolazione √® superiore alla media del peso delle femmine nella popolazione.\nSe vogliamo un test pi√π robusto, che non assume l‚Äôomogeneit√† delle varianze, usiamo la correzione di Welch:\n\nres = pg.ttest(weight_m, weight_f, paired=False, correction=True)\nprint(res)\n\n               T        dof alternative     p-val         CI95%   cohen-d  \\\nT-test  2.784235  13.113752   two-sided  0.015384  [3.8, 29.98]  1.312501   \n\n         BF10     power  \nT-test  4.251  0.743519  \n\n\nLa statistica test resta immutata. Quello che cambiano sono i gradi di libert√†. Con questa correzione dei gradi di libert√†, il p-valore diventa pi√π grande.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>93</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#interpretazione-dei-risultati",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#interpretazione-dei-risultati",
    "title": "93¬† Test t di Student per campioni indipendenti",
    "section": "93.2 Interpretazione dei Risultati",
    "text": "93.2 Interpretazione dei Risultati\nIl test t di Student per campioni indipendenti ha generato un p-valore di 0.013, inferiore alla soglia di significativit√† di Œ± = 0.05. Questo indica che la differenza osservata tra i gruppi √® statisticamente significativa. Tuttavia, anzich√© limitarci a etichettare il risultato come ‚Äústatisticamente significativo‚Äù, √® importante considerare cosa implica questo esito nel contesto della ricerca.\nIn sostanza, il basso p-valore ci porta a rifiutare l‚Äôipotesi nulla, suggerendo che √® improbabile che le differenze osservate nei dati siano dovute al caso. Questo ci permette di concludere con una certa fiducia che esiste una differenza reale tra le medie delle popolazioni da cui i campioni sono stati estratti. Questa interpretazione apre la strada a ulteriori indagini sulle cause di tale differenza e sulle loro implicazioni teoriche o pratiche.\nSe il p-valore fosse stato superiore alla soglia di significativit√† Œ±, avremmo interpretato il risultato in modo diverso. Un p-valore maggiore di Œ± indica che i dati osservati non sono incompatibili con l‚Äôipotesi nulla. In altre parole, non avremmo avuto motivi statistici sufficienti per rifiutare l‚Äôipotesi nulla. Tuttavia, √® importante sottolineare che questo non equivale a dimostrare che l‚Äôipotesi nulla sia vera; piuttosto, i dati non forniscono evidenza sufficiente per confutarla.\nIn pratica, la non rifiutazione dell‚Äôipotesi nulla significa che i dati sono compatibili sia con l‚Äôipotesi nulla sia con altre possibili ipotesi sulle caratteristiche della popolazione. Di conseguenza, in assenza di evidenza contraria, ci asteniamo dal fare affermazioni conclusive e manteniamo una posizione di neutralit√† riguardo l‚Äôipotesi nulla, rimanendo aperti alla possibilit√† di ulteriori indagini e dati futuri che potrebbero chiarire meglio la questione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>93</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#riportare-i-risultati",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#riportare-i-risultati",
    "title": "93¬† Test t di Student per campioni indipendenti",
    "section": "93.3 Riportare i risultati",
    "text": "93.3 Riportare i risultati\nPer riportare i risultati si pu√≤ usare un testo come quello seguente:\n\nAbbiamo condotto un test \\(t\\) di Student per campioni indipendenti per confrontare le medie dei due gruppi. I risultati indicano una differenza tra le medie dei gruppi (\\(t\\)(16) = 2.78, \\(p\\) = 0.013). L‚Äôintervallo di confidenza al 95% per la differenza delle medie √® tra 4.03 e 29.75. L‚Äôampiezza dell‚Äôeffetto, misurata con Cohen‚Äôs \\(d\\), √® stata di 1.31, indicando un effetto grande secondo le convenzioni comunemente accettate. La potenza statistica del test, calcolata post hoc, √® stata del 74.4%, indicando una buona probabilit√† di rilevare un effetto, se presente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>93</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "title": "93¬† Test t di Student per campioni indipendenti",
    "section": "93.4 Test Unidirezionali e Bidirezionali",
    "text": "93.4 Test Unidirezionali e Bidirezionali\nIl criterio secondo il quale un p-valore inferiore a Œ± indica una ‚Äúsignificativit√† statistica‚Äù √® comune sia nei test bidirezionali sia nei test unidirezionali, ma l‚Äôapplicazione differisce a seconda della natura dell‚Äôipotesi testata.\n\n93.4.1 Test Bidirezionale\nNel caso di un test bidirezionale, le ipotesi sono formulate come segue: - Ipotesi nulla (H‚ÇÄ): \\(\\mu_1 = \\mu_2\\) (cio√®, \\(\\mu_1 - \\mu_2 = 0\\)); si assume uguaglianza delle varianze (\\(\\sigma^2_1 = \\sigma^2_2\\)). - Ipotesi alternativa (H‚ÇÅ): \\(\\mu_1 \\neq \\mu_2\\); ancora con uguaglianza delle varianze.\nLa statistica test √® calcolata come $ {Y}_1 - {Y}_2 $, dove \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) sono le medie campionarie dei due gruppi. La regione di rifiuto dell‚Äôipotesi nulla √® equamente divisa tra le due code della distribuzione della statistica test, con Œ±/2 per coda.\n\n\n93.4.2 Test Unidirezionale\nPer i test unidirezionali, la direzione della differenza che si sta testando √® cruciale:\n\nQuando si testa se \\(\\mu_1\\) √® minore di \\(\\mu_2\\):\n\nIpotesi nulla (H‚ÇÄ): \\(\\mu_1 \\geq \\mu_2\\);\nIpotesi alternativa (H‚ÇÅ): \\(\\mu_1 &lt; \\mu_2\\).\n\nLa statistica test √® calcolata come $ {Y}_1 - {Y}_2 $. Se questa differenza √® significativamente negativa (cio√® cade nella coda sinistra oltre il valore critico), supporta H‚ÇÅ.\nQuando si testa se \\(\\mu_1\\) √® maggiore di \\(\\mu_2\\):\n\nIpotesi nulla (H‚ÇÄ): \\(\\mu_1 \\leq \\mu_2\\);\nIpotesi alternativa (H‚ÇÅ): \\(\\mu_1 &gt; \\mu_2\\).\n\nAnche qui, la statistica test √® $ {Y}_1 - {Y}_2 $. Un risultato che supera il valore critico nella coda destra indica supporto per H‚ÇÅ.\n\nIn ogni tipo di test unidirezionale, la regione di rifiuto occupa l‚Äôintero Œ± dell‚Äôarea sotto la curva di densit√†, ma √® posizionata completamente nella coda specificata dall‚Äôipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>93</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "title": "93¬† Test t di Student per campioni indipendenti",
    "section": "93.5 Considerazioni sugli Errori di Tipo I e Tipo II",
    "text": "93.5 Considerazioni sugli Errori di Tipo I e Tipo II\nLa scelta di un livello di significativit√† \\(\\alpha = 0.05\\) implica che, nel contesto di un test d‚Äôipotesi, esiste una probabilit√† del 5% di commettere un errore di Tipo I. Questo tipo di errore si verifica quando l‚Äôipotesi nulla √® vera ma, a causa della variabilit√† casuale nei dati del campione, otteniamo risultati abbastanza estremi da rifiutare erroneamente \\(H_0\\).\nUn errore di Tipo II, invece, si verifica quando l‚Äôipotesi nulla √® falsa, ma i dati del campione non sono sufficientemente estremi da giustificare il suo rifiuto. La probabilit√† di commettere un errore di Tipo II √® spesso influenzata dalla dimensione del campione: campioni pi√π piccoli tendono ad avere una potenza statistica inferiore, aumentando il rischio di non rifiutare \\(H_0\\) quando sarebbe appropriato farlo. La potenza statistica di un test, che rappresenta la probabilit√† di rifiutare correttamente l‚Äôipotesi nulla quando √® falsa, pu√≤ essere stimata, ma questa stima pu√≤ diventare complessa.\nPer i modelli statistici complessi, la stima della potenza pu√≤ essere particolarmente difficile. Non solo i calcoli possono essere intricati, ma non esiste un metodo unico e standardizzato per effettuare tali stime, richiedendo l‚Äôintroduzione di diverse assunzioni.\nLa funzione ttest del pacchetto pingouin offre un modo per calcolare la potenza di un test in contesti di test statistici relativamente semplici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>93</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "93¬† Test t di Student per campioni indipendenti",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npingouin  : 0.5.4\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>93</span>¬† <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "In psicologia, nelle scienze sociali e in altre discipline √® in corso una Riforma Metodologica, scaturita da una profonda crisi che ha colpito la scienza contemporanea: la crisi di replicazione dei risultati delle ricerche. Un esempio emblematico √® rappresentato dal sito Retraction Watch, che monitora le ritrattazioni di studi scientifici. Questa crisi mina la credibilit√† della ricerca scientifica e ha spinto a una revisione radicale delle metodologie alla base delle scienze psicologiche e di altre discipline affini (Korbmacher et al. 2023). Le cause della crisi di replicazione sono molteplici: frodi, pratiche di ricerca scorrette e incentivi distorti offerti dal sistema accademico. Una delle cause pi√π rilevanti per un corso sull‚Äôanalisi dei dati psicologici √® l‚Äôuso delle tecniche inferenziali di stampo frequentista, che ha contribuito alla proliferazione di pubblicazioni contenenti falsi positivi.\nUn articolo di Altmejd et al. (2019) identifica alcuni fattori semplici ma altamente predittivi della replicabilit√† degli studi: il campione era di dimensioni adeguate? I ricercatori hanno ottenuto un risultato appena sotto la soglia di significativit√† di p = 0.05? (Spesso un articolo pu√≤ rivendicare un risultato ‚Äúsignificativo‚Äù se questa soglia viene raggiunta, e molti utilizzano vari trucchi statistici per superare tale limite.) Lo studio ha rilevato un effetto sull‚Äôintera popolazione studiata o ha individuato un ‚Äúeffetto di interazione‚Äù (ad esempio, un effetto presente solo in un segmento pi√π piccolo della popolazione), che √® molto meno probabile che si riproduca?\n√à emerso inoltre che prevedere la replicazione di uno studio √® sorprendentemente semplice. Non √® necessario un approfondimento della metodologia statistica n√© un esame rigoroso dei dati, n√© tantomeno una scrupolosa analisi delle teorie pi√π esoteriche per individuare errori sottili: questi articoli presentano problemi evidenti, a livello superficiale. Uno studio pubblicato su Nature ha coinvolto scienziati in una scommessa su quali studi di scienze sociali sarebbero stati replicati. Camerer et al. (2018) ha scoperto che le previsioni degli scienziati in questo mercato delle scommesse erano estremamente accurate nel determinare quali articoli avrebbero avuto successo nella replicazione.\nUlteriori ricerche hanno dimostrato che non √® nemmeno necessario consultare esperti del settore per indovinare quali studi resisteranno a un esame rigoroso. Uno studio di Hoogeveen, Sarafoglou, e Wagenmakers (2020) ha coinvolto partecipanti senza un background professionale nelle scienze sociali, chiedendo loro di leggere articoli di psicologia e prevedere se questi si sarebbero replicati. ‚ÄúI non-esperti senza una formazione professionale nelle scienze sociali sono in grado di prevedere la replicabilit√† degli studi con una precisione superiore al caso,‚Äù conclude lo studio, ‚Äúbasandosi esclusivamente su semplici descrizioni verbali degli studi.‚Äù\nSebbene i non esperti non siano stati altrettanto precisi nelle loro previsioni rispetto agli scienziati nello studio pubblicato su Nature, il fatto che siano comunque riusciti a individuare molte replicazioni fallite suggerisce che molti di questi studi presentano difetti evidenti, riconoscibili anche da chi non √® un addetto ai lavori.\nLa pubblicazione di un articolo peer-reviewed non rappresenta l‚Äôultimo passo del processo scientifico. Dopo la pubblicazione, altri studi potrebbero citare l‚Äôarticolo originale, diffondendo eventuali errori o fraintendimenti. Uno studio di Yang, Youyou, e Uzzi (2020) mostra che non esiste alcuna correlazione tra la replicabilit√† di uno studio e la sua frequenza di citazione. ‚ÄúGli studi falliti si diffondono nella letteratura scientifica con la stessa rapidit√† degli studi replicabili,‚Äù affermano Yang, Youyou, e Uzzi (2020). Questo solleva una domanda: se gli scienziati sono abbastanza bravi nel prevedere se uno studio si replicher√†, perch√© sono altrettanto inclini a citare studi non replicabili quanto quelli validi?\nQueste considerazioni suggeriscono che la crisi di replicazione non richiede solo una revisione metodologica, ma √® il sintomo di un sistema scientifico che necessita di un ripensamento pi√π ampio. Le riviste scientifiche non sono sufficientemente responsabili per la pubblicazione di articoli discutibili, e il sistema accademico promuove incentivi distorti. In alcuni casi, la cultura accademica sembra addirittura incentivare la produzione di ricerche di bassa qualit√†. La pressione a pubblicare un elevato numero di articoli favorisce chi riesce a farlo rapidamente, spesso ricorrendo a ‚Äúscorciatoie‚Äù. Di conseguenza, si √® creato un sistema in cui gli incentivi continuano a promuovere la cattiva ricerca, nonostante si comprenda sempre meglio cosa costituisca una ricerca di qualit√†.\nIn questa sezione della dispensa, ci concentreremo su uno dei problemi che stanno alla base della crisi della riproducibilit√† dei risultati della ricerca, ovvero i limiti dell‚Äôinferenza frequentista (Baker 2016). Analizzeremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman e Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista. Inoltre, discuteremo alcuni possibili metodi per affrontare la crisi e le implicazioni che derivano dall‚Äôintegrit√† della ricerca.\n\n\n\n\nAltmejd, Adam, Anna Dreber, Eskil Forsell, Juergen Huber, Taisuke Imai, Magnus Johannesson, Michael Kirchler, Gideon Nave, e Colin Camerer. 2019. ¬´Predicting the replicability of social science lab experiments¬ª. PloS one 14 (12): e0225826.\n\n\nBaker, Monya. 2016. ¬´Reproducibility Crisis¬ª. Nature 533 (7604): 452‚Äì54.\n\n\nCamerer, Colin F, Anna Dreber, Felix Holzmeister, Teck-Hua Ho, J√ºrgen Huber, Magnus Johannesson, Michael Kirchler, et al. 2018. ¬´Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015¬ª. Nature human behaviour 2 (9): 637‚Äì44.\n\n\nGelman, Andrew, e John Carlin. 2014. ¬´Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors¬ª. Perspectives on Psychological Science 9 (6): 641‚Äì51.\n\n\nHoogeveen, Suzanne, Alexandra Sarafoglou, e Eric-Jan Wagenmakers. 2020. ¬´Laypeople can predict which social-science studies will be replicated successfully¬ª. Advances in Methods and Practices in Psychological Science 3 (3): 267‚Äì85.\n\n\nKorbmacher, Max, Flavio Azevedo, Charlotte R Pennington, Helena Hartmann, Madeleine Pownall, Kathleen Schmidt, Mahmoud Elsherif, et al. 2023. ¬´The replication crisis has led to positive structural, procedural, and community changes¬ª. Communications Psychology 1 (1): 3.\n\n\nYang, Yang, Wu Youyou, e Brian Uzzi. 2020. ¬´Estimating the deep replicability of scientific findings using human and artificial intelligence¬ª. Proceedings of the National Academy of Sciences 117 (20): 10762‚Äì68.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "94¬† La Crisi della Replicazione",
    "section": "",
    "text": "Introduzione\nQuesto capitolo introduce la crisi di replicazione dei risultati della ricerca in psicologia, esplorando le cause principali di questo fenomeno e mettendo in evidenza il ruolo che l‚Äôapproccio statistico frequentista ha avuto nel contribuire a questa crisi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#feeling-the-future",
    "href": "chapters/replication_crisis/01_crisis.html#feeling-the-future",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.1 Feeling the Future",
    "text": "94.1 Feeling the Future\nIl 2011 ha rappresentato un punto di svolta per la comunit√† scientifica, segnando l‚Äôinizio della cosiddetta ‚Äúcrisi della replicazione‚Äù. Questo fenomeno, pur non influenzando direttamente la vita quotidiana della maggior parte delle persone, inclusi molti psicologi, ha avuto profonde ripercussioni sul mondo della ricerca, specialmente in psicologia, il campo pi√π colpito. Per coloro con una conoscenza anche solo basilare della statistica, e che erano pi√π interessati alla ricerca della verit√† che all‚Äôaccumulo di citazioni o all‚Äôavanzamento di carriera, il 2011 √® stato percepito come un vero e proprio ‚ÄúAnno Zero‚Äù. Questo momento cruciale ha messo in luce problemi fondamentali nei metodi di ricerca e nell‚Äôinterpretazione dei risultati, avviando un processo di ripensamento delle pratiche scientifiche che √® ancora in corso.\n\n94.1.1 La Scoperta di Frodi e Risultati Controversi\n\n94.1.1.1 Il Caso Diederik Stapel\nUno dei primi segnali della crisi fu la scoperta della frode scientifica commessa da Diederik Stapel, una stella nascente della psicologia sociale e professore presso l‚ÄôUniversit√† di Tilburg nei Paesi Bassi, aveva attirato l‚Äôattenzione con una serie di articoli sensazionali: uno suggeriva che mangiare carne rendeva le persone pi√π antisociali; un altro sosteneva che le persone sono pi√π inclini al razzismo se l‚Äôambiente circostante √® pieno di rifiuti. Tuttavia, si scopr√¨ che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti n√© raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati.\n\n\n94.1.1.2 Lo Studio ‚ÄúFeeling the Future‚Äù di Daryl Bem\nNello stesso anno, Daryl Bem della Cornell University pubblic√≤ uno studio intitolato ‚ÄúFeeling the Future‚Äù (Bem 2011), che avrebbe scosso ulteriormente le fondamenta della psicologia sociale. Lo studio di Bem si inseriva nella tradizione degli esperimenti di ‚Äúpriming‚Äù, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ‚Äô70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio √® lo studio di John Bargh del 1996, che dimostr√≤ come l‚Äôesposizione a parole associate all‚Äôet√† avanzata inducesse i soggetti a camminare pi√π lentamente (Bargh, Chen, e Burrows 1996). Un altro studio del 2006 rivel√≤ che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilit√† della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali. Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in met√† delle prove, il priming avveniva dopo che i soggetti avevano gi√† visto e valutato l‚Äôimmagine (Bem 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano pi√π veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l‚Äôipotesi nulla.\nBem interpret√≤ questi risultati come prova della chiaroveggenza, una conclusione che suscit√≤ notevoli controversie e ridicolizz√≤ la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l‚Äôordine temporale invertito, mostrarono risultati altrettanto significativi.\nQuesti risultati ponevano la comunit√† scientifica di fronte a un dilemma: accettare l‚Äôesistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validit√† dei suoi risultati come prova dell‚Äôesistenza di capacit√† precognitive.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#pratiche-di-ricerca-disoneste-e-loro-conseguenze",
    "href": "chapters/replication_crisis/01_crisis.html#pratiche-di-ricerca-disoneste-e-loro-conseguenze",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.2 Pratiche di Ricerca Disoneste e Loro Conseguenze",
    "text": "94.2 Pratiche di Ricerca Disoneste e Loro Conseguenze\nLo studio di Bem, che portava a conclusioni insensate, si rivel√≤ un catalizzatore per un esame critico delle pratiche di ricerca in psicologia, innescando un dibattito che avrebbe avuto profonde ripercussioni sull‚Äôintera disciplina (Ritchie, Wiseman, e French 2012).\nGi√† nel 2005, John Ioannidis dell‚ÄôUniversit√† di Stanford aveva previsto la crisi imminente nel suo articolo ‚ÄúWhy Most Published Research Findings Are False‚Äù (Ioannidis 2005). Il nucleo della critica di Ioannidis riguardava l‚Äôapproccio interpretativo dei dati sperimentali. Secondo la sua analisi, il problema fondamentale risiedeva nel fatto che molti scienziati non valutavano correttamente la probabilit√† che la loro ipotesi fosse vera alla luce dei dati raccolti. Al contrario, seguendo l‚Äôapproccio tradizionale ispirato ai lavori di Bernoulli e Fisher, si concentravano sulla probabilit√† di ottenere i dati osservati nell‚Äôipotesi che la loro teoria fosse falsa.\n\n94.2.1 P-hacking e HARKing\nLa psicologia, come molte altre discipline scientifiche, si trova spesso a confrontarsi con le ‚Äúquestionable research practices‚Äù (pratiche di ricerca discutibili), ovvero quell‚Äôinsieme di comportamenti o azioni adottate dai ricercatori durante il processo di conduzione e comunicazione della ricerca scientifica che possono compromettere l‚Äôintegrit√† e l‚Äôaffidabilit√† dei risultati ottenuti. Queste pratiche includono il ‚ÄúP-hacking‚Äù, in cui i ricercatori manipolano i dati o le analisi statistiche per ottenere risultati significativi; il ‚ÄúHARKing‚Äù (Hypothesizing After Results are Known), in cui le ipotesi vengono formulate retrospettivamente per adattarsi ai risultati ottenuti; e la ‚Äúpresentazione selettiva dei risultati‚Äù, dove vengono presentati solo i risultati che supportano le ipotesi, tralasciando quelli non significativi o contraddittori.\nLa pressione per ottenere risultati ‚Äústatisticamente significativi‚Äù, insieme all‚Äôuso di campioni di piccole dimensioni, porta alla proliferazione di falsi positivi come conseguenza dell‚Äôadozione di pratiche di ricerca discutibili. Simmons, Nelson e Simonsohn hanno dimostrato come, attraverso l‚Äôimpiego di tali pratiche, sia semplice ottenere risultati statisticamente significativi (Nelson, Simmons, e Simonsohn 2018).\nL‚Äôuso di queste pratiche √® molto diffuso nella ricerca e l‚Äôapproccio statistico frequentista √® particolarmente vulnerabile a tali manipolazioni.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.3 La Cultura della Frode nel Sistema Accademico",
    "text": "94.3 La Cultura della Frode nel Sistema Accademico\nIl sistema accademico stesso, con i suoi incentivi alla pubblicazione e al finanziamento, incoraggia indirettamente queste pratiche.\n\n94.3.1 Il Caso Brian Wansink\nUn caso emblematico √® quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l‚Äôamministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di pi√π in presenza di donne o sull‚Äôeffetto dei nomi ‚Äúattraenti‚Äù dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero ‚Äúespressioni di preoccupazione‚Äù, e quindici furono corretti. Nel 2019, Wansink si dimise da Cornell dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n\n94.3.2 Il Caso Sylvain Lesn√©\nUn altro esempio rilevante riguarda Sylvain Lesn√© e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell‚Äôipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesn√©.\nNel 2022, il neuroscienziato Matthew Schrag scopr√¨ immagini manipolate in questo e in molti altri articoli di Lesn√©, inclusi quelli che sostenevano l‚Äôipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell‚Äôarticolo del 2006 alla fine accettarono di ritirarlo, ma non Lesn√© stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesn√© continui a essere finanziato dal National Institutes of Health e impiegato presso l‚ÄôUniversit√† del Minnesota, dimostra un fallimento sistemico nell‚Äôaffrontare la cattiva condotta scientifica.\n\n\n94.3.3 Altri Casi di Rilievo\nHo controllato il contenuto e ho notato che ci sono effettivamente alcune ripetizioni e inconsistenze. Hai ragione nel sospettare che i casi di Dan Ariely e Francesca Gino siano stati trattati separatamente, mentre in realt√† sono parte dello stesso scandalo. Inoltre, il caso di Marc Tessier-Lavigne √® menzionato due volte. Ecco una versione riscritta e migliorata del testo:\nNel mondo accademico, recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all‚Äôindagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonest√† e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonest√†.\nFrancesca Gino, docente presso la Harvard Business School, √® stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che √® in ‚Äúadministrative leave‚Äù.\n\n\nL‚Äôinefficacia delle istituzioni accademiche nel gestire la frode scientifica riflette una corruzione culturale sistemica. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell‚Äôintegrit√† scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene spesso premiato con finanziamenti, promozioni e prestigio accademico. In sintesi, la crisi della riproducibilit√† e la cultura della frode sono problemi diffusi e profondamente radicati nel mondo accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilit√†",
    "href": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilit√†",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.4 Il Progetto di Riproducibilit√†",
    "text": "94.4 Il Progetto di Riproducibilit√†\n\n94.4.1 L‚ÄôIniziativa di Brian Nosek\nNel 2011, Brian Nosek dell‚ÄôUniversit√† della Virginia avvi√≤ il Progetto di Riproducibilit√† (Collaboration 2015), coinvolgendo 270 ricercatori nel tentativo di replicare cento studi di psicologia. L‚Äôobiettivo era ripetere gli esperimenti originali, utilizzando gli stessi metodi ma con nuovi campioni, per verificare la solidit√† e la replicabilit√† dei risultati precedentemente pubblicati.\nI risultati di questo imponente lavoro, pubblicati nel 2015, furono a dir poco sconvolgenti. Dei cento studi esaminati, ben novantasette avevano inizialmente riportato risultati statisticamente significativi. Tuttavia, il team di Nosek riusc√¨ a replicare questi risultati solo in trentasei casi. Non solo: le dimensioni degli effetti nelle replicazioni risultarono, in media, dimezzate rispetto agli studi originali. Inoltre, pi√π della met√† di queste dimensioni degli effetti cadeva al di fuori degli intervalli di confidenza al 95% riportati nei lavori originali.\n\n\n94.4.2 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca pi√π recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell‚Äôarco di vent‚Äôanni. Questa ricerca suggerisce che poco pi√π della met√† di questi articoli di psicologia non supererebbe i test di replicazione (Youyou, Yang, e Uzzi 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilit√† (Collaboration 2015). Questo dato √® in linea con il lavoro di Youyou, Yang, e Uzzi (2023), che ha mostrato come la replicabilit√† degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente pi√π incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i pi√π bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalit√† hanno mostrato tassi leggermente pi√π incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilit√† dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell‚Äôapparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilit√† che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilit√† di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, pi√π in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilit√† di molti risultati ritenuti consolidati, ma anche la necessit√† di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche √® ancora in atto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.5 Cause Profonde della Crisi della Replicazione",
    "text": "94.5 Cause Profonde della Crisi della Replicazione\nLa crisi della replicazione in psicologia e in altre scienze ha radici profonde e non pu√≤ essere attribuita esclusivamente a pratiche di ricerca disoneste. Diverse cause immediate sono state identificate, tra cui:\n\nPressione a pubblicare (‚Äúpublish or perish‚Äù): L‚Äôintensa pressione sui ricercatori a pubblicare prolificamente √® un fattore importante che pu√≤ contribuire a molti dei problemi legati alla crisi della replicazione. La cultura del ‚Äúpublish or perish‚Äù mette i ricercatori sotto stress continuo per produrre risultati significativi e pubblicarli rapidamente (Gopalakrishna et al. 2022; Grimes, Bauch, e Ioannidis 2018).\nRicerca della novit√† a ogni costo e incentivi accademici distorti: La ricerca di risultati innovativi e il valore eccessivo attribuito alle scoperte significative incentivano pratiche di ricerca distorte. Questo include la sovrarappresentazione dei risultati positivi e la mancanza di rigore metodologico (Ferguson e Heene 2012; Ware e Munaf√≤ 2015).\nBassa potenza statistica e scarsit√† di sforzi di replicazione: Molti studi soffrono di bassa potenza statistica, il che rende difficile ottenere risultati affidabili. Inoltre, la mancanza di sforzi di replicazione contribuisce a mantenere e diffondere risultati non replicabili.\nMancanza di trasparenza nella reportistica: La reportistica selettiva e la flessibilit√† non dichiarata nei metodi e nei dati sono pratiche comuni che compromettono l‚Äôintegrit√† scientifica. Inoltre, la riluttanza a condividere dati e materiali e il bias di pubblicazione, per cui i risultati nulli hanno meno probabilit√† di essere pubblicati rispetto a quelli statisticamente significativi, aggravano il problema (Bruton et al. 2020; Nosek, Spies, e Motyl 2012).\n\n\n94.5.1 La Probabilit√† Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora pi√π profonda e risieda nell‚Äôapproccio statistico stesso, ampiamente adottato dalla comunit√† scientifica (Chivers 2024; Gelman e Loken 2014; Loken e Gelman 2017). Questo punto di vista suggerisce che le difficolt√† nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un‚Äôinterpretazione e un‚Äôapplicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L‚Äôapproccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilit√† di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilit√† di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso ‚Äúp-value‚Äù √® un esempio di questa logica: esso indica la probabilit√† di ottenere risultati estremi quanto o pi√π estremi di quelli osservati, supponendo che l‚Äôipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto √® probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una ‚Äúprobabilit√† inferenziale‚Äù, cio√® la probabilit√† che l‚Äôipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l‚Äôapproccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilit√† inferenziale. L‚Äôapproccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le ‚Äúprior‚Äù) relative all‚Äôipotesi in esame.\nLa differenza tra questi due approcci √® cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l‚Äôipotesi nulla √® vera, l‚Äôapproccio bayesiano ci fornisce la probabilit√† che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n\n94.5.2 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L‚Äôuso esclusivo dell‚Äôapproccio frequentista pu√≤ portare a sovrastimare la forza delle evidenze a favore di un‚Äôipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significativit√† statistica, rendendo pi√π difficile dichiarare un risultato ‚Äúsignificativo‚Äù.\nRichiedere la preregistrazione delle ipotesi per prevenire l‚ÄôHARKing (Hypothesizing After Results are Known).\nFar s√¨ che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo ‚Äúpositivi‚Äù o ‚Äúnuovi‚Äù.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell‚Äôinterpretazione delle evidenze statistiche. L‚Äôadozione di un approccio bayesiano offre una soluzione pi√π radicale, fornendo un quadro pi√π completo e realistico della forza delle evidenze a favore o contro un‚Äôipotesi scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "href": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.6 Guardare i Dati",
    "text": "94.6 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua, quella di osservare i risultati man mano che vengono raccolti all‚Äôinterno dell‚Äôapproccio frequentista, possa avere conseguenze enormi sulle conclusioni dello studio, in particolare sulla probabilit√† di ottenere un risultato statisticamente significativo. Nella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l‚Äô‚Äúipotesi nulla‚Äù √® vera: non c‚Äô√® differenza tra le medie delle popolazioni di partenza. Tuttavia, a causa della variabilit√† campionaria, si noter√† come il p-valore sia fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\ndef simulate_t_tests(seed, max_sample_size, mu=0, sigma=1):\n    # Imposta il seme per la riproducibilit√†\n    np.random.seed(seed)\n\n    # Intervallo di grandezza campionaria\n    sample_sizes = range(2, max_sample_size + 1, 2)\n    p_values = []\n\n    # Genera due campioni grandi iniziali da una distribuzione normale\n    full_sample1 = np.random.normal(mu, sigma, max_sample_size)\n    full_sample2 = np.random.normal(mu, sigma, max_sample_size)\n\n    # Simulazione\n    for n in sample_sizes:\n        # Estrai sottoinsiemi incrementali dai campioni completi\n        sample1 = full_sample1[:n]\n        sample2 = full_sample2[:n]\n\n        # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n        t_stat, p_value = ttest_ind(sample1, sample2)\n        p_values.append(p_value)\n\n    color_fill = \"#b97c7c\"\n    color_edge = \"#8f2727\"\n\n    # Crea il grafico del p-valore in funzione della grandezza campionaria\n    plt.plot(sample_sizes, p_values, marker=\"\", linestyle=\"-\", color=color_fill)\n    plt.axhline(y=0.05, color=color_edge, linestyle=\"--\", label=\"Significativit√† a 0.05\")\n    plt.xlabel(\"Grandezza Campionaria\")\n    plt.ylabel(\"P-valore\")\n    plt.title(\"P-valore in funzione della grandezza campionaria\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambia progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). √à evidente come il p-valore vari drasticamente con l‚Äôaggiunta di nuove osservazioni ai campioni. Si noti inoltre che, per alcune configurazioni dei due campioni, il p-valore pu√≤ scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato ‚Äústatisticamente significativo‚Äù. Tuttavia, questa simulazione non mostra altro che rumore: i due campioni sono stati estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed=12, max_sample_size=300, mu=0, sigma=2)\n\n\n\n\n\n\n\n\n\nsimulate_t_tests(seed=42, max_sample_size=300, mu=0, sigma=2)\n\n\n\n\n\n\n\n\nLa simulazione evidenzia una limitazione fondamentale dell‚Äôapproccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questa pratica rende il processo decisionale estremamente volatile, poich√©, teoricamente, ad ogni nuovo studio si ‚Äúdimentica‚Äù tutta l‚Äôinformazione derivante dagli studi precedenti.\n\n94.6.1 Analisi Bayesiana\nL‚Äôapproccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cio√®, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l‚Äôinformazione a priori (ci√≤ che sapevamo prima dell‚Äôesperimento) con la verosimiglianza (ci√≤ che i dati ci dicono). Questo equilibrio √® particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l‚Äôinformazione a priori assume un ruolo pi√π rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l‚Äôanalisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l‚Äôapproccio frequentista, forniscono un risultato ‚Äústatisticamente significativo‚Äù, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilit√† al 95% compreso tra -0.52 e 1.12. Poich√© questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c‚Äô√® una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l‚Äôapproccio bayesiano √® pi√π resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l‚Äôanalisi bayesiana fornisce una rappresentazione pi√π sfumata e realistica dell‚Äôincertezza associata alle nostre conclusioni.\nInoltre, l‚Äôapproccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\nnp.random.seed(12)\nmu=0\nsigma=2\nmax_sample_size=50\nfull_sample1 = np.random.normal(mu, sigma, max_sample_size)\nfull_sample2 = np.random.normal(mu, sigma, max_sample_size)\n\n\nstan_data = {\n    \"N1\": len(full_sample1),\n    \"N2\": len(full_sample2),\n    \"y1\": full_sample1,\n    \"y2\": full_sample2,\n}\nstan_data\n\n{'N1': 50,\n 'N2': 50,\n 'y1': array([ 0.94597166, -1.36285176,  0.48487899, -3.40147127,  1.50628567,\n        -3.06944268,  0.01025416, -0.24045534, -1.61396376,  5.74363879,\n        -1.19564584,  0.94491399,  2.19191224, -2.4303376 ,  2.68471274,\n        -0.24429958,  2.02503095, -1.82773829, -2.05906041,  2.4195929 ,\n         1.00374461,  0.27769235,  1.28152223,  1.05466533, -2.30872047,\n        -4.42666696, -3.36351302, -3.5761885 , -4.43706989, -1.29486156,\n        -1.05680864, -0.07841835,  0.4299519 , -0.76871761, -0.50780816,\n         0.14650415, -1.99440767, -1.42771258,  0.07083269, -1.35589073,\n        -1.14376212, -0.21172463,  2.67166268,  0.63733058, -0.6751905 ,\n        -1.17053656, -0.22983988,  4.48363559, -6.29483304,  1.07027179]),\n 'y2': array([ 0.46498088,  1.7352239 , -2.29642543,  4.22868848,  2.00188552,\n        -0.10282999,  0.3195754 , -1.43252717,  0.10104565, -0.28667483,\n         1.88715078,  0.71528845, -0.16689841,  1.35561221,  1.11212075,\n         0.44543892, -3.05797096,  2.05842235, -2.33251752, -2.0191233 ,\n        -0.21053598,  1.02404432,  2.81545553, -3.37539266,  2.94246799,\n         3.27292581, -0.92278987, -0.40272454, -1.14363346, -1.20659823,\n        -2.67877844, -3.37930584, -0.39865468,  0.51554517,  3.65764143,\n        -2.00200309, -4.18338243,  0.29311941, -0.9327022 ,  0.71244601,\n        -0.79575947, -2.51844703, -1.37775738,  1.6052609 ,  0.54478208,\n        -1.938353  ,  1.74393624, -2.89271889, -1.07296253,  0.39584103])}\n\n\n\nstan_file = os.path.join(project_directory, \"stan\", \"two_means_diff.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n13:52:36 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff\n13:52:47 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff\n\n\ndata {\n  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\n  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\n  vector[N1] y1; // Dati del gruppo 1\n  vector[N2] y2; // Dati del gruppo 2\n}\nparameters {\n  real mu1; // Media del gruppo 1\n  real delta; // Differenza tra le medie\n  real&lt;lower=0&gt; sigma; // Deviazione standard comune\n  real&lt;lower=0&gt; nu; // Gradi di libert√† per la distribuzione t\n}\ntransformed parameters {\n  real mu2; // Media del gruppo 2\n  mu2 = mu1 + delta;\n}\nmodel {\n  // Priori\n  mu1 ~ normal(0, 5);\n  delta ~ normal(0, 2); // Priore su delta\n  sigma ~ cauchy(0, 5);\n  nu ~ gamma(2, 0.1); // Priore sulla t-student\n  \n  // Verosimiglianza\n  y1 ~ student_t(nu, mu1, sigma);\n  y2 ~ student_t(nu, mu2, sigma);\n}\ngenerated quantities {\n  real diff; // Differenza tra le medie (alias di delta per chiarezza)\n  diff = delta;\n}\n\n\n\n\nfit = model.sample(\n    data=stan_data,\n    seed=123,\n    chains=4,\n    iter_sampling=2_000,\n    iter_warmup=1_000,\n    show_progress=False,\n    show_console=False,\n)\n\n13:53:34 - cmdstanpy - INFO - CmdStan start processing\n13:53:34 - cmdstanpy - INFO - Chain [1] start processing\n13:53:34 - cmdstanpy - INFO - Chain [2] start processing\n13:53:34 - cmdstanpy - INFO - Chain [3] start processing\n13:53:34 - cmdstanpy - INFO - Chain [4] start processing\n13:53:34 - cmdstanpy - INFO - Chain [1] done processing\n13:53:34 - cmdstanpy - INFO - Chain [2] done processing\n13:53:34 - cmdstanpy - INFO - Chain [4] done processing\n13:53:34 - cmdstanpy - INFO - Chain [3] done processing\n13:53:34 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: gamma_lpdf: Random variable is inf, but must be positive finite! (in 'two_means_diff.stan', line 22, column 2 to column 21)\nException: gamma_lpdf: Random variable is inf, but must be positive finite! (in 'two_means_diff.stan', line 22, column 2 to column 21)\nConsider re-running with show_console=True if the above output is unclear!\n\n\n\naz.summary(\n    fit,\n    var_names=[\"mu1\", \"mu2\", \"delta\"],\n    round_to=2,\n    hdi_prob=0.95\n)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu1\n-0.43\n0.30\n-1.03\n0.15\n0.00\n0.0\n4961.74\n4696.27\n1.0\n\n\nmu2\n-0.15\n0.30\n-0.73\n0.42\n0.00\n0.0\n9396.35\n6530.40\n1.0\n\n\ndelta\n0.28\n0.42\n-0.52\n1.12\n0.01\n0.0\n4850.37\n5211.27\n1.0\n\n\n\n\n\n\n\n\n\n# Estrai i campioni di delta\ndelta_samples = fit.stan_variable(\"delta\")\n\n# Disegna la distribuzione a posteriori di delta\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(delta_samples, bins=30, density=True, alpha=0.75, color=color_fill)\nplt.axvline(\n    np.mean(delta_samples),\n    color=color_edge,\n    linestyle=\"--\",\n    label=f\"Mean: {np.mean(delta_samples):.2f}\",\n)\nplt.xlabel(\"delta\")\nplt.ylabel(\"Density\")\nplt.title(\"Posterior distribution of delta\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "href": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.7 Il Giardino dei Sentieri che si Biforcano",
    "text": "94.7 Il Giardino dei Sentieri che si Biforcano\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: ‚ÄúGli studenti appassionati di cucina hanno una maggiore probabilit√† di essere figli unici?‚Äù o ‚ÄúGli studenti provenienti da famiglie battiste sono pi√π inclini a partecipare a club politici scolastici?‚Äù. Meehl evidenzi√≤ che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno ‚ÄúIl Giardino dei Sentieri che si Biforcano‚Äù [Garden of Forking Paths; Gelman e Loken (2013)], riferendosi ai molteplici gradi di libert√† a disposizione del ricercatore nell‚Äôanalisi dei dati. Come nell‚Äôesempio di Meehl, √® possibile esaminare le differenze intergruppo (se questo √® l‚Äôoggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno ‚Äústatisticamente significative‚Äù. Ci√≤ indica che, in quello specifico campione, quel particolare aspetto dei dati √® rilevante. Tuttavia, questa differenza ‚Äústatisticamente significativa‚Äù non sar√† necessariamente generalizzabile ad un altro campione, il quale presenter√† le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman, l‚Äôapproccio basato sul test dell‚Äôipotesi nulla si limita a ‚Äúdescrivere il rumore‚Äù. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all‚Äôavanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un‚Äôottica di inferenza statistica, questo problema √® riconducibile al concetto di ‚Äúp-hacking‚Äù o ‚Äúdata dredging‚Äù, dove l‚Äôesplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati pu√≤ portare a falsi positivi e a una sovrastima della significativit√† statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "href": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.8 Garbage In, Garbage Out",
    "text": "94.8 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l‚Äôipotesi nulla o non la si rifiuta. Ci√≤ implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, √® inevitabile trovare qualche effetto, anche se di minima entit√†.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell‚Äôeffetto e di fornire una distribuzione di probabilit√†. Una distribuzione di probabilit√† √® una rappresentazione grafica delle diverse possibilit√† che potrebbero verificarsi. In questo contesto, si tratta della ‚Äúprobabilit√† inversa‚Äù, ovvero della plausibilit√† dell‚Äôipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed √® il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l‚Äôaggiornamento bayesiano. Il parametro \\(\\delta\\) √® la nostra ipotesi sulla differenza tra le due medie, e l‚Äôinferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL‚Äôapproccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell‚Äôipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di ‚Äúsignificativit√† statistica‚Äù, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l‚Äôapproccio frequentista sia spesso considerato ‚Äúingenuo‚Äù da molti ricercatori, adottare l‚Äôapproccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualit√†. Un principio fondamentale della ricerca √® ‚ÄúGarbage in, garbage out‚Äù. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualit√† delle misurazioni √® insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, pu√≤ trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "94¬† La Crisi della Replicazione",
    "section": "94.9 Esercizi",
    "text": "94.9 Esercizi\n\nEsercizio 94.1 Esistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek, Lorenzino, e Liperoti (2017)). Un recente caso emblematico √® rappresentato dallo studio di Karata≈ü e Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman e Brown (2024) per criticare lo studio di Aungle e Langer (2023), si offra un‚Äôinterpretazione del perch√© lo studio di Karata≈ü e Cutright (2023) non sia stato replicato con successo.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "94¬† La Crisi della Replicazione",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jul 29 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAungle, Peter, e Ellen Langer. 2023. ¬´Physical healing as a function of perceived time¬ª. Scientific Reports 13 (1): 22432.\n\n\nBargh, John A, Mark Chen, e Lara Burrows. 1996. ¬´Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action.¬ª Journal of personality and social psychology 71 (2): 230‚Äì244.\n\n\nBem, Daryl J. 2011. ¬´Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect¬ª. Journal of Personality and Social Psychology 100 (3): 407‚Äì25.\n\n\nBruton, Samuel V, Mary Medlin, Mitch Brown, e Donald F Sacco. 2020. ¬´Personal motivations and systemic incentives: Scientists on questionable research practices¬ª. Science and Engineering Ethics 26 (3): 1531‚Äì47.\n\n\nCaudek, Corrado, Martina Lorenzino, e Rosita Liperoti. 2017. ¬´Delta plots do not reveal response inhibition in lying¬ª. Consciousness and Cognition 55: 232‚Äì44.\n\n\nChivers, Tom. 2024. Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, Open Science. 2015. ¬´Estimating the reproducibility of psychological science¬ª. Science 349 (6251): aac4716.\n\n\nFerguson, Christopher J, e Moritz Heene. 2012. ¬´A vast graveyard of undead theories: Publication bias and psychological science‚Äôs aversion to the null¬ª. Perspectives on Psychological Science 7 (6): 555‚Äì61.\n\n\nGelman, Andrew, e Nicholas JL Brown. 2024. ¬´How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology¬ª.\n\n\nGelman, Andrew, e Eric Loken. 2013. ¬´The garden of forking paths: Why multiple comparisons can be a problem, even when there is no ‚Äúfishing expedition‚Äù or ‚Äúp-hacking‚Äù and the research hypothesis was posited ahead of time¬ª. Department of Statistics, Columbia University 348 (1-17): 3.\n\n\n‚Äî‚Äî‚Äî. 2014. ¬´The statistical crisis in science¬ª. American scientist 102 (6): 460‚Äì65.\n\n\nGopalakrishna, Gowri, Gerben Ter Riet, Gerko Vink, Ineke Stoop, Jelte M Wicherts, e Lex M Bouter. 2022. ¬´Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands¬ª. PloS one 17 (2): e0263023.\n\n\nGrimes, David Robert, Chris T Bauch, e John PA Ioannidis. 2018. ¬´Modelling science trustworthiness under publish or perish pressure¬ª. Royal Society open science 5 (1): 171511.\n\n\nIoannidis, John PA. 2005. ¬´Why most published research findings are false¬ª. PLoS medicine 2 (8): e124.\n\n\nKarata≈ü, Mustafa, e Keisha M Cutright. 2023. ¬´Thinking about God increases acceptance of artificial intelligence in decision-making¬ª. Proceedings of the National Academy of Sciences 120 (33): e2218961120.\n\n\nLakens, Dani√´l. 2015. ¬´On the challenges of drawing conclusions from p-values just below 0.05¬ª. PeerJ 3: e1142.\n\n\nLoken, Eric, e Andrew Gelman. 2017. ¬´Measurement Error and the Replication Crisis¬ª. Science 355 (6325): 584‚Äì85.\n\n\nMeehl, Paul E. 2012. ¬´Why summaries of research on psychological theories are often uninterpretable¬ª. In Improving inquiry in social science, 13‚Äì59. Routledge.\n\n\nMoore, Don A, Juliana Schroeder, Erica R Bailey, Rachel Gershon, Joshua E Moore, e Joseph P Simmons. 2024. ¬´Does thinking about God increase acceptance of artificial intelligence in decision-making?¬ª Proceedings of the National Academy of Sciences 121 (31): e2402315121.\n\n\nNelson, Leif D, Joseph Simmons, e Uri Simonsohn. 2018. ¬´Psychology‚Äôs renaissance¬ª. Annual review of psychology 69 (1): 511‚Äì34.\n\n\nNosek, Brian A, Jeffrey R Spies, e Matt Motyl. 2012. ¬´Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability¬ª. Perspectives on Psychological Science 7 (6): 615‚Äì31.\n\n\nRitchie, Stuart J, Richard Wiseman, e Christopher C French. 2012. ¬´Failing the future: Three unsuccessful attempts to replicate Bem‚Äôs ‚ÄòRetroactive Facilitation of Recall‚ÄôEffect¬ª. PloS one 7 (3): e33423.\n\n\nWare, Jennifer J, e Marcus R Munaf√≤. 2015. ¬´Significance chasing in research practice: causes, consequences and possible solutions¬ª. Addiction 110 (1): 4‚Äì8.\n\n\nYouyou, Wu, Yang Yang, e Brian Uzzi. 2023. ¬´A discipline-wide investigation of the replicability of Psychology papers over the past two decades¬ª. Proceedings of the National Academy of Sciences 120 (6): e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>94</span>¬† <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "95¬† Limiti dell‚Äôinferenza frequentista",
    "section": "",
    "text": "95.1 L‚Äôuso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo ‚ÄúStatistical Errors‚Äù (2014), Nuzzo evidenzia i limiti dell‚Äôapproccio NHST nella pratica scientifica Nuzzo (2014). Infatti, sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ‚Äô20, egli non lo ha mai concepito come un test formale. Invece, Fisher lo considerava uno strumento informale per valutare se l‚Äôevidenza empirica fosse significativa in un senso colloquiale, ovvero meritevole di attenzione. In pratica, Fisher suggeriva di assumere un‚Äôipotesi nulla e di calcolare la probabilit√† di osservare un risultato altrettanto estremo o pi√π estremo di quello trovato, se il risultato fosse completamente dovuto alla sola variabilit√† campionaria. Sebbene sia possibile calcolare il valore-\\(p\\) tramite una procedura matematica, per Fisher esso era solo uno strumento da utilizzare all‚Äôinterno di un processo decisionale non numerico, in grado di combinare le evidenze empiriche attuali con le conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) rappresentava uno strumento da utilizzare all‚Äôinterno del processo decisionale, non la conclusione del processo decisionale stesso.\nVerso la fine degli anni ‚Äô20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l‚Äôobiettivo di renderle ‚Äúrigorose e oggettive‚Äù. In particolare, introdussero i concetti di potere statistico e di falso positivo, ma non utilizzarono la nozione di valore-\\(p\\) come aveva fatto Fisher.\nLe divergenze tra i tre autori portarono a un acceso dibattito, in cui Neyman critic√≤ il lavoro di Fisher come matematicamente ‚Äúpeggiore dell‚Äôinutilit√†‚Äù, mentre Fisher defin√¨ l‚Äôapproccio di Neyman ‚Äúinfantile‚Äù e ‚Äúorribile per la libert√† intellettuale dell‚Äôoccidente‚Äù.\nDurante questo dibattito, altri autori iniziarono a scrivere manuali di statistica per fornire uno strumento di lavoro ai ricercatori. Poich√© molti di questi autori non erano statistici e avevano solo una comprensione superficiale della distinzione tra i vari approcci, crearono un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher all‚Äôinterno del ‚Äúsistema rigoroso‚Äù proposto da Neyman e Pearson. √à in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita come ‚Äústatisticamente significativa‚Äù.\nTuttavia, dal punto di vista storico, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso da quello che viene attribuito oggi nel mondo della ricerca. Come abbiamo visto, il valore-\\(p\\) era solo uno strumento informale utilizzato da Fisher all‚Äôinterno di un processo decisionale pi√π ampio, e il suo uso all‚Äôinterno del sistema ibrido creato dai manuali di statistica era privo di giustificazione e fondamento.\nNel 2016 l‚ÄôAmerican Statistical Association ha pubblicato un articolo nel quale si esprime una grande preoccupazione per l‚Äôuso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica odierna Wasserstein e Lazar (2016):\nL‚Äôarticolo prosegue affermando che:",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "95¬† Limiti dell‚Äôinferenza frequentista",
    "section": "",
    "text": "\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\n\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical ‚Äúbright-line‚Äù rules (such as ‚Äú\\(p &lt; 0.05\\)‚Äù) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‚Äòtrue‚Äô on one side of the divide and ‚Äòfalse‚Äô on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‚Äòyes-no‚Äô decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of ‚Äústatistical significance‚Äù (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "95¬† Limiti dell‚Äôinferenza frequentista",
    "section": "95.2 \\(P\\)-hacking",
    "text": "95.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta la principale fallacia associata all‚Äôutilizzo del valore-\\(p\\) ed √® nota anche come ‚Äú\\(P\\)-hacking‚Äù, ‚Äúdata-dredging‚Äù, ‚Äúsnooping‚Äù, ‚Äúfishing‚Äù, ‚Äúsignificance-chasing‚Äù o ‚Äúdouble-dipping‚Äù. Secondo Uri Simonsohn, docente presso l‚ÄôUniversit√† della Pennsylvania, il \\(P\\)-hacking consiste nel tentativo di provare diverse ipotesi finch√© non si ottiene il risultato desiderato. Ad esempio, si potrebbe dire: ‚ÄúQuel risultato sembra essere stato ottenuto attraverso il \\(p\\)-hacking, gli autori hanno eliminato una delle condizioni in modo che il valore-\\(p\\) complessivo fosse inferiore a 0.05‚Äù oppure ‚ÄúLei √® una \\(p\\)-hacker, controlla sempre i dati mentre vengono raccolti‚Äù.\nQuesta pratica ha l‚Äôeffetto di trasformare uno studio esplorativo, che dovrebbe essere sempre interpretato con cautela, in uno studio (apparentemente) confermativo, il cui risultato appare ‚Äúrobusto‚Äù, ma che in realt√† ha una probabilit√† pressoch√© nulla di essere replicato in studi successivi. Secondo le simulazioni di Simonsohn, il cambiamento di poche decisioni nel processo di analisi dei dati pu√≤ aumentare fino al 60% il tasso di falsi positivi in un singolo studio.\nIl \\(P\\)-hacking √® diffuso soprattutto negli studi che tentano di dimostrare piccoli effetti usando dati molto rumorosi. Un‚Äôanalisi della letteratura psicologica ha mostrato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia minima dello 0.05. Questo risultato pu√≤ essere interpretato come conseguenza della pratica del \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovare uno che risulta ‚Äústatisticamente significativo‚Äù e poi riportano solo quello. Come mostra la figura seguente, questa pratica non riguarda solo la psicologia, ma √® diffusa in tutti i campi della ricerca scientifica.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "95¬† Limiti dell‚Äôinferenza frequentista",
    "section": "95.3 Critiche al valore-\\(p\\)",
    "text": "95.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) √® stato paragonato a creature noiose e ostinate come le zanzare, ai vestiti nuovi dell‚Äôimperatore, ovvero alla tendenza di non voler riconoscere evidenti problemi, ma preferire di far finta di nulla, o ad un intellectual rake sterile, che non porta alcun frutto. Si √® anche ironizzato sul fatto che la procedura di statistical hypothesis inference testing venga chiamata cos√¨ solo per l‚Äôacronimo che produce.\nIl valore-\\(p\\) incoraggia un modo di pensare errato, spostando l‚Äôattenzione dal problema centrale della ricerca, ovvero la forza della manipolazione sperimentale, alla dimostrazione di una falsa ipotesi che si sa a priori essere falsa (l‚Äôipotesi nulla). Ad esempio, uno studio con pi√π di 19.000 individui ha dimostrato che coloro che incontrano il loro partner online hanno una probabilit√† minore di divorziare (\\(p &lt;\\) 0,002) e sono pi√π soddisfatti della loro vita matrimoniale (\\(p &lt;\\) 0,001) rispetto a chi non si √® conosciuto online. Questo pu√≤ sembrare un risultato interessante, ma senza considerare la dimensione dell‚Äôeffetto, ovvero il tasso di divorzio che scende dal 7.67% al 5.96% e l‚Äôaumento dell‚Äôindice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti, il risultato perde di interesse. In generale, la domanda cruciale non √® ‚Äúc‚Äô√® un effetto o no?‚Äù ma piuttosto ‚Äúqual √® la dimensione dell‚Äôeffetto?‚Äù.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-√®-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-√®-esattamente-nullo",
    "title": "95¬† Limiti dell‚Äôinferenza frequentista",
    "section": "95.4 L‚Äôeffetto sperimentale √® esattamente nullo?",
    "text": "95.4 L‚Äôeffetto sperimentale √® esattamente nullo?\nUna delle critiche pi√π frequenti alla logica di verifica delle ipotesi statistiche riguarda l‚Äôassunzione irrealistica che l‚Äôeffetto della manipolazione sperimentale sia ‚Äúesattamente‚Äù nullo. Ad esempio, la fisica ci insegna che lo spostamento di un grammo di massa in una stella distante qualche anno luce dalla Terra pu√≤ influenzare il movimento delle molecole di un gas sulla Terra Borel (1914). Questo ci suggerisce che ogni manipolazione sperimentale produca, in qualche modo, un effetto. Pertanto, secondo Andrew Gelman, il problema non √® dimostrare falsa l‚Äôipotesi nulla, ovvero che la manipolazione sperimentale non produca alcun effetto, ma piuttosto valutare se la dimensione dell‚Äôeffetto √® sufficientemente grande da avere un impatto pratico e se l‚Äôeffetto sia riproducibile. In questo senso, la logica di verifica dell‚Äôipotesi nulla pu√≤ essere problematica, soprattutto quando si lavora con piccoli campioni e piccoli effetti, come nella maggior parte degli studi in psicologia, poich√© pu√≤ portare ad una sovrastima della dimensione dell‚Äôeffetto e ad una visione binaria del risultato (vero/falso), invece di concentrarsi sulla stima non distorta della dimensione effettiva dell‚Äôeffetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "95¬† Limiti dell‚Äôinferenza frequentista",
    "section": "95.5 Attenti al valore-\\(p\\)!",
    "text": "95.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Eseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo a verifica l‚Äôipotesi nulla dell‚Äôeguaglianza delle due medie. Sia \\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual √® la probabilit√† che i due campioni siano tratti da distribuzioni con la stessa media?\n\n\\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d) \\(95/100; \\quad\\) (e) sconosciuta.\n\nLa risposta corretta √®: (e) sconosciuta. La statistica frequentista definisce le probabilit√† dei dati condizionatamente alle ipotesi (assunte come vere). Non consente di stabilire la probabilit√† di un‚Äôipotesi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilit√†-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilit√†-dei-risultati-della-ricerca",
    "title": "95¬† Limiti dell‚Äôinferenza frequentista",
    "section": "95.6 La crisi della riprodicibilit√† dei risultati della ricerca",
    "text": "95.6 La crisi della riprodicibilit√† dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilit√† dei risultati della ricerca - inclusa la ricerca psicologica - √® diventata un tema di grande rilevanza. In questo contesto, √® stato evidenziato che alcuni aspetti del metodo scientifico, in particolare il concetto di valore-p e la pratica di verificare la significativit√† dell‚Äôipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a questa ‚Äúcrisi della ricerca scientifica‚Äù. Un‚Äôanalisi pi√π approfondita di questo problema √® stata fornita da Gelman (2016), il quale sostiene che la pratica della NHST sia intrinsecamente problematica. Infatti, essa incoraggia il ricercatore a cercare di rigettare un‚Äôipotesi ‚Äúfantoccio‚Äù (straw-man) che √® certamente falsa a priori o, almeno, poco interessante dal punto di vista scientifico, a favore di un‚Äôipotesi alternativa che il ricercatore preferisce. In generale, sembra pi√π ragionevole affermare che la differenza tra due condizioni sia molto piccola, piuttosto che affermare che sia esattamente uguale a zero.\nSpesso nei libri di statistica viene trasmesso il messaggio che la NHST sia una forma di ‚Äúalchimia‚Äù che cerca di trasformare la casualit√† in una sorta di certezza, con l‚Äôuso di termini come ‚Äúconfidenza‚Äù e ‚Äúsignificativit√†‚Äù Gelman (2016). Il processo di raccolta dei dati, analisi e inferenza statistica che ne segue viene poi riassunto in una conclusione espressa in termini di valore-p e di intervallo di confidenza che escludono lo zero. Tuttavia, ci√≤ pu√≤ dare l‚Äôimpressione errata che il ricercatore abbia una comprensione completa delle propriet√† del fenomeno in questione. Il problema principale della NHST √® che spesso produce risultati ‚Äústatisticamente significativi‚Äù in situazioni in cui le caratteristiche del fenomeno non giustificano la conclusione a cui il ricercatore arriva. Questo pu√≤ portare alla non replicabilit√† dei risultati della ricerca.\nLa comunit√† degli statistici ha evidenziato come la non replicabilit√† dei risultati delle ricerche sia particolarmente evidente quando i ricercatori, utilizzando la metodologia NHST, giungono a conclusioni errate basate sull‚Äôosservazione di piccoli campioni con effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono estremamente problematica l‚Äôapplicazione della NHST. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia.\nLa statistica √® stata definita come un metodo per prendere decisioni razionali in situazioni di incertezza. Gli statistici consigliano ai ricercatori di non solo diventare esperti nelle tecniche statistiche, ma anche di imparare a convivere con l‚Äôincertezza, nonostante la sempre crescente sofisticazione delle tecniche disponibili. Convivere con l‚Äôincertezza implica evitare di pensare che ottenere un valore-\\(p\\) ‚Äústatisticamente significativo‚Äù significhi risolvere un problema scientifico. Come possiamo allora avere fiducia in ci√≤ che abbiamo appreso dai dati? Una possibile strategia √® la replicazione e la convalida esterna, ma nella ricerca in psicologia e nelle scienze sociali, questo pu√≤ spesso essere difficile da perseguire a causa degli oneri elevati che comporta. Il problema di quali strumenti metodologici e metodi statistici siano pi√π appropriati per indagare sui fenomeni psicologici, senza essere ingannati, rimane dunque un problema aperto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "95¬† Limiti dell‚Äôinferenza frequentista",
    "section": "95.7 Commenti e considerazioni finali",
    "text": "95.7 Commenti e considerazioni finali\nNon possiamo concludere senza sottolineare la controversia che circonda la nozione di valore-\\(p\\). Pur essendo ancora ampiamente utilizzato e spesso interpretato erroneamente, il valore-\\(p\\) conferisce solo una patina di legittimit√† ai risultati di studi dubbi, incoraggia cattive pratiche di ricerca e promuove la produzione di falsi positivi. Inoltre, √® difficile comprendere appieno il significato di questa nozione. Anche gli esperti, quando chiamati a fornire una definizione di valore-\\(p\\), spesso sbagliano la risposta. Ci√≤ che i ricercatori vogliono sapere √® se i risultati della ricerca sono corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell‚Äôeffetto, sulla forza dell‚Äôevidenza o sulla probabilit√† che il risultato sia stato ottenuto casualmente. Quindi, qual √® il suo significato? Stuart Buck risponde cos√¨:\n\nImagine that you have a coin that you suspect is weighted toward heads. (Your null hypothesis is then that the coin is fair.) You flip it 100 times and get more heads than tails. The \\(p\\)-value won‚Äôt tell you whether the coin is fair, but it will tell you the probability that you‚Äôd get at least as many heads as you did if the coin was fair. That‚Äôs it ‚Äì nothing more.\n\nIn sintesi, possiamo concludere che il valore-\\(p\\) risponde a una domanda molto specifica che non ha alcuna rilevanza per la validit√† scientifica dei risultati della ricerca. In un‚Äôepoca in cui la crisi della riproducibilit√† dei risultati √® sempre pi√π evidente Baker (2016), il test dell‚Äôipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema, spingendo molti ricercatori a cercare soluzioni alternative.\n\n\n\n\nBaker, Monya. 2016. ¬´Reproducibility Crisis¬ª. Nature 533 (7604): 452‚Äì54.\n\n\nBorel, Emile. 1914. Introduction G√©om√©trique. G. Villars, New York.\n\n\nGelman, Andrew. 2016. ¬´Commentary on ‚ÄúCrisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science‚Äù¬ª. Journal of Statistical Research 48-50 (1): 11‚Äì12.\n\n\nNuzzo, Regina. 2014. ¬´Statistical Errors¬ª. Nature 506 (7487): 150‚Äì52.\n\n\nWasserstein, Ronald L, e Nicole A Lazar. 2016. ¬´The ASA‚Äôs statement on p-values: context, process, and purpose¬ª. The American Statistician 70 (2): 129‚Äì33.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>95</span>¬† <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "96¬† La grandezza dell‚Äôeffetto",
    "section": "",
    "text": "Introduzione\nLa dimensione dell‚Äôeffetto (effect size) √® un concetto fondamentale nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura rappresenta l‚Äôentit√† dell‚Äôeffetto di un intervento o di un trattamento in modo standardizzato, descrivendo in termini quantitativi l‚Äôimportanza di un fenomeno osservato.\n√à cruciale distinguere tra la dimensione dell‚Äôeffetto e la significativit√† statistica. Un risultato pu√≤ essere ‚Äústatisticamente significativo‚Äù pur avendo un effetto di piccole dimensioni, e viceversa. La conoscenza di uno di questi concetti non fornisce automaticamente informazioni sull‚Äôaltro, evidenziando la necessit√† di considerare entrambi gli aspetti nell‚Äôanalisi dei dati.\nL‚Äôimportanza della dimensione dell‚Äôeffetto √® ampiamente riconosciuta nel campo della ricerca scientifica. Il manuale dell‚ÄôAmerican Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di riportare questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all‚ÄôAPA include la dimensione dell‚Äôeffetto, generalmente indicata tra parentesi accanto al valore di p.\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell‚Äôeffetto. Molti ricercatori si limitano a comunicare questi valori senza esaminarli approfonditamente, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza rivela una sottovalutazione sistematica e una diffusa incomprensione delle dimensioni dell‚Äôeffetto, anche tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "96¬† La grandezza dell‚Äôeffetto",
    "section": "96.1 Misurazione dell‚ÄôEffetto: Approcci e Applicazioni",
    "text": "96.1 Misurazione dell‚ÄôEffetto: Approcci e Applicazioni\nTra le metriche pi√π adottate per quantificare la dimensione dell‚Äôeffetto si annoverano il \\(d\\) di Cohen e l‚Äô\\(r\\) di Pearson. Il \\(d\\) di Cohen √® prevalentemente impiegato per descrivere le differenze tra le medie di gruppi sperimentali, quantificando questa differenza in termini di una deviazione standard aggregata.\nLa differenza standardizzata delle medie tra due gruppi pu√≤ essere calcolata con la seguente formula (equazione 5.1, Glass, McGaw, e Smith 1981),\n\\[\nd_p = \\frac{M_1 - M_2}{S_p}.\n\\]\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 √® maggiore della media del gruppo 2. Dividere la differenza delle medie per la deviazione standard combinata, \\(S_p\\), √® la formulazione classica del \\(d\\) di Cohen. La deviazione standard combinata, \\(S_p\\), pu√≤ essere calcolata come la radice quadrata della varianza media (ponderata per i gradi di libert√†, \\(df = n-1\\)) del gruppo 1 e del gruppo 2 (pp.¬†108, Glass, McGaw, e Smith 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}}.\n\\]\nSi noti che il termine varianza si riferisce al quadrato della deviazione standard (\\(S^2\\)). Il \\(d_p\\) di Cohen √® correlato alla statistica t di un test t per campioni indipendenti. Infatti, possiamo calcolare il valore di \\(d_p\\) a partire dalla statistica \\(t\\) con la seguente formula (equazione 5.3, Glass, McGaw, e Smith 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL‚Äôerrore standard corrispondente di \\(d_p\\) √®,\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nLa statistica \\(r\\) di Pearson, d‚Äôaltro canto, viene utilizzato per esprimere il grado di previsione di una variabile attraverso un‚Äôaltra, fornendo una misura della correlazione. √à interessante notare come queste due misure possano essere convertite l‚Äôuna nell‚Äôaltra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "title": "96¬† La grandezza dell‚Äôeffetto",
    "section": "96.2 Interpretare la Dimensione dell‚ÄôEffetto",
    "text": "96.2 Interpretare la Dimensione dell‚ÄôEffetto\nL‚Äôinterpretazione delle dimensioni dell‚Äôeffetto solitamente avviene in due modi comuni: uno √® privo di significato e l‚Äôaltro √® seriamente fuorviante.\n\nGli Standard di Cohen. Funder (2019) affermano che l‚Äôinterpretazione pi√π ampiamente utilizzata ma priva di senso delle dimensioni dell‚Äôeffetto richiama gli standard stabiliti da Jacob Cohen (1977, 1988). Cohen ha fissato i valori di r di .10, .30 e .50 come soglie per effetti piccoli, medi e grandi, rispettivamente. Tuttavia, Cohen stesso ha dichiarato che queste soglie dovrebbero essere utilizzate solo in assenza di una base migliore e in seguito ha espresso rammarico per averle proposte.\nI termini ‚Äúpiccolo‚Äù, ‚Äúmedio‚Äù e ‚Äúgrande‚Äù sono privi di significato senza un contesto di riferimento. √à necessario rispondere a due domande fondamentali: (a) piccolo, medio o grande rispetto a cosa? e (b) piccolo, medio o grande a quale scopo?\nElevare al Quadrato la Correlazione. Secondo Funder e Ozer (2019), un altro metodo comune per valutare la dimensione dell‚Äôeffetto √® ancora pi√π problematico: elevare al quadrato il valore di r. Ad esempio, un r di .30 elevato al quadrato produce .09, interpretato come ‚Äúproporzione di varianza spiegata‚Äù. Questa conversione spesso viene riportata con la parola ‚Äúsolo‚Äù, come in ‚Äúla correlazione di .30 ha spiegato solo il 9% della varianza‚Äù.\nNon esiste una giustificazione valida per considerare r¬≤ come una misura appropriata della dimensione dell‚Äôeffetto. La statistica r corrisponde alla pendenza di regressione quando entrambe le variabili sono standardizzate, mentre r¬≤ √® molto meno interpretabile perch√© riflette la proporzione di varianza in una variabile spiegata da un‚Äôaltra.\nUn esempio illustrativo √® fornito da Darlington (1990). Immaginiamo un gioco in cui si lanciano prima un nickel (5¬¢) e poi un dime (10¬¢), ricevendo un pagamento di 5¬¢ o 10¬¢ rispettivamente se la moneta mostra testa. Le correlazioni tra il valore del nickel e il pagamento (r = .4472) e tra il valore del dime e il pagamento (r = .8944) sono calcolate. Elevando al quadrato queste correlazioni, si ottiene che i nickel spiegano il 20% della varianza nel pagamento, mentre i dime spiegano l‚Äô80%. Tuttavia, interpretare questi valori come indicazione che i dime contano quattro volte tanto quanto i nickel √® fuorviante. Le correlazioni originali (.8944 √® esattamente il doppio di .4472) offrono un confronto pi√π informativo. In conclusione, elevare al quadrato r per valutare la dimensione dell‚Äôeffetto non solo √® poco informativo, ma pu√≤ anche essere fuorviante.\n\n\n96.2.1 Alternative migliori\n√à cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder e Ozer (2019) propongono due strategie principali: l‚Äôadozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l‚Äôentit√† di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l‚Äôaltezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell‚Äôimportanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking pu√≤ includere l‚Äôanalisi di risultati considerati ‚Äúclassici‚Äù nel campo di interesse o la considerazione di dimensioni dell‚Äôeffetto per risultati che hanno ottenuto un solido consenso nella comunit√† psicologica.\nIn un‚Äôottica pi√π ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell‚Äôeffetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell‚Äôeffetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio √® l‚Äôefficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l‚Äôeffetto degli anti-infiammatori non steroidei (come l‚Äôibuprofene) sul dolore √® di \\(r = .14\\).\n\nTali confronti illustrano come l‚Äôinterpretazione delle dimensioni dell‚Äôeffetto possa essere notevolmente approfondita e resa pi√π significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto pi√π vasto, favorendo una valutazione pi√π consapevole della loro rilevanza relativa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "href": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "title": "96¬† La grandezza dell‚Äôeffetto",
    "section": "96.3 Raccomandazioni per la Pratica di Ricerca",
    "text": "96.3 Raccomandazioni per la Pratica di Ricerca\nFunder e Ozer (2019) concludono il loro articolo con una serie di raccomandazioni per migliorare la pratica di riportare le dimensioni degli effetti negli studi scientifici.\nRiportare sempre e in modo evidente le dimensioni degli effetti. Ogni studio dovrebbe evidenziare chiaramente le dimensioni degli effetti. Una conseguenza di questa raccomandazione √® che la dimensione del campione di uno studio deve essere adeguata affinch√© la stima della dimensione dell‚Äôeffetto sia affidabile.\nCondurre studi con campioni ampi. Studi con campioni ampi sono ideali. Sebbene questo non sia sempre fattibile con certi tipi di ricerca o popolazioni specifiche, dovrebbe essere una priorit√† aumentare il pi√π possibile la dimensione del campione.\nRiportare le dimensioni degli effetti in termini utili nel contesto. Il coefficiente di correlazione \\(r\\) di Pearson, essendo una misura standardizzata della dimensione dell‚Äôeffetto, non fornisce informazioni sulle unit√† di misura dello studio. Pertanto, √® necessario utilizzare misure delle dimensioni degli effetti che siano utili nel contesto specifico dello studio, come differenze medie o coefficienti di regressione grezzi, accanto a misure standardizzate, quando possibile.\nEvitare terminologia vuota. Si dovrebbe smettere di elevare al quadrato i valori di \\(r\\) per minimizzare l‚Äôapparente piccola percentuale di varianza spiegata e di utilizzare senza riflettere le linee guida di J. Cohen (1977, 1988), che lo stesso Cohen ha successivamente disconosciuto. Idealmente, termini come ‚Äúpiccolo‚Äù e ‚Äúgrande‚Äù dovrebbero essere eliminati dal vocabolario delle dimensioni degli effetti, poich√© sono etichette soggettive e spesso arbitrarie che non aggiungono informazioni utili ai risultati quantitativi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "title": "96¬† La grandezza dell‚Äôeffetto",
    "section": "96.4 Commenti e considerazioni finali",
    "text": "96.4 Commenti e considerazioni finali\nLa sovrastima della grandezza dell‚Äôeffetto in psicologia costituisce un problema diffuso. Un principio fondamentale della psicologia sociale e dell‚Äôeconomia comportamentale, almeno come viene presentato nei media e insegnato in molte scuole di business, √® che piccoli ‚Äúnudge‚Äù o spinte gentili, spesso cose che potremmo pensare non ci influenzino affatto, possono avere grandi effetti sul comportamento. Questo ha portato a numerose affermazioni sensazionalistiche, come l‚Äôidea che le elezioni siano decise da partite di football, o che la presentazione subliminale di una faccina sorridente possa causare enormi cambiamenti negli atteggiamenti verso l‚Äôimmigrazione.\nIl modello di mondo alla base di queste affermazioni non √® solo ‚Äúl‚Äôeffetto farfalla‚Äù, ovvero che piccoli cambiamenti possono avere grandi effetti, ma piuttosto che piccoli cambiamenti possono avere effetti grandi e prevedibili. √à quello che a volte viene chiamato il modello ‚Äúa pulsante‚Äù delle scienze sociali: l‚Äôidea che se fai X, puoi aspettarti di vedere Y.\nTuttavia, questa visione presenta diversi problemi:\n\nSovrastima degli effetti: Molti studi riportano effetti sorprendentemente grandi per interventi minimi, che spesso non vengono replicati in studi successivi.\nMancanza di considerazione delle interazioni: Se esistessero molti effetti grandi e prevedibili sul comportamento, questi interferirebbero tra loro, rendendo difficile osservare effetti coerenti nei dati osservazionali.\nInstabilit√†: Un sistema sociale con molti effetti grandi e prevedibili sarebbe instabile e difficile da studiare.\nGeneralizzazione eccessiva: Spesso si tende a generalizzare risultati ottenuti in condizioni di laboratorio molto specifiche a contesti pi√π ampi e complessi della vita reale.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilit√† di essere pubblicati, creando una rappresentazione distorta della realt√†.\n\n√à importante sottolineare che la psicologia descrive molti fenomeni robusti, per esempio nella psicologia clinica e nella psicologia della percezione. Tuttavia, √® fondamentale adottare un approccio pi√π cauto e sfumato nell‚Äôinterpretazione e nella comunicazione dei risultati della ricerca psicologica. La consapevolezza di questo problema ha portato a una maggiore enfasi sulla replicabilit√† degli studi, sull‚Äôuso di campioni pi√π ampi e su metodi statistici pi√π robusti. Inoltre, sta emergendo un approccio pi√π critico e riflessivo nella comunit√† scientifica, che riconosce la complessit√† dei fenomeni psicologici e la necessit√† di evitare semplificazioni eccessive.\nIn conclusione, mentre la psicologia offre preziose intuizioni sul comportamento umano, √® essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realt√† √® spesso pi√π complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi.\n\n\n\n\nFunder, David C, e Daniel J Ozer. 2019. ¬´Evaluating effect size in psychological research: Sense and nonsense¬ª. Advances in Methods and Practices in Psychological Science 2 (2): 156‚Äì68.\n\n\nGlass, Gene V., Barry McGaw, e Mary L. Smith. 1981. Meta-analysis in Social Research. Beverly Hills, CA: Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>96</span>¬† <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "97¬† Errori di segno e errori di grandezza",
    "section": "",
    "text": "Introduzione\nIn questo capitolo verr√† esaminata la relazione tra la crisi della replicabilit√† e la procedura di decisione statistica dell‚Äôapproccio frequentista. In particolare, verranno discussi gli errori di tipo M (magnitude) e di tipo S (sign) che sono stati discussi da Loken e Gelman (2017).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significativit√†-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significativit√†-statistica",
    "title": "97¬† Errori di segno e errori di grandezza",
    "section": "97.1 Il Filtro della Significativit√† Statistica",
    "text": "97.1 Il Filtro della Significativit√† Statistica\nNel Capitolo 94 abbiamo esaminato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle notevoli implicazioni economiche legate alla pubblicazione su riviste scientifiche prestigiose. Questo problema √® frequentemente sottovalutato, poich√© le riviste sono riluttanti ad ammettere la necessit√† di correzioni o ritrattazioni degli articoli gi√† pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilit√† dei risultati, pilastro fondamentale del metodo scientifico. Tuttavia, le difficolt√† nel replicare i risultati pubblicati non sono attribuibili esclusivamente alla frode o a ‚Äúpratiche di ricerca disoneste‚Äù (Nelson, Simmons, e Simonsohn 2018). Un problema intrinseco riguarda il metodo statistico ampiamente adottato dai ricercatori: l‚Äôapproccio del test di ipotesi nulla e della significativit√† statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la ‚Äúsignificativit√† statistica‚Äù dovrebbero essere scartati, mentre quelli che la superano possono essere considerati credibili, basandosi unicamente su questo criterio (Wagenmakers et al. 2008).\nTuttavia, l‚Äôidea che la significativit√† statistica sia un filtro affidabile per distinguere i risultati di ricerca ‚Äúvalidi‚Äù da quelli ‚Äúnon validi‚Äù √® fondamentalmente errata. Numerose evidenze dimostrano la fallacia di questo approccio. Per approfondire questo aspetto, esamineremo lo studio di Loken e Gelman (2017), che mette in luce la relazione tra la crisi della replicabilit√† e la procedura di decisione statistica dell‚Äôapproccio frequentista.\nUno dei principali problemi evidenziati dallo studio di Loken e Gelman (2017) √® che, in contesti di ricerca complessi, la significativit√† statistica fornisce prove molto deboli riguardo al segno o all‚Äôentit√† di eventuali effetti sottostanti. In altre parole, il raggiungimento della significativit√† statistica non garantisce n√© la rilevanza n√© la consistenza dei risultati ottenuti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "97¬† Errori di segno e errori di grandezza",
    "section": "97.2 Errori di tipo M e S",
    "text": "97.2 Errori di tipo M e S\nPer evidenziare le implicazioni del processo decisionale basato sulla significativit√† statistica, gli autori di Loken e Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno immaginato una ricerca ipotetica in cui un effetto reale, seppur molto debole, era presente, ma difficilmente individuabile senza una grande quantit√† di dati. I ricercatori hanno quindi cercato di rilevare questo effetto utilizzando l‚Äôapproccio frequentista e valutando la significativit√† statistica.\nI risultati della simulazione hanno rivelato che, anche quando un effetto reale ma debole era presente, l‚Äôapproccio frequentista tendeva a individuare un effetto significativo solo in una piccola percentuale dei casi. Inoltre, quando veniva individuato un effetto significativo, la sua stima di grandezza risultava molto imprecisa e instabile.\nIn altre parole, la significativit√† statistica fornisce solo un‚Äôindicazione generale sulla presenza o assenza di un effetto, ma non offre informazioni precise sulla sua dimensione o replicabilit√†. Questo problema diventa ancora pi√π evidente quando si considera che molte ricerche in psicologia e scienze sociali utilizzano campioni relativamente piccoli, e gli effetti osservati in tali studi tendono ad essere molto modesti. In tali contesti, l‚Äôapproccio frequentista rischia di fornire prove molto deboli e instabili riguardo alla presenza o assenza di un effetto, mettendo a rischio la replicabilit√† e l‚Äôaffidabilit√† dei risultati della ricerca.\nRiproduciamo qui, in maniera semplificata, la simulazione condotta da Loken e Gelman (2017). Iniziamo ad importare le librerie necessarie.\nSupponiamo di considerare due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\) rispettivamente. La dimensione effettiva dell‚Äôeffetto per la differenza tra le medie di questi due campioni √® rappresentata da \\(d\\), calcolato attraverso la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) sono le medie campionarie dei due gruppi, mentre \\(s_p\\) √® la deviazione standard combinata definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ncon \\(s_1\\) e \\(s_2\\) rappresentanti le deviazioni standard campionarie dei due gruppi.\nNel caso specifico preso in esame, la dimensione effettiva dell‚Äôeffetto √® molto piccola, indicando che la differenza osservata tra le medie manca di significativit√† pratica. Questo suggerisce che la distinzione tra i due gruppi non ha un impatto sostanziale nella pratica.\n\nmu_1 = 102\nmu_2 = 100\nsigma = 10\nn1 = 20\nn2 = 25\n\n\nmean_difference = abs(mu_1 - mu_2)\npooled_sd = np.sqrt(((n1 - 1) * sigma**2 + (n2 - 1) * sigma**2) / (n1 + n2 - 2))\ncohen_d = mean_difference / pooled_sd\n\nprint(\"Cohen's d effect size:\", cohen_d)\n\nCohen's d effect size: 0.2\n\n\nEsaminiamo ora quali sarebbero le conclusioni derivanti dall‚Äôapproccio frequentista mediante la procedura di decisione statistica in queste circostanze. Consideriamo una simulazione in cui vengono estratti due campioni: uno composto da 20 osservazioni dalla prima popolazione e l‚Äôaltro da 25 osservazioni dalla seconda popolazione. Successivamente, viene eseguito il test \\(t\\) di Student.\nNell‚Äôapproccio frequentista, se il valore-\\(p\\) risulta essere superiore a 0.05, i risultati vengono considerati non significativi e quindi scartati. Al contrario, se il valore-\\(p\\) √® inferiore a 0.05, il risultato √® considerato ‚Äúpubblicabile‚Äù e si conclude che esiste una differenza significativa tra i due gruppi.\nPer comprendere appieno le conclusioni ottenute mediante la procedura frequentista in questa situazione, √® necessario ripetere il processo sopra descritto per un ampio numero di iterazioni, ad esempio 50,000 volte. Questo implica che il processo di estrazione dei campioni e il calcolo dei valori-\\(p\\) vengono ripetuti numerose volte al fine di ottenere una visione completa delle possibili distribuzioni dei risultati.\n\nn_samples = 50000\n\nres = []\n\nfor i in range(n_samples):\n    # Get random samples \n    y1 = np.random.normal(loc=mu_1, scale=sigma, size=n1)\n    y2 = np.random.normal(loc=mu_2, scale=sigma, size=n2)\n    # Compute effect size\n    y1bar = y1.mean()\n    y2bar = y2.mean()\n    v1 = np.var(y1, ddof=1)\n    v2 = np.var(y2, ddof=1)\n    s = np.sqrt(((n1-1)*v1 + (n2-1)*v2) / (n1 + n2 - 2))\n    efsize = (y1bar - y2bar) / s\n    # Compute p-value\n    out = stats.ttest_ind(a=y1, b=y2, equal_var=True)\n    # Save effect size only for 'statistically significant' results\n    if out.pvalue &lt; 0.05:\n        res.append(efsize)\n\nEsaminiamo un istogramma dei casi nei quali il valore-\\(p\\) √® stato &lt; 0.05.\n\nplt.hist(res, bins=20)\nplt.axvline(\n    x=0.2, color=\"red\", linestyle=\"dashed\", linewidth=2, label=\"True Effect Size\"\n)\nplt.xlabel(\"Effect Size\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of Effect Sizes for 'Statistically Significant' Results\")\nplt.legend()\n_ = plt.show()\n\n\n\n\n\n\n\n\nCome sottolineato da Loken e Gelman (2017), l‚Äôutilizzo dell‚Äôapproccio frequentista nella procedura di decisione statistica pu√≤ portare a due tipi di errori significativi. Il primo errore, noto come ‚Äúmagnitude‚Äù, si manifesta nel fatto che i risultati pubblicati tendono a sovrastimare la vera grandezza dell‚Äôeffetto. Nella simulazione effettuata, sebbene la vera grandezza dell‚Äôeffetto fosse modesta (0.2), la media della grandezza dell‚Äôeffetto per i risultati dichiarati ‚Äústatisticamente significativi‚Äù era di circa 0.8, indicando una grandezza dell‚Äôeffetto ‚Äúampia‚Äù.\nIl secondo errore, denominato ‚Äúsegno‚Äù, si verifica in alcune situazioni in cui, a causa della variabilit√† campionaria, viene commesso un errore nella direzione dell‚Äôeffetto. In tali circostanze, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realt√† non √® cos√¨. √à importante notare che, anche in questi casi, la grandezza dell‚Äôeffetto viene sovrastimata in termini assoluti.\n√à interessante notare che le stesse conclusioni si applicherebbero anche se avessimo considerato l‚Äôintervallo di confidenza per la differenza tra le medie. In sintesi, l‚Äôapproccio frequentista introduce un errore sistematico nella stima della grandezza dell‚Äôeffetto, che √® la quantit√† pi√π importante che il ricercatore deve stimare. In alcune situazioni, pu√≤ persino causare errori nella stima della direzione dell‚Äôeffetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#considerazioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#considerazioni-conclusive",
    "title": "97¬† Errori di segno e errori di grandezza",
    "section": "97.3 Considerazioni conclusive",
    "text": "97.3 Considerazioni conclusive\nIn conclusione, l‚Äôapproccio frequentista non fornisce un metodo affidabile per valutare i risultati della ricerca e determinare la loro attendibilit√† o la necessit√† di scartarli [gelman2014beyond; Loken e Gelman (2017)]. Questa mancanza di affidabilit√† deriva dall‚Äôintroduzione di errori sistematici nella stima delle dimensioni dell‚Äôeffetto, che pu√≤ anche portare a errori nella direzione dell‚Äôeffetto in alcune circostanze. Di conseguenza, non sembra esserci motivo valido per continuare a impiegare questo approccio.\nAl contrario, l‚Äôadozione dell‚Äôapproccio bayesiano sembra offrire risultati pi√π precisi e affidabili nella valutazione dei dati di ricerca. Tale approccio considera la probabilit√† delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell‚Äôapproccio frequentista e fornendo una base pi√π solida per le decisioni sulla validit√† dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "97¬† Errori di segno e errori di grandezza",
    "section": "97.4 Esercizi",
    "text": "97.4 Esercizi\n\nEsercizio 97.1 Esegui una simulazione con 10.000 ripetizioni (nrep = 10000) in cui vengono estratti due campioni casuali dalla stessa popolazione normale con media 0 e deviazione standard 10. Per ogni simulazione, esegui un t-test per confrontare le medie di due gruppi indipendenti.\n\nProporzione di risultati statisticamente significativi: Calcola la proporzione di risultati in cui si ottiene un risultato statisticamente significativo (p &lt; 0.05) in questa condizione in cui i campioni provengono dalla stessa popolazione, e quindi non c‚Äô√® una differenza reale tra i gruppi. Questo ti dar√† un‚Äôidea della frequenza dei falsi positivi.\nGrandezza dell‚Äôeffetto media: Calcola la grandezza dell‚Äôeffetto (d di Cohen) media, considerando solo quei test in cui si √® ottenuta una differenza statisticamente significativa. Questo valore ti mostrer√† quanto grande appare l‚Äôeffetto quando il risultato √® significativo, nonostante la realt√† sia priva di un effetto reale.\nRipetizione della simulazione con diverse grandezze campionarie: Ripeti la simulazione usando due diverse dimensioni campionarie: 20 osservazioni per gruppo e 200 osservazioni per gruppo. Confronta i risultati per capire come la dimensione del campione influenzi la proporzione di falsi positivi e la grandezza dell‚Äôeffetto media.\nInterpretazione dei risultati: Interpreta i risultati alla luce del concetto del ‚Äúfiltro della significativit√† statistica‚Äù. Questo concetto suggerisce che tra tutti gli studi effettuati, tendono ad essere pubblicati e riportati solo quelli che ottengono risultati statisticamente significativi. Di conseguenza, i risultati significativi pubblicati possono sovrastimare la vera grandezza dell‚Äôeffetto o indicare erroneamente che un effetto esiste quando in realt√† non c‚Äô√®. Questa simulazione dovrebbe mostrare come, anche in assenza di una differenza reale tra gruppi, si possano ottenere risultati apparentemente significativi con una certa frequenza, soprattutto quando la dimensione campionaria √® piccola.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "97¬† Errori di segno e errori di grandezza",
    "section": "97.5 Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "97.5 Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\narviz     : 0.18.0\nscipy     : 1.13.0\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nLoken, Eric, e Andrew Gelman. 2017. ¬´Measurement Error and the Replication Crisis¬ª. Science 355 (6325): 584‚Äì85.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nNelson, Leif D, Joseph Simmons, e Uri Simonsohn. 2018. ¬´Psychology‚Äôs renaissance¬ª. Annual review of psychology 69 (1): 511‚Äì34.\n\n\nWagenmakers, Eric-Jan, Michael Lee, Tom Lodewyckx, e Geoffrey J Iverson. 2008. ¬´Bayesian versus frequentist inference¬ª. Bayesian evaluation of informative hypotheses, 181‚Äì207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>97</span>¬† <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_changes.html",
    "href": "chapters/replication_crisis/05_changes.html",
    "title": "98¬† Proposte di cambiamento",
    "section": "",
    "text": "98.1 Introduzione\nLa crisi della riproducibilit√† ha portato a una profonda riflessione sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non erano replicabili ha scosso la fiducia nella ricerca scientifica e ha messo in evidenza le carenze metodologiche e strutturali che affliggono il sistema accademico. Di fronte a questa crisi, sono state avanzate diverse proposte di riforma volte a migliorare la qualit√† e l‚Äôaffidabilit√† della ricerca scientifica.\nSecondo Korbmacher et al. (2023) sono neccessarie riforme strutturali, cambiamenti procedurali e cambiamenti nella comunit√† scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>¬† <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_changes.html#introduzione",
    "href": "chapters/replication_crisis/05_changes.html#introduzione",
    "title": "98¬† Proposte di cambiamento",
    "section": "",
    "text": "98.1.1 Riforme Strutturali\n\n98.1.1.1 Integrazione della Riproducibilit√† nei Curriculum Educativi\nUna delle principali proposte per affrontare la crisi della riproducibilit√† √® l‚Äôintegrazione delle pratiche di riproducibilit√† nei curriculum educativi delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non pongono sufficiente enfasi sull‚Äôimportanza della replicabilit√† e della trasparenza nella ricerca. Incorporare queste tematiche nei corsi di metodologia della ricerca pu√≤ sensibilizzare le nuove generazioni di ricercatori alla necessit√† di adottare pratiche pi√π rigorose e trasparenti. Ad esempio, alcuni programmi universitari hanno iniziato a includere repliche di studi famosi come parte del percorso formativo degli studenti, offrendo loro l‚Äôopportunit√† di comprendere meglio i limiti e le potenzialit√† del processo scientifico.\n\n\n98.1.1.2 Incentivi per la Scienza Aperta\nOltre alla formazione, un altro aspetto cruciale √® la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantit√† di pubblicazioni e la novit√† dei risultati, piuttosto che la loro qualit√† e replicabilit√†. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l‚Äôintroduzione di riconoscimenti ufficiali, come badge di ‚Äúopen science‚Äù o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, √® interessante considerare uno studio di Scheel, Schijen, e Lakens (2021). Gli autori hanno confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, hanno riscontrato che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.\n\n\n\n98.1.2 Cambiamenti Procedurali\n\n98.1.2.1 Mercati di Previsione per la Credibilit√† della Ricerca\nI mercati di previsione sono stati proposti come uno strumento innovativo per valutare la credibilit√† della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilit√† che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato di avere un‚Äôelevata accuratezza nella classificazione della replicabilit√† degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati √® costosa o difficile da realizzare, fornendo una prima indicazione sulla solidit√† dei risultati di ricerca.\n\n\n98.1.2.2 Strumenti di Valutazione Statistica\nUn‚Äôaltra proposta riguarda l‚Äôadozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significativit√† statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte, sebbene non risolutive, rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n98.1.2.3 Analisi Multiverso\nL‚Äôanalisi multiverso √® un‚Äôaltra proposta innovativa che mira a gestire la molteplicit√† di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l‚Äôesecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilit√† dei risultati. L‚Äôadozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilit√† nelle conclusioni tratte dagli studi.\n\n\n\n98.1.3 Cambiamenti nella Comunit√†\n\n98.1.3.1 Big Team Science\nIl concetto di ‚ÄúBig Team Science‚Äù rappresenta un cambiamento significativo nella modalit√† di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l‚Äôobiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l‚Äôefficienza della ricerca, ma promuove anche una maggiore diversit√† nei campioni e nei team di ricerca. Tuttavia, esistono anche criticit√†, come la possibilit√† di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficolt√† nel riconoscere adeguatamente i contributi individuali all‚Äôinterno di grandi consorzi.\n\n\n98.1.3.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualit√† della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione pu√≤ ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni pi√π solide e condivise all‚Äôinterno della comunit√† scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>¬† <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_changes.html#crisi-della-generalizzabilit√†",
    "href": "chapters/replication_crisis/05_changes.html#crisi-della-generalizzabilit√†",
    "title": "98¬† Proposte di cambiamento",
    "section": "98.2 Crisi della generalizzabilit√†",
    "text": "98.2 Crisi della generalizzabilit√†\nYarkoni (2022) affronta la questione critica della scarsa validit√† delle inferenze quantitative presenti nella letteratura psicologica pubblicata proponendo tre strategie principali che, se adottate, potrebbero migliorare significativamente la qualit√† della ricerca in psicologia.\n\n98.2.1 Do Something Else\nIl primo suggerimento dell‚Äôautore √® quello di considerare la possibilit√† di abbandonare la ricerca psicologica quantitativa laddove risulti troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L‚Äôautore critica la tendenza nella psicologia (e in altre discipline) di concludere ogni contributo di ricerca con una nota positiva o ‚Äúcostruttiva‚Äù, indipendentemente dalla realt√† delle evidenze raccolte. Secondo l‚Äôautore, non √® realistico pensare che ogni domanda di ricerca meriti una risposta empirica, soprattutto quando le risorse necessarie per ottenere risultati minimamente informativi superano di gran lunga gli standard convenzionali. In queste circostanze, potrebbe essere pi√π saggio riconoscere i limiti della ricerca e, in alcuni casi, scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi, che potrebbero trovare prospettive di carriera migliori al di fuori dell‚Äôaccademia.\n\n\n98.2.2 Abbracciare l‚ÄôAnalisi Qualitativa\nLa seconda opzione proposta √® continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L‚Äôautore sostiene che gran parte di ci√≤ che attualmente passa per scienza quantitativa in psicologia sia in realt√† un‚Äôanalisi qualitativa mascherata. Alcune teorie psicologiche, secondo l‚Äôautore, non traggono beneficio da un‚Äôanalisi quantitativa poich√© sono o troppo vaghe o troppo ovvie per essere falsificabili attraverso procedure statistiche. L‚Äôautore suggerisce che in molti casi l‚Äôanalisi qualitativa potrebbe fornire risposte pi√π profonde e significative rispetto a un approccio quantitativo superficiale, evitando cos√¨ l‚Äôillusione di una precisione scientifica inesistente.\nIn un approccio qualitativo, i ricercatori potrebbero concentrarsi sulla descrizione e sull‚Äôesplorazione delle relazioni tra variabili senza cercare di trarre conclusioni causali definitive. L‚Äôautore menziona l‚Äôesempio della rivista Basic and Applied Social Psychology, che ha bandito l‚Äôuso dei p-value, come un esempio di come l‚Äôabbandono della statistica inferenziale possa essere gestito in modo costruttivo. Sebbene questa mossa sia stata accolta con scetticismo, l‚Äôautore suggerisce che, se affrontata correttamente, potrebbe essere un passo positivo verso una maggiore integrit√† nella ricerca psicologica.\n\n\n98.2.3 Adottare Standard Migliori\nLa terza e ultima strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla pi√π rigorosa e affidabile. L‚Äôautore propone diverse pratiche che, se implementate, potrebbero migliorare la qualit√† e la validit√† delle inferenze psicologiche:\n\nInferenze pi√π conservative: I ricercatori dovrebbero evitare di fare generalizzazioni ampie basate su dati limitati e dovrebbero esplicitamente indicare quando stanno speculando al di l√† dei dati disponibili. La formulazione di titoli di articoli e affermazioni dovrebbe riflettere in modo pi√π accurato la portata dei risultati ottenuti.\nRicerca descrittiva: L‚Äôautore esorta a prendere pi√π seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili senza ricorrere a spiegazioni causali. Questo tipo di ricerca pu√≤ fornire un‚Äôimportante base empirica che √® spesso trascurata a favore di teorie semplificate e sovrastimate.\nModelli statistici pi√π espansivi: I ricercatori dovrebbero abituarsi a utilizzare modelli statistici che considerino una pi√π ampia gamma di variabili e fattori, oltre a includere effetti random per elementi come stimoli, compiti e siti di ricerca. Questo approccio richiede l‚Äôuso di modelli misti che permettano di gestire la complessit√† della realt√† psicologica in modo pi√π adeguato.\nProgettare con la variazione in mente: Yarkoni (2022) sostiene l‚Äôimportanza di progettare studi che abbraccino la variabilit√† naturale delle condizioni sperimentali, piuttosto che cercare di controllare rigidamente ogni variabile. Questo approccio, sebbene pi√π costoso in termini di risorse, permetterebbe di ottenere risultati pi√π generalizzabili e utili.\nStime della varianza: Un maggiore enfasi dovrebbe essere posta sull‚Äôanalisi dele componenti della varianza piuttosto che sulle stime puntuali. Questo permetterebbe di comprendere meglio l‚Äôimportanza relativa delle diverse fonti di variazione nei dati e di pianificare studi futuri in modo pi√π informato.\nPredizioni pi√π rischiose: Yarkoni (2022) incoraggia i ricercatori a formulare predizioni teoriche che comportino un alto grado di rischio. Predizioni pi√π precise e rischiose ridurrebbero le preoccupazioni sulla generalizzabilit√†, poich√© solo modelli teorici accurati sarebbero in grado di fare previsioni con tale precisione.\nUtilit√† predittiva pratica: Infine, Yarkoni (2022) suggerisce un approccio pi√π pragmatico che si concentri sull‚Äôutilit√† pratica delle predizioni piuttosto che su considerazione puramente teoriche. Invece di chiedersi se un fenomeno esiste, dovremmo chiederci se possiamo costruire modelli che predicano efficacemente comportamenti rilevanti in situazioni specifiche.\n\n\n\n98.2.4 Conclusione\nYarkoni (2022) conclude il suo articolo evidenziando che l‚Äôuso diffuso di test statistici inferenziali in psicologia √® spesso fuorviante, poich√© conferisce un‚Äôapparenza di rigore scientifico a inferenze che, in realt√†, sono essenzialmente qualitative. Questo problema sottolinea la necessit√† di una profonda riforma delle pratiche di ricerca, con un‚Äôattenzione maggiore alla trasparenza, all‚Äôaccuratezza e alla disponibilit√† di abbandonare approcci metodologici che non resistono a un‚Äôanalisi critica. Sebbene questo percorso possa sembrare meno impressionante rispetto ai metodi attualmente in uso, potrebbe essere un metodo per garantire la credibilit√† a lungo termine della disciplina.\nLa crisi della riproducibilit√† ha dato impulso a una serie di riforme che potrebbero trasformare in modo significativo il panorama della ricerca scientifica. Tra queste riforme vi sono la promozione della scienza aperta, l‚Äôadozione di standard pi√π rigorosi e l‚Äôenfasi su pratiche di ricerca che privilegiano la qualit√† e la replicabilit√† rispetto alla mera quantit√† e alla novit√† dei risultati.\nAffinch√© queste riforme abbiano un impatto duraturo, √® necessario un cambiamento a tutti i livelli della comunit√† scientifica. I ricercatori devono adottare pratiche pi√π rigorose e trasparenti; gli enti finanziatori devono incentivare la qualit√† e la replicabilit√† delle ricerche; le istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico; e le riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili.\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per rafforzare la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi significativi alla comprensione della mente umana e del comportamento.\n\n\n\n\nKorbmacher, Max, Flavio Azevedo, Charlotte R Pennington, Helena Hartmann, Madeleine Pownall, Kathleen Schmidt, Mahmoud Elsherif, et al. 2023. ¬´The replication crisis has led to positive structural, procedural, and community changes¬ª. Communications Psychology 1 (1): 3.\n\n\nScheel, Anne M, Mitchell RMJ Schijen, e Dani√´l Lakens. 2021. ¬´An excess of positive results: Comparing the standard psychology literature with registered reports¬ª. Advances in Methods and Practices in Psychological Science 4 (2): 25152459211007467.\n\n\nYarkoni, Tal. 2022. ¬´The generalizability crisis¬ª. Behavioral and Brain Sciences 45: e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>98</span>¬† <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_integrity.html",
    "href": "chapters/replication_crisis/06_integrity.html",
    "title": "99¬† Integrit√† della ricerca",
    "section": "",
    "text": "Introduzione\nL‚Äôintegrit√† della ricerca si basa su principi e standard professionali che mirano a garantire l‚Äôaffidabilit√† e la qualit√† della ricerca, distinguendosi dall‚Äôetica della ricerca, che si focalizza su principi morali. La condivisione dei dati, il consenso informato, e la trasparenza nelle pratiche di ricerca sono elementi chiave. I codici di condotta sono essenziali per orientare i comportamenti etici, tanto dei ricercatori quanto delle istituzioni. Le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio, e la gestione dei conflitti di interesse sono sfide da affrontare per mantenere l‚Äôintegrit√† della ricerca. √à fondamentale promuovere una cultura di ricerca che privilegi l‚Äôonest√†, la trasparenza e il rispetto dei principi etici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrit√†-della-ricerca",
    "href": "chapters/replication_crisis/06_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrit√†-della-ricerca",
    "title": "99¬† Integrit√† della ricerca",
    "section": "99.1 Standard Professionali nei Codici di Condotta per l‚ÄôIntegrit√† della Ricerca",
    "text": "99.1 Standard Professionali nei Codici di Condotta per l‚ÄôIntegrit√† della Ricerca\nNel campo della ricerca, √® essenziale aderire a principi di condotta responsabile. Questi principi, comunemente definiti come buone pratiche di ricerca, stabiliscono gli standard professionali che mirano a ottimizzare qualit√† e affidabilit√† degli studi condotti. Se √® vero che le idee di base su cosa costituisca una buona pratica di ricerca rimangono relativamente stabili nel tempo, la loro applicazione pratica si evolve in risposta ai cambiamenti sociali, politici e tecnologici. Un esempio lampante di questo adattamento √® la crescente enfasi sulla condivisione dei dati di ricerca, facilitata oggi dall‚Äôesistenza di repository online gratuiti, che ha portato a un‚Äôaspettativa diffusa di massima trasparenza e accessibilit√† dei dati raccolti. Molto incoraggiata √® anche la ‚Äúbuona pratica‚Äù corrispondente alla condivisione del codice utilizzato dai ricercatori per analizzare i dati raccolti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_integrity.html#differenziazione-tra-integrit√†-e-etica-della-ricerca",
    "href": "chapters/replication_crisis/06_integrity.html#differenziazione-tra-integrit√†-e-etica-della-ricerca",
    "title": "99¬† Integrit√† della ricerca",
    "section": "99.2 Differenziazione tra Integrit√† e Etica della Ricerca",
    "text": "99.2 Differenziazione tra Integrit√† e Etica della Ricerca\nL‚Äôintegrit√† della ricerca si fonda su standard professionali e si distingue nettamente dall‚Äôetica della ricerca, che si basa su principi morali quali l‚Äôautonomia, la beneficenza, la non-maleficenza e la giustizia. Questi ultimi si traducono in pratiche specifiche, come il consenso informato e la garanzia di verit√† e confidenzialit√† nei confronti dei partecipanti. L‚Äôadozione di tali principi etici implica l‚Äôobbligo per i ricercatori di evitare studi che possano arrecare danno o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l‚Äôintegrit√† della ricerca variano leggermente tra le diverse fonti. Ad esempio, Il codice di condotta europeo per l‚ÄôintegritaÃÄ della ricerca enfatizza l‚Äôimportanza di principi come l‚Äôonest√†, la trasparenza, l‚Äôaccuratezza, la responsabilit√†, l‚Äôaffidabilit√†, il rispetto e l‚Äôindipendenza. Questi principi sono interpretati in termini di comportamenti specifici attesi sia dai ricercatori sia dalle istituzioni di ricerca, come la condivisione dei dati di ricerca nel rispetto delle normative sulla protezione dei dati, come il GDPR europeo.\nUn esempio pratico della variazione degli standard nei codici di condotta √® rappresentato dall‚Äôevoluzione della condivisione dei dati di ricerca. In precedenza, la condivisione dei dati poteva essere limitata dalla mancanza di infrastrutture adeguate. Oggi, l‚Äôaccesso facilitato attraverso i repository online e la pressione esercitata dalle riviste scientifiche e dai finanziatori della ricerca hanno reso la condivisione dei dati una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza nella ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/06_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "99¬† Integrit√† della ricerca",
    "section": "99.3 Pressioni e Sfide nell‚ÄôAdesione ai Codici di Condotta",
    "text": "99.3 Pressioni e Sfide nell‚ÄôAdesione ai Codici di Condotta\nNonostante l‚Äôesistenza di questi codici, i ricercatori, specialmente quelli in fase iniziale della loro carriera, possono trovarsi sotto pressione da parte dei supervisori per adottare comportamenti che si discostano dagli standard stabiliti, spesso a causa della competitivit√† nel campo scientifico e del sistema di valutazione basato sul numero di pubblicazioni. Queste dinamiche possono indurre a pratiche di ricerca discutibili (PRD), che includono la pubblicazione selettiva dei risultati e l‚Äôuso di analisi dei dati flessibili per aumentare artificialmente la probabilit√† di ottenere risultati statisticamente significativi.\nPer mantenere l‚Äôintegrit√† della ricerca, √® fondamentale creare un ambiente di lavoro che valorizzi l‚Äôapertura, l‚Äôinclusivit√† e la discussione franca delle pressioni e delle sfide etiche. Questo implica non solo l‚Äôadesione ai codici di condotta esistenti ma anche l‚Äôimpegno attivo delle istituzioni di ricerca nel promuovere la formazione etica e l‚Äôintegrit√† tra i ricercatori. Attraverso un tale approccio, la comunit√† scientifica pu√≤ aspirare a una ricerca di alta qualit√† che sia sia eticamente responsabile sia metodologicamente solida.\n√à degno di nota che Nature, una delle riviste scientifiche pi√π prestigiose al mondo, abbia recentemente promosso il gioco da tavolo Publish or Perish. La descrizione del gioco √® particolarmente provocatoria:\n\n‚ÄúFalsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.‚Äù\n\nQuesta mossa solleva importanti questioni sullo stato attuale della ricerca scientifica. Non solo il mondo accademico sembra fornire inventivi distorti, ma anche il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che appare in conflitto con gli obiettivi fondamentali della ricerca scientifica. Questo porta all‚Äôaccettazione di pratiche disoneste, perch√© funzionali allo status quo.\nIn questo panorama complesso, emergono voci di dissenso che auspicano e si impegnano per una riforma del mondo pragmatico della scienza (McElreath 2020; Smaldino e McElreath 2016). Questa situazione invita a una riflessione profonda sulla necessit√† di bilanciare la produttivit√† accademica con l‚Äôetica e la qualit√† della ricerca, nonch√© sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.\n\n\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nSmaldino, Paul E, e Richard McElreath. 2016. ¬´The natural selection of bad science¬ª. Royal Society open science 3 (9): 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>99</span>¬† <span class='chapter-title'>Integrit√† della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell‚ÄôInferenza Frequentista\nNel corso di questo testo, abbiamo esplorato i limiti dell‚Äôinferenza frequentista, in particolare quando viene utilizzata come ‚Äúfiltro‚Äù per distinguere tra risultati scientifici importanti e quelli da scartare. Il frequente utilizzo delp-valore come criterio principale per la pubblicazione dei risultati pu√≤ portare a una sovrastima sistematica della grandezza dell‚Äôeffetto e, in alcuni casi, all‚Äôinversione della direzione dell‚Äôeffetto osservato (Loken e Gelman (2017)). Inoltre, l‚Äôenfasi sui risultati statisticamente significativi ha incentivato pratiche scientifiche discutibili, contribuendo alla crisi della replicabilit√† nella ricerca psicologica.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilit√†",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilit√†",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilit√†",
    "text": "La Crisi della Replicabilit√†\nbla bla",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#come-uscirne",
    "href": "chapters/epiloque/epiloque.html#come-uscirne",
    "title": "Considerazioni Conclusive",
    "section": "Come uscirne?",
    "text": "Come uscirne?\nL‚Äôabbandono dell‚Äôinferenza frequentista a favore dei metodi bayesiani √® una delle strategie proposte per affrontare la crisi della replicabilit√† nella ricerca psicologica. Tuttavia, questo cambiamento, pur essendo importante, non √® sufficiente da solo. I problemi pi√π profondi derivano anche da un sistema accademico caratterizzato da incentivi distorti, come la pressione a pubblicare risultati significativi, e dalla riluttanza delle riviste scientifiche a riconoscere e affrontare casi di frode o a ritirare articoli quando necessario.\nUna proposta su cui insiste molto McElreath (2020) √® quella di passare da un approccio descrittivo della relazione tra variabili ‚Äî tipico dei modelli lineari e dei modelli lineari generalizzati ‚Äî a una prospettiva che miri a descrivere formalmente il meccanismo generatore dei dati sottostante al fenomeno in esame. In questo contesto, il ricercatore dovrebbe formulare ipotesi esplicite sul processo che genera i dati e fornire un test quantitativo di tali ipotesi. Questo approccio porta naturalmente alla pratica del confronto tra modelli, un metodo che abbiamo discusso in diversi capitoli di questo testo. Tale confronto pu√≤ essere effettuato utilizzando tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO), che permette di valutare la robustezza dei modelli e la loro capacit√† di generalizzare a nuovi dati. Ma si tengano anche a mente i limiti di tale approccio (Navarro 2019).\nUn altro approccio attuale per superare la cosiddetta ‚Äújunk science‚Äù (Calin-Jageman e Caldwell 2014; Jung et al. 2014; Gelman e Weakliem 2009), che troppo spesso affligge la psicologia e non solo, √® la ‚Äúrivoluzione causale‚Äù. Questo movimento si concentra sul tentativo di comprendere e identificare le relazioni causali in contesti naturali, superando l‚Äôarbitrariet√† e l‚Äôartificialit√† degli esperimenti di laboratorio tradizionali. La ‚Äúrivoluzione causale‚Äù ha molto in comune con l‚Äôapproccio di McElreath (2020), poich√© anche qui si richiede ai ricercatori di formulare ipotesi causali in maniera esplicita e di confrontare modelli alternativi che rappresentano diverse ipotesi sui rapporti causali. Questo approccio non solo migliora la comprensione dei fenomeni studiati, ma aumenta anche la credibilit√† e la replicabilit√† dei risultati scientifici.\nQuesti cambiamenti prevedono anche una profonda revisione dei metodi didattici e dei programmi dei corsi, in cui si insegna agli studenti come formulare inferenze basate sui dati empirici raccolti in psicologia. Questo tema √® stato approfondito da studiosi come Mine Dogucu [Johnson, Ott, e Dogucu (2022); dogucu2022current; rosenberg2022making; dogucu2021web]. Come dovrebbe ormai essere evidente al lettore, il presente testo ha accettato questa sfida.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nL‚Äôapproccio bayesiano rappresenta una risorsa fondamentale per l‚Äôanalisi dei dati psicologici, offrendo strumenti avanzati per gestire l‚Äôincertezza, integrare conoscenze pregresse e adattarsi a modelli complessi. La sua capacit√† di fornire previsioni robuste e aggiornare continuamente le ipotesi alla luce di nuovi dati lo rende particolarmente adatto per esplorare e comprendere la mente umana e il comportamento in tutte le loro sfaccettature.\nTuttavia, per affrontare la crisi della replicabilit√† e migliorare la qualit√† della ricerca scientifica in psicologia, non √® sufficiente adottare esclusivamente metodi bayesiani. √à essenziale combinare questi metodi con altre pratiche rigorose e principi metodologici solidi. Tra queste pratiche, la formalizzazione dei modelli generativi consente di descrivere chiaramente i processi sottostanti che generano i dati, migliorando la trasparenza e la validit√† delle inferenze. Inoltre, il confronto rigoroso tra modelli, ad esempio tramite tecniche di validazione incrociata, aiuta a determinare quale modello meglio rappresenta i dati e a evitare interpretazioni errate.\nInfine, l‚Äôadozione di una prospettiva causale esplicita √® cruciale per identificare correttamente le relazioni di causa-effetto, evitando l‚Äôarbitrariet√† e l‚Äôartificialit√† degli esperimenti tradizionali. Solo attraverso un approccio integrato, che combini l‚Äôinferenza bayesiana con queste pratiche metodologiche avanzate, sar√† possibile progredire verso una scienza psicologica pi√π affidabile e riproducibile, capace di fornire una comprensione pi√π profonda e accurata del comportamento umano.\n\n\n\n\nCalin-Jageman, Robert J, e Tracy L Caldwell. 2014. ¬´Replication of the superstition and performance study by Damisch, Stoberock, and Mussweiler (2010)¬ª. Social Psychology.\n\n\nGelman, Andrew, e David Weakliem. 2009. ¬´Of beauty, sex and power: Too little attention has been paid to the statistical challenges in estimating small effects¬ª. American Scientist 97 (4): 310‚Äì16.\n\n\nJohnson, Alicia A., Miles Ott, e Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nJung, Kiju, Sharon Shavitt, Madhu Viswanathan, e Joseph M Hilbe. 2014. ¬´Female hurricanes are deadlier than male hurricanes¬ª. Proceedings of the National Academy of Sciences 111 (24): 8782‚Äì87.\n\n\nLoken, Eric, e Andrew Gelman. 2017. ¬´Measurement Error and the Replication Crisis¬ª. Science 355 (6325): 584‚Äì85.\n\n\nMcElreath, Richard. 2020. Statistical rethinking: A Bayesian course with examples in R and Stan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nNavarro, Danielle J. 2019. ¬´Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection¬ª. Computational Brain & Behavior 2 (1): 28‚Äì34.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Albert, Jim, and Jingchen Hu. 2019. Probability and Bayesian\nModeling. Boca Raton, Florida: CRC Press.\n\n\nAlexander, Rohan. 2023. Telling Stories with Data: With Applications\nin r. Chapman; Hall/CRC.\n\n\nAltmejd, Adam, Anna Dreber, Eskil Forsell, Juergen Huber, Taisuke Imai,\nMagnus Johannesson, Michael Kirchler, Gideon Nave, and Colin Camerer.\n2019. ‚ÄúPredicting the Replicability of Social Science Lab\nExperiments.‚Äù PloS One 14 (12): e0225826.\n\n\nAngrist, Joshua D, and J√∂rn-Steffen Pischke. 2010. ‚ÄúThe\nCredibility Revolution in Empirical Economics: How Better Research\nDesign Is Taking the Con Out of Econometrics.‚Äù Journal of\nEconomic Perspectives 24 (2): 3‚Äì30.\n\n\nAungle, Peter, and Ellen Langer. 2023. ‚ÄúPhysical Healing as a\nFunction of Perceived Time.‚Äù Scientific Reports 13 (1):\n22432.\n\n\nBaker, Monya. 2016a. ‚Äú1,500 Scientists Lift the Lid on\nReproducibility.‚Äù Nature 533 (7604).\n\n\n‚Äî‚Äî‚Äî. 2016b. ‚ÄúReproducibility Crisis.‚Äù Nature 533\n(7604): 452‚Äì54.\n\n\nBargh, John A, Mark Chen, and Lara Burrows. 1996. ‚ÄúAutomaticity of\nSocial Behavior: Direct Effects of Trait Construct and Stereotype\nActivation on Action.‚Äù Journal of Personality and Social\nPsychology 71 (2): 230‚Äì244.\n\n\nBaribault, Beth, and Anne GE Collins. 2023. ‚ÄúTroubleshooting\nBayesian Cognitive Models.‚Äù Psychological Methods.\n\n\nBem, Daryl J. 2011. ‚ÄúFeeling the Future: Experimental Evidence for\nAnomalous Retroactive Influences on Cognition and Affect.‚Äù\nJournal of Personality and Social Psychology 100 (3): 407‚Äì25.\n\n\nBetancourt, Michael. 2016. ‚ÄúDiagnosing Suboptimal Cotangent\nDisintegrations in Hamiltonian Monte Carlo.‚Äù arXiv Preprint\narXiv:1604.00695.\n\n\nBishop, Dorothy. 2019. ‚ÄúThe Psychology of Experimental\nPsychologists: Overcoming Cognitive Constraints to Improve\nResearch.‚Äù\n\n\nBland, J Martin, and Douglas G Altman. 2011. ‚ÄúComparisons Within\nRandomised Groups Can Be Very Misleading.‚Äù Bmj 342.\n\n\nBoden, Margaret A. 2008. ‚ÄúAn Evaluation of Computational Modeling\nin Cognitive Science.‚Äù\n\n\nBorel, Emile. 1914. Introduction\ng√©om√©trique. G. Villars, New York.\n\n\nBornstein, Aaron M, and Kenneth A Norman. 2017. ‚ÄúReinstated\nEpisodic Context Guides Sampling-Based Decisions for Reward.‚Äù\nNature Neuroscience 20 (7): 997‚Äì1003.\n\n\nBotvinick, Matthew M, Todd S Braver, Deanna M Barch, Cameron S Carter,\nand Jonathan D Cohen. 2001. ‚ÄúConflict Monitoring and Cognitive\nControl.‚Äù Psychological Review 108 (3): 624‚Äì52.\n\n\nBox, George EP. 1976. ‚ÄúScience and Statistics.‚Äù Journal\nof the American Statistical Association 71 (356): 791‚Äì99.\n\n\nBrownstein, Naomi C, Thomas A Louis, Anthony O‚ÄôHagan, and Jane\nPendergast. 2019. ‚ÄúThe Role of Expert Judgment in Statistical\nInference and Evidence-Based Decision-Making.‚Äù The American\nStatistician 73 (sup1): 56‚Äì68.\n\n\nBruton, Samuel V, Mary Medlin, Mitch Brown, and Donald F Sacco. 2020.\n‚ÄúPersonal Motivations and Systemic Incentives: Scientists on\nQuestionable Research Practices.‚Äù Science and Engineering\nEthics 26 (3): 1531‚Äì47.\n\n\nBuchanan, Erin M, Sarah E Crain, Ari L Cunningham, Hannah R Johnson,\nHannah Stash, Marietta Papadatou-Pastou, Peder M Isager, Rickard\nCarlsson, and Balazs Aczel. 2021. ‚ÄúGetting Started Creating Data\nDictionaries: How to Create a Shareable Data Set.‚Äù Advances\nin Methods and Practices in Psychological Science 4 (1):\n2515245920928007.\n\n\nButton, Katherine S, John PA Ioannidis, Claire Mokrysz, Brian A Nosek,\nJonathan Flint, Emma SJ Robinson, and Marcus R Munaf√≤. 2013.\n‚ÄúPower Failure: Why Small Sample Size Undermines the Reliability\nof Neuroscience.‚Äù Nature Reviews Neuroscience 14 (5):\n365‚Äì76.\n\n\nByrnes, Jarrett EK, and Laura E Dee. 2024. ‚ÄúCausal Inference with\nObservational Data and Unobserved Confounding Variables.‚Äù\nbioRxiv, 2024‚Äì02.\n\n\nCalin-Jageman, Robert J, and Tracy L Caldwell. 2014. ‚ÄúReplication\nof the Superstition and Performance Study by Damisch, Stoberock, and\nMussweiler (2010).‚Äù Social Psychology.\n\n\nCamerer, Colin F, Anna Dreber, Felix Holzmeister, Teck-Hua Ho, J√ºrgen\nHuber, Magnus Johannesson, Michael Kirchler, et al. 2018.\n‚ÄúEvaluating the Replicability of Social Science Experiments in\nNature and Science Between 2010 and 2015.‚Äù Nature Human\nBehaviour 2 (9): 637‚Äì44.\n\n\nCaudek, Corrado, Martina Lorenzino, and Rosita Liperoti. 2017.\n‚ÄúDelta Plots Do Not Reveal Response Inhibition in Lying.‚Äù\nConsciousness and Cognition 55: 232‚Äì44.\n\n\nCaudek, Corrado, and Riccardo Luccio. 2001. ‚ÄúStatistica Per\nPsicologi.‚Äù\n\n\nCaudek, Corrado, Claudio Sica, Silvia Cerea, Ilaria Colpizzi, and Debora\nStendardi. 2021. ‚ÄúSusceptibility to Eating Disorders Is Associated\nwith Cognitive Inflexibility in Female University Students.‚Äù\nJournal of Behavioral and Cognitive Therapy 31 (4): 317‚Äì28.\n\n\nCaudek, Corrado, Claudio Sica, Igor Marchetti, Ilaria Colpizzi, and\nDebora Stendardi. 2020. ‚ÄúCognitive Inflexibility Specificity for\nIndividuals with High Levels of Obsessive-Compulsive Symptoms.‚Äù\nJournal of Behavioral and Cognitive Therapy 30 (2): 103‚Äì13.\n\n\nChivers, Tom. 2024. Everything Is Predictable: How Bayesian\nStatistics Explain Our World. Simon; Schuster.\n\n\nCipresso, Pietro, Francesca Borghesi, and Alice Chirico. 2023.\n‚ÄúAffects Affect Affects: A Markov Chain.‚Äù Frontiers in\nPsychology 14: 1162655.\n\n\nClayton, Aubrey. 2021. Bernoulli‚Äôs Fallacy: Statistical Illogic and\nthe Crisis of Modern Science. Columbia University Press.\n\n\nCollaboration, Open Science. 2015. ‚ÄúEstimating the Reproducibility\nof Psychological Science.‚Äù Science 349 (6251): aac4716.\n\n\nCronbach, Lee J. 1957. ‚ÄúThe Two Disciplines of Scientific\nPsychology.‚Äù American Psychologist 12 (11): 671‚Äì84.\n\n\nDanielmeier, Claudia, and Markus Ullsperger. 2011. ‚ÄúPost-Error\nAdjustments.‚Äù Frontiers in Psychology 2: 233.\n\n\nDel Moral, Pierre, and Spiridon Penev. 2017. Stochastic Processes:\nFrom Applications to Theory. Chapman; Hall/CRC.\n\n\nDowney, Allen B. 2021. Think Bayes. \" O‚ÄôReilly Media, Inc.\".\n\n\nDuane, Simon, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth.\n1987. ‚ÄúHybrid Monte Carlo.‚Äù Physics Letters B 195\n(2): 216‚Äì22.\n\n\nDuncan, Katherine D, and Daphna Shohamy. 2016. ‚ÄúMemory States\nInfluence Value-Based Decisions.‚Äù Journal of Experimental\nPsychology: General 145 (11): 1420.\n\n\nEckstein, Maria K, and Anne GE Collins. 2020. ‚ÄúComputational\nEvidence for Hierarchically Structured Reinforcement Learning in\nHumans.‚Äù Proceedings of the National Academy of Sciences\n117 (47): 29381‚Äì89.\n\n\nEckstein, Maria, Christopher Summerfield, Nathaniel Daw, and Kevin J\nMiller. n.d. ‚ÄúHybrid Neural-Cognitive Models Reveal How Memory\nShapes Human Reward Learning.‚Äù\n\n\nEtz, Alexander, Quentin F Gronau, Fabian Dablander, Peter A\nEdelsbrunner, and Beth Baribault. 2018. ‚ÄúHow to Become a Bayesian\nin Eight Easy Steps: An Annotated Reading List.‚Äù Psychonomic\nBulletin & Review 25 (1): 219‚Äì34.\n\n\nFerguson, Christopher J, and Moritz Heene. 2012. ‚ÄúA Vast Graveyard\nof Undead Theories: Publication Bias and Psychological Science‚Äôs\nAversion to the Null.‚Äù Perspectives on Psychological\nScience 7 (6): 555‚Äì61.\n\n\nFincham, Ed, Dragan Ga≈°eviƒá, Jelena Jovanoviƒá, and Abelardo Pardo. 2018.\n‚ÄúFrom Study Tactics to Learning Strategies: An Analytical Method\nfor Extracting Interpretable Representations.‚Äù IEEE\nTransactions on Learning Technologies 12 (1): 59‚Äì72.\n\n\nFinetti, Bruno de. 1970. Teoria Delle Probabilit√†. Torino: G.\nEinaudi.\n\n\nFishburn, Peter C. 1986. ‚ÄúThe Axioms of Subjective\nProbability.‚Äù Statistical Science 1 (3): 335‚Äì45.\n\n\nFox, John. 2015. Applied Regression Analysis and Generalized Linear\nModels. Sage publications.\n\n\nFrank, Michael J, and David Badre. 2012. ‚ÄúMechanisms of\nHierarchical Reinforcement Learning in Corticostriatal Circuits 1:\nComputational Analysis.‚Äù Cerebral Cortex 22 (3): 509‚Äì26.\n\n\nFunder, David C, and Daniel J Ozer. 2019. ‚ÄúEvaluating Effect Size\nin Psychological Research: Sense and Nonsense.‚Äù Advances in\nMethods and Practices in Psychological Science 2 (2): 156‚Äì68.\n\n\nGee, Phillip, Andrew Neal, and Jeffrey B Vancouver. 2018. ‚ÄúA\nFormal Model of Goal Revision in Approach and Avoidance\nContexts.‚Äù Organizational Behavior and Human Decision\nProcesses 146: 51‚Äì61.\n\n\nGelman, Andrew. 2016. ‚ÄúCommentary on ‚ÄòCrisis in Science? Or\nCrisis in Statistics! Mixed Messages in Statistics with Impact on\nScience‚Äô.‚Äù Journal of Statistical Research 48-50\n(1): 11‚Äì12.\n\n\n‚Äî‚Äî‚Äî. 2024. ‚ÄúBefore Data Analysis: Additional Recommendations for\nDesigning Experiments to Learn about the World.‚Äù Journal of\nConsumer Psychology 34: 190‚Äì91.\n\n\nGelman, Andrew, and Nicholas JL Brown. 2024. ‚ÄúHow Statistical\nChallenges and Misreadings of the Literature Combine to Produce\nUnreplicable Science: An Example from Psychology.‚Äù\n\n\nGelman, Andrew, and John Carlin. 2014. ‚ÄúBeyond Power Calculations:\nAssessing Type s (Sign) and Type m (Magnitude) Errors.‚Äù\nPerspectives on Psychological Science 9 (6): 641‚Äì51.\n\n\nGelman, Andrew, John B Carlin, Hal S Stern, and Donald B Rubin. 1995.\nBayesian Data Analysis. Chapman; Hall/CRC.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and\nOther Stories. Cambridge University Press.\n\n\n‚Äî‚Äî‚Äî. 2021. Regression and Other Stories. Cambridge University\nPress.\n\n\nGelman, Andrew, and Eric Loken. 2013. ‚ÄúThe Garden of Forking\nPaths: Why Multiple Comparisons Can Be a Problem, Even When There Is No\n‚ÄòFishing Expedition‚Äô or ‚Äòp-Hacking‚Äô and the\nResearch Hypothesis Was Posited Ahead of Time.‚Äù Department of\nStatistics, Columbia University 348 (1-17): 3.\n\n\n‚Äî‚Äî‚Äî. 2014. ‚ÄúThe Statistical Crisis in Science.‚Äù\nAmerican Scientist 102 (6): 460‚Äì65.\n\n\nGelman, Andrew, and Cosma Rohilla Shalizi. 2013. ‚ÄúPhilosophy and\nthe Practice of Bayesian Statistics.‚Äù British Journal of\nMathematical and Statistical Psychology 66 (1): 8‚Äì38.\n\n\nGelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob\nCarpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian\nB√ºrkner, and Martin Modr√°k. 2020. ‚ÄúBayesian Workflow.‚Äù\narXiv Preprint arXiv:2011.01808.\n\n\nGelman, Andrew, and David Weakliem. 2009. ‚ÄúOf Beauty, Sex and\nPower: Too Little Attention Has Been Paid to the Statistical Challenges\nin Estimating Small Effects.‚Äù American Scientist 97 (4):\n310‚Äì16.\n\n\nGeman, Stuart, and Donald Geman. 1984. ‚ÄúStochastic Relaxation,\nGibbs Distributions, and the Bayesian\nRestoration of Images.‚Äù IEEE Transactions on Pattern Analysis\nand Machine Intelligence 6: 721‚Äì41.\n\n\nGibson, Edward, and H-H Iris Wu. 2013. ‚ÄúProcessing Chinese\nRelative Clauses in Context.‚Äù Language and Cognitive\nProcesses 28 (1-2): 125‚Äì55.\n\n\nGill, Jeff. 2015. Bayesian Methods: A Social and Behavioral Sciences\nApproach. 3rd Edition. Chapman; Hall/CRC.\n\n\nGlass, Gene V., Barry McGaw, and Mary L. Smith. 1981. Meta-Analysis\nin Social Research. Beverly Hills, CA: Sage Publications.\n\n\nGopalakrishna, Gowri, Gerben Ter Riet, Gerko Vink, Ineke Stoop, Jelte M\nWicherts, and Lex M Bouter. 2022. ‚ÄúPrevalence of Questionable\nResearch Practices, Research Misconduct and Their Potential Explanatory\nFactors: A Survey Among Academic Researchers in the Netherlands.‚Äù\nPloS One 17 (2): e0263023.\n\n\nGori, Benedetta, Antonello Grippo, Martina Focardi, and Francesco Lolli.\n2024. ‚ÄúThe Italian Version of Edinburgh Handedness Inventory:\nTranslation, Transcultural Adaptation, and Validation in Healthy\nSubjects.‚Äù Laterality 29 (2): 151‚Äì68.\n\n\nGrimes, David Robert, Chris T Bauch, and John PA Ioannidis. 2018.\n‚ÄúModelling Science Trustworthiness Under Publish or Perish\nPressure.‚Äù Royal Society Open Science 5 (1): 171511.\n\n\nGunawan, David, Guy E Hawkins, Robert Kohn, Minh-Ngoc Tran, and Scott D\nBrown. 2022. ‚ÄúTime-Evolving Psychological Processes over Repeated\nDecisions.‚Äù Psychological Review 129 (3): 438‚Äì56.\n\n\nHardt, Moritz, and Benjamin Recht. 2022. Patterns, Predictions, and\nActions: Foundations of Machine Learning. Princeton, NJ: Princeton\nUniversity Press.\n\n\nHardwicke, Tom E, Robert T Thibault, Jessica E Kosie, Joshua D Wallach,\nMallory C Kidwell, and John PA Ioannidis. 2022. ‚ÄúEstimating the\nPrevalence of Transparency and Reproducibility-Related Research\nPractices in Psychology (2014‚Äì2017).‚Äù Perspectives on\nPsychological Science 17 (1): 239‚Äì51.\n\n\nHastings, W. Keith. 1970. ‚ÄúMonte Carlo\nSampling Methods Using Markov Chains and Their\nApplications.‚Äù Biometrika 57 (1): 97‚Äì109.\n\n\nHealy, Kieran. 2018. Data Visualization: A Practical\nIntroduction. Princeton University Press.\n\n\nHempel, Carl Gustav. 1970. La Formazione Dei Concetti e Delle Teorie\nNella Scienza Empirica. Feltrinelli.\n\n\nHirsch, Colette R, Frances Meeten, Charlotte Krah√©, and Clare Reeder.\n2016. ‚ÄúResolving Ambiguity in Emotional Disorders: The Nature and\nRole of Interpretation Biases.‚Äù Annual Review of Clinical\nPsychology 12 (1): 281‚Äì305.\n\n\nHitchcock, Peter F, Eiko I Fried, and Michael J Frank. 2022.\n‚ÄúComputational Psychiatry Needs Time and Context.‚Äù\nAnnual Review of Psychology 73 (1): 243‚Äì70.\n\n\nHoffman, Matthew D, Andrew Gelman, et al. 2014. ‚ÄúThe No-u-Turn\nSampler: Adaptively Setting Path Lengths in Hamiltonian Monte\nCarlo.‚Äù Journal of Machine Learning Research 15 (1):\n1593‚Äì623.\n\n\nHoffmann, Tabea, Abe Hofman, and Eric-Jan Wagenmakers. 2022.\n‚ÄúBayesian Tests of Two Proportions: A Tutorial with r and\nJASP.‚Äù Methodology 18 (4): 239‚Äì77.\n\n\nHoogeveen, Suzanne, Alexandra Sarafoglou, and Eric-Jan Wagenmakers.\n2020. ‚ÄúLaypeople Can Predict Which Social-Science Studies Will Be\nReplicated Successfully.‚Äù Advances in Methods and Practices\nin Psychological Science 3 (3): 267‚Äì85.\n\n\nHowson, Colin, and Peter Urbach. 2006. Scientific Reasoning: The\nBayesian Approach. Open Court Publishing.\n\n\nHuntington-Klein, Nick. 2021. The Effect: An Introduction to\nResearch Design and Causality. Chapman; Hall/CRC.\n\n\nIoannidis, John PA. 2005. ‚ÄúWhy Most Published Research Findings\nAre False.‚Äù PLoS Medicine 2 (8): e124.\n\n\n‚Äî‚Äî‚Äî. 2008. ‚ÄúWhy Most Discovered True Associations Are\nInflated.‚Äù Epidemiology 19 (5): 640‚Äì48.\n\n\nJaynes, Edwin T. 2003. Probability Theory: The Logic of\nScience. Cambridge University Press.\n\n\nJohnson, Alicia A., Miles Ott, and Mine Dogucu. 2022. Bayes Rules! An Introduction to Bayesian Modeling with\nR. CRC Press.\n\n\nJohnson, Kaneesha R. 2021. ‚ÄúTwo Regimes of Prison Data\nCollection.‚Äù Harvard Data Science Review 3 (3): 10‚Äì1162.\n\n\nJung, Kiju, Sharon Shavitt, Madhu Viswanathan, and Joseph M Hilbe. 2014.\n‚ÄúFemale Hurricanes Are Deadlier Than Male Hurricanes.‚Äù\nProceedings of the National Academy of Sciences 111 (24):\n8782‚Äì87.\n\n\nKanazawa, Satoshi. 2007. ‚ÄúBeautiful Parents Have More Daughters: A\nFurther Implication of the Generalized Trivers‚ÄìWillard Hypothesis\n(gTWH).‚Äù Journal of Theoretical Biology 244 (1): 133‚Äì40.\n\n\nKaplan, David. 2023. Bayesian Statistics for the Social\nSciences. Guilford Publications.\n\n\nKarata≈ü, Mustafa, and Keisha M Cutright. 2023. ‚ÄúThinking about God\nIncreases Acceptance of Artificial Intelligence in\nDecision-Making.‚Äù Proceedings of the National Academy of\nSciences 120 (33): e2218961120.\n\n\nKhaw, Mel W, Paul W Glimcher, and Kenway Louie. 2017. ‚ÄúNormalized\nValue Coding Explains Dynamic Adaptation in the Human Valuation\nProcess.‚Äù Proceedings of the National Academy of\nSciences 114 (48): 12696‚Äì701.\n\n\nKnight, Emma, Andrew Neal, Hector Palada, and Timothy Ballard. 2023.\n‚ÄúA Tutorial on Bayesian Modeling of Change Across Time,\nIndividuals, and Groups.‚Äù Computational Brain &\nBehavior 6 (4): 697‚Äì718.\n\n\nKorbmacher, Max, Flavio Azevedo, Charlotte R Pennington, Helena\nHartmann, Madeleine Pownall, Kathleen Schmidt, Mahmoud Elsherif, et al.\n2023. ‚ÄúThe Replication Crisis Has Led to Positive Structural,\nProcedural, and Community Changes.‚Äù Communications\nPsychology 1 (1): 3.\n\n\nKruschke, John. 2014. Doing Bayesian Data Analysis: A\nTutorial with R, JAGS, and Stan. Academic\nPress.\n\n\nLabatut, Benjamƒ±ÃÅn. 2021. Quando Abbiamo Smesso Di Capire Il\nMondo. Adelphi Edizioni spa.\n\n\nLakens, Dani√´l. 2015. ‚ÄúOn the Challenges of Drawing Conclusions\nfrom p-Values Just Below 0.05.‚Äù PeerJ 3: e1142.\n\n\nLarson, Caroline, David Kaplan, Teresa Girolamo, Sara T Kover, and\nInge-Marie Eigsti. 2023. ‚ÄúA Bayesian Statistics Tutorial for\nClinical Research: Prior Distributions and Meaningful Results for Small\nClinical Samples.‚Äù Journal of Clinical Psychology 79\n(11): 2602‚Äì24.\n\n\nLilienfeld, Scott O, and Adele N Strother. 2020. ‚ÄúPsychological\nMeasurement and the Replication Crisis: Four Sacred Cows.‚Äù\nCanadian Psychology/Psychologie Canadienne 61 (4): 281‚Äì288.\n\n\nLim, Lyn, Maria Bannert, Joep van der Graaf, Shaveen Singh, Yizhou Fan,\nSurya Surendrannair, Mladen Rakovic, Inge Molenaar, Johanna Moore, and\nDragan Ga≈°eviƒá. 2023. ‚ÄúEffects of Real-Time Analytics-Based\nPersonalized Scaffolds on Students‚Äô Self-Regulated Learning.‚Äù\nComputers in Human Behavior 139: 107547.\n\n\nLindley, Dennis V. 2013. Understanding Uncertainty. John Wiley\n& Sons.\n\n\nLoken, Eric, and Andrew Gelman. 2017. ‚ÄúMeasurement Error and the\nReplication Crisis.‚Äù Science 355 (6325): 584‚Äì85.\n\n\nMarr, David. 2010. Vision: A Computational Investigation into the\nHuman Representation and Processing of Visual Information. MIT\npress.\n\n\nMartin, Osvaldo. 2024. Bayesian Analysis with Python. Packt\nPublishing Ltd.\n\n\nMartin, Osvaldo A, Ravin Kumar, and Junpeng Lao. 2022. Bayesian\nModeling and Computation in Python. CRC Press.\n\n\nMatcha, Wannisa, Dragan Gasevic, Jelena Jovanovic, Abelardo Pardo, Lisa\nLim, Jorge Maldonado-Mahauad, Sheridan Gentili, Mar P√©rez-Sanagustƒ±ÃÅn,\nYi-Shan Tsai, et al. 2020. ‚ÄúAnalytics of Learning Strategies: Role\nof Course Design and Delivery Modality Authors.‚Äù Journal of\nLearning Analytics 7 (2): 45‚Äì71.\n\n\nMatter, Ulrich. 2025. Data Analysis with AI and\nR. 1st Edition. New York, NY: Manning Publications.\n\n\nMaul, Andrew, David Torres Irribarra, and Mark Wilson. 2016. ‚ÄúOn\nthe Philosophical Foundations of Psychological Measurement.‚Äù\nMeasurement 79: 311‚Äì20.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd Edition. Boca Raton, Florida: CRC Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. \" O‚ÄôReilly\nMedia, Inc.\".\n\n\nMeehl, Paul E. 1967. ‚ÄúTheory-Testing in Psychology and Physics: A\nMethodological Paradox.‚Äù Philosophy of Science 34 (2):\n103‚Äì15.\n\n\n‚Äî‚Äî‚Äî. 2012. ‚ÄúWhy Summaries of Research on Psychological Theories\nAre Often Uninterpretable.‚Äù In Improving Inquiry in Social\nScience, 13‚Äì59. Routledge.\n\n\nMehr, S. A., L. A. Song, and E. S. Spelke. 2016. ‚ÄúFor 5-Month-Old\nInfants, Melodies Are Social.‚Äù Psychological Science 27\n(4): 486‚Äì501.\n\n\nMetropolis, Nicholas, Arianna W. Rosenbluth, Marshall N. Rosenbluth,\nAugusta H. Teller, and Edward Teller. 1953. ‚ÄúEquation of State\nCalculations by Fast Computing Machines.‚Äù The Journal of\nChemical Physics 21 (6): 1087‚Äì92.\n\n\nMogg, Karin, Katherine E Bradbury, and Brendan P Bradley. 2006.\n‚ÄúInterpretation of Ambiguous Information in Clinical\nDepression.‚Äù Behaviour Research and Therapy 44 (10):\n1411‚Äì19.\n\n\nMoore, Don A, Juliana Schroeder, Erica R Bailey, Rachel Gershon, Joshua\nE Moore, and Joseph P Simmons. 2024. ‚ÄúDoes Thinking about God\nIncrease Acceptance of Artificial Intelligence in\nDecision-Making?‚Äù Proceedings of the National Academy of\nSciences 121 (31): e2402315121.\n\n\nMunger, Kevin. 2023. ‚ÄúTemporal Validity as Meta-Science.‚Äù\nResearch & Politics 10 (3): 20531680231187271.\n\n\nMyers, Catherine E, Alejandro Interian, and Ahmed A Moustafa. 2022.\n‚ÄúA Practical Introduction to Using the Drift Diffusion Model of\nDecision-Making in Cognitive Psychology, Neuroscience, and Health\nSciences.‚Äù Frontiers in Psychology 13: 1039172.\n\n\nNavarro, Danielle J. 2019. ‚ÄúBetween the Devil and the Deep Blue\nSea: Tensions Between Scientific Judgement and Statistical Model\nSelection.‚Äù Computational Brain & Behavior 2 (1):\n28‚Äì34.\n\n\nNelson, Leif D, Joseph Simmons, and Uri Simonsohn. 2018.\n‚ÄúPsychology‚Äôs Renaissance.‚Äù Annual Review of\nPsychology 69 (1): 511‚Äì34.\n\n\nNobles, Melissa. 2000. Shades of Citizenship: Race and the Census in\nModern Politics. Stanford University Press.\n\n\nNosek, Brian A, Jeffrey R Spies, and Matt Motyl. 2012. ‚ÄúScientific\nUtopia: II. Restructuring Incentives and Practices to Promote Truth over\nPublishability.‚Äù Perspectives on Psychological Science 7\n(6): 615‚Äì31.\n\n\nNotebaert, Wim, Femke Houtman, Filip Van Opstal, Wim Gevers, Wim Fias,\nand Tom Verguts. 2009. ‚ÄúPost-Error Slowing: An Orienting\nAccount.‚Äù Cognition 111 (2): 275‚Äì79.\n\n\nNuzzo, Regina. 2014. ‚ÄúStatistical Errors.‚Äù Nature\n506 (7487): 150‚Äì52.\n\n\nO‚ÄôHagan, Anthony. 2019. ‚ÄúExpert Knowledge Elicitation: Subjective\nbut Scientific.‚Äù The American Statistician 73 (sup1):\n69‚Äì81.\n\n\nOberauer, Klaus, and Stephan Lewandowsky. 2019. ‚ÄúAddressing the\nTheory Crisis in Psychology.‚Äù Psychonomic Bulletin &\nReview 26: 1596‚Äì1618.\n\n\nPalminteri, Stefano, Mehdi Khamassi, Mateus Joffily, and Giorgio\nCoricelli. 2015. ‚ÄúContextual Modulation of Value Signals in Reward\nand Punishment Learning.‚Äù Nature Communications 6 (1):\n8096.\n\n\nPapadatou-Pastou, Marietta, Eleni Ntolka, Judith Schmitz, Maryanne\nMartin, Marcus R Munaf√≤, Sebastian Ocklenburg, and Silvia Paracchini.\n2020. ‚ÄúHuman Handedness: A Meta-Analysis.‚Äù\nPsychological Bulletin 146 (6): 481‚Äì524.\n\n\nPaxinou, Evgenia, Dimitrios Kalles, Christos T Panagiotakopoulos, and\nVassilios S Verykios. 2021. ‚ÄúAnalyzing Sequence Data with Markov\nChain Models in Scientific Experiments.‚Äù SN Computer\nScience 2 (5): 385.\n\n\nPearl, Judea. 1995. ‚ÄúCausal Diagrams for Empirical\nResearch.‚Äù Biometrika 82 (4): 669‚Äì88.\n\n\n‚Äî‚Äî‚Äî. 2009. Causality. Cambridge University Press.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. John Wiley &\nSons.\n\n\nPearl, Judea, and Dana Mackenzie. 2018. The Book of Why: The New\nScience of Cause and Effect. Basic books.\n\n\nPeeters, Ward, Mohammed Saqr, and Olga Viberg. 2020. ‚ÄúApplying\nLearning Analytics to Map Students‚Äô Self-Regulated Learning Tactics in\nan Academic Writing Course.‚Äù In Proceedings of the 28th\nInternational Conference on Computers in Education, 1:245‚Äì54.\nSeptember. Asia-Pacific Society for Computers in Education.\n\n\nPress, S James. 2009. Subjective and Objective Bayesian Statistics:\nPrinciples, Models, and Applications. John Wiley & Sons.\n\n\nRafaeli, Eshkol, and William Revelle. 2006. ‚ÄúA Premature\nConsensus: Are Happiness and Sadness Truly Opposite Affects?‚Äù\nMotivation and Emotion 30: 1‚Äì12.\n\n\nRamsey, Frank P. 1926. ‚ÄúTruth and Probability.‚Äù In\nReadings in Formal Epistemology: Sourcebook, 21‚Äì45. Springer.\n\n\nRescorla, Robert A, and A. R. Wagner. 1972. ‚ÄúA Theory of Pavlovian\nConditioning: Variations in the Effectiveness of Reinforcement and\nNon-Reinforcement.‚Äù Classical Conditioning II, Current\nResearch and Theory 2: 64‚Äì69.\n\n\nRiederer, Emily. 2021. ‚ÄúCausal Design Patterns for Data\nAnalysts,‚Äù January. https://emilyriederer.netlify.app/post/causal-design-patterns/.\n\n\nRitchie, Stuart J, Richard Wiseman, and Christopher C French. 2012.\n‚ÄúFailing the Future: Three Unsuccessful Attempts to Replicate\nBem‚Äôs ‚ÄòRetroactive Facilitation of Recall‚Äôeffect.‚Äù PloS\nOne 7 (3): e33423.\n\n\nRoger, Eckhardt. 1987. ‚ÄúStan Ulam, John von Neumann, and the Monte\nCarlo Method.‚Äù Los Alamos Science 15: 131‚Äì37.\n\n\nRosa, Linda, Emily Rosa, Larry Sarner, and Stephen Barrett. 1998.\n‚ÄúA Close Look at Therapeutic Touch.‚Äù Jama 279\n(13): 1005‚Äì10.\n\n\nRoss, Cody T, Bruce Winterhalder, and Richard McElreath. 2021.\n‚ÄúRacial Disparities in Police Use of Deadly Force Against Unarmed\nIndividuals Persist After Appropriately Benchmarking Shooting Data on\nViolent Crime Rates.‚Äù Social Psychological and Personality\nScience 12 (3): 323‚Äì32.\n\n\nRowland, Zarah, and Mario Wenzel. 2020. ‚ÄúMindfulness and\nAffect-Network Density: Does Mindfulness Facilitate Disengagement from\nAffective Experiences in Daily Life?‚Äù Mindfulness 11:\n1253‚Äì66.\n\n\nRussell, James A. 1980. ‚ÄúA Circumplex Model of Affect.‚Äù\nJournal of Personality and Social Psychology 39 (6): 1161‚Äì78.\n\n\nSaqr, Mohammed, and Sonsoles L√≥pez-Pernas. 2023. ‚ÄúThe Temporal\nDynamics of Online Problem-Based Learning: Why and When Sequence\nMatters.‚Äù International Journal of Computer-Supported\nCollaborative Learning 18 (1): 11‚Äì37.\n\n\nScheel, Anne M, Mitchell RMJ Schijen, and Dani√´l Lakens. 2021. ‚ÄúAn\nExcess of Positive Results: Comparing the Standard Psychology Literature\nwith Registered Reports.‚Äù Advances in Methods and Practices\nin Psychological Science 4 (2): 25152459211007467.\n\n\nSchennach, Susanne M. 2016. ‚ÄúRecent Advances in the Measurement\nError Literature.‚Äù Annual Review of Economics 8 (1):\n341‚Äì77.\n\n\nSchoot, Van Rens de, Duco Veen, Laurent Smeets, and Sonja Winter. 2020.\n‚ÄúA Tutorial on Using the WAMBS Checklist to Avoid the Misuse of\nBayesian Statistics.‚Äù Routledge.\n\n\nSchulz, Eric, and Samuel J Gershman. 2019. ‚ÄúThe Algorithmic\nArchitecture of Exploration in the Human Brain.‚Äù Current\nOpinion in Neurobiology 55: 7‚Äì14.\n\n\nShiffrin, Richard M, and Walter Schneider. 1977. ‚ÄúControlled and\nAutomatic Human Information Processing: II. Perceptual Learning,\nAutomatic Attending and a General Theory.‚Äù Psychological\nReview 84 (2): 127‚Äì90.\n\n\nSimchon, Almog, Britt Hadar, and Michael Gilead. 2023. ‚ÄúA\nComputational Text Analysis Investigation of the Relation Between\nPersonal and Linguistic Agency.‚Äù Communications\nPsychology 1 (1): 23.\n\n\nSimmons, Joseph P, Leif D Nelson, and Uri Simonsohn. 2011.\n‚ÄúFalse-Positive Psychology: Undisclosed Flexibility in Data\nCollection and Analysis Allows Presenting Anything as\nSignificant.‚Äù Psychological Science 22 (11): 1359‚Äì66.\n\n\nSkinner, Burrhus Frederic. 1965. Science and Human Behavior.\n92904. Simon; Schuster.\n\n\nSmaldino, Paul E, and Richard McElreath. 2016. ‚ÄúThe Natural\nSelection of Bad Science.‚Äù Royal Society Open Science 3\n(9): 160384.\n\n\nSorensen, Tanner, and Shravan Vasishth. 2015. ‚ÄúBayesian Linear\nMixed Models Using Stan: A Tutorial for Psychologists, Linguists, and\nCognitive Scientists.‚Äù arXiv Preprint arXiv:1506.06201.\n\n\nSpector, Aaron J. 1956. ‚ÄúExpectations, Fulfillment, and\nMorale.‚Äù The Journal of Abnormal and Social Psychology\n52 (1): 51‚Äì56.\n\n\nSpeelman, Craig P, Laura Parker, Benjamin J Rapley, and Marek McGann.\n2024. ‚ÄúMost Psychological Researchers Assume Their Samples Are\nErgodic: Evidence from a Year of Articles in Three Major\nJournals.‚Äù Collabra: Psychology 10 (1).\n\n\nStevens, Stanley Smith. 1946. ‚ÄúOn the Theory of Scales of\nMeasurement.‚Äù Science 103 (2684): 677‚Äì80.\n\n\nStigler, Stephen. 1986. The History of Statistics.\nMassachusetts: Belknap Harvard.\n\n\nSutton, Richard S, and Andrew G Barto. 2018. ‚ÄúReinforcement\nLearning: An Introduction, Second Edi.‚Äù The MIT Press.\n\n\nTomitaka, Shinichiro, Yohei Kawasaki, Kazuki Ide, Maiko Akutagawa,\nYutaka Ono, and Toshi A Furukawa. 2019. ‚ÄúDistribution of\nPsychological Distress Is Stable in Recent Decades and Follows an\nExponential Pattern in the US Population.‚Äù Scientific\nReports 9 (1): 11982.\n\n\nT√∂rm√§nen, Tiina, Hanna J√§rvenoja, Mohammed Saqr, Jonna Malmberg, and\nSanna J√§rvel√§. 2022. ‚ÄúA Person-Centered Approach to Study\nStudents‚Äô Socio-Emotional Interaction Profiles and Regulation of\nCollaborative Learning.‚Äù In Frontiers in Education,\n7:866612. Frontiers Media SA.\n\n\n‚Äî‚Äî‚Äî. 2023. ‚ÄúAffective States and Regulation of Learning During\nSocio-Emotional Interactions in Secondary School Collaborative\nGroups.‚Äù British Journal of Educational Psychology 93:\n48‚Äì70.\n\n\nVan Dongen, Noah, Riet van Bork, Adam Finnemann, Jonas Haslbeck, Han LJ\nvan der Maas, Donald J Robinaugh, Jill de Ron, Jan Sprenger, and Denny\nBorsboom. 2024. ‚ÄúProductive Explanation: A Framework for\nEvaluating Explanations in Psychological Science.‚Äù\nPsychological Review.\n\n\nVehtari, Aki, Andrew Gelman, Daniel Simpson, Bob Carpenter, and\nPaul-Christian B√ºrkner. 2021. ‚ÄúRank-Normalization, Folding, and\nLocalization: An Improved r ÃÇ for Assessing Convergence of MCMC (with\nDiscussion).‚Äù Bayesian Analysis 16 (2): 667‚Äì718.\n\n\nWagenmakers, Eric-Jan, Michael Lee, Tom Lodewyckx, and Geoffrey J\nIverson. 2008. ‚ÄúBayesian Versus Frequentist Inference.‚Äù\nBayesian Evaluation of Informative Hypotheses, 181‚Äì207.\n\n\nWard, Andrew, and Traci Mann. 2022. ‚ÄúControl Yourself: Broad\nImplications of Narrowed Attention.‚Äù Perspectives on\nPsychological Science 17 (6): 1692‚Äì1703.\n\n\nWare, Jennifer J, and Marcus R Munaf√≤. 2015. ‚ÄúSignificance Chasing\nin Research Practice: Causes, Consequences and Possible\nSolutions.‚Äù Addiction 110 (1): 4‚Äì8.\n\n\nWasserstein, Ronald L, and Nicole A Lazar. 2016. ‚ÄúThe\nASA‚Äôs Statement on p-Values: Context, Process, and\nPurpose.‚Äù The American Statistician 70 (2): 129‚Äì33.\n\n\nWatson, John B. 1913. ‚ÄúPsychology as the Behaviorist Views\nIt.‚Äù Psychological Review 20 (2): 158.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science. \" O‚ÄôReilly Media, Inc.\".\n\n\nWilke, Claus O. 2019. Fundamentals of Data Visualization: A Primer\non Making Informative and Compelling Figures. O‚ÄôReilly Media.\n\n\nWilkinson, GN, and CE Rogers. 1973. ‚ÄúSymbolic Description of\nFactorial Models for Analysis of Variance.‚Äù Journal of the\nRoyal Statistical Society Series C: Applied Statistics 22 (3):\n392‚Äì99.\n\n\nWilms, Rafael, E M√§thner, Lothar Winnen, and Ralf Lanwehr. 2021.\n‚ÄúOmitted Variable Bias: A Threat to Estimating Causal\nRelationships.‚Äù Methods in Psychology 5: 100075.\n\n\nYang, Yang, Wu Youyou, and Brian Uzzi. 2020. ‚ÄúEstimating the Deep\nReplicability of Scientific Findings Using Human and Artificial\nIntelligence.‚Äù Proceedings of the National Academy of\nSciences 117 (20): 10762‚Äì68.\n\n\nYaple, Zachary A, and Rongjun Yu. 2019. ‚ÄúFractionating Adaptive\nLearning: A Meta-Analysis of the Reversal Learning Paradigm.‚Äù\nNeuroscience & Biobehavioral Reviews 102: 85‚Äì94.\n\n\nYarkoni, Tal. 2022. ‚ÄúThe Generalizability Crisis.‚Äù\nBehavioral and Brain Sciences 45: e1.\n\n\nYouyou, Wu, Yang Yang, and Brian Uzzi. 2023. ‚ÄúA Discipline-Wide\nInvestigation of the Replicability of Psychology Papers over the Past\nTwo Decades.‚Äù Proceedings of the National Academy of\nSciences 120 (6): e2208863120.\n\n\nYu, Bin, and Rebecca L Barter. 2024. Veridical Data Science: The\nPractice of Responsible Data Analysis and Decision Making. MIT\nPress.\n\n\nZanesco, Anthony P. 2020. ‚ÄúQuantifying Streams of Thought During\nCognitive Task Performance Using Sequence Analysis.‚Äù Behavior\nResearch Methods 52 (6): 2417‚Äì37.\n\n\nZetsche, Ulrike, Paul-Christian Buerkner, and Babette Renneberg. 2019.\n‚ÄúFuture Expectations in Clinical Depression: Biased or\nRealistic?‚Äù Journal of Abnormal Psychology 128 (7): 678.\n\n\nZwet, Erik van, Andrew Gelman, Sander Greenland, Guido Imbens, Simon\nSchwab, and Steven N Goodman. 2023. ‚ÄúA New Look at p Values for\nRandomized Clinical Trials.‚Äù NEJM Evidence 3 (1):\nEVIDoa2300003.",
    "crumbs": [
      "Bibliografia"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html",
    "href": "chapters/appendix/a00_installation.html",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "",
    "text": "A.1 Guida all‚ÄôInstallazione Locale dei Jupyter Notebook\nPer facilitare l‚Äôapprendimento e l‚Äôapplicazione delle tecniche di analisi dei dati discusse in questo corso, utilizzeremo i Jupyter Notebook come strumento principale. I Jupyter Notebook sono documenti interattivi che consentono di combinare codice, testo narrativo, visualizzazioni grafiche e altri elementi multimediali, rendendoli ideali per documentare e condividere analisi di dati in modo trasparente e riproducibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "href": "chapters/appendix/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "",
    "text": "A.1.1 Prerequisiti per l‚ÄôUso dei Jupyter Notebook\nPer utilizzare i Jupyter Notebook, √® necessario soddisfare alcuni prerequisiti:\n\nInstallare Python: √à il linguaggio di programmazione fondamentale per il nostro corso e deve essere installato sul vostro computer.\nGestione degli Ambienti Virtuali con conda: Utilizzeremo conda per creare e gestire ambienti virtuali, che permettono di isolare e gestire le dipendenze del progetto.\nInstallazione dei Pacchetti Python Necessari: Dovrete installare specifici pacchetti Python, inclusi PyMC per l‚Äôanalisi bayesiana, e altri pacchetti utili, all‚Äôinterno dell‚Äôambiente virtuale creato per questo corso.\nInterfaccia per l‚ÄôUso dei Jupyter Notebook: Avrete bisogno di un IDE (Integrated Development Environment) che supporti i Jupyter Notebook, come Visual Studio Code, per scrivere e eseguire i vostri notebook.\n\n\n\nA.1.2 Installazione di Anaconda\nLa maggior parte dei requisiti elencati pu√≤ essere agevolmente soddisfatta tramite l‚Äôinstallazione di Anaconda, una distribuzione di Python che include conda e facilita la gestione degli ambienti virtuali e l‚Äôinstallazione dei pacchetti.\n\n\n\n\n\n\nSe Anaconda √® gi√† stata installata, potrebbero sorgere problemi dopo l‚Äôaggiornamento del sistema operativo. In tal caso, sar√† indispensabile procedere con una nuova installazione di Anaconda.\n\n\n\n\nA.1.2.1 Per Utenti macOS\nSe lavorate su macOS, potreste trovare pi√π pratico utilizzare conda direttamente dal Terminale o da un‚Äôapplicazione terminale moderna come Warp, piuttosto che attraverso Anaconda Navigator. In questo caso, potete optare per installare una versione di Visual Studio Code indipendente da quella fornita con Anaconda, per un maggiore controllo e flessibilit√†.\n\n\nA.1.2.2 Per Utenti Windows\nPer coloro che utilizzano Windows, l‚Äôuso di Jupyter Notebook tramite Anaconda Navigator potrebbe risultare la scelta pi√π semplice e diretta, grazie all‚Äôintegrazione e alla facilit√† d‚Äôuso fornite da Anaconda in ambienti Windows.\n\n\n\nA.1.3 Creazione e Configurazione dell‚ÄôAmbiente Virtuale\nIndipendentemente dal sistema operativo, √® fondamentale installare e configurare conda, che vi permetter√† di creare {ref}appendix-virtual-env dedicati. All‚Äôinterno di questi ambienti, installerete cmdstanpy (o PyMC) e gli altri pacchetti richiesti per il corso. La strada pi√π semplice per soddisfare questi requisiti √® attraverso l‚Äôinstallazione di Anaconda, che semplifica notevolmente il processo di configurazione iniziale e gestione degli ambienti virtuali.\nQuesta guida all‚Äôinstallazione locale mira a fornirvi tutti gli strumenti necessari per iniziare a utilizzare i Jupyter Notebook nel contesto del nostro corso, facilitando un apprendimento efficiente e la condivisione dei risultati delle vostre analisi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#guida-allinstallazione-di-anaconda",
    "href": "chapters/appendix/a00_installation.html#guida-allinstallazione-di-anaconda",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.2 Guida all‚ÄôInstallazione di Anaconda",
    "text": "A.2 Guida all‚ÄôInstallazione di Anaconda\nAnaconda √® una distribuzione popolare per la programmazione in Python. Ecco una guida passo-passo per l‚Äôinstallazione:\n\nScaricare Anaconda:\n\nVisitate il sito ufficiale di Anaconda: https://www.anaconda.com/.\nScegliete la versione adatta al vostro sistema operativo (Windows, macOS o Linux).\nOptate per il download dell‚Äôultima versione disponibile, che include l‚Äôultima versione di Python.\n\nInstallare Anaconda:\n\nEseguite il file di installazione scaricato.\nSeguite le istruzioni visualizzate, mantenendo le impostazioni predefinite, a meno che non abbiate esigenze specifiche.\n\nAggiungere Anaconda al ‚ÄòPATH‚Äô del Sistema:\n\nDurante l‚Äôinstallazione, vi sar√† chiesto se desiderate aggiungere Anaconda al ‚ÄòPATH‚Äô del sistema. Questo passaggio √® cruciale poich√© consente di utilizzare Python da qualunque parte del computer.\nVi consiglio di selezionare questa opzione (altri metodi sono possibili, ma questo ha dimostrato di funzionare senza problemi).\n\nConfermare l‚ÄôInstallazione:\n\nAl termine dell‚Äôinstallazione, aprite PowerShell all‚Äôinterno di Anaconda Navigagor (Windows) o il terminale (macOS/Linux) e digitate python --version per verificare se l‚Äôinstallazione √® riuscita. Se compare la versione di Python, tutto √® andato a buon fine.\n\n\nAnaconda include il Navigator, un‚Äôinterfaccia utente grafica per gestire ambienti di sviluppo, installare librerie aggiuntive e lanciare strumenti come Jupyter Notebook, che consente (in alternativa a VS Code) di scrivere ed eseguire codice Python.\n\n\n\n\n\n\nIstruzioni Specifiche per Utenti Windows:\n\nScaricare Anaconda:\n\nScaricate la versione ‚Äú64-Bit Graphical Installer‚Äù dal sito di Anaconda.\n\nInstallare Anaconda:\n\nAvviate l‚Äôinstaller scaricato e seguite le istruzioni visualizzate.\nDurante l‚Äôinstallazione, selezionate ‚ÄúJust Me‚Äù (solo per l‚Äôutente corrente).\nMantenete il percorso di installazione predefinito.\n\nIncludere Anaconda nel ‚ÄòPATH‚Äô:\n\nIMPORTANTE: Selezionate l‚Äôopzione per aggiungere Anaconda al PATH e impostarlo come installazione di Python di default. Di default, questa opzione √® deselezionata.\n\nVerifica dell‚ÄôInstallazione:\n\nCercate ‚ÄúAnaconda Navigator‚Äù nel menu Start. Se si apre correttamente, l‚Äôinstallazione √® riuscita.\nAprite ‚ÄúAnaconda Prompt‚Äù (o ‚ÄúPowerShell‚Äù) dal menu Start di Anaconda Navigator e digitate conda --version per confermare l‚Äôinstallazione di conda.\n\n\nSeguite attentamente queste istruzioni per garantire un‚Äôinstallazione senza problemi.\nPer maggiori dettagli, consultate il tutorial su come installare Anaconda su Windows: Tutorial Installazione di Anaconda su Windows. Questo tutorial offre spiegazioni dettagliate e una guida passo-passo.\n\n\n\nUna volta installato Anaconda, potrete utilizzare Anaconda Navigator per gestire progetti Python, installare librerie necessarie e avviare strumenti come Jupyter Notebook.\n\n\n\n\n\n\n√à necessario comprendere la differenza tra applicazione (App) e installer.\nCos‚Äô√® un‚ÄôApplicazione (App)\nUn‚Äôapplicazione, comunemente chiamata ‚Äúapp‚Äù, √® un software che funziona sul vostro computer o dispositivo mobile per uno scopo specifico, come navigare in internet, inviare messaggi, elaborare testi o fare calcoli. Esempi includono browser web come Google Chrome, programmi di elaborazione testi come Microsoft Word, o sistemi come Anaconda Navigator.\nCos‚Äô√® un Installer\nUn installer √® un software che installa un‚Äôapplicazione sul vostro computer. Tipicamente, quando scaricate un‚Äôapplicazione da internet, scaricate in realt√† l‚Äôinstaller. L‚Äôinstaller ha il compito di: - Copiare i file dell‚Äôapp nella corretta cartella del computer. - Creare scorciatoie per l‚Äôapp, come icone sul desktop o voci nel menu Start. - Configurare impostazioni iniziali per il corretto funzionamento dell‚Äôapp.\nDopo l‚ÄôInstallazione\nDopo che l‚Äôinstaller ha completato il suo lavoro, l‚Äôapplicazione sar√† pronta all‚Äôuso e l‚Äôinstaller pu√≤ essere eliminato.\nIn sintesi, l‚Äôapplicazione √® il software che userete per svolgere compiti specifici, mentre l‚Äôinstaller √® lo strumento temporaneo per installare l‚Äôapplicazione sul vostro computer. Capire questa distinzione √® fondamentale nel mondo dell‚Äôinformatica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#sec-virtual-environment",
    "href": "chapters/appendix/a00_installation.html#sec-virtual-environment",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.3 L‚ÄôAmbiente Virtuale in Python",
    "text": "A.3 L‚ÄôAmbiente Virtuale in Python\nDopo aver installato Python tramite Anaconda, un aspetto fondamentale da considerare √® la creazione di un ambiente virtuale. Un ambiente virtuale rappresenta uno spazio dedicato sul vostro computer, dove √® possibile installare e gestire le librerie Python necessarie per il corso, inclusi quelle per l‚Äôanalisi statistica. La creazione di un ambiente virtuale √® estremamente vantaggiosa poich√© contribuisce all‚Äôorganizzazione del lavoro e previene possibili conflitti tra diverse librerie. Le istruzioni dettagliate per la configurazione di un ambiente virtuale sono disponibili nel Appendice E`.\nL‚Äôesecuzione delle fasi precedentemente delineate, ossia l‚Äôinstallazione di Anaconda, la configurazione di Visual Studio Code e la creazione di un ambiente virtuale, assicurer√† la completa preparazione di un ambiente di sviluppo locale ottimizzato per l‚Äôutilizzo dei Jupyter Notebook nelle vostre attivit√† legate alla data science all‚Äôinterno di questo corso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#la-shell",
    "href": "chapters/appendix/a00_installation.html#la-shell",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.4 La Shell",
    "text": "A.4 La Shell\nPer la creazione e la gestione dell‚Äôambiente di calcolo, l‚Äôuso di una shell √® indispensabile. Questa pu√≤ essere approfondita nella sezione {ref}appendix-shell. La shell permette di interagire con il sistema operativo attraverso l‚Äôuso di comandi in un terminale. Diverse soluzioni software sono disponibili per facilitare questa interazione.\n\nA.4.1 Unix (MacOS, Linux)\nIn ambienti Unix come MacOS e Linux, ci sono diverse shell tra cui scegliere. Una scelta popolare √® Bash, che √® comunemente preinstallata su molti sistemi Unix. Un‚Äôaltra opzione moderna √® Zsh, nota per la sua facilit√† di personalizzazione e funzionalit√† avanzate. Per un‚Äôesperienza di terminale migliorata, warp √® un‚Äôopzione innovativa che offre un‚Äôinterfaccia utente ricca di funzionalit√† e supporto per i comandi intelligenti.\n\n\nA.4.2 Windows\nSu Windows, la shell predefinita √® il Prompt dei Comandi, ma non √® cos√¨ potente o flessibile come le shell disponibili su Unix. PowerShell √® un‚Äôopzione pi√π avanzata disponibile su Windows, che combina la gestione della configurazione e l‚Äôautomazione delle attivit√† con un linguaggio di scripting.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#lavorare-con-visual-studio-code",
    "href": "chapters/appendix/a00_installation.html#lavorare-con-visual-studio-code",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.5 Lavorare con Visual Studio Code",
    "text": "A.5 Lavorare con Visual Studio Code\nPer utilizzare Visual Studio Code con Python e Jupyter Notebook, √® essenziale installare le relative estensioni. Per fare ci√≤, √® sufficiente seguire alcuni semplici passaggi:\n\nAvvia Visual Studio Code sul tuo computer.\nNella barra laterale sinistra, trova e clicca sull‚Äôicona con quattro quadrati, di cui uno disallineato. Questo √® il menu delle estensioni.\nNella barra di ricerca all‚Äôinterno del menu delle estensioni, digita ‚ÄúPython‚Äù e premi Invio. Troverai diverse estensioni relative a Python.\nTrova l‚Äôestensione ufficiale di Python sviluppata da Microsoft e installala cliccando sul pulsante ‚ÄúInstalla‚Äù.\nSuccessivamente, cerca ‚ÄúJupyter‚Äù nella barra di ricerca delle estensioni e premi Invio.\nTrova l‚Äôestensione ‚ÄúJupyter‚Äù nell‚Äôelenco dei risultati e installala cliccando sul pulsante ‚ÄúInstalla‚Äù.\n\nUna volta completati questi passaggi, avrai installato con successo le componenti aggiuntive necessarie per lavorare con Python e Jupyter Notebook all‚Äôinterno di Visual Studio Code. Potrai quindi iniziare a scrivere, eseguire e testare il tuo codice Python e i tuoi notebook Jupyter direttamente nell‚Äôambiente di sviluppo di Visual Studio Code.\nQuando apri un file con estensione .ipynb in Visual Studio Code ricorda di selezionare l‚Äôambiente virtuale che desiderate utilizzare. Puoi farlo tramite la ‚ÄúCommand Palette‚Äù (‚áß‚åòP), utilizzando l‚Äôistruzione Python: Select Interpreter. In alternativa, puoi fare clic sull‚Äôicona Select kernel di Visual Studio Code, che si trova nell‚Äôangolo in alto a destra, sotto l‚Äôicona degli ingranaggi (‚öôÔ∏è).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#google-colab",
    "href": "chapters/appendix/a00_installation.html#google-colab",
    "title": "Appendice A ‚Äî Ambiente di lavoro",
    "section": "A.6 Google Colab",
    "text": "A.6 Google Colab\nUtilizzando il link √® possibile accedere a Google Colab e iniziare a scrivere codice Python direttamente dal proprio browser, senza dover effettuare alcuna installazione. Basta selezionare l‚Äôopzione ‚ÄúNuovo notebook‚Äù per creare un nuovo ambiente di lavoro. Per avere un‚Äôintroduzione completa sulle funzionalit√† di Colab, si pu√≤ consultare la guida disponibile al seguente link. √à possibile salvare ogni notebook nella propria cartella di Google Drive per una facile gestione e condivisione dei file.\n\nA.6.1 Uso dei Comandi Speciali in Colab\nNell‚Äôambiente Google Colab, √® possibile utilizzare il comando\n!pip list -v\nper visualizzare un elenco dettagliato di tutte le librerie preinstallate. Questo comando fornisce informazioni utili per comprendere quali strumenti sono immediatamente disponibili per l‚Äôuso, comprese le versioni delle librerie e i percorsi di installazione.\nIl prefisso ! indica un comando speciale, noto anche come comando ‚Äúshell‚Äù, che consente di interagire con il sistema sottostante di Colab direttamente dalla cella del notebook, eseguendo operazioni al di fuori dell‚Äôambiente Python standard.\n\n\nA.6.2 Installazione di Librerie Supplementari\nSe necessario aggiungere ulteriori librerie all‚Äôambiente Colab, come pymc, bambi, e arviz, √® possibile farlo facilmente mediante l‚Äôuso dei comandi pip. Ad esempio, per installare queste tre librerie, si possono eseguire i seguenti comandi uno dopo l‚Äôaltro:\n!pip install bambi\n!pip install pymc\n!pip install arviz\nQuesti comandi non solo installeranno le librerie specificate ma gestiranno anche automaticamente l‚Äôinstallazione delle dipendenze necessarie, tra cui numpy, pandas, matplotlib, seaborn, scipy, e statsmodels, assicurando cos√¨ che tutto l‚Äôambiente di lavoro sia pronto per l‚Äôuso.\n\n\nA.6.3 Google Drive\n\nA.6.3.1 Collegare Google Drive a Colab\nPer accedere alla propria cartella di Google Drive durante l‚Äôutilizzo di Colab, √® possibile seguire i seguenti passaggi:\n\nDalla pagina iniziale, fare clic sull‚Äôicona a forma di cartella (Files) situata nel menu in alto a sinistra.\n\n\n\nSi aprir√† un menu con diverse opzioni.\n\n\n\nSelezionare la terza icona tra le quattro disposte orizzontalmente. Apparir√† l‚Äôistruzione ‚ÄúRun this cell to mount your Google Drive‚Äù. Fare clic sull‚Äôicona del triangolo contenuta in un cerchio grigio.\nA questo punto, fare clic sull‚Äôicona ‚Äúdrive‚Äù e successivamente su ‚ÄúMyDrive‚Äù per accedere alle cartelle e ai file salvati sul proprio Google Drive.\n\n√à importante tenere presente che la versione gratuita del runtime di Google Colaboratory non salva le informazioni in modo permanente, il che significa che tutto il lavoro svolto verr√† eliminato una volta terminata la sessione. Pertanto, √® necessario reinstallare le librerie utilizzate in precedenza ogni volta che ci si connette a Colab. Al contrario, i Jupyter Notebook possono essere salvati nella propria cartella di Google Drive.\nPer salvare un Jupyter Notebook su Google Drive utilizzando Colab, √® possibile seguire i seguenti passaggi:\n\nFare clic su File nella barra del menu di Colab.\nSelezionare Save a copy in Drive. Di default, Colab salver√† il Notebook nella cartella Colab Notebooks/.ipynb_checkpoints con un nome simile a Untitled7.ipynb.\nDopo aver salvato il Notebook, √® consigliabile rinominarlo facendo clic con il pulsante destro del mouse sul file nella cartella di Google Drive e selezionando Rename. In questo modo sar√† possibile assegnare un nome pi√π significativo al Notebook.\nPer organizzare i file, √® possibile trascinare il Notebook nella cartella desiderata all‚Äôinterno di Google Drive.\n\nSeguendo questi passaggi, sar√† possibile salvare e organizzare i Jupyter Notebook nella propria cartella di Google Drive, consentendo di accedervi facilmente e mantenerli in modo permanente anche dopo la sessione di Colab.\n\n\n\n\n\n\n√à possibile accedere a un breve tutorial video su come utilizzare Colab e come leggere i dati da un file esterno in un Notebook di Jupyter in Colab. Il video tutorial pu√≤ essere trovato seguendo il link fornito.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>¬† <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html",
    "href": "chapters/appendix/a01_markdown.html",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "",
    "text": "B.1 Configurazione Locale per Jupyter Notebook\nPer iniziare a lavorare con i Jupyter Notebook nel proprio ambiente di sviluppo locale, √® necessario completare alcuni passaggi preliminari che assicurano una configurazione ottimale:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "href": "chapters/appendix/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "",
    "text": "Installazione di Python tramite Anaconda: Anaconda √® una distribuzione di Python che include gi√† Jupyter e altre librerie utili per la data science e l‚Äôanalisi di dati. Seguendo le istruzioni dettagliate disponibili sul sito di Anaconda (e fornite in precedenza in questa dispensa), si pu√≤ facilmente installare Python e Jupyter sul proprio sistema.\nSelezione di un Ambiente di Sviluppo Integrato (IDE): Visual Studio Code (VS Code) rappresenta una scelta eccellente per chi cerca un IDE versatile e gratuito. Disponibile al download dal sito ufficiale, VS Code supporta Python tramite l‚Äôinstallazione di una specifica estensione. Dopo aver installato VS Code, √® possibile aggiungere il supporto per Python e per i Jupyter Notebook installando l‚Äôestensione ‚ÄúPython‚Äù disponibile nella sezione ‚ÄúExtensions‚Äù, identificabile dall‚Äôicona dei quattro quadrati. Per una completa integrazione dei notebook Jupyter, potrebbe essere necessario installare anche la libreria ipykernel.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#celle",
    "href": "chapters/appendix/a01_markdown.html#celle",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.2 Celle",
    "text": "B.2 Celle\nI Jupyter Notebook sono organizzati in celle, elementi discreti che possono contenere codice o testo (markdown). La possibilit√† di cambiare il tipo di una cella tramite il menu ‚ÄúCell‚Äù o la barra degli strumenti, selezionando ‚ÄúCode‚Äù per codice Python o ‚ÄúMarkdown‚Äù per annotazioni testuali, rende i notebook estremamente versatili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#formattazione-del-testo-con-markdown",
    "href": "chapters/appendix/a01_markdown.html#formattazione-del-testo-con-markdown",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.3 Formattazione del Testo con Markdown",
    "text": "B.3 Formattazione del Testo con Markdown\nMarkdown permette di arricchire le celle di testo con formattazioni varie, creando un documento strutturato e leggibile. Ecco alcuni esempi:\n\nTitoli: # Titolo per un titolo di primo livello, ## Sottotitolo per un secondo livello, e cos√¨ via.\nElenchi: - Elemento per elenchi puntati, 1. Elemento per elenchi numerati.\nCollegamenti: [Testo del link](URL) per inserire un link.\nEnfasi: **grassetto** per il testo in grassetto, *corsivo* per il corsivo.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "href": "chapters/appendix/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "title": "Appendice B ‚Äî Jupyter Notebook",
    "section": "B.4 Comandi Magici in Jupyter Notebook",
    "text": "B.4 Comandi Magici in Jupyter Notebook\nI Jupyter Notebook supportano i ‚Äúcomandi magici‚Äù, comandi speciali che iniziano con % (per comandi su una singola riga) o %% (per comandi che occupano un‚Äôintera cella). Questi comandi offrono funzionalit√† avanzate come:\n\n%run: esegue un file Python esterno.\n%timeit: valuta il tempo di esecuzione di una singola riga di codice.\n%matplotlib inline: integra grafici Matplotlib direttamente nel notebook.\n%load: carica il codice da un file esterno in una cella.\n%reset: cancella tutte le variabili definite nel notebook.\n%pwd e %cd: gestiscono il percorso della directory di lavoro.\n\nDigitando %lsmagic in una cella, si pu√≤ accedere all‚Äôelenco completo dei comandi magici disponibili, esplorando cos√¨ ulteriori strumenti e funzionalit√† offerte da Jupyter Notebook.\nIn conclusione, i Jupyter Notebook rappresentano uno strumento indispensabile per chi lavora nel campo della programmazione e dell‚Äôanalisi dati, grazie alla loro capacit√† di unire codice, visualizzazione dei dati, e annotazioni testuali in un unico documento interattivo e facilmente condivisibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>¬† <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html",
    "href": "chapters/appendix/a02_shell.html",
    "title": "Appendice C ‚Äî La Shell",
    "section": "",
    "text": "C.1 Che cos‚Äô√® una Shell?\nUna shell √® un programma che riceve comandi dall‚Äôutente tramite tastiera (o da file) e li passa al sistema operativo per l‚Äôesecuzione. Pu√≤ essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html#che-cos√®-una-shell",
    "href": "chapters/appendix/a02_shell.html#che-cos√®-una-shell",
    "title": "Appendice C ‚Äî La Shell",
    "section": "",
    "text": "C.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nC.1.2 Windows vs macOS/Linux\n\nWindows 10: √à possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l‚Äôambiente preferito √® solitamente PowerShell.\nmacOS/Linux: Zsh √® la shell predefinita in entrambi i sistemi. √à consigliabile sfruttare l‚Äôapplicazione warp per un‚Äôesperienza utente moderna e ottimizzata.\n\n\n\nC.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nC.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nC.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless/more: Visualizza il contenuto dei file con possibilit√† di navigazione.\ncat: Mostra l‚Äôintero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nC.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l‚Äôutilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilit√† nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma pi√π potente perch√© pu√≤ rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nC.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nC.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilit√† di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l‚Äôintero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\n√à cruciale familiarizzarsi con l‚Äôutilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L‚Äôimpiego dei percorsi relativi rende il processo di navigazione pi√π intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l‚Äôutilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: √à importante evitare l‚Äôinserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, ), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l‚Äôuso del trattino (-) pu√≤ causare problemi; quindi √® consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilit√† con alcuni sistemi operativi o applicazioni, rendendo pi√π complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, √® consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, √® possibile ottimizzare notevolmente l‚Äôorganizzazione e la gestione dei propri file, migliorando l‚Äôefficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti. La familiarit√† con la shell √® fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>¬† <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_colab_tutorial.html",
    "href": "chapters/appendix/a03_colab_tutorial.html",
    "title": "Appendice D ‚Äî Colab: un breve tutorial",
    "section": "",
    "text": "D.1 Preparazione su Google Drive\nPer iniziare, √® necessario effettuare alcune operazioni preliminari su Google Drive:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_colab_tutorial.html#preparazione-su-google-drive",
    "href": "chapters/appendix/a03_colab_tutorial.html#preparazione-su-google-drive",
    "title": "Appendice D ‚Äî Colab: un breve tutorial",
    "section": "",
    "text": "Salvataggio dei file necessari: Accedi al tuo account Google Drive e salva i file di interesse, come un dataset e un Jupyter Notebook. Per esempio, potresti creare un Jupyter Notebook con Visual Studio Code e salvarlo con l‚Äôestensione .ipynb. In questo esempio, il file STAR.csv √® stato salvato nella cartella drive/MyDrive/teaching/psicometria/2024.\nPosizionamento dei file: Assicurati di conoscere con precisione il percorso della cartella in cui hai salvato i tuoi file. √à possibile salvare il notebook in qualsiasi cartella, ma √® importante ricordare dove si trova. Nel nostro esempio, anche il notebook import_data.ipynb √® stato salvato nella stessa cartella del dataset.\n\n\nD.1.1 Collegamento a Google Colab\nPer collegare il tuo Google Drive a Colab, inserisci il seguente codice nella prima cella del tuo Jupyter Notebook su Colab:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nEsegui questa cella per iniziare il processo di autenticazione. Ti verr√† richiesto di inserire le tue credenziali (si consiglia di utilizzare l‚Äôaccount istituzionale) e di concedere i permessi necessari a Colab per accedere al tuo Drive.\n\n\nD.1.2 Verifica del file\nPrima di procedere, √® utile verificare che il file desiderato si trovi effettivamente nel percorso specificato. Usa un comando simile al seguente per elencare i file presenti nella cartella:\n!ls drive/MyDrive/teaching/psicometria/2024\nSe il comando mostra il file STAR.csv, significa che √® presente nella cartella e pronto per essere utilizzato.\n\n\nD.1.3 Importazione dei pacchetti e del dataset\nPrima di importare i dati, importa i pacchetti Python necessari per la tua analisi:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nSuccessivamente, puoi importare i dati direttamente dal file CSV specificando il percorso completo:\ndf = pd.read_csv(\"drive/MyDrive/teaching/psicometria/2024/STAR.csv\")\n√à fondamentale usare il percorso completo dal punto di montaggio drive fino al nome del file. Il percorso varier√† a seconda dell‚Äôutente e della struttura del suo Drive.\n\n\nD.1.4 Visualizzazione dei dati\nCon i dati ora disponibili in df, puoi procedere con l‚Äôanalisi. Per esempio, per creare un istogramma della variabile reading, puoi usare il seguente codice:\n_ = sns.histplot(data=df, x=\"reading\", stat='density')\nQuesto ti permetter√† di visualizzare la distribuzione dei dati relativi alla lettura nel dataset STAR.csv.\nSeguendo questi passaggi, puoi facilmente lavorare con i file salvati su Google Drive direttamente all‚Äôinterno di un Jupyter Notebook su Google Colab.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>¬† <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html",
    "href": "chapters/appendix/a04_virtual_env.html",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "",
    "text": "E.1 Concetto di Ambiente Virtuale\nUn ambiente virtuale √® uno spazio di lavoro isolato sul vostro computer, dove potete installare e utilizzare librerie Python senza interferire con il sistema principale. Questo isolamento consente di gestire le versioni delle librerie in modo efficiente, mantenendo il sistema organizzato e sicuro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "href": "chapters/appendix/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.2 Vantaggi dell‚ÄôUso degli Ambienti Virtuali",
    "text": "E.2 Vantaggi dell‚ÄôUso degli Ambienti Virtuali\n\nIsolamento: Permette di selezionare e mantenere versioni specifiche di Python e delle librerie, garantendo la compatibilit√† e la stabilit√† del progetto.\nOrdine e Sicurezza: Mantiene separato l‚Äôambiente virtuale dal sistema principale, evitando conflitti e assicurando che le modifiche non influenzino altri programmi.\nRiproducibilit√† del Codice: Consente di condividere il codice in modo che funzioni correttamente su altri computer, garantendo coerenza e riproducibilit√† del lavoro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "href": "chapters/appendix/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda",
    "text": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda\nPer creare e gestire ambienti virtuali, √® possibile utilizzare conda, uno strumento incluso in Anaconda. Seguire i seguenti passaggi:\n\nAssicurarsi di avere Anaconda correttamente installato sul sistema.\nUtilizzare il terminale su macOS/Linux o PowerShell su Windows.\nEvitare di installare pacchetti direttamente nell‚Äôambiente base di Conda.\nCreare un nuovo ambiente virtuale usando il comando conda create.\nAttivare l‚Äôambiente virtuale appena creato utilizzando conda activate.\nInstallare i pacchetti necessari all‚Äôinterno dell‚Äôambiente virtuale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "href": "chapters/appendix/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.4 Gestione dell‚ÄôAmbiente Virtuale",
    "text": "E.4 Gestione dell‚ÄôAmbiente Virtuale\nPer una gestione pi√π efficiente degli ambienti virtuali, √® consigliabile utilizzare la linea di comando anzich√© l‚Äôinterfaccia grafica di Anaconda. Questo offre maggiore controllo e flessibilit√† nel processo di creazione e gestione degli ambienti.\nSeguendo correttamente questi passaggi, √® possibile sfruttare appieno i vantaggi degli ambienti virtuali, garantendo un ambiente di sviluppo Python pulito e ben organizzato.\n\n\n\n\n\n\n√à fondamentale evitare l‚Äôinstallazione diretta di pacchetti nell‚Äôambiente base di Conda. Assicuratevi sempre di seguire attentamente i seguenti passaggi:\n\nDisattivate l‚Äôambiente base.\nCreate un nuovo ambiente virtuale.\nAttivate il nuovo ambiente appena creato.\n\nSolo dopo aver completato questi passaggi, √® sicuro procedere con l‚Äôinstallazione dei pacchetti necessari. √à possibile verificare l‚Äôambiente attivo osservando il nome visualizzato all‚Äôinizio del prompt nel terminale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "href": "chapters/appendix/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali",
    "text": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali\n\nDisattivare l‚ÄôAmbiente Virtuale Corrente: Se siete in un ambiente virtuale e desiderate uscirne, utilizzate il comando:\nconda deactivate\nSe non siete in un ambiente virtuale, potete procedere al passaggio successivo.\nCreare un Nuovo Ambiente Virtuale: Per utilizzare il campionatore CmdStan e il linguaggio di programmazione probabilistica Stan, adottate l‚Äôambiente virtuale cmdstan_env. Se si utilizza conda, √® possibile installare CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge tramite la seguente procedura:\nconda create -n cmdstan_env -c conda-forge cmdstanpy\nConda richieder√† la conferma digitando y. Questo passaggio crea l‚Äôambiente e installa cmdstanpy insieme alle dipendenze necessarie.\nAttivare il Nuovo Ambiente: Per utilizzare l‚Äôambiente appena creato, attivatelo tramite:\nconda activate cmdstan_env\nInstallare le Librerie Richieste: All‚Äôinterno dell‚Äôambiente, installate altre librerie necessarie. Ecco come installare le librerie che utilizzeremo:\nconda install -c conda-forge jax numpyro bambi arviz seaborn jupyter-book ipywidgets watermark pingouin networkx -y \nNota: Gli utenti Windows potrebbero dover utilizzare nutpie come alternativa a jax.\nComandi Utili per Gestire Ambienti e Librerie:\n\nElencare gli ambienti virtuali disponibili e verificare quello attivo:\nconda env list\nRimuovere un ambiente virtuale specifico, ad esempio my_env:\nconda env remove -n my_env\nRimuovere una libreria da un ambiente specifico, ad esempio package_name:\nconda remove -n nome_ambiente package_name\n\n\nSeguendo attentamente questi passaggi e utilizzando i comandi di gestione, sarete in grado di creare e gestire efficacemente gli ambienti virtuali con Conda, garantendo una gestione pulita e ordinata delle dipendenze dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#conda-forge",
    "href": "chapters/appendix/a04_virtual_env.html#conda-forge",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.6 Conda Forge",
    "text": "E.6 Conda Forge\n√à consigliato aggiungere Conda Forge come canale aggiuntivo da cui Conda pu√≤ cercare e installare i pacchetti. Conda Forge √® una collezione di pacchetti gestita dalla community.\n\nE.6.1 Aggiungere Conda Forge\nPer aggiungere Conda Forge come canale, eseguire i seguenti comandi:\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\nconda config --add channels conda-forge: Aggiunge Conda Forge come canale aggiuntivo per la ricerca e l‚Äôinstallazione dei pacchetti.\nconda config --set channel_priority strict: Imposta la priorit√† dei canali su ‚Äústrict‚Äù, dando priorit√† ai pacchetti trovati nei canali elencati per primi nel file di configurazione .condarc.\n\n\n\nE.6.2 Vantaggi dell‚ÄôUso di Conda Forge\n\nAmpia Disponibilit√† di Pacchetti: Conda Forge offre un numero maggiore di pacchetti rispetto al canale predefinito di Conda, aumentando le possibilit√† di trovare il pacchetto necessario senza ricorrere ad altre soluzioni.\nAggiornamenti Frequenti: I pacchetti su Conda Forge vengono aggiornati pi√π frequentemente, rendendo pi√π probabile trovare le versioni pi√π recenti.\nCoerenza e Compatibilit√†: Utilizzando la priorit√† ‚Äústrict‚Äù e Conda Forge, si aumenta la coerenza e la compatibilit√† tra i pacchetti, riducendo il rischio di conflitti tra dipendenze.\n\nAggiungere Conda Forge come canale e impostare la priorit√† dei canali su ‚Äústrict‚Äù sono pratiche consigliate per migliorare la gestione dei pacchetti con Conda. Questo approccio aiuta a mantenere l‚Äôambiente stabile, aggiornato e compatibile con le ultime versioni dei pacchetti disponibili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "href": "chapters/appendix/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "title": "Appendice E ‚Äî Ambienti virtuali",
    "section": "E.7 Utilizzo di Graphviz (Opzionale)",
    "text": "E.7 Utilizzo di Graphviz (Opzionale)\nPer utilizzare il pacchetto Python graphviz, √® necessario installare prima Graphviz sul vostro computer. Le istruzioni specifiche per l‚Äôinstallazione variano a seconda del sistema operativo e sono disponibili sul sito ufficiale di Graphviz.\n\nE.7.1 Installazione di Graphviz\n\nInstallazione di Graphviz: Seguire le istruzioni sul sito di Graphviz per installare il software sul vostro sistema operativo (Windows, macOS, Linux).\nVerifica dell‚ÄôInstallazione: Dopo l‚Äôinstallazione, assicuratevi che Graphviz sia correttamente installato eseguendo il seguente comando nel terminale:\ndot -V\nQuesto comando dovrebbe restituire la versione di Graphviz installata.\n\n\n\nE.7.2 Installazione del Pacchetto Python graphviz\nDopo aver installato Graphviz, potete procedere con l‚Äôinstallazione del pacchetto Python graphviz nel vostro ambiente virtuale. Seguite questi passaggi:\n\nAttivare l‚ÄôAmbiente Virtuale: Attivate l‚Äôambiente virtuale in cui avete installato pymc (ad esempio, pymc_env) nella vostra console:\nconda activate pymc_env\nInstallare il Pacchetto Python graphviz: Eseguite il seguente comando per installare il pacchetto graphviz tramite Conda Forge:\nconda install -c conda-forge graphviz\n\n\n\nE.7.3 Vantaggi dell‚ÄôUtilizzo di Graphviz\nL‚Äôinstallazione di Graphviz e del relativo pacchetto Python consente di creare e visualizzare grafici e diagrammi all‚Äôinterno del vostro ambiente Python. Questo pu√≤ essere particolarmente utile per visualizzare strutture di dati complesse, flussi di lavoro o grafi probabilistici.\nSeguendo questi passaggi, sarete in grado di utilizzare le funzionalit√† di Graphviz nel vostro ambiente Python, migliorando le capacit√† di visualizzazione e analisi dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>¬† <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a10_math_symbols.html",
    "href": "chapters/appendix/a10_math_symbols.html",
    "title": "Appendice F ‚Äî Simbologia di base",
    "section": "",
    "text": "Per una scrittura pi√π sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL‚Äôoperatore logico booleano \\(\\land\\) significa ‚Äúe‚Äù (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa ‚Äúo‚Äù (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire ‚Äúesiste almeno un‚Äù e indica l‚Äôesistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicit√† \\(\\exists!\\) (‚Äúesiste soltanto un‚Äù) indica l‚Äôesistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l‚Äôesistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire ‚Äúper ogni.‚Äù\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) √® un elemento dell‚Äôinsieme \\(A\\).\nL‚Äôimplicazione logica ‚Äú\\(\\Rightarrow\\)‚Äù significa ‚Äúimplica‚Äù (se ‚Ä¶allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) √® condizione sufficiente per la verit√† di \\(Q\\) e che \\(Q\\) √® condizione necessaria per la verit√† di \\(P\\).\nL‚Äôequivalenza matematica ‚Äú\\(\\iff\\)‚Äù significa ‚Äúse e solo se‚Äù e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge ‚Äútale che.‚Äù\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge ‚Äúuguale per definizione.‚Äù\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge ‚Äúproporzionale a.‚Äù\nIl simbolo \\(\\approx\\) si legge ‚Äúcirca.‚Äù\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire ‚Äúappartiene‚Äù e indica l‚Äôappartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire ‚Äúnon appartiene.‚Äù\nIl simbolo \\(\\subseteq\\) si legge ‚Äú√® un sottoinsieme di‚Äù (pu√≤ coincidere con l‚Äôinsieme stesso). Il simbolo \\(\\subset\\) si legge ‚Äú√® un sottoinsieme proprio di.‚Äù\nIl simbolo \\(\\#\\) indica la cardinalit√† di un insieme.\nIl simbolo \\(\\cap\\) indica l‚Äôintersezione di due insiemi. Il simbolo \\(\\cup\\) indica l‚Äôunione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l‚Äôinsieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l‚Äôinsieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) √® l‚Äôinsieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore pi√π alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densit√† di probabilit√†.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilit√† o densit√† di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) √® una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilit√† di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilit√† di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>¬† <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice G ‚Äî Numeri e intervalli",
    "section": "",
    "text": "G.1 Numeri binari\nI numeri binari costituiscono la forma pi√π fondamentale di sistema numerico in informatica, essendo composto esclusivamente da due simboli, ovvero 0 e 1. Questo sistema √® frequentemente impiegato per rappresentare dualit√† logiche, come vero/falso o presenza/assenza, in virt√π della sua innata semplicit√† binaria. La sua applicazione √® particolarmente efficace nell‚Äôelaborazione di dati per generare statistiche sintetiche in modo efficiente e rapido.\nImmaginiamo di porre la seguente domanda a 10 studenti: ‚ÄúTi piacciono i mirtilli?‚Äù Le risposte potrebbero essere le seguenti:\nopinion = (True, False, True, True, True, False, True, True, True, False)\nopinion\n\n(True, False, True, True, True, False, True, True, True, False)\nIn questo caso, abbiamo utilizzato i numeri binari 0 e 1 per rappresentare risposte diverse, dove False indica ‚ÄúNo‚Äù e True indica ‚ÄúSi‚Äù. Questa rappresentazione binaria ci consente di ottenere facilmente una panoramica delle preferenze degli studenti riguardo i mirtilli.\nIn Python True equivale a 1 e False a zero. Possiamo dunque calcolare la proporzione di risposte positive nel modo seguente:\nsum(opinion) / len(opinion)\n\n0.7",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice G ‚Äî Numeri e intervalli",
    "section": "G.2 Numeri interi",
    "text": "G.2 Numeri interi\nI numeri interi sono numeri privi di decimali e comprendono sia i numeri naturali utilizzati per il conteggio, come 1, 2, ‚Ä¶, sia i numeri con il segno, necessari per rappresentare grandezze negative. L‚Äôinsieme dei numeri naturali √® indicato con il simbolo \\(\\mathbb{N}\\). L‚Äôinsieme numerico dei numeri interi relativi si rappresenta come \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice G ‚Äî Numeri e intervalli",
    "section": "G.3 Numeri razionali",
    "text": "G.3 Numeri razionali\nI numeri razionali sono numeri frazionari rappresentabili come \\(m/n\\), dove \\(m\\) e \\(n\\) sono numeri interi e \\(n\\) √® diverso da zero. Gli elementi dell‚Äôinsieme dei numeri razionali sono quindi dati da \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). √à importante notare che l‚Äôinsieme dei numeri naturali √® incluso in quello dei numeri interi, che a sua volta √® incluso in quello dei numeri razionali, ovvero \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Per rappresentare solo i numeri razionali non negativi, utilizziamo il simbolo \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice G ‚Äî Numeri e intervalli",
    "section": "G.4 Numeri irrazionali",
    "text": "G.4 Numeri irrazionali\nTuttavia, alcune grandezze non possono essere esprimibili come numeri interi o razionali. Questi numeri sono noti come numeri irrazionali e sono rappresentati dall‚Äôinsieme \\(\\mathbb{R}\\). Essi comprendono numeri illimitati e non periodici, che non possono essere scritti come frazioni. Ad esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\(\\pi = 3.141592\\ldots\\) sono esempi di numeri irrazionali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice G ‚Äî Numeri e intervalli",
    "section": "G.5 Numeri reali",
    "text": "G.5 Numeri reali\nI numeri razionali rappresentano solo una parte dei punti sulla retta \\(r\\). Per rappresentare ogni possibile punto sulla retta, √® necessario introdurre i numeri reali. L‚Äôinsieme dei numeri reali comprende numeri positivi, negativi e nulli, e contiene come casi particolari i numeri interi, razionali e irrazionali. In statistica, il numero di decimali spesso indica il grado di precisione della misurazione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli",
    "href": "chapters/appendix/a11_numbers.html#intervalli",
    "title": "Appendice G ‚Äî Numeri e intervalli",
    "section": "G.6 Intervalli",
    "text": "G.6 Intervalli\nQuesto ci porta a esplorare gli intervalli, una struttura matematica che ci aiuta a definire sottoinsiemi specifici sulla retta numerica. Gli intervalli aperti, che escludono i punti di inizio e fine. D‚Äôaltro canto, gli intervalli chiusi includono sia il punto di inizio che quello di fine, fornendo una copertura di valori senza tralasciare i confini. Le caratteristiche degli intervalli sono riportate nella tabella seguente.\n\n\n\nIntervallo\n\n\n\n\n\n\nchiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\naperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nchiuso a sinistra e aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\naperto a sinistra e chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>¬† <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice H ‚Äî Sommatorie",
    "section": "",
    "text": "H.1 Manipolazione di somme\n√à conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l‚Äôoperatore della sommatoria.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice H ‚Äî Sommatorie",
    "section": "",
    "text": "H.1.1 Propriet√† 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) √® pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\n\nH.1.2 Propriet√† 2 (propriet√† distributiva)\nNel caso in cui l‚Äôargomento contenga una costante, √® possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\n√® possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nH.1.3 Propriet√† 3 (propriet√† associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\n√à dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nH.1.4 Propriet√† 4\nSe deve essere eseguita un‚Äôoperazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull‚Äôargomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nH.1.5 Propriet√† 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice H ‚Äî Sommatorie",
    "section": "H.2 Doppia sommatoria",
    "text": "H.2 Doppia sommatoria\n√à possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell‚Äôindice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria √® il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi pu√≤ osservare che nella sommatoria interna (quella che dipende dall‚Äôindice \\(j\\)), la quantit√† \\(x_i\\) √® costante, ovvero non dipende dall‚Äôindice (che √® \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall‚Äôoperatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si pu√≤ osservare che nell‚Äôargomento della sommatoria esterna la quantit√† costituita dalla sommatoria in \\(j\\) non dipende dall‚Äôindice \\(i\\) e quindi questa quantit√† pu√≤ essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n}¬†x_i \\sum_{j=1}^{n} y_j.\n\\]\nFacciamo un esercizio. Verifichiamo quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto cos√¨ ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\n\\]\novvero\n\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>¬† <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "",
    "text": "I.1 Diagrammi di Eulero-Venn\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le propriet√† delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19¬∞ secolo John Venn, anche se rappresentazioni simili erano gi√† state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, √® possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le propriet√† degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all‚Äôinterno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.2 Appartenenza ad un insieme",
    "text": "I.2 Appartenenza ad un insieme\nUsiamo ora Python.\n\nSet1 = {1, 2}\nprint(Set1)\nprint(type(Set1))\n\n{1, 2}\n&lt;class 'set'&gt;\n\n\n\nmy_list = [1, 2, 3, 4]\nmy_set_from_list = set(my_list)\nprint(my_set_from_list)\n\n{1, 2, 3, 4}\n\n\nL‚Äôappartenenza ad un insieme si verifica con in e not in.\n\nmy_set = set([1, 3, 5])\nprint(\"Ecco il mio insieme:\", my_set)\nprint(\"1 appartiene all'insieme:\", 1 in my_set)\nprint(\"2 non appartiene all'insieme:\", 2 in my_set)\nprint(\"4 NON appartiene all'insieme:\", 4 not in my_set)\n\nEcco il mio insieme: {1, 3, 5}\n1 appartiene all'insieme: True\n2 non appartiene all'insieme: False\n4 NON appartiene all'insieme: True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.3 Relazioni tra insiemi",
    "text": "I.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l‚Äôinsieme universo e l‚Äôinsieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv = set([x for x in range(11)])\nSuper = set([x for x in range(11) if x % 2 == 0])\nDisj = set([x for x in range(11) if x % 2 == 1])\nSub = set([4, 6])\nNull = set([x for x in range(11) if x &gt; 10])\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\", Univ)\nprint(\"Tutti gli interi positivi pari fino a 10:\", Super)\nprint(\"Tutti gli interi positivi dispari fino a 10:\", Disj)\nprint(\"Insieme di due elementi, 4 e 6:\", Sub)\nprint(\"Un isieme vuoto:\", Null)\n\nInsieme Universo (tutti gli interi positivi fino a 10): {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\nTutti gli interi positivi pari fino a 10: {0, 2, 4, 6, 8, 10}\nTutti gli interi positivi dispari fino a 10: {1, 3, 5, 7, 9}\nInsieme di due elementi, 4 e 6: {4, 6}\nUn isieme vuoto: set()\n\n\n\nprint('√à \"Super\" un sovrainsieme di \"Sub\"?', Super.issuperset(Sub))\nprint('√à \"Super\" un sottoinsieme di \"Univ\"?', Super.issubset(Univ))\nprint('√à \"Sub\" un sovrainsieme di \"Super\"?', Sub.issuperset(Super))\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?', Sub.isdisjoint(Disj))\n\n√à \"Super\" un sovrainsieme di \"Sub\"? True\n√à \"Super\" un sottoinsieme di \"Univ\"? True\n√à \"Sub\" un sovrainsieme di \"Super\"? False\nSono \"Super\" e \"Disj\" insiemi disgiunti? True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.4 Operazioni tra insiemi",
    "text": "I.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cio√®\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l‚Äôinsieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l‚Äôinsieme differenza \\(A \\setminus B\\) √® detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) √® una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare √® data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) √® la regione delimitata dal rettangolo, \\(L\\) √® la regione all‚Äôinterno del cerchio di sinistra e \\(R\\) √® la regione all‚Äôinterno del cerchio di destra. La regione evidenziata mostra l‚Äôinsieme indicato sotto ciascuna figura.\n\n\n\nDiagrammi di Venn\n\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\n\nLeggi di DeMorgan\n\n\nVediamo ora come si eseguono le operazioni tra insiemi con Python.\nEguaglianza e differenza.\n\nS1 = {1, 2}\nS2 = {2, 2, 1, 1, 2}\nprint(\n    \"S1 e S2 sono uguali perch√© l'ordine o la ripetizione di elementi non importano per gli insiemi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 sono uguali perch√© l'ordine o la ripetizione di elementi non importano per gli insiemi\nS1==S2: True\n\n\n\nS1 = {1, 2, 3, 4, 5, 6}\nS2 = {1, 2, 3, 4, 0, 6}\nprint(\n    \"S1 e S2 NON sono uguali perch√© si differenziano per almeno uno dei loro elementi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 NON sono uguali perch√© si differenziano per almeno uno dei loro elementi\nS1==S2: False\n\n\nIntersezione. Si noti che il connettivo logico & corrisponde all‚Äôintersezione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\n\nS1: {9, 3, 6}\n\n\n\nS2 = set([x for x in range(1, 7)])\nprint(\"S2:\", S2)\n\nS2: {1, 2, 3, 4, 5, 6}\n\n\n\nS_intersection = S1.intersection(S2)\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nS_intersection = S1 & S2\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\n\n\n\nS3 = set([x for x in range(6, 10)])\nprint(\"S3:\", S3)\nS1_S2_S3 = S1.intersection(S2).intersection(S3)\nprint(\"Intersection of S1, S2, and S3:\", S1_S2_S3)\n\nS3: {8, 9, 6, 7}\nIntersection of S1, S2, and S3: {6}\n\n\nUnione. Si noti che il connettivo logico | corrisponde all‚Äôunione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\nS2 = set([x for x in range(1, 5)])\nprint(\"S2:\", S2)\n\nS_union = S1.union(S2)\nprint(\"Unione di S1 e S2:\", S_union)\nS_union = S1 | S2\nprint(\"Unione di S1 e S2:\", S_union)\n\nS1: {9, 3, 6}\nS2: {1, 2, 3, 4}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\n\n\nInsieme complementare.\n\nS = set([x for x in range(21) if x % 2 == 0])\nprint(\"S √® l'insieme dei numeri interi pari tra 0 e 20:\", S)\n\nS √® l'insieme dei numeri interi pari tra 0 e 20: {0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20}\n\n\n\nS_complement = set([x for x in range(21) if x % 2 != 0])\nprint(\"S_complement √® l'insieme dei numeri interi dispari tra 0 e 20:\", S_complement)\n\nS_complement √® l'insieme dei numeri interi dispari tra 0 e 20: {1, 3, 5, 7, 9, 11, 13, 15, 17, 19}\n\n\n\nprint(\n    \"√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\",\n    S.union(S_complement) == set([x for x in range(21)]),\n)\n\n√à l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20? True\n\n\nDifferenza tra insiemi.\n\nS1 = set([x for x in range(31) if x % 3 == 0])\nprint(\"Set S1:\", S1)\n\nSet S1: {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\n\n\n\nS2 = set([x for x in range(31) if x % 5 == 0])\nprint(\"Set S2:\", S2)\n\nSet S2: {0, 5, 10, 15, 20, 25, 30}\n\n\n\nS_difference = S2 - S1\nprint(\"Differenza tra S2 e S1, i.e. S2\\S1:\", S_difference)\n\nS_difference = S1.difference(S2)\nprint(\"Differenza tra S1 e S2, i.e. S1\\S2:\", S_difference)\n\nDifferenza tra S1 e S2 i.e. S2\\S1: {25, 10, 20, 5}\nDifferenza tra S2 e S1 i.e. S1\\S2: {3, 6, 9, 12, 18, 21, 24, 27}\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Œî, √® un‚Äôoperazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all‚Äôunione tra i due insiemi meno la loro intersezione.\n\nprint(\"S1\", S1)\nprint(\"S2\", S2)\nprint(\"Differenza simmetrica\", S1 ^ S2)\nprint(\"Differenza simmetrica\", S2.symmetric_difference(S1))\n\nS1 {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\nS2 {0, 5, 10, 15, 20, 25, 30}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice I ‚Äî Insiemi",
    "section": "I.5 Coppie ordinate e prodotto cartesiano",
    "text": "I.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) √® l‚Äôinsieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) √® la prima componente (o prima coordinata) e \\(y\\) la seconda. L‚Äôinsieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPi√π in generale, un prodotto cartesiano di \\(n\\) insiemi pu√≤ essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento √® una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non √® dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento √® possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all‚Äôn-esimo. Il prodotto cartesiano prende il nome da Ren√© Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA = set([\"a\", \"b\", \"c\"])\nS = {1, 2, 3}\n\n\ndef cartesian_product(S1, S2):\n    result = set()\n    for i in S1:\n        for j in S2:\n            result.add(tuple([i, j]))\n    return result\n\n\nC = cartesian_product(A, S)\nprint(f\"Prodotto cartesiano di A e S\\n{A} x {S} = {C}\")\n\nProdotto cartesiano di A e S\n{'Head', 'Tail'} x {1, 2, 3} = {('Tail', 1), ('Head', 2), ('Head', 1), ('Tail', 3), ('Tail', 2), ('Head', 3)}\n\n\nSi definisce cardinalit√† (o potenza) di un insieme finito il numero degli elementi dell‚Äôinsieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalit√† dell'insieme prodotto cartesiano √®:\", len(C))\n\nLa cardinalit√† dell'insieme prodotto cartesiano √®: 9\n\n\nInvece di scrivere funzioni noi stessi, √® possibile usare la libreria itertools di Python. Si ricordi di trasformare l‚Äôoggetto risultante in una lista per la visualizzazione e la successiva elaborazione.\n\nfrom itertools import product as prod\n\n\nA = set([x for x in range(1, 7)])\nB = set([x for x in range(1, 7)])\np = list(prod(A, B))\n\nprint(\"A √® l'insieme di tutti i possibili lanci di un dado:\", A)\nprint(\"B √® l'insieme di tutti i possibili lanci di un dado:\", B)\nprint(\n    \"\\nIl prodotto di A e B √® l'insieme dei risultati che si possono ottenere lanciando due dadi:\\n\",\n    p,\n)\n\nA √® l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\nB √® l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\n\nIl prodotto di A e B √® l'insieme dei risultati che si possono ottenere lanciando due dadi:\n [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\nLa cardinalit√† (cio√® il numero di elementi) del prodotto cartesiano tra due o pi√π insiemi √® uguale al prodotto delle cardinalit√† degli insiemi considerati: card(A √ó B) = card(A) ¬∑ card(B).\nUsando itertools √® facile calcolare la cardinalit√† del prodotto cartesiano di un insieme per se stesso. Consideriamo il quadrato dell‚Äôinsieme costituito dai risultati del lancio di una moneta. L‚Äôinsieme risultante avr√† cardinalit√† \\(2 \\cdot 2 = 4\\).\n\nA = {\"Head\", \"Tail\"} \np2 = list(prod(A, repeat=2))  \nprint(f\"Il quadrato dell'insieme A √® un insieme che contiene {len(p2)} elementi: {p2}\")\n\nIl quadrato dell'insieme A √® un insieme che contiene 4 elementi: [('Head', 'Head'), ('Head', 'Tail'), ('Tail', 'Head'), ('Tail', 'Tail')]\n\n\nL‚Äôinsieme \\(A\\) elevato alla terza potenza produce un insieme la cui cardinalit√† √®\n\np3 = list(prod(A, repeat=3))  \nprint(f\"L'insieme A elevato alla terza potenza √® costituito da {len(p3)} elementi: {p3}\")\n\nL'insieme A elevato alla terza potenza √® costituito da 8 elementi: [('Head', 'Head', 'Head'), ('Head', 'Head', 'Tail'), ('Head', 'Tail', 'Head'), ('Head', 'Tail', 'Tail'), ('Tail', 'Head', 'Head'), ('Tail', 'Head', 'Tail'), ('Tail', 'Tail', 'Head'), ('Tail', 'Tail', 'Tail')]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>¬† <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "",
    "text": "J.1 Principio del prodotto\nI metodi di base del calcolo combinatorio applicano due principi: la regola del prodotto e la regola della somma. Consideriamo il principio del prodotto.\nIn generale, una scelta pu√≤ essere effettuata in pi√π fasi, ad esempio \\(k\\). Supponiamo che per ogni \\(i = 1, \\dots, k\\) la scelta da compiere al \\(i\\)-esimo stadio possa essere effettuata in \\(n_i\\) modi. Secondo il principio del prodotto, il numero totale di possibili scelte √® dato dal prodotto dei singoli numeri, ovvero:\n\\[\nn_{\\text{tot}} = n_1 \\cdot  n_2 \\cdots n_{k-1} \\cdot n_k.\n\\]\nEsempio 1. Ho a disposizione 2 paia di scarpe, 3 paia di pantaloni e 5 magliette. In quanti modi diversi mi posso vestire?\n\\[\n2 \\cdot 3 \\cdot 5 = 30\n\\]\nEsempio 2. In Minnesota le targhe delle automobili sono costituite da tre lettere (da A a Z) seguite da tre numeri (da 0 a 9). Qual √® la proporzione di targhe che iniziano con GZN?\nLa soluzione √® data dal numero di targhe che iniziano con GZN diviso per il numero totale di targhe possibili.\nIl numero totale di targe √® \\(26 \\cdot 26 \\cdot 26 \\cdot 10 \\cdot 10 \\cdot 10 = 17,576,000\\). Per calcolare il numero di targhe che iniziano con GZN, consideriamo le targhe che hanno la forma GZN _ _ _. Per i tre simboli mancanti ci sono \\(10 \\cdot 10 \\cdot 10\\) possibilit√†. Dunque la proporzione cercata √®\n\\[\n10^3/(26^3 \\cdot 10^3) = 1/26^3 = 0.0000569.\n\\]\n10**3 / (26**3 * 10**3)\n\n5.689576695493855e-05",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.2 Principio della somma",
    "text": "J.2 Principio della somma\nIl principio della somma afferma che se un insieme pu√≤ essere suddiviso in due o pi√π sottoinsiemi disgiunti, allora il numero totale di elementi nell‚Äôinsieme √® dato dalla somma dei numeri di elementi in ciascun sottoinsieme.\nIn altre parole, se si vuole determinare il numero totale di modi in cui √® possibile realizzare un certo evento, e questo evento pu√≤ essere realizzato in modo esclusivo in modo A oppure B, allora il numero totale di modi in cui √® possibile realizzare l‚Äôevento √® dato dalla somma dei modi in cui pu√≤ essere realizzato in modo A e dei modi in cui pu√≤ essere realizzato in modo B.\nAd esempio, se si vuole determinare il numero totale di modi in cui √® possibile scegliere un dolce da una tavola con due tipi di dolci (ad esempio torta e biscotti), il principio della somma afferma che il numero totale di modi √® dato dalla somma del numero di modi in cui √® possibile scegliere la torta e del numero di modi in cui √® possibile scegliere i biscotti.\nEsempio 3. L‚Äôurna \\(A\\) contiene \\(5\\) palline numerate da \\(1\\) a \\(5\\), l‚Äôurna \\(B\\) contiene \\(6\\) palline numerate da \\(6\\) a \\(11\\), l‚Äôurna \\(C\\) contiene \\(3\\) palline numerate da \\(12\\) a \\(14\\) e l‚Äôurna \\(D\\) contiene \\(2\\) palline numerate \\(15\\) e \\(16\\). Quanti insiemi composti da due palline, ciascuna estratta da un‚Äôurna differente, si possono formare?\nIl numero di insiemi di tipo \\(AB\\) √® dato dal prodotto delle palline che possono essere estratte dall‚Äôurna \\(A\\) (5) e da quelle che possono essere estratte dall‚Äôurna \\(B\\) (6), ovvero \\(5 \\cdot 6 = 30\\). In modo analogo, si ottengono 15 insiemi di tipo \\(AC\\), 10 di tipo \\(AD\\), 18 di tipo \\(BC\\), 12 di tipo \\(BD\\), 6 di tipo \\(CD\\). Quindi, per la regola della somma, il numero totale di insiemi distinti che si possono formare con due palline provenienti dalle quattro urne √® dato dalla somma di questi valori, ovvero \\(30 + 15 + 10 + 18 + 12 + 6 = 91\\). Pertanto, ci sono 91 insiemi composti da due palline, ciascuna estratta da un‚Äôurna differente, che si possono formare.\nIn conclusione, il principio del prodotto e il principio della somma sono due concetti fondamentali del calcolo combinatorio. In generale, il principio del prodotto si applica quando si tratta di eventi indipendenti che si verificano in successione, mentre il principio della somma si applica quando si tratta di eventi mutuamente esclusivi (cio√® non possono accadere contemporaneamente) e si cerca di calcolare il numero totale di possibili risultati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.3 Il modello dell‚Äôurna",
    "text": "J.3 Il modello dell‚Äôurna\nI problemi di combinatoria spesso coinvolgono l‚Äôestrazione di palline da urne, le quali rappresentano dei modelli delle corrispondenti situazioni considerate. Una procedura comune per rappresentare queste situazioni √® il modello dell‚Äôurna, che consiste nell‚Äôestrazione di \\(k\\) palline da un‚Äôurna contenente \\(n\\) palline. Le palline possono essere tutte diverse, oppure alcune palline possono essere indistinguibili tra loro. Tra le possibili modalit√† di estrazione, sono particolarmente importanti:\n\nL‚Äôestrazione Bernoulliana di \\(k\\) palline, che si ottiene estraendo una pallina alla volta e rimettendola nell‚Äôurna dopo ogni estrazione;\nL‚Äôestrazione senza ripetizione di \\(k\\) palline, che si ottiene estraendo una pallina alla volta senza rimetterla nell‚Äôurna dopo l‚Äôestrazione;\nL‚Äôestrazione in blocco di \\(k\\) palline, che si ottiene estraendo \\(k\\) palline contemporaneamente.\n\nPer esempio, nel caso di campioni di ampiezza 2 estratti da un‚Äôurna con tre elementi \\(\\{1, 2, 3\\}\\), abbiamo i seguenti quattro casi:\n\ncampionamento con reimmissione tenendo conto dell‚Äôordine di estrazione: \\(\\{1,  1\\}, \\{2,  1\\}, \\{3,  1\\}, \\{1,  2\\}, \\{2,  2\\}, \\{3,  2\\}, \\{1,  3\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento con reimmissione senza tenere conto dell‚Äôordine di estrazione: \\(\\{1,  1\\}, \\{1,  2\\}, \\{1,  3\\}, \\{2,  2\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento senza reimmissione tenendo conto dell‚Äôordine di estrazione: \\(\\{1,  2\\}, \\{2,  1\\}, \\{1,  3\\}, \\{3,  1\\}, \\{2,  3\\}, \\{3,  2\\}\\);\ncampionamento senza reimmissione e senza tenere conto dell‚Äôordine di estrazione: \\(\\{1 , 2\\}, \\{1,  3\\}, \\{2, 3\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-semplici",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.4 Permutazioni semplici",
    "text": "J.4 Permutazioni semplici\nLe permutazioni semplici sono il risultato di uno scambio dell‚Äôordine degli elementi di un insieme che contiene elementi distinti tra loro. Queste permutazioni sono indicate con il simbolo \\(P_n\\), e il numero di permutazioni semplici di \\(n\\) elementi distinti √® pari al fattoriale di \\(n\\), cio√® \\(n!\\), come espresso dall‚Äôeq. {eq}eq-permsem:\n\\[\nP_n = n!\n\\] (eq-permsem)\ndove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed √® uguale al prodotto di \\(n\\) numeri interi decrescenti da \\(n\\) fino a 1. Per definizione, il fattoriale di 0 √® 1.\nIl numero di permutazioni di \\(n\\) elementi distinti pu√≤ essere visto come l‚Äôestrazione senza rimessa di \\(n\\) elementi diversi da un‚Äôurna contenente gli \\(n\\) oggetti. Questo ci consente di applicare il principio del prodotto, il quale afferma che il numero di modi in cui √® possibile combinare o disporre un insieme di oggetti √® dato dal prodotto del numero di scelte possibili per ciascuna categoria di oggetti. Nel caso delle permutazioni, il principio del prodotto si applica nel seguente modo: se abbiamo \\(n\\) oggetti distinti da disporre in un ordine particolare, il numero di permutazioni possibili √® dato dal prodotto del numero di scelte possibili per la prima posizione, per la seconda posizione, per la terza posizione, e cos√¨ via, fino alla \\(n\\)-esima posizione.\nPer esempio, consideriamo il caso di disporre tre oggetti, A, B e C. Ci sono tre modi per scegliere il primo oggetto: A, B o C. Una volta scelto il primo oggetto, ci sono due modi per scegliere il secondo oggetto. Infine, rimane un solo modo per scegliere l‚Äôultimo oggetto. Possiamo concettualizzare questo processo come un albero, dove il numero totale di foglie √® uguale al numero di permutazioni. Per calcolare il numero di foglie, basta moltiplicare sequenzialmente il numero di rami a ogni livello, cio√® \\(3 \\times 2 \\times 1\\).\nEsempio 4. Consideriamo l‚Äôinsieme: \\(A = \\{a, b, c\\}\\). Calcoliamo il numero di permutazioni semplici.\nLe permutazioni semplici di \\(A\\) sono: \\(\\{a, b, c\\}\\), \\(\\{a, c, b\\}\\), \\(\\{b, c, a\\}\\), \\(\\{b, a, c\\}\\), \\(\\{c, a, b\\}\\), \\(\\{c, b, a\\}\\), ovvero 6. Applichiamo l‚Äôeq. {ref}eq-permsem:\n\\[\nP_n = P_3 = 3! = 3 \\cdot 2 \\cdot 1 = 6.\n\\]\nLo strumento principale che usiamo in Python per trovare le permutazioni di un insieme √® una libreria specificamente progettata per iterare sugli oggetti in modi diversi, ovvero itertools. Con itertools.permutations() generiamo le permutazioni.\n\nA = {\"A\", \"B\", \"C\"}\nprint(A)\n\n{'A', 'B', 'C'}\n\n\n\npermutations = it.permutations(A)\n\nPer visualizzare il risultato dobbiamo trasformarlo in una tupla:\n\ntuple(permutations)\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nLo stesso risultato si ottiene con\n\npermutations = it.permutations(\"ABC\")\npermutations = tuple(permutations)\npermutations\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nPossiamo ora contare quanti elementi ci sono nella tupla usando la funzione len():\n\nlen(permutations)\n\n6\n\n\nOppure, possiamo appliare la formula {eq}eq-permsem mediante la funzione factorial() contenuta nella libreria math di Numpy:\n\nmath.factorial(3)\n\n6\n\n\nEsempio 5. Gli anagrammi sono le permutazioni che si ottengono da una parola variando l‚Äôordine delle lettere. Le permutazioni semplici si applicano al caso di parole costituite da lettere tutte diverse tra loro. Ad esempio, con la parola NUMERO si ottengono \\(P_6 = 6! = 6\\cdot5\\cdot4\\cdot3\\cdot2\\cdot1 = 720\\) anagrammi.\n\npermutations = it.permutations(\"NUMERO\")\npermutations = tuple(permutations)\npermutations[1:10]\n\n(('N', 'U', 'M', 'E', 'O', 'R'),\n ('N', 'U', 'M', 'R', 'E', 'O'),\n ('N', 'U', 'M', 'R', 'O', 'E'),\n ('N', 'U', 'M', 'O', 'E', 'R'),\n ('N', 'U', 'M', 'O', 'R', 'E'),\n ('N', 'U', 'E', 'M', 'R', 'O'),\n ('N', 'U', 'E', 'M', 'O', 'R'),\n ('N', 'U', 'E', 'R', 'M', 'O'),\n ('N', 'U', 'E', 'R', 'O', 'M'))\n\n\n\nlen(permutations)\n\n720\n\n\n\nmath.factorial(6)\n\n720\n\n\nEsempio 6. Un altro esempio riguarda i giochi di carte. Ci sono 52! \\(\\approx 8 \\times 10^{67}\\) modi di ordinare un mazzo di carte da poker; questo numero √® ‚Äúquasi‚Äù grande come il numero di atomi dell‚Äôuniverso che si stima essere uguale a circa \\(10^{80}\\).\n\nmath.factorial(52)\n\n80658175170943878571660636856403766975289505440883277824000000000000\n\n\n\nprint(\"{:.2e}\".format(math.factorial(52)))\n\n8.07e+67\n\n\nEsempio 7. Le cifre 1, 2, 3, 4 e 5 sono disposte in ordine casuale per formare un numero di cinque cifre.\n\nQuanti diversi numeri di cinque cifre possono essere formati?\nQuanti diversi numeri di cinque cifre sono dispari?\n\nIniziamo a creare una tupla con le cinque cifre:\n\ntuple(range(1, 6))\n\n(1, 2, 3, 4, 5)\n\n\nCome in precedenza, possiamo usare it.permutations():\n\npermutations = it.permutations(range(1, 6))\npermutations = tuple(permutations)\npermutations[1:10]\n\n((1, 2, 3, 5, 4),\n (1, 2, 4, 3, 5),\n (1, 2, 4, 5, 3),\n (1, 2, 5, 3, 4),\n (1, 2, 5, 4, 3),\n (1, 3, 2, 4, 5),\n (1, 3, 2, 5, 4),\n (1, 3, 4, 2, 5),\n (1, 3, 4, 5, 2))\n\n\nCi sono 120 permutazioni.\n\nlen(permutations)\n\n120\n\n\nPer trovare i numeri dispari tra queste 120 permutazioni utilizziamo la funzione sum() in Python abbinato alle espressioni for e in. Accediamo al quinto elemento di una permutazione utilizzando la notazione [4] (il primo elemento √® indicato con 0, quindi il quinto √® 4):\n\nsum(permutation[4] % 2 for permutation in permutations)\n\n72\n\n\nPossiamo controllare questo teoricamente: nel caso presente, ci sono tre possibili cifre dispari per l‚Äôultima posizione di un numero di cinque cifre: 1, 3 e 5. Dopo aver scelto una di queste, le cifre rimanenti nelle prime quattro posizioni possono essere formate in 4! modi. Pertanto:\n\nmath.factorial(4) * 3\n\n72",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-semplici",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.5 Disposizioni semplici",
    "text": "J.5 Disposizioni semplici\nLe disposizioni semplici rappresentano tutti i modi in cui un insieme di oggetti pu√≤ essere disposto in sequenza, tenendo conto dell‚Äôordine in cui gli oggetti vengono scelti e senza permettere la scelta di un oggetto pi√π di una volta.\nQuindi, se abbiamo un insieme di \\(n\\) oggetti distinti e vogliamo selezionarne \\(k\\) per formare una sequenza, le disposizioni semplici rappresentano tutti i sottoinsiemi di \\(k\\) oggetti distinti che possono essere selezionati dall‚Äôinsieme di \\(n\\) oggetti distinti in modo tale che l‚Äôordine in cui vengono selezionati sia importante.\nAd esempio, se abbiamo l‚Äôinsieme di oggetti \\({a,b,c}\\) e vogliamo selezionare due oggetti per formare una sequenza, le disposizioni semplici sarebbero: \\(ab\\), \\(ba\\), \\(ac\\), \\(ca\\), \\(bc\\), \\(cb\\). Nota che, in questo caso, l‚Äôordine in cui gli oggetti vengono scelti √® importante e ogni oggetto viene scelto una sola volta.\nIl numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) √® indicato con \\(D_{n,k}\\) e pu√≤ essere calcolato dividendo il numero di permutazioni di \\(n\\) oggetti distinti per il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti, poich√© ogni disposizione semplice pu√≤ essere ottenuta come una permutazione di un sottoinsieme di \\(k\\) oggetti distinti.\nQuindi, il numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) √® dato da\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!},\n\\] (eq_disp_simple)\ndove \\(n!\\) rappresenta il numero di permutazioni di \\(n\\) oggetti distinti e \\((n-k)!\\) rappresenta il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti.\nEsempio 8. Consideriamo l‚Äôinsieme: \\(A = \\{a, b, c\\}\\). Qual √® il numero di disposizioni semplici di classe 2? Come abbiamo visto sopra, le disposizioni semplici di classe 2 sono \\(\\{a, b\\}\\), \\(\\{b, a\\}\\), \\(\\{a, c\\}\\), \\(\\{c, a\\}\\), \\(\\{b, c\\}\\), \\(\\{c, b\\}\\), ovvero 6.\nApplichiamo l‚Äôeq. {eq}eq_disp_simple:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} = 3 \\cdot 2 = 6.\n\\]\nIn maniera equivalente possiamo trovare il risultato usando itertools.permutations(iterable, k). Tale istruzione ci consente di trovare il numero di permutazioni possibili di tutti i sottoinsiemi di \\(k\\) elementi distinti, ovvero il numero di diverse sequenze ordinate che possiamo ottenere scegliendo \\(k\\) oggetti dall‚Äôinsieme.\n\ntuple(it.permutations(\"ABC\", 2))\n\n(('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B'))\n\n\n\nres = tuple(it.permutations(\"ABC\", 2))\nlen(res)\n\n6\n\n\nOppure possiamo implementare l‚Äôeq. {eq}eq_disp_simple:\n\ndef simple_disp(n, k):\n    return math.factorial(n) / math.factorial(n - k)\n\n\nsimple_disp(3, 2)\n\n6.0",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sec-combinazione-semplice",
    "href": "chapters/appendix/a14_combinatorics.html#sec-combinazione-semplice",
    "title": "Appendice J ‚Äî Calcolo combinatorio",
    "section": "J.6 Combinazioni semplici",
    "text": "J.6 Combinazioni semplici\nLe combinazioni sono simili alle permutazioni, ma ignorano l‚Äôordine degli elementi. In altre parole, le combinazioni rappresentano i modi di scegliere \\(k\\) elementi distinti da\\(n\\)elementi senza considerare l‚Äôordine. Ad esempio, scegliendo 2 elementi da 3 (A, B e C), le permutazioni sono 6 (AB, BA, AC, CA, BC, CB), mentre le combinazioni sono 3 (AB, AC, BC).\nPer calcolare le combinazioni, prima calcoliamo le permutazioni \\(D_{n,k}\\) e poi dividiamo per \\(k!\\). Questo perch√© ci sono \\(k!\\) modi per disporre \\(k\\) elementi in ordine diverso, ma tutte queste disposizioni contano come una singola combinazione. La formula generale per le combinazioni √®:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{D_{n,k}}{P_k} = \\frac{n!}{k!(n-k)!},\n\\] (eq_combsemp)\nche √® spesso indicata con il simbolo \\(\\binom{n}{k}\\) e viene chiamato ‚Äúcoefficiente binomiale‚Äù. In sintesi, le combinazioni semplici rappresentano il numero di sottoinsiemi di \\(k\\) elementi distinti scelti da un insieme di \\(n\\) elementi distinti senza considerare l‚Äôordine di estrazione.\nEsempio 9. Per l‚Äôinsieme \\(A = \\{a, b, c\\}\\) si trovino le combinazioni semplici di classe 2.\nLe combinazioni semplici dell‚Äôinsieme \\(A\\) sono \\(\\{a, b\\}\\), \\(\\{a, c\\}\\), \\(\\{b, c\\}\\), ovvero 3. Applichiamo l‚Äôeq. {eq}eq_combsemp:\n\\[\nC_{n,k} = \\binom{n}{k} = \\binom{3}{2} = 3.\n\\]\nUsiamo itertools:\n\nc_nk = tuple(it.combinations(\"ABC\", 2))\nc_nk\n\n(('A', 'B'), ('A', 'C'), ('B', 'C'))\n\n\n\nlen(c_nk)\n\n3\n\n\nLa soluzione si trova anche usando la funzione comb() della libreria math.\n\nmath.comb(3, 2)\n\n3\n\n\nOppure usando la funzione comb() della libreria scipy.special.\n\nimport scipy.special as sp\n\nsp.comb(3, 2)\n\n3.0\n\n\nEsempio 10. Quanti gruppi di 2 si possono formare con 5 individui?\n\nc_nk = tuple(it.combinations(range(5), 2))\nc_nk\n\n((0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (1, 2),\n (1, 3),\n (1, 4),\n (2, 3),\n (2, 4),\n (3, 4))\n\n\n\nlen(c_nk)\n\n10\n\n\novvero\n\nmath.comb(5, 2)\n\n10\n\n\nEsempio 11. Ho un‚Äôassociazione con 50 soci. Devo scegliere 5 membri che compongano il comitato direttivo. Quante possibili scelte?\n\nmath.comb(50, 5)\n\n2118760\n\n\nEsempio 12. Una gelateria offre 15 gusti di gelato differenti. Quante coppe diverse posso formare se ognuna contiene 3 gusti di gelato differenti tra loro?\n\nmath.comb(15, 3)\n\n455\n\n\nEsempio 13. Uno studente deve rispondere a 5 domande su 10. Solo 5 su 10. Quante possibili scelte ha?\n\nmath.comb(10, 5)\n\n252\n\n\nEsempio 14. Consideriamo un incidente del 2009 quando il Governatore della California Arnold Schwarzenegger invi√≤ un messaggio all‚Äôassemblea statale riguardo il veto al disegno di legge 1176. Questo messaggio formava un acrostico volgare con le prime lettere di ogni riga.\n\n\n\n\n\n\nFigura¬†J.1\n\n\n\nCi possiamo chiedere quale sia la probabilit√† che questo acrostico sia stato casuale. Per rispondere a questa domanda, calcoliamo le combinazioni di due diversi eventi.\nIl messaggio di Arnold Schwarzenegger √® composto da 85 parole. Supponiamo che il messaggio sia stato diviso in 7 righe in modo casuale. Per creare 7 righe, dobbiamo inserire 6 interruzioni di riga. Queste interruzioni di riga possono essere inserite in qualsiasi posizione tra le parole.\nPoich√© ci sono 85 parole, ci sono 84 spazi tra le parole (prima della seconda parola, terza parola, e cos√¨ via). Il numero di modi in cui possiamo inserire 6 interruzioni di riga in 84 spazi √® dato dalla combinazione:\n\\[\n\\binom{84}{6} = \\frac{84!}{6!(78!)} \\approx 406,481,544.\n\\]\nCalcoliamo ora il numero di modi in cui questo particolare acrostico pu√≤ essere ottenuto.\nSupponiamo che l‚Äôacrostico ‚ÄúFUCKYOU‚Äù possa essere formato solo in un numero limitato di combinazioni specifiche. Per calcolare queste combinazioni, dobbiamo considerare le parole che iniziano con ciascuna delle lettere dell‚Äôacrostico e le posizioni in cui possono essere inserite le interruzioni di riga.\n\nIdentificazione delle parole chiave:\n\nF: ‚ÄúFor‚Äù\nU: ‚Äúunnecessary‚Äù\nC: ‚Äúconversation‚Äù\nK: ‚Äúkeeping‚Äù\nY: ‚Äúyou‚Äù\nO: ‚Äúover‚Äù\nU: ‚Äúuntil‚Äù\n\nDeterminazione delle possibili interruzioni di riga: Per formare l‚Äôacrostico, dobbiamo posizionare le interruzioni di riga in modo che le parole chiave siano all‚Äôinizio delle righe. Le interruzioni possono essere inserite tra le parole chiave, con un certo numero di parole tra di esse.\nConteggio delle combinazioni:\n\nTra ‚ÄúFor‚Äù e ‚Äúunnecessary‚Äù: 11 possibilit√†\nTra ‚Äúunnecessary‚Äù e ‚Äúconversation‚Äù: 3 possibilit√†\nTra ‚Äúconversation‚Äù e ‚Äúkeeping‚Äù: 9 possibilit√†\nTra ‚Äúkeeping‚Äù e ‚Äúyou‚Äù: 2 possibilit√†\nTra ‚Äúyou‚Äù e ‚Äúover‚Äù: 2 possibilit√†\nTra ‚Äúover‚Äù e ‚Äúuntil‚Äù: 1 possibilit√†\n\nQuindi, il numero totale di combinazioni √®:\n\\[\n11 \\times 3 \\times 9 \\times 2 \\times 2 \\times 1 = 1,188.\n\\]\n\nIn conclusione, la probabilit√† che l‚Äôacrostico volgare si verifichi casualmente √® data dal rapporto tra il numero di combinazioni specifiche che formano l‚Äôacrostico (1,188) e il numero totale di modi per inserire 6 interruzioni di riga in 84 spazi (406,481,544):\n\\[\n\\frac{1,188}{406,481,544} \\approx 2.92 \\times 10^{-6} \\approx 1 \\text{ su } 342,000.\n\\]\nQuesta analisi ci mostra che √® estremamente improbabile che l‚Äôacrostico volgare sia stato il risultato di una divisione casuale delle righe del messaggio. In altre parole, la probabilit√† che questo acrostico sia stato generato casualmente √® trascurabile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>¬† <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice K ‚Äî Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "K.1 Introduzione ai logaritmi\nAggiungo alcune nozioni di base sui logaritmi. Il logaritmo √® una funzione matematica che risponde alla domanda: ‚Äúquante volte devo moltiplicare un certo numero (chiamato‚Äùbase‚Äù) per ottenere un altro numero?‚Äù Matematicamente, questo √® espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perch√© \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano pi√π grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo √® utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio: - \\(\\log(1) = 0\\) - \\(\\log(0.1) = -1\\) - \\(\\log(0.01) = -2\\) - \\(\\log(0.001) = -3\\)\nCome si pu√≤ vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle propriet√† pi√π utili dei logaritmi √® che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta propriet√† √® estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilit√† potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn‚Äôaltra propriet√† utile dei logaritmi √® che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa propriet√† √® molto utilizzata in matematica, specialmente in situazioni in cui √® necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare pi√π agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli pi√π gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#watermark",
    "href": "chapters/appendix/a15_calculus.html#watermark",
    "title": "Appendice K ‚Äî Per liberarvi dai terrori preliminari",
    "section": "K.2 Watermark",
    "text": "K.2 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Feb 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\nnumpy     : 1.26.4\narviz     : 0.17.0\nscipy     : 1.12.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>¬† <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a20_kde_plot.html",
    "href": "chapters/appendix/a20_kde_plot.html",
    "title": "Appendice L ‚Äî Kernel Density Estimation",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport scipy.stats as st\nfrom scipy.constants import golden\nimport arviz as az\n\n\n%config InlineBackend.figure_format = 'retina'\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\naz.style.use(\"arviz-darkgrid\")\nsns.set_theme(palette=\"colorblind\")\n\nConsideriamo in maggiore dettaglio la procedura di costruzione di un Kernel Density plot.\nUn istogramma divide i dati in intervalli discreti, conta il numero di punti che rientrano in ciascun intervallo e visualizza i risultati in un modo intuitivo. Nell‚Äôistruzione seguente, se specifichiamo il parametro density=True, l‚Äôarea totale delle barre dell‚Äôistogramma diventa uguale a 1.\nPer fare un esempio, definisco una funzione che simula dei dati estratti da una distribuzione bimodale.\n\ndef make_data(N, f=0.3, rseed=1):\n    rand = np.random.RandomState(rseed)\n    x = rand.randn(N)\n    x[int(f * N) :] += 5\n    return x\n\n\nx = make_data(1000)\nhist = plt.hist(x, bins=30, density=True)\n\n\n\n\n\n\n\n\nGenero ora un numero pi√π piccolo di dati.\n\nx = make_data(20, f=0.3, rseed=10)\nx\n\narray([ 1.3315865 ,  0.71527897, -1.54540029, -0.00838385,  0.62133597,\n       -0.72008556,  5.26551159,  5.10854853,  5.00429143,  4.82539979,\n        5.43302619,  6.20303737,  4.03493433,  6.02827408,  5.22863013,\n        5.44513761,  3.86339779,  5.13513688,  6.484537  ,  3.92019511])\n\n\nIl primo dei due istrogrammi seguenti chiarisce che si tratta di una distribuzione bimodale. Quello successivo, invece, mostra una distribuzione unimodale con una lunga coda. Senza vedere il codice, probabilmente non ci verrebbe in mente che questi due istogrammi sono stati costruiti dagli stessi dati. Il problema degli istogrammi, infatti, √® che, a seconda della scelta dell‚Äôampiezza degli intervalli, il profilo dell‚Äôistogramma pu√≤ cambiare anche in maniera drastica. La domanda √®: come possiamo ottenere un risultato migliore?\n\nhist = plt.hist(x, bins=12, density=True)\nplt.plot(x, np.full_like(x, -0.01), \"|k\", markeredgewidth=1);\n\n\n\n\n\n\n\n\n\nhist = plt.hist(x, bins=4, density=True)\nplt.plot(x, np.full_like(x, -0.01), \"|k\", markeredgewidth=1);\n\n\n\n\n\n\n\n\nL‚Äôistogramma conta quante osservazioni sono contenute in ciascun intervallo. Il Kernel Density Plot (KDE) fa una cosa simile, ma sostituisce alle frequenze assolute (o relative) un metodo diverso. Immaginiamo di posizionare la curva densit√† di una distribuzione gaussiana (con un‚Äôopportuna deviazione standard) in corrispondenza di ciascun punto della distribuzione. I punti sono rappresentati, nelle figure precedenti dai ‚Äúticks‚Äù evidenziati sotto l‚Äôistogramma. Per ciascun valore dell‚Äôasse \\(X\\), le ordinate di queste funzioni di densit√† vengono sommate. I punti cos√¨ ottenuti sono congiunti da una curva. Il processo √® descritto nella cella seguente.\n\nx_d = np.linspace(-4, 8, 1000)\ndensity = sum(st.norm(xi).pdf(x_d) for xi in x)\ndensity[0:10]\n\narray([0.02160887, 0.02227584, 0.02296033, 0.02366267, 0.02438324,\n       0.02512238, 0.02588048, 0.02665789, 0.02745499, 0.02827215])\n\n\nIl risultato √® il cosiddetto KDE plot, ovvero un istogramma ‚Äúlisciato‚Äù.\n\nplt.fill_between(x_d, density, alpha=0.5)\nplt.plot(x, np.full_like(x, -0.1), \"|k\", markeredgewidth=1)\n\nplt.axis([-4, 8, -0.2, 5]);\n\n\n\n\n\n\n\n\nUn risultato equivalente si ottiene con la funzione kdeplot() di seaborn. Si noti l‚Äôargomento bw_adjust che determina la deviazione standard delle gaussiane che vengono sommate.\n\n_ = sns.kdeplot(x, bw_adjust=0.6);\n\n\n\n\n\n\n\n\nIn generale, questo tipo di rappresentazione di una distribuzione empirica di frequenza √® pi√π informativa di un istogramma.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>¬† <span class='chapter-title'>Kernel Density Estimation</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a30_prob_tutorial.html",
    "href": "chapters/appendix/a30_prob_tutorial.html",
    "title": "Appendice M ‚Äî Esercizi di probabilit√† discreta",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport math\nimport seaborn as sns\nfrom collections import defaultdict\nimport arviz as az\n\n\n%config InlineBackend.figure_format = 'retina'\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\naz.style.use(\"arviz-viridish\")\n\nConsidereremo qui alcuni esempi che illustrano come, generando delle liste che corrispondono a spazi campione ed eventi, sia possibile calcolare la probabilit√† associata agli eventi definiti sullo spazio campione di un esperimento casuale. In questo capitolo ci focalizzeremo su tre esperimenti casuali che producono uno spazio campione discreto: lancio di monete, lancio di dadi, estrazione di carte da un mazzo ben mescolato. Inizieremo ad esaminare il caso del lancio di uno o pi√π dadi e i giochi di carte. In seguito esamineremo delle funzioni specializzate che possono essere usate per modellare l‚Äôesperimento casuale corrispondene ad una serie di lanci di una moneta. Prima di fare questo, per√≤, esamineremo alcune funzioni Python utili per il calcolo delle probabilit√†.\nProbabilit√† di ottenere un numero minore di 4 dal lancio di un dado\nAbbiamo gi√† visto in precedenza come generare lo spazio campione dell‚Äôesperimento aleatorio che corrisponde al lancio di un dado equilibrato a 6 facce.\n\nsample = [dice1 for dice1 in range(1, 7)]\nlist(sample)\n\n[1, 2, 3, 4, 5, 6]\n\n\nSu tale spazio campione definiamo un evento.\n\nevent = [roll for roll in sample if roll &lt; 4]\nprint(list(event))\n\n[1, 2, 3]\n\n\nCalcoliamo la probabilit√† di osservare l‚Äôevento che abbiamo definito.\n\nprint(f\"La probabilit√† dell'evento √® {len(event)}/{len(sample)}.\")\n\nLa probabilit√† dell'evento √® 3/6.\n\n\nLa probabilit√† di ottenere almeno un 6 dal lancio di due dadi\nConsideriamo un caso un po‚Äô pi√π complesso, ma che abbiamo gi√† incontrato in precedenza. Iniziamo nuovamente a definire lo spazio campione dell‚Äôesperimento casuale. Si noti la sintassi della list comprehension.\n\nsample = [(dice1, dice2) for dice1 in range(1, 7) for dice2 in range(1, 7)]\nsample\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (2, 6),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (4, 6),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\nL‚Äôevento definito dal problema si verifica se √® vera la condizione roll[0] == 6 (si ottiene un 6 con il primo dado) oppure se si verifica la condizione roll[1] (si ottiene un 6 con il secondo dado), oppure se si verificano entrambe. Si noti il connettivo logico or.\n\nevent = [roll for roll in sample if roll[0] == 6 or roll[1] == 6]\nevent\n\n[(1, 6),\n (2, 6),\n (3, 6),\n (4, 6),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n11 / 36\n\n\nLa probabilit√† di non ottenere neppure un 6 dal lancio di due dadi\nLa soluzione di questo problema richiede che si neghino le due condizioni definite in precedenza.\n\nevent = [roll for roll in sample if roll[0] != 6 and roll[1] != 6]\nevent\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5)]\n\n\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n25 / 36\n\n\nIn maniera equivalente, la soluzione √® data dalla probabilit√† dell‚Äôevento complementare a quello definito dal problema precedente: 1 - 11/36.\nLa probabilit√† che lanciando contemporaneamente due dadi a 6 facce la somma faccia 4\nIn questo caso la condizione logica che viene definita nella list comprehension √® if sum(roll) == 4.\n\nevent = [roll for roll in sample if sum(roll) == 4]\nevent\n\n[(1, 3), (2, 2), (3, 1)]\n\n\nTroviamo la probabilit√†.\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n3 / 36\n\n\nLa probabilit√† che lanciando contemporaneamente tre dadi a 6 facce la somma faccia 10\nQuesto problema √® solo una variante del problema precedente. L‚Äôunica differenza di rilievo √® che dobbiamo costruire uno spazio campione corrispondente al prodotto cartesiano dell‚Äôinsieme dei punti di un dado elevato alla terza potenza.\n\nr = range(1, 7)\nsample = [(i, j, k) for i in r for j in r for k in r]\nevent = [roll for roll in sample if sum(roll) == 10]\nprint(event)\nprint(f\"{len(event)} / {len(sample)}\")\n\n[(1, 3, 6), (1, 4, 5), (1, 5, 4), (1, 6, 3), (2, 2, 6), (2, 3, 5), (2, 4, 4), (2, 5, 3), (2, 6, 2), (3, 1, 6), (3, 2, 5), (3, 3, 4), (3, 4, 3), (3, 5, 2), (3, 6, 1), (4, 1, 5), (4, 2, 4), (4, 3, 3), (4, 4, 2), (4, 5, 1), (5, 1, 4), (5, 2, 3), (5, 3, 2), (5, 4, 1), (6, 1, 3), (6, 2, 2), (6, 3, 1)]\n27 / 216\n\n\nLa probabilit√† che lanciando contemporaneamente quattro dadi a 6 facce la somma faccia 13\nLa struttura logica √® identica alla precedente, aumenta solo la dimensione dello spazio campione.\n\nr = range(1, 7)\nsample = [(i, j, k, l) for i in r for j in r for k in r for l in r]\nevent = [roll for roll in sample if sum(roll) == 13]\nprint(f\"{len(event)} / {len(sample)}\")\n\n140 / 1296\n\n\nLa probabilit√† di ottenere un 6 e un altro numero (diverso da 6) nel lancio di due dadi a 6 facce\nQuesto problema introduce un nuovo modo per valutare una condizione logica in riferimento allo spazio campione. Il problema dice che dobbiamo ottenere solo un 6, con il primo o con il secondo dado, ma non con entrambi. Dobbiamo dunque esaminare ciascun punto dello spazio campione (una tupla di due elementi) e verificare se contiene un solo 6. Per fare questo definiamo la funzione numsix() che prende come argomento una tupla e ritorna il numero di 6 che ha trovato. Avendo definito questa funzione, la applichiamo a tutti i punti dello spazio campione e estraiamo gli elementi nei quali la funzione ritorna 1 (ovvero, i punti campione nei quali c‚Äô√® un solo 6).\n\nsample = [(i, j) for i in r for j in r]\n\n\ndef numsix(roll):\n    return len([dice for dice in roll if dice == 6])\n\n\nevent = [roll for roll in sample if numsix(roll) == 1]\nprint(event)\n\n[(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n\n\nLa probabilit√† cercata √® dunque 10/36.\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n10 / 36\n\n\nLa probabilit√† di ottenere un 6 e un altro numero (diverso da 6) nel lancio di quattro dadi a 6 facce\nQuesto problema √® simile al precedente, ma considera uno spazio campione pi√π grande.\n\nsample = [(i, j, k, l) for i in r for j in r for k in r for l in r]\n\nevent = [roll for roll in sample if numsix(roll) == 1]\nprint(f\"{len(event)} / {len(sample)}\")\n\n500 / 1296\n\n\nLa probabilit√† di ottenere tre 6 e un altro numero (diverso da 6) nel lancio di quattro dadi a 6 facce\nQui cambia solo la quantificazione della condizione logica usata prima.\n\nevent = [roll for roll in sample if numsix(roll)==3]\nprint(f\"{len(event)} / {len(sample)}\")\n\n20 / 1296\n\n\nEsaminiamo ora alcuni esempio relativi ai giochi di carte. Per questi scopi abbiamo bisogno di generare degli spazi campione che corrispondono a selezioni di elementi nelle quali l‚Äôordine non conta e gli elementi non possono essere ripetuti. Questa √® la definizione di una combinazione semplice ‚Äì si veda la sezione {ref}combinazione-semplice-section. Importiamo la funzione combinations da itertools.\n\nfrom itertools import combinations, product\n\nPer chiarire la procedura, iniziamo a considerare un mazzo di carte molto piccolo, in cui abbiamo solo due semi e tre numeri. Generiamo il mazzo di carte.\n\ncards = list(product(range(1,3), range(1,4)))\ncards\n\n[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3)]\n\n\nDiciamo che il primo valore di ciascuna delle precedenti coppie di numeri corrisponde al seme e il secondo valore corrisponde al numero. Se vogliamo, possiamo immaginare cuori e picche con i numeri 1, 2, 3.\nIniziamo a chiederci quante mani di due carte siano possibili per questo mazzo di carte. Ci sono 15 possibilit√†. Usiamo la formula delle combinazioni semplici.\n\nmath.comb(6, 2)\n\n15\n\n\nElenchiamo tutte le possibili combinazioni semplici.\n\nsample = list(combinations(cards, 2))\nsample\n\n[((1, 1), (1, 2)),\n ((1, 1), (1, 3)),\n ((1, 1), (2, 1)),\n ((1, 1), (2, 2)),\n ((1, 1), (2, 3)),\n ((1, 2), (1, 3)),\n ((1, 2), (2, 1)),\n ((1, 2), (2, 2)),\n ((1, 2), (2, 3)),\n ((1, 3), (2, 1)),\n ((1, 3), (2, 2)),\n ((1, 3), (2, 3)),\n ((2, 1), (2, 2)),\n ((2, 1), (2, 3)),\n ((2, 2), (2, 3))]\n\n\n\nlen(sample)\n\n15\n\n\nChiediamoci ora quale sia la probabilit√† di una coppia di assi. Ovviamente nello spazio campione precedente c‚Äô√® solo un modo di ottenere una coppia di assi: ((1, 1), (2, 1)). Ma poniamoci il problema di trovare questa soluzione in maniera algoritmica.\n\ndef numval(hand, val):\n    return len([card for card in hand if card[1] == val])\n\n\ndef numace(hand):\n    return numval(hand, 1)\n\n\nevent = [hand for hand in sample if numace(hand) == 2]\nprint(f\"{len(event)} / {len(sample)}\")\n\n1 / 15\n\n\nLa probabilit√† di un pocker d‚Äôassi\nOra che abbiamo capito come fare, possiamo usare la procedura descritta sopra per calcolare un evento pi√π interessante, ovvero la probabilit√† di ottenere un pocker d‚Äôassi in un regolare mazzo da pocker di 52 carte. Iniziamo trovando il numero di possibili di mani di 5 carte:\n\ncards = list(product(range(1,5), range(1,14)))\nsample = list(combinations(cards, 5))\nlen(sample)\n\n2598960\n\n\nTroviamo ora la probabilit√† di un pocker d‚Äôassi.\n\nevent = [hand for hand in sample if numace(hand) == 4]\nprint(f\"{len(event)} / {len(sample)}\")\n\n48 / 2598960\n\n\nLa probabilit√† di una coppia d‚Äôassi e una coppia di Jack\nIn una variante di questo problema, troviamo la probabilit√† di una coppia d‚Äôassi e una coppia di Jack:\n\ndef numjack(hand):\n    return numval(hand, 11)\n\n\nevent = [hand for hand in sample if numace(hand) == 2 and numjack(hand) == 2]\nprint(f\"{len(event)} / {len(sample)}\")\n\n1584 / 2598960\n\n\nConcludiamo con alcuni esempi discussi nel secondo capitolo del testo di {cite:t}unpingco2022python.\nConsideriamo nuovamente l‚Äôesperimento casuale corrispondente al lancio di due dati equilibrati. Sia \\(X\\) la v.c. corrispondente alla somma dei punti prodotti dai due lanci. Poniamoci il problema di trovare la distribuzione di massa di probabilit√† di \\(X\\) e la probabilit√† associata a diversi eventi. Vedremo qui una procedura alternativa per risolvere questo problema rispetto quella discussa in precedenza.\nPer affrontare questo problema, {cite:t}unpingco2022python inizia a costruire un dizionario Python i cui elementi sono i punti del prodotto cartesiano i cui elementi sono della forma (a,b), dove \\(a\\) appartiene ad \\(A\\) = {1, 2, 3, 4, 5, 6} (punti del primo dado) e \\(b\\) appartiene a \\(B\\) = {1, 2, 3, 4, 5, 6} (punti del secondo dado).\n\nd = {(i, j): i + j for i in range(1, 7) for j in range(1, 7)}\nd\n\n{(1, 1): 2,\n (1, 2): 3,\n (1, 3): 4,\n (1, 4): 5,\n (1, 5): 6,\n (1, 6): 7,\n (2, 1): 3,\n (2, 2): 4,\n (2, 3): 5,\n (2, 4): 6,\n (2, 5): 7,\n (2, 6): 8,\n (3, 1): 4,\n (3, 2): 5,\n (3, 3): 6,\n (3, 4): 7,\n (3, 5): 8,\n (3, 6): 9,\n (4, 1): 5,\n (4, 2): 6,\n (4, 3): 7,\n (4, 4): 8,\n (4, 5): 9,\n (4, 6): 10,\n (5, 1): 6,\n (5, 2): 7,\n (5, 3): 8,\n (5, 4): 9,\n (5, 5): 10,\n (5, 6): 11,\n (6, 1): 7,\n (6, 2): 8,\n (6, 3): 9,\n (6, 4): 10,\n (6, 5): 11,\n (6, 6): 12}\n\n\nIl passo successivo √® quello di raccogliere tutte le coppie (a,b) la cui somma corrisponde a ciascuno dei possibili valori da 2 a 12. Per fare questo, {cite:t}unpingco2022python utilizza la funzione defaultdict():\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\ndinv\n\ndefaultdict(list,\n            {2: [(1, 1)],\n             3: [(1, 2), (2, 1)],\n             4: [(1, 3), (2, 2), (3, 1)],\n             5: [(1, 4), (2, 3), (3, 2), (4, 1)],\n             6: [(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)],\n             7: [(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)],\n             8: [(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)],\n             9: [(3, 6), (4, 5), (5, 4), (6, 3)],\n             10: [(4, 6), (5, 5), (6, 4)],\n             11: [(5, 6), (6, 5)],\n             12: [(6, 6)]})\n\n\nA questo punto √® possibile ottenere una lista di tutte le coppie la cui somma √® 7, per esempio:\n\ndinv[7]\n\n[(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)]\n\n\nIl passo successivo consiste nel calcolare la probabilit√† misurata per ciascun elemento di dinv. Utilizzando l‚Äôipotesi di indipendenza, ci√≤ significa che dobbiamo calcolare la somma dei prodotti delle probabilit√† dei singoli elementi in dinv. Poich√© sappiamo che ogni risultato √® ugualmente probabile, la probabilit√† di ogni termine nella somma √® uguale a 1/36. Pertanto, tutto ci√≤ che dobbiamo fare √® contare il numero di elementi nell‚Äôelenco corrispondente per ogni key in dinv e dividere per 36. Ad esempio, dinv[11] contiene [(5, 6), (6, 5)]. La probabilit√† di 5+6=6+5=11 √® la probabilit√† di questo insieme, che √® composto dalla somma delle probabilit√† dei singoli elementi {(5,6),(6,5)}. In questo caso, abbiamo P(11) = P({(5, 6)}) + P({(6, 5)}) = 1/36 + 1/36 = 2/36. Ripetendo questa procedura per tutti gli elementi, deriviamo la funzione di massa di probabilit√† come mostrato di seguito:\n\nX = {i: len(j) / 36.0 for i, j in dinv.items()}\nX\n\n{2: 0.027777777777777776,\n 3: 0.05555555555555555,\n 4: 0.08333333333333333,\n 5: 0.1111111111111111,\n 6: 0.1388888888888889,\n 7: 0.16666666666666666,\n 8: 0.1388888888888889,\n 9: 0.1111111111111111,\n 10: 0.08333333333333333,\n 11: 0.05555555555555555,\n 12: 0.027777777777777776}\n\n\n{cite:t}unpingco2022python afferma che questo esempio mostra quali sono gli elementi della teoria della probabilit√† che sono in gioco in questo semplice problema, sopprimendo deliberatamente alcuni dei dettagli tecnici pi√π fastidiosi.\nEsaminiamo con pi√π attenzione la funzione defaultdict(). Si noti che, nell‚Äôesempio sopra, essa prende come argomento list. Consideriamo con il seguente problema. Vogliamo contare quante volte ciascuna parola compare in un testo. Un primo modo per affrontare il problema √® il seguente: creiamo un dizionario a cui aggiungiamo come key ciascuna parola (se non √® gi√† presente nel dizionario) e, come valore, il numero di occorrenze:\n\ntext = \"Suppose I need to count the number of word occurrences in a text. How could I do that? Python provides us with multiple ways to do this same thing.\"\nword_count_dict = {}\nfor w in text.split(\" \"):\n    if w in word_count_dict:\n        word_count_dict[w]+=1\n    else:\n        word_count_dict[w]=1\n\nword_count_dict\n\n{'Suppose': 1,\n 'I': 2,\n 'need': 1,\n 'to': 2,\n 'count': 1,\n 'the': 1,\n 'number': 1,\n 'of': 1,\n 'word': 1,\n 'occurrences': 1,\n 'in': 1,\n 'a': 1,\n 'text.': 1,\n 'How': 1,\n 'could': 1,\n 'do': 2,\n 'that?': 1,\n 'Python': 1,\n 'provides': 1,\n 'us': 1,\n 'with': 1,\n 'multiple': 1,\n 'ways': 1,\n 'this': 1,\n 'same': 1,\n 'thing.': 1}\n\n\nLo stesso risultato si ottiene con defaultdict(). In questo caso\n\nword_count_dict = defaultdict(int)\nfor w in text.split(\" \"):\n    word_count_dict[w] += 1\n\nword_count_dict\n\ndefaultdict(int,\n            {'Suppose': 1,\n             'I': 2,\n             'need': 1,\n             'to': 2,\n             'count': 1,\n             'the': 1,\n             'number': 1,\n             'of': 1,\n             'word': 1,\n             'occurrences': 1,\n             'in': 1,\n             'a': 1,\n             'text.': 1,\n             'How': 1,\n             'could': 1,\n             'do': 2,\n             'that?': 1,\n             'Python': 1,\n             'provides': 1,\n             'us': 1,\n             'with': 1,\n             'multiple': 1,\n             'ways': 1,\n             'this': 1,\n             'same': 1,\n             'thing.': 1})\n\n\nCi√≤ rende chiaro che, in questo caso, defaultdict() viene usato per creare un dizionario dove associamo a ciascuna key la frequenza con la quale essa √® presente nell‚Äôoggetto text. In questo secondo esempio, defaultdict() prende come argomento int perch√© ritorner√† un integer.\nNel caso del lancio dei due dadi, invece, l‚Äôargomento di defaultdict() √® list, perch√© a ciascuna key verr√† associata una lista. d.items() sono i dict_items.\n\nd.items()\n\ndict_items([((1, 1), 2), ((1, 2), 3), ((1, 3), 4), ((1, 4), 5), ((1, 5), 6), ((1, 6), 7), ((2, 1), 3), ((2, 2), 4), ((2, 3), 5), ((2, 4), 6), ((2, 5), 7), ((2, 6), 8), ((3, 1), 4), ((3, 2), 5), ((3, 3), 6), ((3, 4), 7), ((3, 5), 8), ((3, 6), 9), ((4, 1), 5), ((4, 2), 6), ((4, 3), 7), ((4, 4), 8), ((4, 5), 9), ((4, 6), 10), ((5, 1), 6), ((5, 2), 7), ((5, 3), 8), ((5, 4), 9), ((5, 5), 10), ((5, 6), 11), ((6, 1), 7), ((6, 2), 8), ((6, 3), 9), ((6, 4), 10), ((6, 5), 11), ((6, 6), 12)])\n\n\nIl ciclo for i, j in d.items(): fa riferimento a ciascuno degli elementi del dizionario d.\n\nfor i, j in d.items():\n    print(i,j)\n\n(1, 1) 2\n(1, 2) 3\n(1, 3) 4\n(1, 4) 5\n(1, 5) 6\n(1, 6) 7\n(2, 1) 3\n(2, 2) 4\n(2, 3) 5\n(2, 4) 6\n(2, 5) 7\n(2, 6) 8\n(3, 1) 4\n(3, 2) 5\n(3, 3) 6\n(3, 4) 7\n(3, 5) 8\n(3, 6) 9\n(4, 1) 5\n(4, 2) 6\n(4, 3) 7\n(4, 4) 8\n(4, 5) 9\n(4, 6) 10\n(5, 1) 6\n(5, 2) 7\n(5, 3) 8\n(5, 4) 9\n(5, 5) 10\n(5, 6) 11\n(6, 1) 7\n(6, 2) 8\n(6, 3) 9\n(6, 4) 10\n(6, 5) 11\n(6, 6) 12\n\n\nL‚Äôindice i indica le coppie\n\nfor i, j in d.items():\n    print(i)\n\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n(2, 1)\n(2, 2)\n(2, 3)\n(2, 4)\n(2, 5)\n(2, 6)\n(3, 1)\n(3, 2)\n(3, 3)\n(3, 4)\n(3, 5)\n(3, 6)\n(4, 1)\n(4, 2)\n(4, 3)\n(4, 4)\n(4, 5)\n(4, 6)\n(5, 1)\n(5, 2)\n(5, 3)\n(5, 4)\n(5, 5)\n(5, 6)\n(6, 1)\n(6, 2)\n(6, 3)\n(6, 4)\n(6, 5)\n(6, 6)\n\n\nMentre j fa riferimento alla somma\n\nfor i, j in d.items():\n    print(j)\n\n2\n3\n4\n5\n6\n7\n3\n4\n5\n6\n7\n8\n4\n5\n6\n7\n8\n9\n5\n6\n7\n8\n9\n10\n6\n7\n8\n9\n10\n11\n7\n8\n9\n10\n11\n12\n\n\nOra possiamo usare defaultdict(list). Per ciascun valore della somma (j), appendiamo alla lista ad esso associata gli elementi (i) che producono tale somma:\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\nAvendo ottenuto il risultato riportato sopra, {cite:t}unpingco2022python si pone un altra domanda: qual √® la probabilit√† che la met√† del prodotto dei punti prodotti da tre dadi superi la loro somma? Possiamo risolverlo usando lo stesso metodo del seguente. Innanzitutto, si crea lo spazio campione dell‚Äôesperimento casuale, ovvero un dizionario a cui, per ciascun punto dello spazio campione si aggiunge una variabile booleana che √® True se la condizione specificata √® soddisfatta ed √® False altrimenti.\n\nd = {\n    (i, j, k): ((i * j * k) / 2 &gt; i + j + k)\n    for i in range(1, 7)\n    for j in range(1, 7)\n    for k in range(1, 7)\n}\nd\n\n{(1, 1, 1): False,\n (1, 1, 2): False,\n (1, 1, 3): False,\n (1, 1, 4): False,\n (1, 1, 5): False,\n (1, 1, 6): False,\n (1, 2, 1): False,\n (1, 2, 2): False,\n (1, 2, 3): False,\n (1, 2, 4): False,\n (1, 2, 5): False,\n (1, 2, 6): False,\n (1, 3, 1): False,\n (1, 3, 2): False,\n (1, 3, 3): False,\n (1, 3, 4): False,\n (1, 3, 5): False,\n (1, 3, 6): False,\n (1, 4, 1): False,\n (1, 4, 2): False,\n (1, 4, 3): False,\n (1, 4, 4): False,\n (1, 4, 5): False,\n (1, 4, 6): True,\n (1, 5, 1): False,\n (1, 5, 2): False,\n (1, 5, 3): False,\n (1, 5, 4): False,\n (1, 5, 5): True,\n (1, 5, 6): True,\n (1, 6, 1): False,\n (1, 6, 2): False,\n (1, 6, 3): False,\n (1, 6, 4): True,\n (1, 6, 5): True,\n (1, 6, 6): True,\n (2, 1, 1): False,\n (2, 1, 2): False,\n (2, 1, 3): False,\n (2, 1, 4): False,\n (2, 1, 5): False,\n (2, 1, 6): False,\n (2, 2, 1): False,\n (2, 2, 2): False,\n (2, 2, 3): False,\n (2, 2, 4): False,\n (2, 2, 5): True,\n (2, 2, 6): True,\n (2, 3, 1): False,\n (2, 3, 2): False,\n (2, 3, 3): True,\n (2, 3, 4): True,\n (2, 3, 5): True,\n (2, 3, 6): True,\n (2, 4, 1): False,\n (2, 4, 2): False,\n (2, 4, 3): True,\n (2, 4, 4): True,\n (2, 4, 5): True,\n (2, 4, 6): True,\n (2, 5, 1): False,\n (2, 5, 2): True,\n (2, 5, 3): True,\n (2, 5, 4): True,\n (2, 5, 5): True,\n (2, 5, 6): True,\n (2, 6, 1): False,\n (2, 6, 2): True,\n (2, 6, 3): True,\n (2, 6, 4): True,\n (2, 6, 5): True,\n (2, 6, 6): True,\n (3, 1, 1): False,\n (3, 1, 2): False,\n (3, 1, 3): False,\n (3, 1, 4): False,\n (3, 1, 5): False,\n (3, 1, 6): False,\n (3, 2, 1): False,\n (3, 2, 2): False,\n (3, 2, 3): True,\n (3, 2, 4): True,\n (3, 2, 5): True,\n (3, 2, 6): True,\n (3, 3, 1): False,\n (3, 3, 2): True,\n (3, 3, 3): True,\n (3, 3, 4): True,\n (3, 3, 5): True,\n (3, 3, 6): True,\n (3, 4, 1): False,\n (3, 4, 2): True,\n (3, 4, 3): True,\n (3, 4, 4): True,\n (3, 4, 5): True,\n (3, 4, 6): True,\n (3, 5, 1): False,\n (3, 5, 2): True,\n (3, 5, 3): True,\n (3, 5, 4): True,\n (3, 5, 5): True,\n (3, 5, 6): True,\n (3, 6, 1): False,\n (3, 6, 2): True,\n (3, 6, 3): True,\n (3, 6, 4): True,\n (3, 6, 5): True,\n (3, 6, 6): True,\n (4, 1, 1): False,\n (4, 1, 2): False,\n (4, 1, 3): False,\n (4, 1, 4): False,\n (4, 1, 5): False,\n (4, 1, 6): True,\n (4, 2, 1): False,\n (4, 2, 2): False,\n (4, 2, 3): True,\n (4, 2, 4): True,\n (4, 2, 5): True,\n (4, 2, 6): True,\n (4, 3, 1): False,\n (4, 3, 2): True,\n (4, 3, 3): True,\n (4, 3, 4): True,\n (4, 3, 5): True,\n (4, 3, 6): True,\n (4, 4, 1): False,\n (4, 4, 2): True,\n (4, 4, 3): True,\n (4, 4, 4): True,\n (4, 4, 5): True,\n (4, 4, 6): True,\n (4, 5, 1): False,\n (4, 5, 2): True,\n (4, 5, 3): True,\n (4, 5, 4): True,\n (4, 5, 5): True,\n (4, 5, 6): True,\n (4, 6, 1): True,\n (4, 6, 2): True,\n (4, 6, 3): True,\n (4, 6, 4): True,\n (4, 6, 5): True,\n (4, 6, 6): True,\n (5, 1, 1): False,\n (5, 1, 2): False,\n (5, 1, 3): False,\n (5, 1, 4): False,\n (5, 1, 5): True,\n (5, 1, 6): True,\n (5, 2, 1): False,\n (5, 2, 2): True,\n (5, 2, 3): True,\n (5, 2, 4): True,\n (5, 2, 5): True,\n (5, 2, 6): True,\n (5, 3, 1): False,\n (5, 3, 2): True,\n (5, 3, 3): True,\n (5, 3, 4): True,\n (5, 3, 5): True,\n (5, 3, 6): True,\n (5, 4, 1): False,\n (5, 4, 2): True,\n (5, 4, 3): True,\n (5, 4, 4): True,\n (5, 4, 5): True,\n (5, 4, 6): True,\n (5, 5, 1): True,\n (5, 5, 2): True,\n (5, 5, 3): True,\n (5, 5, 4): True,\n (5, 5, 5): True,\n (5, 5, 6): True,\n (5, 6, 1): True,\n (5, 6, 2): True,\n (5, 6, 3): True,\n (5, 6, 4): True,\n (5, 6, 5): True,\n (5, 6, 6): True,\n (6, 1, 1): False,\n (6, 1, 2): False,\n (6, 1, 3): False,\n (6, 1, 4): True,\n (6, 1, 5): True,\n (6, 1, 6): True,\n (6, 2, 1): False,\n (6, 2, 2): True,\n (6, 2, 3): True,\n (6, 2, 4): True,\n (6, 2, 5): True,\n (6, 2, 6): True,\n (6, 3, 1): False,\n (6, 3, 2): True,\n (6, 3, 3): True,\n (6, 3, 4): True,\n (6, 3, 5): True,\n (6, 3, 6): True,\n (6, 4, 1): True,\n (6, 4, 2): True,\n (6, 4, 3): True,\n (6, 4, 4): True,\n (6, 4, 5): True,\n (6, 4, 6): True,\n (6, 5, 1): True,\n (6, 5, 2): True,\n (6, 5, 3): True,\n (6, 5, 4): True,\n (6, 5, 5): True,\n (6, 5, 6): True,\n (6, 6, 1): True,\n (6, 6, 2): True,\n (6, 6, 3): True,\n (6, 6, 4): True,\n (6, 6, 5): True,\n (6, 6, 6): True}\n\n\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\ndinv\n\ndefaultdict(list,\n            {False: [(1, 1, 1),\n              (1, 1, 2),\n              (1, 1, 3),\n              (1, 1, 4),\n              (1, 1, 5),\n              (1, 1, 6),\n              (1, 2, 1),\n              (1, 2, 2),\n              (1, 2, 3),\n              (1, 2, 4),\n              (1, 2, 5),\n              (1, 2, 6),\n              (1, 3, 1),\n              (1, 3, 2),\n              (1, 3, 3),\n              (1, 3, 4),\n              (1, 3, 5),\n              (1, 3, 6),\n              (1, 4, 1),\n              (1, 4, 2),\n              (1, 4, 3),\n              (1, 4, 4),\n              (1, 4, 5),\n              (1, 5, 1),\n              (1, 5, 2),\n              (1, 5, 3),\n              (1, 5, 4),\n              (1, 6, 1),\n              (1, 6, 2),\n              (1, 6, 3),\n              (2, 1, 1),\n              (2, 1, 2),\n              (2, 1, 3),\n              (2, 1, 4),\n              (2, 1, 5),\n              (2, 1, 6),\n              (2, 2, 1),\n              (2, 2, 2),\n              (2, 2, 3),\n              (2, 2, 4),\n              (2, 3, 1),\n              (2, 3, 2),\n              (2, 4, 1),\n              (2, 4, 2),\n              (2, 5, 1),\n              (2, 6, 1),\n              (3, 1, 1),\n              (3, 1, 2),\n              (3, 1, 3),\n              (3, 1, 4),\n              (3, 1, 5),\n              (3, 1, 6),\n              (3, 2, 1),\n              (3, 2, 2),\n              (3, 3, 1),\n              (3, 4, 1),\n              (3, 5, 1),\n              (3, 6, 1),\n              (4, 1, 1),\n              (4, 1, 2),\n              (4, 1, 3),\n              (4, 1, 4),\n              (4, 1, 5),\n              (4, 2, 1),\n              (4, 2, 2),\n              (4, 3, 1),\n              (4, 4, 1),\n              (4, 5, 1),\n              (5, 1, 1),\n              (5, 1, 2),\n              (5, 1, 3),\n              (5, 1, 4),\n              (5, 2, 1),\n              (5, 3, 1),\n              (5, 4, 1),\n              (6, 1, 1),\n              (6, 1, 2),\n              (6, 1, 3),\n              (6, 2, 1),\n              (6, 3, 1)],\n             True: [(1, 4, 6),\n              (1, 5, 5),\n              (1, 5, 6),\n              (1, 6, 4),\n              (1, 6, 5),\n              (1, 6, 6),\n              (2, 2, 5),\n              (2, 2, 6),\n              (2, 3, 3),\n              (2, 3, 4),\n              (2, 3, 5),\n              (2, 3, 6),\n              (2, 4, 3),\n              (2, 4, 4),\n              (2, 4, 5),\n              (2, 4, 6),\n              (2, 5, 2),\n              (2, 5, 3),\n              (2, 5, 4),\n              (2, 5, 5),\n              (2, 5, 6),\n              (2, 6, 2),\n              (2, 6, 3),\n              (2, 6, 4),\n              (2, 6, 5),\n              (2, 6, 6),\n              (3, 2, 3),\n              (3, 2, 4),\n              (3, 2, 5),\n              (3, 2, 6),\n              (3, 3, 2),\n              (3, 3, 3),\n              (3, 3, 4),\n              (3, 3, 5),\n              (3, 3, 6),\n              (3, 4, 2),\n              (3, 4, 3),\n              (3, 4, 4),\n              (3, 4, 5),\n              (3, 4, 6),\n              (3, 5, 2),\n              (3, 5, 3),\n              (3, 5, 4),\n              (3, 5, 5),\n              (3, 5, 6),\n              (3, 6, 2),\n              (3, 6, 3),\n              (3, 6, 4),\n              (3, 6, 5),\n              (3, 6, 6),\n              (4, 1, 6),\n              (4, 2, 3),\n              (4, 2, 4),\n              (4, 2, 5),\n              (4, 2, 6),\n              (4, 3, 2),\n              (4, 3, 3),\n              (4, 3, 4),\n              (4, 3, 5),\n              (4, 3, 6),\n              (4, 4, 2),\n              (4, 4, 3),\n              (4, 4, 4),\n              (4, 4, 5),\n              (4, 4, 6),\n              (4, 5, 2),\n              (4, 5, 3),\n              (4, 5, 4),\n              (4, 5, 5),\n              (4, 5, 6),\n              (4, 6, 1),\n              (4, 6, 2),\n              (4, 6, 3),\n              (4, 6, 4),\n              (4, 6, 5),\n              (4, 6, 6),\n              (5, 1, 5),\n              (5, 1, 6),\n              (5, 2, 2),\n              (5, 2, 3),\n              (5, 2, 4),\n              (5, 2, 5),\n              (5, 2, 6),\n              (5, 3, 2),\n              (5, 3, 3),\n              (5, 3, 4),\n              (5, 3, 5),\n              (5, 3, 6),\n              (5, 4, 2),\n              (5, 4, 3),\n              (5, 4, 4),\n              (5, 4, 5),\n              (5, 4, 6),\n              (5, 5, 1),\n              (5, 5, 2),\n              (5, 5, 3),\n              (5, 5, 4),\n              (5, 5, 5),\n              (5, 5, 6),\n              (5, 6, 1),\n              (5, 6, 2),\n              (5, 6, 3),\n              (5, 6, 4),\n              (5, 6, 5),\n              (5, 6, 6),\n              (6, 1, 4),\n              (6, 1, 5),\n              (6, 1, 6),\n              (6, 2, 2),\n              (6, 2, 3),\n              (6, 2, 4),\n              (6, 2, 5),\n              (6, 2, 6),\n              (6, 3, 2),\n              (6, 3, 3),\n              (6, 3, 4),\n              (6, 3, 5),\n              (6, 3, 6),\n              (6, 4, 1),\n              (6, 4, 2),\n              (6, 4, 3),\n              (6, 4, 4),\n              (6, 4, 5),\n              (6, 4, 6),\n              (6, 5, 1),\n              (6, 5, 2),\n              (6, 5, 3),\n              (6, 5, 4),\n              (6, 5, 5),\n              (6, 5, 6),\n              (6, 6, 1),\n              (6, 6, 2),\n              (6, 6, 3),\n              (6, 6, 4),\n              (6, 6, 5),\n              (6, 6, 6)]})\n\n\n\nX = {i: len(j) / 6.0**3 for i, j in dinv.items()}\nprint(X)\n\n{False: 0.37037037037037035, True: 0.6296296296296297}\n\n\n\nd = pd.DataFrame(\n    index=[(i, j) for i in range(1, 7) for j in range(1, 7)],\n    columns=[\"sm\", \"d1\", \"d2\", \"pd1\", \"pd2\", \"p\"],\n)\nd\n\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nd.d1 = [i[0] for i in d.index]\nd.d2 = [i[1] for i in d.index]\n\nd.head(), d.tail()\n\n(         sm  d1  d2  pd1  pd2    p\n (1, 1)  NaN   1   1  NaN  NaN  NaN\n (1, 2)  NaN   1   2  NaN  NaN  NaN\n (1, 3)  NaN   1   3  NaN  NaN  NaN\n (1, 4)  NaN   1   4  NaN  NaN  NaN\n (1, 5)  NaN   1   5  NaN  NaN  NaN,\n          sm  d1  d2  pd1  pd2    p\n (6, 2)  NaN   6   2  NaN  NaN  NaN\n (6, 3)  NaN   6   3  NaN  NaN  NaN\n (6, 4)  NaN   6   4  NaN  NaN  NaN\n (6, 5)  NaN   6   5  NaN  NaN  NaN\n (6, 6)  NaN   6   6  NaN  NaN  NaN)\n\n\n\nd[\"sm\"] = d[\"d1\"] + d[\"d2\"]\nd.head()\n\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\n2\n1\n1\nNaN\nNaN\nNaN\n\n\n(1, 2)\n3\n1\n2\nNaN\nNaN\nNaN\n\n\n(1, 3)\n4\n1\n3\nNaN\nNaN\nNaN\n\n\n(1, 4)\n5\n1\n4\nNaN\nNaN\nNaN\n\n\n(1, 5)\n6\n1\n5\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nd[\"pd1\"] = 1/6\nd[\"pd2\"] = 1/6\nd[\"p\"] = d[\"pd1\"] * d[\"pd2\"]\nd.head()\n\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\n2\n1\n1\n0.166667\n0.166667\n0.027778\n\n\n(1, 2)\n3\n1\n2\n0.166667\n0.166667\n0.027778\n\n\n(1, 3)\n4\n1\n3\n0.166667\n0.166667\n0.027778\n\n\n(1, 4)\n5\n1\n4\n0.166667\n0.166667\n0.027778\n\n\n(1, 5)\n6\n1\n5\n0.166667\n0.166667\n0.027778\n\n\n\n\n\n\n\n\n\nd[\"p\"].sum()\n\n1.0\n\n\n\nd.groupby('sm')['p'].sum()\n\nsm\n2     0.027778\n3     0.055556\n4     0.083333\n5     0.111111\n6     0.138889\n7     0.166667\n8     0.138889\n9     0.111111\n10    0.083333\n11    0.055556\n12    0.027778\nName: p, dtype: float64",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>M</span>¬† <span class='chapter-title'>Esercizi di probabilit√† discreta</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html",
    "href": "chapters/appendix/a40_rng.html",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "",
    "text": "N.1 Distribuzione uniforme\nConsideriamo la distribuzione uniforme: rng.uniform([low, high, size]). Genero un singolo valore:\nLo genero una seconda volta:\nrng.uniform(0, 1, size=1)\n\narray([0.77395605])\nGenero 20 valori:\nrng.uniform(0, 1, size=20)\n\narray([0.43887844, 0.85859792, 0.69736803, 0.09417735, 0.97562235,\n       0.7611397 , 0.78606431, 0.12811363, 0.45038594, 0.37079802,\n       0.92676499, 0.64386512, 0.82276161, 0.4434142 , 0.22723872,\n       0.55458479, 0.06381726, 0.82763117, 0.6316644 , 0.75808774])\nCreo un istogramma.\nn_samples = 1000000\n_ = plt.hist(rng.uniform(0, 1, size=n_samples), bins=50, density=True)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-normale",
    "href": "chapters/appendix/a40_rng.html#distribuzione-normale",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.2 Distribuzione normale",
    "text": "N.2 Distribuzione normale\nEstraiamo ora dei campioni casuali dalla distribuzione Gaussiana, rng.normal([loc, scale, size]). Per esempio, generiamo 10 valori dalla distribuzione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\):\n\nx = rng.normal(loc=100, scale=15, size=10)\nprint(x)\n\n[ 88.39130723 106.85972149 112.68284617  98.40757644  59.28402571\n  83.63194152 127.29102032  91.32585446 109.21359401 103.23261596]\n\n\nOra generiamo un grande numero (1000000) di valori casuali dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\). Con questi valori creiamo un istogramma e a tale istogramma sovrapponiamo la funzione di densit√† \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\). In questo modo possiamo accertarci che i numeri casuali che abbiamo ottenuto si riferiscano veramente alla densit√† desiderata. Per trovare la densit√† della distribuzione normale, uso norm.pdf da scipy.stats.\n\nn_samples = 1000000\nmu = 100\nsigma = 15\n# create x's\nxs = np.linspace(55, 145, n_samples)\ny_pdf = stats.norm.pdf(xs, mu, sigma)\n# create random samples\nsamps = rng.normal(loc=mu, scale=sigma, size=n_samples)\n# plot them\nplt.plot(xs, y_pdf)\nplt.hist(samps, bins=50, density=True)\nplt.title(\"Distribuzione Normale $\\mathcal{N}(\\mu=100, \\sigma=15)$\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xlim(40, 160);\n\n\n\n\n\n\n\n\nLa stessa procedura pu√≤ essere usata per tutte le distribuzioni implementate da NumPy. Esaminiamo alcuni esempi qui sotto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-beta",
    "href": "chapters/appendix/a40_rng.html#distribuzione-beta",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.3 Distribuzione Beta",
    "text": "N.3 Distribuzione Beta\nPer estrarre dei campioni casuali dalla distribuzione Beta usiamo il generatore rng.beta(a, b[, size]); per la densit√† Beta usiamo stats.beta.pdf(x, a, b).\n\n# Definisci il numero di campioni\nn_samples = 1000000\na = 3\nb = 9\n\n# Crea un array di valori x\nxs = np.linspace(0, 1, n_samples)\n\n# Calcola la densit√† di probabilit√† (PDF) della distribuzione Beta\ny_pdf = stats.beta.pdf(xs, a, b)\n\n# Genera i campioni casuali\nsamps = rng.beta(a, b, size=n_samples)\n\n# Traccia il grafico\nplt.plot(xs, y_pdf, label=\"Densit√† Beta(3,9)\")\nplt.hist(samps, bins=50, density=True, label=\"Campioni\")\nplt.title(\"Confronto tra la Distribuzione Beta(3,9) e Campioni Casuali\")\nplt.ylabel(\"Densit√†\")\nplt.xlabel(\"Valore\")\n_ = plt.legend()",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-binomiale",
    "href": "chapters/appendix/a40_rng.html#distribuzione-binomiale",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.4 Distribuzione binomiale",
    "text": "N.4 Distribuzione binomiale\nPer estrarre dei campioni casuali dalla distribuzione Binomiale usiamo rng.binomial(n, p[, size]); per la distribuzione di massa Binomiale usiamo stats.binom.pmf(r, n, p).\n\nn_samples = 1000000\n\nn = 10\np = 0.3\n# create r values\nr_values = list(range(n + 1))\n# pmf\ny_pmf = [stats.binom.pmf(r, n, p) for r in r_values]\n# create random samples\nr_samps = rng.binomial(n=n, p=p, size=n_samples)\nplt.plot(r_values, y_pmf, \"x\")\nplt.hist(r_samps, bins=np.arange(-0.5, 11.5, 1), density=True)\nplt.title(\"Distribuzione Binomiale($n$=10, $p$=0.3)\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\");",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-t-di-student",
    "href": "chapters/appendix/a40_rng.html#distribuzione-t-di-student",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.5 Distribuzione \\(t\\) di Student",
    "text": "N.5 Distribuzione \\(t\\) di Student\nPer estrarre dei campioni casuali dalla distribuzione \\(t\\) di Student uso il generatore rng con standard_t(df, size=None); per la densit√† \\(t\\) di Student uso t.pdf da scipy.stats.\n\nn_samples = 100000\ndf = 4\n# create x's\nxs = np.linspace(-4, 4, n_samples)\ny_pdf = stats.t.pdf(xs, df=df)\n# create random samples\nsamps = rng.standard_t(df=df, size=n_samples)\n# plot them\nfig, ax = plt.subplots()\nplt.plot(xs, y_pdf)\nplt.hist(samps, bins=400, density=True)\nplt.title(\"Distribuzione $t(\\\\nu=4)$\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xlim(-4, 4);",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-arbitraria-di-una-variabile-casuale-distreta",
    "href": "chapters/appendix/a40_rng.html#distribuzione-arbitraria-di-una-variabile-casuale-distreta",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.6 Distribuzione arbitraria di una variabile casuale distreta",
    "text": "N.6 Distribuzione arbitraria di una variabile casuale distreta\nCon la funzione random.choices √® possible specificare i valori di una variabile casuale discreta con una distribuzione di massa di probabilit√† arbitraria.\n\n# Define the set of values\nx_rv = [1, 2, 3, 4]\n# Define the weights for each value\nweights = [0.1, 0.1, 0.3, 0.5]\n\nx_sample = rng.choice(x_rv, size=100, p=weights)\nprint(f\"Random Sample: {x_sample}\")\n\nRandom Sample: [1 1 4 3 1 4 1 4 3 3 4 4 1 4 4 4 4 2 4 2 1 4 4 2 1 3 2 4 1 4 4 3 4 2 4 4 1\n 4 3 4 4 4 4 3 1 4 3 3 2 4 3 4 4 3 3 4 4 1 3 4 4 4 3 2 1 4 4 4 4 4 3 4 3 2\n 3 4 4 3 3 4 4 3 4 2 4 3 4 3 1 2 4 4 1 1 4 3 1 4 4 4]\n\n\nNell‚Äôesempio, i pesi weights indicano che, nella distribuzione, il valore 4 √® presente con una frequenza di cinque volte maggiore dei valori 1 e 2.\nSe aggiungiamo l‚Äôargomento k possiamo definire i pesi (indirettamente, le probabilit√†) dei diversi valori della variabile casuale che sono stati specificati. Nell‚Äôesempio, i pesi [1, 1, 3, 6] indicano che, nella distribuzione, il valore 4 √® presente con una frequenza di sei volte maggiore dei valori 1 e 2.\n\nn_samples = 100000\nx = rng.choice(x_rv, size=n_samples, p=weights)\nbins = plt.hist(x, density=True)\nplt.title(\"Distribuzione arbitraria di massa di probabilit√†\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xticks(x_rv);\n\n\n\n\n\n\n\n\n\nrng.binomial(10, .1, size=4)\n\narray([3, 0, 3, 1])",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#la-tecnica-dellinversione",
    "href": "chapters/appendix/a40_rng.html#la-tecnica-dellinversione",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.7 La Tecnica dell‚ÄôInversione",
    "text": "N.7 La Tecnica dell‚ÄôInversione\nLa tecnica dell‚Äôinversione per la simulazione, introdotta nel 1947 da John Von Neumann (Roger 1987), permette di generare campioni casuali da una distribuzione data sfruttando una variabile casuale uniforme. Questo metodo consente di trasformare una variabile casuale uniforme in una variabile casuale con la distribuzione desiderata, permettendo cos√¨ di ottenere un campione casuale da qualsiasi distribuzione specifica a partire da un campione di variabili casuali uniformi.\n\nN.7.1 Intuizione di Base\nImmaginiamo di avere una variabile casuale \\(X\\) con una funzione di distribuzione cumulativa \\(F(x)\\), che √® una funzione che mappa i valori di \\(X\\) nell‚Äôintervallo \\([0, 1]\\). La tecnica dell‚Äôinversione sfrutta il fatto che possiamo invertire questa mappatura per ottenere i valori di \\(X\\) a partire da una variabile casuale uniforme \\(U\\) su \\([0, 1]\\).\n\nN.7.1.1 Passi Fondamentali:\n\nSi genera una variabile casuale \\(U\\) che √® uniformemente distribuita nell‚Äôintervallo \\([0, 1]\\).\nSi applica l‚Äôinversa della funzione di distribuzione cumulativa \\(F^{-1}(u)\\) per ottenere il valore corrispondente di \\(X\\).\n\nVediamo come implementare questa tecnica utilizzando una distribuzione Gaussiana (Normale) con media \\(\\mu\\) e deviazione standard \\(\\sigma\\).\n\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n# Parametri della distribuzione normale\nmu = 0    # Media\nsigma = 1 # Deviazione standard\n\n# Generazione di 10000 variabili casuali uniformi\nu = np.random.uniform(0, 1, 10000)\n\n# Applicazione dell'inversa della funzione di distribuzione cumulativa normale\nx = stats.norm.ppf(u, loc=mu, scale=sigma)\n\n# Visualizzazione dell'istogramma dei campioni generati\nplt.hist(x, bins=50, density=True, alpha=0.6, color='g')\n\n# Sovrapposizione della funzione di densit√† di probabilit√† teorica\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\n\np = stats.norm.pdf(x, mu, sigma)\nplt.plot(x, p, 'k', linewidth=2)\ntitle = \"Istogramma dei campioni generati con la tecnica dell'inversione\"\nplt.title(title)\nplt.show()\n\n\n\n\n\n\n\n\nQuesto esempio illustra l‚Äôutilizzo della tecnica dell‚Äôinversione per generare campioni da una distribuzione normale utilizzando variabili casuali uniformi. Il processo √® suddiviso in quattro passaggi:\n\nDefinizione della media Œº e della deviazione standard œÉ della distribuzione normale desiderata.\nGenerazione di 10.000 numeri casuali uniformemente distribuiti nell‚Äôintervallo [0, 1].\nApplicazione dell‚Äôinversa della funzione di distribuzione cumulativa normale (tramite stats.norm.ppf) per trasformare i numeri casuali uniformi in campioni dalla distribuzione normale.\nCreazione di un istogramma dei campioni generati e confronto con la funzione di densit√† di probabilit√† teorica della distribuzione normale.\n\nQuesta tecnica dimostra come sia possibile generare campioni da una distribuzione specifica a partire da variabili casuali uniformi. La stessa metodologia pu√≤ essere applicata ad altre distribuzioni, semplicemente modificando la funzione di distribuzione cumulativa e la sua inversa.\nSebbene siano disponibili funzioni di alto livello, come np.random.normal() in NumPy, che ottengono lo stesso risultato in modo pi√π semplice (si veda sotto), la tecnica dell‚Äôinversione fornisce una comprensione pi√π approfondita del processo matematico sottostante. Questa conoscenza pu√≤ essere utile per estendere il metodo ad altre distribuzioni non supportate direttamente dalle librerie esistenti.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generazione di 10000 numeri casuali da una distribuzione normale\nmu = 0    # Media\nsigma = 1 # Deviazione standard\nsamples = np.random.normal(mu, sigma, 10000)\n\n\n# Visualizzazione dell'istogramma dei campioni generati\nplt.hist(samples, bins=50, density=True, alpha=0.6, color='g')\n\n# Sovrapposizione della funzione di densit√† di probabilit√† teorica\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = (1/(np.sqrt(2*np.pi*sigma**2))) * np.exp(-(x-mu)**2/(2*sigma**2))\nplt.plot(x, p, 'k', linewidth=2)\ntitle = \"Istogramma dei campioni generati con np.random.normal()\"\nplt.title(title)\nplt.show()",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#commenti-e-considerazioni-finali",
    "href": "chapters/appendix/a40_rng.html#commenti-e-considerazioni-finali",
    "title": "Appendice N ‚Äî Generazione di numeri casuali",
    "section": "N.8 Commenti e Considerazioni Finali",
    "text": "N.8 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esaminato l‚Äôutilizzo della funzione rng = np.random.default_rng() per generare un campione di numeri pseudo-casuali da una distribuzione. Dopo aver inizializzato rng con rng = np.random.default_rng(RANDOM_SEED), possiamo generare campioni casuali da diverse distribuzioni di massa e di densit√† di probabilit√†:\n\nDistribuzione uniforme: rng.uniform(min, max, size)\nDistribuzione normale: rng.normal(loc, scale, size)\nDistribuzione t di Student: rng.standard_t(df, size)\nDistribuzione beta: rng.beta(alpha, beta, size)\nDistribuzione binomiale: rng.binomial(n, p, size)\n\nNei capitoli precedenti, nello specifico nei notebook {ref}discr_distr_notebook e {ref}cont-rv-distr-notebook, abbiamo invece approfondito l‚Äôutilizzo di varie funzioni della libreria scipy.stats per manipolare le distribuzioni di probabilit√†. In particolare, abbiamo illustrato come sia possibile utilizzare:\n\n.pdf per ottenere i valori della funzione di densit√† di probabilit√† o .pmf per ottenere i valori della distribuzione di massa di probabilit√†.\n.ppf per calcolare i quantili della distribuzione.\n.cdf per calcolare la probabilit√† associata a un valore specifico. Nel caso di una variabile casuale continua, questo corrisponde al valore della funzione di ripartizione, che rappresenta l‚Äôarea sotto la curva di densit√† nella coda sinistra. Nel caso di una variabile casuale discreta, corrisponde alla somma delle probabilit√† dalla distribuzione di massa di probabilit√† dal valore minimo fino al valore specificato (incluso).\n\n\n\n\n\nRoger, Eckhardt. 1987. ¬´Stan Ulam, John Von Neumann, and the Monte Carlo Method¬ª. Los Alamos Science 15: 131‚Äì37.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>¬† <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html",
    "href": "chapters/appendix/a44_montecarlo.html",
    "title": "Appendice O ‚Äî Simulazione Monte Carlo",
    "section": "",
    "text": "O.1 Stima dell‚Äôintegrale di un cerchio\nImmaginiamo un quadrato di lato 2 centrato sull‚Äôorigine. Genereremo punti casuali uniformemente distribuiti all‚Äôinterno di questo quadrato. Per ogni punto \\((x, y)\\), verificheremo se cade all‚Äôinterno del cerchio di raggio unitario inscritto nel quadrato, cio√® se la distanza dall‚Äôorigine √® minore di 1:\n\\[\n\\sqrt{x^2 + y^2} &lt; 1,\n\\]\nche si semplifica a:\n\\[\nx^2 + y^2 &lt; 1.\n\\]\nLa proporzione di tali punti rappresenta la proporzione dell‚Äôarea del quadrato occupata dal cerchio. Poich√© il quadrato ha un‚Äôarea di 4, l‚Äôarea del cerchio √® pari a 4 volte la proporzione dei punti che cadono all‚Äôinterno del cerchio.\nQuindi, se generiamo un numero sufficiente di punti casuali e contiamo quanti di essi cadono all‚Äôinterno del cerchio, possiamo stimare \\(\\pi\\) come:\n\\[\n\\pi \\approx 4 \\times \\frac{\\text{numero di punti dentro il cerchio}}{\\text{numero totale di punti}}.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#stima-dellintegrale-di-un-cerchio",
    "href": "chapters/appendix/a44_montecarlo.html#stima-dellintegrale-di-un-cerchio",
    "title": "Appendice O ‚Äî Simulazione Monte Carlo",
    "section": "",
    "text": "O.1.1 Codice Stan\nEsaminiamo il corrispondente codice Stan.\ngenerated quantities {\n  real&lt;lower=-1, upper=1&gt; x = uniform_rng(-1, 1);\n  real&lt;lower=-1, upper=1&gt; y = uniform_rng(-1, 1);\n  int&lt;lower=0, upper=1&gt; inside = x^2 + y^2 &lt; 1;\n  real&lt;lower=0, upper=4&gt; pi = 4 * inside;\n}\n\nVariabili x e y:\n\nVengono generate casualmente e uniformemente nell‚Äôintervallo \\((-1, 1)\\). Questo significa che stiamo campionando punti all‚Äôinterno di un quadrato di lato 2 centrato sull‚Äôorigine.\n\nVariabile inside:\n\n√à un indicatore che verifica se il punto \\((x, y)\\) cade all‚Äôinterno del cerchio unitario. La condizione \\(x^2 + y^2 &lt; 1\\) √® vera se il punto \\((x, y)\\) √® all‚Äôinterno del cerchio di raggio 1 centrato sull‚Äôorigine, e falsa altrimenti.\nSe la condizione √® vera, inside √® impostato a 1, altrimenti a 0.\n\nVariabile pi:\n\npi viene calcolata come 4 volte il valore di inside.\n\n\nIl programma Stan genera punti casuali, verifica se cadono all‚Äôinterno del cerchio e usa la proporzione di punti che cadono all‚Äôinterno del cerchio per stimare \\(\\pi\\). Moltiplicando il valore indicatore per 4, otteniamo una stima di \\(\\pi\\) basata su ciascun punto generato. La stima finale di \\(\\pi\\) sar√† la media di queste stime su molti punti campionati.\n\n\nO.1.2 Media Campionaria dell‚ÄôIndicatore\nDopo aver generato un numero sufficiente di punti casuali e aver verificato quanti di essi cadono all‚Äôinterno del cerchio, calcoliamo la media campionaria dell‚Äôindicatore inside. Questo indicatore √® uguale a 1 se il punto √® dentro il cerchio e a 0 se √® fuori. La media di questi valori ci d√† la proporzione dei punti che cadono dentro il cerchio.\nQuesta proporzione √® una stima della probabilit√† che un punto casuale sia all‚Äôinterno del cerchio. Moltiplicando questa proporzione per 4, otteniamo una stima di \\(\\pi\\).\nMatematicamente, possiamo scrivere questo processo come segue:\n\\[\n\\mathbb{E}[4 \\cdot \\textrm{I}(\\sqrt{X^2 + Y^2} \\leq 1)] = \\int_{-1}^1 \\int_{-1}^1 4 \\cdot \\textrm{I}(x^2 + y^2 &lt; 1) \\, \\textrm{d}x \\, \\textrm{d}y = \\pi,\n\\]\ndove \\(\\textrm{I}()\\) √® l‚Äôindicatore che ritorna 1 se il suo argomento √® vero e 0 altrimenti.\nIn altre parole, stiamo calcolando l‚Äôaspettativa di 4 volte l‚Äôindicatore che un punto casuale \\((x, y)\\) cade dentro il cerchio unitario. Questo valore atteso √® uguale a \\(\\pi\\), il che ci permette di stimare \\(\\pi\\) usando i metodi Monte Carlo.\n\n\nO.1.3 Compilazione e Campionamento\nCompiliamo e poi campioniamo dal modello, prendendo un campione di dimensione \\(M = 10,000\\) estrazioni.\n\nM = 10_000\nmodel = CmdStanModel(stan_file=\"../../stan/monte-carlo-pi.stan\")\n\nsample = model.sample(\n    chains=1,\n    iter_warmup=1,\n    iter_sampling=M,\n    show_progress=False,\n    show_console=False,\n    seed=123,\n)\n\nx_draws = sample.stan_variable(\"x\")\ny_draws = sample.stan_variable(\"y\")\ninside_draws = sample.stan_variable(\"inside\")\npi_draws = sample.stan_variable(\"pi\")\n\ndf = pd.DataFrame({\"N\": 1000, \"x\": x_draws, \"y\": y_draws, \"inside\": inside_draws})\n\nplt.figure(figsize=(5, 5))\nplt.scatter(df[\"x\"], df[\"y\"], c=df[\"inside\"], cmap=\"coolwarm\", s=1)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Monte Carlo Simulation of Pi Estimation\")\nplt.gca().set_aspect(\"equal\", adjustable=\"box\")\nplt.show()\n\n\n\n\n\n\n\n\nSuccessivamente, calcoliamo la media campionaria dell‚Äôindicatore dentro-il-cerchio, che produce una stima della probabilit√† che un punto sia dentro il cerchio:\n\nPr_is_inside = np.mean(inside_draws)\npi_hat = np.mean(pi_draws)\nprint(f\"Pr[Y is inside circle] = {Pr_is_inside:.3f};\")\nprint(f\"estimate for pi = {pi_hat:.3f}\")\n\nPr[Y is inside circle] = 0.786;\nestimate for pi = 3.144\n\n\nIl valore esatto di \\(\\pi\\) fino a tre cifre decimali √® \\(3.142\\). Con il nostro metodo, ci avviciniamo a questo valore, ma non lo raggiungiamo esattamente, il che √® tipico dei metodi Monte Carlo. Aumentando il numero di estrazioni, l‚Äôerrore diminuisce. Teoricamente, con un numero sufficiente di estrazioni, possiamo ottenere qualsiasi precisione desiderata; tuttavia, in pratica, dobbiamo accontentarci di pochi decimali di accuratezza nelle nostre stime Monte Carlo. Questo di solito non √® un problema, poich√© l‚Äôincertezza statistica tende a dominare rispetto all‚Äôimprecisione numerica nella maggior parte delle applicazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>¬† <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html",
    "href": "chapters/appendix/a46_stan.html",
    "title": "Appendice P ‚Äî Linguaggio Stan",
    "section": "",
    "text": "P.1 Interfacce e pacchetti\n√à possibile accedere al linguaggio Stan tramite diverse interfacce:\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, sia in Python che in Linguaggio \\(\\mathsf{R}\\):",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#interfacce-e-pacchetti",
    "href": "chapters/appendix/a46_stan.html#interfacce-e-pacchetti",
    "title": "Appendice P ‚Äî Linguaggio Stan",
    "section": "",
    "text": "CmdStanPy - integrazione con il linguaggio di programmazione Python;\nPyStan - integrazione con il linguaggio di programmazione Python;\nCmdStan - eseguibile da riga di comando,\nRStan - integrazione con il linguaggio \\(\\mathsf{R}\\);\nMatlabStan - integrazione con MATLAB;\nStan.jl - integrazione con il linguaggio di programmazione Julia;\nStataStan - integrazione con Stata.\nScalaStan - integrazione con Scala.\n\n\n\nArviz - ArviZ √® una libreria Python per l‚Äôanalisi esplorativa dei modelli bayesiani. Essa funge da strumento indipendente dal backend per diagnosticare e visualizzare l‚Äôinferenza bayesiana.\nshinystan - interfaccia grafica interattiva per l‚Äôanalisi della distribuzione a posteriori e le diagnostiche MCMC in \\(\\mathsf{R}\\);\nbayesplot - insieme di funzioni utilizzabili per creare grafici relativi all‚Äôanalisi della distribuzione a posteriori, ai test del modello e alle diagnostiche MCMC in \\(\\mathsf{R}\\);\nbrms - fornisce un‚Äôampia gamma di modelli lineari e non lineari specificando i modelli statistici mediante la sintassi usata in \\(\\mathsf{R}\\);\nrstanarm - fornisce un sostituto per i modelli frequentisti forniti da base \\(\\mathsf{R}\\) e lme4 utilizzando la sintassi usata in \\(\\mathsf{R}\\) per la specificazione dei modelli statistici;\ncmdstanr - un‚Äôinterfaccia \\(\\mathsf{R}\\) per CmdStan.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#interfaccia-cmdstanpy",
    "href": "chapters/appendix/a46_stan.html#interfaccia-cmdstanpy",
    "title": "Appendice P ‚Äî Linguaggio Stan",
    "section": "P.2 Interfaccia cmdstanpy",
    "text": "P.2 Interfaccia cmdstanpy\nNegli esempi di questa dispensa verr√† utilizzata l‚Äôinterfaccia cmdstanpy. CmdStanPy √® una interfaccia di Stan per gli utenti Python, che fornisce gli oggetti e le funzioni necessarie per condurre l‚Äôinferenza bayesiana su un modello di probabilit√† e dei dati. Essa racchiude l‚Äôinterfaccia a riga di comando di CmdStan in un piccolo insieme di classi Python, le quali offrono metodi per analizzare e gestire l‚Äôinsieme risultante di modello, dati e stime a posteriori.\nPer l‚Äôinstallazione di CmdStanPy, si segua il link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#codice-stan",
    "href": "chapters/appendix/a46_stan.html#codice-stan",
    "title": "Appendice P ‚Äî Linguaggio Stan",
    "section": "P.3 Codice Stan",
    "text": "P.3 Codice Stan\nStan consente agli utenti di definire un modello bayesiano attraverso il linguaggio Stan. Questo modello, di solito, viene salvato in un file di testo con estensione .stan.\nIl codice Stan deve poi essere compilato. Il processo di compilazione di un modello in Stan avviene in due fasi: innanzitutto, Stan traduce il modello dal formato .stan in codice C++, il quale viene successivamente compilato in codice macchina.\nDopo la compilazione del modello (ovvero, dopo che il codice macchina √® stato generato), l‚Äôutente pu√≤ utilizzare l‚Äôinterfaccia prescelta (per esempio, CmdStan) per campionare la distribuzione definita dal modello e per eseguire altri calcoli correlati al modello stesso.\nIl codice Stan √® costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono: data, transformed data, parameters, transformed parameters, model, e generated quantities.\n\nP.3.1 Blocco data\nNel blocco data vengono specificate le variabili di input che saranno utilizzate nel modello Stan. Per ciascuna variabile, √® necessario definire il tipo di dato e le dimensioni, oltre a eventuali vincoli sui valori che le variabili possono assumere.\nPer esempio\ndata {\n  int&lt;lower=0&gt; ntrials; // Numero di prove\n  int&lt;lower=0&gt; y; // Successi osservati\n  real&lt;lower=0&gt; alpha_prior; // Parametro alpha per il prior Beta\n  real&lt;lower=0&gt; beta_prior; // Parametro beta per il prior Beta\n}\nEcco una sintesi dei tipi di dati e delle specifiche che possono essere dichiarate:\n\nint: rappresenta numeri interi.\nreal: designa numeri reali, inclusi quelli con parte decimale.\nvector: si riferisce a un vettore unidimensionale di numeri reali.\nmatrix: indica una matrice bidimensionale di numeri reali.\narray: descrive una sequenza ordinata di elementi che possono essere di qualsiasi tipo specificato, e pu√≤ avere pi√π di una dimensione.\n\n√à importante dichiarare le dimensioni di ciascuna variabile e, se necessario, applicare vincoli sui valori che queste possono assumere (ad esempio, specificando lower=0 e upper=1 per vincolare i valori tra 0 e 1). Questi vincoli sono utili per ottimizzare la stima dei parametri e garantire che il modello sia ben definito.\n\nP.3.1.1 Interi\nGli interi non vincolati vengono dichiarati utilizzando la parola chiave int. Ad esempio, la variabile N viene dichiarata come un intero nel seguente modo.\nint N;\nI tipi di dati interi possono essere vincolati per consentire valori solo in un intervallo specificato fornendo un limite inferiore, un limite superiore o entrambi. Ad esempio, per dichiarare N come un intero positivo, si utilizza quanto segue.\nint&lt;lower=1&gt; N;\n\n\nP.3.1.2 Reali\nLe variabili reali non vincolate vengono dichiarate utilizzando la parola chiave real. Ad esempio,\nreal theta;\nLe variabili reali possono essere limitate utilizzando la stessa sintassi degli interi. Per esempio, la variabile sigma pu√≤ essere dichiarata come non negativa come segue.\nreal&lt;lower=0&gt; sigma;\n\n\nP.3.1.3 Tipi di dati vettoriali e matriciali\nStan fornisce tre tipi di oggetti contenitore: array, vettori e matrici. I vettori e le matrici sono tipi di strutture dati pi√π limitati rispetto agli array. I vettori sono collezioni intrinsecamente unidimensionali di valori reali o complessi, mentre le matrici sono intrinsecamente bidimensionali. I vettori, le matrici e gli array non sono assegnabili tra loro, anche se le loro dimensioni sono identiche. Una matrice 3√ó4 √® un tipo di oggetto diverso in Stan rispetto a un array 3√ó4.\nI vettori e le matrici non possono essere tipizzati per restituire valori interi. Sono limitati a valori reali e complessi.\n\n\nP.3.1.4 Indicizzazione da 1\nVettori e matrici, cos√¨ come gli array, sono indicizzati a partire da uno (1) in Stan.\n\n\nP.3.1.5 Tipi di dati array\nStan supporta array di dimensioni arbitrarie. I valori in un array possono essere di qualsiasi tipo, in modo che gli array possano contenere valori che sono semplici reali o interi, vettori, matrici o altri array. Gli array sono l‚Äôunico modo per memorizzare sequenze di interi, e alcune funzioni in Stan, come le distribuzioni discrete, richiedono argomenti interi.\nUn array bidimensionale √® semplicemente un array di array. Quando viene fornito un indice a un array, restituisce il valore in quell‚Äôindice. Quando vengono forniti pi√π di un indice, questa operazione di indicizzazione √® concatenata. Ad esempio, se a √® un array bidimensionale, allora a[m, n] √® solo una abbreviazione per a[m][n].\n\n\nP.3.1.6 Dichiarazione di variabili array\nGli array sono dichiarati con la parola chiave array seguita dalle dimensioni racchiuse tra parentesi quadre, il tipo di elemento e il nome della variabile.\nPer esempio, la variabile n viene dichiarata come un array di cinque interi come segue.\narray[5] int n;\nUn array bidimensionale di valori interi con tre righe e quattro colonne viene dichiarato come segue.\narray[3, 4] int a;\nUn array di N numeri reali vincolati tra 0 e 1 viene dichiarato come segue.\nint&lt;lower=0&gt; N;\narray[N] real&lt;lower=0, upper=1&gt; y;\nUn array di N interi positivi viene dichiarato come segue.\nint&lt;lower=0&gt; N;\narray[N] int&lt;lower=0&gt; x;\n\n\nP.3.1.7 Vettori\nI vettori in Stan sono vettori colonna. I vettori sono dichiarati con una dimensione (cio√®, una dimensionalit√†). Ad esempio, un vettore reale tridimensionale di dimensione 3 viene dichiarato con la parola chiave vector, come segue.\nvector[3] u;\n\nP.3.1.7.1 Matrici\nLe matrici sono dichiarate con la parola chiave matrix insieme a un numero di righe e un numero di colonne. Ad esempio,\nmatrix[3, 3] A;\nmatrix[M, N] B;\ndichiara A come una matrice 3√ó3 e B come una matrice M√óN. Perch√© la seconda dichiarazione sia ben formata, le variabili M e N devono essere dichiarate come interi nel blocco dati o dati trasformati e prima della dichiarazione della matrice.\n\n\nP.3.1.7.2 Miscelazione di tipi di array, vettore e matrice\nArray, vettori riga, vettori colonna e matrici non sono interscambiabili in Stan. Quindi una variabile di uno qualsiasi di questi tipi fondamentali non √® assegnabile a nessuno degli altri, anche se le loro dimensioni sono identiche, n√© pu√≤ essere utilizzata come argomento dove √® richiesto l‚Äôaltro.\n\n\nP.3.1.7.3 Dizionari\n√à fondamentale che i dati forniti a Stan tramite CmdStanPy siano organizzati in un oggetto di tipo dizionario. In Python, un dizionario √® una collezione di coppie chiave-valore che permette di associare a ogni chiave (unica) un valore specifico. Quando si preparano i dati per un modello Stan utilizzando CmdStanPy, si crea un dizionario dove:\n\nOgni chiave corrisponde al nome di una variabile dichiarata nel blocco data del modello Stan.\nIl valore associato a ciascuna chiave rappresenta i dati effettivi da passare al modello per quella variabile.\n\nQuesta struttura consente di mappare direttamente le variabili definite nel modello Stan ai dati che si desidera analizzare, facilitando il processo di assegnazione dei dati e assicurando che ogni variabile riceva i dati corretti.\n\n\n\n\nP.3.2 Blocco parameters\nI parametri da stimare sono definiti all‚Äôinterno del blocco parameters.\nAd esempio, consideriamo il seguente codice, dove viene dichiarata la variabile theta per rappresentare una probabilit√†. Si notino i vincoli che specificano che i valori possibili per theta devono essere contenuti nell‚Äôintervallo [0, 1].\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Parametro stimato, limitato tra 0 e 1\n}\nCerto, ecco il testo corretto e migliorato:\n\n\nP.3.3 Sezione model\nNella sezione model, vengono definite le relazioni tra i dati osservati e i parametri del modello, insieme alle distribuzioni a priori di tali parametri.\nA titolo di esempio, il seguente codice assegna una distribuzione a priori Beta ai parametri alpha_prior e beta_prior per il parametro theta. La verosimiglianza specifica che il meccanismo generatore dei dati osservati y √® binomiale, con parametri ntrials e theta.\nmodel {\n  // Prior\n  theta ~ beta(alpha_prior, beta_prior);\n  \n  // Likelihood\n  y ~ binomial(ntrials, theta);\n}\nIl simbolo ~ √® chiamato tilde. In generale, possiamo leggerlo come ‚Äú√® distribuito come‚Äù, e questa notazione viene utilizzata come abbreviazione per definire distribuzioni. Pertanto, l‚Äôesempio sopra pu√≤ essere scritto anche come:\n\\[\np(\\theta \\mid \\alpha_p, \\beta_p) = \\text{Beta}(\\alpha_p, \\beta_p)\n\\]\ne\n\\[\np(y \\mid \\theta) = \\text{Binomiale}(y \\mid n, \\theta)\n\\]\nQuesta notazione compatta facilita la definizione delle relazioni probabilistiche nel modello.\nSe non specificata, Stan utilizza una distribuzione a priori uniforme tra meno infinito e pi√π infinito. Per ulteriori raccomandazioni sulle scelte delle distribuzioni a priori, √® possibile consultare questo link.\n\n\nP.3.4 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. √à possibile trasformare i parametri del modello; solitamente ci√≤ viene fatto nel caso dei modelli pi√π avanzati per consentire un campionamento MCMC pi√π efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantit√† che non fa parte del modello ma pu√≤ essere calcolata a partire dai parametri del modello, per ogni iterazione dell‚Äôalgoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\n\n\nP.3.5 Sintassi\nSi noti che il codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos‚Äôaltro. I punti e virgola non sono invece richiesti all‚Äôinizio di un ciclo o di un‚Äôistruzione condizionale, dove non viene assegnato nulla.\nIn STAN, qualsiasi stringa che segue // denota un commento e viene ignorata dal programma.\nUna descrizione dettagliata della sintassi del linguaggio Stan √® disponibile al seguente link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>¬† <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html",
    "href": "chapters/appendix/a47_first_order_markov.html",
    "title": "Appendice Q ‚Äî Catene di Markov",
    "section": "",
    "text": "Q.1 Classificazione degli Stati\nConsideriamo ora la terminologia usata per descrivere le varie caratteristiche di una catena di Markov.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "href": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "title": "Appendice Q ‚Äî Catene di Markov",
    "section": "",
    "text": "Q.1.1 Catene di Markov Irriducibili\nUna catena di Markov √® detta irriducibile se, per qualsiasi coppia di stati \\(i\\) e \\(j\\), esiste una probabilit√† positiva di passare dallo stato \\(i\\) allo stato \\(j\\) in un numero finito di passi. In altre parole, una catena irriducibile non ha stati isolati: ogni stato √® raggiungibile da qualsiasi altro stato.\n\n\nQ.1.2 Stati Ricorrenti\nUno stato \\(i\\) di una catena di Markov si dice ricorrente se, partendo da \\(i\\), la probabilit√† di ritornarvi √® uguale a 1. Questo implica che una volta raggiunto lo stato \\(i\\), √® garantito che la catena torner√† in \\(i\\) prima o poi. Gli stati ricorrenti possono essere ulteriormente classificati come:\n\nPositivamente ricorrenti: uno stato √® positivamente ricorrente se il tempo medio atteso per ritornare in quello stato, partendo da esso, √® finito.\nNullamente ricorrenti: uno stato √® nullamente ricorrente se il tempo medio atteso per ritornare in quello stato √® infinito.\nRicorrenti di Harris: sono stati ricorrenti che vengono visitati infinite volte quando il tempo tende all‚Äôinfinito, garantendo una certa frequenza di visita.\n\n\n\nQ.1.3 Aperiodicit√†\nUno stato \\(i\\) si dice aperiodico se il massimo comun divisore dei tempi di ritorno in \\(i\\) √® 1. In altre parole, uno stato √® aperiodico se non esiste un ciclo deterministico che vincola i tempi in cui la catena pu√≤ ritornare in quello stato. Una catena di Markov √® aperiodica se tutti i suoi stati sono aperiodici. L‚Äôaperiodicit√† evita che la catena rimanga bloccata in una sequenza ciclica fissa, permettendo un comportamento pi√π variegato nel tempo.\n\n\nQ.1.4 Stazionariet√†\nNella teoria delle catene di Markov, una distribuzione stazionaria \\(\\pi\\) √® una distribuzione di probabilit√† sugli stati tale che, se la catena parte con questa distribuzione iniziale, la distribuzione delle probabilit√† rimane invariata nel tempo. Matematicamente, se \\(\\pi\\) √® la distribuzione stazionaria, allora \\(\\pi P = \\pi\\), dove \\(P\\) √® la matrice di transizione della catena di Markov. La stazionariet√† √® fondamentale per analizzare il comportamento a lungo termine della catena, poich√© una volta raggiunta, la distribuzione di probabilit√† sugli stati rimane costante.\n\n\nQ.1.5 Ergodicit√†\nUna catena di Markov si dice ergodica se √® irriducibile e aperiodica, e tutti i suoi stati sono positivamente ricorrenti. Questo implica che la catena, nel lungo termine, visita tutti gli stati secondo una distribuzione di probabilit√† che diventa stabile (stazionaria) e non dipende dallo stato iniziale. La propriet√† di ergodicit√† √® cruciale in quanto garantisce che le medie temporali di una funzione sugli stati della catena convergono alle medie rispetto alla distribuzione stazionaria.\n\n\nQ.1.6 Convergenza\nLa convergenza di una catena di Markov si riferisce al processo mediante il quale la distribuzione di probabilit√† degli stati si avvicina alla distribuzione stazionaria \\(\\pi\\) man mano che il numero di passi \\(n\\) tende all‚Äôinfinito. In altre parole, indipendentemente dalla distribuzione iniziale degli stati, la distribuzione della catena dopo un lungo periodo di tempo sar√† vicina a \\(\\pi\\). Questo concetto √® strettamente legato alla stazionariet√†, poich√© la convergenza descrive il percorso verso l‚Äôequilibrio, mentre la stazionariet√† rappresenta lo stato di equilibrio raggiunto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#estensioni-del-modello-di-markov",
    "href": "chapters/appendix/a47_first_order_markov.html#estensioni-del-modello-di-markov",
    "title": "Appendice Q ‚Äî Catene di Markov",
    "section": "Q.2 Estensioni del modello di Markov",
    "text": "Q.2 Estensioni del modello di Markov\nOltre al modello di base, esistono diverse estensioni del processo di Markov che aumentano la sua capacit√† di rappresentare situazioni pi√π complesse.\n\nQ.2.1 Modello di Markov misto\nUn‚Äôestensione comune del modello di Markov √® il modello di Markov misto (Mixture Markov model, MMM), che considera la possibilit√† che una popolazione sia composta da sottogruppi distinti (cluster) con proprie probabilit√† di transizione. Ad esempio, possiamo immaginare di dividere una popolazione studentesca in due gruppi: quelli con alte prestazioni e quelli con basse prestazioni. Ogni gruppo ha una propria matrice di transizione che descrive la probabilit√† di rimanere o cambiare stato. Questo approccio permette di identificare sottogruppi latenti all‚Äôinterno della popolazione e pu√≤ essere utilizzato per raggruppare dati sequenziali in base a modelli di comportamento simili.\n\n\nQ.2.2 Modello di Markov nascosto\nUn‚Äôaltra estensione utile √® il modello di Markov nascosto (Hidden Markov model, HMM), utilizzato quando lo stato di interesse non pu√≤ essere osservato direttamente o quando vi √® un errore di misurazione nelle osservazioni. In un HMM, la catena di Markov opera a livello di stati nascosti, che generano o emettono stati osservati con diverse probabilit√†. Ad esempio, consideriamo l‚Äôabilit√† di uno studente come uno stato nascosto e il suo successo scolastico come uno stato osservato. Non possiamo misurare direttamente la vera abilit√† dello studente, ma possiamo stimarla dai punteggi dei test, che rappresentano le emissioni del loro stato di abilit√†. Questi modelli, noti come modelli di Markov nascosti misti (Mixture hidden Markov models, MHMM), combinano l‚Äôidea di cluster tempo-costanti con stati nascosti variabili nel tempo, permettendo di modellare popolazioni complesse con sottogruppi che si comportano in modo diverso nel tempo.\n\n\nQ.2.3 Sommario\nUna catena di Markov √® una sequenza di variabili aleatorie \\(X_0, X_1, X_2, \\ldots\\) che soddisfa la cosiddetta propriet√† di Markov. Questa propriet√† stabilisce che, dato lo stato attuale della catena, il futuro √® indipendente dal passato. Formalmente, questa propriet√† si esprime come:\n\\[\nP(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i) = q_{ij},\n\\]\ndove \\(q_{ij}\\) rappresenta la probabilit√† di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo. Queste probabilit√† di transizione sono organizzate in una matrice di transizione \\(Q = (q_{ij})\\), in cui ogni riga corrisponde a una distribuzione di probabilit√† condizionata sui possibili stati futuri dato l‚Äôattuale stato della catena.\nLa distribuzione di probabilit√† degli stati della catena dopo \\(n\\) passi pu√≤ essere calcolata moltiplicando la matrice di transizione \\(Q\\) elevata alla potenza \\(n\\) per il vettore di probabilit√† iniziale \\(s\\), che descrive la distribuzione di probabilit√† degli stati al tempo \\(0\\). In simboli, questo √® rappresentato da \\(sQ^n\\), che fornisce la distribuzione di probabilit√† marginale degli stati dopo \\(n\\) passi.\nGli stati di una catena di Markov possono essere classificati come ricorrenti o transitori. Uno stato √® ricorrente se la catena torna a questo stato ripetutamente nel tempo; √® transitorio se la catena potrebbe lasciare questo stato per non ritornarvi mai pi√π. Gli stati possono anche avere un periodo associato, definito come il massimo comun divisore dei numeri di passi necessari per ritornare allo stato stesso. Una catena di Markov √® detta irriducibile se √® possibile raggiungere qualsiasi stato da qualsiasi altro stato in un numero finito di passi, ed √® aperiodica se ogni stato ha periodo 1.\nUna distribuzione stazionaria di una catena di Markov √® una distribuzione di probabilit√† che rimane invariata nel tempo. Se la catena inizia con questa distribuzione, continuer√† a mantenerla in ogni passo successivo. Questa condizione si esprime matematicamente come \\(sQ = s\\), dove \\(s\\) √® il vettore di probabilit√† stazionaria e \\(Q\\) √® la matrice di transizione. Per una catena di Markov finita che √® irriducibile e aperiodica, esiste una distribuzione stazionaria unica verso la quale la catena converge indipendentemente dalla distribuzione iniziale.\nUn concetto importante nelle catene di Markov √® quello di reversibilit√†. Una catena di Markov √® detta reversibile se esiste una distribuzione di probabilit√† \\(s\\) tale che, per ogni coppia di stati \\(i\\) e \\(j\\), la condizione di reversibilit√† \\(s_i q_{ij} = s_j q_{ji}\\) sia soddisfatta. Questa condizione garantisce che \\(s\\) sia una distribuzione stazionaria per la catena. Le catene di Markov reversibili sono particolarmente utili in applicazioni pratiche come gli algoritmi di simulazione Monte Carlo, ad esempio l‚Äôalgoritmo di Metropolis-Hastings, poich√© permettono di progettare catene che convergono rapidamente alla distribuzione di probabilit√† desiderata.\n\n\nQ.2.4 Letteratura\nI metodi markoviani sono stati ampiamente utilizzati in vari ambiti della psicologia e dell‚Äôeducazione. Una delle applicazioni pi√π comuni di questi metodi √® il clustering dei dati sequenziali (T√∂rm√§nen et al. (2022); T√∂rm√§nen et al. (2023); Fincham et al. (2018)). Ad esempio, i modelli nascosti di Markov (HMM) sono stati utilizzati per raggruppare le sequenze di dati tracciati da sistemi di gestione dell‚Äôapprendimento (LMS) degli studenti, al fine di identificare i loro schemi di attivit√†, ovvero le tattiche e strategie di apprendimento (Fincham et al. (2018)). Un uso molto diffuso dei modelli di Markov di primo ordine √® quello di mappare le transizioni degli studenti tra diverse attivit√† di apprendimento. Per esempio, Matcha et al. (2020) ha utilizzato modelli di Markov di primo ordine per studiare i processi di transizione degli studenti tra diverse strategie di apprendimento. Altri usi includono lo studio delle transizioni tra diverse strategie di scrittura accademica (Peeters, Saqr, e Viberg (2020)), tra eventi di apprendimento autoregolato (Lim et al. (2023)), o all‚Äôinterno di contesti di apprendimento collaborativo (Saqr e L√≥pez-Pernas (2023)). Esempi pi√π specifici nell‚Äôambito psicologico comprendono lo studio delle influenze reciproche tra stati affettivi (Cipresso, Borghesi, e Chirico (2023)) e l‚Äôanalisi degli effetti psicologici che dipendono dal tempo nelle sequenze di decision-making (Gunawan et al. (2022)).\n\n\nQ.2.5 Stima dei Parametri del Modello\nI parametri di un modello di Markov, come le probabilit√† iniziali degli stati e le probabilit√† di transizione tra stati, possono essere stimati a partire dai dati utilizzando diversi metodi statistici. In questo corso, ci concentreremo sulla stima bayesiana utilizzando il software Stan, che offre una grande flessibilit√† nella definizione dei modelli e permette di ottenere stime precise.\nPer chiarire meglio, consideriamo l‚Äôesempio di un processo di Markov di primo ordine implementato in Stan. Immaginiamo di voler modellare un sistema meteorologico, come abbiamo discusso in precedenza. In questo contesto, potremmo voler stimare le probabilit√† iniziali di condizioni meteorologiche specifiche e le probabilit√† di transizione che descrivono come il tempo potrebbe cambiare da un giorno all‚Äôaltro.\ndata {\n  int&lt;lower=1&gt; N;           // Numero di osservazioni\n  int&lt;lower=1&gt; K;           // Numero di stati possibili (3 per Soleggiato, Piovoso, Nebbioso)\n  int&lt;lower=1, upper=K&gt; y[N]; // Sequenza di osservazioni (stati)\n}\n\nparameters {\n  simplex[K] P[K]; // Matrice di transizione delle probabilit√†\n}\n\nmodel {\n  for (n in 2:N) {\n    y[n] ~ categorical(P[y[n-1]]);\n  }\n}\nIn questo modello, usiamo la distribuzione categorical() per modellare le transizioni tra i tre stati meteorologici possibili.\nConsideriamo ora una situazione ancora pi√π semplice, come quella discussa nel Capitolo 84. In questo secondo caso, abbiamo una sequenza di prove con solo due stati: prova prova corretta (0) e prova sbagliata (1). Il nostro interesse √® la prestazione post-errore. Questo scenario si presta naturalmente all‚Äôuso della distribuzione bernoulli().\ndata {\n  int&lt;lower=1&gt; N;           // Numero di prove\n  int&lt;lower=0, upper=1&gt; y[N]; // Sequenza di risultati (0 = corretto, 1 = errore)\n}\n\nparameters {\n  real&lt;lower=0, upper=1&gt; p_error_given_correct;\n  real&lt;lower=0, upper=1&gt; p_error_given_error;\n}\n\nmodel {\n  for (n in 2:N) {\n    if (y[n - 1] == 1) {\n      y[n] ~ bernoulli(p_error_given_error);\n    } else {\n      y[n] ~ bernoulli(p_error_given_correct);\n    }\n  }\n}\nIn questo modello:\n\np_error_given_correct rappresenta la probabilit√† di errore dopo una prova corretta.\np_error_given_error rappresenta la probabilit√† di errore dopo un errore precedente.\n\nMentre nel modello Meteo avevamo tre stati (Soleggiato, Piovoso, Nebbioso), nel caso del modello Post-Errore abbiamo solo due stati (Corretto, Errore). Ci√≤ porta ad una differenza tra le funzioni di verosimiglianza che vengono utilizzate:\n\nModello Meteo: categorical();\nModello Post-Errore: bernoulli().\n\nDi conseguenza, la parametrizzazione dei modelli cambia:\n\nModello Meteo: Matrice di transizione completa (simplex[K] P[K]);\nModello Post-Errore: Due probabilit√† di transizione (p_error_given_correct, p_error_given_error)\n\nIn conclusione, il processo di Markov di primo ordine √® uno strumento potente per modellare sequenze di eventi con memoria limitata. L‚Äôimplementazione in Stan permette di effettuare inferenze su questi modelli, sia in contesti con molteplici stati (come le previsioni meteo) sia in scenari binari (come l‚Äôanalisi della prestazione post-errore).\n\n\n\n\nCipresso, Pietro, Francesca Borghesi, e Alice Chirico. 2023. ¬´Affects affect affects: A Markov chain¬ª. Frontiers in Psychology 14: 1162655.\n\n\nFincham, Ed, Dragan Ga≈°eviƒá, Jelena Jovanoviƒá, e Abelardo Pardo. 2018. ¬´From study tactics to learning strategies: An analytical method for extracting interpretable representations¬ª. IEEE Transactions on Learning Technologies 12 (1): 59‚Äì72.\n\n\nGunawan, David, Guy E Hawkins, Robert Kohn, Minh-Ngoc Tran, e Scott D Brown. 2022. ¬´Time-evolving psychological processes over repeated decisions.¬ª Psychological Review 129 (3): 438‚Äì56.\n\n\nLim, Lyn, Maria Bannert, Joep van der Graaf, Shaveen Singh, Yizhou Fan, Surya Surendrannair, Mladen Rakovic, Inge Molenaar, Johanna Moore, e Dragan Ga≈°eviƒá. 2023. ¬´Effects of real-time analytics-based personalized scaffolds on students‚Äô self-regulated learning¬ª. Computers in Human Behavior 139: 107547.\n\n\nMatcha, Wannisa, Dragan Gasevic, Jelena Jovanovic, Abelardo Pardo, Lisa Lim, Jorge Maldonado-Mahauad, Sheridan Gentili, Mar P√©rez-Sanagustƒ±ÃÅn, Yi-Shan Tsai, et al. 2020. ¬´Analytics of Learning Strategies: Role of Course Design and Delivery Modality Authors¬ª. Journal of Learning Analytics 7 (2): 45‚Äì71.\n\n\nPeeters, Ward, Mohammed Saqr, e Olga Viberg. 2020. ¬´Applying learning analytics to map students‚Äô self-regulated learning tactics in an academic writing course¬ª. In Proceedings of the 28th International Conference on Computers in Education, 1:245‚Äì54. September. Asia-Pacific Society for Computers in Education.\n\n\nSaqr, Mohammed, e Sonsoles L√≥pez-Pernas. 2023. ¬´The temporal dynamics of online problem-based learning: Why and when sequence matters¬ª. International Journal of Computer-Supported Collaborative Learning 18 (1): 11‚Äì37.\n\n\nT√∂rm√§nen, Tiina, Hanna J√§rvenoja, Mohammed Saqr, Jonna Malmberg, e Sanna J√§rvel√§. 2022. ¬´A person-centered approach to study students‚Äô socio-emotional interaction profiles and regulation of collaborative learning¬ª. In Frontiers in Education, 7:866612. Frontiers Media SA.\n\n\n‚Äî‚Äî‚Äî. 2023. ¬´Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups¬ª. British Journal of Educational Psychology 93: 48‚Äì70.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>¬† <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice R ‚Äî La funzione lineare",
    "section": "",
    "text": "La funzione lineare √® definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di questa funzione √® una retta, dove il parametro \\(b\\) rappresenta il coefficiente angolare e il parametro \\(a\\) rappresenta l‚Äôintercetta con l‚Äôasse delle \\(y\\). In altre parole, la retta interseca l‚Äôasse \\(y\\) nel punto \\((0,a)\\) se \\(b \\neq 0\\).\nPossiamo dare un‚Äôinterpretazione geometrica alle costanti \\(a\\) e \\(b\\) considerando la funzione:\n\\[\ny = b x.\n\\]\nQuesta funzione rappresenta un caso speciale, la proporzionalit√† diretta tra \\(x\\) e \\(y\\). Nel caso generale della funzione lineare:\n\\[\ny = a + b x,\n\\]\naggiungiamo una costante \\(a\\) a ciascun valore \\(y = b x\\). Nella funzione lineare, se il coefficiente \\(b\\) √® positivo, il valore di \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) √® negativo, il valore di \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\), la retta √® orizzontale e il valore di \\(y\\) non varia al variare di \\(x\\).\nConsideriamo ora il coefficiente \\(b\\) in modo pi√π dettagliato. Prendiamo un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\), come mostrato nella figura. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono chiamate ‚Äúincrementi‚Äù di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) √® definito come il rapporto\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\]\nindipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Per dare un‚Äôinterpretazione geometrica al coefficiente angolare (o pendenza) della retta, possiamo semplificare assumendo \\(\\Delta x = 1\\). In questo caso, \\(b\\) √® uguale a \\(\\Delta y\\).\n\n\n\n\n\n\nFigura¬†R.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nPossiamo dunque dire che la pendenza \\(b\\) di un retta √® uguale all‚Äôincremento \\(\\Delta y\\) associato ad un incremento unitario nella \\(x\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>¬† <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a51_r_squared.html",
    "href": "chapters/appendix/a51_r_squared.html",
    "title": "Appendice S ‚Äî Teorema della scomposizione della devianza",
    "section": "",
    "text": "S.1 Formulazione del Teorema\nDato un set di dati \\(y_1, y_2, \\dots, y_n\\), dove \\(y_i\\) rappresenta l‚Äôi-esimo valore della variabile dipendente, e \\(\\bar{y}\\) √® la media campionaria di \\(y\\), la devianza totale (o variazione totale) dei dati pu√≤ essere scomposta nel seguente modo:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>S</span>¬† <span class='chapter-title'>Teorema della scomposizione della devianza</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a51_r_squared.html#formulazione-del-teorema",
    "href": "chapters/appendix/a51_r_squared.html#formulazione-del-teorema",
    "title": "Appendice S ‚Äî Teorema della scomposizione della devianza",
    "section": "",
    "text": "Devianza Totale (VT): Misura la dispersione totale dei dati intorno alla loro media. \\[\nDT = \\sum_{i=1}^n (y_i - \\bar{y})^2\n\\]\nDevianza Spiegata (VS): Misura quanto della variazione totale √® spiegata dal modello di regressione.\n\\[\nDS = \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2\n\\]\ndove \\(\\hat{y}_i\\) √® il valore predetto dalla regressione per l‚Äôi-esimo osservazione.\nDevianza Residua (VR): Misura la variazione dei dati che il modello non riesce a spiegare. \\[\nDR = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n\\]\n\n\nS.1.1 Teorema di Scomposizione della Devianza\nIl teorema afferma che la variazione totale \\(DT\\) √® uguale alla somma della variazione spiegata \\(DS\\) e della variazione residua \\(DR\\):\n\\[\nDT = DS + DR\n\\]\n\n\nS.1.2 Dimostrazione\nLa dimostrazione di questa identit√† si basa sul principio di ortogonalit√† dei residui e delle stime. I residui \\(y_i - \\hat{y}_i\\) sono ortogonali alle predizioni \\(\\hat{y}_i - \\bar{y}\\) nel contesto della regressione lineare. Matematicamente, ci√≤ √® espresso da:\n\\[\n\\sum_{i=1}^n (\\hat{y}_i - \\bar{y})(y_i - \\hat{y}_i) = 0\n\\]\nUtilizzando l‚Äôortogonalit√†, possiamo scrivere la variazione totale come segue:\n\\[\n\\begin{align*}\nDT &= \\sum_{i=1}^n (y_i - \\bar{y})^2 \\\\\n   &= \\sum_{i=1}^n [(y_i - \\hat{y}_i) + (\\hat{y}_i - \\bar{y})]^2 \\\\\n   &= \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + 2\\sum_{i=1}^n (y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) + \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2 \\\\\n   &= DR + 2 \\cdot 0 + DS \\\\\n   &= DR + DS\n\\end{align*}\n\\]\nQuesta dimostrazione chiarisce che la variazione totale √® esattamente uguale alla somma della devianza spiegata dal modello e quella non spiegata (residua).\n\n\nS.1.3 Applicazione\nApplichiamo ora il teorema di scomposizione della devianza ai dati in esame. Usando pg.linear_regression(x, y) calcoliamo il coefficiente di determinazione.\nConsideriamo i dati forniti dal dataset kidiq.\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nCi concentreremo sulla relazione lineare tra l‚Äôintelligenza del bambino e l‚Äôintelligenza della madre.\nRinominiamo le due variabili di interesse.\n\nx = kidiq[\"mom_iq\"]\ny = kidiq[\"kid_score\"]\n\nUn diagramma a dispersione evidenzia un‚Äôassociazione tra le due variabili in esame, che pu√≤ essere ragionevolmente approssimata da una retta. Tuttavia, il grafico suggerisce anche che la relazione tra le variabili non sia particolarmente forte.\nIn questo contesto, ci poniamo il duplice obiettivo di individuare la retta che meglio si adatta ai dati del diagramma e di quantificare la bont√† di questo adattamento. In altre parole, vogliamo valutare quanto, in media, i punti del diagramma si discostano dalla retta individuata.\n\nplt.plot(x, y, \"x\")\nplt.xlabel(\"Intelligenza della madre\")\n_ = plt.ylabel(\"Intelligenza del bambino\")\n\n\n\n\n\n\n\n\nCalcoliamo i coefficienti del modello\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + e_i\n\\]\ncon il metodo della massima verosimiglianza. A questo scopo usiamo la funzione linear_regression() del pacchetto pingouin.\n\nlm = pg.linear_regression(x, y)\nlm.round(2)\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n25.80\n5.92\n4.36\n0.0\n0.2\n0.2\n14.17\n37.43\n\n\n1\nmom_iq\n0.61\n0.06\n10.42\n0.0\n0.2\n0.2\n0.49\n0.72\n\n\n\n\n\n\n\n\n\nr_squared = lm[\"r2\"][0] # R-squared del modello\nprint(r_squared)\n\n0.20095123075855126\n\n\nCalcoliamo la devianza totale.\n\nDT = np.sum((y - np.mean(y))**2)\nprint(DT)\n\n180386.15668202768\n\n\nCalcoliamo la devianza spiegata.\n\nDS = np.sum((yhat - np.mean(y)) ** 2)\nprint(DS)\n\n36248.82019705826\n\n\nCalcoliamo la devianza residua.\n\nDR = np.sum((y - yhat) ** 2)\nprint(DR)\n\n144137.33648496936\n\n\nLa devianza totale √® la somma della devianza spiegata e della devianza residua.\n\nDS + DR\n\n180386.15668202762\n\n\nIl coefficiente di determinazione √® il rapporto tra la devianza spiegata e la devianza totale.\n\nRsq = DS / DT\nprint(Rsq)\n\n0.2009512307585509\n\n\nCi√≤ significa che solo il 20% della devianza totale del QI dei bambini pu√≤ essere predetta dal QI delle madri in base ad un modello lineare in questo campione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>S</span>¬† <span class='chapter-title'>Teorema della scomposizione della devianza</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a55_rescorla_wagner.html",
    "href": "chapters/appendix/a55_rescorla_wagner.html",
    "title": "Appendice T ‚Äî Apprendimento per rinforzo",
    "section": "",
    "text": "T.1 Simulare l‚ÄôApprendimento\nIniziamo con il simulare il processo decisionale di un partecipante che sceglie tra due slot machine utilizzando il modello di apprendimento di Rescorla-Wagner.\nConfigurazione della simulazione:\nLa simulazione dei dati segue la procedura discussa nel Capitolo 86.\ndef simulate_RescorlaWagner(params, T, mu, noisy_choice=True):\n\n    alpha, theta = params\n    \n    # Un array di zeri di lunghezza T\n    c = np.zeros((T), dtype=int)\n    r = np.zeros((T), dtype=int)\n\n    # Un array multidimensionale di zeri di dimensione 2xT\n    Q_stored = np.zeros((2, T), dtype=float)\n    \n    # Inizializza Q per t == 0\n    Q = [0.5, 0.5]\n\n    for t in range(T):\n\n        # Salva i valori Q per Q_{t+1}\n        Q_stored[:, t] = Q\n\n        # Calcola le probabilit√† di scelta\n        p0 = np.exp(theta*Q[0]) / (np.exp(theta*Q[0]) + np.exp(theta*Q[1]))\n        p1 = 1 - p0\n        \n        # Se noisy_choice √® vero, viene simulato un comportamento di scelta rumoroso in \n        # cui l'opzione 0 √® scelta con probabilit√† p0, mentre l'opzione 1 √® scelta con \n        # probabilit√† 1-p0.\n        if noisy_choice:\n            if np.random.random_sample(1) &lt; p0:\n                c[t] = 0\n            else:\n                c[t] = 1\n        else:  # la scelta viene effettuata senza rumore\n            c[t] = np.argmax([p0, p1])\n\n        # Genera la ricompensa sulla base delle probabilit√† di ricompensa\n        r[t] = np.random.rand() &lt; mu[c[t]]\n\n        # Aggiorna le aspettative di valore\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    return c, r, Q_stored\nSimuliamo T = 100 prove utilizzando il modello generativo dei dati definito in precedenza.\nT = 100\nK = 2\nmu = [0.2, 0.8]\nc, r, Q = simulate_RescorlaWagner([.1, 2.5], T=T, mu=mu)\nRappresentiamo graficamente i risultati ottenuti dalla simulazione ‚Äì i dati sono identici a quelli del Capitolo 86.\nplt.plot(range(T), r, 'r--', alpha=.6)\nplt.plot(range(T), c, '+', label='scelta')\nplt.xlabel('Prove')\nplt.ylabel('Feedback (1=Ricompensa,\\n 0=Nessuna ricompensa)')\nplt.title(f'Apprendimento di Rescorla-Wagner')\nplt.show()\nIl grafico successivo mostra le aspettative di valore \\(Q\\) delle due slot machine nel corso delle prove.\nplt.plot(range(T), Q[1, :], 'r--', alpha=.6, label='80% machine')\nplt.plot(range(T), Q[0, :], 'm-', alpha=.6, label='20% machine')\nplt.plot(range(T), c, 'b+', label='choice')\nplt.xlabel('trials')\nplt.ylabel('value')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a55_rescorla_wagner.html#simulare-lapprendimento",
    "href": "chapters/appendix/a55_rescorla_wagner.html#simulare-lapprendimento",
    "title": "Appendice T ‚Äî Apprendimento per rinforzo",
    "section": "",
    "text": "Numero di tentativi: \\(T = 100\\). Significa che il partecipante far√† 100 scelte consecutive.\nNumero di slot machine: \\(K = 2\\). Il partecipante sceglier√† tra due slot machine ad ogni tentativo.\nProbabilit√† di ricompensa: \\(\\mu = [0.2, 0.8]\\). Ci√≤ significa che la Slot machine 1 ha una probabilit√† pari a 0.2 di offrire una ricompensa, mentre la Slot machine 2 ha una probabilit√† pari a 0.8 di offrire una ricompensa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a55_rescorla_wagner.html#la-massima-verosimiglianza",
    "href": "chapters/appendix/a55_rescorla_wagner.html#la-massima-verosimiglianza",
    "title": "Appendice T ‚Äî Apprendimento per rinforzo",
    "section": "T.2 La Massima Verosimiglianza",
    "text": "T.2 La Massima Verosimiglianza\nIl passo successivo √® stimare i parametri del modello a partire dai dati osservati. Esistono diversi metodi per stimare i parametri, ma in questa appendice ci concentreremo sull‚Äôapproccio della Massima Verosimiglianza.\nL‚Äôapproccio della massima verosimiglianza cerca di trovare i valori dei parametri del modello che massimizzano la probabilit√† dei dati osservati. In altre parole, vogliamo trovare i parametri \\((\\alpha, \\theta)\\) che rendono i dati osservati \\(d_{1:T}\\) pi√π probabili secondo il modello Rescorla-Wagner.\n\nT.2.1 Calcolo del Logaritmo della Verosimiglianza\nMassimizzare la verosimiglianza √® spesso pi√π facile se si lavora con il logaritmo della verosimiglianza, perch√© le moltiplicazioni di probabilit√† diventano somme. La log-verosimiglianza pu√≤ essere espressa come:\n\\[\n\\log \\mathcal{L} = \\log p(d_{1:T} | (\\alpha, \\theta)_m, m) = \\sum_{t=1}^T \\log p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\n\\]\nIn questa equazione:\n\n\\(\\log \\mathcal{L}\\) √® il logaritmo della verosimiglianza.\n\\(p(d_{1:T} | (\\alpha, \\theta)_m, m)\\) √® la probabilit√† dei dati osservati dato il modello e i parametri.\n\\(p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\\) √® la probabilit√† di ogni singola scelta \\(c_t\\) data la storia delle scelte e dei feedback fino al tempo \\(t\\) e i parametri del modello.\n\n\n\nT.2.2 Minimizzazione del Logaritmo Negativo della Verosimiglianza\nIn pratica, massimizzare la log-verosimiglianza √® equivalente a minimizzare il logaritmo negativo della verosimiglianza. Questo ci porta alla seguente equazione:\n\\[\n-\\log \\mathcal{L} = -\\sum_{t=1}^T \\log p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\n\\]\nPer applicare questa procedura al modello di Rescorla-Wagner, dobbiamo definire la funzione di log-verosimiglianza negativa specifica per il nostro modello. Questa funzione ci permette di calcolare quanto bene i parametri \\(\\alpha\\) e \\(\\theta\\) spiegano i dati osservati. Durante il processo di stima, l‚Äôobiettivo √® minimizzare questa funzione per trovare i valori ottimali dei parametri.\n\n\nT.2.3 Esempio Pratico\nImmaginiamo di avere dati osservati da un esperimento in cui un partecipante ha fatto 100 scelte tra due slot machine. Il nostro obiettivo √® stimare i parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\theta\\) (temperatura) che meglio spiegano queste scelte. Per fare ci√≤, utilizziamo il metodo della massima verosimiglianza.\nLa seguente funzione negll_RescorlaWagner calcola il negativo della log-verosimiglianza per il modello di apprendimento di Rescorla-Wagner. Questo ci permette di capire quanto bene i parametri del modello (\\(\\alpha\\) e \\(\\theta\\)) spiegano le scelte osservate. Ecco una spiegazione passo passo per capire come funziona questa funzione.\nI parametri della Funzione sono:\n\nparams: una lista che contiene i valori dei parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\theta\\) (temperatura).\nc: un array che contiene le scelte effettuate dal partecipante (0 o 1).\nr: un array che contiene le ricompense ricevute dopo ogni scelta (1 per ricompensa, 0 per nessuna ricompensa).\n\nEsaminiamo ora il corpo della funzione.\n\nInizializzazione dei Parametri\nalpha, theta = params\nQ = [0.5, 0.5]\nT = len(c)\nchoiceProb = np.zeros((T), dtype=float)\n\nalpha e theta sono estratti dalla lista params.\nQ √® una lista che tiene traccia delle aspettative di valore per le due slot machine, inizializzate a 0.5.\nT √® il numero di scelte effettuate.\nchoiceProb √® un array che memorizza la probabilit√† di ogni scelta effettuata.\n\nCalcolo delle Probabilit√† di Scelta e Aggiornamento dei Valori\nfor t in range(T):\n    p0 = np.exp(theta * Q[0]) / (np.exp(theta * Q[0]) + np.exp(theta * Q[1]))\n    p = [p0, 1 - p0]\n    choiceProb[t] = p[c[t]]\n    delta = r[t] - Q[c[t]]\n    Q[c[t]] = Q[c[t]] + alpha * delta\n\nCalcolo delle Probabilit√† di Scelta:\n\np0 √® la probabilit√† di scegliere la prima slot machine.\np √® una lista delle probabilit√† di scegliere ciascuna delle due slot machine.\nchoiceProb[t] memorizza la probabilit√† della scelta effettivamente fatta al tempo \\(t\\).\n\nAggiornamento delle Aspettative di Valore:\n\ndelta √® la differenza tra la ricompensa effettiva r[t] e l‚Äôaspettativa di valore Q[c[t]] per la scelta fatta.\nQ[c[t]] viene aggiornata secondo la regola di Rescorla-Wagner: il nuovo valore atteso √® il vecchio valore atteso pi√π una frazione (determinata da \\(\\alpha\\)) dell‚Äôerrore di previsione.\n\n\nCalcolo del Negativo della Log-Verosimiglianza\nnegLL = -np.sum(np.log(choiceProb))\nreturn negLL\n\nLog-Verosimiglianza:\n\nnp.log(choiceProb) calcola il logaritmo delle probabilit√† di scelta.\nnp.sum(np.log(choiceProb)) somma questi logaritmi.\n\nNegativo della Log-Verosimiglianza:\n\nIl risultato √® moltiplicato per -1 per ottenere il negativo della log-verosimiglianza, poich√© nella stima dei parametri cerchiamo di minimizzare questa funzione.\n\n\n\nIn sintesi, la funzione negll_RescorlaWagner:\n\nCalcola le probabilit√† di scelta basate sui parametri \\(\\alpha\\) e \\(\\theta\\).\nAggiorna le aspettative di valore in base alle scelte e alle ricompense osservate.\nCalcola il negativo della log-verosimiglianza per valutare quanto bene i parametri spiegano i dati osservati.\n\nEcco la funzione completa con commenti per facilitarne la comprensione:\n\ndef negll_RescorlaWagner(params, c, r):\n    alpha, theta = params\n    Q = [0.5, 0.5]\n    T = len(c)\n    choiceProb = np.zeros((T), dtype=float)\n\n    for t in range(T):\n        # Calcola le probabilit√† di scelta per k = 2\n        p0 = np.exp(theta * Q[0]) / (np.exp(theta * Q[0]) + np.exp(theta * Q[1]))\n        # \"p\" √® una lista di probabilit√† di scelta per le due opzioni disponibili\n        p = [p0, 1 - p0]\n\n        # Memorizza la probabilit√† della scelta effettuata\n        choiceProb[t] = p[c[t]]\n\n        # Aggiorna le aspettative di valore secondo la regola di Rescorla-Wagner\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    # Calcola il negativo della log-verosimiglianza\n    negLL = -np.sum(np.log(choiceProb))\n\n    return negLL\n\nSimuliamo ora un set di dati.\n\n# simulate choices from RW Model\nalpha = .2\ntheta = 1.5\nc, r, Q2 = simulate_RescorlaWagner([alpha, theta], T=T, mu=[.2, .8])\n\nPer fare un esempio, valutiamo la log-verosimiglianza negativa per i dati simulati in corrispondenza dei valori alpha e theta indicati di seguito.\n\nalpha_hat = 0.3\ntheta_hat = 2.5\nnegLL = negll_RescorlaWagner([alpha_hat, theta_hat], c, r)\nprint(alpha_hat, theta_hat, negLL)\n\n0.3 2.5 67.02432583559954\n\n\n\nalpha_hat = 0.2\ntheta_hat = 1.5\nnegLL = negll_RescorlaWagner([alpha_hat, theta_hat], c, r)\nprint(alpha_hat, theta_hat, negLL)\n\n0.2 1.5 62.40238018291291\n\n\nUn metodo per trovare i parametri di massima verosimiglianza √® effettuare una ricerca esaustiva su tutto lo spazio dei parametri. Questo significa selezionare i valori di alpha e theta per i quali la funzione negLL assume il valore pi√π basso.\nPer illustrare questo metodo, applichiamolo a un set di dati simulato. Per semplicit√†, assumiamo di conoscere il valore di \\(\\theta\\) e di dover trovare solo il valore di \\(\\alpha\\).\n\nnLL = []\nalpha_vals = np.linspace(0, 0.5, 1000)\nfor alpha_val in alpha_vals:\n    nLL.append(negll_RescorlaWagner([alpha_val, theta], c, r))\n\nplt.figure()\nplt.plot(alpha_vals, nLL, '-')\nplt.plot(\n    alpha_vals[np.argmin(nLL)], nLL[np.argmin(nLL)],\n    'X', label=r'optimal $\\hat \\alpha$'\n)\nplt.ylabel('negative log likelihood')\nplt.xlabel(fr'learning rate, $\\hat \\alpha$')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nT.2.4 Validazione\nUna volta stabilito un metodo per stimare i parametri del modello dai dati, dobbiamo valutare quanto accuratamente queste stime riflettano i veri valori dei parametri del modello. Per rispondere a questa domanda, possiamo condurre uno studio di simulazione.\nI parametri della simulazione sono i seguenti.\n\nT = 250\nmu = [0.2, 0.8]\nnum_subjects = 20\n\nCalcolimo i valori di massima verosimiglianza dei parametri alpha e theta usando la funzione minimize per minimizzare la funzione di log-verosimiglianza. Simuliamo i dati di un soggetto.\nSpecifichiamo poi le stime iniziali per i valori dei parametri e i valori margine delle possibili soluzioni. I risultati saranno salvati nell‚Äôoggetto result. Le stime dei due parametri si estraggono con result.x.\n\nc, r, Q = simulate_RescorlaWagner([0.15, 1.5], T=T, mu=mu)\n\ninit_guess = (0.1, 0.1)\n\n# minimize neg LL\nresult = minimize(\n    negll_RescorlaWagner,\n    init_guess,\n    (c, r),\n    bounds=((0, 1), (0, 10)),\n)\nprint(result.x)\n\n[0.1093135  1.27704408]\n\n\nSimuliamo i dati per 500 soggetti, con 250 osservazioni ciascuno, utilizzando valori casuali di alpha e theta. Successivamente, eseguiamo la stima di massima verosimiglianza per i dati di ogni soggetto, inizializzando casualmente i parametri per ciascuno di essi. Infine, salviamo i risultati ottenuti nel DataFrame df. Ecco il codice corrispondente:\n\nNREP = 500\ndf = pd.DataFrame(\n    index=range(0, NREP), columns=[\"true_alpha\", \"alpha\", \"true_theta\", \"theta\"]\n)\n\n# loop through subjects\nfor index in range(NREP):\n\n    true_alpha = 0.95 * np.random.random()\n    true_theta = 4.0 * np.random.random()\n\n    c, r, Q = simulate_RescorlaWagner([true_alpha, true_theta], T=250, mu=mu)\n\n    init_guess = (0.2 * np.random.random(), 1.0 * np.random.random())\n    # minimize neg LL\n    param_fits = minimize(\n        negll_RescorlaWagner,\n        init_guess,\n        (c, r),\n        bounds=((0, 1), (0, 10)),\n    )\n\n    # store in dataframe\n    df.at[index, \"true_alpha\"] = true_alpha\n    df.at[index, \"true_theta\"] = true_theta\n    df.at[index, \"alpha\"] = param_fits.x[0]\n    df.at[index, \"theta\"] = param_fits.x[1]\n\nLa figura successiva mostra una corrispondenza tra i valori stimati di alpha e i valori veri. √à importante notare che la corrispondenza non √® perfetta a causa della presenza di una componente di casualit√† nei dati. Inoltre, in alcuni casi si possono osservare valori stimati di alpha pari a 0 o 1, che corrispondono a risultati spurii dell‚Äôalgoritmo. Il numero di risultati spurii aumenta con il diminuire del numero di osservazioni per ciascun soggetto.\n\nplt.plot(df.true_alpha, df.alpha, 'ob', alpha=.4)\nplt.xlabel('True alpha')\nplt.ylabel('Estimated alpha')\nplt.title(f'ML estimation')\nplt.show()\n\n\n\n\n\n\n\n\nUn discorso analogo si pu√≤ fare per theta, anche se in questo caso vi √® una migliore corrispondenza tra i valori stimati e i valori veri.\n\nplt.plot(df.true_theta, df.theta, 'or', alpha=.4)\nplt.xlabel('True theta')\nplt.ylabel('Estimated theta')\nplt.title(f'ML estimation')\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, possiamo affermare che il metodo della massima verosimiglianza √® in grado di recuperare i valori simulati dei parametri \\(\\alpha\\) e \\(\\theta\\) del modello di Rescorla-Wagner, ma solo quando il numero di osservazioni per soggetto √® considerevole. Tuttavia, √® importante notare che questo metodo pu√≤ produrre risultati imprecisi in determinate circostanze.\nEsistono altri metodi di stima che offrono risultati migliori anche con un numero inferiore di osservazioni per soggetto. Tra questi, il metodo gerarchico bayesiano √® ampiamente utilizzato nella pratica. Va precisato che l‚Äôobiettivo di questo tutorial era principalmente illustrare in modo semplice come sia possibile ottenere con buona accuratezza i parametri del modello di Rescorla-Wagner dai dati generati da una simulazione, considerando condizioni ottimali in cui i valori dei parametri del modello sono noti.\n√à importante sottolineare che, nella pratica, la stima dei parametri pu√≤ essere un processo complesso e che l‚Äôaccuratezza delle stime dipende da molteplici fattori, come la dimensione del campione e la natura dei dati osservati. Pertanto, √® sempre consigliabile valutare attentamente i risultati e considerare l‚Äôutilizzo di approcci pi√π sofisticati, come il metodo gerarchico bayesiano, per ottenere stime pi√π affidabili dei parametri del modello.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a55_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/appendix/a55_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "title": "Appendice T ‚Äî Apprendimento per rinforzo",
    "section": "Informazioni sull‚ÄôAmbiente di Sviluppo",
    "text": "Informazioni sull‚ÄôAmbiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.14.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>¬† <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html",
    "href": "chapters/appendix/a60_ttest_exercises.html",
    "title": "Appendice U ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "",
    "text": "U.1 Inferenza statistica su una singola media",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#inferenza-statistica-su-una-singola-media",
    "href": "chapters/appendix/a60_ttest_exercises.html#inferenza-statistica-su-una-singola-media",
    "title": "Appendice U ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "",
    "text": "U.1.1 Test \\(t\\) di Student a un campione\nPer descrivere l‚Äôinferenza su una singola media consideriamo il seguente esempio. √à stato condotto uno studio di ricerca al fine di esaminare le differenze tra gli adulti anziani e quelli giovani sulla percezione della soddisfazione nella vita. Per testare questa ipotesi, √® stato effettuato uno studio pilota su dati ipotetici. Il test √® stato somministrato a dieci adulti anziani (oltre i 70 anni) e dieci adulti giovani (tra i 20 e i 30 anni). La scala di valutazione utilizzata ha un range di punteggi da 0 a 60, dove punteggi elevati indicano una maggiore soddisfazione nella vita e punteggi bassi indicano una minore soddisfazione. √à stata scelta una scala con elevata affidabilit√† e validit√†. I dati (fittizi) raccolti sono riportati di seguito.\n\nyounger = np.array([45, 38, 52, 48, 25, 39, 51, 46, 55, 46])\nolder = np.array([34, 33, 36, 38, 37, 40, 42, 43, 32, 36])\n\nPer ora, esaminiamo soltanto il gruppo degli adulti pi√π anziani. Si suppponga che studi precedenti indichino che, per questo gruppo d‚Äôet√†, la soddisfazione della vita misurata con questo test sia pari a 60. Svolgiamo il test t di Student usando l‚Äôipotesi nulla che nella popolazione la media sia effettivamente uguale a 40.\nInziamo a svolgere l‚Äôesercizio applicando la funzione ttest del modulo pingouin. Per l‚Äôesempio presente, poniamo \\(\\mu_0\\), la media dell‚Äôipotesi nulla, uguale a 40. Svolgiamo l‚Äôesercizio con ttest.\n\nres = pg.ttest(older, 40)\n\nEsaminiamo il risultato.\n\nprint(res)\n\n               T  dof alternative     p-val           CI95%   cohen-d   BF10  \\\nT-test -2.481666    9   two-sided  0.034896  [34.46, 39.74]  0.784772  2.319   \n\n           power  \nT-test  0.599895  \n\n\nInterpretazione. Dato che il valore-p √® minore di \\(\\alpha\\) = 0.05, ovvero in modo equivalente, dato che la statistica test cade nella regione di rifiuto, rifiutiamo \\(H_0: \\mu = 40\\).\nProcediamo ora con i calcoli passo-passo utilizzando la formula del test t di Student. La statistica \\(T\\) calcolata dal test √® definita come:\n\\[\nT = \\frac{\\bar{X} - \\mathbb{E}(\\bar{X})}{s / \\sqrt{n}} = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) √® la media campionaria, \\(\\mu_0\\) √® l‚Äôipotesi nulla sulla media della popolazione, \\(s\\) √® la deviazione standard campionaria e \\(n\\) √® la dimensione del campione. Tale statistica ha una semplice interpretazione: essa corrisponde alla standardizzazione della media del campione all‚Äôinterno della distribuzione campionaria delle medie di ampiezza \\(n\\) = 10. La distribuzione campionaria delle medie di ampiezza \\(n\\) = 10 ha media \\(\\mu_{\\bar{X}} = \\mu\\) e varianza \\(\\sigma^2_{\\bar{X}} = \\frac{\\sigma^2}{n}\\), dove \\(\\mu\\) √® la media della popolazione e \\(\\sigma^2\\) √® la varianza della popolazione da cui il campione √® stato estratto. Tuttavia, poich√© i parametri della popolazione sono sconosciuti, l‚Äôapproccio frequentista utilizza la media \\(\\mu_0\\) ipotizzata dall‚Äôipotesi nulla \\(H_0\\) al posto della media sconosciuta della popolazione e stima il parametro sconosciuto \\(\\sigma\\) con la deviazione standard \\(s\\) del campione. In queste circostanze, la statistica \\(T\\) segue la distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libert√† se il campione √® stato estratto da una popolazione normale.\nSvolgiamo i calcoli con Python.\n\nT = (np.mean(older) - 40) / (np.std(older, ddof=1) / np.sqrt(len(older)))\nT\n\n-2.481665888425312\n\n\nI gradi di libert√† sono \\(n-1\\).\n\ndf = len(older) - 1\nprint(df)\n\n9\n\n\nTroviamo il valore-p, ovvero l‚Äôarea sottesa alla distribuzione t di Student con 9 gradi di libert√† nei due intervalli \\([-\\infty, -T]\\) e \\([T, +\\infty]\\).\n\n# Set up the x-axis values for the t-distribution plot\nx = np.linspace(st.t.ppf(0.001, df), st.t.ppf(0.999, df), 1000)\n\n# Set up the y-axis values for the t-distribution plot\ny = st.t.pdf(x, df)\n\n# Create the t-distribution plot\nplt.plot(x, y, label=\"t-distribution\")\n\n# Shade the areas [-infinity, -T] and [T, +infinity]\nplt.fill_between(x[x &lt;= -T], y[x &lt;= -T], color=\"red\", alpha=0.2)\nplt.fill_between(x[x &gt;= T], y[x &gt;= T], color=\"red\", alpha=0.2)\n\n# Add vertical lines for T and -T\nplt.axvline(x=T, color=\"black\", linestyle=\"--\")\nplt.axvline(x=-T, color=\"black\", linestyle=\"--\")\n\n\n# Set the plot title and axis labels\nplt.title(f\"Distribuzione t di Student con {df} gradi di libert√†\")\nplt.xlabel(\"Valore t\")\nplt.ylabel(\"Densit√† di probabilit√†\")\nplt.show()\n\n\n\n\n\n\n\n\n\nst.t.cdf(T, df=len(older) - 1) * 2\n\n0.03489593108658913\n\n\n\n\nU.1.2 Intervallo di confidenza per una media\nCalcoliamo ora l‚Äôintervallo di confidenza al livello di fiducia del 95%. Come visto in precedenza, la procedura ttest ha calcolato l‚Äôintervallo di confidenza del 95% per la media della popolazione che va da 34.46 a 39.74. Questo intervallo pu√≤ essere interpretato come segue: se la stessa procedura venisse applicata molte volte, in circa il 95% dei casi l‚Äôintervallo ottenuto conterr√† il vero valore della media della popolazione.\nIniziamo a trovare il valore critico della distribuzione \\(t\\) di Student che lascia \\(\\alpha/2\\) in ciascuna coda.\n\nalpha = 0.05\ndf # 9\nt_c = st.t.ppf(1 - alpha / 2, df)\nt_c\n\n2.262157162854099\n\n\nL‚Äôintervallo di confidenza √® dato da\n\\[\n\\bar{X} \\pm t_{n-1} \\frac{s}{\\sqrt{n}}.\n\\]\nSvolgiamo i calcoli.\n\nci_lower = np.mean(older) - t_c * np.std(older, ddof=1) / np.sqrt(len(older))\nci_upper = np.mean(older) + t_c * np.std(older, ddof=1) / np.sqrt(len(older))\nprint(\"L'intervallo di confidenza al 95% per la media della popolazione √®: [{:.2f}, {:.2f}].\".format(ci_lower, ci_upper))\n\nL'intervallo di confidenza al 95% per la media della popolazione √®: [34.46, 39.74].",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#confronto-tra-medie-per-campioni-indipendenti",
    "href": "chapters/appendix/a60_ttest_exercises.html#confronto-tra-medie-per-campioni-indipendenti",
    "title": "Appendice U ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "U.2 Confronto tra medie per campioni indipendenti",
    "text": "U.2 Confronto tra medie per campioni indipendenti\n\nU.2.1 Test \\(t\\) di Student per campioni indipendenti\nPer eseguire il test t di Student per due campioni indipendenti, iniziamo svolgendo i calcoli con la funzione ttest del modulo pingouin. L‚Äôipotesi nulla √® che la differenza tra le medie delle due popolazioni sia uguale a 0: \\(\\mu_1 - \\mu_2 = 0\\). La funzione ttest implementa la seguente formula:\n\\[\nT = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\n    \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}.\n}},\n\\]\n\nres = pg.ttest(younger, older, paired=False)\nprint(res)\n\n               T  dof alternative    p-val          CI95%  cohen-d   BF10  \\\nT-test  2.479867   18   two-sided  0.02326  [1.13, 13.67]  1.10903  2.849   \n\n           power  \nT-test  0.650317  \n\n\nSvolgiamo i calcoli passo-passo.\n\nt_num = np.mean(younger) - np.mean(older)\nt_denom = np.sqrt(np.var(younger, ddof=1) / len(younger) + np.var(older, ddof=1) / len(older))\nT = np.divide(t_num, t_denom)\nT\n\n2.479866520313643\n\n\nLa statistica \\(T\\) calcolata sopra si distribuisce con \\((n_1 - 1) + (n_2 - 1)\\), ovvero \\(n_1 + n_2 - 2\\), gradi di libert√†.\n\ndf = len(younger) + len(older) - 2\nprint(df)\n\n18\n\n\nIl valore-p √® uguale all‚Äôarea sottesa alla funzione t di Student con \\(n_1 + n_2 - 2\\) negli intervalli \\([-\\infty, -T]\\) e \\([T, +\\infty]\\). Nel caso presente abbiamo\n\n(1 - st.t.cdf(T, df=df)) * 2\n\n0.023260241301116924\n\n\n\n\nU.2.2 Intervallo di confidenza per la differenza tra due medie\nCalcoliamo ora l‚Äôintervallo di confidenza al livello di fiducia del 95% per la differenza tra le due medie. Iniziamo a calcolare il valore critico \\(t\\).\n\nalpha = 0.05\nt_c = st.t.ppf(1 - alpha / 2, df)\nt_c\n\n2.10092204024096\n\n\nTroviamo l‚Äôerrore standard della differenza tra le due medie.\n\nse_diff = np.sqrt(np.var(younger, ddof=1) / len(younger) + np.var(older, ddof=1) / len(older))\nse_diff\n\n2.9840315756446754\n\n\nTroviamo i limiti inferiore e superiore dell‚Äôintervallo di confidenza al 95%.\n\nci_lower = (np.mean(younger) - np.mean(older)) - (t_c * se_diff)\nci_upper = (np.mean(younger) - np.mean(older)) + (t_c * se_diff)\nprint(\"L'intervallo di confidenza al 95% per la differenza tra le due medie √®: [{:.2f}, {:.2f}].\".format(ci_lower, ci_upper))\n\nL'intervallo di confidenza al 95% per la differenza tra le due medie √®: [1.13, 13.67].\n\n\nSi noti che i gradi di libert√† sono \\(n_1+n_2-2\\) quando le varianze delle due popolazioni sono uguali. La formula di Welch-Satterthwaite viene usata per approssimare i gradi di libert√† quando le due varianze non sono uguali:\n\\[\n\\nu \\approx \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1 - 1} + \\frac{(s_2^2/n_2)^2}{n_2 - 1}}\n\\]\ndove \\(\\nu\\) rappresenta i gradi di libert√† approssimati, \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie delle due popolazioni, \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni.\nNel caso di varianze diverse, l‚Äôargomento correction=True produce una correzione dei gradi di liberta con l‚Äôapprossimazione di Welch-Satterthwaite e il corrispondente valore-p.\n\nres1 = pg.ttest(younger, older, paired=False, correction=True)\nprint(res1)\n\n               T        dof alternative     p-val          CI95%  cohen-d  \\\nT-test  2.479867  12.156852   two-sided  0.028738  [0.91, 13.89]  1.10903   \n\n         BF10     power  \nT-test  2.849  0.650317  \n\n\nConsideriamo ora la statistica \\(d\\) di Cohen. Il \\(d\\) di Cohen √® una misura di effetto comunemente utilizzata per valutare la differenza tra le medie di due gruppi indipendenti. La formula del \\(d\\) di Cohen per la differenza di due medie indipendenti √® la seguente:\n\\[\nd = \\frac{\\bar{X}_1 - \\bar{X}_2}{s},\n\\]\ndove \\(\\bar{X}_1\\) e \\(\\bar{X}_2\\) sono le medie dei due gruppi, e \\(s\\) √® la deviazione standard raggruppata (pooled standard deviation), definita come:\n\\[\ns = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi e \\(s_1\\) e \\(s_2\\) sono le deviazioni standard dei due gruppi. Il \\(d\\) di Cohen pu√≤ essere interpretato come la differenza tra le medie dei due gruppi in unit√† di deviazioni standard raggruppate. Un valore di \\(d\\) di Cohen di 0.2 √® considerato un effetto piccolo, un valore di 0.5 √® considerato un effetto medio e un valore di 0.8 o superiore √® considerato un effetto grande.\nLa funzione ttest ha trovato un valore di 1.10903. Svolgiamo i calcoli passo-passo.\nIniziamo a calcolare la deviazione standard raggruppata (pooled standard deviation).\n\ns_pool_num = np.sum(\n    [\n        (len(younger) - 1) * np.std(younger, ddof=1) ** 2,\n        (len(older) - 1) * np.std(older, ddof=1) ** 2,\n    ]\n)\ns_pool_denom = len(younger) + len(older) - 2\n\ns_pool = np.sqrt(np.divide(s_pool_num, s_pool_denom))\ns_pool\n\n6.672497450147301\n\n\nTroviamo ora il \\(d\\) di Cohen.\n\nd = (np.mean(younger) - np.mean(older)) / s_pool\nprint(d)\n\n1.1090300229094336\n\n\nInterpretazione. Il risultato dell‚Äôanalisi suggerisce che la differenza nella soddisfazione nella vita tra i due gruppi di et√†, misurata tramite l‚Äôindice \\(d\\) di Cohen, √® considerevole in termini di dimensione dell‚Äôeffetto.\n\n\nU.2.3 PyMC\nSvolgiamo ora lo stesso esercizio usando l‚Äôinferenza Bayesiana. Utilizzeremo distribuzioni a priori ampie per garantire un risultato simile all‚Äôanalisi frequentista. Inseriamo i dati in un DataFrame.\n\ny = np.concatenate((younger, older))\nx = np.concatenate((np.repeat(1, len(younger)), np.repeat(0, len(older))))\ndf = pd.DataFrame({\"y\": y, \"x\": x})\ndf.head()\n\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n0\n45\n1\n\n\n1\n38\n1\n\n\n2\n52\n1\n\n\n3\n48\n1\n\n\n4\n25\n1\n\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n15\n40\n0\n\n\n16\n42\n0\n\n\n17\n43\n0\n\n\n18\n32\n0\n\n\n19\n36\n0\n\n\n\n\n\n\n\n\n\nsns.scatterplot(x=df[\"x\"], y=df[\"y\"])\nsns.regplot(x=df[\"x\"], y=df[\"y\"], ci=False)\n\n\n\n\n\n\n\n\nCreaimo il modello statistico corrispondente ad un modello di regressione con un predittore dicotomico codificato con 0 per il primo gruppo e con 1 per il secondo gruppo. Iniziamo con l‚Äôanalisi predittiva a priori per determinare se le distribuzioni a priori sono adeguate.\n\nwith Model() as model_p:\n\n    # Priors\n    alpha = Normal(\"alpha\", mu=0, sigma=50)\n    beta = Normal(\"beta\", mu=0, sigma=100)\n    sigma = pm.HalfNormal(\"sigma\", sigma=50)\n\n    # Expected value of outcome\n    mu = alpha + beta * x\n\n    # Likelihood of observations\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n\n    # Sampling\n    idata_p = pm.sample_prior_predictive(samples=50)\n\nSampling: [Y_obs, alpha, beta, sigma]\n\n\nUtilizzo lo script fornito dal sito di PyMC per generare casualmente un campione di rette di regressione dal modello utilizzando le distribuzioni a priori specificate.\n\n_, ax = plt.subplots()\n\nxp = xr.DataArray(np.linspace(0, 1, 11), dims=[\"plot_dim\"])\nprior = idata_p.prior\nyp = prior[\"alpha\"] + prior[\"beta\"] * xp\n\nax.plot(xp, yp.stack(sample=(\"chain\", \"draw\")), c=\"k\", alpha=0.4)\n\nax.set_ylabel(\"Soddisfazione della vita\")\nax.set_xlabel(\"Gruppo (codificato con 0 e 1)\")\nax.set_title(\"Distribuzione predittiva a priori\");\n\n\n\n\n\n\n\n\nSi noti che prior[\"alpha\"] √® un array che contiene 50 valori generati casualmente dal modello per il parametro alpha.\n\nprior[\"alpha\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'alpha' (chain: 1, draw: 50)&gt; Size: 400B\narray([[ 27.91316336,  -9.761233  ,  21.89391528, -14.56856298,\n         68.39580771, -37.42800408, -52.79004685,  90.34566945,\n        -53.22280112, -83.55364275,  -5.15598452, -15.56387412,\n         35.18040675,  45.55683681,  44.74212001,  52.60001141,\n          4.91303814, -13.8408394 , -29.8977839 ,   3.06879684,\n         50.20452599,  39.56802222,  28.65514305,  -7.73157439,\n        -18.9430296 ,  -4.08430141, -48.42185103, -36.97779067,\n         34.10768708, -51.30605918,  -4.31841036, -30.40509399,\n        -36.26374915,  36.98455803, -45.12949691, -37.09592811,\n        -35.53336193, -54.06503347, -75.56008329,   6.52612528,\n        -73.64141351,  28.0803143 ,  60.28700248, 108.42906955,\n        -51.10481884, -74.83993705, -16.03126424,  -8.95153788,\n        -12.08582618,   0.62408476]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49xarray.DataArray'alpha'chain: 1draw: 5027.91 -9.761 21.89 -14.57 68.4 ... -74.84 -16.03 -8.952 -12.09 0.6241array([[ 27.91316336,  -9.761233  ,  21.89391528, -14.56856298,\n         68.39580771, -37.42800408, -52.79004685,  90.34566945,\n        -53.22280112, -83.55364275,  -5.15598452, -15.56387412,\n         35.18040675,  45.55683681,  44.74212001,  52.60001141,\n          4.91303814, -13.8408394 , -29.8977839 ,   3.06879684,\n         50.20452599,  39.56802222,  28.65514305,  -7.73157439,\n        -18.9430296 ,  -4.08430141, -48.42185103, -36.97779067,\n         34.10768708, -51.30605918,  -4.31841036, -30.40509399,\n        -36.26374915,  36.98455803, -45.12949691, -37.09592811,\n        -35.53336193, -54.06503347, -75.56008329,   6.52612528,\n        -73.64141351,  28.0803143 ,  60.28700248, 108.42906955,\n        -51.10481884, -74.83993705, -16.03126424,  -8.95153788,\n        -12.08582618,   0.62408476]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nLo stesso si pu√≤ dire per beta.\n\nprior[\"beta\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'beta' (chain: 1, draw: 50)&gt; Size: 400B\narray([[  36.25169578,   -7.92409658,   78.11662091,  -77.30445403,\n          -2.91861005,   63.14901963, -120.4458863 , -122.9803336 ,\n         -29.99397584,  -79.06934517,  196.1112678 ,  -47.14082206,\n         -80.37696349, -105.18911559,   55.41040452,   81.30111272,\n          82.17672831,    5.54854267,   87.26233082,   80.28598144,\n        -143.41337086,  129.64063429,  -71.67569728,   -7.63877719,\n         103.65954504,  133.47888441, -179.02868192,  -69.95843954,\n         -93.39842188, -104.65997079,   21.09319786,  -73.99700599,\n          92.13556843,   44.7699911 ,  -23.466116  ,  115.23595245,\n         109.53955429, -106.70959991,   -3.47936206, -107.42657989,\n        -194.18473598, -113.7431577 ,    6.26294595,   13.49018829,\n           9.02114705,  -61.35179689, -116.75047565,  -28.45809619,\n          82.9444729 ,    6.62830301]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49xarray.DataArray'beta'chain: 1draw: 5036.25 -7.924 78.12 -77.3 -2.919 ... -61.35 -116.8 -28.46 82.94 6.628array([[  36.25169578,   -7.92409658,   78.11662091,  -77.30445403,\n          -2.91861005,   63.14901963, -120.4458863 , -122.9803336 ,\n         -29.99397584,  -79.06934517,  196.1112678 ,  -47.14082206,\n         -80.37696349, -105.18911559,   55.41040452,   81.30111272,\n          82.17672831,    5.54854267,   87.26233082,   80.28598144,\n        -143.41337086,  129.64063429,  -71.67569728,   -7.63877719,\n         103.65954504,  133.47888441, -179.02868192,  -69.95843954,\n         -93.39842188, -104.65997079,   21.09319786,  -73.99700599,\n          92.13556843,   44.7699911 ,  -23.466116  ,  115.23595245,\n         109.53955429, -106.70959991,   -3.47936206, -107.42657989,\n        -194.18473598, -113.7431577 ,    6.26294595,   13.49018829,\n           9.02114705,  -61.35179689, -116.75047565,  -28.45809619,\n          82.9444729 ,    6.62830301]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nL‚Äôarray xp √® un vettore unidimensionale di 11 elementi compresi tra 0 e 1.\n\nxp.shape\n\n(11,)\n\n\n\nxp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (plot_dim: 11)&gt; Size: 88B\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])\nDimensions without coordinates: plot_dimxarray.DataArrayplot_dim: 110.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nSi noti che l‚Äôxarray yp ha coordinate chain e draw.\n\nyp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (chain: 1, draw: 50, plot_dim: 11)&gt; Size: 4kB\narray([[[ 2.79131634e+01,  3.15383329e+01,  3.51635025e+01,\n          3.87886721e+01,  4.24138417e+01,  4.60390112e+01,\n          4.96641808e+01,  5.32893504e+01,  5.69145200e+01,\n          6.05396896e+01,  6.41648591e+01],\n        [-9.76123300e+00, -1.05536427e+01, -1.13460523e+01,\n         -1.21384620e+01, -1.29308716e+01, -1.37232813e+01,\n         -1.45156910e+01, -1.53081006e+01, -1.61005103e+01,\n         -1.68929199e+01, -1.76853296e+01],\n        [ 2.18939153e+01,  2.97055774e+01,  3.75172395e+01,\n          4.53289016e+01,  5.31405636e+01,  6.09522257e+01,\n          6.87638878e+01,  7.65755499e+01,  8.43872120e+01,\n          9.21988741e+01,  1.00010536e+02],\n        [-1.45685630e+01, -2.22990084e+01, -3.00294538e+01,\n         -3.77598992e+01, -4.54903446e+01, -5.32207900e+01,\n         -6.09512354e+01, -6.86816808e+01, -7.64121262e+01,\n         -8.41425716e+01, -9.18730170e+01],\n        [ 6.83958077e+01,  6.81039467e+01,  6.78120857e+01,\n          6.75202247e+01,  6.72283637e+01,  6.69365027e+01,\n          6.66446417e+01,  6.63527807e+01,  6.60609197e+01,\n          6.57690587e+01,  6.54771977e+01],\n...\n        [-7.48399371e+01, -8.09751167e+01, -8.71102964e+01,\n         -9.32454761e+01, -9.93806558e+01, -1.05515835e+02,\n         -1.11651015e+02, -1.17786195e+02, -1.23921375e+02,\n         -1.30056554e+02, -1.36191734e+02],\n        [-1.60312642e+01, -2.77063118e+01, -3.93813594e+01,\n         -5.10564069e+01, -6.27314545e+01, -7.44065021e+01,\n         -8.60815496e+01, -9.77565972e+01, -1.09431645e+02,\n         -1.21106692e+02, -1.32781740e+02],\n        [-8.95153788e+00, -1.17973475e+01, -1.46431571e+01,\n         -1.74889667e+01, -2.03347764e+01, -2.31805860e+01,\n         -2.60263956e+01, -2.88722052e+01, -3.17180148e+01,\n         -3.45638245e+01, -3.74096341e+01],\n        [-1.20858262e+01, -3.79137889e+00,  4.50306840e+00,\n          1.27975157e+01,  2.10919630e+01,  2.93864103e+01,\n          3.76808576e+01,  4.59753048e+01,  5.42697521e+01,\n          6.25641994e+01,  7.08586467e+01],\n        [ 6.24084763e-01,  1.28691506e+00,  1.94974537e+00,\n          2.61257567e+00,  3.27540597e+00,  3.93823627e+00,\n          4.60106657e+00,  5.26389687e+00,  5.92672717e+00,\n          6.58955747e+00,  7.25238777e+00]]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49\nDimensions without coordinates: plot_dimxarray.DataArraychain: 1draw: 50plot_dim: 1127.91 31.54 35.16 38.79 42.41 46.04 ... 4.601 5.264 5.927 6.59 7.252array([[[ 2.79131634e+01,  3.15383329e+01,  3.51635025e+01,\n          3.87886721e+01,  4.24138417e+01,  4.60390112e+01,\n          4.96641808e+01,  5.32893504e+01,  5.69145200e+01,\n          6.05396896e+01,  6.41648591e+01],\n        [-9.76123300e+00, -1.05536427e+01, -1.13460523e+01,\n         -1.21384620e+01, -1.29308716e+01, -1.37232813e+01,\n         -1.45156910e+01, -1.53081006e+01, -1.61005103e+01,\n         -1.68929199e+01, -1.76853296e+01],\n        [ 2.18939153e+01,  2.97055774e+01,  3.75172395e+01,\n          4.53289016e+01,  5.31405636e+01,  6.09522257e+01,\n          6.87638878e+01,  7.65755499e+01,  8.43872120e+01,\n          9.21988741e+01,  1.00010536e+02],\n        [-1.45685630e+01, -2.22990084e+01, -3.00294538e+01,\n         -3.77598992e+01, -4.54903446e+01, -5.32207900e+01,\n         -6.09512354e+01, -6.86816808e+01, -7.64121262e+01,\n         -8.41425716e+01, -9.18730170e+01],\n        [ 6.83958077e+01,  6.81039467e+01,  6.78120857e+01,\n          6.75202247e+01,  6.72283637e+01,  6.69365027e+01,\n          6.66446417e+01,  6.63527807e+01,  6.60609197e+01,\n          6.57690587e+01,  6.54771977e+01],\n...\n        [-7.48399371e+01, -8.09751167e+01, -8.71102964e+01,\n         -9.32454761e+01, -9.93806558e+01, -1.05515835e+02,\n         -1.11651015e+02, -1.17786195e+02, -1.23921375e+02,\n         -1.30056554e+02, -1.36191734e+02],\n        [-1.60312642e+01, -2.77063118e+01, -3.93813594e+01,\n         -5.10564069e+01, -6.27314545e+01, -7.44065021e+01,\n         -8.60815496e+01, -9.77565972e+01, -1.09431645e+02,\n         -1.21106692e+02, -1.32781740e+02],\n        [-8.95153788e+00, -1.17973475e+01, -1.46431571e+01,\n         -1.74889667e+01, -2.03347764e+01, -2.31805860e+01,\n         -2.60263956e+01, -2.88722052e+01, -3.17180148e+01,\n         -3.45638245e+01, -3.74096341e+01],\n        [-1.20858262e+01, -3.79137889e+00,  4.50306840e+00,\n          1.27975157e+01,  2.10919630e+01,  2.93864103e+01,\n          3.76808576e+01,  4.59753048e+01,  5.42697521e+01,\n          6.25641994e+01,  7.08586467e+01],\n        [ 6.24084763e-01,  1.28691506e+00,  1.94974537e+00,\n          2.61257567e+00,  3.27540597e+00,  3.93823627e+00,\n          4.60106657e+00,  5.26389687e+00,  5.92672717e+00,\n          6.58955747e+00,  7.25238777e+00]]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nL‚Äôistruzione yp = prior[\"alpha\"] + prior[\"beta\"] * xp genera i valori y per una serie di rette con coefficienti prior[\"alpha\"] e prior[\"beta\"]. Nel nostro caso, stiamo generando 50 rette perch√© abbiamo selezionato 50 valori di alpha e 50 valori di beta dalle distribuzioni a posteriori.\nNel contesto della modellazione bayesiana, il termine ‚Äúchain‚Äù si riferisce alla catena di campionamento di Markov Monte Carlo (MCMC). Durante il processo di campionamento, vengono eseguiti diversi passaggi successivi per ottenere campioni indipendenti dalla distribuzione a posteriori. Ogni passaggio viene chiamato ‚Äúdraw‚Äù o ‚Äúsample‚Äù. Pertanto, ‚Äúchain‚Äù rappresenta le catene di campionamento e ‚Äúdraw‚Äù rappresenta i singoli campioni all‚Äôinterno di ciascuna catena.\nL‚Äôistruzione yp.stack(sample=(\"chain\", \"draw\")) viene utilizzata per combinare le dimensioni ‚Äúchain‚Äù e ‚Äúdraw‚Äù al fine di ottenere un array multidimensionale che rappresenta i campioni di parametri estratti dalla distribuzione a posteriori. Ci√≤ facilita la visualizzazione e l‚Äôanalisi dei campioni.\nNotiamo che le pendenze delle rette di regressione generate casualmente dal modello, utilizzando le distribuzioni a priori specificate, presentano un intervallo pi√π ampio rispetto alle pendenze trovate nel campione osservato. Inoltre, il valore medio della variabile dipendente \\(y\\) nel campione √® incluso nella distribuzione a priori. Questo suggerisce che le scelte delle distribuzioni a priori siano appropriate per il modello.\nAvendo determinato le distribuzioni a priori, eseguiamo il campionamento MCMC.\n\nwith Model() as model:\n\n    # Priors\n    alpha = Normal(\"alpha\", mu=0, sigma=50)\n    beta = Normal(\"beta\", mu=0, sigma=50)\n    sigma = pm.HalfNormal(\"sigma\", sigma=50)\n\n    # Expected value of outcome\n    mu = alpha + beta * x\n\n    # Likelihood of observations\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n\n    # Sampling\n    idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, beta, sigma]\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 16 seconds.\n\n\n\n\n\n\n\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(idata, combined=True)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nNel contesto di un modello di regressione in cui i gruppi ‚Äúolder‚Äù e ‚Äúyounger‚Äù sono codificati rispettivamente come 0 e 1, la media del gruppo ‚Äúolder‚Äù pu√≤ essere interpretata come il valore di riferimento o l‚Äôintercetta del modello. In termini matematici, la media del gruppo ‚Äúolder‚Äù corrisponde al coefficiente Œ± (alpha) del modello di regressione. La differenza tra le medie dei due gruppi √® invece uguale al coefficiente beta.\nPer verificare, troviamo la media del gruppo ‚Äúolder‚Äù (codificato con x = 0).\n\nnp.mean(older)\n\n37.1\n\n\nCalcoliamo la differenza tra le medie dei due campioni.\n\nnp.mean(younger) - np.mean(older)\n\n7.399999999999999\n\n\nEsaminiamo ora le stime a posteriori dei due coefficienti del modello e gli intervalli di credibilit√† al 95%.\n\naz.summary(idata, hdi_prob=0.95)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n37.067\n2.260\n32.572\n41.284\n0.048\n0.034\n2210.0\n2191.0\n1.0\n\n\nbeta\n7.406\n3.250\n1.230\n14.012\n0.070\n0.050\n2142.0\n2151.0\n1.0\n\n\nsigma\n7.178\n1.278\n4.916\n9.771\n0.028\n0.020\n2183.0\n2007.0\n1.0\n\n\n\n\n\n\n\n\nI coefficienti alpha e beta nel modello di regressione assumono i valori previsti. L‚Äôintervallo di credibilit√† per il coefficiente beta pu√≤ essere interpretato nel seguente modo: si pu√≤ affermare con una certezza soggettiva del 95% che il gruppo ‚Äúyounger‚Äù tende ad avere una soddisfazione della vita che √® almeno 1.1 punti superiore e non pi√π di 14.1 punti superiore rispetto al gruppo ‚Äúolder‚Äù.\nUsiamo ora la funzione dedicata di PyMC per campionare le distribuzioni a posteriori per generare il posterior predictive check. La funzione sample_posterior_predictive estrarr√† casualmente 40000 campioni dei parametri del modello dalla traccia MCMC. Successivamente, per ogni campione, verranno estratti 100 numeri casuali da una distribuzione normale specificata dai valori di mu e sigma in quel campione:\n\nwith model:\n    pm.sample_posterior_predictive(idata, extend_inferencedata=True, random_seed=rng)\n\nSampling: [Y_obs]\n\n\n\n\n\n\n\n\n\n\n\nL‚Äôoggetto xarray ‚Äúposterior_predictive‚Äù in ‚Äúidata‚Äù conterr√† ora 40000 insiemi di dati (ciascuno contenente 100 valori), i quali sono stati generati utilizzando una diversa configurazione dei parametri dalle distribuzioni a posteriori di alpha e beta:\n\nidata.posterior_predictive\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 648kB\nDimensions:      (chain: 4, draw: 1000, Y_obs_dim_2: 20)\nCoordinates:\n  * chain        (chain) int64 32B 0 1 2 3\n  * draw         (draw) int64 8kB 0 1 2 3 4 5 6 ... 993 994 995 996 997 998 999\n  * Y_obs_dim_2  (Y_obs_dim_2) int64 160B 0 1 2 3 4 5 6 ... 13 14 15 16 17 18 19\nData variables:\n    Y_obs        (chain, draw, Y_obs_dim_2) float64 640kB 56.93 45.38 ... 29.89\nAttributes:\n    created_at:                 2024-05-07T04:19:22.885544+00:00\n    arviz_version:              0.18.0\n    inference_library:          pymc\n    inference_library_version:  5.14.0xarray.DatasetDimensions:chain: 4draw: 1000Y_obs_dim_2: 20Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Y_obs_dim_2(Y_obs_dim_2)int640 1 2 3 4 5 6 ... 14 15 16 17 18 19array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19])Data variables: (1)Y_obs(chain, draw, Y_obs_dim_2)float6456.93 45.38 44.72 ... 47.46 29.89array([[[56.93119105, 45.38112552, 44.71705033, ..., 36.6533742 ,\n         26.7945236 , 43.70073916],\n        [48.59795404, 49.14921972, 36.26414691, ..., 33.9800401 ,\n         43.64123915, 27.04789784],\n        [46.20305509, 37.31314497, 24.9156855 , ..., 34.63748569,\n         43.68189988, 25.00128306],\n        ...,\n        [41.88456655, 46.6706999 , 42.15297999, ..., 33.78602401,\n         45.84205574, 30.18639455],\n        [42.50078136, 51.06733118, 58.90315575, ..., 25.58896962,\n         23.22293853, 36.39028755],\n        [37.25135731, 33.72155053, 49.35109368, ..., 38.50069572,\n         43.37827239, 40.12896516]],\n\n       [[69.89704936, 44.89150638, 35.56737805, ..., 40.56827667,\n         24.40992124, 38.77930154],\n        [41.05292868, 34.71488032, 44.81629245, ..., 42.46278301,\n         44.84971018, 50.22855624],\n        [47.57661051, 44.39864842, 34.75311598, ..., 37.36811349,\n         52.05518433, 60.44519465],\n...\n        [46.36530415, 46.82141194, 43.99908701, ..., 33.36542914,\n         38.30912878, 24.24702688],\n        [58.0412549 , 40.54760807, 44.01622446, ..., 17.3388618 ,\n         29.39961152, 36.3022488 ],\n        [45.5066708 , 40.26978451, 45.96019551, ..., 27.45048685,\n         31.34425973, 27.56274796]],\n\n       [[49.10864016, 50.6347884 , 33.25334531, ..., 41.79996363,\n         56.15275593, 32.58161595],\n        [61.01484177, 45.19326455, 47.63829417, ..., 48.95528758,\n         33.60197361, 36.22097782],\n        [46.69327667, 52.18230406, 43.11523761, ..., 27.3596807 ,\n         41.88385917, 38.33724321],\n        ...,\n        [44.95070411, 36.79029201, 46.02741174, ..., 24.30896316,\n         21.17478346, 30.58681844],\n        [44.15401203, 43.59896216, 50.40780036, ..., 45.82617659,\n         29.65260042, 20.27135168],\n        [40.78029668, 41.79302778, 37.94651275, ..., 30.31091397,\n         47.45717734, 29.89154143]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Y_obs_dim_2PandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64', name='Y_obs_dim_2'))Attributes: (4)created_at :2024-05-07T04:19:22.885544+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.14.0\n\n\nPossiamo utilizzare questi dati per verificare se il modello √® in grado di riprodurre le caratteristiche osservate nel campione. Per fare ci√≤, possiamo utilizzare la funzione plot_ppc fornita da ArviZ:\n\naz.plot_ppc(idata, num_pp_samples=200);\n\n\n\n\n\n\n\n\nOsserviamo che i dati generati dal modello seguono l‚Äôandamento dei dati osservati, indicando che il modello √® adeguato per i dati considerati. Inoltre, notiamo che il modello produce campioni di dati molto diversi tra loro. Questa variazione √® coerente considerando che il campione osservato era di dimensioni ridotte e quindi vi √® un‚Äôampia incertezza associata alle caratteristiche dei campioni futuri.\nEseguiamo ora l‚Äôanalisi di regressione sugli stessi dati usando il metodo dei minimi quadrati. A questo fine usiamo la funzione linear_regression del modulo pingouin.\n\npg.linear_regression(df['x'], df['y'])\n\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n37.1\n2.110029\n17.582697\n8.790692e-13\n0.25465\n0.213242\n32.666994\n41.533006\n\n\n1\nx\n7.4\n2.984032\n2.479867\n2.326024e-02\n0.25465\n0.213242\n1.130782\n13.669218\n\n\n\n\n\n\n\n\nLa stima dei coefficienti √® altamente coerente con quella ottenuta utilizzando PyMC. L‚Äôintervallo di fiducia per il coefficiente b, che rappresenta la differenza tra le medie dei due gruppi, presenta una somiglianza notevole con l‚Äôintervallo di credibilit√† bayesiano.\nTuttavia, √® importante sottolineare che, anche se in questo caso specifico l‚Äôapproccio frequentista produce risultati simili all‚Äôapproccio bayesiano, non √® possibile generalizzare questa conclusione a tutti i casi. Le differenze tra i due approcci possono emergere in scenari diversi e richiedono un‚Äôanalisi caso per caso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#project-star",
    "href": "chapters/appendix/a60_ttest_exercises.html#project-star",
    "title": "Appendice U ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "U.3 Project Star",
    "text": "U.3 Project Star\nSvolgiamo ora un altro esercizio usando dei dati reali relativi al progetto Star. Il Project STAR (Student-Teacher Achievement Ratio) √® stato un grande esperimento educativo condotto negli Stati Uniti tra il 1985 e il 1990. L‚Äôobiettivo era quello di esaminare l‚Äôeffetto della dimensione delle classi sulla performance degli studenti. In particolare, gli studenti venivano assegnati in modo casuale a classi di piccole dimensioni (13-17 studenti) o grandi dimensioni (22-25 studenti).\nIl progetto coinvolse pi√π di 6.000 studenti e 1.000 insegnanti in 79 scuole elementari in Tennessee. I risultati dello studio indicarono che gli studenti assegnati a classi pi√π piccole hanno ottenuto risultati migliori in termini di performance accademica, partecipazione in classe, comportamento e assenze rispetto agli studenti assegnati a classi pi√π grandi.\nIn questo capitolo, analizziamo una parte dei dati del Project STAR. Come variabili abbiamo i punteggi ottenuti dagli studenti ai test standardizzati di lettura e matematica alla fine del terzo anno, insieme alla percentuale di studenti che hanno completato gli studi superiori.\nL‚Äôobiettivo dell‚Äôesercizio √® calcolare la media dell‚Äôeffetto causale della frequenza delle classi piccole rispetto alle classi di dimensioni standard sui punteggi dei test di lettura di terza elementare per tutta la popolazione target di studenti.\nLeggiamo i dati dal file STAR.csv.\n\ndf_star = pd.read_csv(\"../data/STAR.csv\")\ndf_star.head()\n\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\n\nLe medie dei due gruppi sono le seguenti.\n\ngroup_means = df_star.groupby('classtype')[\"reading\"].mean()\nprint(group_means)\n\nclasstype\nregular    625.492017\nsmall      632.702564\nName: reading, dtype: float64\n\n\nGeneriamo un violin plot per i punteggi nel test di lettura di terza elementare per i due gruppi.\n\nsns.violinplot(x=\"classtype\", y=\"reading\", data=df_star)\n\n\n\n\n\n\n\n\nL‚Äôipotesi nulla √® che i dati provengono da due popolazioni aventi la stessa media: \\(H_0: \\mu_1 - \\mu_2 = 0\\). Useremo un test bilaterale, ovvero rifiuteremo \\(H_0\\) sia quando il valore \\(T\\) cade nella regione di rifiuto perch√© \\(\\mu_1 &gt; \\mu_2 = 0\\), sia quando cade nella regione di rifiuto perch√© \\(\\mu_1 &lt; \\mu_2 = 0\\).\nPer semplicit√†, credo due DataFrame, uno per ciascun gruppo.\n\ndf_small = df_star[df_star['classtype'] == 'small']\ndf_regular = df_star[df_star['classtype'] == 'regular']\n\nSvolgo il test \\(t\\) di Student per due gruppi indipendenti con la funzione ttest.\n\nres = pg.ttest(df_small[\"reading\"], df_regular[\"reading\"], paired=False)\nprint(res)\n\n               T          dof alternative    p-val          CI95%   cohen-d  \\\nT-test  3.495654  1220.993525   two-sided  0.00049  [3.16, 11.26]  0.197183   \n\n          BF10     power  \nT-test  25.771  0.938789  \n\n\nInterpretazione. Avendo ottenuto un valore-p minore di \\(\\alpha\\), si conclude rifiutando l‚Äôipotesi nulla di uguaglianza delle due medie. Si presti per√≤ attenzione al \\(d\\) di Cohen: \\(d\\) = 0.20. Ci√≤ significa che la dimensione dell‚Äôeffetto √® piccola.\nSvolgiamo ora i calcoli passo-passo. Calcoliamo la differenza tra le medie dei due gruppi.\n\nmean_diff = np.mean(df_small[\"reading\"]) - np.mean(df_regular[\"reading\"])\nmean_diff\n\n7.210546686018347\n\n\nTroviamo i gradi di libert√† per la differenza tra due medie indipendenti.\n\nnum_rows = df_star.shape[0]\nnum_rows\n\n1274\n\n\n\ndof = 2 * num_rows - 2\ndof\n\n2546\n\n\nTroviamo il valore critico per un test bilaterale.\n\nt_c = st.t.ppf(0.975, dof)\nt_c\n\n1.9608961841574426\n\n\nSe non assumiamo che le due varianze siano uguali, allora l‚Äôerrore standard per la differenza tra le medie di due gruppi indipendenti √®\n\\[\n\\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}.\n\\]\n\nse_diff = np.sqrt(\n    np.var(df_small[\"reading\"], ddof=1) / len(df_small[\"reading\"]) +\n    np.var(df_regular[\"reading\"], ddof=1) / len(df_regular[\"reading\"])\n    )\nse_diff\n\n2.0627173626882493\n\n\nTroviamo il valore della statistica \\(T\\).\n\nT = mean_diff / se_diff\nprint(T)\n\n3.4956542357413216\n\n\nTroviamo il valore-p.\n\n(1 - st.t.cdf(T, df=dof)) * 2\n\n0.0004809856733483109\n\n\nCalcoliamo ora l‚Äôintervallo di fiducia al 95% per la differenza tra le medie dei due gruppi:\n\\[\n(\\bar{X}_1 - \\bar{X}_2) \\pm t_{n_1 + n_2 - 2} \\cdot \\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}.\n\\]\n\npm = np.array([-1, +1])\nci = mean_diff + pm * (t_c * se_diff)\nprint(ci)\n\n[ 3.16577208 11.25532129]\n\n\nInterpretazione. Dai risultati ottenuti, si pu√≤ concludere che l‚Äôeffetto causale medio di frequentare una classe piccola sui punteggi dei test di lettura di terza elementare, per tutti gli studenti della popolazione target, √® probabilmente un aumento compreso tra 3.17 e 11.25 punti.\n\nU.3.1 Margine d‚Äôerrore\nEsiste un modo alternativo di esprimere gli intervalli di confidenza, che √® popolare nel mondo dei sondaggi. Coinvolge l‚Äôuso di ci√≤ che √® noto come ‚Äúmargine di errore‚Äù, definito come la met√† della larghezza dell‚Äôintervallo di confidenza. Utilizzando questo termine, possiamo esprimere l‚Äôintervallo di confidenza come:\n\\[\n\\text{stimatore} \\pm \\text{margine di errore.}\n\\]\nPer i dati presenti, possiamo dire che frequentare una classe piccola produce un incremento atteso di 7.21 ¬± 4.04 punti sui punteggi dei test di lettura di terza elementare. L‚Äôampiezza dell‚Äôintervallo di confidenza √® qui di 8.08 punti, quindi il margine di errore √® di 4.04 punti.\nSi deve notare la differenza concettuale tra il risultato espresso in termini di intervallo di confidenza o margine d‚Äôerrore, che rappresenta una differenza assoluta tra le medie dei due gruppi, e l‚Äôindice \\(d\\) di Cohen, il quale rappresenta una differenza relativa tra le medie dei due gruppi, ponderata in base all‚Äôincertezza della stima. In altre parole, mentre il margine d‚Äôerrore esprime la precisione della stima assoluta della differenza tra le medie, l‚Äôindice \\(d\\) di Cohen esprime la dimensione dell‚Äôeffetto relativo tra i due gruppi, tenendo conto della variazione naturale dei dati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#inferenza-su-una-proporzione",
    "href": "chapters/appendix/a60_ttest_exercises.html#inferenza-su-una-proporzione",
    "title": "Appendice U ‚Äî Esercizi sull‚Äôinferenza frequentista",
    "section": "U.4 Inferenza su una proporzione",
    "text": "U.4 Inferenza su una proporzione\nOccupiamoci ora dell‚Äôinferenza sulla proporzione di una popolazione. La teoria delle probabilit√† ci dice che il valore atteso della proporzione campionaria \\(\\hat{p}\\) √® la proporzione \\(p\\) della popolazione e che la deviazione standard della proporzione campionaria √® la deviazione standard della variabile casuale binomiale \\(Y\\) divisa per \\(n\\):\n\\[\\begin{align}\n\\mu_{\\hat p}&=\\frac{\\mu_Y}{n} = p \\\\\n\\sigma_{\\hat p} &=\\frac{\\sigma_Y}{n} = \\frac{\\sqrt{n \\cdot p \\cdot (1-p)}}{n} = \\sqrt{\\frac{p \\cdot (1-p)}{n}}\n\\end{align}\\]\nQuesto punto pu√≤ essere chiarito da una simulazione. Supponiamo di esaminare 10000 campioni casuali di ampiezza 10 estratti da una popolazione nella quale la probabilit√† di ‚Äúsuccesso‚Äù √® 0.6.\n\np = 0.6\nn = 10\nX = st.bernoulli(p)\nY = [X.rvs(n) for i in range(10000)]\n\nI primi 5 campioni sono i seguenti.\n\nY[0:5]\n\n[array([0, 0, 1, 1, 0, 1, 0, 1, 0, 1]),\n array([0, 0, 0, 1, 1, 1, 1, 0, 0, 1]),\n array([0, 1, 1, 1, 0, 1, 1, 0, 0, 1]),\n array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1]),\n array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0])]\n\n\n\n_ = plt.hist(np.sum(Y, axis=1), density=True)\n\n\n\n\n\n\n\n\nL‚Äôistogramma precedente √® un‚Äôapprossimazione empirica della distribuzione delle proporzioni campionarie di ampiezza 10 estratte da una popolazione con probabilit√† di successo uguale a 0.6.\n\nprint('Media empirica della distribuzione campionaria: {}'.format(np.mean(np.mean(Y, axis=1))))\nprint('Valore teorico atteso: {}'.format(p))\n\nMedia empirica della distribuzione campionaria: 0.5986799999999999\nValore teorico atteso: 0.6\n\n\n\nprint('Stima empirica della deviazione standard: {}'.format(np.std(np.mean(Y, axis=1))))\nprint('Deviazione standard teorica: {}'.format(np.sqrt(p*(1-p)/n)))\n\nStima empirica della deviazione standard: 0.154939528849161\nDeviazione standard teorica: 0.15491933384829668\n\n\nMan mano che aumenta il numero di campioni estratti dalla popolazione, i due valori diventano sempre pi√π simili.\nPer quel che riguarda la forma della distribuzione, come conseguenza del TLC possiamo dire che la distribuzione delle proporzioni campionarie tende sempre pi√π ad assumere una forma normale all‚Äôaumentare della dimensione dei campioni.\nPer mettere alla prova il TLC, consideriamo un caso estremo, ovvero una popolazione nella quale la probabilit√† di successo √® 0.03. Supponiamo che la numerosit√† campionaria sia uguale a 400.\n\np = 0.03\nn = 400\nX = st.bernoulli(p)\nY = [X.rvs(n) for i in range(10000)]\n\n\nprint('Media empirica della distribuzione campionaria: {}'.format(np.mean(np.mean(Y, axis=1))))\nprint('Valore teorico atteso: {}'.format(p))\n\nMedia empirica della distribuzione campionaria: 0.029917250000000003\nValore teorico atteso: 0.03\n\n\n\nprint('Stima empirica della deviazione standard: {}'.format(np.std(np.mean(Y, axis=1))))\nprint('Deviazione standard teorica: {}'.format(np.sqrt(p*(1-p)/n)))\n\nStima empirica della deviazione standard: 0.008587201373992577\nDeviazione standard teorica: 0.00852936105461599\n\n\n\nnp.mean(Y, axis=1)\n\narray([0.03  , 0.04  , 0.0275, ..., 0.045 , 0.0325, 0.035 ])\n\n\n\ny = np.mean(Y, axis=1)\nsns.distplot(y, bins=10, hist=True, kde=False, norm_hist=True, hist_kws={'edgecolor':'black'})\nx = np.linspace(0, 0.1, 1000)\ny = st.norm.pdf(x, np.mean(y), np.std(y))  # Normal density values\nplt.plot(x, y, 'r-', label='Normal Density')\n\n\n\n\n\n\n\n\n\nU.4.1 Brexit\nPrendiamo in considerazione un ulteriore relativo all‚Äôindagine BES condotta prima del referendum sulla Brexit del 2016 al fine di valutare l‚Äôopinione pubblica dell‚Äôintera popolazione del Regno Unito. Importiamo i dati.\n\nbes = pd.read_csv(\"../data/BES.csv\")\nbes.head()\n\n\n\n\n\n\n\n\n\nvote\nleave\neducation\nage\n\n\n\n\n0\nleave\n1.0\n3.0\n60\n\n\n1\nleave\n1.0\nNaN\n56\n\n\n2\nstay\n0.0\n5.0\n73\n\n\n3\nleave\n1.0\n4.0\n64\n\n\n4\ndon't know\nNaN\n2.0\n68\n\n\n\n\n\n\n\n\n\nbes.shape\n\n(30895, 4)\n\n\nEliminiamo le righe del DataFrame che contengono dati mancanti.\n\nbes_cleaned = bes.dropna()\nbes_cleaned.shape\n\n(25097, 4)\n\n\nCalcoliamo la proporzione di risposte ‚Äúleave‚Äù.\n\nbes_cleaned[\"leave\"].mean()\n\n0.47188907040682154\n\n\nL‚Äôoutput del sondaggio BES indica che il 47.19% dei partecipanti era a favore della Brexit. Tuttavia, non possiamo inferire da questo risultato che circa il 47% di tutti gli elettori del Regno Unito era a favore della Brexit, poich√© si tratta di un risultato a livello di campione. Per generalizzare a livello di popolazione, dobbiamo considerare la variabilit√† campionaria che introduce rumore nei nostri risultati.\nAbbiamo visto sopra che la distribuzione campionaria di una proporzione presenta le seguenti caratteristiche:\n\nLa media della distribuzione campionaria di una proporzione √® uguale alla proporzione della popolazione. Ci√≤ significa che in media, la proporzione dei valori del campione √® uguale alla proporzione della popolazione.\nLa deviazione standard della distribuzione campionaria di una proporzione √® calcolata come \\(\\sqrt{\\pi (1-\\pi) / n}\\), dove \\(\\pi\\) rappresenta la proporzione della popolazione e \\(n\\) √® la dimensione del campione. La deviazione standard rappresenta la dispersione dei valori del campione intorno alla proporzione della popolazione. Possiamo stimare l‚Äôerrore standard sostituendo \\(\\pi\\) con \\(p\\), la proporzione campionaria.\nLa distribuzione campionaria di una proporzione tende alla normale se la dimensione del campione √® grande.\n\nPer fare inferenze sul parametro \\(\\pi\\) della popolazione (la proporzione di elettori del Regno Unito a favore della Brexit nel 2016), possiamo costruire un intervallo di confidenza al 95% per la proporzione nella popolazione.\nPer iniziare il calcolo dell‚Äôintervallo di confidenza, dobbiamo prima determinare la dimensione del campione.\n\nn = bes_cleaned.shape[0]\nn\n\n25097\n\n\nPossiamo stimare l‚Äôerrore standard di una proporzione con la formula $ SE = . $\n\np = bes_cleaned[\"leave\"].mean()\nse = np.sqrt(p * (1 - p) / n)\nprint(se)\n\n0.0031511685382488307\n\n\nTroviamo il limite inferiore e il limite superiore dell‚Äôintervallo di fiducia al 95%.\n\npm = np.array([-1, +1])\nci = np.mean(bes_cleaned[\"leave\"]) + pm * st.norm.ppf(0.975) * se\nprint(f\"L'intervallo di fiducia al 95% √® [{ci[0]:.4f}, {ci[1]:.4f}].\")\n\nL'intervallo di fiducia al 95% √® [0.4657, 0.4781].\n\n\nSecondo l‚Äôapproccio frequentista, √® possibile affermare che la proporzione di sostegno per la Brexit tra tutti gli elettori del Regno Unito nel 2016 era compresa con una probabilit√† del 95% tra il 46.57% e il 47.81%. Questo intervallo di confidenza √® stato ottenuto mediante una procedura di stima con un livello di confidenza del 95%, il quale indica la probabilit√† che l‚Äôintervallo contenga il vero valore del parametro.\nInoltre, il margine di errore, che rappresenta la met√† della larghezza dell‚Äôintervallo di confidenza, √® di 0.62 punti percentuali. Ci√≤ significa che la proporzione di sostegno per la Brexit tra tutti gli elettori del Regno Unito nel 2016 era probabilmente del 47.19%, con un margine di errore di 0.62 punti percentuali.\nSi noti che il margine di errore dipende dalla dimensione del campione. Nel caso del sondaggio BES, che ha una grande dimensione del campione di 25097 osservazioni, il margine di errore √® relativamente piccolo. Tuttavia, per la maggior parte dei sondaggi che hanno una dimensione del campione molto pi√π piccola, di circa 1000 osservazioni, il margine di errore sar√† molto pi√π grande. In generale, all‚Äôaumentare della dimensione del campione, la larghezza dell‚Äôintervallo di confidenza diminuisce, e viceversa.\n\n\nU.4.2 Supporto per la Brexit ed et√†\nCon i dati del sondaggio BES facciamo un altro esempio relativo al confronto tra due medie indipendenti. Nello specifico, esamineremo la differenza d‚Äôet√† tra gli elettori che hanno espresso supporto per la Brexit e quelli che invece hanno sostenuto la posizione ‚Äústay‚Äù.\n\nsns.violinplot(x=\"leave\", y=\"age\", data=bes)\n\n\n\n\n\n\n\n\nIl violin plot rivela che l‚Äôet√† media dei sostenitory della posizione ‚Äúleave‚Äù √® pi√π alta dell‚Äôet√† media del gruppo ‚Äústay‚Äù. Si noti per√≤ che le due distribuzioni non sembrano gaussiane.\nPer verificare l‚Äôipotesi di gaussianit√† dei dati, usiamo un QQ-plot (Quantile-Quantile plot). Un QQ-plot √® uno strumento grafico utilizzato per verificare se una distribuzione di dati segue o meno una distribuzione teorica, come ad esempio una distribuzione normale. In pratica, un QQ-plot confronta i quantili di una distribuzione di dati con quelli di una distribuzione teorica, disegnando un grafico dei quantili teorici lungo l‚Äôasse x e dei quantili dei dati lungo l‚Äôasse y. Se i dati seguono la distribuzione teorica, allora i punti nel QQ-plot si distribuiranno lungo una linea retta. Se invece ci sono deviazioni dalla distribuzione teorica, i punti nel QQ-plot si discosteranno dalla retta e si potr√† individuare in che punto si verificano le maggiori deviazioni.\n\nax = pg.qqplot(bes[\"age\"], dist=\"norm\")\n\n\n\n\n\n\n\n\nSi pu√≤ osservare dal QQ-plot che i valori di et√† estremi della distribuzione differiscono marcatamente dalle corrispondenti aspettative teoriche. Solo per fare un esecizio, proseguiamo comunque con l‚Äôanalisi dei dati e applichiamo il test t di Student ai due gruppi d‚Äôet√†. Si noti per√≤ che, per dati non normali, una tale procedura di analisi statistica √® inappropriata.\nPossiamo anche visualizzare i dati dei due gruppi tramite un KDE plot (da notare che questa rappresentazione √® gi√† inclusa nel violin plot precedente).\n\nsns.kdeplot(data=bes, x=\"age\", hue=\"leave\")\n\n\n\n\n\n\n\n\nPer agevolare il test t di Student, dividiamo il DataFrame originale in due DataFrame distinti.\n\nleave_df = bes[bes[\"leave\"] == 1]\nstay_df = bes[bes[\"leave\"] == 0]\n\nL‚Äôipotesi nulla che viene sottoposta a verifica con il test t di Student √® l‚Äôuguaglianza delle medie dei valori dell‚Äôet√† nelle due popolazioni da cui i campioni sono stati estratti: \\(H_0: \\mu_{\\text{leave}} = \\mu_{\\text{stay}}\\). Il test t di Student pu√≤ essere facilmente eseguito utilizzando la funzione ttest del pacchetto pingouin.\n\nres = pg.ttest(leave_df[\"age\"], stay_df[\"age\"], paired=False)\nprint(res)\n\n                T           dof alternative  p-val         CI95%   cohen-d  \\\nT-test  41.588603  27738.840259   two-sided    0.0  [7.63, 8.38]  0.495062   \n\n       BF10  power  \nT-test  inf    1.0  \n\n\nSvolgiamo ora i calcoli applicando la formula del test t di Student. La statistica \\(t\\) di Student per la differenza tra le medie di due campioni indipendenti √®\n\\[T = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}},\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}2\\) sono le medie dei due campioni, \\(s^2_1\\) e \\(s^2_2\\) sono le varianze dei due campioni e \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni.\n\nn_l = leave_df.shape[0]\nn_l\n\n13692\n\n\n\nn_s = stay_df.shape[0]\nn_s\n\n14352\n\n\n\nn_l + n_s - 2\n\n28042\n\n\nCalcoliamo l‚Äôerrore standard della differenza delle medie di due campioni indipendenti.\n\nse = np.sqrt(\n    (np.var(leave_df[\"age\"], ddof=1) / n_l) + \n    (np.var(stay_df[\"age\"], ddof=1) / n_s)\n) \nse\n\n0.19250126816432642\n\n\nTroviamo la statistica t di Student.\n\nT = (np.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])) / se\n\nTroviamo il valore-p con la funzione t.sf che calcola l‚Äôarea sottesa alla funzione \\(t\\) nella coda di destra. √à importante notare che le funzioni Python che abbiamo utilizzato in precedenza calcolano i gradi di libert√† in modo diverso rispetto alla formula \\(n_1+n_2-2\\). Infatti, il numero di gradi di libert√† calcolato come \\(n_1+n_2-2\\) √® appropriato solo quando le varianze delle due popolazioni sono uguali. Se le varianze sono diverse, √® necessario introdurre un fattore di correzione, che viene calcolato mediante software. Tuttavia, per questo esercizio, procederemo con \\(n_1+n_2-2\\), poich√© per un valore \\(t\\) cos√¨ estremo non fa alcuna differenza.\n\n2 * st.t.sf(T, df = n_l + n_s - 2)\n\n0.0\n\n\nPoniamoci ora l‚Äôobiettivo di trovare l‚Äôintervallo di fiducia per la differenza tra le due medie. Iniziamo a trovare il valore critico della distribuzione \\(t\\) corrispondente al livello di significativit√† scelto.\n\nt_c = st.t.ppf(0.975, df=n_l + n_s - 2)\nt_c\n\n1.9600485852064147\n\n\nPossiamo ora trovare l‚Äôintervallo di fiducia.\n\npm = np.array([-1, +1])\nci = (np.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])) + pm * t_c * se\nprint(f\"L'intervallo di fiducia al 95% √® [{ci[0]:.2f}, {ci[1]:.2f}].\")\n\nL'intervallo di fiducia al 95% √® [7.63, 8.38].\n\n\nIn conclusione, l‚Äôintervallo di confidenza al 95% per la differenza di et√† media tra i sostenitori della Brexit e coloro che sostenevano la posizione ‚Äòstay‚Äô √® [7.63, 8.38]. Ci√≤ significa che, utilizzando una procedura di stima corretta nel 95% dei casi, ci si aspetta che l‚Äôet√† media dei sostenitori della Brexit sia 8 anni superiore a quella dei sostenitori della posizione ‚Äòstay‚Äô, con un‚Äôincertezza di +/- 0.375 anni.\n\nnp.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])\n\n8.00585876624487\n\n\n\n(8.38 - 7.63) / 2\n\n0.37500000000000044",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>¬† <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html",
    "href": "chapters/appendix/a70_predict_counts.html",
    "title": "Appendice V ‚Äî La predizione delle frequenze",
    "section": "",
    "text": "V.1 La ricerca sul trauma\nPer fare un esempio di questo approccio, in questo capitolo faremo riferimento alla ricerca sul trauma. In questo campo di ricerca, come in altri, il risultato di interesse pu√≤ essere rappresentato dalla frequenza del numero di episodi che si verificano in un dato periodo di tempo. Nel caso della ricerca sulla violenza domestica, ad esempio, potremmo esaminare il tasso di atti aggressivi durante l‚Äôintervallo tra un momento temporale di baseline e un‚Äôintervista di follow-up. Altri esempi di risultati esprimibili in termini di frequenze nalla ricerca post-traumatica includono la frequenza dell‚Äôabuso di sostanze durante un periodo di osservazione o il numero di interventi della polizia durante un dato periodo.\nNell‚Äôesempio seguente esamineremo l‚Äôuso della predizione bayesiana per predire il numero di aggressioni nei confronti del partner nelle relazioni di coppia. I dati presentati sono tratti da uno studio che esamina la frequenza di episodi di aggressione messi in atto da pazienti di sesso maschile che avevano recentemente iniziato un programma di trattamento dell‚Äôalcol nei confronti del loro partner di sesso femminile.\nLa frequenza degli episodi di violenza, cos√¨ come altri fenomeni quantificabili in termini di frequenze assolute, pu√≤ essere modellata da un processo di Poisson, che si basa sul presupposto che gli eventi siano casuali e abbiano la stessa probabilit√† di verificarsi in qualsiasi momento. Naturalmente, questa ipotesi non √® sempre valida, ma spesso √® sufficiente per la modellazione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-priori",
    "href": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-priori",
    "title": "Appendice V ‚Äî La predizione delle frequenze",
    "section": "V.2 La distribuzione a priori",
    "text": "V.2 La distribuzione a priori\nIn una ricerca sui pazienti che avevano recentemente iniziato un programma di trattamento per l‚Äôabuso o la dipendenza da alcol, {cite:t}gagnon2008poisson hanno trovato che, in un periodo di 6 mesi, il numero di assalti fisici da parte dei pazienti di genere maschile nei confronti del loro partner femminile √® uguale, in media, a 11.46 (\\(SD\\) = 25.79; \\(n\\) = 114).\nPer questi dati, √® dunque sensato pensare che la distribuzione del numero di episodi di aggressione fisica pu√≤ essere rappresentata dalla distribuzione esponenziale.\nDal punto di vista statistico, ricordiamo che la distribuzione esponenziale modella il numero di eventi che si verificano in un intervallo di tempo quando questi eventi si verificano raramente e indipendentemente l‚Äôuno dall‚Äôaltro.\nLa funzione di densit√† di probabilit√† della distribuzione esponenziale √® data da:\n\\[\nf(x) = Œªe^{(-Œªx)}\n\\]\ndove Œª √® il parametro della distribuzione e rappresenta il tasso medio di occorrenza degli eventi. La media e la varianza della distribuzione esponenziale sono entrambe uguali a 1/Œª.\nPoniamoci dunque il problema di rappresentare le nostre credenze a priori relative al numero di episodi di aggressione fisica mediante una distribuzione esponenziale.\nDalla ricerca di {cite:t}gagnon2008poisson sappiamo che, in un periodo di 6 mesi, il numero di assalti fisici nei confronti del partner femminile, in questa popolazione, √® uguale a 11.46.\nConsidereremo una distribuzione esponenziale per rappresentare le nostre credenze a priori circa la frequenza media \\(\\mu\\) degli episodi di aggressione nei confronti del partner per questa popolazione, in un periodo di 6 mesi. In Python, scipy.stats.expon √® un modulo che fornisce funzioni per lavorare con la distribuzione esponenziale. In particolare, la funzione pdf (probability density function) calcola la funzione di densit√† di probabilit√† della distribuzione esponenziale per un dato valore di x.\nLa sintassi per utilizzare questa funzione √® la seguente:\nscipy.stats.expon.pdf(x, loc=0, scale=1)\ndove x √® il valore per il quale si vuole calcolare la funzione di densit√† di probabilit√†. Il parametro loc(opzionale) e scale specificano rispettivamente la posizione e la scala della distribuzione. La posizione (loc) di solito √® impostata a 0, mentre la scala (scale) √® l‚Äôinverso del parametro Œª della distribuzione esponenziale. In altre parole, la scala √® uguale alla media della distribuzione esponenziale.\nPer il caso presente, dunque, se vogliamo che la distribuzione esponenziale abbia una media di 11.46, procediamo come indicato sotto\n\nx = np.linspace (0, 50, 100) \ny = st.expon.pdf(x, 0, 11.46)\nplt.plot(x, y);\n\n\n\n\n\n\n\n\nPer verificare che abbiamo implementato correttamente la funzione esponenziale con il parametro voluto, estraiamo un grande numero di realizzazioni della v.c. e calcoliamo la media.\n\nr = st.expon.rvs(0, 11.46, size=100000)\nr.mean()\n\n11.438957034038369",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#inferenza-bayesiana",
    "href": "chapters/appendix/a70_predict_counts.html#inferenza-bayesiana",
    "title": "Appendice V ‚Äî La predizione delle frequenze",
    "section": "V.3 Inferenza bayesiana",
    "text": "V.3 Inferenza bayesiana\nUna volta capito come descrivere le nostre credenze a priori, poniamoci il problema di usare PyMC per l‚Äôinferenza Bayesiana.\nConsideriamo un singlo individuo di genere maschile appartenente a questa popolazione. Se, in media, in 6 mesi ci aspettiamo un numero di episodi di violenza pari a 11.46, possiamo descrivere il numero di episodi di violenza per un singolo individuo con la seguente distribuzione esponenziale. Si noti che, in questo caso, la funzione pm.Exponential √® parametrizzata usando il parametro l che √® uguale a \\(\\lambda = 1/ \\mu\\).\n\nl = 1/11.46\n\nwith pm.Model() as model:\n    mu = pm.Exponential(\"mu\", l)\n    idata = pm.sample_prior_predictive(samples=10000, random_seed=rng)\n\nSampling: [mu]\n\n\nEsaminiamo 10000 campioni casuali estratti dalla distribuzione a priori. Il risultato √® simile alla distribuzione di densit√† teorica rappresentata nel grafico precedente.\n\n_ = az.plot_posterior(idata.prior.mu);\n\n\n\n\n\n\n\n\nSi noti che, in questo caso, stiamo usando una distribuzione a priori informativa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-verosimiglianza",
    "href": "chapters/appendix/a70_predict_counts.html#la-verosimiglianza",
    "title": "Appendice V ‚Äî La predizione delle frequenze",
    "section": "V.4 La verosimiglianza",
    "text": "V.4 La verosimiglianza\nAdesso inseriamo nel modello PyMC la verosimiglianza.\nIn questo caso, usiamo quale modello generativo dei dati una distribuzione di Poisson.\nLe distribuzioni di Poisson sono usate per modellare il numero di eventi rari che si verificano in un intervallo di tempo fisso. Ad esempio, il numero di episodi di comportamento inappropriato per settimana in individui con disturbi alimentari, nascite in un giorno o incidenti in una settimana.\nLa verosimiglianza di Poisson √® simile a quella binomiale, ma non ha un limite superiore al numero di successi.\nPer esempio, consideriamo un paziente chiamato Mario. Usando gli item della sottoscala relativa agli episodi di violenza fisica della Conflict Tactics Scales-2, troviamo che Mario ha avuto 8 episodi violenti nei confronti del partner negli ultimi 6 mesi.\nInseriamo questa informazione nel modello bayesiano usando 8 come dato che specifica una verosimiglianza di Poisson con parametro sconosciuto mu, a cui abbiamo attribuito una distribuzione a priori esponenziale ed eseguiamo il campionamento.\n\nwith pm.Model() as model:\n    mu = pm.Exponential(\"mu\", l)\n    episodes = pm.Poisson(\"episodes\", mu, observed=8)\n    idata2 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 11 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-posteriori",
    "href": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-posteriori",
    "title": "Appendice V ‚Äî La predizione delle frequenze",
    "section": "V.5 La distribuzione a posteriori",
    "text": "V.5 La distribuzione a posteriori\nEstraiamo dall‚Äôoggetto idata2 i campioni della distribuzione a posteriori del parametro mu (media del numero di episodi di violenza negli ultimi 6 mesi).\n\nsample_posterior = idata2.posterior['mu']\n\nGeneriamo un grafico della distribuzione a posteriori del parametro mu.\n\naz.plot_posterior(sample_posterior)\n\n\n\n\n\n\n\n\nPossiamo dunque concludere, con un livello di certezza soggettiva del 94%, che per Mario, il numero di episodi di violenza nei confronti del partner varier√† da un minimo di 3.5 ad un massimo di 13, in un periodo di 6 mesi, con una media di 8.2.\nSupponiamo ora di volere confrontare due individui, Mario e Paolo. Di Mario abbiamo osservato 8 episodi di violenza in 6 mesi; di Paolo abbiamo osservato 12 episodi di violenza negli ultimi 6 mesi. Possiamo dire che Paolo √® pi√π violento di Mario? Oppure dobbiamo pensare che la differenza tra i due sia solo una fluttuazione casuale?\nScriviamo il modello bayesiano nel modo seguente, usando sempre la distribuzione a priori che abbiamo definito in precedenza.\n\nwith pm.Model() as model3:\n    mu_A = pm.Exponential(\"mu_A\", l)\n    mu_B = pm.Exponential(\"mu_B\", l)\n    episodes_A = pm.Poisson(\"episodes_A\", mu_A, observed=[8])\n    episodes_B = pm.Poisson(\"episodes_B\", mu_B, observed=[12])\n    idata3 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu_A, mu_B]\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 36 seconds.\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nEsaminiamo le distribuzioni a posteriori dei parametri mu_A e mu_B che rappresentano la media del numero di episodi di violenza per i due individui.\n\nwith model3:\n    az.plot_trace(idata3, kind=\"rank_bars\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nEstraiamo le distribuzioni a posteriori dei due parametri da idata3.\n\nmu_A = idata3.posterior['mu_A']\nmu_B = idata3.posterior['mu_B']\nmu_B.mean(), mu_A.mean()\n\n(&lt;xarray.DataArray 'mu_B' ()&gt;\n array(11.98949309),\n &lt;xarray.DataArray 'mu_A' ()&gt;\n array(8.26997179))\n\n\nRappresentiamo graficamente le due distribuzioni a posteriori.\n\naz.plot_posterior(mu_A)\naz.plot_posterior(mu_B);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVogliamo eseguire un test di ipotesi bayesiano per determinare la probabilit√† che la media del numero di episodi di violenza di Mario sia maggiore di quella di Paolo. Per fare ci√≤, calcoliamo quante volte mu_B √® maggiore di mu_A nelle due distribuzioni a posteriori.\n\n(mu_B &gt; mu_A).mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0.808)xarray.DataArray0.808array(0.808)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nPossiamo dunque dire che, se confrontiamo i valori dei parametri delle due distribuzioni a posteriori, nell‚Äô81% di casi risulta che Paolo √® pi√π violento di Mario.\nIl grafico seguente mostra le stime degli intervalli di credibilit√† del 94% per ciascuna delle 4 catene, pe i due parametri.\n\n_ = az.plot_forest(idata3, var_names=[\"mu_A\", \"mu_B\"])\n\n\n\n\n\n\n\n\nDato che gli intervalli di credibilit√† sono sovrapposti, concludiamo che non ci sono evidenze credibili di una differenza. Ovvero, sulla base delle nostre credenze a priori e sulla base dei dati osservati, ad un livello di certezza soggettiva del 94%, non possiamo concludere che Paolo sia pi√π violento di Mario.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-predizione-di-episodi-di-violenza-futuri",
    "href": "chapters/appendix/a70_predict_counts.html#la-predizione-di-episodi-di-violenza-futuri",
    "title": "Appendice V ‚Äî La predizione delle frequenze",
    "section": "V.6 La predizione di episodi di violenza futuri",
    "text": "V.6 La predizione di episodi di violenza futuri\nConsideriamo ora il problema della predizione di dati futuri. Utilizziamo nuovamente il modello che abbiamo gi√† usato in precedenza, ovvero model3.\nCreiamo la distribuzione predittiva a posteriori per il parametro mu_A, ovvero la media del numero di eventi di violenza attesi in futuro per Mario.\n\nwith model3:\n    post_pred = pm.sample_posterior_predictive(idata3)\n\nSampling: [episodes_A, episodes_B]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00&lt;00:00]\n    \n    \n\n\n\npost_pred\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (chain: 4, draw: 2000, episodes_A_dim_2: 1,\n                       episodes_B_dim_2: 1)\nCoordinates:\n  * chain             (chain) int64 0 1 2 3\n  * draw              (draw) int64 0 1 2 3 4 5 ... 1994 1995 1996 1997 1998 1999\n  * episodes_A_dim_2  (episodes_A_dim_2) int64 0\n  * episodes_B_dim_2  (episodes_B_dim_2) int64 0\nData variables:\n    episodes_A        (chain, draw, episodes_A_dim_2) int64 1 4 12 ... 6 10 11\n    episodes_B        (chain, draw, episodes_B_dim_2) int64 18 13 4 ... 14 14 17\nAttributes:\n    created_at:                 2023-10-27T04:56:02.607337\n    arviz_version:              0.16.1\n    inference_library:          pymc\n    inference_library_version:  5.9.1xarray.DatasetDimensions:chain: 4draw: 2000episodes_A_dim_2: 1episodes_B_dim_2: 1Coordinates: (4)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([   0,    1,    2, ..., 1997, 1998, 1999])episodes_A_dim_2(episodes_A_dim_2)int640array([0])episodes_B_dim_2(episodes_B_dim_2)int640array([0])Data variables: (2)episodes_A(chain, draw, episodes_A_dim_2)int641 4 12 14 7 4 1 ... 9 13 11 6 10 11array([[[ 1],\n        [ 4],\n        [12],\n        ...,\n        [ 6],\n        [13],\n        [ 7]],\n\n       [[12],\n        [12],\n        [ 4],\n        ...,\n        [ 4],\n        [ 6],\n        [15]],\n\n       [[ 9],\n        [ 4],\n        [ 8],\n        ...,\n        [ 9],\n        [ 5],\n        [12]],\n\n       [[22],\n        [ 3],\n        [ 7],\n        ...,\n        [ 6],\n        [10],\n        [11]]])episodes_B(chain, draw, episodes_B_dim_2)int6418 13 4 6 10 8 ... 9 22 7 14 14 17array([[[18],\n        [13],\n        [ 4],\n        ...,\n        [13],\n        [10],\n        [18]],\n\n       [[ 7],\n        [11],\n        [ 6],\n        ...,\n        [ 5],\n        [13],\n        [ 4]],\n\n       [[ 8],\n        [ 5],\n        [22],\n        ...,\n        [16],\n        [11],\n        [14]],\n\n       [[20],\n        [10],\n        [12],\n        ...,\n        [14],\n        [14],\n        [17]]])Indexes: (4)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='draw', length=2000))episodes_A_dim_2PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_A_dim_2'))episodes_B_dim_2PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_B_dim_2'))Attributes: (4)created_at :2023-10-27T04:56:02.607337arviz_version :0.16.1inference_library :pymcinference_library_version :5.9.1\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (episodes_A_dim_0: 1, episodes_B_dim_0: 1)\nCoordinates:\n  * episodes_A_dim_0  (episodes_A_dim_0) int64 0\n  * episodes_B_dim_0  (episodes_B_dim_0) int64 0\nData variables:\n    episodes_A        (episodes_A_dim_0) int64 8\n    episodes_B        (episodes_B_dim_0) int64 12\nAttributes:\n    created_at:                 2023-10-27T04:56:02.610237\n    arviz_version:              0.16.1\n    inference_library:          pymc\n    inference_library_version:  5.9.1xarray.DatasetDimensions:episodes_A_dim_0: 1episodes_B_dim_0: 1Coordinates: (2)episodes_A_dim_0(episodes_A_dim_0)int640array([0])episodes_B_dim_0(episodes_B_dim_0)int640array([0])Data variables: (2)episodes_A(episodes_A_dim_0)int648array([8])episodes_B(episodes_B_dim_0)int6412array([12])Indexes: (2)episodes_A_dim_0PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_A_dim_0'))episodes_B_dim_0PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_B_dim_0'))Attributes: (4)created_at :2023-10-27T04:56:02.610237arviz_version :0.16.1inference_library :pymcinference_library_version :5.9.1\n                      \n                  \n            \n            \n              \n            \n            \n\n\nRappresentiamo la distribuzione predittiva a posteriori di mu_A con un istogramma.\n\n_ = az.plot_posterior(post_pred.posterior_predictive.episodes_A, hdi_prob=0.94)\n\n\n\n\n\n\n\n\nFacciamo la stessa cosa per Paolo.\n\n_ = az.plot_posterior(post_pred.posterior_predictive.episodes_B, hdi_prob=0.94)\n\n\n\n\n\n\n\n\nIn base alle nostre credenze precedenti e ai dati osservati negli ultimi 6 mesi, possiamo aspettarci con una certezza soggettiva del 94% che nei prossimi 6 mesi Mario avr√† tra 1 e 15 episodi di violenza, mentre Paolo ne avr√† tra 3 e 20.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>¬† <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_probability.html",
    "href": "chapters/appendix/solutions_probability.html",
    "title": "Appendice W ‚Äî Probabilit√†",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nimport math\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 21\nEsercizio¬†21.1\nPer calcolare questa probabilit√† in maniera analitica, utilizziamo la seguente uguaglianza:\n\\[\nP(\\text{almeno 2 psicologi clinici}) = 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}).\n\\]\nIl numero totale di modi per selezionare 5 persone dal gruppo di 20 √® dato da:\n\\[\n\\binom{20}{5} = \\frac{20!}{5!(15!)} = 15,504.\n\\]\nIl numero di modi per avere nessun psicologo clinico nella commissione (ovvero, selezionare solo psicologi del lavoro) √®:\n\\[\n\\binom{10}{0} \\times \\binom{10}{5} = 1 \\times 252 = 252.\n\\]\nQuindi, la probabilit√† di avere nessun psicologo clinico √®:\n\\[\nP(\\text{nessun psicologo clinico}) = \\frac{252}{15,504} \\approx 0.016.\n\\]\nIl numero di modi per avere esattamente 1 psicologo clinico nella commissione √®:\n\\[\n\\binom{10}{1} \\times \\binom{10}{4} = 10 \\times 210 = 2,100.\n\\]\nQuindi, la probabilit√† di avere esattamente 1 psicologo clinico √®:\n\\[\nP(\\text{1 psicologo clinico}) = \\frac{2,100}{15,504} \\approx 0.135.\n\\]\nLa probabilit√† di avere almeno 2 psicologi clinici nella commissione √® quindi:\n\\[\n\\begin{align}\nP(\\text{almeno 2 psicologi clinici}) &= 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}) \\notag\\\\\n&= 1 - 0.016 - 0.135 \\notag\\\\\n&= 0.848.\\notag\n\\end{align}\n\\]\nQuindi, la probabilit√† che almeno 2 psicologi clinici siano nella commissione √® circa 0.848.\n\n# Funzione per calcolare le combinazioni\ndef nCk(n, k):\n    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n\n\n# Calcolo delle probabilit√† per il problema della commissione\ntotal_ways = nCk(20, 5)\nno_clinical = nCk(10, 0) * nCk(10, 5)\none_clinical = nCk(10, 1) * nCk(10, 4)\n\np_no_clinical = no_clinical / total_ways\np_one_clinical = one_clinical / total_ways\n\np_at_least_two_clinical = 1 - p_no_clinical - p_one_clinical\n\nprint(f\"Probabilit√† di almeno 2 psicologi clinici: {p_at_least_two_clinical:.3f}\")\n\nProbabilit√† di almeno 2 psicologi clinici: 0.848\n\n\nIn maniera pi√π intuitiva, possiamo risolvere il problema con una simulazione Monte Carlo.\n\nimport random\n\n# Numero di simulazioni\nsimulations = 1000000\n\n# Numero di successi (almeno 2 psicologi clinici nella commissione)\nsuccess_count = 0\n\n# Creiamo una lista che rappresenta il gruppo di 20 persone\n# 1 rappresenta un psicologo clinico, 0 rappresenta un psicologo del lavoro\ngroup = [1] * 10 + [0] * 10\n\n# Simulazione Monte Carlo\nfor _ in range(simulations):\n    # Estrai casualmente 5 persone dal gruppo\n    committee = random.sample(group, 5)\n\n    # Conta quanti psicologi clinici ci sono nella commissione\n    num_clinical_psychologists = sum(committee)\n\n    # Verifica se ci sono almeno 2 psicologi clinici\n    if num_clinical_psychologists &gt;= 2:\n        success_count += 1\n\n# Calcola la probabilit√†\nprobability = success_count / simulations\n\n# Mostra il risultato\nprint(\n    f\"La probabilit√† che almeno 2 psicologi clinici siano nella commissione √®: {probability:.4f}\"\n)\n\nLa probabilit√† che almeno 2 psicologi clinici siano nella commissione √®: 0.8482\n\n\n\n\nCapitolo 32\nEsercizio¬†32.1\nPer calcolare le deviazioni standard delle distribuzioni gaussiane date le percentuali di studenti che ottengono meno di 18, possiamo utilizzare le propriet√† della distribuzione normale e i quantili della distribuzione normale standard (distribuzione normale con media 0 e deviazione standard 1).\nLe distribuzioni normali hanno la propriet√† che possiamo trasformare qualsiasi valore \\(X\\) della distribuzione \\(N(\\mu, \\sigma)\\) nella distribuzione normale standard \\(N(0, 1)\\) tramite la formula:\n\\[ Z = \\frac{X - \\mu}{\\sigma}, \\]\ndove \\(Z\\) √® il quantile standardizzato.\nPer trovare il valore di \\(\\sigma\\) dato un certo percentile, utilizziamo l‚Äôinverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale standard. Per un dato percentile \\(p\\), \\(z_p\\) √® tale che:\n\\[ p = P(Z \\leq z_p) \\]\nQuindi possiamo trovare \\(\\sigma\\) risolvendo per \\(\\sigma\\) nella formula:\n\\[ z_p = \\frac{X - \\mu}{\\sigma}, \\]\n\\[ \\sigma = \\frac{X - \\mu}{z_p}, \\]\ndove:\n\n\\(X\\) √® il punteggio di soglia (18 in questo caso).\n\\(\\mu\\) √® la media della distribuzione.\n\\(z_p\\) √® il quantile della distribuzione normale standard per il percentile \\(p\\).\n\nI quantili della distribuzione normale standard per i percentili desiderati sono:\n\nPer il 15%, il quantile √® \\(z_{0.15} \\approx -1.036\\).\nPer il 10%, il quantile √® \\(z_{0.10} \\approx -1.281\\).\nPer il 5%, il quantile √® \\(z_{0.05} \\approx -1.645\\).\n\nPrima Prova\n\nMedia: \\(\\mu = 24\\)\nPercentuale che ottiene meno di 18: 15%\nQuantile: \\(z_{0.15} = -1.036\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_1 = \\frac{24 - 18}{1.036} \\approx 5.79 \\]\nSeconda Prova\n\nMedia: \\(\\mu = 25\\)\nPercentuale che ottiene meno di 18: 10%\nQuantile: \\(z_{0.10} = -1.281\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_2 = \\frac{25 - 18}{1.281} \\approx 5.46 \\]\nTerza Prova\n\nMedia: \\(\\mu = 26\\)\nPercentuale che ottiene meno di 18: 5%\nQuantile: \\(z_{0.05} = -1.645\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_3 = \\frac{26 - 18}{1.645} \\approx 4.86 \\]\n\n# Funzione per calcolare la deviazione standard data la media, la soglia e il quantile\ndef calculate_std(mean, threshold, quantile):\n    return abs((mean - threshold) / quantile)\n\n\n# Parametri delle distribuzioni gaussiane per le tre prove\nmean_test1 = 24\nstd_test1 = calculate_std(mean_test1, 18, -1.036)\nmean_test2 = 25\nstd_test2 = calculate_std(mean_test2, 18, -1.281)\nmean_test3 = 26\nstd_test3 = calculate_std(mean_test3, 18, -1.645)\n\n# Numero di studenti\nn_students = 220\n\n# Percentuale di studenti che non fa le prove\ndrop_test1 = 0.10\ndrop_test2 = 0.05\n\n# Seed per il generatore di numeri casuali basato sulla stringa \"simulation\"\nseed = sum(map(ord, \"simulation\"))\nrng = np.random.default_rng(seed=seed)\n\n# Generazione dei voti per le tre prove\n# Genera i voti solo per gli studenti che partecipano alla prova\ntest1_scores = np.where(\n    rng.random(n_students) &gt; drop_test1,\n    rng.normal(mean_test1, std_test1, n_students),\n    np.nan,\n)\ntest2_scores = np.where(\n    rng.random(n_students) &gt; drop_test2,\n    rng.normal(mean_test2, std_test2, n_students),\n    np.nan,\n)\ntest3_scores = rng.normal(mean_test3, std_test3, n_students)\n\n# Calcola il voto finale solo per gli studenti che hanno partecipato a tutte e tre le prove\nfinal_scores = np.nanmean(\n    np.column_stack((test1_scores, test2_scores, test3_scores)), axis=1\n)\n\n# Filtra gli studenti che non hanno partecipato a tutte e tre le prove\nvalid_final_scores = final_scores[~np.isnan(final_scores)]\n\n# Visualizzazione della distribuzione finale dei voti\nplt.hist(valid_final_scores, bins=30, edgecolor=\"black\")\nplt.title(\"Distribuzione dei voti finali\")\nplt.xlabel(\"Voto finale\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n# Statistiche descrittive dei voti finali\nmean_final_score = np.mean(valid_final_scores)\nmedian_final_score = np.median(valid_final_scores)\nstd_final_score = np.std(valid_final_scores)\n\nprint(f\"Media dei voti finali: {mean_final_score:.2f}\")\nprint(f\"Mediana dei voti finali: {median_final_score:.2f}\")\nprint(f\"Deviazione standard dei voti finali: {std_final_score:.2f}\")",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>W</span>¬† <span class='chapter-title'>Probabilit√†</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_bayesian_inference.html",
    "href": "chapters/appendix/solutions_bayesian_inference.html",
    "title": "Appendice X ‚Äî Inferenza bayesiana",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n\nCapitolo 34\nEsercizio¬†34.1\nimport numpy as np\nfrom scipy.stats import binom\n\n# Definire i parametri del problema\nn = 100  # numero di studi\nk = 20   # numero di studi che hanno condiviso i materiali\n\n# Discretizzazione della probabilit√† theta\ntheta_grid = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])\n\n# Distribuzione a priori\nprior_probs = np.array([0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02])\n\n# Calcolo della verosimiglianza per ciascuna theta\nlikelihood = binom.pmf(k, n, theta_grid)\n\n# Distribuzione a posteriori (non normalizzata)\nposterior_unnorm = likelihood * prior_probs\n\n# Normalizzazione della distribuzione a posteriori\nposterior_probs = posterior_unnorm / np.sum(posterior_unnorm)\n\n# Calcolo della media a posteriori\nposterior_mean = np.sum(posterior_probs * theta_grid)\n\n# Estrazione di un campione casuale dalla distribuzione a posteriori\nnp.random.seed(42)  # per la riproducibilit√†\nposterior_sample = np.random.choice(theta_grid, size=10000, p=posterior_probs)\n\n# Calcolo dell'intervallo di credibilit√† al 89%\ncred_interval = np.percentile(posterior_sample, [5.5, 94.5])\n\nposterior_mean, cred_interval\nLa soluzione dell‚Äôesercizio basato sul metodo della griglia fornisce i seguenti risultati:\n\nMedia della distribuzione a posteriori: 0.2152\nIntervallo di credibilit√† al 89%: [0.15, 0.25]\n\nQuesti risultati indicano che, dopo aver osservato i dati e aver considerato la distribuzione a priori, la probabilit√† stimata che uno studio condivida i materiali di ricerca √® circa il 21.5%, con un intervallo di credibilit√† all‚Äô89% che va dal 15% al 25%.\n\n\nCapitolo 36\nEsercizio¬†36.1\nimport scipy.stats as stats\nimport numpy as np\n\n# Dati forniti\nalpha_prior = 31.91\nbeta_prior = 100 - 31.91  # 100 - successo = insuccesso\n\n# Parametri per la distribuzione a priori\na_prior = alpha_prior\nb_prior = beta_prior\n\n# Parametri per il calcolo della distribuzione a posteriori\nn_observations = 152\n\n# Scenario (a): tasso di successo del 60%\nsuccesses_a = 0.60 * n_observations\n\n# Scenario (b): tasso di successo del 96%\nsuccesses_b = 0.96 * n_observations\n\n# Calcolo della distribuzione a posteriori\na_posterior_a = a_prior + successes_a\nb_posterior_a = b_prior + (n_observations - successes_a)\n\na_posterior_b = a_prior + successes_b\nb_posterior_b = b_prior + (n_observations - successes_b)\n\n# Distribuzioni beta a posteriori\nx = np.linspace(0, 1, 1000)\nposterior_a = stats.beta.pdf(x, a_posterior_a, b_posterior_a)\nposterior_b = stats.beta.pdf(x, a_posterior_b, b_posterior_b)\n\na_posterior_a, b_posterior_a, a_posterior_b, b_posterior_b\nLa risoluzione del problema ha portato al calcolo delle distribuzioni a posteriori nei due scenari specificati, utilizzando il metodo delle famiglie coniugate.\nScenario (a): Tasso di successo del 60%\n\nParametri della distribuzione a posteriori:\n\n\\(\\alpha_{\\text{post}} = 123.11\\)\n\\(\\beta_{\\text{post}} = 128.89\\)\n\n\nScenario (b): Tasso di successo del 96%\n\nParametri della distribuzione a posteriori:\n\n\\(\\alpha_{\\text{post}} = 177.83\\)\n\\(\\beta_{\\text{post}} = 74.17\\)\n\n\nIn entrambi gli scenari, i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\) determinano le forme delle distribuzioni a posteriori, che ci forniscono informazioni aggiornate su \\(\\theta\\) (il tasso di successo) dopo aver osservato i dati.\nCommento sui Risultati\n\nScenario (a): Con un tasso di successo osservato del 60%, la distribuzione a posteriori riflette una moderata concentrazione attorno a \\(\\theta = 0.49\\), suggerendo una certa incertezza nella stima del vero tasso di successo, ma comunque compatibile con la distribuzione a priori basata sugli studi preregistrati.\nScenario (b): Con un tasso di successo osservato del 96%, la distribuzione a posteriori √® fortemente concentrata verso l‚Äôalto, con un valore medio di \\(\\theta\\) che si avvicina a 0.71. Questo scenario riflette una maggiore confidenza in un tasso di successo elevato, pur risultando in una distribuzione molto diversa rispetto alla distribuzione a priori.\n\nQuesti risultati mostrano come i dati osservati influenzino la nostra stima del tasso di successo, con la distribuzione a priori che viene ‚Äúaggiornata‚Äù in base alle osservazioni fatte. In particolare, lo scenario con il 96% di successo evidenzia una netta discrepanza rispetto alla distribuzione a priori, suggerendo che i risultati ottenuti potrebbero essere molto pi√π ottimistici rispetto alla base di riferimento data dagli studi preregistrati.\nEsercizio¬†36.2\nSia \\(\\theta\\) la probabilit√† di nascita di una femmina dato il caso di placenta previa. Se utilizziamo una distribuzione a priori uniforme per \\(\\theta\\) (Beta(1, 1)), allora il problema si riduce a trovare la distribuzione a posteriori per \\(\\theta\\) nel contesto di un modello beta-binomiale. La distribuzione a posteriori risulta essere una Beta(y + \\(\\alpha_{\\text{prior}}\\), N - y + \\(\\beta_{\\text{prior}}\\)), ovvero una Beta(438, 544). Possiamo calcolare la media a posteriori di \\(\\theta\\) nel modo seguente:\n\nbirths = 987\nfem_births = 437\nstats.beta.mean(fem_births + 1, births - fem_births + 1).round(3)\n\n0.443\n\n\nPossiamo anche simulare un campione dalla distribuzione a posteriori per fare inferenze.\n\nposterior_sample = stats.beta.rvs(size=10000, a=fem_births + 1, b=births - fem_births + 1)\n\nsns.histplot(posterior_sample, alpha=0.5, stat=\"density\")\n_ = plt.xlabel(r\"$\\theta$\")\nplt.axvline(0.485, color=\"gray\", linestyle=\"--\")\n\nplt.annotate(\n    \"Proporzione di nascite femminili\\nnella popolazione generale\",\n    xy=(0.485, 20),  # Posizione dell'annotazione (x, y)\n    xytext=(0.5, 0.95),  # Posizione del testo dell'annotazione\n    textcoords=\"axes fraction\",\n    arrowprops=dict(facecolor=\"black\", arrowstyle=\"-&gt;\"),\n    horizontalalignment=\"left\",\n)\n\nText(0.5, 0.95, 'Proporzione di nascite femminili\\nnella popolazione generale')\n\n\n\n\n\n\n\n\n\n\nnp.quantile(posterior_sample, [0.025, 0.975]).round(3)\n\narray([0.411, 0.473])\n\n\nRiassunti precisi della distribuzione a posteriori possono essere ottenuti dalle propriet√† della distribuzione beta. I quantili esatti della distribuzione a posteriori possono essere calcolati tramite integrazione numerica della densit√† beta; la mediana risulta essere 0.446 e l‚Äôintervallo centrale di credibilit√† al 95% √® [0.415, 0.477].\nIn conclusione, possiamo affermare con un livello di certezza soggettiva del 95% che la proporzione di nascite femminili nella popolazione con placenta previa √® inferiore alla proporzione di nascite femminili nella popolazione generale.\nEsercizio¬†36.3\n\n# Parametri della distribuzione Beta\nalpha_prior = 48.5\nbeta_prior = 51.5\n\n# Creazione dei valori x su cui valutare la distribuzione Beta\nx = np.linspace(0, 1, 1000)\n\n# Valutazione della densit√† di probabilit√† Beta su x\ny = stats.beta.pdf(x, alpha_prior, beta_prior)\n\n# Creazione del grafico\nplt.plot(x, y, color=\"rebeccapurple\")\nplt.fill_between(x, y, alpha=0.3)\nplt.xlim(0, 1)\nplt.ylim(0, max(y) + 0.05)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribuzione Beta(48.5, 51.5)\")\nplt.legend()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_10074/1642415141.py:19: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend()\n\n\n\n\n\n\n\n\n\n\nbirths = 987\nfem_births = 437\n\nposterior_sample = stats.beta.rvs(\n    size=10000, a=fem_births + alpha_prior, b=births - fem_births + beta_prior\n)\n\nsns.histplot(posterior_sample, alpha=0.5, stat=\"density\")\n_ = plt.xlabel(r\"$\\theta$\")\nplt.axvline(0.485, color=\"gray\", linestyle=\"--\")\n\nplt.annotate(\n    \"Proporzione di nascite femminili\\nnella popolazione generale\",\n    xy=(0.485, 20),  # Posizione dell'annotazione (x, y)\n    xytext=(0.5, 0.95),  # Posizione del testo dell'annotazione\n    textcoords=\"axes fraction\",\n    arrowprops=dict(facecolor=\"black\", arrowstyle=\"-&gt;\"),\n    horizontalalignment=\"left\",\n)\n\nText(0.5, 0.95, 'Proporzione di nascite femminili\\nnella popolazione generale')\n\n\n\n\n\n\n\n\n\n\nnp.quantile(posterior_sample, [0.025, 0.975]).round(3)\n\narray([0.417, 0.476])\n\n\nI risultati replicano sostanzialmente quelli ottenuti nell‚ÄôEsercizio¬†36.2.\nEsercizio¬†36.4\nPer risolvere il problema utilizzando il modello beta-binomiale e calcolare la distribuzione a posteriori, seguiamo i seguenti passaggi.\n\nAbbiamo un campione di 202 soggetti adulti italiani, e 6.4% di questi sono mancini. Ci√≤ significa che il numero di mancini osservati √® \\(y = 0.064 \\times 202 = 12.928\\), che approssimiamo a \\(y = 13\\).\nLa prior informativa basata sullo studio di Papadatou-Pastou et al. (2020) √® espressa come una distribuzione Beta(8, 60).\n\nNel modello beta-binomiale, se abbiamo una prior \\(\\text{Beta}(\\alpha_{\\text{prior}}, \\beta_{\\text{prior}})\\), e osserviamo \\(y\\) successi su \\(N\\) tentativi, la distribuzione a posteriori sar√†:\n\\[\n\\text{Beta}(\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y, \\, \\beta_{\\text{post}} = \\beta_{\\text{prior}} + N - y)\n\\]\nIn questo caso:\n\n\\(\\alpha_{\\text{prior}} = 8\\)\n\\(\\beta_{\\text{prior}} = 60\\)\n\\(y = 13\\)\n\\(N = 202\\)\n\nQuindi i parametri della distribuzione a posteriori saranno:\n\\[\n\\alpha_{\\text{post}} = 8 + 13 = 21\n\\]\n\\[\n\\beta_{\\text{post}} = 60 + 202 - 13 = 249\n\\]\nLa distribuzione a posteriori √® dunque una Beta(21, 249).\nQuesta distribuzione a posteriori riflette la nostra credenza aggiornata sulla proporzione di mancini nella popolazione italiana, tenendo conto sia delle evidenze dello studio di Gori et al. (2024) che delle informazioni pregresse della meta-analisi di Papadatou-Pastou et al. (2020).\nPer visualizzare questa distribuzione a posteriori, possiamo utilizzare Python:\n\n# Parametri della distribuzione Beta a posteriori\nalpha_post = 21\nbeta_post = 249\n\n# Creazione dei valori x su cui valutare la distribuzione Beta\nx = np.linspace(\n    0, 0.2, 1000\n)  # Si concentra la visualizzazione nell'intervallo plausibile\n\n# Valutazione della densit√† di probabilit√† Beta su x\ny = stats.beta.pdf(x, alpha_post, beta_post)\n\n# Creazione del grafico\nplt.plot(x, y)\nplt.fill_between(x, y, alpha=0.3)\nplt.xlim(0, 0.2)\nplt.ylim(0, max(y) + 0.5)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribuzione a Posteriori Beta(21, 249)\")\nplt.legend()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_10074/519876995.py:21: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend()\n\n\n\n\n\n\n\n\n\nPossiamo anche calcolare la media e la varianza della distribuzione a posteriori:\n\nMedia a posteriori:\n\n\\[\n\\mu_{\\text{post}} = \\frac{\\alpha_{\\text{post}}}{\\alpha_{\\text{post}} + \\beta_{\\text{post}}} = \\frac{21}{21 + 249} = 0.077\n\\]\n\nVarianza a posteriori:\n\n\\[\n\\text{Var}_{\\text{post}} = \\frac{\\alpha_{\\text{post}} \\beta_{\\text{post}}}{(\\alpha_{\\text{post}} + \\beta_{\\text{post}})^2 (\\alpha_{\\text{post}} + \\beta_{\\text{post}} + 1)} \\approx 0.00026\n\\]\nLa distribuzione a posteriori Beta(21, 249) suggerisce che la proporzione di mancini nella popolazione italiana √® molto probabilmente vicina al 7.7%, con un intervallo di incertezza che riflette sia i dati attuali che le informazioni pregresse.\n\n\n(sec_stan?)\nEsercizio¬†44.1\nLaplace adott√≤ la seguente distribuzione campionaria per modellare il numero di maschi nati su un totale di \\(N\\) nascite:\n\\[\ny \\sim \\text{binomiale}(N, \\theta),\n\\]\ndove \\(N\\) √® il numero totale di nascite, \\(\\theta\\) √® la probabilit√† di nascita di un maschio e \\(y\\) √® il numero di nascite maschili.\nLaplace utilizz√≤ la seguente distribuzione a priori per \\(\\theta\\):\n\\[\n\\theta \\sim \\text{beta}(1, 1),\n\\]\ndove la distribuzione \\(\\text{beta}(1, 1)\\) √® uniforme sull‚Äôintervallo \\(\\theta \\in (0, 1)\\).\nEcco come possiamo specificare il modello Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"sex-ratio.stan\")\n\nwith open(stan_file, \"r\") as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\n\n\n\nIn questo programma Stan, vediamo che sia il numero totale di nascite (\\(N\\)) sia il numero di nascite maschili (\\(y\\)) sono forniti come dati. Poi ci sono due blocchi aggiuntivi: un blocco dei parametri, usato per dichiarare valori sconosciuti (qui, solo il tasso di nascite maschili \\(\\theta\\)), e un blocco del modello, dove specifichiamo la distribuzione a priori e la verosimiglianza. La distribuzione a posteriori viene calcolata da Stan combinando queste due componenti. Inoltre, c‚Äô√® un blocco delle quantit√† generate dove viene calcolata una variabile booleana che indica se la probabilit√† di nascita dei maschi \\(\\theta\\) √® maggiore di 0.5.\nIl modello di Laplace ci consente di calcolare non solo la probabilit√† di nascita di un maschio, ma anche la probabilit√† che nascano pi√π maschi che femmine.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nboys = 110312\ngirls = 105287\n\ndata = {\"N\": boys + girls, \"y\": boys, \"alpha_prior\": 1, \"beta_prior\": 1}\n\n\nsample = model.sample(\n    data=data,\n    iter_warmup=1000,\n    iter_sampling=10_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\n11:19:03 - cmdstanpy - INFO - CmdStan start processing\n11:19:03 - cmdstanpy - INFO - Chain [1] start processing\n11:19:03 - cmdstanpy - INFO - Chain [2] start processing\n11:19:03 - cmdstanpy - INFO - Chain [3] start processing\n11:19:03 - cmdstanpy - INFO - Chain [4] start processing\n11:19:03 - cmdstanpy - INFO - Chain [1] done processing\n11:19:03 - cmdstanpy - INFO - Chain [2] done processing\n11:19:03 - cmdstanpy - INFO - Chain [3] done processing\n11:19:03 - cmdstanpy - INFO - Chain [4] done processing\n\n\nProcediamo quindi a estrarre i campioni a posteriori per le variabili theta e boys_gt_girls.\n\ntheta_draws = sample.stan_variable(\"theta\")\nboys_gt_girls_draws = sample.stan_variable(\"boys_gt_girls\")\n\n\nplt.hist(\n    theta_draws,\n    bins=30,\n    alpha=0.5,\n    density=True,\n)\nplt.title(\"Istogramma della distribizione a posteriori di theta\")\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\nPer il modello di Laplace, la stima per il tasso di nascite maschili \\(\\theta\\) condizionata sui dati di nascita \\(y\\) √® calcolata come la media campionaria delle estrazioni per theta.\n\ntheta_hat = np.mean(theta_draws)\nprint(f\"estimated theta = {theta_hat:.3f}\")\n\nestimated theta = 0.512\n\n\n\nquantile_05 = np.quantile(theta_draws, 0.05)\nquantile_95 = np.quantile(theta_draws, 0.95)\nprint(\n    f\"\"\"0.05 quantile = {quantile_05:.3f};\n0.95 quantile = {quantile_95:.3f}\"\"\"\n)\n\n0.05 quantile = 0.510;\n0.95 quantile = 0.513\n\n\n\nPr_boy_gt_girl = np.mean(boys_gt_girls_draws)\nprint(f\"estimated Pr[boy more likely] = {Pr_boy_gt_girl:.15f}\")\n\nestimated Pr[boy more likely] = 1.000000000000000\n\n\nCome possiamo vedere di seguito, tutti i nostri campioni per \\(\\theta\\) sono maggiori di \\(\\frac{1}{2}\\), ovvero boys_gt_girls_draws √® sempre uguale a 1:\n\nnp.unique(boys_gt_girls_draws)\n\narray([1.])\n\n\nIl valore 1 restituito come stima solleva l‚Äôimportante problema della precisione numerica. Laplace calcol√≤ il risultato analiticamente, che √®\n\\[\n\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\ \\bigg| \\ N, y\\right] \\approx 1 - 10^{-27}.\n\\]\nQuindi avremmo bisogno di un numero astronomico di campioni a posteriori prima di generare un valore di \\(\\theta\\) inferiore a \\(\\frac{1}{2}\\). La risposta di 1.0 trovata da Stan √® molto vicina alla risposta vera e ben entro l‚Äôerrore Monte Carlo atteso.\n\nsample.summary(sig_figs=3)\n\n\n\n\n\n\n\n\n\nMean\nMCSE\nStdDev\n5%\n50%\n95%\nN_Eff\nN_Eff/s\nR_hat\n\n\n\n\nlp__\n-149000.000\n0.004770\n6.720000e-01\n-149000.00\n-149000.000\n-149000.000\n19800.0\n39900.0\n1.0\n\n\ntheta\n0.512\n0.000009\n1.090000e-03\n0.51\n0.512\n0.513\n13700.0\n27600.0\n1.0\n\n\nboys_gt_girls\n1.000\nNaN\n9.380000e-14\n1.00\n1.000\n1.000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\n\nCapitolo 42\nEsercizio¬†42.1\nPer risolvere questo problema, calcoleremo la distribuzione predittiva a posteriori per il prossimo lancio utilizzando un nuovo set di dati: tre ‚Äútesta‚Äù seguite da una ‚Äúcroce‚Äù. Procederemo passo dopo passo:\nPasso 1: Definire il Problema e i Dati\nAbbiamo tre tipi di monete nel sacchetto:\n\nMoneta di Tipo 0: D√† sempre ‚Äúcroce‚Äù (probabilit√† di ‚Äútesta‚Äù = 0).\nMoneta di Tipo 1: √à una moneta equa (probabilit√† di ‚Äútesta‚Äù = 0.5).\nMoneta di Tipo 2: D√† sempre ‚Äútesta‚Äù (probabilit√† di ‚Äútesta‚Äù = 1).\n\nSupponiamo di avere un nuovo set di dati composto da tre ‚Äútesta‚Äù seguite da una ‚Äúcroce‚Äù. Indichiamo questo set di dati come \\(D' = (\\text{\"testa\"}, \\text{\"testa\"}, \\text{\"testa\"}, \\text{\"croce\"})\\).\nPasso 2: Calcolare le Probabilit√† a Posteriori\nPrima di calcolare la distribuzione predittiva a posteriori, dobbiamo aggiornare le probabilit√† a posteriori per ciascun tipo di moneta utilizzando il nuovo set di dati \\(D'\\).\nPrima di osservare i dati, le probabilit√† iniziali (priori) per ciascun tipo di moneta sono uguali:\n\\[\nP(X = 0) = \\frac{1}{3}, \\quad P(X = 1) = \\frac{1}{3}, \\quad P(X = 2) = \\frac{1}{3}.\n\\]\nOra calcoliamo la verosimiglianza di ottenere il set di dati \\(D'\\) per ciascun tipo di moneta:\n\nMoneta di Tipo 0 (X = 0):\nProbabilit√† di ottenere ‚Äútesta‚Äù = 0, quindi ottenere tre ‚Äútesta‚Äù seguite da una ‚Äúcroce‚Äù √® impossibile:\n\\[\nP(D' | X = 0) = 0.\n\\]\nMoneta di Tipo 1 (X = 1):\nProbabilit√† di ottenere ‚Äútesta‚Äù o ‚Äúcroce‚Äù = 0.5. La probabilit√† di ottenere tre ‚Äútesta‚Äù seguite da una ‚Äúcroce‚Äù √®:\n\\[\nP(D' | X = 1) = 0.5^3 \\times 0.5 = 0.5^4 = 0.0625.\n\\]\nMoneta di Tipo 2 (X = 2):\nProbabilit√† di ottenere ‚Äútesta‚Äù = 1, quindi ottenere tre ‚Äútesta‚Äù seguite da una ‚Äúcroce‚Äù √® impossibile:\n\\[\nP(D' | X = 2) = 0.\n\\]\n\nLe probabilit√† a posteriori sono calcolate usando la formula di Bayes:\n\\[\nP(X = i | D') = \\frac{P(D' | X = i) \\times P(X = i)}{P(D')},\n\\]\ndove \\(P(D')\\) √® la probabilit√† totale di osservare il set di dati \\(D'\\), calcolata come:\n\\[\nP(D') = P(D' | X = 0) \\times P(X = 0) + P(D' | X = 1) \\times P(X = 1) + P(D' | X = 2) \\times P(X = 2).\n\\]\nSostituendo i valori:\n\\[\nP(D') = 0 \\times \\frac{1}{3} + 0.0625 \\times \\frac{1}{3} + 0 \\times \\frac{1}{3} = \\frac{0.0625}{3} = 0.020833.\n\\]\nOra possiamo calcolare le probabilit√† a posteriori:\n\nPer la Moneta di Tipo 0 (X = 0): \\[\nP(X = 0 | D') = \\frac{0 \\times \\frac{1}{3}}{0.020833} = 0.\n\\]\nPer la Moneta di Tipo 1 (X = 1): \\[\nP(X = 1 | D') = \\frac{0.0625 \\times \\frac{1}{3}}{0.020833} = \\frac{0.020833}{0.020833} = 1.\n\\]\nPer la Moneta di Tipo 2 (X = 2): \\[\nP(X = 2 | D') = \\frac{0 \\times \\frac{1}{3}}{0.020833} = 0.\n\\]\n\nPasso 3: Calcolare la Distribuzione Predittiva a Posteriori\nLa distribuzione predittiva a posteriori per il prossimo lancio √® data dalla combinazione delle probabilit√† a posteriori con le probabilit√† di ottenere ‚Äúcroce‚Äù con ciascun tipo di moneta:\n\\[\nP(\\text{croce nel prossimo lancio} | D') = P(X = 0 | D') \\times 0 + P(X = 1 | D') \\times 0.5 + P(X = 2 | D') \\times 0.\n\\]\nSostituendo i valori calcolati:\n\\[\nP(\\text{croce nel prossimo lancio} | D') = 0 \\times 0 + 1 \\times 0.5 + 0 \\times 0 = 0.5.\n\\]\nLa distribuzione predittiva a posteriori per il prossimo lancio, dato che abbiamo osservato tre ‚Äútesta‚Äù seguite da una ‚Äúcroce‚Äù, √® 0.5.\nEsercizio¬†42.2\nPasso 1: Prior.\nLe probabilit√† preliminari sono:\n\\[\nP(X = 0) = 0.5, \\quad P(X = 1) = 0.25, \\quad P(X = 2) = 0.25.\n\\]\nPasso 2: Verosimiglianza.\n\nMoneta di Tipo 0 (X = 0): \\(P(D | X = 0) = 0.\\)\nMoneta di Tipo 1 (X = 1): \\(P(D | X = 1) = 0.3 \\times 0.7 \\times 0.3 = 0.063.\\)\nMoneta di Tipo 2 (X = 2): \\(P(D | X = 2) = 0.\\)\n\nPasso 3: Calcolo delle Probabilit√† a Posteriori.\n\\[\nP(D) = 0 \\times 0.5 + 0.063 \\times 0.25 + 0 \\times 0.25 = 0.01575.\n\\]\n\\[\nP(X = 0 | D) = 0, \\quad P(X = 1 | D) = 1, \\quad P(X = 2 | D) = 0.\n\\]\nPasso 4: Distribuzione Predittiva a Posteriori.\n\\[\n\\begin{align}\nP(\\text{croce nel quarto lancio} | D) &= P(X = 0 | D) \\times 1 + P(X = 1 | D) \\times 0.3 + P(X = 2 | D) \\times 0\\notag\\\\\n&= 0 \\times 1 + 1 \\times 0.3 + 0 \\times 0\\notag\\\\\n&= 0.3.\\notag\n\\end{align}\n\\]\nIn conclusione, la probabilit√† di ottenere ‚Äúcroce‚Äù al quarto lancio, dopo aver osservato la sequenza croce, testa, croce, √® 0.3.\n\n\n\n\nGori, Benedetta, Antonello Grippo, Martina Focardi, e Francesco Lolli. 2024. ¬´The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects¬ª. Laterality 29 (2): 151‚Äì68.\n\n\nPapadatou-Pastou, Marietta, Eleni Ntolka, Judith Schmitz, Maryanne Martin, Marcus R Munaf√≤, Sebastian Ocklenburg, e Silvia Paracchini. 2020. ¬´Human handedness: A meta-analysis.¬ª Psychological bulletin 146 (6): 481‚Äì524.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>X</span>¬† <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_causality.html",
    "href": "chapters/appendix/solutions_causality.html",
    "title": "Appendice Y ‚Äî Causalit√†",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\n?sec-causality\nEsercizio¬†18.1\nRisposta corretta:\n\nControllare per B √® sufficiente e necessario per ottenere una stima non distorta dell‚Äôeffetto di A su C.\n\nSpiegazione: In questo DAG, B agisce come un mediatore nella catena causale da A a C (A ‚Üí B ‚Üí C). Controllare per B √® sufficiente per bloccare il flusso di informazioni lungo questo percorso. Inoltre, B √® anche un collider nel percorso A ‚Üí B ‚Üê D, ma questo percorso non crea un back-door path tra A e C, quindi non √® necessario controllare per D. Controllare per B √® necessario perch√© altrimenti l‚Äôeffetto di A su C attraverso B non verrebbe rimosso. Le altre opzioni sono errate perch√©:\n\nNon c‚Äô√® un back-door path da A a C attraverso D.\nB √® un mediatore che deve essere controllato.\nControllare per D non √® necessario e potrebbe introdurre bias.\nB non √® un collider nel percorso rilevante per l‚Äôeffetto di A su C.\n\nEsercizio¬†18.2\nRisposta corretta:\n\n√à necessario controllare solo per Z per bloccare tutti i back-door paths tra X e Y.\n\nSpiegazione: In questo DAG, esiste un back-door path tra X e Y attraverso Z (X ‚Üê Z ‚Üí W ‚Üí Y). Secondo il criterio del back-door, per ottenere una stima non distorta dell‚Äôeffetto causale di X su Y, dobbiamo bloccare tutti i back-door paths tra queste variabili.\nControllare per Z √® sufficiente per bloccare questo back-door path, poich√© Z √® una ‚Äúforchetta‚Äù (fork) nel percorso. Una volta che controlliamo per Z, il flusso di informazioni non causali da X a Y attraverso questo percorso viene bloccato.\nLe altre opzioni sono errate perch√©:\n\nC‚Äô√® un back-door path che deve essere bloccato.\nControllare solo per W non √® sufficiente, poich√© non blocca il flusso di informazioni attraverso Z.\nNon √® necessario controllare per W una volta che si √® controllato per Z. Controllare per variabili non necessarie pu√≤ ridurre la precisione della stima.\n√à possibile stimare l‚Äôeffetto causale in questo DAG utilizzando il criterio del back-door, controllando per Z.\n\nQuesto esercizio illustra l‚Äôimportanza di identificare correttamente i back-door paths e di selezionare il set minimo di variabili necessarie per bloccarli quando si applica il criterio del back-door nell‚Äôinferenza causale.\nEsercizio¬†18.3\nRisposta corretta:\n\nA e B sono indipendenti, ma diventano dipendenti se controlliamo per C.\n\nSpiegazione: In questo DAG, C √® un collider rispetto ad A e B. Un collider √® una variabile che riceve frecce da due o pi√π altre variabili nel grafo. Il comportamento dei collider √® particolare e contro-intuitivo nell‚Äôanalisi causale.\nQuando non controlliamo per un collider o per i suoi discendenti:\n\nLe variabili che influenzano il collider (in questo caso, A e B) sono indipendenti tra loro.\n\nQuando controlliamo per un collider o per i suoi discendenti:\n\nIntroduciamo una dipendenza tra le variabili che influenzano il collider.\n\nQuindi, in questo caso:\n\nA e B sono originariamente indipendenti.\nSe controlliamo per C (il collider), creiamo una dipendenza tra A e B.\nAnche controllare per D (discendente del collider) creerebbe una dipendenza tra A e B.\n\nLe altre opzioni sono errate perch√©:\n\nLa direzione della dipendenza √® opposta a quella corretta.\nA e B non sono sempre dipendenti; lo diventano solo se controlliamo per C o D.\nA e B diventano dipendenti se controlliamo per C o D.\nControllare per D non rende A e B indipendenti, ma al contrario crea una dipendenza.\n\nQuesto esercizio illustra l‚Äôimportanza di identificare correttamente i collider in un DAG e di comprendere come il controllo di queste variabili possa influenzare le relazioni tra altre variabili nel sistema.\nEsercizio¬†18.4\nRisposta corretta:\n\nControllare per Z potrebbe introdurre un bias nella stima dell‚Äôeffetto causale di X su Y.\n\nSpiegazione: In questo DAG, abbiamo la seguente situazione:\n\nC‚Äô√® un back-door path da X a Y attraverso U (X ‚Üê U ‚Üí Y). Questo percorso crea confondimento.\nZ √® un collider nel percorso X ‚Üí Z ‚Üê Y.\nU non √® osservata, quindi non possiamo controllare direttamente per essa.\n\nApplicando il criterio del back-door:\n\nNon possiamo bloccare il back-door path X ‚Üê U ‚Üí Y perch√© U non √® osservata.\nControllare per Z non aiuterebbe a bloccare questo back-door path.\nAnzi, controllare per Z (un collider) aprirebbe un nuovo percorso non causale tra X e Y, introducendo un bias nella stima dell‚Äôeffetto causale.\n\nLe altre opzioni sono errate perch√©:\n\nAnche se U non √® osservata, possiamo ancora applicare il criterio del back-door per analizzare la situazione.\nControllare per Z non √® sufficiente e anzi introdurrebbe un bias.\nC‚Äô√® un back-door path attraverso U.\nNon possiamo controllare per U poich√© non √® osservata.\n\nQuesto esercizio illustra l‚Äôimportanza di identificare correttamente i back-door paths e i collider in un DAG, e di comprendere come la presenza di variabili non osservate possa complicare l‚Äôapplicazione del criterio del back-door nell‚Äôinferenza causale.\nEsercizio¬†18.5\nLa struttura causale √® quella della mediazione.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# A √® una variabile casuale distribuita secondo una normale standard\nA = np.random.normal(0, 1, n)\n\n# M √® una funzione lineare di A con un termine di errore\nM = A + np.random.normal(0, 1, n)\n\n# B √® una funzione lineare di M con un termine di errore\nB = M + np.random.normal(0, 1, n)\n\n# Plot di A contro B\nplt.scatter(A, B, alpha=0.5)\nplt.xlabel('A')\nplt.ylabel('B')\nplt.title('Relazione tra A e B')\nplt.show()\n\n# Calcolo della correlazione tra A e B\ncorrelation_matrix = np.corrcoef(A, B)\ncorrelation = correlation_matrix[0, 1]\n\n# Stampa il valore della correlazione\nprint(f\"Correlazione tra A e B: {correlation:.4f}\")\nEsercizio¬†18.6\nSe ( A ) e ( B ) condividono un antenato comune ( C ) (biforcazione causale), ( A ) e ( B ) saranno correlati nei dati. Questo fenomeno √® chiamato confondimento. La regola si applica anche se l‚Äôeffetto di C su A e/o su B √® mediato da altre variabili.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# C √® una variabile casuale distribuita secondo una normale standard\nC = np.random.normal(0, 1, n)\n\n# A √® una funzione lineare di C con un termine di errore\nA = C + np.random.normal(0, 1, n)\n\n# B √® una funzione lineare di C con un termine di errore\nB = C + np.random.normal(0, 1, n)\n\n# Plot di A contro B\nplt.scatter(A, B, alpha=0.5)\nplt.xlabel('A')\nplt.ylabel('B')\nplt.title('Relazione tra A e B')\nplt.show()\n\n# Calcolo della correlazione tra A e B\ncorrelation_matrix = np.corrcoef(A, B)\ncorrelation = correlation_matrix[0, 1]\n\n# Stampa il valore della correlazione\nprint(f\"Correlazione tra A e B: {correlation:.4f}\")\nEsercizio¬†18.7\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# Generazione delle variabili secondo le specifiche\nC = np.random.normal(0, 1, n)\nA = C + np.random.normal(0, 1, n)\nB = C + np.random.normal(0, 1, n)\n\n# Regressione A ~ C per ottenere i residui\nmodel_A_C = sm.OLS(A, sm.add_constant(C)).fit()\nresiduals_A = model_A_C.resid\n\n# Regressione B ~ C per ottenere i residui\nmodel_B_C = sm.OLS(B, sm.add_constant(C)).fit()\nresiduals_B = model_B_C.resid\n\n# Calcolo della correlazione tra i residui di A e B\ncorrelation_residuals = np.corrcoef(residuals_A, residuals_B)[0, 1]\n\n# Stampa del risultato\nprint(f\"Correlazione tra A e B dopo aver controllato per C: {correlation_residuals:.4f}\")\n\n# Plot dei residui di A contro i residui di B\nplt.scatter(residuals_A, residuals_B, alpha=0.5)\nplt.xlabel('Residui di A')\nplt.ylabel('Residui di B')\nplt.title('Correlazione tra i residui di A e B')\nplt.show()\nEsercizio¬†18.8\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# Generazione delle variabili secondo le specifiche\nA = np.random.normal(0, 1, n)\nM = A + np.random.normal(0, 1, n)\nB = M + np.random.normal(0, 1, n)\n\n# Regressione M ~ A per ottenere i residui\nmodel_M_A = sm.OLS(M, sm.add_constant(A)).fit()\nresiduals_M = model_M_A.resid\n\n# Regressione B ~ M per ottenere i residui\nmodel_B_M = sm.OLS(B, sm.add_constant(M)).fit()\nresiduals_B = model_B_M.resid\n\n# Calcolo della correlazione tra A e i residui di B\ncorrelation_residuals = np.corrcoef(A, residuals_B)[0, 1]\n\n# Stampa del risultato\nprint(f\"Correlazione tra A e i residui di B (dopo aver controllato per M): {correlation_residuals:.4f}\")\n\n# Plot di A contro i residui di B\nplt.scatter(A, residuals_B, alpha=0.5)\nplt.xlabel('A')\nplt.ylabel('Residui di B')\nplt.title('Correlazione tra A e i residui di B')\nplt.show()\nSe ( M ) media completamente l‚Äôeffetto di ( A ) su ( B ), ci aspettiamo che, una volta controllato ( M ), non ci sia alcuna correlazione residua significativa tra ( A ) e ( B ). La correlazione calcolata dovrebbe essere prossima a zero se la mediazione √® completa. Se la correlazione √® significativamente diversa da zero, potrebbe indicare che esistono effetti diretti di ( A ) su ( B ) non mediati da ( M ) o che esistono altri percorsi attraverso i quali ( A ) influenza ( B ).\nEsercizio¬†18.9\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n# Numero di punti dati\nn = 10000\n\n# Generazione delle variabili secondo le specifiche\nA = np.random.normal(0, 1, n)\nB = np.random.normal(0, 1, n)\nD = A + B + np.random.normal(0, 1, n)\n\n# Regressione A ~ D per ottenere i residui\nmodel_A_D = sm.OLS(A, sm.add_constant(D)).fit()\nresiduals_A = model_A_D.resid\n\n# Regressione B ~ D per ottenere i residui\nmodel_B_D = sm.OLS(B, sm.add_constant(D)).fit()\nresiduals_B = model_B_D.resid\n\n# Plot dei residui di A contro i residui di B\nplt.scatter(residuals_A, residuals_B, alpha=0.5)\nplt.xlabel(\"Residui di A\")\nplt.ylabel(\"Residui di B\")\nplt.title(\"Correlazione tra i residui di A e B dopo aver controllato per D\")\nplt.show()\n\n# Calcolo della correlazione tra A e i residui di B\ncorrelation_residuals = np.corrcoef(residuals_A, residuals_B)[0, 1]\n\n# Stampa del risultato\nprint(\n    f\"Correlazione tra A e i residui di B (dopo aver controllato per D): {correlation_residuals:.4f}\"\n)\nIn una struttura causale di tipo collider, A e B sono indipendenti, ma quando si controlla per D si pu√≤ generare una correlazione spuria tra A e B. Questo effetto √® dovuto alla struttura del collider: controllare per D introduce una dipendenza tra A e B, anche se non esiste un legame diretto tra loro.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>Y</span>¬† <span class='chapter-title'>Causalit√†</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_mult_regr.html",
    "href": "chapters/appendix/solutions_mult_regr.html",
    "title": "Appendice Z ‚Äî Regressione multipla",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 65\nEsercizio¬†65.1\n\nDeterminazione delle Matrici.\n\nLe variabili indipendenti (\\(x_1\\), \\(x_2\\) e \\(x_3\\)) sono date, e possiamo creare la matrice delle variabili indipendenti \\(\\mathbf{X}\\). Aggiungiamo una colonna di 1 per il termine costante \\(\\beta_0\\):\n\\[\n\\mathbf{X} = \\begin{pmatrix}\n1 & 2 & 11 & 12 \\\\\n1 & 1 & 9 & 9 \\\\\n1 & 3 & 12 & 7 \\\\\n1 & 4 & 10 & 8 \\\\\n1 & 5 & 11 & 6\n\\end{pmatrix}\n\\]\nLa matrice dei coefficienti \\(\\boldsymbol{\\beta}\\) √® data come:\n\\[\n\\boldsymbol{\\beta} = \\begin{pmatrix}\n-1.402020 \\\\\n0.183838 \\\\\n1.405051 \\\\\n-0.664646\n\\end{pmatrix}\n\\]\nLa matrice degli errori \\(\\boldsymbol{\\epsilon}\\) non √® fornita, ma la rappresentiamo comunque:\n\\[\n\\boldsymbol{\\epsilon} = \\begin{pmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\epsilon_3 \\\\\n\\epsilon_4 \\\\\n\\epsilon_5\n\\end{pmatrix}\n\\]\nL‚Äôequazione del modello lineare in forma matriciale √®:\n\\[\n\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\nEspansione del Modello.\n\nEspandiamo il modello per ottenere le cinque equazioni esplicite utilizzando i valori forniti. Il modello per ogni osservazione \\(i\\) √®:\n\\[\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\epsilon_i\n\\]\nCalcoliamo le cinque equazioni:\n\\[\n\\begin{aligned}\ny_1 &= -1.402020 + 0.183838 \\cdot 2 + 1.405051 \\cdot 11 - 0.664646 \\cdot 12 + \\epsilon_1 \\\\\ny_2 &= -1.402020 + 0.183838 \\cdot 1 + 1.405051 \\cdot 9 - 0.664646 \\cdot 9 + \\epsilon_2 \\\\\ny_3 &= -1.402020 + 0.183838 \\cdot 3 + 1.405051 \\cdot 12 - 0.664646 \\cdot 7 + \\epsilon_3 \\\\\ny_4 &= -1.402020 + 0.183838 \\cdot 4 + 1.405051 \\cdot 10 - 0.664646 \\cdot 8 + \\epsilon_4 \\\\\ny_5 &= -1.402020 + 0.183838 \\cdot 5 + 1.405051 \\cdot 11 - 0.664646 \\cdot 6 + \\epsilon_5 \\\\\n\\end{aligned}\n\\]\n\nCalcolo dei Valori Predetti (\\(\\hat{y}_i\\)).\n\nCalcoliamo i valori predetti \\(\\hat{y}_i\\) sostituendo \\(\\epsilon_i\\) con 0:\n\\[\n\\begin{aligned}\n\\hat{y}_1 &= -1.402020 + 0.183838 \\cdot 2 + 1.405051 \\cdot 11 - 0.664646 \\cdot 12 \\\\\n\\hat{y}_2 &= -1.402020 + 0.183838 \\cdot 1 + 1.405051 \\cdot 9 - 0.664646 \\cdot 9 \\\\\n\\hat{y}_3 &= -1.402020 + 0.183838 \\cdot 3 + 1.405051 \\cdot 12 - 0.664646 \\cdot 7 \\\\\n\\hat{y}_4 &= -1.402020 + 0.183838 \\cdot 4 + 1.405051 \\cdot 10 - 0.664646 \\cdot 8 \\\\\n\\hat{y}_5 &= -1.402020 + 0.183838 \\cdot 5 + 1.405051 \\cdot 11 - 0.664646 \\cdot 6 \\\\\n\\end{aligned}\n\\]\nCalcoliamo i valori numerici:\n\\[\n\\begin{aligned}\n\\hat{y}_1 &= -1.402020 + 0.367676 + 15.455561 - 7.975752 \\approx 6.445465 \\\\\n\\hat{y}_2 &= -1.402020 + 0.183838 + 12.645459 - 5.981814 \\approx 5.445463 \\\\\n\\hat{y}_3 &= -1.402020 + 0.551514 + 16.860612 - 4.652522 \\approx 11.357584 \\\\\n\\hat{y}_4 &= -1.402020 + 0.735352 + 14.05051 - 5.317168 \\approx 8.066674 \\\\\n\\hat{y}_5 &= -1.402020 + 0.91919 + 15.455561 - 3.987876 \\approx 10.985855 \\\\\n\\end{aligned}\n\\]\nI valori predetti sono quindi:\n\\[\n\\begin{aligned}\n\\hat{y}_1 &\\approx 6.445 \\\\\n\\hat{y}_2 &\\approx 5.445 \\\\\n\\hat{y}_3 &\\approx 11.358 \\\\\n\\hat{y}_4 &\\approx 8.067 \\\\\n\\hat{y}_5 &\\approx 10.986 \\\\\n\\end{aligned}\n\\]\n\nCalcolo degli errori casuali (\\(\\boldsymbol{\\epsilon}\\)).\n\nGli errori casuali (\\(\\epsilon_i\\)) si ottengono sottraendo i valori predetti (\\(\\hat{y}_i\\)) dai valori osservati (\\(y_i\\)). Per ciascun \\(i\\):\n\\[\n\\epsilon_i = y_i - \\hat{y}_i\n\\]\nCalcoliamo gli errori casuali per ciascuna osservazione:\n\\[\n\\begin{aligned}\n\\epsilon_1 &= 5.7 - 6.445 \\approx -0.745 \\\\\n\\epsilon_2 &= 4.7 - 5.445 \\approx -0.745 \\\\\n\\epsilon_3 &= 12.6 - 11.358 \\approx 1.242 \\\\\n\\epsilon_4 &= 10.8 - 8.067 \\approx 2.733 \\\\\n\\epsilon_5 &= 8.5 - 10.986 \\approx -2.486 \\\\\n\\end{aligned}\n\\]\nQuindi, la matrice degli errori \\(\\boldsymbol{\\epsilon}\\) √®:\n\\[\n\\boldsymbol{\\epsilon} = \\begin{pmatrix}\n-0.745 \\\\\n-0.745 \\\\\n1.242 \\\\\n2.733 \\\\\n-2.486\n\\end{pmatrix}\n\\]\nEsercizio¬†65.2\nEcco come implementare la formula dei minimi quadrati in Python utilizzando la libreria numpy e come verificare il risultato usando pingouin.linear_regression.\n\nimport numpy as np\nimport pandas as pd\nimport pingouin as pg\n\n# Definizione della matrice X e del vettore y\nX = np.array([[2, 11, 12], [1, 9, 9], [3, 12, 7], [4, 10, 8], [5, 11, 6]])\ny = np.array([5.7, 4.7, 12.6, 10.8, 8.5])\n\n# Implementazione con NumPy\nX_numpy = np.hstack([np.ones((X.shape[0], 1)), X])\nbeta_numpy = np.linalg.inv(X_numpy.T @ X_numpy) @ X_numpy.T @ y\nprint(\"I coefficienti beta calcolati con NumPy sono:\", beta_numpy)\n\n# Implementazione con Pingouin\ndata = pd.DataFrame(X, columns=[\"x1\", \"x2\", \"x3\"])\ndata[\"y\"] = y\nmodel_pingouin = pg.linear_regression(\n    data[[\"x1\", \"x2\", \"x3\"]], data[\"y\"], add_intercept=True\n)\nprint(\"\\nI coefficienti beta calcolati con Pingouin sono:\")\nprint(model_pingouin)\n\n# Confronto dei risultati\nprint(\"\\nConfrontiamo i coefficienti:\")\nprint(\"NumPy:   \", beta_numpy)\nprint(\"Pingouin:\", model_pingouin[\"coef\"].values)\n\nI coefficienti beta calcolati con NumPy sono: [-1.4020202   0.18383838  1.40505051 -0.66464646]\n\nI coefficienti beta calcolati con Pingouin sono:\n       names      coef         se         T      pval        r2   adj_r2  \\\n0  Intercept -1.402020  22.592392 -0.062057  0.960544  0.632638 -0.46945   \n1         x1  0.183838   1.901446  0.096683  0.938640  0.632638 -0.46945   \n2         x2  1.405051   1.960075  0.716835  0.604064  0.632638 -0.46945   \n3         x3 -0.664646   1.214501 -0.547259  0.681221  0.632638 -0.46945   \n\n     CI[2.5%]   CI[97.5%]  \n0 -288.465573  285.661533  \n1  -23.976322   24.343999  \n2  -23.500063   26.310164  \n3  -16.096345   14.767052  \n\nConfrontiamo i coefficienti:\nNumPy:    [-1.4020202   0.18383838  1.40505051 -0.66464646]\nPingouin: [-1.4020202   0.18383838  1.40505051 -0.66464646]\n\n\nCapitolo 66\nEsercizio¬†66.1\nimport os\nimport pandas as pd\nimport bambi as bmb\nimport arviz as az\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\ndata_path = os.path.join(project_directory, \"data\", \"Aungle_Langer_2023.csv\")\nd = pd.read_csv(data_path)\nd[\"Condition\"] = d[\"Condition\"].astype(\"category\")\nd.head()\n\n# Define and fit the basic mixed-effects model\nmodel = bmb.Model(\n    \"Healing ~ Condition + (1|Subject) + (1|ResponseId)\",\n    data=d\n)\n\nidata = model.fit(nuts_sampler=\"numpyro\")\naz.summary(idata, round_to=2, var_names=\"Condition\")\n\nmodel_varying_slopes = bmb.Model(\n    \"Healing ~ Condition + (1 + Condition|Subject) + (1 + Condition|ResponseId)\",\n    data=d,\n)\nidata_varying_slopes = model_varying_slopes.fit(nuts_sampler=\"numpyro\")\naz.summary(idata_varying_slopes, round_to=2, var_names=\"Condition\")\nGelman e Brown (2024) hanno replicato l‚Äôanalisi degli autori originali utilizzando un modello a effetti misti con pendenze casuali. Questa nuova analisi ha prodotto risultati sostanzialmente diversi. Nel nuovo modello statistico, i t-score sono stati notevolmente ridotti: da 10.7 a 3.0 per il confronto tra la condizione di 56 minuti e quella di 14 minuti, e da 2.5 a 0.7 per il confronto tra la condizione di 28 minuti e quella di 14 minuti. Inoltre, l‚Äôeffetto della manipolazione sulla guarigione √® stato stimato come altamente variabile tra i singoli soggetti, risultando a volte positivo e a volte negativo.\nGelman e Brown (2024) esprimono scetticismo riguardo alla capacit√† di questo studio di rivelare effetti reali del tempo percepito sulla guarigione fisica, basandosi su quattro argomentazioni principali.\n\nSelezione dei risultati: Il risultato statisticamente significativo emerso √® solo uno dei molti confronti possibili. Lo studio ha raccolto dati su diverse variabili (ansia, stress, depressione, mindfulness, umore e tratti della personalit√†), aprendo la possibilit√† a numerose altre analisi. In assenza di una preregistrazione dello studio, non √® possibile determinare quali analisi sarebbero state condotte se i dati fossero stati diversi.\nVariabilit√† tra i soggetti: La grande variazione stimata nell‚Äôeffetto tra i soggetti suggerisce che qualsiasi effetto medio stimato sarebbe altamente dipendente dal campione specifico di partecipanti. Non vi √® motivo di ritenere che i 33 partecipanti siano rappresentativi di una popolazione pi√π ampia di interesse.\nVariabilit√† situazionale: Ci si aspetterebbe che l‚Äôeffetto vari non solo tra le persone, ma anche tra le situazioni, sollevando preoccupazioni sulla stabilit√† e sulla generalizzabilit√† dei risultati. Inoltre, l‚Äôesperimento ha coinvolto solo contusioni molto lievi, non vere e proprie malattie o lesioni. Dunque, √® difficile concludere, come fanno gli autori, che la tecnica del cupping abbia delle vere e propri propriet√† curative.\nMancanza di un meccanismo chiaro: Non √® chiaro come la percezione del tempo possa influenzare la guarigione della pelle in questo contesto. Gli autori fanno riferimento a concetti generali come ‚Äúl‚Äôunit√† mente-corpo‚Äù, ma non sono stati esaminati meccanismi specifici. Attribuire le differenze osservate al ‚Äútempo percepito‚Äù piuttosto che ad altri fattori che variavano tra le condizioni sembra essere una conclusione azzardata.\n\nIn conclusione, Gelman e Brown (2024) suggeriscono che, data la molteplicit√† di variabili in gioco nell‚Äôesperimento, potrebbe essere pi√π plausibile interpretare i risultati come un esempio della capacit√† dei ricercatori di trovare pattern nel rumore in studi non adeguatamente controllati, piuttosto che come una prova dell‚Äôeffetto del tempo percepito sulla guarigione fisica.\n\n\n\n\nGelman, Andrew, e Nicholas JL Brown. 2024. ¬´How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology¬ª.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>Z</span>¬† <span class='chapter-title'>Regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_rescorla_wagner.html",
    "href": "chapters/appendix/solutions_rescorla_wagner.html",
    "title": "[Appendice ‚Äî Modello Rescorla-Wagner",
    "section": "",
    "text": "Capitolo 86\nEsercizio¬†86.1\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef softmax(Q, theta):\n    \"\"\"\n    Calcola le probabilit√† di selezione delle azioni utilizzando la regola softmax.\n\n    Args:\n        Q (numpy array): Array di valori attesi per ciascuna azione.\n        theta (float): Parametro di temperatura.\n\n    Returns:\n        numpy array: Array di probabilit√† di selezione delle azioni.\n    \"\"\"\n    # Calcola le probabilit√† softmax\n    exp_values = np.exp(theta * Q)\n    probabilities = exp_values / np.sum(exp_values)\n    return probabilities\n\n\n# Esempio di utilizzo della funzione softmax\nQ = np.array([0.25, 0.75])\ntheta_values = [0.1, 1, 2, 5]\n\n# Visualizziamo le probabilit√† per diversi valori di theta\nfor theta in theta_values:\n    probabilities = softmax(Q, theta)\n    print(f\"Theta = {theta}: Probabilit√† = {probabilities}\")\n\n# Tracciare il grafico delle probabilit√† al variare di theta\ntheta_range = np.linspace(0, 5, 100)\nprobabilities_list = [softmax(Q, theta) for theta in theta_range]\nprobabilities_array = np.array(probabilities_list).T\n\nplt.figure()\nplt.plot(theta_range, probabilities_array[0], label=\"Opzione 1: Q = 0.25\")\nplt.plot(theta_range, probabilities_array[1], label=\"Opzione 2: Q = 0.75\")\nplt.xlabel(\"Theta\")\nplt.ylabel(\"Probabilit√†\")\nplt.title(\"Funzione Softmax - Modello Rescorla-Wagner\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\nTheta = 0.1: Probabilit√† = [0.4875026 0.5124974]\nTheta = 1: Probabilit√† = [0.37754067 0.62245933]\nTheta = 2: Probabilit√† = [0.26894142 0.73105858]\nTheta = 5: Probabilit√† = [0.07585818 0.92414182]\n\n\n\n\n\n\n\n\n\nEsercizio¬†86.2\n\nimport numpy as np\n\n\ndef update_value(Q, R, alpha):\n    \"\"\"\n    Aggiorna il valore atteso utilizzando il modello di Rescorla-Wagner.\n\n    Args:\n        Q (float): Valore atteso attuale.\n        R (float): Ricompensa ricevuta.\n        alpha (float): Tasso di apprendimento.\n\n    Returns:\n        float: Nuovo valore atteso.\n        float: Errore di previsione.\n    \"\"\"\n    # Calcola l'errore di previsione\n    prediction_error = R - Q\n    # Aggiorna il valore atteso\n    Q_new = Q + alpha * prediction_error\n    return Q_new, prediction_error\n\n\n# Esempio di utilizzo della funzione update_value\nQ = 0.5  # Valore atteso iniziale\nR_values = [1, 0, 1, 1, 0]  # Sequenza di ricompense ricevute\nalpha = 0.1  # Tasso di apprendimento\n\n# Inizializza una lista per tracciare i valori attesi e gli errori di previsione\nQ_values = [Q]\nprediction_errors = []\n\n# Aggiorna il valore atteso per ciascuna ricompensa ricevuta\nfor R in R_values:\n    Q, error = update_value(Q, R, alpha)\n    Q_values.append(Q)\n    prediction_errors.append(error)\n    print(\n        f\"Ricompensa: {R}, Errore di Previsione: {error:.2f}, Nuovo Valore Atteso: {Q:.2f}\"\n    )\n\n# Visualizziamo i risultati\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(Q_values, label=\"Valore Atteso\")\nplt.plot(\n    range(1, len(prediction_errors) + 1),\n    prediction_errors,\n    label=\"Errore di Previsione\",\n    linestyle=\"--\",\n)\nplt.xlabel(\"Prove\")\nplt.ylabel(\"Valore\")\nplt.title(\n    \"Aggiornamento del Valore Atteso e dell'Errore di Previsione nel Modello di Rescorla-Wagner\"\n)\nplt.legend()\nplt.grid(True)\nplt.show()\n\nRicompensa: 1, Errore di Previsione: 0.50, Nuovo Valore Atteso: 0.55\nRicompensa: 0, Errore di Previsione: -0.55, Nuovo Valore Atteso: 0.50\nRicompensa: 1, Errore di Previsione: 0.50, Nuovo Valore Atteso: 0.55\nRicompensa: 1, Errore di Previsione: 0.45, Nuovo Valore Atteso: 0.59\nRicompensa: 0, Errore di Previsione: -0.59, Nuovo Valore Atteso: 0.53\n\n\n\n\n\n\n\n\n\nEsercizio¬†86.3\n\nScenario 1: Apprendimento Rapido in un Ambiente Stabile\n\nTasso di Apprendimento (alpha): In questo scenario, un tasso di apprendimento elevato (ad esempio, alpha = 0.8) sarebbe vantaggioso perch√© l‚Äôambiente √® stabile e la ricompensa √® consistente. Un alto tasso di apprendimento permetter√† al cane di aggiornare rapidamente le sue aspettative e imparare il trucco pi√π velocemente.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso potrebbe essere basso (ad esempio, Q_0 = 0.1), riflettendo la mancanza di conoscenza iniziale del cane sul trucco e la ricompensa associata.\n\nScenario 2: Apprendimento Lento in un Ambiente Stabile\n\nTasso di Apprendimento (alpha): Qui, un tasso di apprendimento pi√π basso (ad esempio, alpha = 0.2) sarebbe pi√π appropriato. Anche se l‚Äôambiente √® stabile, un apprendimento pi√π lento potrebbe essere sufficiente poich√© il bambino potrebbe non essere costantemente focalizzato sui puzzle e pu√≤ imparare gradualmente.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso potrebbe essere moderato (ad esempio, Q_0 = 0.3), considerando che il bambino potrebbe avere un‚Äôidea preliminare che risolvere puzzle porta a una ricompensa, ma non √® ancora certo dell‚Äôentit√† della ricompensa.\n\nScenario 3: Apprendimento in un Ambiente Variabile\n\nTasso di Apprendimento (alpha): In un ambiente variabile, un tasso di apprendimento moderato (ad esempio, alpha = 0.5) potrebbe essere utile. Questo permetterebbe al giocatore di aggiornare rapidamente le aspettative senza essere troppo influenzato dalle variazioni casuali delle ricompense.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso potrebbe essere neutro (ad esempio, Q_0 = 0.5), poich√© il giocatore non ha informazioni iniziali solide su quale arma sia la migliore e dovrebbe esplorare per raccogliere dati.\n\nScenario 4: Apprendimento con Informazioni Iniziali Parziali\n\nTasso di Apprendimento (alpha): Un tasso di apprendimento moderato (ad esempio, alpha = 0.4) potrebbe essere adeguato. Il ricercatore dovrebbe essere in grado di aggiornare le sue aspettative basandosi su nuovi dati, ma non dovrebbe ignorare completamente le informazioni preliminari.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso dovrebbe essere relativamente alto (ad esempio, Q_0 = 0.7), riflettendo la conoscenza preliminare del ricercatore che un certo farmaco potrebbe essere efficace.\n\n\nIn conclusione\n\nTasso di Apprendimento (alpha): Un tasso di apprendimento elevato √® utile in ambienti stabili dove le informazioni raccolte sono affidabili, mentre un tasso pi√π basso √® preferibile in contesti dove l‚Äôapprendimento deve essere graduale o l‚Äôambiente √® meno prevedibile.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso riflette la conoscenza preliminare dell‚Äôagente. Un valore basso indica poca conoscenza iniziale, mentre un valore alto indica una forte aspettativa basata su informazioni preliminari.\n\nQuesto esercizio ti aiuta a comprendere come i parametri del modello di Rescorla-Wagner influenzano il processo di apprendimento e come adattare questi parametri in base al contesto specifico.\nEsercizio¬†86.4\n\nContesto 1: Addestramento di un Animale Domestico\n\nErrore di Previsione: Quando il cane esegue correttamente il comando e riceve una ricompensa, l‚Äôerrore di previsione sar√† positivo, indicando che il risultato √® migliore di quanto atteso. Questo rinforza il comportamento corretto.\nAggiornamento del Valore Atteso: Il valore atteso per eseguire il comando ‚Äúseduto‚Äù aumenter√†, portando il cane a eseguire il comando pi√π frequentemente in futuro.\nLimitazioni del Modello RW: Il modello potrebbe non catturare la variabilit√† individuale del cane, come il suo livello di motivazione o distrazione, che possono influenzare l‚Äôapprendimento.\n\nContesto 2: Apprendimento Scolastico\n\nErrore di Previsione: Se lo studente riceve un voto migliore del previsto, l‚Äôerrore di previsione sar√† positivo, motivando lo studente a continuare ad impegnarsi. Un voto peggiore del previsto porter√† a un errore di previsione negativo.\nAggiornamento del Valore Atteso: Il valore atteso per lo studio e l‚Äôimpegno nella materia aumenter√† con feedback positivi e diminuir√† con feedback negativi.\nLimitazioni del Modello RW: Il modello potrebbe non considerare fattori esterni come il supporto familiare, lo stress o le risorse disponibili per lo studente, che influenzano l‚Äôapprendimento.\n\nContesto 3: Terapia Comportamentale\n\nErrore di Previsione: Quando il paziente affronta la situazione temuta con successo e riceve un rinforzo positivo, l‚Äôerrore di previsione sar√† positivo, riducendo gradualmente l‚Äôansia associata.\nAggiornamento del Valore Atteso: Il valore atteso per affrontare la situazione temuta senza evitare aumenter√†, incoraggiando il paziente a continuare ad esporsi.\nLimitazioni del Modello RW: Il modello potrebbe non catturare l‚Äôimportanza del contesto terapeutico e del rapporto di fiducia tra paziente e terapeuta, che sono cruciali per il successo della terapia.\n\nContesto 4: Apprendimento nelle Organizzazioni\n\nErrore di Previsione: I dipendenti che ricevono premi o riconoscimenti migliori del previsto avranno un errore di previsione positivo, aumentando la loro motivazione e impegno.\nAggiornamento del Valore Atteso: Il valore atteso per raggiungere gli obiettivi di performance aumenter√† con i premi, incoraggiando i dipendenti a mantenere o migliorare le loro prestazioni.\nLimitazioni del Modello RW: Il modello potrebbe non tenere conto di fattori come la cultura aziendale, la collaborazione tra colleghi e l‚Äôequilibrio tra vita lavorativa e personale, che possono influenzare le performance dei dipendenti.\n\n\nIn conclusione,\n\nErrore di Previsione: Gioca un ruolo cruciale nell‚Äôapprendimento, influenzando il grado di aggiornamento delle aspettative in base ai risultati osservati.\nAggiornamento del Valore Atteso: Determina la probabilit√† che un comportamento venga ripetuto in futuro, basato sull‚Äôesperienza passata.\nLimitazioni del Modello RW: Sebbene il modello di Rescorla-Wagner fornisca un framework utile per comprendere l‚Äôapprendimento basato sul rinforzo, potrebbe non catturare tutte le sfaccettature dei contesti di apprendimento reali, inclusi fattori individuali, sociali e ambientali.\n\nQuesto esercizio ti aiuta a riflettere su come i concetti teorici del modello di Rescorla-Wagner si applicano a diversi contesti pratici di apprendimento e a riconoscere le potenziali limitazioni del modello.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>[</span>¬† <span class='chapter-title'>Modello Rescorla-Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_entropia.html",
    "href": "chapters/appendix/solutions_entropia.html",
    "title": "Appendice ¬†‚Äî Entropia",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 79\nEsercizio¬†79.1\n\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.1, 0.2, 0.7])\n\n\n# Calcoliamo l'entropia di $p$.\nh_p = -np.sum(p * np.log(p))\nprint(\"Entropia di p: \", h_p)\n\nEntropia di p:  1.0296530140645737\n\n\n\n# Calcoliamo l'entropia incrociata tra $p$ e $q$.\nh_pq = -np.sum(p * np.log(q))\nprint(\"Entropia incrociata tra p e q: \", h_pq)\n\nEntropia incrociata tra p e q:  1.372238457997479\n\n\n\n# Calcoliamo la divergenza di Kullback-Leibler da $p$ a $q$.\nkl_pq = h_pq - h_p\nprint(\"Divergenza KL da p a q: \", kl_pq)\n\nDivergenza KL da p a q:  0.34258544393290524\n\n\n\n# Lo stesso risultato si ottiene applicando la formula della Divergenza $\\mathbb{KL}$.\nnp.sum(p * (np.log(p) - np.log(q)))\n\n0.3425854439329054\n\n\n\n# Se invece $q$ √® molto simile a $p$, la differenza $\\mathbb{KL}$ √® molto minore.\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.2, 0.55, 0.25])\nnp.sum(p * (np.log(p) - np.log(q)))\n\n0.007041377136023895\n\n\nEsercizio¬†79.2\n\n# Define the parameters\nn = 4\np = 0.2\n\n# Compute the probability mass function\ntrue_py = stats.binom.pmf(range(n + 1), n, p)\nprint(true_py)\n\n[0.4096 0.4096 0.1536 0.0256 0.0016]\n\n\n\nq1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01])\nprint(q1)\n\n[0.46 0.42 0.1  0.01 0.01]\n\n\n\nq2 = [0.2] * 5\nprint(q2)\n\n[0.2, 0.2, 0.2, 0.2, 0.2]\n\n\n\n# La divergenza $\\mathbb{KL}$ di $q_1$ da $p$ √®\nkl_pq1 = np.sum(true_py * (np.log(true_py) - np.log(q1)))\nprint(\"Divergenza KL di q1 da p: \", kl_pq1)\n\nDivergenza KL di q1 da p:  0.02925199033345882\n\n\n\n# La divergenza $\\mathbb{KL}$ di $q_2$ da $p$ √®:\nkl_pq2 = np.sum(true_py * (np.log(true_py) - np.log(q2)))\nprint(\"Divergenza KL di q2 da p: \", kl_pq2)\n\nDivergenza KL di q2 da p:  0.48635777871415425\n\n\n√à chiaro che perdiamo una quantit√† maggiore di informazioni se, per descrivere la distribuzione binomiale \\(p\\), usiamo la distribuzione uniforme \\(q_2\\) anzich√© \\(q_1\\).\nEsercizio¬†79.3\n\n# Definire le distribuzioni p e q\np = np.array([0.01, 0.99])\nq = np.array([0.7, 0.3])\n\n# Calcolo dell'entropia di p\nh_p = -np.sum(p * np.log(p))\n\n# Calcolo dell'entropia incrociata da p a q\nh_pq = -np.sum(p * np.log(q))\n\n# Calcolo della divergenza KL da p a q\nkl_pq = h_pq - h_p\n\n# Calcolo dell'entropia di q\nh_q = -np.sum(q * np.log(q))\n\n# Calcolo dell'entropia incrociata da q a p\nh_qp = -np.sum(q * np.log(p))\n\n# Calcolo della divergenza KL da q a p\nkl_qp = h_qp - h_q\n\nprint(f\"Entropia di p: {h_p}\")\nprint(f\"Entropia incrociata da p a q: {h_pq}\")\nprint(f\"Divergenza KL da p a q: {kl_pq}\")\n\nprint(f\"\\nEntropia di q: {h_q}\")\nprint(f\"Entropia incrociata da q a p: {h_qp}\")\nprint(f\"Divergenza KL da q a p: {kl_qp}\")\n\nEntropia di p: 0.056001534354847345\nEntropia incrociata da p a q: 1.1954998257220641\nDivergenza KL da p a q: 1.1394982913672167\n\nEntropia di q: 0.6108643020548935\nEntropia incrociata da q a p: 3.226634230947714\nDivergenza KL da q a p: 2.6157699288928207",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>\\</span>¬† <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_replication_crisis.html",
    "href": "chapters/appendix/solutions_replication_crisis.html",
    "title": "[Appendice ] ‚Äî Crisi della replicazione]{#sec-replication-crisis .quarto-section-identifier}",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 94\nEsercizio¬†94.1\nLe argomentazioni di Gelman e Brown (2024) mettono in luce fattori come la selezione dei confronti, la variabilit√† degli effetti tra i soggetti, l‚Äôinfluenza delle condizioni sperimentali, e l‚Äôassenza di un chiaro meccanismo d‚Äôazione. Questi stessi fattori potrebbero essere stati determinanti nella mancata replicazione dello studio di Karata≈ü e Cutright (2023). La combinazione di una possibile sovrainterpretazione dei dati iniziali, la presenza di variabili non controllate, e la mancanza di un chiaro modello teorico per spiegare i risultati originali potrebbe aver portato a risultati che non si sono confermati in studi successivi.\n\n\nCapitolo 97\nEsercizio¬†97.1\nIl seguente codice √® scritto in R. Pu√≤ essere facilmente convertito in Python.\nset.seed(42)  # Imposta un seed per la riproducibilit√†\n\nn_sim &lt;- 10000  # Numero di simulazioni\nn_per_group &lt;- 20  # Campioni per gruppo\nsd_max_fp &lt;- 10  # Deviazione standard scelta per massimizzare i falsi positivi\n\n# Vettori per conservare i risultati\nsignificant_results &lt;- numeric()\neffect_sizes &lt;- numeric()\n\nfor (i in 1:n_sim) {\n  # Genera due gruppi con media 0 e sd massimizzata\n  group1 &lt;- rnorm(n_per_group, mean = 0, sd = sd_max_fp)\n  group2 &lt;- rnorm(n_per_group, mean = 0, sd = sd_max_fp)\n  \n  # Esegui il t-test\n  t_test &lt;- t.test(group1, group2)\n  \n  # Calcola l'effect size (d di Cohen)\n  pooled_sd &lt;- sqrt(((n_per_group - 1) * var(group1) + (n_per_group - 1) * var(group2)) / \n                      (2 * n_per_group - 2))\n  cohen_d &lt;- abs(mean(group1) - mean(group2)) / pooled_sd\n  \n  # Conserva i risultati solo se significativi\n  if (t_test$p.value &lt; 0.05) {\n    significant_results &lt;- c(significant_results, t_test$p.value)\n    effect_sizes &lt;- c(effect_sizes, cohen_d)\n  }\n}\n\n# Calcola la proporzione di risultati significativi\nproportion_significant &lt;- length(significant_results) / n_sim\n\n# Calcola l'effect size medio dei risultati significativi\nmean_effect_size_significant &lt;- mean(effect_sizes)\n\n# Stampa i risultati\ncat(\"Proporzione di risultati statisticamente significativi:\", proportion_significant, \"\\n\")\ncat(\"Effect size medio dei risultati significativi:\", mean_effect_size_significant, \"\\n\")\n\n\n\n\nGelman, Andrew, e Nicholas JL Brown. 2024. ¬´How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology¬ª.\n\n\nKarata≈ü, Mustafa, e Keisha M Cutright. 2023. ¬´Thinking about God increases acceptance of artificial intelligence in decision-making¬ª. Proceedings of the National Academy of Sciences 120 (33): e2218961120.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>]</span>¬† <span class='chapter-title'>Crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#parametri-nel-modello-di-diffusione-del-drift-ddm",
    "href": "chapters/cognitive_models/01_ddm.html#parametri-nel-modello-di-diffusione-del-drift-ddm",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.3 Parametri nel modello di diffusione del drift (DDM)",
    "text": "89.3 Parametri nel modello di diffusione del drift (DDM)\nIl modello di diffusione del drift (DDM) parte dall‚Äôassunto che il tempo di reazione (RT) in ogni prova, definito come il tempo che intercorre dall‚Äôinizio dello stimolo fino all‚Äôesecuzione della risposta motoria, possa essere scomposto in tre componenti: il tempo necessario per il sistema nervoso per rilevare o codificare lo stimolo (spesso indicato come Te), il tempo per raggiungere una decisione su come rispondere a quello stimolo (Td) e il tempo richiesto per eseguire la risposta motoria scelta (Tr). Pertanto, in una data prova, il tempo di reazione osservato √® la somma di queste tre componenti: RT = Te + Td + Tr.\nSebbene in teoria sia possibile misurare separatamente Te e Tr, normalmente il tempo di codifica e di risposta vengono combinati in un unico parametro che rappresenta il tempo di non-decisione (Ter), ovvero la parte del RT che avviene indipendentemente dal processo decisionale Td. Con questa semplificazione, l‚Äôequazione diventa RT = Ter + Td. I valori tipici di Ter variano tra 0.1 e 0.5 secondi, in parte a seconda della complessit√† degli stimoli e delle risposte motorie specifiche coinvolte (ad esempio, le persone possono generalmente eseguire saccadi pi√π velocemente rispetto alla pressione di un tasto). Si assume solitamente che Ter possa differire tra individui, ma rimanga relativamente costante tra le prove per un singolo individuo che esegue un determinato compito.\nL‚Äôaltra componente del RT √® il tempo di decisione (Td), che √® il tempo necessario per prendere una decisione (dopo che lo stimolo √® stato codificato, ma prima che venga eseguita la risposta scelta). In una singola prova, l‚Äôinformazione rumorosa viene accumulata nel tempo mentre il processo si muove lungo un corridoio delimitato dalle due possibili risposte. Man mano che si accumulano maggiori informazioni, l‚Äôevidenza a favore di una risposta spinge il processo decisionale pi√π vicino al confine corrispondente. Quando uno dei confini viene raggiunto, viene selezionata la risposta corrispondente, e il tempo per raggiungere quel confine definisce il tempo di decisione Td in quella prova.\n\n\n\nDrift Diffusion Model.\n\n\nIl modello DDM prevede che il processo decisionale inizi da un punto sulla y definito da un parametro che denota un punto di partenza relativo (z) che varia da 0 (asse inferiore) a 1 (asse superiore). Se z = 0.5, il punto di partenza √® equidistante dai due confini. Tuttavia, se z si avvicina a 1 (o 0), il processo decisionale inizia vicino al confine superiore (o inferiore) in ogni prova, il che significa che √® necessaria meno informazione per raggiungere quel confine e iniziare la risposta corrispondente. Il punto di partenza z riflette quindi un bias di risposta a favore di una o dell‚Äôaltra risposta.\nIl processo decisionale nel DDM √® considerato rumoroso, il che riflette la presenza di input sensoriali rumorosi, variazioni stocastiche nel tasso di scarica neuronale nei centri decisionali del cervello e anche fluttuazioni momentanee nell‚Äôattenzione. Questo rumore implica che lo stesso stimolo potrebbe non generare lo stesso tempo di decisione o addirittura la stessa risposta ogni volta che si verifica, portando a variazioni nel RT e nell‚Äôaccuratezza delle risposte tra le prove.\nNel DDM, il tasso medio al quale l‚Äôevidenza si accumula verso il confine corretto √® definito da un parametro che rappresenta il tasso di drift (drift rate) (d). Il tasso di drift √® una misura della velocit√† di elaborazione delle informazioni, che pu√≤ variare a seconda della difficolt√† del compito. Per compiti facili con stimoli altamente discriminabili, ci dovrebbe essere un alto tasso di drift (pendenza ripida su o gi√π), e l‚Äôevidenza dovrebbe accumularsi rapidamente e in modo affidabile verso il confine corretto, risultando in tempi di reazione rapidi e alta accuratezza. Per compiti pi√π difficili o stimoli pi√π ambigui, il tasso di drift pu√≤ essere pi√π basso (meno ripido), il che significa che l‚Äôaccumulo di evidenza √® pi√π lento e rumoroso, risultando in tempi di reazione pi√π lenti e variabili.\nRiassumendo, i parametri del DDM si mappano su diversi processi cognitivi: impostazioni di velocit√†-accuratezza (separazione del confine \\(a\\)), bias di risposta (punto di partenza \\(z\\)), velocit√† di elaborazione delle informazioni (tasso di drift \\(d\\)) e tempo di non-decisione (\\(Ter\\)). Questi parametri sono talvolta chiamati ‚Äúparametri liberi‚Äù, nel senso che possono assumere diversi valori liberamente, e proprio come le manopole di uno stereo, cambiare ciascun parametro influenza il comportamento del DDM.\nPer esempio, in un compito in cui il soggetto √® istruito a eseguire una risposta r1 il pi√π rapidamente possibile ogni volta che viene mostrato uno stimolo s1, ma una risposta diversa r2 ogni volta che viene mostrato uno stimolo s2, l‚Äôaumento del punto di partenza (\\(z\\)) avviciner√† il punto di partenza al confine superiore, rendendo pi√π facile (e veloce) decidere a favore di r2 in ogni prova. Questo potrebbe creare un bias di risposta preponderante per r2 se, ad esempio, le risposte r2 sono molto pi√π frequenti o altamente ricompensate nel compito.\nRiducendo la separazione del confine (\\(a\\)), entrambe le risposte diventerebbero pi√π veloci, ma aumenterebbe anche il tasso di errore, perch√© il rumore potrebbe facilmente spingere il processo decisionale oltre uno dei confini. Una separazione del confine ridotta potrebbe verificarsi se, ad esempio, il soggetto fosse stato istruito a rispondere rapidamente, anche a scapito della precisione. Al contrario, aumentare a avrebbe l‚Äôeffetto opposto, aumentando la cautela nelle risposte e producendo tempi di reazione pi√π lenti.\nAumentare il tasso di drift per un tipo di stimolo comporterebbe un accumulo di evidenza pi√π rapido in quelle prove, mentre diminuirlo comporterebbe un accumulo pi√π lento. I tassi di drift sono tipicamente pi√π lenti in condizioni di compiti pi√π difficili, con minore discriminabilit√† degli stimoli o in presenza di stimoli distraenti.\nInfine, aumentare o diminuire il tempo di non-decisione Ter influenzerebbe il tempo di reazione complessivo, senza altrimenti influenzare il processo decisionale. Ad esempio, pazienti con disfunzioni motorie potrebbero avere un Ter aumentato (e un RT complessivo maggiore), indipendentemente dalle considerazioni decisionali.\nIn sintesi, i valori dei parametri del DDM Ter, \\(a\\), \\(z\\) e \\(d\\) interagiscono per influenzare le prestazioni complessive del compito, compresi sia l‚Äôaccuratezza che il tempo di reazione.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#panoramica-del-modello-di-diffusione-del-drift-ddm",
    "href": "chapters/cognitive_models/01_ddm.html#panoramica-del-modello-di-diffusione-del-drift-ddm",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.2 Panoramica del modello di diffusione del drift (DDM)",
    "text": "89.2 Panoramica del modello di diffusione del drift (DDM)\nNelle attivit√† di decisione rapida in psicologia cognitiva, ai partecipanti viene richiesto di scegliere rapidamente tra due o pi√π risposte in competizione. Esempi tipici includono il compito di decisione lessicale (dove si preme un tasto se lo stimolo √® una parola e un altro se non lo √®), il compito di Stroop (in cui si preme un tasto corrispondente al colore dell‚Äôinchiostro di una parola, ignorando il contenuto semantico della parola stessa) e il compito dei flanker saccadici (che richiede di muovere l‚Äôocchio nella direzione indicata da uno stimolo centrale, ignorando le direzioni dei flanker).\nIn questi compiti, anche partecipanti ben addestrati mostrano un compromesso tra velocit√† e accuratezza: essi possono incrementare l‚Äôaccuratezza a scapito di tempi di risposta pi√π lenti (e quindi maggiormente deliberati), oppure optare per decisioni rapide che risultano pi√π suscettibili a errori (Schouten e Bekker, 1967; Wickelgren, 1977). Questo trade-off tra velocit√† e accuratezza sembra essere almeno parzialmente sotto il controllo conscio, poich√© i partecipanti possono modulare le loro prestazioni in base alle istruzioni ricevute per enfatizzare la velocit√† o l‚Äôaccuratezza (Ratcliff e Rouder, 1998; Voss et al., 2004; Milosavljevic et al., 2010; Katsimpokis et al., 2020). Questa flessibilit√† comportamentale complica l‚Äôinterpretazione dei dati, poich√© le differenze nei tempi di risposta tra gruppi possono riflettere meccanismi cognitivi sottostanti distinti (Voss et al., 2013). Ad esempio, due gruppi di pazienti potrebbero entrambi avere tempi di reazione medi pi√π lenti rispetto a un gruppo di controllo sano, ma mentre in un gruppo ci√≤ potrebbe riflettere una strategia decisionale pi√π cauta, nell‚Äôaltro potrebbe indicare un rallentamento dovuto alla patologia. √à quindi fondamentale disporre di metodi di analisi che considerino non solo la velocit√† e l‚Äôaccuratezza, ma anche l‚Äôinterazione tra queste due variabili.\nPer affrontare queste complessit√†, un approccio complementare all‚Äôanalisi dei dati comportamentali osservati √® l‚Äôuso di modelli computazionali che mirano a inferire i parametri di modelli che descrivono processi cognitivi latenti. Questi parametri, quando combinati, sono in grado di riprodurre la distribuzione osservata dei tempi di reazione (RT) e delle accuratezze.\nIl modello di diffusione del drift (Drift Diffusion Model, DDM), descritto inizialmente da Ratcliff e colleghi (Ratcliff, 1978; Ratcliff e McKoon, 2008; Ratcliff et al., 2016), √® un esempio prominente di una classe pi√π ampia di modelli denominati ‚Äúmodelli di accumulazione dell‚Äôevidenza‚Äù. Tali modelli concettualizzano il processo decisionale come un accumulo di evidenza a favore di una delle risposte possibili, fino al raggiungimento di una soglia decisionale che innesca la risposta corrispondente. Questi modelli, noti anche come modelli di campionamento sequenziale, suggeriscono che il sistema nervoso acquisisca ripetutamente frammenti di informazione (campioni) dall‚Äôambiente in modo sequenziale, fino a raggiungere una soglia di evidenza sufficiente per prendere una decisione. Il compromesso tra velocit√† e accuratezza rappresenta quindi un punto di equilibrio che determina quando interrompere il campionamento e agire sulla base delle informazioni accumulate.\nCome tutti i modelli computazionali, il DDM √® formalizzato attraverso un insieme di equazioni matematiche che includono diversi parametri, ciascuno dei quali pu√≤ essere assegnato a valori differenti. Un modo intuitivo di concepire i parametri √® considerarli come regolatori (o sliders) di un sistema stereo, ognuno dei quali controlla un aspetto diverso del suono (ad esempio, alti, bassi, volume) e che possono essere regolati singolarmente per ottenere l‚Äôeffetto desiderato complessivo. Analogamente, i parametri in un modello di accumulazione dell‚Äôevidenza regolano aspetti come la velocit√† di accumulazione dell‚Äôevidenza, un bias intrinseco verso una delle risposte, e la tendenza a privilegiare la velocit√† rispetto all‚Äôaccuratezza. La regolazione di ciascuno di questi parametri influenza il comportamento del modello.\nNelle sezioni seguenti, descriveremo i passaggi principali nel processo di modellizzazione. Inizialmente, forniremo una descrizione generale del DDM, dei suoi parametri e del suo utilizzo in psicologia cognitiva. Successivamente, presenteremo un esempio concreto di applicazione del DDM in un semplice compito di decisione a due scelte, illustrando il processo di fitting del modello per stimare i valori dei parametri per un singolo partecipante, seguito dalla validazione del modello. Infine, discuteremo come riportare i risultati del modello e sottoporli ad analisi statistica.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#simulazione",
    "href": "chapters/cognitive_models/01_ddm.html#simulazione",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.7 Simulazione",
    "text": "89.7 Simulazione\nL‚Äôobiettivo di questa sezione √® esaminare un campione di dati generato in conformit√† con il modello DDM. Nella simulazione, i parametri utilizzati per generare i dati secondo il DDM sono noti. Successivamente, ci proponiamo di inferire questi parametri a partire dai dati simulati. Per raggiungere questo scopo, utilizzeremo un approccio bayesiano implementato in Stan.\nIniziamo generando i dati secondo il DDM utilizzando i seguenti parametri:\n\nDrift rate: 2.0\nThreshold separation (separazione delle soglie): 1.0\nNon-decision time (tempo di non decisione): 0.3\nStarting point (punto di partenza) \\(z\\): 0.5\n\n\ndef simulate_ddm(v, a, t, z, n_trials):\n    \"\"\"\n    Simulate data from a simplified Drift Diffusion Model.\n\n    Parameters:\n    v (float): Drift rate\n    a (float): Boundary separation\n    t (float): Non-decision time\n    z (float): Starting point (a priori bias)\n    n_trials (int): Number of trials to simulate\n\n    Returns:\n    tuple: (RTs, responses)\n    \"\"\"\n    RTs = []\n    responses = []\n\n    for _ in range(n_trials):\n        x = z * a  # starting point\n        time = 0\n\n        while True:\n            x += v * 0.001 + np.random.normal(\n                0, np.sqrt(0.001)\n            )  # update every millisecond\n            time += 0.001\n\n            if x &lt;= 0 or x &gt;= a:\n                break\n\n        RT = time + t  # add non-decision time\n        response = 1 if x &gt;= a else 0\n\n        RTs.append(RT)\n        responses.append(response)\n\n    return np.array(RTs), np.array(responses)\n\n\n# Parameters\nv_true = 2.0\na_true = 1.0\nt_true = 0.3\nz_true = 0.5\nn_trials = 1000\n\nRTs, responses = simulate_ddm(v_true, a_true, t_true, z_true, n_trials)\n\nprint(f\"Mean RT: {np.mean(RTs):.3f}\")\nprint(f\"Proportion of upper boundary responses: {np.mean(responses):.3f}\")\n\nMean RT: 0.501\nProportion of upper boundary responses: 0.888\n\n\nCreiamo un istogramma dei tempi di reazione (RT).\n\nplt.hist(RTs, bins=30, edgecolor=\"black\")\nplt.title(\"Istogramma dei Tempi di Reazione (RT)\")\nplt.xlabel(\"Tempo di Reazione (secondi)\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\nImportiamo e compiliamo il codice Stan, che utilizzeremo per generare le distribuzioni a posteriori dei parametri del DDM, basandoci su distribuzioni a priori debolmente informative.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"ddm_wiener_model.stan\"\n)\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\nfunctions {\n  real wiener_rng(real alpha, real tau, real beta, real delta) {\n    real dt = 0.0001;\n    real x = alpha * beta;\n    real t = 0;\n    while (x &gt; 0 && x &lt; alpha) {\n      x += delta * dt + sqrt(dt) * normal_rng(0, 1);\n      t += dt;\n    }\n    return t + tau;\n  }\n}\ndata {\n  int&lt;lower=1&gt; N; // number of trials\n  array[N] real&lt;lower=0&gt; rt; // response times\n  array[N] int&lt;lower=0, upper=1&gt; resp; // responses (0 or 1)\n}\nparameters {\n  real&lt;lower=0, upper=10&gt; v; // drift rate\n  real&lt;lower=0.1, upper=5&gt; a; // boundary separation\n  real&lt;lower=0.001, upper=min(rt)&gt; t; // non-decision time\n  real&lt;lower=0.1, upper=0.9&gt; z; // starting point\n}\nmodel {\n  // Priors\n  v ~ normal(2, 1) T[0, 10];\n  a ~ normal(1, 0.5) T[0.1, 5];\n  t ~ normal(0.3, 0.1) T[0.001, min(rt)];\n  z ~ beta(5, 5);\n  \n  // Likelihood\n  for (i in 1 : N) {\n    if (rt[i] &gt; t) {\n      if (resp[i] == 1) {\n        target += wiener_lpdf(rt[i] | a, t, z, v);\n      } else {\n        target += wiener_lpdf(rt[i] | a, t, 1 - z, -v);\n      }\n    } else {\n      target += -1e10; // Strongly penalize impossible RTs\n    }\n  }\n}\ngenerated quantities {\n  array[N] real log_lik;\n  array[N] real y_pred;\n  for (i in 1 : N) {\n    if (rt[i] &gt; t) {\n      if (resp[i] == 1) {\n        log_lik[i] = wiener_lpdf(rt[i] | a, t, z, v);\n        y_pred[i] = wiener_rng(a, t, z, v);\n      } else {\n        log_lik[i] = wiener_lpdf(rt[i] | a, t, 1 - z, -v);\n        y_pred[i] = wiener_rng(a, t, 1 - z, -v);\n      }\n    } else {\n      log_lik[i] = -1e10;\n      y_pred[i] = t; // Set to non-decision time for impossible RTs\n    }\n  }\n}\n\n\n\nLa likelihood (verosimiglianza) nel modello Stan specifica la probabilit√† dei dati osservati dato un insieme di parametri. Nel contesto del DDM, la likelihood √® costruita sulla base della distribuzione di probabilit√† dei tempi di reazione (RT) per una risposta corretta o errata, dato un set di parametri del modello (drift rate \\(v\\), boundary separation \\(a\\), non-decision time \\(t\\), e starting point \\(z\\)).\nNel blocco model, la likelihood √® costruita utilizzando un ciclo for per ogni trial (prova) nei dati. Per ogni prova, la likelihood tiene conto delle seguenti considerazioni:\n\nCondizioni su \\(\\text{rt}[i] &gt; t\\):\n\nPrima di tutto, il modello verifica se il tempo di reazione osservato (rt[i]) √® maggiore del tempo di non-decisione (t). Questo perch√© il tempo di reazione non pu√≤ essere inferiore al tempo di non-decisione: se lo fosse, sarebbe un tempo di reazione impossibile.\nSe \\(\\text{rt}[i] &gt; t\\), il codice procede a calcolare la verosimiglianza; altrimenti, impone una penalit√† molto forte (-1e10) per quei dati, indicando che tali osservazioni sono impossibili o estremamente improbabili. Questa penalit√† √® cos√¨ grande da garantire che tali eventi non contribuiscano alla log-verosimiglianza complessiva, influenzando negativamente l‚Äôadattamento del modello se venissero accettati.\n\nCalcolo della Likelihood per le Risposte:\n\nRisposte corrette (resp[i] == 1):\n\nSe la risposta √® corretta (resp[i] == 1), viene utilizzata la distribuzione dei tempi di reazione del DDM per una risposta corretta, data dai parametri \\(a\\), \\(t\\), \\(z\\), e \\(v\\).\nLa funzione wiener_lpdf(rt[i] | a, t, z, v) calcola il log della densit√† di probabilit√† per il tempo di reazione osservato (rt[i]) sotto queste condizioni.\n\nRisposte errate (resp[i] == 0):\n\nSe la risposta √® errata (resp[i] == 0), viene utilizzata la distribuzione dei tempi di reazione del DDM per una risposta errata. In questo caso, il modello inverte il drift rate a \\(-v\\) e considera la posizione di partenza opposta \\((1 - z)\\).\nLa funzione wiener_lpdf(rt[i] | a, t, 1 - z, -v) calcola il log della densit√† di probabilit√† per il tempo di reazione osservato (rt[i]) sotto queste condizioni.\n\n\n\nQuesto approccio consente di stimare i parametri del modello che meglio spiegano i dati osservati, tenendo conto delle distribuzioni stocastiche che descrivono il processo decisionale nel contesto di un compito di scelta binaria.\nNel blocco parameters e model del codice, vediamo le seguenti distribuzioni a priori.\n\nv ~ normal(2, 1) T[0, 10]: Il drift rate (v) ha una distribuzione a priori normale con media 2 e deviazione standard 1, troncata tra 0 e 10. Questo prior riflette l‚Äôassunzione che il drift rate tipico sia intorno a 2, con una moderata incertezza, ed √® limitato a valori non negativi e ragionevolmente grandi (fino a 10) per rappresentare le condizioni realistiche di un processo decisionale umano.\na ~ normal(1, 0.5) T[0.1, 5]: La separazione delle soglie (a) ha una distribuzione a priori normale con media 1 e deviazione standard 0.5, troncata tra 0.1 e 5. Questo prior suggerisce che, normalmente, i confini sono vicini a 1, con una certa variazione consentita. La troncatura assicura che il parametro rimanga in un intervallo ragionevole, evitando valori troppo piccoli o troppo grandi che non sarebbero realistici nei modelli di decisione umana.\nt ~ normal(0.3, 0.1) T[0.001, min(rt)]: Il tempo di non-decisione (t) ha una distribuzione a priori normale con media 0.3 e deviazione standard 0.1, troncata tra 0.001 e il valore minimo dei tempi di reazione osservati min(rt). Questo prior riflette l‚Äôidea che il tempo di non-decisione (che rappresenta il tempo impiegato per percepire e avviare una risposta senza prendere una decisione) √® solitamente intorno a 0.3 secondi, ma con una moderata variabilit√†. La troncatura inferiore (0.001) impedisce che il tempo di non-decisione diventi irrealisticamente piccolo, mentre la troncatura superiore (min(rt)) garantisce che (t) sia sempre inferiore a qualsiasi tempo di reazione registrato.\nz ~ beta(5, 5): Il punto di partenza (z) ha una distribuzione a priori beta con parametri 5 e 5, limitata tra 0.1 e 0.9. Questo prior beta √® simmetrico intorno a 0.5, suggerendo una preferenza iniziale che il punto di partenza sia centrato tra le due soglie decisionali, ma con una certa variabilit√† consentita. La troncatura tra 0.1 e 0.9 evita punti di partenza troppo vicini alle soglie, il che rappresenterebbe un bias estremo non tipico nelle decisioni umane.\n\nIn sintesi, questi priors debolmente informativi assicurano che le stime dei parametri siano basate sui dati osservati, ma anche che rimangano in un intervallo realistico.\nCreiamo un dizionario con i dati nel formato richiesto da Stan.\n\n# Create the data dictionary for the Stan models\nstan_data = {\n    \"N\": len(RTs),  # Number of trials\n    \"rt\": RTs,  # Reaction times\n    \"resp\": responses,  # Accuracy\n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n07:05:19 - cmdstanpy - INFO - CmdStan start processing\n07:05:19 - cmdstanpy - INFO - Chain [1] start processing\n07:05:19 - cmdstanpy - INFO - Chain [2] start processing\n07:05:19 - cmdstanpy - INFO - Chain [3] start processing\n07:05:19 - cmdstanpy - INFO - Chain [4] start processing\n07:06:15 - cmdstanpy - INFO - Chain [3] done processing\n07:06:16 - cmdstanpy - INFO - Chain [2] done processing\n07:06:17 - cmdstanpy - INFO - Chain [1] done processing\n07:06:18 - cmdstanpy - INFO - Chain [4] done processing\n\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpeh6g91py/ddm_wiener_modelhxa8924m/ddm_wiener_model-20240829070519_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpeh6g91py/ddm_wiener_modelhxa8924m/ddm_wiener_model-20240829070519_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpeh6g91py/ddm_wiener_modelhxa8924m/ddm_wiener_model-20240829070519_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpeh6g91py/ddm_wiener_modelhxa8924m/ddm_wiener_model-20240829070519_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri del DDM.\n\nfit_az = az.from_cmdstanpy(posterior=fit)\naz.summary(fit_az, var_names=[\"v\", \"a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nv\n1.93\n0.10\n1.75\n2.11\n0.0\n0.0\n3858.53\n4325.16\n1.0\n\n\na\n1.03\n0.02\n0.99\n1.07\n0.0\n0.0\n4116.55\n5011.74\n1.0\n\n\nt\n0.30\n0.00\n0.30\n0.31\n0.0\n0.0\n3233.80\n4430.35\n1.0\n\n\nz\n0.52\n0.01\n0.49\n0.54\n0.0\n0.0\n3782.31\n4288.92\n1.0\n\n\n\n\n\n\n\n\nDa notare che l‚Äôapproccio bayesiano √® riuscito a fornire stime accurate dei parametri utilizzati per la simulazione dei dati, con un livello di incertezza relativamente basso. Questo √® stato possibile grazie all‚Äôuso di un campione di dati piuttosto ampio (N = 1000), che rappresenta le prove di un singolo soggetto.\nAbbiamo utilizzato il metodo Leave-One-Out (LOO) cross-validation per valutare il modello. I valori k di Pareto sono stati calcolati per identificare eventuali influenze indebite di osservazioni anomale sui risultati:\n\nloo_results = az.loo(fit_az)\nprint(loo_results)\n\nComputed from 8000 posterior samples and 1000 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   404.07    34.22\np_loo        3.79        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1000  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nTutte le osservazioni hanno valori k di Pareto ben sotto la soglia di 0.5, il che significa che non ci sono prove di influenze indebite da parte di osservazioni anomale sui risultati. I risultati indicano dunque che non ci sono evidenze di influenze eccessive da parte di osservazioni anomale nel campione, confermando che il modello √® stabile e le stime sono affidabili.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#processo-di-wiener",
    "href": "chapters/cognitive_models/01_ddm.html#processo-di-wiener",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.5 Processo di Wiener",
    "text": "89.5 Processo di Wiener\nPer comprendere meglio il funzionamento del DDM, √® utile chiarire il concetto di moto browniano (ovvero, la componente \\(B_t\\) nell‚ÄôEquazione¬†89.1), noto anche come processo di Wiener.\nIl processo di Wiener, o moto browniano, √® un tipo di processo stocastico che descrive il comportamento casuale di una particella in movimento. √à uno dei modelli pi√π semplici e utilizzati per rappresentare l‚Äôevoluzione temporale di variabili che cambiano in modo incerto e imprevedibile nel tempo.\nIl processo di Wiener ha diverse propriet√† che lo rendono utile per modellare fenomeni casuali:\n\nInizio a zero: Il processo inizia da un punto di partenza, spesso zero, cio√® \\(W(0) = 0\\).\nIncrementi indipendenti: Gli incrementi del processo sono indipendenti tra loro. Ci√≤ significa che il cambiamento del valore del processo in un intervallo di tempo non dipende dal cambiamento in un altro intervallo di tempo non sovrapposto.\nIncrementi normali: Gli incrementi del processo di Wiener su un intervallo di tempo \\(t\\) sono distribuiti normalmente (secondo una distribuzione gaussiana) con media 0 e varianza proporzionale a \\(t\\). Formalmente, se \\(t_2 &gt; t_1\\), allora \\(W(t_2) - W(t_1) \\sim N(0, t_2 - t_1)\\).\nContinuit√†: Il processo di Wiener √® continuo, senza salti improvvisi, il che implica che il percorso del processo nel tempo √® una funzione continua.\n\nNel contesto del Drift Diffusion Model (DDM), il processo di Wiener √® utilizzato per rappresentare le fluttuazioni casuali nel processo di accumulo dell‚Äôevidenza verso una delle due possibili decisioni.\n\nEvidenza accumulata: Nel DDM, l‚Äôaccumulo di evidenza per una decisione √® considerato come un processo che si evolve nel tempo. Questo accumulo √® influenzato da un termine deterministico (il drift rate, \\(v\\)) e da un termine stocastico (il rumore, modellato dal processo di Wiener).\nTermine deterministico (drift rate, \\(v\\)): Rappresenta la velocit√† media di accumulo dell‚Äôevidenza verso una delle decisioni. Un drift rate positivo indica una tendenza verso una decisione ‚Äúa favore‚Äù, mentre un drift rate negativo indica una tendenza verso una decisione ‚Äúcontro‚Äù.\nTermine stocastico (rumore): Rappresenta la variabilit√† casuale nell‚Äôaccumulo dell‚Äôevidenza. Questo rumore √® modellato come un processo di Wiener, il che significa che l‚Äôevidenza pu√≤ fluttuare casualmente mentre si accumula nel tempo. Ecco una versione rivista del testo che segue il precedente, migliorando la chiarezza e la coerenza:\n\n\n89.5.1 Simulazione di un Processo di Wiener\nPer simulare un processo di Wiener, possiamo utilizzare un semplice modello matematico che genera incrementi casuali normali a ogni passo temporale. Nel contesto del DDM, l‚Äôevidenza accumulata \\(X(t)\\) a un tempo \\(t\\) pu√≤ essere rappresentata come:\n\\[\nX(t + \\Delta t) = X(t) + v \\Delta t + s \\Delta W,\n\\]\ndove:\n\n\\(\\Delta t\\) √® un piccolo intervallo di tempo.\n\\(v\\) √® il drift rate, che rappresenta la velocit√† media con cui l‚Äôevidenza si accumula in una direzione preferita.\n\\(s\\) √® la deviazione standard del rumore, che misura l‚Äôintensit√† delle fluttuazioni casuali nel processo di accumulo dell‚Äôevidenza.\n\\(\\Delta W \\sim N(0, \\Delta t)\\) √® un incremento casuale del processo di Wiener, distribuito normalmente con media 0 e varianza \\(\\Delta t\\). Questo termine rappresenta il rumore stocastico che influenza il processo decisionale.\n\nUn esempio intuitivo per comprendere il funzionamento di questi elementi √® il seguente: immagina di camminare su una linea dritta su una superficie ghiacciata. Se cammini dritto, il drift rate \\(v\\) rappresenta il tuo intento di muoverti verso una direzione specifica. Tuttavia, poich√© la superficie √® scivolosa, ogni passo che fai √® influenzato dalla casualit√† (il processo di Wiener), facendoti scivolare in modo imprevedibile in diverse direzioni. La tua posizione finale dipender√† sia dalla tua intenzione di camminare dritto (drift rate) sia dalla casualit√† dei tuoi scivolamenti (rumore stocastico).\nIn conclusione, nel DDM, il processo di Wiener rappresenta la componente casuale del processo decisionale, mentre il drift rate rappresenta la componente sistematica o deterministica. Le soglie decisionali determinano i criteri per la decisione finale. Insieme, questi elementi permettono di modellare il processo di accumulazione dell‚Äôevidenza che porta alla decisione finale e determina il tempo di reazione in situazioni di scelta binaria.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#face-masks-influence-emotion-judgments-of-facial-expressions-a-drift-diffusion-model",
    "href": "chapters/cognitive_models/01_ddm.html#face-masks-influence-emotion-judgments-of-facial-expressions-a-drift-diffusion-model",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.8 Face Masks Influence Emotion Judgments of Facial Expressions: A Drift-Diffusion Model",
    "text": "89.8 Face Masks Influence Emotion Judgments of Facial Expressions: A Drift-Diffusion Model\nPer fare un esercizio, esaminiamo ora lo studio di\n\ndf_angry_upper = pd.read_csv(\"../../data/williams_2023_angry_upper.csv\")\ndf_angry_upper.head()\n\n\n\n\n\n\n\n\n\nsubj_idx\ntrial\nresponse\nrt\nresp\n\n\n\n\n0\n11dsfdtym1yy5mx\n2\n0\n1.66723\n1\n\n\n1\n11dsfdtym1yy5mx\n9\n0\n0.88728\n1\n\n\n2\n11dsfdtym1yy5mx\n38\n0\n0.83632\n1\n\n\n3\n11dsfdtym1yy5mx\n43\n0\n0.95458\n1\n\n\n4\n11dsfdtym1yy5mx\n93\n0\n0.73080\n1\n\n\n\n\n\n\n\n\n\ndf_angry_baseline = pd.read_csv(\"../../data/williams_2023_angry_baseline.csv\")\ndf_angry_baseline.head()\n\n\n\n\n\n\n\n\n\nsubj_idx\ntrial\nresponse\nrt\nresp\n\n\n\n\n0\n11dsfdtym1yy5mx\n24\n0\n0.900965\n1\n\n\n1\n11dsfdtym1yy5mx\n31\n0\n1.270770\n1\n\n\n2\n11dsfdtym1yy5mx\n50\n0\n1.102485\n1\n\n\n3\n11dsfdtym1yy5mx\n58\n0\n0.810590\n1\n\n\n4\n11dsfdtym1yy5mx\n60\n0\n1.048160\n1\n\n\n\n\n\n\n\n\n\nstan_data_baseline = {\n    \"N\": len(df_angry_baseline[\"rt\"]),  # Number of trials\n    \"rt\": df_angry_baseline[\"rt\"],  # Reaction times\n    \"resp\": df_angry_baseline[\"resp\"],  # Accuracy\n}\n\n\nfit_baseline = model.sample(\n    data=stan_data_baseline,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n13:11:06 - cmdstanpy - INFO - CmdStan start processing\n13:11:06 - cmdstanpy - INFO - Chain [1] start processing\n13:11:06 - cmdstanpy - INFO - Chain [2] start processing\n13:11:06 - cmdstanpy - INFO - Chain [3] start processing\n13:11:06 - cmdstanpy - INFO - Chain [4] start processing\n13:16:18 - cmdstanpy - INFO - Chain [1] done processing\n13:16:18 - cmdstanpy - INFO - Chain [4] done processing\n13:16:21 - cmdstanpy - INFO - Chain [3] done processing\n13:16:22 - cmdstanpy - INFO - Chain [2] done processing\n\n\n\nfit_baseline_az = az.from_cmdstanpy(posterior=fit_baseline)\naz.summary(fit_baseline_az, var_names=[\"v\", \"a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nv\n0.43\n0.03\n0.37\n0.48\n0.0\n0.0\n4921.34\n5331.86\n1.0\n\n\na\n2.19\n0.03\n2.15\n2.24\n0.0\n0.0\n4662.82\n4737.77\n1.0\n\n\nt\n0.01\n0.01\n0.00\n0.02\n0.0\n0.0\n4158.62\n2732.21\n1.0\n\n\nz\n0.47\n0.01\n0.45\n0.49\n0.0\n0.0\n4765.49\n5379.68\n1.0\n\n\n\n\n\n\n\n\n\nstan_data_upper = {\n    \"N\": len(df_angry_upper[\"rt\"]),  # Number of trials\n    \"rt\": df_angry_upper[\"rt\"],  # Reaction times\n    \"resp\": df_angry_upper[\"resp\"],  # Accuracy\n}\n\n\nfit_upper = model.sample(\n    data=stan_data_upper,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n13:16:58 - cmdstanpy - INFO - CmdStan start processing\n13:16:58 - cmdstanpy - INFO - Chain [1] start processing\n13:16:58 - cmdstanpy - INFO - Chain [2] start processing\n13:16:58 - cmdstanpy - INFO - Chain [3] start processing\n13:16:58 - cmdstanpy - INFO - Chain [4] start processing\n13:21:47 - cmdstanpy - INFO - Chain [1] done processing\n13:21:47 - cmdstanpy - INFO - Chain [3] done processing\n13:21:51 - cmdstanpy - INFO - Chain [2] done processing\n13:21:51 - cmdstanpy - INFO - Chain [4] done processing\n\n\n\nfit_upper_az = az.from_cmdstanpy(posterior=fit_upper)\naz.summary(fit_upper_az, var_names=[\"v\", \"a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nv\n0.59\n0.03\n0.53\n0.65\n0.0\n0.0\n4862.98\n4647.52\n1.0\n\n\na\n2.18\n0.03\n2.13\n2.23\n0.0\n0.0\n5509.49\n5728.87\n1.0\n\n\nt\n0.02\n0.01\n0.01\n0.03\n0.0\n0.0\n3967.71\n2400.69\n1.0\n\n\nz\n0.45\n0.01\n0.43\n0.47\n0.0\n0.0\n4712.96\n4778.83\n1.0\n\n\n\n\n\n\n\n\n\nEsempio 89.1 Simulare un singolo percorso del processo di Wiener e visualizzarlo.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\n\n# Simulazione del processo di Wiener\nW = np.zeros(N + 1)\nfor i in range(1, N + 1):\n    dW = np.random.normal(0, np.sqrt(dt))\n    W[i] = W[i - 1] + dW\n\n# Visualizzazione del percorso\nplt.plot(np.linspace(0, T, N + 1), W)\nplt.title(\"Percorso del Processo di Wiener\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 89.2 Simulare pi√π percorsi del processo di Wiener e verificare che la distribuzione finale sia normale con media 0 e varianza \\(T\\).\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\nnum_simulations = 1000  # Numero di percorsi\n\n# Simulazione del processo di Wiener\nfinal_values = []\nfor _ in range(num_simulations):\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    final_values.append(W[-1])\n\n# Visualizzazione della distribuzione finale\nplt.hist(final_values, bins=50, density=True, alpha=0.75)\nplt.title(\"Distribuzione dei Valori Finali del Processo di Wiener\")\nplt.xlabel(\"Valore Finale\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 89.3 Studiare come cambia il percorso simulato del processo di Wiener al variare del passo temporale \\(dt\\).\n\n# Parametri\nT = 1.0  # Tempo totale\ndt_values = [0.1, 0.01, 0.001]  # Differenti passi temporali\n\nplt.figure(figsize=(10, 6))\n\nfor dt in dt_values:\n    N = int(T / dt)\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    plt.plot(np.linspace(0, T, N + 1), W, label=f\"dt = {dt}\")\n\nplt.title(\"Effetto del Passo Temporale sul Processo di Wiener\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 89.4 Calcolare le statistiche (media, varianza) del processo di Wiener in vari momenti temporali e confrontarle con le aspettative teoriche.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\nnum_simulations = 1000  # Numero di percorsi\ntimes = [0.2, 0.5, 1.0]  # Tempi da analizzare\n\n# Simulazione del processo di Wiener\nresults = {time: [] for time in times}\n\nfor _ in range(num_simulations):\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    for time in times:\n        index = int(time / dt)\n        results[time].append(W[index])\n\n# Calcolo delle statistiche e confronto con la teoria\nfor time in times:\n    mean_empirical = np.mean(results[time])\n    var_empirical = np.var(results[time])\n    print(f\"Tempo: {time}\")\n    print(f\"Media empirica: {mean_empirical}, Media teorica: 0\")\n    print(f\"Varianza empirica: {var_empirical}, Varianza teorica: {time}\")\n    print(\"-\" * 40)\n\nTempo: 0.2\nMedia empirica: -0.006703382087767821, Media teorica: 0\nVarianza empirica: 0.19327362421410388, Varianza teorica: 0.2\n----------------------------------------\nTempo: 0.5\nMedia empirica: 0.01038903728780053, Media teorica: 0\nVarianza empirica: 0.49708050310832264, Varianza teorica: 0.5\n----------------------------------------\nTempo: 1.0\nMedia empirica: -0.0020292823315716008, Media teorica: 0\nVarianza empirica: 0.9963194727739045, Varianza teorica: 1.0\n----------------------------------------\n\n\n\n\nEsempio 89.5 Simulare un processo di Wiener con un drift costante (valore di tendenza \\(\\mu\\)) e osservare come il percorso viene influenzato.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\ndrift_values = [0.0, 0.5, 1.0]  # Differenti valori di drift\n\nplt.figure(figsize=(10, 6))\n\nfor drift in drift_values:\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + drift * dt + dW\n    plt.plot(np.linspace(0, T, N + 1), W, label=f\"Drift = {drift}\")\n\nplt.title(\"Processo di Wiener con Drift\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#il-meccanismo-di-accumulo-dellevidenza",
    "href": "chapters/cognitive_models/01_ddm.html#il-meccanismo-di-accumulo-dellevidenza",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.4 Il Meccanismo di Accumulo dell‚ÄôEvidenza",
    "text": "89.4 Il Meccanismo di Accumulo dell‚ÄôEvidenza\nDal punto di vista formale, il Drift Diffusion Model (DDM) √® un modello matematico utilizzato per descrivere il processo decisionale in situazioni di scelta binaria. Questo modello rappresenta il processo decisionale attraverso il meccanismo di accumulo dell‚Äôevidenza \\(Z_t\\).\nNel DDM, l‚Äôaccumulo dell‚Äôevidenza \\(Z_t\\) √® modellato come un moto browniano con drift \\(\\delta\\) e volatilit√† \\(\\alpha\\). Matematicamente, √® espresso dalla formula:\n\\[\nZ_t = \\delta t + \\alpha B_t,\n\\tag{89.1}\\]\ndove \\(B_t\\) √® un moto browniano standard o processo di Wiener.\nCiascun termine di questa formula rappresenta un aspetto fondamentale del processo decisionale:\n\n\\(Z_t\\) - Processo di accumulo dell‚Äôevidenza:\n\\(Z_t\\) rappresenta l‚Äôevidenza accumulata fino al tempo \\(t\\) verso una delle due possibili decisioni. Quando \\(Z_t\\) raggiunge una delle soglie decisionali, viene presa una decisione.\n\\(\\delta\\) - Drift rate (tasso di drift):\n\\(\\delta\\) indica la velocit√† media di accumulo dell‚Äôevidenza. √à un parametro deterministico che rappresenta la tendenza media dell‚Äôevidenza verso una decisione. Un \\(\\delta\\) positivo implica una tendenza verso una delle opzioni (ad esempio, quella ‚Äúa favore‚Äù), mentre un \\(\\delta\\) negativo suggerisce una tendenza verso l‚Äôaltra opzione (ad esempio, quella ‚Äúcontro‚Äù). Il drift rate determina quindi la direzione e la velocit√† media con cui l‚Äôevidenza si accumula.\n\\(t\\) - Tempo:\n\\(t\\) rappresenta il tempo trascorso dall‚Äôinizio del processo decisionale. Nel contesto della formula, \\(t\\) viene moltiplicato per il drift rate \\(\\delta\\), indicando come l‚Äôevidenza si accumula linearmente nel tempo in base alla velocit√† e direzione del drift.\n\\(\\alpha\\) - Volatilit√†:\n\\(\\alpha\\) rappresenta l‚Äôintensit√† delle fluttuazioni casuali nel processo di accumulo dell‚Äôevidenza. Questo parametro misura la quantit√† di variabilit√† o ‚Äúrumore‚Äù nel processo decisionale. Un valore di \\(\\alpha\\) pi√π elevato implica maggiori fluttuazioni casuali nel percorso dell‚Äôevidenza accumulata, rendendo il processo decisionale pi√π imprevedibile.\n\\(B_t\\) - Moto browniano standard (processo di Wiener):\n\\(B_t\\) rappresenta un moto browniano standard, noto anche come processo di Wiener, che √® un modello matematico per descrivere un movimento casuale nel tempo. √à un processo stocastico con media zero e varianza proporzionale al tempo \\(t\\). Nel DDM, \\(B_t\\) rappresenta le fluttuazioni casuali dell‚Äôevidenza accumulata che si verificano mentre l‚Äôindividuo elabora le informazioni per prendere una decisione.\n\nIn sintesi, la formula \\(Z_t = \\delta t + \\alpha B_t\\) descrive come l‚Äôevidenza accumulata (\\(Z_t\\)) si evolve nel tempo come somma di un componente deterministico (\\(\\delta t\\)), che rappresenta la tendenza media dell‚Äôaccumulo di evidenza, e un componente stocastico (\\(\\alpha B_t\\)), che rappresenta la variabilit√† casuale o rumore nel processo decisionale. Questa combinazione di elementi permette al DDM di modellare accuratamente come le decisioni binarie vengono prese nel tempo in presenza di incertezza e variabilit√†.\nNel DDM, il processo di accumulo dell‚Äôevidenza si muove in modo casuale verso l‚Äôalto o verso il basso fino a raggiungere una delle soglie decisionali prestabilite. Queste soglie rappresentano i punti critici che determinano la decisione finale: quando l‚Äôevidenza accumulata \\(Z_t\\) raggiunge una soglia, viene presa una decisione a favore dell‚Äôalternativa associata a quella soglia. Generalmente, ci sono due soglie, una superiore e una inferiore, che corrispondono alle due possibili decisioni. La scelta finale √® determinata dal raggiungimento di una di queste soglie, indicando la selezione dell‚Äôagente tra le due alternative disponibili.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#il-moto-browniano",
    "href": "chapters/cognitive_models/01_ddm.html#il-moto-browniano",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.5 Il Moto Browniano",
    "text": "89.5 Il Moto Browniano\nPer comprendere meglio il funzionamento del DDM, √® utile chiarire il concetto di moto browniano (ovvero, la componente \\(B_t\\) nell‚ÄôEquazione¬†89.1), noto anche come processo di Wiener.\nIl moto browniano √® un tipo di processo stocastico che descrive il comportamento casuale di una particella in movimento. √à uno dei modelli pi√π semplici e utilizzati per rappresentare l‚Äôevoluzione temporale di variabili che cambiano in modo incerto e imprevedibile nel tempo.\nIl processo di Wiener ha diverse propriet√† che lo rendono utile per modellare fenomeni casuali:\n\nInizio a zero: Il processo inizia da un punto di partenza, spesso zero, cio√® \\(W(0) = 0\\).\nIncrementi indipendenti: Gli incrementi del processo sono indipendenti tra loro. Ci√≤ significa che il cambiamento del valore del processo in un intervallo di tempo non dipende dal cambiamento in un altro intervallo di tempo non sovrapposto.\nIncrementi normali: Gli incrementi del processo di Wiener su un intervallo di tempo \\(t\\) sono distribuiti normalmente (secondo una distribuzione gaussiana) con media 0 e varianza proporzionale a \\(t\\). Formalmente, se \\(t_2 &gt; t_1\\), allora \\(W(t_2) - W(t_1) \\sim N(0, t_2 - t_1)\\).\nContinuit√†: Il processo di Wiener √® continuo, senza salti improvvisi, il che implica che il percorso del processo nel tempo √® una funzione continua.\n\nNel contesto del Drift Diffusion Model (DDM), il processo di Wiener √® utilizzato per rappresentare le fluttuazioni casuali nel processo di accumulo dell‚Äôevidenza verso una delle due possibili decisioni.\n\nEvidenza accumulata: Nel DDM, l‚Äôaccumulo di evidenza per una decisione √® considerato come un processo che si evolve nel tempo. Questo accumulo √® influenzato da un termine deterministico (il drift rate, \\(v\\)) e da un termine stocastico (il rumore, modellato dal processo di Wiener).\nTermine deterministico (drift rate, \\(v\\)): Rappresenta la velocit√† media di accumulo dell‚Äôevidenza verso una delle decisioni. Un drift rate positivo indica una tendenza verso una decisione ‚Äúa favore‚Äù, mentre un drift rate negativo indica una tendenza verso una decisione ‚Äúcontro‚Äù.\nTermine stocastico (rumore): Rappresenta la variabilit√† casuale nell‚Äôaccumulo dell‚Äôevidenza. Questo rumore √® modellato come un processo di Wiener, il che significa che l‚Äôevidenza pu√≤ fluttuare casualmente mentre si accumula nel tempo.\n\n\n89.5.1 Simulazione di un Processo di Wiener\nPer simulare un processo di Wiener, possiamo utilizzare un semplice modello matematico che genera incrementi casuali normali a ogni passo temporale. Nel contesto del DDM, l‚Äôevidenza accumulata \\(Z(t)\\) a un tempo \\(t\\) pu√≤ essere rappresentata come:\n\\[\nZ(t + \\Delta t) = Z(t) + v \\Delta t + s \\Delta W,\n\\]\ndove:\n\n\\(\\Delta t\\) √® un piccolo intervallo di tempo.\n\\(v\\) √® il drift rate, che rappresenta la velocit√† media con cui l‚Äôevidenza si accumula in una direzione preferita.\n\\(s\\) √® la deviazione standard del rumore, che misura l‚Äôintensit√† delle fluttuazioni casuali nel processo di accumulo dell‚Äôevidenza.\n\\(\\Delta W \\sim N(0, \\Delta t)\\) √® un incremento casuale del processo di Wiener, distribuito normalmente con media 0 e varianza \\(\\Delta t\\). Questo termine rappresenta il rumore stocastico che influenza il processo decisionale.\n\nUn esempio intuitivo per comprendere il funzionamento di questi elementi √® il seguente: immagina di camminare su una linea dritta su una superficie ghiacciata. Se cammini dritto, il drift rate \\(v\\) rappresenta il tuo intento di muoverti verso una direzione specifica. Tuttavia, poich√© la superficie √® scivolosa, ogni passo che fai √® influenzato dalla casualit√† (il processo di Wiener), facendoti scivolare in modo imprevedibile in diverse direzioni. La tua posizione finale dipender√† sia dalla tua intenzione di camminare dritto (drift rate) sia dalla casualit√† dei tuoi scivolamenti (rumore stocastico).\nIn conclusione, nel DDM, il processo di Wiener rappresenta la componente casuale del processo decisionale, mentre il drift rate rappresenta la componente sistematica o deterministica. Le soglie decisionali determinano i criteri per la decisione finale. Insieme, questi elementi permettono di modellare il processo di accumulazione dell‚Äôevidenza che porta alla decisione finale e determina il tempo di reazione in situazioni di scelta binaria.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#linfluenza-delle-mascherine-sulle-valutazioni-delle-emozioni-espresse-dal-viso",
    "href": "chapters/cognitive_models/01_ddm.html#linfluenza-delle-mascherine-sulle-valutazioni-delle-emozioni-espresse-dal-viso",
    "title": "89¬† Drift Diffusion Model",
    "section": "89.8 L‚Äôinfluenza delle mascherine sulle valutazioni delle emozioni espresse dal viso",
    "text": "89.8 L‚Äôinfluenza delle mascherine sulle valutazioni delle emozioni espresse dal viso\nPer esercizio, esaminiamo lo studio di Williams et al. (2023), che ha analizzato l‚Äôinfluenza delle mascherine facciali sul riconoscimento delle emozioni. Sebbene sia noto che le mascherine rallentano la diffusione del SARS-CoV-2, non √® ancora chiaro in che modo possano influenzare le interazioni sociali. Una possibile conseguenza √® che le mascherine possano modificare il modo in cui le persone comunicano le emozioni attraverso le espressioni facciali. Nel loro studio, Williams et al. (2023) indagano in che misura e in che modo le mascherine influenzano la comunicazione delle emozioni facciali, utilizzando il modello di drift-diffusion (DDM).\n\n\n\nAi partecipanti venivano mostrate espressioni facciali che rappresentavano sei emozioni (rabbia, disgusto, paura, felicit√†, tristezza, sorpresa) con tre diversi tipi di ‚Äúmaschere facciali‚Äù (inferiore, nessuna, superiore) ‚Äì figura tratta da Williams et al. (2023).\n\n\nI risultati evidenziano che, sebbene le persone siano ancora in grado di comunicare efficacemente le emozioni indossando mascherine, emergono anche delle difficolt√† legate al riconoscimento delle emozioni stesse. Utilizzando il DDM, Williams et al. (2023) dimostrano che l‚Äôaccumulo di evidenze, come meccanismo sottostante, pu√≤ essere influenzato dall‚Äôuso delle mascherine, e che in situazioni in cui il tempo √® un fattore critico, le mascherine potrebbero aumentare il rischio di incomprensioni.\nI risultati dello studio di Williams et al. (2023) mostrano che i partecipanti sono riusciti a identificare le espressioni facciali pi√π frequentemente rispetto al caso anche con le mascherine. Tuttavia, i partecipanti erano meno propensi e pi√π lenti a riconoscere correttamente le espressioni quando le mascherine coprivano parte del volto e accumulavano evidenze sulle emozioni in modo pi√π lento rispetto a quando non indossavano le mascherine.\nPer gli scopi di questo tutorial, utilizzeremo il modello Stan descritto in precedenza per analizzare il riconoscimento di una specifica emozione, considerando se il volto √® coperto o meno da una maschera visiva. L‚Äôemozione che prenderemo in esame √® la rabbia. La maschera visiva, quando presente, copre la parte superiore del volto. In queste condizioni, Williams et al. (2023) hanno riscontrato un drift rate inferiore quando i partecipanti dovevano riconoscere l‚Äôemozione da stimoli parzialmente mascherati.\nNel loro studio originale, Williams et al. (2023) hanno coinvolto 228 soggetti. Per analizzare questi dati sarebbe quindi opportuno utilizzare un modello bayesiano gerarchico. Tuttavia, per semplicit√†, in questo tutorial utilizzeremo un sotto-campione casuale di 30 soggetti nelle due condizioni descritte. Inoltre, considereremo questi dati come provenienti da un unico ‚Äúsuper-soggetto‚Äù, trascurando le differenze individuali.\nIniziamo importando i dati relativi alla condizione in cui il volto arrabbiato √® parzialmente coperto da una maschera visiva.\n\ndf_angry_upper = pd.read_csv(\"../../data/williams_2023_angry_upper.csv\")\ndf_angry_upper.head()\n\n\n\n\n\n\n\n\n\nsubj_idx\ntrial\nresponse\nrt\nresp\n\n\n\n\n0\n2b3o5c2c6ntefnb\n35\n0\n1.720625\n1\n\n\n1\n2b3o5c2c6ntefnb\n65\n0\n2.227810\n1\n\n\n2\n2b3o5c2c6ntefnb\n69\n0\n0.584445\n1\n\n\n3\n2b3o5c2c6ntefnb\n73\n0\n0.805395\n1\n\n\n4\n2b3o5c2c6ntefnb\n91\n0\n1.181125\n1\n\n\n\n\n\n\n\n\nImportiamo i dati relativi alla condizione in cui il volto arrabbiato non √® coperto da una maschera visiva.\n\ndf_angry_baseline = pd.read_csv(\"../../data/williams_2023_angry_baseline.csv\")\ndf_angry_baseline.head()\n\n\n\n\n\n\n\n\n\nsubj_idx\ntrial\nresponse\nrt\nresp\n\n\n\n\n0\n2b3o5c2c6ntefnb\n18\n0\n0.771650\n1\n\n\n1\n2b3o5c2c6ntefnb\n47\n0\n0.626895\n1\n\n\n2\n2b3o5c2c6ntefnb\n77\n0\n0.744640\n1\n\n\n3\n2b3o5c2c6ntefnb\n93\n0\n0.612550\n1\n\n\n4\n2b3o5c2c6ntefnb\n98\n0\n0.639810\n1\n\n\n\n\n\n\n\n\nGeneriamo un dizionario con i dati e eseguiamo il campionamento per i giudizi nei quali il volto arrabbiato non √® coperto da una maschera visiva.\n\nstan_data_baseline = {\n    \"N\": len(df_angry_baseline[\"rt\"]),  # Number of trials\n    \"rt\": df_angry_baseline[\"rt\"],  # Reaction times\n    \"resp\": df_angry_baseline[\"resp\"],  # Accuracy\n}\n\n\nfit_baseline = model.sample(\n    data=stan_data_baseline,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n08:53:25 - cmdstanpy - INFO - CmdStan start processing\n08:53:25 - cmdstanpy - INFO - Chain [1] start processing\n08:53:25 - cmdstanpy - INFO - Chain [2] start processing\n08:53:25 - cmdstanpy - INFO - Chain [3] start processing\n08:53:25 - cmdstanpy - INFO - Chain [4] start processing\n08:55:13 - cmdstanpy - INFO - Chain [2] done processing\n08:55:13 - cmdstanpy - INFO - Chain [4] done processing\n08:55:13 - cmdstanpy - INFO - Chain [1] done processing\n08:55:15 - cmdstanpy - INFO - Chain [3] done processing\n\n\nEsaminiamo la distribuzione a posteriori dei parametri del DDM.\n\nfit_baseline_az = az.from_cmdstanpy(posterior=fit_baseline)\naz.summary(fit_baseline_az, var_names=[\"v\", \"a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nv\n0.58\n0.05\n0.48\n0.67\n0.0\n0.0\n4298.51\n4116.92\n1.0\n\n\na\n2.04\n0.04\n1.97\n2.11\n0.0\n0.0\n5596.90\n5367.25\n1.0\n\n\nt\n0.02\n0.01\n0.01\n0.04\n0.0\n0.0\n5183.94\n2552.18\n1.0\n\n\nz\n0.44\n0.01\n0.41\n0.46\n0.0\n0.0\n4684.97\n4835.42\n1.0\n\n\n\n\n\n\n\n\nGeneriamo un dizionario con i dati e eseguiamo il campionamento per i giudizi nei quali il volto arrabbiato √® parzialmente coperto da una maschera visiva.\n\nstan_data_upper = {\n    \"N\": len(df_angry_upper[\"rt\"]),  # Number of trials\n    \"rt\": df_angry_upper[\"rt\"],  # Reaction times\n    \"resp\": df_angry_upper[\"resp\"],  # Accuracy\n}\n\n\nfit_upper = model.sample(\n    data=stan_data_upper,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n08:55:40 - cmdstanpy - INFO - CmdStan start processing\n08:55:40 - cmdstanpy - INFO - Chain [1] start processing\n08:55:40 - cmdstanpy - INFO - Chain [2] start processing\n08:55:40 - cmdstanpy - INFO - Chain [3] start processing\n08:55:40 - cmdstanpy - INFO - Chain [4] start processing\n08:57:22 - cmdstanpy - INFO - Chain [3] done processing\n08:57:22 - cmdstanpy - INFO - Chain [1] done processing\n08:57:23 - cmdstanpy - INFO - Chain [4] done processing\n08:57:24 - cmdstanpy - INFO - Chain [2] done processing\n\n\nEsaminiamo la distribuzione a posteriori dei parametri del DDM.\n\nfit_upper_az = az.from_cmdstanpy(posterior=fit_upper)\naz.summary(fit_upper_az, var_names=[\"v\", \"a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nv\n0.80\n0.05\n0.69\n0.90\n0.0\n0.0\n5111.57\n5265.06\n1.0\n\n\na\n2.03\n0.04\n1.96\n2.10\n0.0\n0.0\n5790.70\n5524.83\n1.0\n\n\nt\n0.03\n0.01\n0.02\n0.05\n0.0\n0.0\n5451.82\n4255.68\n1.0\n\n\nz\n0.41\n0.01\n0.38\n0.43\n0.0\n0.0\n5288.96\n5238.00\n1.0\n\n\n\n\n\n\n\n\nI risultati ottenuti mostrano che il drift rate √® pi√π alto nella condizione in cui il volto √® parzialmente coperto. Con un sottocampione di 50 soggetti, questo risultato contraddice quanto riscontrato da Williams et al. (2023). L‚Äôobiettivo di questo esercizio era semplicemente verificare se il modello Stan descritto in precedenza potesse essere applicato a un campione di dati reali. Le due analisi effettuate confermano che ci√≤ √® possibile. Tuttavia, i risultati evidenziano anche i limiti del modello Stan utilizzato. √à infatti fondamentale considerare le differenze individuali, cosa che non √® stata fatta in questo caso, e disporre di un campione di grandi dimensioni per ottenere risultati affidabili.\nRiformuliamo dunque il modello Stan per rendere conto delle differenze individuali nei parametri del modello DDM. Nella versione qui considerata consentiremo a drift rate e boundary separation di assumere valori diversi tra i soggetti.\nCreaiamo il dizionario dei dati nel formato richiesto dal modello gerarchico.\n\n# Crea un indice unico per ogni soggetto\ndf_angry_baseline[\"subj_id\"] = (\n    df_angry_baseline[\"subj_idx\"].astype(\"category\").cat.codes + 1\n)\n\n# Crea il dizionario per Stan\nstan_data_baseline = {\n    \"N\": len(df_angry_baseline),  # numero totale di prove\n    \"S\": df_angry_baseline[\"subj_id\"].nunique(),  # numero totale di soggetti\n    \"subj\": df_angry_baseline[\"subj_id\"].values,  # array di ID soggetto per ogni prova\n    \"rt\": df_angry_baseline[\"rt\"].values,  # array di tempi di reazione\n    \"resp\": df_angry_baseline[\"resp\"].values,  # array di risposte\n}\n\n\n# Crea un indice unico per ogni soggetto\ndf_angry_upper[\"subj_id\"] = df_angry_upper[\"subj_idx\"].astype(\"category\").cat.codes + 1\n\n# Crea il dizionario per Stan\nstan_data_upper = {\n    \"N\": len(df_angry_upper),  # numero totale di prove\n    \"S\": df_angry_upper[\"subj_id\"].nunique(),  # numero totale di soggetti\n    \"subj\": df_angry_upper[\"subj_id\"].values,  # array di ID soggetto per ogni prova\n    \"rt\": df_angry_upper[\"rt\"].values,  # array di tempi di reazione\n    \"resp\": df_angry_upper[\"resp\"].values,  # array di risposte\n}\n\nCompiliamo e stampiamo il modello gerarchico. Si noti l‚Äôistruzione target += wiener_lpdf(rt[i] | a[subj[i]], t, 1 - z, -v[subj[i]]); che consente le differenze individuali nei due parametri indicati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"ddm_h_wiener_model.stan\")\n\nmodel_h = CmdStanModel(stan_file=stan_file)\nprint(model_h.code())\n\n08:39:25 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/ddm_h_wiener_model.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/ddm_h_wiener_model\n08:39:41 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/ddm_h_wiener_model\n\n\nfunctions {\n  real wiener_rng(real alpha, real tau, real beta, real delta) {\n    real dt = 0.0001;\n    real x = alpha * beta;\n    real t = 0;\n    while (x &gt; 0 && x &lt; alpha) {\n      x += delta * dt + sqrt(dt) * normal_rng(0, 1);\n      t += dt;\n    }\n    return t + tau;\n  }\n}\ndata {\n  int&lt;lower=1&gt; N; // number of trials\n  int&lt;lower=1&gt; S; // number of subjects\n  array[N] int&lt;lower=1, upper=S&gt; subj; // subject IDs\n  array[N] real&lt;lower=0&gt; rt; // response times\n  array[N] int&lt;lower=0, upper=1&gt; resp; // responses (0 or 1)\n}\nparameters {\n  // Group-level parameters\n  real&lt;lower=0, upper=10&gt; mu_v; // group mean drift rate\n  real&lt;lower=0, upper=10&gt; sigma_v; // group std dev for drift rate\n  real&lt;lower=0.1, upper=5&gt; mu_a; // group mean boundary separation\n  real&lt;lower=0, upper=5&gt; sigma_a; // group std dev for boundary separation\n  real&lt;lower=0.001, upper=min(rt)&gt; t; // non-decision time\n  real&lt;lower=0.1, upper=0.9&gt; z; // starting point\n  \n  // Subject-level parameters\n  array[S] real&lt;lower=0, upper=10&gt; v; // drift rate for each subject\n  array[S] real&lt;lower=0.1, upper=5&gt; a; // boundary separation for each subject\n}\nmodel {\n  // Priors for group-level parameters\n  mu_v ~ normal(2, 1) T[0, 10];\n  sigma_v ~ normal(0, 1) T[0, 5];\n  mu_a ~ normal(1, 0.5) T[0.1, 5];\n  sigma_a ~ normal(0, 0.5) T[0, 5];\n  t ~ normal(0.3, 0.1) T[0.001, min(rt)];\n  z ~ beta(5, 5);\n  \n  // Priors for subject-level parameters\n  v ~ normal(mu_v, sigma_v) T[0, 10];\n  a ~ normal(mu_a, sigma_a) T[0.1, 5];\n  \n  // Likelihood\n  for (i in 1 : N) {\n    if (rt[i] &gt; t) {\n      if (resp[i] == 1) {\n        target += wiener_lpdf(rt[i] | a[subj[i]], t, z, v[subj[i]]);\n      } else {\n        target += wiener_lpdf(rt[i] | a[subj[i]], t, 1 - z, -v[subj[i]]);\n      }\n    } else {\n      target += -1e10; // Strongly penalize impossible RTs\n    }\n  }\n}\ngenerated quantities {\n  array[N] real log_lik;\n  array[N] real y_pred;\n  for (i in 1 : N) {\n    if (rt[i] &gt; t) {\n      if (resp[i] == 1) {\n        log_lik[i] = wiener_lpdf(rt[i] | a[subj[i]], t, z, v[subj[i]]);\n        y_pred[i] = wiener_rng(a[subj[i]], t, z, v[subj[i]]);\n      } else {\n        log_lik[i] = wiener_lpdf(rt[i] | a[subj[i]], t, 1 - z, -v[subj[i]]);\n        y_pred[i] = wiener_rng(a[subj[i]], t, 1 - z, -v[subj[i]]);\n      }\n    } else {\n      log_lik[i] = -1e10;\n      y_pred[i] = t; // Set to non-decision time for impossible RTs\n    }\n  }\n}\n\n\n\nEseguiamo il campionamento.\n\nfit_h_upper = model_h.sample(\n    data=stan_data_upper,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n08:40:51 - cmdstanpy - INFO - CmdStan start processing\n08:40:51 - cmdstanpy - INFO - Chain [1] start processing\n08:40:51 - cmdstanpy - INFO - Chain [2] start processing\n08:40:51 - cmdstanpy - INFO - Chain [3] start processing\n08:40:51 - cmdstanpy - INFO - Chain [4] start processing\n08:46:59 - cmdstanpy - INFO - Chain [2] done processing\n08:47:07 - cmdstanpy - INFO - Chain [4] done processing\n08:47:26 - cmdstanpy - INFO - Chain [1] done processing\n08:47:41 - cmdstanpy - INFO - Chain [3] done processing\n08:47:41 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_lpdf: Scale parameter is 0, but must be positive! (in 'ddm_h_wiener_model.stan', line 44, column 2 to column 38)\nConsider re-running with show_console=True if the above output is unclear!\n08:47:42 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 4 had 1 divergent transitions (0.1%)\n    Use the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n\n\n\nfit_h_upper_az = az.from_cmdstanpy(posterior=fit_h_upper)\naz.summary(fit_h_upper_az, var_names=[\"mu_v\", \"mu_a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_v\n0.57\n0.22\n0.12\n0.92\n0.0\n0.0\n3661.41\n2767.05\n1.0\n\n\nmu_a\n2.20\n0.10\n2.01\n2.38\n0.0\n0.0\n10142.31\n5346.70\n1.0\n\n\nt\n0.08\n0.00\n0.08\n0.09\n0.0\n0.0\n8233.31\n5854.03\n1.0\n\n\nz\n0.42\n0.01\n0.40\n0.44\n0.0\n0.0\n5464.86\n5489.24\n1.0\n\n\n\n\n\n\n\n\n\nfit_h_baseline = model_h.sample(\n    data=stan_data_baseline,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n08:49:25 - cmdstanpy - INFO - CmdStan start processing\n08:49:25 - cmdstanpy - INFO - Chain [1] start processing\n08:49:25 - cmdstanpy - INFO - Chain [2] start processing\n08:49:25 - cmdstanpy - INFO - Chain [3] start processing\n08:49:25 - cmdstanpy - INFO - Chain [4] start processing\n08:51:25 - cmdstanpy - INFO - Chain [1] done processing\n08:51:26 - cmdstanpy - INFO - Chain [4] done processing\n08:51:26 - cmdstanpy - INFO - Chain [2] done processing\n08:51:31 - cmdstanpy - INFO - Chain [3] done processing\n08:51:31 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_lpdf: Scale parameter is 0, but must be positive! (in 'ddm_h_wiener_model.stan', line 44, column 2 to column 38)\nConsider re-running with show_console=True if the above output is unclear!\n08:51:32 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 1 had 3 divergent transitions (0.1%)\n    Chain 3 had 2 divergent transitions (0.1%)\n    Use the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n\n\n\nfit_h_baseline_az = az.from_cmdstanpy(posterior=fit_h_baseline)\naz.summary(fit_h_baseline_az, var_names=[\"mu_v\", \"mu_a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_v\n0.61\n0.22\n0.14\n0.97\n0.0\n0.0\n5215.94\n3176.96\n1.0\n\n\nmu_a\n2.01\n0.12\n1.78\n2.21\n0.0\n0.0\n8588.11\n5230.70\n1.0\n\n\nt\n0.07\n0.01\n0.06\n0.08\n0.0\n0.0\n8776.01\n6180.00\n1.0\n\n\nz\n0.42\n0.01\n0.39\n0.45\n0.0\n0.0\n6994.74\n6781.55\n1.0\n\n\n\n\n\n\n\n\nNemmeno il modello gerarchico √® riuscito a replicare i risultati riportati da Williams et al. (2023) utilizzando un sotto-campione di 30 soggetti. Tuttavia, in questo caso, abbiamo riscontrato che l‚Äôintervallo di credibilit√† al 94% per il parametro v √® estremamente ampio, il che impedisce di differenziare chiaramente tra le due condizioni (maschera presente / assente). Pertanto, non giungiamo a una conclusione opposta a quella di Williams et al. (2023), ma dobbiamo ammettere che, con soli 30 soggetti, i dati non permettono di distinguere tra le due condizioni. Questo secondo esercizio dimostra che un modello gerarchico fornisce un risultato pi√π ragionevole rispetto al modello precedente, che non considerava le differenze individuali. I risultati evidenziano anche che, per ottenere stime interpretabili e non eccessivamente rumorose, √® necessario disporre di un campione di dimensioni adeguate: 30 soggetti non sono sufficienti. Williams et al. (2023) ne hanno utilizzati 228.\n\nEsempio 89.1 Simulare un singolo percorso del processo di Wiener e visualizzarlo.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\n\n# Simulazione del processo di Wiener\nW = np.zeros(N + 1)\nfor i in range(1, N + 1):\n    dW = np.random.normal(0, np.sqrt(dt))\n    W[i] = W[i - 1] + dW\n\n# Visualizzazione del percorso\nplt.plot(np.linspace(0, T, N + 1), W)\nplt.title(\"Percorso del Processo di Wiener\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 89.2 Simulare pi√π percorsi del processo di Wiener e verificare che la distribuzione finale sia normale con media 0 e varianza \\(T\\).\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\nnum_simulations = 1000  # Numero di percorsi\n\n# Simulazione del processo di Wiener\nfinal_values = []\nfor _ in range(num_simulations):\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    final_values.append(W[-1])\n\n# Visualizzazione della distribuzione finale\nplt.hist(final_values, bins=50, density=True, alpha=0.75)\nplt.title(\"Distribuzione dei Valori Finali del Processo di Wiener\")\nplt.xlabel(\"Valore Finale\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 89.3 Studiare come cambia il percorso simulato del processo di Wiener al variare del passo temporale \\(dt\\).\n\n# Parametri\nT = 1.0  # Tempo totale\ndt_values = [0.1, 0.01, 0.001]  # Differenti passi temporali\n\nplt.figure(figsize=(10, 6))\n\nfor dt in dt_values:\n    N = int(T / dt)\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    plt.plot(np.linspace(0, T, N + 1), W, label=f\"dt = {dt}\")\n\nplt.title(\"Effetto del Passo Temporale sul Processo di Wiener\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 89.4 Calcolare le statistiche (media, varianza) del processo di Wiener in vari momenti temporali e confrontarle con le aspettative teoriche.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\nnum_simulations = 1000  # Numero di percorsi\ntimes = [0.2, 0.5, 1.0]  # Tempi da analizzare\n\n# Simulazione del processo di Wiener\nresults = {time: [] for time in times}\n\nfor _ in range(num_simulations):\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    for time in times:\n        index = int(time / dt)\n        results[time].append(W[index])\n\n# Calcolo delle statistiche e confronto con la teoria\nfor time in times:\n    mean_empirical = np.mean(results[time])\n    var_empirical = np.var(results[time])\n    print(f\"Tempo: {time}\")\n    print(f\"Media empirica: {mean_empirical}, Media teorica: 0\")\n    print(f\"Varianza empirica: {var_empirical}, Varianza teorica: {time}\")\n    print(\"-\" * 40)\n\nTempo: 0.2\nMedia empirica: -0.01777872452188507, Media teorica: 0\nVarianza empirica: 0.2053824073161039, Varianza teorica: 0.2\n----------------------------------------\nTempo: 0.5\nMedia empirica: -0.005285999658711841, Media teorica: 0\nVarianza empirica: 0.5293344499462272, Varianza teorica: 0.5\n----------------------------------------\nTempo: 1.0\nMedia empirica: 0.008509695492746614, Media teorica: 0\nVarianza empirica: 0.999542671263401, Varianza teorica: 1.0\n----------------------------------------\n\n\n\n\nEsempio 89.5 Simulare un processo di Wiener con un drift costante (valore di tendenza \\(\\mu\\)) e osservare come il percorso viene influenzato.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\ndrift_values = [0.0, 0.5, 1.0]  # Differenti valori di drift\n\nplt.figure(figsize=(10, 6))\n\nfor drift in drift_values:\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + drift * dt + dW\n    plt.plot(np.linspace(0, T, N + 1), W, label=f\"Drift = {drift}\")\n\nplt.title(\"Processo di Wiener con Drift\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>89</span>¬† <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_stan_multreg.html#interpretazione-dei-coefficienti-parziali-di-regressione",
    "href": "chapters/linear_models/08_stan_multreg.html#interpretazione-dei-coefficienti-parziali-di-regressione",
    "title": "65¬† Il modello di regressione multipla",
    "section": "65.8 Interpretazione dei Coefficienti Parziali di Regressione",
    "text": "65.8 Interpretazione dei Coefficienti Parziali di Regressione\nLa regressione lineare √® un metodo statistico utilizzato per adattare una linea (o un iperpiano in spazi multidimensionali) che descrive la relazione tra una variabile dipendente e una o pi√π variabili indipendenti. L‚Äôobiettivo principale di questo metodo √® spiegare la variazione della variabile dipendente in base alle variazioni delle variabili indipendenti. √à importante sottolineare che il modello di regressione, di per s√©, non implica alcun tipo di relazione causale tra le variabili. Nonostante ci√≤, √® comune, e spesso errato, attribuire ai coefficienti del modello un‚Äôinterpretazione causale.\nAd esempio, si dice spesso che il coefficiente parziale \\(\\beta_j\\) rappresenta l‚Äôincremento atteso della variabile dipendente \\(Y\\) per una variazione unitaria della variabile indipendente \\(X_j\\), mantenendo costanti gli effetti lineari degli altri predittori inclusi nel modello. Questa interpretazione suggerisce implicitamente una relazione causale: se \\(X_j\\) cambia di un‚Äôunit√†, allora, tenendo conto dell‚Äôeffetto lineare delle altre variabili, la media di \\(Y\\) cambier√† necessariamente di una quantit√† pari a \\(\\beta_j\\) (Westreich e Greenland 2013).\nTuttavia, questa interpretazione √® valida solo sotto condizioni specifiche che sono raramente soddisfatte nella pratica. Nella maggior parte dei casi, il coefficiente \\(\\beta_j\\) riflette semplicemente una descrizione di ci√≤ che accade nel campione di dati analizzato. La sua validit√† al di fuori del campione, cio√® nella popolazione generale, dipende dal fatto che il modello di regressione rappresenti accuratamente il processo generativo dei dati nella popolazione. Se il modello √® mal specificato o se esistono variabili confondenti non incluse nel modello, l‚Äôinterpretazione causale dei coefficienti diventa invalida.\nIn altre parole, i risultati di un‚Äôanalisi di regressione lineare su un campione di dati non possono essere utilizzati direttamente per inferire nessi causali. L‚Äôinferenza causale richiede una conoscenza approfondita del dominio e l‚Äôuso di metodi appropriati, come esperimenti controllati o modelli di equazioni strutturali, che permettono di identificare relazioni causali. Solo una volta stabiliti i nessi causali, la regressione lineare pu√≤ essere impiegata per quantificare la forza di queste relazioni. Pertanto, non √® possibile procedere nel modo opposto, ovvero dedurre relazioni causali direttamente dai coefficienti di regressione ‚Äî si vedano le sezioni relative all‚Äôerrore di specificazione del modello e all‚Äôinferenza causale nei modelli di regressione per maggiori dettagli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>65</span>¬† <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  }
]