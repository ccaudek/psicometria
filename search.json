[
  {
    "objectID": "chapters/python/introduction_python.html",
    "href": "chapters/python/introduction_python.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa verranno presentati alcuni concetti fondamentali per l’analisi dei dati utilizzando Python come linguaggio di programmazione e Jupyter come ambiente di sviluppo. Tuttavia, saranno trattati solo in modo conciso, poiché esistono numerose risorse online che approfondiscono questo argomento. Per coloro che preferiscono una trattazione più completa, si consiglia il libro A Beginners Guide to Python 3 Programming di John Hunt (disponibile gratuitamente alla comunità UniFi). Il tutorial ufficiale della documentazione Python, in italiano, è fornito qui.\nPrima di procedere con il presente capitolo, è indispensabile leggere l’Appendice A — Ambiente di lavoro, l’Appendice C — La Shell e l’Appendice I — Insiemi.",
    "crumbs": [
      "Python",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html",
    "href": "chapters/python/00_prelims.html",
    "title": "2  Preliminari",
    "section": "",
    "text": "2.1 Iniziare ad Usare Python\nIn questo corso, utilizzeremo Python all’interno di un ambiente Jupyter Notebook. L’appendice Appendice A fornisce le istruzioni per installare Jupyter Notebook sul vostro computer.\nIn alternativa, è possibile scrivere uno script Python in un file con estensione .py, il quale può essere eseguito tramite il comando python nome_file.py dalla linea di comando.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#jupyter-notebook",
    "href": "chapters/python/00_prelims.html#jupyter-notebook",
    "title": "2  Preliminari",
    "section": "2.2 Jupyter Notebook",
    "text": "2.2 Jupyter Notebook\nI Jupyter Notebook offrono un ambiente interattivo in cui è possibile eseguire il codice suddiviso in celle. Sebbene sia possibile eseguire il codice nelle celle in qualsiasi ordine, è considerata una pratica consigliata eseguirle in sequenza al fine di prevenire errori e garantire una corretta esecuzione del codice.\nI Jupyter Notebook supportano due tipi di celle:\n\nCelle di Testo: Queste celle consentono di scrivere testo formattato utilizzando la sintassi Markdown. Questo permette agli autori di inserire del testo descrittivo, comprese immagini, formule in formato \\(\\LaTeX\\), tabelle e altro ancora. Le celle di testo facilitano la documentazione del processo di analisi dei dati in modo chiaro e comprensibile.\nCelle di Codice: Le celle di codice consentono di scrivere e eseguire codice Python. Il codice può essere eseguito facendo clic sul triangolo situato a sinistra di ogni cella. Diverse celle possono contenere istruzioni diverse e possono essere eseguite in sequenza. È importante notare che una funzione definita in una cella precedente può essere utilizzata solo se la cella precedente è stata eseguita.\n\nQui sotto abbiamo una cella di codice.\n\n# Make plot\n%matplotlib inline\nimport math\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntheta = np.arange(0, 4 * math.pi, 0.1)\neight = plt.figure()\naxes = eight.add_axes([0, 0, 1, 1])\naxes.plot(0.5 * np.sin(theta), np.cos(theta / 2))\n\n\n\n\n\n\n\n\nQuando lavori con il notebook, puoi essere all’interno di una cella, digitando i suoi contenuti, oppure al di fuori delle celle, muovendoti nel notebook.\nQuando sei all’interno di una cella, premi Esc per uscirne. Quando ti muovi al di fuori delle celle, premi Invio per entrare.\n\nFuori da una cella:\n\nUsa i tasti freccia per muoverti.\nPremi Shift+Invio per eseguire il codice nel blocco.\n\nAll’interno di una cella:\n\nPremi Tab per suggerire completamenti delle variabili.\n\n\n\n\n\n\n\n\nIl nome “Jupyter” deriva dalle tre principali lingue di programmazione supportate: Julia, Python e R. Tuttavia, è possibile utilizzare i Jupyter Notebook con molte altre lingue di programmazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#esecuzione-locale-o-su-colab",
    "href": "chapters/python/00_prelims.html#esecuzione-locale-o-su-colab",
    "title": "2  Preliminari",
    "section": "2.3 Esecuzione Locale o su Colab",
    "text": "2.3 Esecuzione Locale o su Colab\nI Jupyter Notebook possono essere eseguiti sia in locale, sul vostro computer, che su un server remoto, come Google Colab. Questa flessibilità permette agli utenti di accedere ai propri notebook da qualsiasi dispositivo connesso a Internet e di condividere agevolmente il proprio lavoro con altri.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#kernel-nei-jupyter-notebook",
    "href": "chapters/python/00_prelims.html#kernel-nei-jupyter-notebook",
    "title": "2  Preliminari",
    "section": "2.4 Kernel nei Jupyter Notebook",
    "text": "2.4 Kernel nei Jupyter Notebook\nI Jupyter Notebook sono strumenti che agevolano la programmazione in Python grazie a un componente essenziale: il kernel. Quest’ultimo funge da motore di esecuzione per il codice Python presente nelle celle dei notebook. Ogni volta che eseguite una cella, il suo contenuto viene processato dal kernel. La caratteristica più significativa del kernel è la sua capacità di preservare lo stato delle variabili e delle funzioni tra le diverse celle. In pratica, ciò significa che potete definire variabili o funzioni in una cella e poi riutilizzarle in celle successive. Questa interattività facilita l’esecuzione iterativa del codice e offre un modo dinamico per esplorare i dati.\nDurante l’installazione di Jupyter Notebook, di norma ricevete anche IPython, un kernel ottimizzato per Python.\nSi noti che il kernel Python deve essere installato all’interno di un ambiente di sviluppo dedicato noto come “ambiente virtuale” (per ulteriori dettagli, si veda {ref}sec-virtual-environment). Questo ambiente svolge un ruolo fondamentale nel separare e isolare le librerie e le dipendenze necessarie per il kernel. Ciò aiuta a evitare conflitti tra diverse configurazioni e garantisce il corretto funzionamento del codice nel contesto desiderato. L’utilizzo di ambienti specifici risulta particolarmente vantaggioso nei progetti che richiedono versioni particolari di librerie.\nIn questo insegnamento, faremo ampio uso della funzionalità conda, inclusa nell’installazione di Anaconda, per la gestione di questi ambienti. conda mette a disposizione funzioni utili per la creazione, la gestione e l’attivazione di ambienti separati, ciascuno con le sue configurazioni e dipendenze uniche. Questa capacità semplifica notevolmente la transizione tra diversi ambienti, garantendo che ogni progetto o kernel disponga delle risorse necessarie per operare in modo efficiente e senza interferenze.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/00_prelims.html#visual-studio-code",
    "href": "chapters/python/00_prelims.html#visual-studio-code",
    "title": "2  Preliminari",
    "section": "2.5 Visual Studio Code",
    "text": "2.5 Visual Studio Code\nIl modo più semplice di usare un Jupyter Notebook è all’interno di Visual Studio Code. Dopo aver installato Visual Studio Code, è necessario installare l’estensione Python per sfruttare le funzionalità specifiche per Python, inclusa la capacità di lavorare con Jupyter Notebook.\n\nIn Visual Studio Code, si clicca sull’icona delle estensioni (quadrati che si intersecano) nella barra laterale a sinistra.\nSi cerca “Python” nella barra di ricerca e si seleziona l’estensione ufficiale offerta da Microsoft.\nSi clicca su “Install”.\n\nUna volta completate le installazioni, siete pronti per creare il vostro primo Jupyter Notebook in VS Code.\n\nSi apre Visual Studio Code.\nSi clicca su File &gt; New File.\nSi preme Ctrl+Shift+P per aprire la Palette dei Comandi.\nSi digita “Jupyter” e si seleziona Jupyter: Create New Blank Notebook.\nSi aprirà un nuovo notebook dove si può iniziare a scrivere il codice Python nelle celle.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html",
    "href": "chapters/python/01_python_1.html",
    "title": "3  Python (1)",
    "section": "",
    "text": "3.1 Scrivere Codice con il Supporto dei LLM\nI Large Language Models (LLM), come GPT-4 o Claude, stanno rivoluzionando non solo la generazione di testo in linguaggio naturale, ma anche il campo della programmazione e dell’analisi dei dati. La programmazione, con le sue regole esplicite e la sintassi strutturata, si adatta particolarmente bene alle capacità di riconoscimento dei pattern degli LLM. A differenza dei linguaggi umani, ricchi di ambiguità ed espressioni idiomatiche, i linguaggi di programmazione sono rigorosi e precisi.\nNel contesto dell’analisi dei dati, è naturale combinare le capacità degli LLM con la potenza computazionale di linguaggi statistici come R o di programmazione come Python. Sono già stati pubblicati libri su come integrare le capacità degli LLM con l’analisi dei dati (Matter, 2025), e sta emergendo una nuova branca dell’ingegneria dedicata allo sviluppo dei prompt più efficaci per l’uso con gli LLM. Pertanto, il problema non è se utilizzare gli LLM a supporto della programmazione, ma come farlo nel modo più efficace.\nGli LLM possono essere utilizzati per risolvere vari problemi di programmazione in Python o R, basandosi su richieste formulate in linguaggio naturale. Questi modelli sono in grado di generare codice, identificare errori negli script, ottimizzare il codice, generare documentazione e creare casi di test, anche per problemi di programmazione complessi. L’avvento degli LLM ha cambiato radicalmente il modo in cui sia i principianti sia i professionisti si approcciano alla programmazione. Tuttavia, ciò non significa che gli LLM abbiano completamente sostituito la scrittura di codice da parte degli esseri umani. Piuttosto, gli LLM sono strumenti che possono migliorare notevolmente il lavoro di chi ha già una buona conoscenza delle regole sintattiche e dei principi di programmazione.\nUn principio fondamentale da tenere a mente è che maggiore è la conoscenza delle regole sintattiche di un linguaggio di programmazione, maggiore sarà l’efficacia dell’uso degli LLM per gli scopi dell’analisi dei dati. Anche se i problemi di programmazione trattati in questo corso sono relativamente semplici rispetto alle capacità degli LLM, gli utenti che sfrutteranno questi strumenti trarranno sicuramente vantaggio dalla comprensione delle regole sintattiche del linguaggio di programmazione utilizzato, principalmente Python (con alcuni esempi anche in R).\nGli LLM si basano sul concetto di “predizione del prossimo token”. Questo significa che sono addestrati per prevedere la parola o il carattere successivo in una sequenza, basandosi sui precedenti. Questo principio è alla base della capacità degli LLM di generare codice e di migliorare i flussi di lavoro dell’analisi dei dati in Python o R. Oltre a miliardi di parole provenienti da testi comuni (siti web, libri, articoli di riviste), gli LLM di OpenAI, come GPT-4, sono stati addestrati su un vasto corpus di codice open-source e discussioni sul codice presenti su piattaforme come Stack Overflow. Questo consente loro di generare codice sintatticamente e semanticamente corretto in molte situazioni.\nAcquisire competenze sull’uso pratico dell’AI/LLM nella programmazione e nell’analisi dei dati è più di una tendenza: è una necessità. I professionisti che sanno utilizzare efficacemente l’AI/LLM per migliorare le loro competenze di programmazione e integrare questi strumenti in Python e R hanno un vantaggio competitivo. Con la crescente diffusione dell’AI e degli LLM nell’industria e nel mondo accademico, la domanda per queste competenze continuerà a crescere.\nL’obiettivo di questa sezione della dispensa è fornire una panoramica della sintassi di Python e delle principali funzioni di pacchetti come Pandas, Numpy e Matplotlib, utili per la data science. Python è un linguaggio di programmazione versatile e di facile lettura, adatto a numerosi usi. Anche se il suo nome è un omaggio al gruppo comico Monty Python, apprendere Python richiede tempo, pratica e impegno.\nQuesta guida (e l’intero corso) si concentra sull’insegnamento dei principi fondamentali della programmazione e dell’analisi dei dati psicologici, piuttosto che sui dettagli tecnici. Facendo riferimento alla distinzione di Marr tra livello computazionale e livello algoritmico (Marr, 2010), una spiegazione a livello computazionale descrive la logica del problema e i passaggi necessari per trasformare l’input in output, mentre il livello algoritmico specifica come eseguire queste operazioni logiche utilizzando la sintassi di un particolare linguaggio di programmazione.\nIl focus di questo corso è il livello computazionale, poiché è fondamentale per comprendere i problemi e progettare soluzioni. Con questa conoscenza, gli studenti saranno più capaci di risolvere problemi specifici e di cercare autonomamente la sintassi appropriata per il problema da risolvere.\nNell’era dell’intelligenza artificiale, è essenziale sviluppare la capacità di pensare in modo computazionale. Questa competenza va oltre la mera programmazione e offre un approccio strutturato per risolvere problemi complessi. Sebbene i modelli di linguaggio avanzati (LLM) siano in grado di risolvere molti dei problemi di programmazione affrontati in questo corso, una comprensione approfondita dei principi della programmazione rimane cruciale per interpretare, modificare o migliorare le soluzioni proposte da tali sistemi.\nIn conclusione, nonostante i notevoli progressi dell’AI, una solida conoscenza della programmazione rimane indispensabile. Padroneggiare i principi fondamentali della codifica è essenziale per sfruttare al massimo strumenti avanzati come i modelli linguistici di grandi dimensioni (LLM) e per affrontare con efficacia le sfide legate alla programmazione e all’analisi dei dati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#espressioni-e-operatori",
    "href": "chapters/python/01_python_1.html#espressioni-e-operatori",
    "title": "3  Python (1)",
    "section": "3.2 Espressioni e Operatori",
    "text": "3.2 Espressioni e Operatori\nI programmi sono costituiti da insiemi di espressioni che elaborano dati per fornire istruzioni specifiche al computer. In Python, ad esempio, l’operazione di moltiplicazione viene eseguita utilizzando l’asterisco (*) tra due numeri. Quando il programma incontra un’espressione come 3 * 4, il computer la valuta e restituisce il risultato, che può essere visualizzato, ad esempio, in una cella successiva di un notebook Jupyter.\nLe regole sintattiche di un linguaggio di programmazione come Python sono rigorose. Per esempio, non è consentito inserire due simboli di moltiplicazione (*) consecutivi senza un operando tra di essi. Se un’espressione viola queste regole sintattiche, Python restituirà un “SyntaxError”, un messaggio che segnala la non conformità alle regole del linguaggio. Ad esempio:\n3 * * 4\nrestituirà:\n Cell In[3], line 1\n    3 * * 4\n        ^\nSyntaxError: invalid syntax\nAnche piccole variazioni all’interno di un’espressione possono cambiarne completamente il significato. Nell’esempio seguente, lo spazio tra i due asterischi è stato rimosso. Ora, poiché gli asterischi compaiono correttamente tra due numeri, l’espressione diventa sintatticamente valida e indica l’elevamento a potenza: 3 ** 4 equivale a 3 elevato alla quarta potenza (\\(3 \\times 3 \\times 3 \\times 3\\)). In programmazione, simboli come * e ** sono chiamati “operatori”, mentre i valori su cui agiscono sono detti “operandi”.\n\n3 ** 4\n\n81\n\n\nLa tabella seguente elenca i principali operatori binari utilizzati in Python, chiamati così perché agiscono su due operandi.\n\n\n\nOperazione\nOperatore\n\n\n\n\naddizione\n+\n\n\nsottrazione\n-\n\n\nmoltiplicazione\n*\n\n\ndivisione (reale)\n/\n\n\ndivisione (intera; rimuove il resto)\n//\n\n\nresto (modulo)\n%\n\n\nelevamento a potenza\n**\n\n\n\nLe due operazioni che potrebbero essere meno familiari sono % (trova il resto di una divisione) e // (esegui una divisione scartando il resto).\nPer esempio, la divisione intera (scartando il resto) di 11/2 produce 5.\n\n11 // 2\n\n5\n\n\nIl resto di 11/2 è 1.\n\n11 % 2\n\n1\n\n\nUsando gli operatori che abbiamo elencato in precedenza possiamo usare Python come un calcolatore.\n\nprint(\"4 + 2 è\", 4 + 2)\nprint(\"4 - 2 è\", 4 - 2)\nprint(\"4 * 2 è\", 4 * 2)\nprint(\"4 / 2 è\", 4 / 2)\nprint(\"4 ** 2 è\", 4**2)\nprint(\"9 % 4 è\", 9 % 4)\nprint(\"9 // 4 è\", 9 // 4)\n\n4 + 2 è 6\n4 - 2 è 2\n4 * 2 è 8\n4 / 2 è 2.0\n4 ** 2 è 16\n9 % 4 è 1\n9 // 4 è 2\n\n\nL’applicazione degli operatori aritmetici in Python dipende dalle seguenti regole di precedenza degli operatori, che sono analoghe a quelle usate in algebra.\n\nLe espressioni tra parentesi vengono valutate per prime.\nSuccessivamente si valutano gli elevamenti a potenza.\nIn seguito, si valutano moltiplicazioni, divisioni e moduli.\nPer ultime vengono valutate somme e sottrazioni.\n\n\n1 + 2 * 3 * 4 * 5 / 6 ** 3 + 7 + 8 - 9 + 10\n\n17.555555555555557\n\n\n\n1 + 2 * (3 * 4 * 5 / 6) ** 3 + 7 + 8 - 9 + 10\n\n2017.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#variabili",
    "href": "chapters/python/01_python_1.html#variabili",
    "title": "3  Python (1)",
    "section": "3.3 Variabili",
    "text": "3.3 Variabili\nQuando un risultato viene generato, viene visualizzato ma non memorizzato da nessuna parte, come visto negli esempi precedenti. Per poter riutilizzare quel risultato in seguito, è necessario salvarlo in un oggetto a cui possiamo dare un nome. Questo oggetto prende il nome di variabile.\nPer creare una variabile, utilizziamo un’istruzione di assegnazione. Un’istruzione di assegnazione consiste nel dare un nome alla variabile, seguito dal simbolo di uguale (=), e dall’espressione il cui valore vogliamo memorizzare. Il processo di assegnazione associa il valore dell’espressione a destra del simbolo di uguale al nome specificato a sinistra. Da quel momento, ogni volta che utilizziamo quel nome in un’espressione, verrà utilizzato il valore associato a esso durante l’assegnazione.\n\na = 10\nb = 20\na + b\n\n30\n\n\n\na = 1/4\nb = 2 * a\nb\n\n0.5\n\n\n\nmy_var = 100\nconst = 3\n\nmy_var * const\n\n300\n\n\nIn Python, ogni “oggetto” è un’area di memoria nel computer. Una “variabile” funge da etichetta che fa riferimento a quest’area. Se un oggetto non ha più etichette (ovvero, non ci sono più variabili che lo referenziano), i dati contenuti nell’oggetto diventano inaccessibili. Il Garbage Collector del linguaggio si occuperà di rilevare questi oggetti non referenziati e liberare la memoria, permettendo che venga riutilizzata per nuovi dati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#nomi-delle-variabili",
    "href": "chapters/python/01_python_1.html#nomi-delle-variabili",
    "title": "3  Python (1)",
    "section": "3.4 Nomi delle Variabili",
    "text": "3.4 Nomi delle Variabili\nQuando scriviamo programmi in Python, è importante scegliere nomi significativi per le variabili, poiché queste ci permettono di memorizzare e manipolare dati nel corso dell’esecuzione del programma. I nomi delle variabili devono rispettare alcune regole specifiche per essere validi all’interno del linguaggio.\nIn Python, i nomi delle variabili possono contenere caratteri alfanumerici (da a-z, A-Z, 0-9) e il carattere speciale _ (underscore). Tuttavia, devono iniziare con una lettera (a-z, A-Z) o con un underscore, ma non con un numero. Gli spazi non sono permessi all’interno dei nomi delle variabili, quindi l’underscore è comunemente usato per separare le parole all’interno di un nome (ad esempio, nome_variabile).\nPer facilitare la leggibilità del codice, è buona pratica seguire alcune convenzioni: i nomi delle variabili iniziano generalmente con una lettera minuscola, mentre i nomi delle classi cominciano con una lettera maiuscola.\nÈ importante notare che in Python esiste una serie di parole riservate, chiamate parole chiave (keywords), che non possono essere utilizzate come nomi di variabili. Queste parole chiave hanno un significato speciale all’interno del linguaggio e sono essenziali per la sintassi di Python. Queste parole chiave sono:\n\nimport keyword\nprint(*keyword.kwlist, sep=\"\\n\")\n\nFalse\nNone\nTrue\nand\nas\nassert\nasync\nawait\nbreak\nclass\ncontinue\ndef\ndel\nelif\nelse\nexcept\nfinally\nfor\nfrom\nglobal\nif\nimport\nin\nis\nlambda\nnonlocal\nnot\nor\npass\nraise\nreturn\ntry\nwhile\nwith\nyield\n\n\nSi presti attenzione alla parola chiave “lambda”, che potrebbe facilmente essere un nome di variabile naturale in un programma scientifico. Tuttavia, essendo una parola chiave, non può essere utilizzata come nome di variabile.\nUtilizzare nomi di variabili chiari e appropriati aiuta a rendere il codice più leggibile e comprensibile, sia per il programmatore che per chiunque altro debba interagire con il codice.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#tipologie-di-dati-in-python",
    "href": "chapters/python/01_python_1.html#tipologie-di-dati-in-python",
    "title": "3  Python (1)",
    "section": "3.5 Tipologie di Dati in Python",
    "text": "3.5 Tipologie di Dati in Python\nIn Python, le variabili possono appartenere a diverse tipologie di dati, ciascuna con caratteristiche e utilizzi specifici.\n\n3.5.1 Stringhe (String)\nLe stringhe sono sequenze di caratteri, utilizzate per rappresentare testo. In Python, le stringhe possono essere create utilizzando apici singoli (' '), doppi (\" \") o tripli (''' ''' oppure \"\"\" \"\"\") per delimitare il testo. Esempi di stringhe sono:\n\"Hello, world!\"\n'Beyonce-Lemonade.txt'\n\"lemonade\"\nSi noti il risultato ottenuto quando si applica l’operatore + a due stringhe.\n\n\"data\" + \"science\"\n\n'datascience'\n\n\n\n\"data\" + \" \" + \"science\"\n\n'data science'\n\n\nSia le virgolette singole che doppie possono essere utilizzate per creare le stringhe: “ciao” e ‘ciao’ sono espressioni equivalenti. Tuttavia, le virgolette doppie sono spesso preferite poiché consentono di includere virgolette singole all’interno delle stringhe.\n\n\"Che cos'è una parola?\"\n\n\"Che cos'è una parola?\"\n\n\nL’espressione precedente avrebbe prodotto un SyntaxError se fosse stata racchiusa da virgolette singole.\n\n3.5.1.1 Parsing strings\nIn Python, una stringa è concepita come una sequenza ordinata di caratteri. Grazie all’operatore di indicizzazione, rappresentato dalle parentesi quadre [], è possibile accedere a singoli elementi della stringa.\nÈ importante ricordare che l’indicizzazione in Python parte da zero.\nL’indice del primo carattere è [0], quello del secondo è [1], del terzo [2], e così via. Questa funzionalità consente di manipolare o consultare specifici segmenti della stringa, piuttosto che gestirla come un blocco unico.\nConsideriamo questo verso di Eugenio Montale:\n\nmy_string = \"Tendono alla chiarità le cose oscure\"\nprint(my_string)\n\nTendono alla chiarità le cose oscure\n\n\n\nmy_string[0]\n\n'T'\n\n\n\nmy_string[3]\n\n'd'\n\n\n\nlen(my_string)\n\n36\n\n\nLa stringa “my_string” conta 36 caratteri. Pertanto, gli indici validi per questa stringa vanno da 0 a 35. Per accedere all’ultimo carattere, è necessario utilizzare l’indice 35, che corrisponde a 36 meno 1.\n\nmy_string[35]\n\n'e'\n\n\nUn modo efficiente per ottenere l’ultimo carattere è ricorrere alla funzione len, sottraendo 1 al risultato:\n\nmy_string[len(my_string) - 1]\n\n'e'\n\n\nSi noti che len() è una funzione. Una funzione è un blocco di codice che esegue un’operazione specifica. I programmatori chiamano anche gli input delle funzioni “parametri” o “argomenti”.\nLa funzione len prende un input e restituisce un output. L’output è la lunghezza di ciò che è stato passato come input.\n\n\n3.5.1.2 Slicing strings\nOltre a estrarre caratteri individuali da una stringa, Python offre la possibilità di selezionare segmenti di testo attraverso la tecnica dello “slicing”. Questo meccanismo è simile all’indicizzazione, ma utilizza due indici separati da un carattere a due punti (:). Il primo indice indica la posizione di partenza dello “slicing” nella stringa, mentre il secondo indice segnala il punto in cui terminare l’estrazione del segmento.\n\nmy_string[2:4]\n\n'nd'\n\n\nSe si omette il primo indice, Python utilizzerà l’inizio della stringa; se si omette il secondo, utilizzerà la fine della stringa.\n\nmy_string[:4]\n\n'Tend'\n\n\n\nmy_string[4:]\n\n'ono alla chiarità le cose oscure'\n\n\n\n\n3.5.1.3 Metodi\nA partire da una stringa esistente, si possono generare nuove stringhe mediante l’utilizzo di metodi specifici per le stringhe. Questi metodi sono essenzialmente funzioni che agiscono direttamente sull’oggetto stringa. Per invocare un metodo, basta posizionare un punto subito dopo la stringa e seguire con il nome del metodo desiderato. Ad esempio, il metodo successivo converte tutti i caratteri della stringa in maiuscole.\n\nmy_string.upper()\n\n'TENDONO ALLA CHIARITÀ LE COSE OSCURE'\n\n\nIl metodo my_string.title() è utilizzato per convertire la prima lettera di ogni parola nella stringa my_string in maiuscolo, mentre rende tutte le altre lettere minuscole. In pratica, trasforma la stringa in una forma “a titolo”, in cui ogni parola inizia con una lettera maiuscola.\n\nmy_string.title()\n\n'Tendono Alla Chiarità Le Cose Oscure'\n\n\n\n\n\n3.5.2 Numeri Interi (Integer)\nI numeri interi rappresentano numeri senza una componente decimale. In Python, possono essere creati assegnando un valore senza parte decimale a una variabile. Esempio di un numero intero è:\n\nage = 20\n\n\n\n3.5.3 Numeri in Virgola Mobile (Float)\nI numeri in virgola mobile, o “float”, rappresentano numeri che hanno una componente decimale. Sono creati assegnando un valore con una parte decimale a una variabile. Esempio di un numero float è:\n\ntemperature = 36.4\n\nI numeri in virgola mobile, o “float”, hanno una precisione limitata a circa 15-16 cifre decimali; oltre questo limite, la precisione viene persa. Nonostante questa limitazione, sono sufficienti per la maggior parte delle applicazioni.\nInoltre, è possibile utilizzare la notazione scientifica per rappresentare numeri molto grandi o molto piccoli. In questa notazione, m * 10^n viene comunemente abbreviato come mEn, dove “E” rappresenta l’esponente dieci. Ad esempio, 1E9 equivale a un miliardo (\\(1 \\times 10^9\\)) e 1E-9 rappresenta un miliardesimo (\\(1 \\times 10^{-9}\\)).\n\n\n3.5.4 Valori Booleani (Boolean)\nI valori booleani possono assumere solo due stati: vero (True) o falso (False). Sono utilizzati per rappresentare le condizioni logiche e sono ottenuti attraverso espressioni di confronto. Esempio di un valore booleano è:\n\nis_raining = False\n\nNel contesto delle operazioni aritmetiche, True è equivalente al numero intero 1, mentre False corrisponde a 0. Questo permette di includere valori booleani in calcoli matematici. Per esempio:\n\nTrue + True + False\n\n2\n\n\nUn valore booleano viene ritornato quando si valuta un confronto. Per esempio:\n\n3 &gt; 1 + 1\n\nIl valore True indica che il confronto è valido; Python ha confermato questo semplice fatto sulla relazione tra 3 e 1+1.\nSi noti la regola di precedenza: gli operatori &gt;, &lt;, &gt;=, &lt;=, ==, != hanno la precedenza più bassa (vengono valutati per ultimi), il che significa che nell’espressione precedente viene prima valutato (1 + 1) e poi (3 &gt; 2).\n\n\n3.5.5 Operatori di confronto\nUn operatore di confronto è un operatore che esegue un qualche tipo di confronto e restituisce un valore booleano (True oppure False). Per esempio, l’operatore == confronta le espressioni su entrambi i lati e restituisce True se hanno gli stessi valori e False altrimenti. L’opposto di == è !=, che si può leggere come ‘non uguale al valore di’. Gli operatori di confronto sono elencati qui sotto:\n\n\n\nConfronto\nOperatore\n\n\n\n\nMinore\n&lt;\n\n\nMaggiore\n&gt;\n\n\nMinore o uguale\n&lt;=\n\n\nMaggiore o uguale\n&gt;=\n\n\nUguale\n==\n\n\nNon uguale\n!=\n\n\n\nAd esempio:\n\na = 4\nb = 2\n\nprint(\"a &gt; b\", \"is\", a &gt; b)\nprint(\"a &lt; b\", \"is\", a &lt; b)\nprint(\"a == b\", \"is\", a == b)\nprint(\"a &gt;= b\", \"is\", a &gt;= b)\nprint(\"a &lt;= b\", \"is\", a &lt;= b)\n\nNella cella seguente si presti attenzione all’uso di = e di ==:\n\nboolean_condition = 10 == 20\nprint(boolean_condition)\n\nL’operatore = è un’istruzione di assegnazione. Ovvero, crea un nuovo oggetto. L’operatore == valuta invece una condizione logica e ritorna un valore booleano.\nUn’espressione può contenere più confronti e tutti devono essere veri affinché l’intera espressione sia vera. Ad esempio:\n\n1 &lt; 1 + 1 &lt; 3\n\n\n\n3.5.6 Tipizzazione Dinamica in Python\nPython è un linguaggio con tipizzazione dinamica, il che significa che il tipo di una variabile è determinato dal valore che le viene assegnato durante l’esecuzione del programma e non necessita di essere dichiarato esplicitamente.\nPer identificare il tipo di una variabile o del risultato di un’espressione, Python mette a disposizione la funzione type(). Questa funzione, quando chiamata con una variabile o un’espressione come argomento, restituisce il tipo di dati corrispondente.\nNell’esempio seguente il programma stamperà &lt;class 'str'&gt;, indicando che x è una variabile di tipo “stringa”.\n\nx = \"hello\"\nprint(type(x))\n\n&lt;class 'str'&gt;\n\n\nApplichiamo la funzione type() alle altre variabili che abbiamo definito in precedenza.\n\nage = 20\nprint(type(age))\n\n&lt;class 'int'&gt;\n\n\n\ntemperature = 36.4\nprint(type(temperature))\n\n&lt;class 'float'&gt;\n\n\n\nis_raining = False\nprint(type(is_raining))\n\n&lt;class 'bool'&gt;\n\n\n\n\n3.5.7 Operatori Booleani\nGli operatori booleani (o operatori logici) confrontano espressioni (non valori) e ritornano un valore booleano. Python ha tre operatori logici:\n\nand – Ritorna True solo se entrambi le espressioni sono vere, altrimenti ritorna False\nor – Ritorna True se almeno una delle due espressioni è vera, altrimenti ritorna False.\nnot – Ritorna True se l’espressione è falsa, altrimenti ritorna False.\n\nAd esempio:\n\na = 2\nb = 3\n\n(a + b &gt; a) and (a + b &gt; b)\n\nTrue\n\n\nNella cella sopra le parentesi tonde sono opzionali ma facilitano la lettura.\nL’operatore and restituisce True solo se entrambe le condizioni booleane sono vere. Ad esempio, True and False restituirà False perché una delle condizioni è falsa:\n\nTrue and False\n\nFalse\n\n\nL’operatore or restituisce True se almeno una delle due condizioni booleane è vera. Ad esempio, True or False restituirà True perché almeno una delle condizioni è vera.\n\nTrue or False\n\nTrue\n\n\nL’operatore not viene utilizzato per invertire il valore di verità di una condizione booleana. Ad esempio, not True restituirà False e not False restituirà True.\n\nnot True\n\nFalse\n\n\nAlcuni esempi sono i seguenti (si noti l’uso della funzione len()):\n\nprint(3 &gt; 2)  # True, because 3 is greater than 2\nprint(3 &gt;= 2)  # True, because 3 is greater than 2\nprint(3 &lt; 2)  # False,  because 3 is greater than 2\nprint(2 &lt; 3)  # True, because 2 is less than 3\nprint(2 &lt;= 3)  # True, because 2 is less than 3\nprint(3 == 2)  # False, because 3 is not equal to 2\nprint(3 != 2)  # True, because 3 is not equal to 2\nprint(len(\"mango\") == len(\"avocado\"))  # False\nprint(len(\"mango\") != len(\"avocado\"))  # True\nprint(len(\"mango\") &lt; len(\"avocado\"))  # True\nprint(len(\"milk\") != len(\"meat\"))  # False\nprint(len(\"milk\") == len(\"meat\"))  # True\nprint(len(\"tomato\") == len(\"potato\"))  # True\nprint(len(\"python\") &gt; len(\"dragon\"))  # False\n\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\nAltri esempi di come questi operatori possono essere utilizzati sono i seguenti:\n\nprint(3 &gt; 2 and 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 and 4 &lt; 3)  # False - because the second statement is false\nprint(3 &lt; 2 and 4 &lt; 3)  # False - because both statements are false\nprint(\"True and True: \", True and True)\nprint(3 &gt; 2 or 4 &gt; 3)  # True - because both statements are true\nprint(3 &gt; 2 or 4 &lt; 3)  # True - because one of the statements is true\nprint(3 &lt; 2 or 4 &lt; 3)  # False - because both statements are false\nprint(\"True or False:\", True or False)\nprint(not 3 &gt; 2)  # False - because 3 &gt; 2 is true, then not True gives False\nprint(not True)  # False - Negation, the not operator turns true to false\nprint(not False)  # True\nprint(not not True)  # True\nprint(not not False)  # False\n\nTrue\nFalse\nFalse\nTrue and True:  True\nTrue\nTrue\nFalse\nTrue or False: True\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\nAbbiamo tralasciato alcuni operatori in Python. Due di quelli che abbiamo omesso sono gli operatori di appartenenza, in e not in. Gli altri operatori che abbiamo tralasciato sono gli operatori bitwise e gli operatori sugli insiemi, che verranno trattati in seguito.\n\n\n3.5.8 Valori Numerici di True e False\nÈ fondamentale comprendere i valori numerici associati alle parole chiave True e False. Queste due parole chiave hanno i valori numerici di 1 e 0, rispettivamente.\n\nTrue == 1\n\nTrue\n\n\n\nFalse == 0\n\nTrue\n\n\n\nTrue + False\n\n1\n\n\n\ntype(True + False)\n\nint",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#sequenze",
    "href": "chapters/python/01_python_1.html#sequenze",
    "title": "3  Python (1)",
    "section": "3.6 Sequenze",
    "text": "3.6 Sequenze\nOltre ai numeri e ai valori booleani, Python supporta anche un insieme di “contenitori”, ovvero i seguenti tipi strutturati:\n\nle liste,\nle tuple,\ngli insiemi,\ni dizionari.\n\n\n3.6.1 Le tuple\nUna tupla è una collezione di diversi tipi di dati che è ordinata e immutabile (non modificabile). Le tuple sono scritte tra parentesi tonde, (). Una volta creata una tupla, non è possibile modificarne i contenuti.\n\ncolors = (\"Rosso\", \"Nero\", \"Bianco\")\ncolors\n\n('Rosso', 'Nero', 'Bianco')\n\n\n\ntype(colors)\n\ntuple\n\n\nLe stringhe sono tuple di caratteri. Pertanto non sono modificabili.\n\n\n3.6.2 Le liste\nGli oggetti di tipo lista sono simili alle tuple, ma con alcune differenze. La lista è un oggetto mutabile, il che significa che possiamo aggiungere o rimuovere elementi dalla lista anche dopo la sua creazione. Una lista viene creata separando i suoi elementi tramite virgola e racchiudendo il tutto tra parentesi quadre.\nSi noti che una lista è una struttura dati eterogenea contentente una sequenza di elementi che possono essere di tipo diverso.\n\nmy_list = [\"Pippo\", 3, -2.953, [1, 2, 3]]\nmy_list\n\n['Pippo', 3, -2.953, [1, 2, 3]]\n\n\n\ntype(my_list)\n\nlist\n\n\nLa lista my_list è composta da diversi elementi: una stringa (“Pippo”), un numero intero (3), un numero decimale (-2.953) e un’altra lista ([1, 2, 3]).\nGli elementi nella lista sono ordinati in base all’indice, il quale rappresenta la loro posizione all’interno della lista. Gli indici delle liste partono da 0 e aumentano di uno. Per accedere a un elemento della lista tramite il suo indice, si utilizza la notazione delle parentesi quadre: nome_lista[indice]. Ad esempio:\n\nmy_list[1]\n\n3\n\n\n\nmy_list[0]\n\n'Pippo'\n\n\nPython prevede alcune funzioni che elaborano liste, come per esempio len che restituisce il numero di elementi contenuti in una lista:\n\nlen(my_list)\n\n4\n\n\nBenché questa lista contenga come elemento un’altra lista, tale lista nidificata conta comunque come un singolo elemento. La lunghezza di di my_list è quattro.\nUna lista vuota si crea nel modo seguente:\n\nempty_list = []\nlen(empty_list)\n\n0\n\n\nEcco alcuni esempi.\n\nfruits = [\"banana\", \"orange\", \"mango\", \"lemon\"]  # list of fruits\nvegetables = [\"Tomato\", \"Potato\", \"Cabbage\", \"Onion\", \"Carrot\"]  # list of vegetables\n\nprint(\"Fruits:\", fruits)\nprint(\"Number of fruits:\", len(fruits))\nprint(\"Vegetables:\", vegetables)\nprint(\"Number of vegetables:\", len(vegetables))\n\nFruits: ['banana', 'orange', 'mango', 'lemon']\nNumber of fruits: 4\nVegetables: ['Tomato', 'Potato', 'Cabbage', 'Onion', 'Carrot']\nNumber of vegetables: 5\n\n\nSupponiamo di voler ordinare in ordine alfabetico i nomi presenti nella lista. Per fare ciò, è necessario utilizzare il metodo sort sulla lista utilizzando la notazione con il punto (dot notation):\n\nnames = [\"Carlo\", \"Giovanni\", \"Giacomo\"]\nnames.sort()\n\nTale metodo però non restituisce alcun valore, in quanto l’ordinamento è eseguito in place: dopo l’invocazione, gli elementi della lista saranno stati riposizionati nell’ordine richiesto. Visualizziamo la listra trasformata:\n\nnames\n\n['Carlo', 'Giacomo', 'Giovanni']\n\n\nL’invocazione di metodi (e di funzioni) prevede anche la possibilità di specificare degli argomenti opzionali. Per esempio:\n\nnames.sort(reverse=True)\nnames\n\n['Giovanni', 'Giacomo', 'Carlo']\n\n\nIl metodo remove() può essere usato per rimuovere elementi da una lista.\n\nprint(fruits)\nfruits.remove(\"banana\")\nprint(fruits)\n\n['banana', 'orange', 'mango', 'lemon']\n['orange', 'mango', 'lemon']\n\n\nIl metodo insert() può essere usato per aggiungere elementi ad una lista.\n\nprint(fruits)\nfruits.insert(2, \"watermelon\")\nprint(fruits)\n\n['orange', 'mango', 'lemon']\n['orange', 'mango', 'watermelon', 'lemon']\n\n\nÈ possibile copiare una lista in una nuova variabile:\n\nprint(fruits)\nnew_fruits = fruits.copy()\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\nprint(new_fruits)\n\n['orange', 'mango', 'watermelon', 'lemon']\n\n\n\n\n3.6.3 Operazioni su liste\nL’operatore + concatena liste:\n\na = [1, 2, 3]\nb = [4, 5, 6]\nc = a + b\nprint(c)\n\n[1, 2, 3, 4, 5, 6]\n\n\nIn maniera simile, l’operatore * ripete una lista un certo numero di volte:\n\n[0] * 4\n\n[0, 0, 0, 0]\n\n\n\n[1, 2, 3] * 3\n\n[1, 2, 3, 1, 2, 3, 1, 2, 3]\n\n\nL’aspetto importante da considerare è che, essendo una sequenza di elementi eterogenei, è difficile eseguire operazioni algebriche sulle liste in Python puro. Ad esempio, consideriamo la seguente lista:\n\nx = [1, 2, 3]\nx\n\n[1, 2, 3]\n\n\nSe desideriamo calcolare una semplice operazione, come la media di x, è necessario seguire una procedura abbastanza articolata. Ad esempio:\n\ntotal = 0\ncounter = 0\n\nfor num in x:\n    counter += 1\n    total += num\n\navg = total / counter\n\nprint(avg)\n\n2.0\n\n\nIndubbiamente, sarebbe preferibile ottenere questo risultato con un approccio più semplice. In seguito, vedremo che se utilizziamo una sequenza di elementi omogenei, il problema può essere risolto in modo molto più agevole. Ad esempio,\n\nimport numpy as np\n\nx = np.array([1, 2, 3])\nnp.mean(x)\n\n2.0\n\n\nPossiamo contare il numero degli elementi specificati che sono contenuti in una lista usando count().\n\nages = [22, 19, 24, 25, 26, 24, 25, 24]\nprint(ages.count(24))         \n\n3\n\n\nPossiamo trovare l’indice di un elemento in una lista con index().\n\nages.index(24)  # index of the first occurrence\n\n2\n\n\n\n\n3.6.4 Operatore slice\nL’operatore di slice (:) applicato alle liste in Python consente di estrarre una porzione specifica di elementi dalla lista. L’operatore di slice ha la seguente sintassi: lista[inizio:fine:passo].\n\ninizio rappresenta l’indice di partenza dell’intervallo (inclusivo).\nfine rappresenta l’indice di fine dell’intervallo (esclusivo).\npasso rappresenta il passo o l’incremento tra gli indici degli elementi selezionati (facoltativo).\n\nEcco alcuni esempi per illustrare l’utilizzo dell’operatore di slice:\n\nlista = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n# Estrarre una porzione della lista\nporzione = lista[2:6]  # [3, 4, 5, 6]\n\n# Estrarre una porzione con un passo specifico\nporzione_passo = lista[1:9:2]  # [2, 4, 6, 8]\n\n# Estrarre una porzione dalla fine della lista\nporzione_fine = lista[6:]  # [7, 8, 9, 10]\n\n# Estrarre una porzione dall'inizio della lista\nporzione_inizio = lista[:5]  # [1, 2, 3, 4, 5]\n\n\n\n3.6.5 Gli insiemi\nGli insiemi sono collezioni finite di elementi distinti e non memorizzati in un ordine specifico. Un insieme non può contenere più di un’istanza dello stesso elemento. Per creare un insieme si utilizzano le parentesi graffe {}. Ad esempio:\n\nmy_set = {\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"}\nmy_set\n\n{'A', 'B', 'C', 'D', 'E', 'F'}\n\n\n\ntype(my_set)\n\nset\n\n\nGli oggetti di tipo “set” sono utili per eseguire operazioni matematiche sugli insiemi.\nPer verificare se un elemento esiste in un insieme usiamo l’operatore in.\n\nprint(\"Does set my_set contain D? \", \"D\" in my_set)\n\nDoes set my_set contain D?  True\n\n\nL’unione di due insieme si ottiene con union().\n\nfruits = {\"banana\", \"orange\", \"mango\", \"lemon\"}\nvegetables = {\"tomato\", \"potato\", \"cabbage\", \"onion\", \"carrot\"}\nprint(fruits.union(vegetables))\n\n{'carrot', 'onion', 'lemon', 'mango', 'tomato', 'potato', 'banana', 'cabbage', 'orange'}\n\n\nL’intersezione di due insieme si trova con intersection().\n\npython = {\"p\", \"y\", \"t\", \"h\", \"o\", \"n\"}\ndragon = {\"d\", \"r\", \"a\", \"g\", \"o\", \"n\"}\npython.intersection(dragon)\n\n{'n', 'o'}\n\n\nUn insieme può essere un sottoinsieme o un sovrainsieme di altri insiemi.\nPer verificare se un insieme è un sottoinsieme di un altro, si utilizza il metodo issubset(). Per verificare se un insieme è un sovrainsieme di un altro, si utilizza il metodo issuperset().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.issubset(st1)\n\nTrue\n\n\n\nst1.issuperset(st2) \n\nTrue\n\n\nLa differenza tra due insiemi si ottiene con difference().\n\nwhole_numbers = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\neven_numbers = {0, 2, 4, 6, 8, 10}\nwhole_numbers.difference(even_numbers)\n\n{1, 3, 5, 7, 9}\n\n\nPossiamo verificare se due insiemi sono disgiunti, ovvero non hanno elementi in comune, utilizzando il metodo isdisjoint().\n\nst1 = {\"item1\", \"item2\", \"item3\", \"item4\"}\nst2 = {\"item2\", \"item3\"}\nst2.isdisjoint(st1)\n\nFalse\n\n\n\n\n3.6.6 I dizionari\nGli oggetti di tipo “dizionario” vengono utilizzati per creare coppie chiave-valore, dove ogni chiave è unica. Un dizionario viene creato specificando ogni coppia come chiave : valore, separando le diverse coppie con una virgola e racchiudendo il tutto tra parentesi graffe. Ad esempio:\n\nmusic = {\n    \"blues\": \"Betty Smith\",\n    \"classical\": \"Gustav Mahler\",\n    \"pop\": \"David Bowie\",\n    \"jazz\": \"John Coltrane\",\n}\n\nL’accesso agli elementi di un dizionario viene fatto specificando all’interno di parentesi quadre la chiave per ottenere o modificare il valore corrispondente:\n\nmusic[\"pop\"]\n\n'David Bowie'\n\n\nPer trovare il numero di coppie key: value nel dizionario usiamo len().\n\nprint(len(music))\n\n4\n\n\n\nmusic[\"new music\"] = \"Missy Mazzoli\"\nprint(music)\n\n{'blues': 'Betty Smith', 'classical': 'Gustav Mahler', 'pop': 'David Bowie', 'jazz': 'John Coltrane', 'new music': 'Missy Mazzoli'}\n\n\n\n\n3.6.7 Contenitori vuoti\nA volte è utile creare dei contenitori vuoti. I comandi per creare liste vuote, tuple vuote, dizionari vuoti e insiemi vuoti sono rispettivamente lst = [], tup=(), dic={} e st = set().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/01_python_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "3  Python (1)",
    "section": "3.7 Informazioni sull’Ambiente di Sviluppo",
    "text": "3.7 Informazioni sull’Ambiente di Sviluppo\nAlla fine di ogni capitolo e, in effetti, alla fine (o all’inizio) di qualsiasi notebook che creiamo, è utile includere informazioni sull’ambiente di calcolo, compresi i numeri di versione di tutti i pacchetti che utilizziamo. Il pacchetto watermark può essere usato per questo scopo. Il pacchetto watermark contiene comandi speciali ed è un’estensione di IPython. In generale, per utilizzare tali comandi speciali, li precediamo con il segno % o %% in una cella. Utilizziamo la funzione speciale built-in %load_ext per caricare watermark, e quindi utilizziamo %watermark per invocarlo.\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 24 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\n\n\nEcco una spiegazione dettagliata delle opzioni che sono state utilizzate nell’istruzione watermark.\n\n-n o --datename: Aggiunge la data e l’ora correnti al watermark. Questo può essere utile per mantenere una cronologia delle modifiche o delle esecuzioni del notebook.\n-u o --updated: Mostra l’ultima volta in cui il notebook è stato salvato. È utile per tenere traccia delle modifiche recenti apportate al notebook.\n-v o --python: Mostra la versione di Python utilizzata nel kernel del notebook. Questo è importante per garantire la compatibilità del codice e replicare gli ambienti di lavoro.\n-iv o --iversions: Visualizza le versioni delle librerie importate nel notebook. È fondamentale per la replicabilità degli esperimenti e degli analisi, dato che diverse versioni delle librerie possono comportare risultati diversi.\n-w o --watermark: Aggiunge il watermark stesso, che è semplicemente il logo “watermark”. È più una questione estetica che funzionale.\n-m o --machine: Fornisce informazioni sulla macchina su cui viene eseguito il Jupyter Notebook, come il tipo di sistema operativo e l’architettura della macchina (ad esempio, x86_64). Questo può essere utile per documentare l’ambiente hardware in cui vengono eseguiti gli esperimenti.\n\nQueste opzioni forniscono un modo semplice e immediato per documentare e tracciare importanti metadati nei notebook Jupyter.\n\n\n\n\n\n\n\nMarr, D. (2010). Vision: A computational investigation into the human representation and processing of visual information. MIT press.\n\n\nMatter, U. (2025). Data Analysis with AI and R (1st Edition). Manning Publications.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html",
    "href": "chapters/python/02_python_2.html",
    "title": "4  Python (2)",
    "section": "",
    "text": "4.1 Funzioni\nLo scopo delle funzioni è raggruppare il codice in un formato organizzato, leggibile e riutilizzabile, contribuendo così a ridurre la ridondanza del codice.\nUna regola generale per le funzioni è che dovrebbero essere di piccole dimensioni e svolgere un’unica operazione.\nNella programmazione, una funzione accetta un input, esegue operazioni su di esso e può restituire un output. Python mette a disposizione un’ampia gamma di funzioni integrate, e si può anche importare funzioni da pacchetti aggiuntivi o definirne di nuove.\nPer definire una nuova funzione in Python, si utilizza la parola chiave def, seguita dal nome della funzione e dai nomi simbolici dei suoi argomenti, separati da virgole e racchiusi tra parentesi. La definizione continua con i due punti (:) e il corpo della funzione, le cui istruzioni devono essere indentate. Il valore restituito dalla funzione viene specificato tramite la parola chiave return, generalmente nella riga finale del corpo della funzione.\ndef add_numbers(a, b):\n    \"\"\"\n    returns the sum of the two numeric arguments\n    \"\"\"\n    the_sum = a + b\n    return the_sum\nUna volta definita una funzione, è possibile eseguirla chiamandola e passando gli argomenti appropriati. Ad esempio, possiamo chiamare la funzione add_numbers per sommare due numeri, come ad esempio 20 e 10:\nadd_numbers(20, 10)\n\n30\nConsideriamo la funzione roll_die():\nimport random\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return random.choice([1, 2, 3, 4, 5, 6])\nIl corpo della funzione è composto da una singola riga di codice che utilizza la funzione choice() della libreria random, a cui viene passata una lista. Questo significa che una funzione può utilizzare altre funzioni che sono già state definite. In questo caso, la funzione si limita a specificare l’argomento da passare a choice(). La funzione choice() restituirà un numero casuale tra quelli specificati in input. Pertanto, la funzione roll_die() simula il lancio di un dado:\nroll_die()\n\n6\nroll_die()\n\n5\nSi noti inoltre la docstring, cioè una stringa (in genere racchiusa tra “““…”““) che si trova come prima istruzione all’interno di una funzione. La docstring contiene informazioni sullo scopo e sulle modalità d’uso della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#funzioni",
    "href": "chapters/python/02_python_2.html#funzioni",
    "title": "4  Python (2)",
    "section": "",
    "text": "4.1.1 Introspection\nUsando un punto interrogativo (?) prima o dopo una variabile è possibile visualizzare alcune informazioni generale su quell’oggetto. Nel caso di una funzione viene stampata la doc string.\n\nroll_die?\n\nSignature: roll_die()\nDocstring: returns a random int between 1 and 6\nFile:      /var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_13125/63164766.py\nType:      function\n\n\n\n\n4.1.2 Metodi\nLe funzioni definite all’interno di una classe, chiamate “metodi”, rappresentano operazioni specifiche che possono essere eseguite sugli oggetti di quella classe. Una classe è una struttura concettuale che rappresenta un concetto o un oggetto nel contesto del problema che stiamo affrontando. Ad esempio, nel capitolo sull’introduzione a Pandas, lavorando con dati organizzati in una tabella, utilizziamo un oggetto chiamato DataFrame, appartenente alla classe “pandas.DataFrame”. Un DataFrame è una struttura tabellare che contiene dati disposti in righe e colonne.\nI metodi specifici della classe DataFrame offrono funzionalità per manipolare e analizzare i dati in questa struttura. Per esempio, il metodo “hist()” genera istogrammi dei valori presenti in una colonna specifica del DataFrame. Per invocare un metodo su un oggetto DataFrame, come “df”, utilizziamo la sintassi “nome_oggetto.nome_metodo()” e possiamo passare eventuali parametri richiesti tra parentesi.\nD’altra parte, gli attributi rappresentano le caratteristiche o le proprietà degli oggetti di una classe. Gli attributi possono essere richiamati utilizzando la sintassi “nome_oggetto.nome_attributo” e restituiscono un valore specifico associato a quell’oggetto. Per esempio, l’attributo “.shape” applicato a un DataFrame come “df.shape” restituisce il numero di righe e colonne presenti nel DataFrame.\nIn sintesi, una classe definisce un tipo di oggetto che ha attributi che ne descrivono le caratteristiche e metodi che rappresentano le azioni eseguibili su di esso. Gli attributi forniscono informazioni specifiche sull’oggetto, mentre i metodi consentono di effettuare operazioni e manipolazioni sui dati contenuti nell’oggetto stesso.\n\n\n4.1.3 La funzione lambda\nPython offre una sintassi alternativa che consente di definire funzioni “inline”, cioè in una singola linea di codice. Queste funzioni, chiamate funzioni anonime, non richiedono una definizione esplicita poiché vengono utilizzate solo nel punto in cui sono dichiarate. Per creare una funzione anonima, utilizziamo la parola chiave lambda, seguita da un elenco di argomenti separati da virgole, due punti “:” e l’espressione che definisce il comportamento della funzione basandosi sugli argomenti forniti.\nlambda argomento1, argomento2, ... : espressione\nQuesta sintassi permette di creare funzioni semplici ed espressive in modo conciso.\nNell’esempio seguente, la funzione somma 1 al valore passato come input:\n\n(lambda x : x + 1)(2)\n\n3\n\n\nQuando eseguiamo (lambda x : x + 1)(2), avviene quanto segue:\n\nL’interprete Python definisce la funzione lambda lambda x : x + 1.\nLa funzione lambda viene immediatamente chiamata con l’argomento 2.\nAll’interno della funzione lambda, x viene sostituito da 2, quindi l’espressione x + 1 diventa 2 + 1.\nLa funzione lambda restituisce 3.\n\nQuindi, il risultato dell’espressione (lambda x : x + 1)(2) è 3.\nIn sintesi, la funzione lambda (lambda x : x + 1) definisce una funzione che aggiunge 1 al suo argomento. Quando la chiamiamo con l’argomento 2, otteniamo 3 come risultato.\nIn questo secondo esempio sommiamo i due numeri in entrata:\n\n(lambda x, y: x + y)(2, 3)\n\n5\n\n\nLa sintassi seguente è valida in quanto, per l’interprete, il carattere _ corrisponde all’ultima funzione che è stata valutata:\n\nlambda x, y: x + y\n\n&lt;function __main__.&lt;lambda&gt;(x, y)&gt;\n\n\n\n_(20, 10)\n\n30\n\n\nSi noti che abbiamo valutato la funzione lambda x, y: x + y in una cella precedente a quella che contiene _(20, 10); inserendo le due espressioni in una singola cella si ottiene un SyntaxError.\n\n\n4.1.4 Le funzioni map() e filter()\nPer gli esercizi che svolgeremo in seguito, risultano utili le funzioni map() e filter().\nLa funzione map() prende come input una funzione e una lista, e restituisce il risultato dell’applicazione della funzione a ciascun elemento della lista (è anche possibile usare qualsiasi oggetto iterabile al posto della lista). La lista stessa rimane invariata. Ad esempio, la seguente linea di codice eleva al quadrato ciascuno degli elementi della lista a e salva il risultato nella lista b:\n\na = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nb = list(map(lambda x: x * x, a))\nb\n\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n\n\nUn’altra funzione molto utile per manipolare gli oggetti iterabili è la funzione filter(). Questa funzione filtra un oggetto iterabile selezionando solo gli elementi che rispondono ad un determinato predicato. (Il predicato è una funzione che restituisce un booleano). Per esempio\n\nc = list(filter(lambda x: x &gt; 50, b))\nc\n\n[64, 81, 100]\n\n\nSia map() che filter() restituiscono risultati che non sono ancora stati calcolati.\n\nfilter(lambda x: x &gt; 50, b)\n\n&lt;filter at 0x171da9720&gt;\n\n\nPossiamo visualizzare il risultato convertendolo in una lista:\n\nlist(filter(lambda x: x &gt; 50, b))\n\n[64, 81, 100]\n\n\n\n\n4.1.5 La funzione zip()\nLa funzione zip() crea una lista di tuple dagli elementi di due contenitori. Come nel caso delle operazioni precedenti, gli elementi vengono calcolati solo quando viene richiesto. Per esempio:\n\na = list(range(4))\na\n\n[0, 1, 2, 3]\n\n\n\nb = list(range(4, 8))\nb\n\n[4, 5, 6, 7]\n\n\n\nb = zip(a, b)\nb\n\n&lt;zip at 0x172034f80&gt;\n\n\n\nlist(b)\n\n[(0, 4), (1, 5), (2, 6), (3, 7)]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#il-flusso-di-esecuzione",
    "href": "chapters/python/02_python_2.html#il-flusso-di-esecuzione",
    "title": "4  Python (2)",
    "section": "4.2 Il flusso di esecuzione",
    "text": "4.2 Il flusso di esecuzione\nIn Python il codice viene eseguito sequenzialmente, partendo dalla prima riga fino a quando non c’è più nulla da eseguire. L’ordine di esecuzione delle varie istruzioni è detto flusso di esecuzione.\nPer esempio la cella seguente prima memorizza la lista names, poi la lista born e infine la lista dead.\n\nnames = [\"Sigmund Freud\", \"Jean Piaget\", \"Burrhus Frederic Skinner\", \"Albert Bandura\"]\nborn = [1856, 1896, 1904, 1925]\ndead = [1939, 1980, 1990, None]\n\nHo usato il valore speciale None in quanto non risulta disponibile l’anno. In queste situazioni si parla di valori mancanti (missing values) che, di norma, vengono indicati con la sigla NA (not available).\nLa cella seguente include le istruzioni condizionali che specificano se e quando devono essere eseguiti determinati blocchi di codice. La più semplice istruzione di controllo è l’istruzione if. Per esempio:\n\nname = \"Maria\"\ngrade = 29\n\nif name == \"Maria\" and grade &gt; 28:\n    print(\"Maria, hai ottenuto un ottimo voto all'esame!\")\n\nif name == \"Giovanna\" or grade &gt; 28:\n    print(\n        \"Tu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\"\n    )\n\nif name != \"Giovanna\" and grade &gt; 28:\n    print(\"Tu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\")\n\nMaria, hai ottenuto un ottimo voto all'esame!\nTu potresti essere Giovanna oppure potresti avere ottenuto un ottimo voto all'esame.\nTu non sei Giovanna ma hai ottenuto un ottimo voto all'esame.\n\n\nTutte e tre le condizioni precedenti ritornano True, quindi vengono stampati tutti e tre i messaggi.\nSi noti che == e != confrontano valori, mentre is e not confrontano oggetti. Per esempio,\n\nname_list = [\"Maria\", \"Giovanna\"]\nname_list_two = [\"Marco\", \"Francesco\"]\n\n# Compare values\nprint(name_list == name_list_two)\n\n# Compare objects\nprint(name_list is name_list_two)\n\nFalse\nFalse\n\n\nUna delle parole chiave condizionali più utili è in. Un esempio è il seguente:\n\nname_list = [\"Maria\", \"Giovanna\", \"Marco\", \"Francesco\"]\n\nprint(\"Giovanna\" in name_list)\nprint(\"Luca\" in name_list)\n\nTrue\nFalse\n\n\nLa condizione opposta è not in.\n\nprint(\"Luca\" not in name_list)\n\nTrue\n\n\nFacciamo un altro esempio.\n\nage = 26\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\n\nSei maggiorenne\n\n\nPython dispone di un’espressione ternaria che introduce la potenza dell’istruzione ‘else’ in una sintassi concisa:\n\nage = 26\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei maggiorenne\n\n\n\nage = 16\nb = \"Sei maggiorenne\" if age &gt;=18 else \"Sei minorenne\"\nprint(b)\n\nSei minorenne\n\n\nUna struttura di selezione leggermente più complessa è “if-else”. La sintassi di questa struttura è la seguente:\nif &lt;condizione&gt;:\n    &lt;istruzione_se_condizione_vera&gt;\nelse:\n    &lt;istruzione_se_condizione_falsa&gt;\nLa semantica di “if-else” è quella che ci si aspetta: la condizione tra la parola chiave if e il carattere di due punti viene valutata: se risulta vera viene eseguita l’istruzione alla linea seguente, altrimenti viene eseguita l’istruzione dopo la parola chiave else. Anche in questo caso l’indentazione permette di identificare quali istruzioni devono essere eseguite nei due rami della selezione. Per esempio:\n\nage = 16\nif age &gt;= 18:\n    print(\"Sei maggiorenne\")\nelse:\n    print(\"Sei minorenne\")\n\nSei minorenne\n\n\nIn presenza di più di due possibilità mutuamente esclusive ed esaustive possiamo usare l’istruzione elif. Per esempio:\n\ncfu = 36\nthesis_defense = False\n\nif cfu &gt;= 180 and thesis_defense == True:\n    print(\"Puoi andare a festeggiare!\")\nelif cfu &gt;= 180 and thesis_defense == False:\n    print(\"Devi ancora superare la prova finale!\")\nelse:\n    print(\"Ripassa tra qualche anno!\")\n\nRipassa tra qualche anno!\n\n\n\n4.2.1 Commenti\nIn Python è possibile usare il carattere # per aggiungere commenti al codice. Ogni riga di commento deve essere preceduta da un #. I commenti non devono spiegare il metodo (cosa fa il codice: quello si vede), ma bensì lo scopo: quello che noi intendiamo ottenere. I primi destinatari dei commenti siamo noi stessi tra un po’ di tempo, ovvero quando ci saremo dimenticati cosa avevamo in mente quando abbiamo scritto il codice.\n\n# This is a comment and will not be executed.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#cicli",
    "href": "chapters/python/02_python_2.html#cicli",
    "title": "4  Python (2)",
    "section": "4.3 Cicli",
    "text": "4.3 Cicli\nUn ciclo è un modo per eseguire una porzione di codice più di una volta. I cicli sono fondamentali nei linguaggi di programmazione. Come molti altri linguaggi di programmazione, Python ha due tipi di cicli per gestire tutte le proprie necessità di iterazione: il ciclo “while” e il ciclo “for”.\n\n4.3.1 Il ciclo while\nil ciclo while permette l’esecuzione di un blocco di codice finché una determinata condizione è True. Per esempio:\n\ncounter = 0\n\nwhile counter &lt;= 10:\n    print(counter)\n    counter += 1\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nIl codice counter += 1 è equivalente a counter = counter + 1 e, ogni qualvolta viene eseguito il ciclo, riassegna alla variabile counter il valore che aveva in precedenza + 1.\nL’istruzione while controlla se alla variabile counter è associato un valore minore o uguale a 10. Nel primo passo del ciclo la condizione è soddisfatta, avendo noi definito counter = 0, pertanto il programma entra nel loop, stampa il valore della variabile counter e incrementa counter di un’unità.\nQuesto comportamento si ripete finché la condizione counter &lt;= 10 risulta True. Quando il contatore counter assume il valore 11 il ciclo while si interrompe e il blocco di codice del ciclo non viene più eseguito.\n\n\n4.3.2 Il ciclo for\nIl ciclo for è un costrutto di controllo di flusso che viene utilizzato per iterare su una sequenza di valori, come ad esempio una lista, una tupla, una stringa o un dizionario.\nLa sintassi generale di un ciclo for in Python è la seguente:\nfor element in sequence:\n    # codice da eseguire\nDove element è una variabile temporanea che assume il valore di ciascun elemento della sequenza ad ogni iterazione del ciclo, e sequence è la sequenza di valori su cui iterare.\nDurante l’esecuzione del ciclo, il blocco di codice indentato sotto la linea for viene eseguito una volta per ogni elemento della sequenza. Ad ogni iterazione, la variabile elemento assume il valore dell’elemento corrente della sequenza e il codice all’interno del blocco viene eseguito con questo valore.\nIl ciclo for è spesso utilizzato per eseguire operazioni su ciascun elemento di una sequenza, come ad esempio la somma degli elementi di una lista o la stampa di ciascun carattere di una stringa. Per esempio\n\nnumbers = [0, 1, 2, 3, 4, 5]\nfor number in numbers: # number is temporary name to refer to the list's items, valid only inside this loop\n    print(number)\n\n0\n1\n2\n3\n4\n5\n\n\n\nlanguage = \"Python\"\nfor letter in language:\n    print(letter)\n\nP\ny\nt\nh\no\nn\n\n\nLa funzione range() è spesso usata nei cicli for e permette di impostare un intervallo di esecuzione tanto ampio quanto il numero che le passiamo come parametro meno uno.\nLa funzione range() prende tre parametri: start (default 0), stop e step (default 1), ovvero un punto di inizio dell’intervallo, un punto di fine e un passo di avanzamento. L’indicizzazione Python parte da 0; quindi range(0, 11, 1) una lista di 11 elementi, da 0 a 10 inclusi.\n\nprint(list(range(0, 11, 1)))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nAd esempio, impostiamo un punto di inizio a 3, il punto di fine a 11 e un passo di 2:\n\nprint(list(range(3, 12, 2)))\n\n[3, 5, 7, 9, 11]\n\n\nIn un ciclo for, l’intervallo di range() corrisponde al numero di iterazioni che verranno eseguite, ovvero al numero di volte che il ciclo verrà processato. Nel caso seguente, l’indice del ciclo (qui chiamato number) assume il valore 0 la prima volta che il ciclo viene eseguito e il valore 10 nell’ultima esecuzione del ciclo.\n\nfor number in range(11):\n    print(number)\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\nfor number in range(3, 12, 2):\n    print(number)\n\n3\n5\n7\n9\n11\n\n\n\n4.3.2.1 Cicli for annidati\nSono possibili i cicli for annidati, vale a dire un ciclo posto all’interno del corpo di un altro (chiamato ciclo esterno). Al suo primo passo, il ciclo esterno mette in esecuzione quello interno che esegue il proprio blocco di codice fino alla conclusione. Quindi, al secondo passo, il ciclo esterno rimette in esecuzione quello interno. Questo si ripete finché il ciclo esterno non termina. Per esempio:\n\nfor i in range(4):\n    for j in range(4):\n        print((i, j))\n\n(0, 0)\n(0, 1)\n(0, 2)\n(0, 3)\n(1, 0)\n(1, 1)\n(1, 2)\n(1, 3)\n(2, 0)\n(2, 1)\n(2, 2)\n(2, 3)\n(3, 0)\n(3, 1)\n(3, 2)\n(3, 3)\n\n\n\n\n4.3.2.2 Modificare gli elementi di una lista\nIl ciclo for è il modo più comune per scorrere gli elementi di una lista, come abbiamo visto in precedenza.\n\nfor name in name_list:\n    print(name)\n\nMaria\nGiovanna\nMarco\nFrancesco\n\n\nQuesto approccio può essere usato se abbiamo solo bisogno di leggere gli elementi della lista. Nel ciclo seguente, ad esempio, leggiamo gli elementi d una lista per incrementare una variabile così da calcolare una somma.\n\nnumbers = [2, -4, 1, 6, 3]\n\ntotal = 0\nfor num in numbers:\n    total += num\n\nprint(total)\n\n8\n\n\nMa se vogliamo cambiare gli elementi di una lista l’approccio precedente non funziona e dobbiamo usare gli indici. Nell’esempio seguente, questo risultato viene ottenuto utilizzando le funzioni range e len:\n\nnumbers = [2, -4, 1, 6, 3]\n\nfor i in range(len(numbers)):\n    numbers[i] = numbers[i] * 2\n\nprint(numbers)\n\n[4, -8, 2, 12, 6]\n\n\nNel codice seguente, la funzione len() ritorna 5.\n\nnumbers = [2, -4, 1, 6, 3]\nlen(numbers)\n\n5\n\n\nQuindi, range(5) produce la seguente sequenza iterabile:\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]\n\n\nQuesti sono gli indici che verranno usati nelle iterazioni del ciclo for.\n\nLa prima volta che il ciclo viene eseguito, l’indice i vale 0 e numbers[i] si riferisce al primo elemento della lista;\nla seconda volta che il ciclo viene eseguito, i vale 1 e numbers[i] si riferisce al secondo elemento della lista;\ne così via.\n\nL’istruzione di assegnazione nel corpo del ciclo for usa i per leggere il valore i-esimo della lista originale (a destra dell’uguale) e per assegnargli un nuovo valore (a sinistra dell’uguale).\n\n\n\n4.3.3 List comprehension\nUna list comprehension è un modo conciso di creare una lista. È un modo compatto per creare una nuova lista. Accade speso di dover creare una lista dove ciascun elemento è il risultato di un’operazione condotta sugli elementi di un’altra lista o di un iterabile; oppure, di dover estrarre gli elementi che soddisfano una certa condizione. Per esempio, supponiamo di volere sommare una costante ad una lista di numeri. Usando un ciclo for possiamo procedere nel modo seguente (si noti l’uso della funzione append):\n\nnew_list = []\nk = 10\nfor x in range(10):\n    new_list.append(x + k)\n\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nOppure, in maniera più semplice, possiamo usare una list comprehension:\n\nnew_list = [x + k for x in range(10)]\nnew_list\n\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n\n\nUna list comprehension è racchiusa tra parentesi quadre; contiene un’espressione, seguita da una clausola for, seguita da zero o più clausole for o if. La sintassi è la seguente:\n[ &lt;expression&gt; for item in iterable &lt;if optional_condition&gt; ]\nIl risultato è una nuova lista costruita valutando l’espressione nel contesto delle clausole for e if che la seguono. Una list comprehension combina dunque un ciclo for e (se necessario) una o più condizioni logiche in una singola riga di codice. Esaminiamo una variante dell’esempio precedente.\n\nlist1 = [1, 2, 3, 4, 5, 6]\nprint(\"list1:\", list1)\n\nlist1: [1, 2, 3, 4, 5, 6]\n\n\n\nlist2 = [item + 1 for item in list1]\nprint(\"list2:\", list2)\n\nlist2: [2, 3, 4, 5, 6, 7]\n\n\nSi noti che la parola item avrebbe potuto essere quasi qualsiasi stringa (in precedenza abbiamo usato x). La possiamo immaginare con la seguente definizione: ...per ogni elemento in .... Nel seguente esempio, sommiamo 1 agli elementi di list1 solo se sono pari:\n\nlist3 = [item + 1 for item in list1 if item % 2 == 0] \nprint('list3:', list3)\n\nlist3: [3, 5, 7]\n\n\nFacciamo un altro esempio usando range():\n\nnum_list = range(50, 60)\n[1 + num for num in num_list]\n\n[51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n\n\nQui selezioniamo solo i numeri pari (oltre allo zero):\n\n[i for i in range(11) if i % 2 == 0]\n\n[0, 2, 4, 6, 8, 10]\n\n\nSpecificando una condizione, possiamo cambiare il segno solo dei numeri dispari nella lista:\n\n[-i if i % 2 else i for i in range(11)]\n\n[0, -1, 2, -3, 4, -5, 6, -7, 8, -9, 10]\n\n\nPossiamo anche eseguire più iterazioni simultaneamente:\n\n[(i, j) for i in range(3) for j in range(4)]\n\n[(0, 0),\n (0, 1),\n (0, 2),\n (0, 3),\n (1, 0),\n (1, 1),\n (1, 2),\n (1, 3),\n (2, 0),\n (2, 1),\n (2, 2),\n (2, 3)]\n\n\nIn questo esempio vengono selezionati solo i nomi inclusi nella lista female_names:\n\nfirst_names = [\"Maria\", \"Marco\", \"Francesco\", \"Giovanna\"]\nfemale_names = [\"Alice\", \"Maria\", \"Giovanna\", \"Lisa\"]\nfemale_list = [name for name in first_names if name in female_names]\nprint(female_list)\n\n['Maria', 'Giovanna']\n\n\nNel seguente esempio vengono estratte le prime tre lettere di ciascuno dei nomi che compongono una lista:\n\nletters = [name[0:3] for name in first_names] \nletters\n\n['Mar', 'Mar', 'Fra', 'Gio']\n\n\nPer estrarre l’ultimo carattere di una stringa usiamo [-1]:\n\nmy_string = \"barbablù\"\nmy_string[-1]\n\n'ù'\n\n\nPossiamo dunque usare seguente list comprehension estrae gli ultimi tre caratteri di ciascun elemento della lista first_names.\n\nletters = [name[-3:] for name in first_names] \nletters\n\n['ria', 'rco', 'sco', 'nna']\n\n\nÈ possibile impiegare un’espressione ternaria all’interno di una list comprehension per sfruttare la versatilità dell’istruzione ‘else’ in modo sintatticamente efficace. Ad esempio, possiamo sostituire tutti i numeri dispari di una lista (un un NumPy array) con il valore 99.\n\nnum = np.array([4, 7, 2, 6, 3, 9])  # può anche essere una lista Python\n[e if e % 2 == 0 else 99 for e in num]\n\n[4, 99, 2, 6, 99, 99]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#librerie-e-moduli",
    "href": "chapters/python/02_python_2.html#librerie-e-moduli",
    "title": "4  Python (2)",
    "section": "4.4 Librerie e moduli",
    "text": "4.4 Librerie e moduli\n\n4.4.1 Importare moduli\nI moduli (anche conosciuti come librerie in altri linguaggi) sono dei file usati per raggruppare funzioni e altri oggetti. Python include una lista estensiva di moduli standard (anche conosciuti come Standard Library), ma è anche possibile scaricarne o definirne di nuovi. Prima di potere utilizzare le funzioni non presenti nella Standard Library all’interno dei nostri programmi dobbiamo importare dei moduli aggiuntivi, e per fare ciò usiamo il comando import.\nL’importazione può riguardare un intero modulo oppure solo uno (o più) dei suoi elementi. Consideriamo per esempio la funzione mean. Essa è disponibile nel modulo numpy. L’istruzione import numpy importa tutto il modulo numpy. Dopo che un modulo è stato importato, è possibile accedere a un suo generico elemento usando il nome del modulo, seguito da un punto e dal nome dell’elemento in questione. Ad esempio, numpy.mean().\nIndicare il nome di un modulo per poter accedere ai suoi elementi ha spesso l’effetto di allungare il codice, diminuendone al contempo la leggibilità. È per questo motivo che è possibile importare un modulo specificando un nome alternativo, più corto. È quello che succede quando scriviamo l’istruzione import numpy as np. In questo caso, l’istruzione precedente diventa np.mean().\nI moduli più complessi sono organizzati in strutture gerarchiche chiamate package. La seguente cella importa il modulo pyplot che è contenuto nel package matplotlib (matplotlib è la libreria di riferimento in Python per la creazione di grafici).\n\nimport matplotlib.pyplot as plt\n\nQui di seguito sono descritte tutte le possibilità:\n\n# import everything from library\nimport random\n# call function by\nrandom.random()\n\n0.16777284588756924\n\n\n\n#import everything, but change name\nimport random as rnd\n# call function by\nrnd.random()\n\n0.05690270000491682\n\n\n\n# select what to import from library\nfrom random import random\n#call function by\nrandom()\n\n0.037974565142151695\n\n\n\n# import everything from library\nfrom random import *\n# call function by\nrandom()\n\n0.20988431417194764\n\n\nNella cella seguente importiamo seaborn con il nome sns e usiamo le sue funzionalità per impostare uno stile e una palette di colori per la visualizzazione dei grafici.\n\nimport seaborn as sns\nsns.set_theme()\nsns.set_palette(\"colorblind\")\n\nNell’esempio seguente calcoliamo la somma degli elementi della lista numerica primes usando funzione sum() contenuta nella libreria NumPy che abbiamo importato con il nome di np:\n\nimport numpy as np\n\nprimes = [1, 2, 3, 5, 7, 11, 13]\nnp.sum(primes)\n\n42\n\n\nCalcolo la media di primes:\n\nnp.mean(primes)\n\n6.0\n\n\nScriviamo una nuova funzione per la media, \\(\\bar{x} = n^{-1}\\sum_{i=1}^n x_i\\):\n\ndef my_mean(x):\n    res = np.sum(x) / len(x)\n    return res\n\n\nmy_mean(primes)\n\n6.0\n\n\nSi noti che, nel corpo di una funzione, è possibile usare altre funzioni: qui, np.sum() e len().\nÈ sempre possibile usare la funzione di help su una funzione:\n\nhelp(sum)\n\nHelp on built-in function sum in module builtins:\n\nsum(iterable, /, start=0)\n    Return the sum of a 'start' value (default: 0) plus an iterable of numbers\n    \n    When the iterable is empty, return the start value.\n    This function is intended specifically for use with numeric values and may\n    reject non-numeric types.\n\n\n\nIn Visual Studio Code è sufficiente posizionare il cursore sul nome della funzione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#formattazione-del-codice",
    "href": "chapters/python/02_python_2.html#formattazione-del-codice",
    "title": "4  Python (2)",
    "section": "4.5 Formattazione del Codice",
    "text": "4.5 Formattazione del Codice",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/02_python_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "4  Python (2)",
    "section": "4.6 Informazioni sull’Ambiente di Sviluppo",
    "text": "4.6 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.1.4\nnumpy     : 1.26.2\nseaborn   : 0.13.0\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html",
    "href": "chapters/python/03_numpy.html",
    "title": "5  NumPy",
    "section": "",
    "text": "5.1 Preparazione del Notebook\nimport numpy as np",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "href": "chapters/python/03_numpy.html#utilizzo-degli-array-nel-modulo-numpy",
    "title": "5  NumPy",
    "section": "5.2 Utilizzo degli Array nel Modulo NumPy",
    "text": "5.2 Utilizzo degli Array nel Modulo NumPy\nIn Python standard, abbiamo a disposizione tipi di dati numerici (come numeri interi e decimali) e strutture come liste, dizionari e insiemi. NumPy, d’altro canto, introduce un nuovo tipo di struttura dati: l’array N-dimensionale, noto come ndarray. Questi array hanno alcune caratteristiche distintive:\n\nDimensioni: Gli ndarray possono variare nel numero di dimensioni, definite come “assi”. Ad esempio, un array può essere unidimensionale (simile a un vettore lineare), bidimensionale (come una matrice o una tabella), tridimensionale (simile a un cubo), e così via.\nTipo di Dato: A differenza delle liste in Python standard che possono contenere diversi tipi di dati, ogni elemento all’interno di un ndarray deve essere dello stesso tipo, come numeri interi, decimali, booleani o stringhe.\nForma: La “forma” di un ndarray si riferisce alle sue dimensioni, ovvero quante righe, colonne o altri livelli di profondità ha. Per esempio, la forma (3, 4) indica un array con 3 righe e 4 colonne.\nIndicizzazione: Gli ndarray possono essere indicizzati in modo simile agli array standard di Python, ma offrono anche opzioni più avanzate per l’indicizzazione.\n\nGli ndarray sono potenti per manipolare e analizzare i dati, grazie alle loro funzioni e metodi che includono operazioni matematiche e statistiche, trasformazioni e altre manipolazioni dei dati.\nTerminologia Importante: - Size: Indica il numero totale di elementi in un array. - Rank: Si riferisce al numero di dimensioni, o assi, di un array. - Shape: Denota le dimensioni specifiche dell’array, ovvero una sequenza di numeri che rappresentano il conteggio degli elementi in ogni dimensione.\nCome Creare un ndarray: Il modo più diretto per creare un ndarray è attraverso la conversione di una lista Python. Ad esempio, è possibile creare un array unidimensionale (1-D) a partire da una lista standard di Python.\n\nx = np.array([1, 2, 3, 4, 5, 6])\n\nL’istruzione precedente crea un array in NumPy, assegnandolo alla variabile x. Questo array è un vettore unidimensionale contenente sei elementi, che sono i numeri interi specificati all’interno delle parentesi quadre.\n\nprint(x)\n\n[1 2 3 4 5 6]\n\n\nIndicizzazione\nSe vogliamo estrarre un singolo elemento del vettore lo indicizziamo con la sua posizione (si ricordi che l’indice inizia da 0):\n\nx[0]\n\n1\n\n\n\nx[2]\n\n3\n\n\nUn array 2-D si crea nel modo seguente:\n\ny = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nEstraiamo un singolo elemento dall’array:\n\ny[0, 2]\n\n3\n\n\nEstraiamo la seconda riga dall’array:\n\ny[1]\n\narray([5, 6, 7, 8])\n\n\nEstraiamo la seconda colonna dall’array:\n\ny[:, 1] \n\narray([ 2,  6, 10])\n\n\nLa sintassi con i due punti è chiamata “slicing” dell’array.\n\n# Display the first row of the array\nprint(\"Displaying the first row:\")\nprint(y[0, :])\n\nDisplaying the first row:\n[1 2 3 4]\n\n\n\n# Show the last two elements in the first row\nprint(\"Showing the last two elements in the first row:\")\nprint(y[0, -2:])\n\nShowing the last two elements in the first row:\n[3 4]\n\n\n\n# Retrieve every second element in the first row\nprint(\"Retrieving every second element in the first row:\")\nprint(y[0, ::2])\n\nRetrieving every second element in the first row:\n[1 3]\n\n\n\n# Extract a submatrix from the original array\nprint(\"Extracting a submatrix:\")\nprint(y[:2, 1:3])\n\nExtracting a submatrix:\n[[2 3]\n [6 7]]\n\n\n\n5.2.1 Funzioni per ndarray\nNumpy offre varie funzioni per creare ndarray. Per esempio, è possibile creare un array 1-D con la funzione .arange(start, stop, incr, dtype=..) che fornisce l’intervallo di numeri compreso fra start, stop, al passo incr:\n\nz = np.arange(2, 9, 2)\nprint(z)\n\n[2 4 6 8]\n\n\nSi usa spesso .arange per creare sequenze a incrementi unitari:\n\nw = np.arange(11)\nprint(w)\n\n[ 0  1  2  3  4  5  6  7  8  9 10]\n\n\nUn’altra funzione molto utile è .linspace:\n\nx = np.linspace(0, 10, num=20)\nprint(x)\n\n[ 0.          0.52631579  1.05263158  1.57894737  2.10526316  2.63157895\n  3.15789474  3.68421053  4.21052632  4.73684211  5.26315789  5.78947368\n  6.31578947  6.84210526  7.36842105  7.89473684  8.42105263  8.94736842\n  9.47368421 10.        ]\n\n\nFissati gli estremi (qui 0, 10) e il numero di elementi desiderati, .linspace determina in maniera automatica l’incremento.\nUna proprietà molto utile dei ndarray è la possibilità di filtrare gli elementi di un array che rispondono come True ad un criterio. Per esempio:\n\nprint(x[x &gt; 7])\n\n[ 7.36842105  7.89473684  8.42105263  8.94736842  9.47368421 10.        ]\n\n\nperché solo gli ultimi sei elementi di x rispondono True al criterio \\(x &gt; 7\\).\nLe dimensioni (“assi”) di un ndarray vengono ritornate dal metodo .dim. Per esempio:\n\nprint(y)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\ny.ndim\n\n2\n\n\n\nprint(y.max(axis=1))\n\n[ 4  8 12]\n\n\n\nprint(y.max(axis=0))\n\n[ 9 10 11 12]\n\n\nIl numero di elementi per ciascun asse viene ritornato dal metodo .shape:\n\ny.shape\n\n(3, 4)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#manipolazione-di-array-con-numpy",
    "href": "chapters/python/03_numpy.html#manipolazione-di-array-con-numpy",
    "title": "5  NumPy",
    "section": "5.3 Manipolazione di Array con NumPy",
    "text": "5.3 Manipolazione di Array con NumPy\nNumPy rende più agevole lavorare con grandi quantità di dati. Un concetto fondamentale in NumPy sono gli array monodimensionali, spesso utilizzati per rappresentare vettori, ovvero sequenze di numeri che possono rappresentare, ad esempio, le misurazioni di una variabile specifica. Grazie a NumPy, possiamo eseguire operazioni aritmetiche su questi vettori in modo semplice, applicando la stessa operazione a tutti gli elementi dell’array contemporaneamente.\n\n5.3.1 Cosa Significa Vettorizzare un’Operazione\nLa vettorizzazione è una delle funzionalità più efficaci di NumPy. Quando diciamo che un’operazione è vettorizzata, significa che questa operazione viene applicata in un colpo solo a tutti gli elementi dell’array, invece di dover agire su ciascun elemento individualmente. Questo approccio rende la manipolazione di grandi insiemi di dati non solo più veloce ma anche più intuitiva, poiché consente di trattare l’intero insieme di dati come un’unica entità anziché come una serie di punti dati individuali.\nSupponiamo di avere raccolto i dati di 4 individui\n\nm = np.array([1.62, 1.75, 1.55, 1.74])\nkg = np.array([55.4, 73.6, 57.1, 59.5])\n\nprint(m)\nprint(kg)\n\n[1.62 1.75 1.55 1.74]\n[55.4 73.6 57.1 59.5]\n\n\ndove m è l’array che contiene i dati relativi all’altezza in metri dei quattro individui e kg è l’array che contiene i dati relativi al peso in kg. I dati sono organizzati in modo tale che il primo elemento di entrambi i vettori si riferisce alle misure del primo individuo, il secondo elemento dei due vettori si riferisce alle misure del secondo individuo, ecc.\nSupponiamo di volere calcolare l’indice BMI:\n\\[\nBMI = \\frac{kg}{m^2}.\n\\]\nPer il primo individuo del campione, l’indice di massa corporea è\n\n55.4 / 1.62**2\n\n21.109586953208346\n\n\nSi noti che non abbiamo bisogno di scrivere 55.4 / (1.62**2) in quanto, in Python, l’elevazione a potenza viene eseguita prima della somma e della divisione (come in tutti i linguaggi). Usando i dati immagazzinati nei due vettori, lo stesso risultato si ottiene nel modo seguente:\n\nkg[0] / m[0]**2\n\n21.109586953208346\n\n\nSe ora non specifichiamo l’indice (per esempio, [0]), le operazioni aritmetiche indicate verranno eseguite per ciascuna coppia di elementi corrispondenti nei due vettori:\n\nbmi = kg / m**2\n\nOtteniamo così, con una sola istruzione, l’indice BMI dei quattro individui:\n\nbmi.round(1)\n\narray([21.1, 24. , 23.8, 19.7])\n\n\nQuesto esempio illustra come le operazioni aritmetiche standard vengano eseguite elemento per elemento negli array, grazie al processo di vettorizzazione.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#broadcasting",
    "href": "chapters/python/03_numpy.html#broadcasting",
    "title": "5  NumPy",
    "section": "5.4 Broadcasting",
    "text": "5.4 Broadcasting\nIl broadcasting è una caratteristica distintiva di NumPy che facilita l’esecuzione di operazioni tra array di dimensioni diverse o tra un array e uno scalare, anche se le loro dimensioni non sono direttamente compatibili. Grazie al broadcasting, NumPy è in grado di “espandere” automaticamente le dimensioni di uno degli operandi per rendere possibile l’operazione.\nQuesto significa che possiamo, per esempio, eseguire un’operazione tra un array e un numero singolo (un vettore e uno scalare) o tra due array di dimensioni differenti, senza la necessità di modificare manualmente le dimensioni di questi array. Il broadcasting si occupa di adattare le dimensioni in modo coerente per consentire l’operazione desiderata. Ciò rende il codice più snello e leggibile, eliminando la necessità di espandere gli array manualmente.\nIn breve, il broadcasting in NumPy è un potente strumento che semplifica l’esecuzione di operazioni su array di dimensioni diverse o tra array e scalari, automatizzando l’allineamento delle dimensioni.\n\n5.4.1 Esempio di Broadcasting\nImmaginiamo di avere un array A con dimensioni 3x3 e un numero scalare B. Senza broadcasting, dovremmo espandere B in un array 3x3 riempiendo ogni cella con il valore di B per eseguire un’operazione come l’addizione su ciascun elemento di A. Grazie al broadcasting, possiamo semplicemente scrivere A + B, e NumPy si occuperà automaticamente di “espandere” B durante l’operazione, applicando il valore scalare a ogni elemento di A.\n\n# Creiamo un array 3x3\nA = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Definiamo uno scalare\nB = 5\n\n# Applichiamo il broadcasting per aggiungere lo scalare a ogni elemento dell'array\nC = A + B\n\nprint(C)\n\n[[ 6  7  8]\n [ 9 10 11]\n [12 13 14]]\n\n\nIn questo esempio, C conterrà l’array originale A con ogni elemento incrementato di 5, dimostrando come il broadcasting semplifichi operazioni che altrimenti richiederebbero passaggi aggiuntivi.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#altre-operazioni-sugli-array",
    "href": "chapters/python/03_numpy.html#altre-operazioni-sugli-array",
    "title": "5  NumPy",
    "section": "5.5 Altre operazioni sugli array",
    "text": "5.5 Altre operazioni sugli array\nC’è un numero enorme di funzioni predefinite in NumPy che calcolano automaticamente diverse quantità sugli ndarray. Ad esempio:\n\nmean(): calcola la media di un vettore o matrice;\nsum(): calcola la somma di un vettore o matrice;\nstd(): calcola la deviazione standard;\nmin(): trova il minimo nel vettore o matrice;\nmax(): trova il massimo;\nndim: dimensione del vettore o matrice;\nshape: restituisce una tupla con la “forma” del vettore o matrice;\nsize: restituisce la dimensione totale del vettore (=ndim) o della matrice;\ndtype: scrive il tipo numpy del dato;\nzeros(num): scrive un vettore di num elementi inizializzati a zero;\narange(start,stop,step): genera un intervallo di valori (interi o reali, a seconda dei valori di start, ecc.) intervallati di step. Nota che i dati vengono generati nell’intervallo aperto [start,stop)!\nlinstep(start,stop,num): genera un intervallo di num valori interi o reali a partire da start fino a stop (incluso!);\nastype(tipo): converte l’ndarray nel tipo specificato\n\nPer esempio:\n\nx = np.array([1, 2, 3])\nprint(x)\n\n[1 2 3]\n\n\n\n[x.min(), x.max(), x.sum(), x.mean(), x.std()]\n\n[1, 3, 6, 2.0, 0.816496580927726]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#lavorare-con-formule-matematiche",
    "href": "chapters/python/03_numpy.html#lavorare-con-formule-matematiche",
    "title": "5  NumPy",
    "section": "5.6 Lavorare con formule matematiche",
    "text": "5.6 Lavorare con formule matematiche\nL’implementazione delle formule matematiche sugli array è un processo molto semplice con Numpy. Possiamo prendere ad esempio la formula della deviazione standard che discuteremo nel capitolo {ref}loc-scale-notebook:\n\\[\ns = \\sqrt{\\sum_{i=1}^n\\frac{(x_i - \\bar{x})^2}{n}}\n\\]\nL’implementazione su un array NumPy è la seguente:\n\nprint(x)\n\n[1 2 3]\n\n\n\nnp.sqrt(np.sum((x - np.mean(x)) ** 2) / np.size(x))\n\n0.816496580927726\n\n\nQuesta implementazione funziona nello stesso modo sia che x contenga 3 elementi (come nel caso presente) sia che x contenga migliaia di elementi. È importante notare l’utilizzo delle parentesi tonde per specificare l’ordine di esecuzione delle operazioni. In particolare, nel codice fornito, si inizia calcolando la media degli elementi del vettore x per mezzo della funzione np.mean(x). Questa operazione produce uno scalare, ovvero un singolo valore numerico che rappresenta la media degli elementi del vettore. L’utilizzo delle parentesi tonde è fondamentale per garantire l’ordine corretto delle operazioni. In questo caso, la funzione np.mean() viene applicata al vettore x prima di qualsiasi altra operazione matematica. Senza le parentesi tonde, le operazioni verrebbero eseguite in un ordine diverso e il risultato potrebbe essere errato.\n\nnp.mean(x)\n\n2.0\n\n\nSuccessivamente, eseguiamo la sottrazione dei singoli elementi del vettore x per la media del vettore stesso, ovvero \\(x_i - \\bar{x}\\), utilizzando il meccanismo del broadcasting.\n\nx - np.mean(x)\n\narray([-1.,  0.,  1.])\n\n\nEleviamo poi al quadrato gli elementi del vettore che abbiamo ottenuto:\n\n(x - np.mean(x)) ** 2\n\narray([1., 0., 1.])\n\n\nSommiamo gli elementi del vettore:\n\nnp.sum((x - np.mean(x)) ** 2)\n\n2.0\n\n\nDividiamo il numero ottenuto per \\(n\\). Questa è la varianza di \\(x\\):\n\nres = np.sum((x - np.mean(x)) ** 2) / np.size(x)\nres\n\n0.6666666666666666\n\n\nInfine, per ottenere la deviazione standard, prendiamo la radice quadrata:\n\nnp.sqrt(res)\n\n0.816496580927726\n\n\nIl risultato ottenuto coincide con quello che si trova applicando la funzione np.std():\n\nnp.std(x)\n\n0.816496580927726",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#slicing",
    "href": "chapters/python/03_numpy.html#slicing",
    "title": "5  NumPy",
    "section": "5.7 Slicing",
    "text": "5.7 Slicing\nPer concludere, spendiamo ancora alcune parole sull’indicizzazione degli ndarray.\nSlicing in Numpy è un meccanismo che consente di selezionare una porzione di un array multidimensionale, ovvero una sotto-matrice o un sotto-vettore. Per selezionare una porzione di un array, si utilizza la sintassi [start:stop:step], dove start indica l’indice di partenza della porzione, stop indica l’indice di fine e step indica il passo da utilizzare per la selezione. Se uno o più di questi valori vengono omessi, vengono utilizzati dei valori di default.\nAd esempio, se abbiamo un array arr di dimensione (3, 4) e vogliamo selezionare la seconda colonna, possiamo usare la sintassi arr[:, 1]. In questo caso, il simbolo : indica che vogliamo selezionare tutte le righe, mentre il numero 1 indica che vogliamo selezionare la seconda colonna.\nInoltre, possiamo utilizzare il meccanismo di slicing anche per selezionare porzioni di array multidimensionali. Ad esempio, se abbiamo un array arr di dimensione (3, 4, 5) e vogliamo selezionare la prima riga di ciascuna matrice 4x5, possiamo usare la sintassi arr[:, 0, :].\nPer esempio, creiamo l’array x di rango 2 con shape (3, 4):\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nUtilizziamo il meccanismo di slicing per estrarre la sottomatrice composta dalle prime 2 righe e dalle colonne 1 e 2. y è l’array risultante di dimensione (2, 2):\n\ny = x[:2, 1:3]\nprint(y)\n\n[[2 3]\n [6 7]]\n\n\nÈ importante sapere che uno slice di un array in Numpy è una vista degli stessi dati, il che significa che modificarlo implica la modifica dell’array originale. In pratica, quando si modifica uno slice di un array, si sta modificando direttamente l’array originale e tutte le altre visualizzazioni dell’array vedranno la stessa modifica. Questo avviene perché Numpy è progettato per gestire enormi quantità di dati, pertanto cerca di evitare il più possibile di effettuare copie dei dati.\nQuesto comportamento deve essere preso in considerazione durante la modifica degli array in Numpy, al fine di evitare modifiche accidentali o indesiderate. In alcuni casi, è possibile utilizzare il metodo copy() per creare una copia indipendente di un array e lavorare sulla copia senza modificare l’originale. Vediamo un esempio.\n\nprint(x[0, 1])   \n\n2\n\n\n\ny[0, 0] = 77     \n\n\nprint(x)\n\n[[ 1 77  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nx = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nz = x.copy()\nprint(z)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nz[0, 1] = 33\nprint(z)\n\n[[ 1 33  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\n\nprint(x)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#copia-e-copia-profonda-in-python",
    "href": "chapters/python/03_numpy.html#copia-e-copia-profonda-in-python",
    "title": "5  NumPy",
    "section": "5.8 Copia e “Copia Profonda” in Python",
    "text": "5.8 Copia e “Copia Profonda” in Python\nIn Python, per ottimizzare le prestazioni, le assegnazioni di solito non copiano gli oggetti sottostanti. Questo è particolarmente importante, ad esempio, quando gli oggetti vengono passati tra funzioni, per evitare una quantità eccessiva di copie in memoria quando non sono necessarie (questo approccio è noto tecnicamente come “passaggio per riferimento”).\nConsideriamo il seguente esempio con un array A:\n\nA = np.array([[1, 2], [3, 4]])\n\nSe creiamo un nuovo riferimento B a A:\n\nB = A\n\nOra B si riferisce allo stesso insieme di dati di A. Se modifichiamo B, anche A viene modificato di conseguenza:\n\nB[0,0] = 10\n\nDopo questa modifica, sia B che A saranno:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nSe desideriamo evitare questo comportamento, in modo tale che B diventi un oggetto completamente indipendente da A, dobbiamo effettuare una cosiddetta “copia profonda” utilizzando la funzione copy:\n\nB = np.copy(A)\n\nOra, se modificassimo B, A non subirebbe alcuna modifica. Ad esempio:\n\nB[0,0] = -5\n\nA questo punto, B sarà:\n\nprint(B)\n\n[[-5  2]\n [ 3  4]]\n\n\nMa A rimarrà invariato:\n\nprint(A)\n\n[[10  2]\n [ 3  4]]\n\n\nQuesto esempio mostra chiaramente la differenza tra una semplice assegnazione, che crea un riferimento all’oggetto originale, e una “copia profonda”, che crea un nuovo oggetto indipendente.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/03_numpy.html#informazioni-sullambiente-di-sviluppo",
    "title": "5  NumPy",
    "section": "5.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "5.9 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy: 1.26.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html",
    "href": "chapters/python/04_pandas.html",
    "title": "6  Pandas (1)",
    "section": "",
    "text": "Introduzione\nLa libreria Pandas offre diverse funzionalità per importare dati da fonti eterogenee, tra cui fogli Excel, file CSV, JSON e database SQL.\nPandas si basa su due strutture dati principali:\nL’obiettivo di questo capitolo è imparare a usare i DataFrame e a manipolare i dati al loro interno.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#introduzione",
    "href": "chapters/python/04_pandas.html#introduzione",
    "title": "6  Pandas (1)",
    "section": "",
    "text": "Series: utilizzata per rappresentare singole righe o colonne di un DataFrame, è simile a un array di NumPy.\nDataFrame: una struttura dati simile a una tabella, organizzata in colonne, dove ciascuna riga rappresenta un’unità di osservazione con i relativi dati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#series",
    "href": "chapters/python/04_pandas.html#series",
    "title": "6  Pandas (1)",
    "section": "6.1 Series",
    "text": "6.1 Series\nIn Pandas, una Series è un array unidimensionale composto da una sequenza di valori omogenei, simile ad un ndarray, accompagnato da un array di etichette chiamato “index”. A differenza degli indici degli array Numpy, che sono sempre interi e partono da zero, gli oggetti Series supportano etichette personalizzate che possono essere, ad esempio, delle stringhe. Inoltre, gli oggetti Series possono contenere dati mancanti che vengono ignorati da molte delle operazioni della classe.\nIl modo più semplice di creare un oggetto Series è di convertire una lista. Per esempio:\n\ngrades = pd.Series([27, 30, 24, 18, 22, 20, 29])\n\nÈ possibile ottenere la rappresentazione dell’array dell’oggetto e dell’indice dell’oggetto Series tramite i suoi attributi array e index, rispettivamente.\n\ngrades.array\n\n&lt;NumpyExtensionArray&gt;\n[27, 30, 24, 18, 22, 20, 29]\nLength: 7, dtype: int64\n\n\n\ngrades.index\n\nRangeIndex(start=0, stop=7, step=1)\n\n\nOppure, possiamo semplicemente stampare i contenuti dell’oggetto Series direttamente:\n\nprint(grades)\n\n0    27\n1    30\n2    24\n3    18\n4    22\n5    20\n6    29\ndtype: int64\n\n\nPer accedere agli elementi di un oggetto Series si usano le parentesi quadre contenenti un indice:\n\ngrades[0]\n\n27\n\n\n\ngrades[0:3]\n\n0    27\n1    30\n2    24\ndtype: int64\n\n\nÈ possibile filtrare gli elementi di un oggetto Series con un array booleano:\n\ngrades &gt; 24\n\n0     True\n1     True\n2    False\n3    False\n4    False\n5    False\n6     True\ndtype: bool\n\n\n\ngrades[grades &gt; 24]\n\n0    27\n1    30\n6    29\ndtype: int64\n\n\nÈ possibile manipolare gli elementi di un oggetto Series con le normali operazioni aritmetiche mediante la vettorializzazione:\n\ngrades / 10\n\n0    2.7\n1    3.0\n2    2.4\n3    1.8\n4    2.2\n5    2.0\n6    2.9\ndtype: float64\n\n\n\nnp.sqrt(grades)\n\n0    5.196152\n1    5.477226\n2    4.898979\n3    4.242641\n4    4.690416\n5    4.472136\n6    5.385165\ndtype: float64\n\n\nGli oggetti Series hanno diversi metodi per svolgere varie operazioni, per esempio per ricavare alcune statistiche descrittive:\n\n[grades.count(), grades.mean(), grades.min(), grades.max(), grades.std(), grades.sum()]\n\n[7, 24.285714285714285, 18, 30, 4.572172558506722, 170]\n\n\nMolto utile è il metodo .describe():\n\ngrades.describe()\n\ncount     7.000000\nmean     24.285714\nstd       4.572173\nmin      18.000000\n25%      21.000000\n50%      24.000000\n75%      28.000000\nmax      30.000000\ndtype: float64",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#dataframe",
    "href": "chapters/python/04_pandas.html#dataframe",
    "title": "6  Pandas (1)",
    "section": "6.2 DataFrame",
    "text": "6.2 DataFrame\nUn pandas.DataFrame è composto da righe e colonne. Ogni colonna di un dataframe è un oggetto pandas.Series: quindi, un dataframe è una collezione di serie. A differenza di un array NumPy, un dataframe può combinare più tipi di dati, come numeri e testo, ma i dati in ogni colonna sono dello stesso tipo.\nEsistono molti modi per costruire un DataFrame. Un primo metodo è quello di utilizzare un dizionario che include una o più liste o array Numpy di uguale lunghezza. Per esempio:\n\ndata = {\n    \"name\": [\n        \"Maria\",\n        \"Anna\",\n        \"Francesco\",\n        \"Cristina\",\n        \"Gianni\",\n        \"Gabriella\",\n        \"Stefano\",\n    ],\n    \"sex\": [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"],\n    \"group\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"],\n    \"x\": [1, 2, 3, 4, 5, 6, 7],\n    \"y\": [8, 9, 10, 11, 12, 13, 14],\n    \"z\": [15, 16, 17, 18, 19, 20, 21],\n}\nframe = pd.DataFrame(data)\nframe\n\n\n\n\n\n\n\n\nname\nsex\ngroup\nx\ny\nz\n\n\n\n\n0\nMaria\nf\na\n1\n8\n15\n\n\n1\nAnna\nf\nb\n2\n9\n16\n\n\n2\nFrancesco\nm\na\n3\n10\n17\n\n\n3\nCristina\nf\nb\n4\n11\n18\n\n\n4\nGianni\nm\nb\n5\n12\n19\n\n\n5\nGabriella\nf\nc\n6\n13\n20\n\n\n6\nStefano\nm\na\n7\n14\n21\n\n\n\n\n\n\n\nOppure possiamo procedere nel modo seguente:\n\ndf = pd.DataFrame()\n\ndf[\"x\"] = [1, 2, 3, 4, 5, 6, 7]\ndf[\"y\"] = [8, 9, 10, 11, 12, 13, 14]\ndf[\"z\"] = [14.4, 15.1, 16.7, 17.3, 18.9, 19.3, 20.2]\ndf[\"group\"] = [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\", \"a\"]\ndf[\"sex\"] = [\"f\", \"f\", \"m\", \"f\", \"m\", \"f\", \"m\"]\ndf[\"name\"] = [\n    \"Maria\",\n    \"Anna\",\n    \"Francesco\",\n    \"Cristina\",\n    \"Gianni\",\n    \"Gabriella\",\n    \"Stefano\",\n]\n\nprint(df)\n\n   x   y     z group sex       name\n0  1   8  14.4     a   f      Maria\n1  2   9  15.1     b   f       Anna\n2  3  10  16.7     a   m  Francesco\n3  4  11  17.3     b   f   Cristina\n4  5  12  18.9     b   m     Gianni\n5  6  13  19.3     c   f  Gabriella\n6  7  14  20.2     a   m    Stefano\n\n\nMolto spesso un DataFrame viene creato dal caricamento di dati da file.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#lettura-di-dati-da-file",
    "href": "chapters/python/04_pandas.html#lettura-di-dati-da-file",
    "title": "6  Pandas (1)",
    "section": "6.3 Lettura di dati da file",
    "text": "6.3 Lettura di dati da file\nDi solito la quantità di dati da analizzare è tale che non è pensabile di poterli immettere manualmente in una o più liste. Normalmente i dati sono memorizzati su un file ed è necessario importarli. La lettura (importazione) dei file è il primo fondamentale passo nel processo più generale di analisi dei dati.\nIn un primo esempio, importiamo i dati da un repository remoto.\n\nurl = \"https://raw.githubusercontent.com/pandas-dev/pandas/master/doc/data/titanic.csv\"\ntitanic = pd.read_csv(url, index_col=\"Name\")\n\nÈ possibile usare il metodo .head() per visualizzare le prime cinque righe.\n\ntitanic.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\nName\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBraund, Mr. Owen Harris\n1\n0\n3\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\n2\n1\n1\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\nHeikkinen, Miss. Laina\n3\n1\n3\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n4\n1\n1\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\nAllen, Mr. William Henry\n5\n0\n3\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\n\n\n\n\n\n\n\nLe statistiche descrittive per ciascuna colonna si ottengono con il metodo describe.\n\ntitanic.describe()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n891.000000\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.000000\n0.383838\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208\n\n\nstd\n257.353842\n0.486592\n0.836071\n14.526497\n1.102743\n0.806057\n49.693429\n\n\nmin\n1.000000\n0.000000\n1.000000\n0.420000\n0.000000\n0.000000\n0.000000\n\n\n25%\n223.500000\n0.000000\n2.000000\n20.125000\n0.000000\n0.000000\n7.910400\n\n\n50%\n446.000000\n0.000000\n3.000000\n28.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n668.500000\n1.000000\n3.000000\n38.000000\n1.000000\n0.000000\n31.000000\n\n\nmax\n891.000000\n1.000000\n3.000000\n80.000000\n8.000000\n6.000000\n512.329200\n\n\n\n\n\n\n\nIn questo modo possiamo ottenere informazioni sui nomi dei passeggeri, la sopravvivenza (0 o 1), l’età, il prezzo del biglietto, ecc. Con le statistiche riassuntive vediamo che l’età media è di 29,7 anni, il prezzo massimo del biglietto è di 512 USD, il 38% dei passeggeri è sopravvissuto, ecc.\nPer fare un secondo esempio, importo i dati dal file penguins.csv situato nella directory “data” del mio computer. I dati relativi ai pinguini di Palmer sono resi disponibili da Kristen Gorman e dalla Palmer station, Antarctica LTER. La seguente cella legge il contenuto del file penguins.csv e lo inserisce nell’oggetto df utilizzando la funzione read_csv() di Pandas.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nPer il DataFrame df il significato delle colonne è il seguente:\n\nspecies: a factor denoting penguin type (Adélie, Chinstrap and Gentoo)\nisland: a factor denoting island in Palmer Archipelago, Antarctica (Biscoe, Dream or Torgersen)\nbill_length_mm: a number denoting bill length (millimeters)\nbill_depth_mm: a number denoting bill depth (millimeters)\nflipper_length_mm: an integer denoting flipper length (millimeters)\nbody_mass_g: an integer denoting body mass (grams)\nsex: a factor denoting sexuality (female, male)\nyear: the year of the study\n\nUsiamo il metodo .head() per visualizzare le prime cinque righe.\n\ndf.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nA volte potrebbero esserci dati estranei alla fine del file, quindi è importante anche controllare le ultime righe:\n\ndf.tail()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n\n\n\nUn breve tutorial in formato video è disponibile tramite il seguente [collegamento](https://drive.google.com/file/d/12y7jZ0McvZBXThg6yjFgWx2ljQKrhoYR/view?usp=share_link), il quale illustra come effettuare la lettura dei dati da un file esterno in Visual Studio Code. \nL’attributo .dtypes restituisce il tipo dei dati:\n\ndf.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\nGli attributi più comunemente usati sono elencati di seguito:\n\n\n\n\n\n\n\nAttributo\nRitorna\n\n\n\n\ndtypes\nIl tipo di dati in ogni colonna\n\n\nshape\nUna tupla con le dimensioni del DataFrame object (numero di righe, numero di colonne)\n\n\nindex\nL’oggetto Index lungo le righe del DataFrame\n\n\ncolumns\nIl nome delle colonne\n\n\nvalues\nI dati contenuti nel DataFrame\n\n\nempty\nCheck if the DataFrame object is empty\n\n\n\nPer esempio, l’istruzione della cella seguente restituisce l’elenco con i nomi delle colonne del DataFrame df:\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')\n\n\nLe dimensioni del Data Frame si ottengono con l’attributo .shape, che ritorna il numero di righe e di colonne. Nel caso presente, ci sono 344 righe e 8 colonne.\n\ndf.shape\n\n(344, 8)\n\n\nCome abbiamo già visto in precedenza, un sommario dei dati si ottiene con il metodo .describe():\n\ndf.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\nUna descrizione del DataFrame si ottiene con il metodo .info().\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\nSi noti che, alle volte, abbiamo utilizzato la sintassi `df.word` e talvolta la sintassi `df.word()`. Tecnicamente, la classe Pandas Dataframe ha sia attributi che metodi. Gli attributi sono `.word`, mentre i metodi sono `.word()` o `.word(arg1, arg2, ecc.)`. Per sapere se qualcosa è un metodo o un attributo è necessario leggere la documentazione.\nAbbiamo visto in precedenza come possiamo leggere i dati in un dataframe utilizzando la funzione read_csv(). Pandas comprende anche molti altri formati, ad esempio utilizzando le funzioni read_excel(), read_hdf(), read_json(), ecc. (e i corrispondenti metodi per scrivere su file: to_csv(), to_excel(), to_hdf(), to_json(), ecc.).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#gestione-dei-dati-mancanti",
    "href": "chapters/python/04_pandas.html#gestione-dei-dati-mancanti",
    "title": "6  Pandas (1)",
    "section": "6.4 Gestione dei dati mancanti",
    "text": "6.4 Gestione dei dati mancanti\nNell’output di .info() troviamo la colonna “Non-Null Count”, ovvero il numero di dati non mancanti per ciascuna colonna del DataFrame. Da questo si nota che le colonne del DataFrame df contengono alcuni dati mancanti. La gestione dei dati mancanti è un argomento complesso. Per ora ci limitiamo ad escludere tutte le righe che, in qualche colonna, contengono dei dati mancanti.\nOttengo il numero di dati per ciascuna colonna del DataFrame:\n\ndf.isnull().sum()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\nyear                  0\ndtype: int64\n\n\nRimuovo i dati mancanti con il metodo .dropna(). L’argomento inplace=True specifica il DataFrame viene trasformato in maniera permanente.\n\ndf.dropna(inplace=True)\n\nVerifico che i dati mancanti siano stati rimossi.\n\ndf.shape\n\n(333, 8)\n\n\nIn alternativa, possiamo rimuovere solo le righe del DataFrame per le quali ci sono dei dati mancanti rispetto a specifiche colonne. Per esempio\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf0 = df.copy()\n\nmissing_data = df0.isnull()[[\"bill_length_mm\", \"body_mass_g\"]].any(axis=1)\n# Drop rows with any missing data\ndf0_cleaned = df0.loc[~missing_data]\ndf0_cleaned.shape\n\n(342, 8)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#rinominare-le-colonne",
    "href": "chapters/python/04_pandas.html#rinominare-le-colonne",
    "title": "6  Pandas (1)",
    "section": "6.5 Rinominare le colonne",
    "text": "6.5 Rinominare le colonne\nÈ possibile rinominare tutte le colonne passando al metodo .rename() un dizionario che specifica quali colonne devono essere mappate a cosa. Nella cella seguente facciamo prima una copia del DataFrame con il metodo copy() e poi rinominiamo sex che diventa gender e year che diventa year_of_the_study:\n\ndf1 = df.copy()\n\n# rename(columns={\"OLD_NAME\": \"NEW_NAME\"})\ndf1.rename(columns={\n    \"sex\": \"gender\", \n    \"year\": \"year_of_the_study\"\n    }, \n           inplace=True)\ndf1.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\ngender\nyear_of_the_study\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nSi noti che in Python valgono le seguenti regole.\n\n- Il nome di una variabile deve iniziare con una lettera o con il trattino basso (*underscore*) `_`.\n- Il nome di una variabile non può iniziare con un numero.\n- Un nome di variabile può contenere solo caratteri alfanumerici e il trattino basso (A-z, 0-9 e _).\n- I nomi delle variabili fanno distinzione tra maiuscole e minuscole (`age`, `Age` e `AGE` sono tre variabili diverse).\n\nGli spazi non sono consentiti nel nome delle variabili: come separatore usate il trattino basso.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "href": "chapters/python/04_pandas.html#estrarre-i-dati-dal-dataframe",
    "title": "6  Pandas (1)",
    "section": "6.6 Estrarre i dati dal DataFrame",
    "text": "6.6 Estrarre i dati dal DataFrame\nUna parte cruciale del lavoro con i DataFrame è l’estrazione di sottoinsiemi di dati: vogliamo trovare le righe che soddisfano un determinato insieme di criteri, vogliamo isolare le colonne/righe di interesse, ecc. Per rispondere alle domande di interesse dell’analisi dei dati, molto spesso è necessario selezionare un sottoinsieme del DataFrame.\n\n6.6.1 Colonne\nÈ possibile estrarre una colonna da un DataFrame usando una notazione simile a quella che si usa per il dizionario (DataFrame['word']) o utilizzando la notazione DataFrame.word. Per esempio:\n\ndf[\"bill_length_mm\"]\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\n\ndf.bill_length_mm\n\n0      39.1\n1      39.5\n2      40.3\n4      36.7\n5      39.3\n       ... \n339    55.8\n340    43.5\n341    49.6\n342    50.8\n343    50.2\nName: bill_length_mm, Length: 333, dtype: float64\n\n\nSe tra parentesi quadre indichiamo una lista di colonne, come nel caso di df[['bill_length_mm','species']], otteniamo un nuovo DataFrame costituito unicamente dalle colonne selezionate:\n\ndf[[\"bill_length_mm\", \"species\"]]\n\n\n\n\n\n\n\n\nbill_length_mm\nspecies\n\n\n\n\n0\n39.1\nAdelie\n\n\n1\n39.5\nAdelie\n\n\n2\n40.3\nAdelie\n\n\n4\n36.7\nAdelie\n\n\n5\n39.3\nAdelie\n\n\n...\n...\n...\n\n\n339\n55.8\nChinstrap\n\n\n340\n43.5\nChinstrap\n\n\n341\n49.6\nChinstrap\n\n\n342\n50.8\nChinstrap\n\n\n343\n50.2\nChinstrap\n\n\n\n\n333 rows × 2 columns\n\n\n\n\n\n6.6.2 Righe\nIn un pandas.DataFrame, anche le righe hanno un nome. I nomi delle righe sono chiamati index:\n\ndf.index\n\nInt64Index([  0,   1,   2,   4,   5,   6,   7,  12,  13,  14,\n            ...\n            334, 335, 336, 337, 338, 339, 340, 341, 342, 343],\n           dtype='int64', length=333)\n\n\nCi sono vari metodi per estrarre sottoinsimi di righe da un DataFrame. È possibile fare riferimento ad un intervallo di righe mediante un indice di slice. Per esempio, possiamo ottenere le prime 3 righe del DataFrame df nel modo seguente:\n\ndf[0:3]\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\nSi noti che in Python una sequenza è determinata dal valore iniziale e quello finale ma si interrompe ad n-1. Pertanto, per selezionare una singola riga (per esempio, la prima) dobbiamo procedere nel modo seguente:\n\ndf[0:1]\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n\n\n\n\n\n\n\n6.6.3 Indicizzazione, selezione e filtraggio\nPoiché l’oggetto DataFrame è bidimensionale, è possibile selezionare un sottoinsieme di righe e colonne utilizzando le etichette degli assi (loc) o gli indici delle righe (iloc).\nPer esempio, usando l’attributo iloc posso selezionare la prima riga del DataFrame:\n\ndf.iloc[0]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            39.1\nbill_depth_mm             18.7\nflipper_length_mm        181.0\nbody_mass_g             3750.0\nsex                       male\nyear                      2007\nName: 0, dtype: object\n\n\nLa cella seguene seleziona le prime tre righe del DataFrame:\n\ndf.iloc[0:3]\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n\n\n\n\n\nL’attributo loc consente di selezionare simultaneamente righe e colonne per “nome”. Il “nome” delle righe è l’indice di riga. Per esempio, visualizzo il quinto valore della colonna body_mass_g:\n\ndf.loc[4, \"body_mass_g\"]\n\n3450.0\n\n\noppure, il quinto valore delle colonne bill_length_mm, bill_depth_mm, flipper_length_mm:\n\ndf.loc[4, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\nbill_length_mm        36.7\nbill_depth_mm         19.3\nflipper_length_mm    193.0\nName: 4, dtype: object\n\n\nVisualizzo ora le prime tre righe sulle tre colonne precedenti. Si noti l’uso di : per definire un intervallo di valori sull’indice di riga.\n\ndf.loc[0:2, [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n39.1\n18.7\n181.0\n\n\n1\n39.5\n17.4\n186.0\n\n\n2\n40.3\n18.0\n195.0\n\n\n\n\n\n\n\nUna piccola variante della sintassi precedente si rivela molto utile. Qui, il segno di due punti (:) signfica “tutte le righe”:\n\nkeep_cols = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]\nprint(df.loc[:, keep_cols])\n\n     bill_length_mm  bill_depth_mm  flipper_length_mm\n0              39.1           18.7              181.0\n1              39.5           17.4              186.0\n2              40.3           18.0              195.0\n4              36.7           19.3              193.0\n5              39.3           20.6              190.0\n..              ...            ...                ...\n339            55.8           19.8              207.0\n340            43.5           18.1              202.0\n341            49.6           18.2              193.0\n342            50.8           19.0              210.0\n343            50.2           18.7              198.0\n\n[333 rows x 3 columns]\n\n\n\n\n6.6.4 Filtrare righe in maniera condizionale\nIn precedenza abbiamo utilizzato la selezione delle righe in un DataFrame in base alla loro posizione. Tuttavia, è più comune selezionare le righe del DataFrame utilizzando una condizione logica, cioè tramite l’indicizzazione booleana.\nIniziamo con un esempio relativo ad una condizione specificata sui valori di una sola colonna. Quando applichiamo un operatore logico come &gt;, &lt;, ==, != ai valori di una colonna del DataFrame, il risultato è una sequenza di valori booleani (True, False), uno per ogni riga nel DataFrame, i quali indicano se, per quella riga, la condizione è vera o falsa. Ad esempio:\n\ndf[\"island\"] == \"Torgersen\"\n\n0       True\n1       True\n2       True\n4       True\n5       True\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nName: island, Length: 333, dtype: bool\n\n\nUtilizzando i valori booleani che sono stati ottenuti in questo modo è possibile filtrare le righe del DataFrame, ovvero, ottenere un nuovo DataFrame nel quale la condizione logica specificata è vera su tutte le righe. Per esempio, nella cella seguente selezioniamo solo le osservazioni relative all’isola Torgersen, ovvero tutte le righe del DataFrame nelle quali la colonna island assume il valore Torgersen.\n\nonly_torgersen = df[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo scrivere:\n\nonly_torgersen = df.loc[df[\"island\"] == \"Torgersen\"]\nonly_torgersen.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n\n\n\n\n\nÈ possibile combinare più condizioni logiche usando gli operatori & (e), | (oppure). Si presti attenzione all’uso delle parentesi.\n\ndf.loc[(df[\"island\"] == \"Torgersen\") & (df[\"sex\"] == \"female\")].head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n12\nAdelie\nTorgersen\n41.1\n17.6\n182.0\n3200.0\nfemale\n2007\n\n\n\n\n\n\n\n\n\n6.6.5 Metodo .query\nÈ anche possibile filtrare le righe del DataFrame usando il metodo query(). Ci sono diversi modi per generare sottoinsiemi con Pandas. I metodi loc e iloc consentono di recuperare sottoinsiemi in base alle etichette di riga e colonna o all’indice intero delle righe e delle colonne. E Pandas ha una notazione a parentesi quadre che consente di utilizzare condizioni logiche per recuperare righe di dati specifiche. Ma la sintassi di questi metodi non è la più trasparente. Inoltre, tali metodi sono difficili da usare insieme ad altri metodi di manipolazione dei dati in modo organico.\nIl metodo .query di Pandas cerca di risolve questi problemi. Il metodo .query consente di “interrogare” un DataFrame e recuperare sottoinsiemi basati su condizioni logiche. La sintassi è un po’ più snella rispetto alla notazione a parentesi quadre di Pandas. Inoltre, il metodo .query può essere utilizzato con altri metodi di Pandas in modo snello e semplice, rendendo la manipolazione dei dati maggiormente fluida e diretta.\nLa sintassi è la seguente:\nyour_data_frame.query(expression, inplace = False)\nL’espressione utilizzata nella query è una sorta di espressione logica che descrive quali righe restituire in output. Se l’espressione è vera per una particolare riga, la riga verrà inclusa nell’output. Se l’espressione è falsa per una particolare riga, quella riga verrà esclusa dall’output.\nIl parametro inplace consente di specificare se si desidera modificare direttamente il DataFrame con cui si sta lavorando.\nPer esempio:\n\neval_string = \"island == 'Torgersen' & sex == 'female' & year != 2009\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n6\n17.8\n181.0\n\n\n12\n17.6\n182.0\n\n\n15\n17.8\n185.0\n\n\n16\n19.0\n195.0\n\n\n18\n18.4\n184.0\n\n\n68\n16.6\n190.0\n\n\n70\n19.0\n190.0\n\n\n72\n17.2\n196.0\n\n\n74\n17.5\n190.0\n\n\n76\n16.8\n191.0\n\n\n78\n16.1\n187.0\n\n\n80\n17.2\n189.0\n\n\n82\n18.8\n187.0\n\n\n\n\n\n\n\nUn altro esempio usa la keyword in per selezionare solo le righe relative alle due isole specificate.\n\neval_string = \"island in ['Torgersen', 'Dream']\"\ndf.query(eval_string)[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n0\n18.7\n181.0\n\n\n1\n17.4\n186.0\n\n\n2\n18.0\n195.0\n\n\n4\n19.3\n193.0\n\n\n5\n20.6\n190.0\n\n\n...\n...\n...\n\n\n339\n19.8\n207.0\n\n\n340\n18.1\n202.0\n\n\n341\n18.2\n193.0\n\n\n342\n19.0\n210.0\n\n\n343\n18.7\n198.0\n\n\n\n\n170 rows × 2 columns\n\n\n\nIl metodo query() può anche essere utilizzato per selezionare le righe di un DataFrame in base alle relazioni tra le colonne. Ad esempio,\n\ndf.query(\"bill_length_mm &gt; 3*bill_depth_mm\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n152\n13.2\n211.0\n\n\n153\n16.3\n230.0\n\n\n154\n14.1\n210.0\n\n\n155\n15.2\n218.0\n\n\n156\n14.5\n215.0\n\n\n...\n...\n...\n\n\n272\n14.3\n215.0\n\n\n273\n15.7\n222.0\n\n\n274\n14.8\n212.0\n\n\n275\n16.1\n213.0\n\n\n293\n17.8\n181.0\n\n\n\n\n106 rows × 2 columns\n\n\n\nÈ anche possibile fare riferimento a variabili non contenute nel DataFrame usando il carattere @.\n\noutside_var = 21\ndf.query(\"bill_depth_mm &gt; @outside_var\")[[\"bill_depth_mm\", \"flipper_length_mm\"]]\n\n\n\n\n\n\n\n\nbill_depth_mm\nflipper_length_mm\n\n\n\n\n13\n21.2\n191.0\n\n\n14\n21.1\n198.0\n\n\n19\n21.5\n194.0\n\n\n35\n21.1\n196.0\n\n\n49\n21.2\n191.0\n\n\n61\n21.1\n195.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "href": "chapters/python/04_pandas.html#selezione-casuale-di-un-sottoinsieme-di-righe",
    "title": "6  Pandas (1)",
    "section": "6.7 Selezione casuale di un sottoinsieme di righe",
    "text": "6.7 Selezione casuale di un sottoinsieme di righe\nIl metodo sample() viene usato per ottenere un sottoinsieme casuale di righe del DataFrame. L’argomento replace=False indica l’estrazione senza rimessa (default); se specifichiamo replace=True otteniamo un’estrazione con rimessa. L’argomento n specifica il numero di righe che vogliamo ottenere. Ad esempio\n\ndf_sample = df.sample(4)\ndf_sample\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n204\nGentoo\nBiscoe\n45.1\n14.4\n210.0\n4400.0\nfemale\n2008\n\n\n69\nAdelie\nTorgersen\n41.8\n19.4\n198.0\n4450.0\nmale\n2008\n\n\n296\nChinstrap\nDream\n42.4\n17.3\n181.0\n3600.0\nfemale\n2007\n\n\n208\nGentoo\nBiscoe\n43.8\n13.9\n208.0\n4300.0\nfemale\n2008\n\n\n\n\n\n\n\n\ndf_sample = df[[\"bill_length_mm\", \"bill_depth_mm\"]].sample(4)\ndf_sample\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\n\n\n175\n46.3\n15.8\n\n\n133\n37.5\n18.5\n\n\n182\n47.3\n15.3\n\n\n251\n51.1\n16.5",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#selezione-di-colonne",
    "href": "chapters/python/04_pandas.html#selezione-di-colonne",
    "title": "6  Pandas (1)",
    "section": "6.8 Selezione di colonne",
    "text": "6.8 Selezione di colonne\nIl metodo drop() prende in input una lista con i nomi di colonne che vogliamo escludere dal DataFrame e può essere usato per creare un nuovo DataFrame o per sovrascrivere quello di partenza. È possibile usare le espressioni regolari (regex) per semplificare la ricerca dei nomi delle colonne.\nIn *regex* il simbolo `$` significa \"la stringa finisce con\"; il simbolo `^` significa \"la stringa inizia con\". L'espressione `regex` può contenere (senza spazi) il simbolo `|` che significa \"oppure\". \nNel codice della cella seguente, alla funzione .columns.str.contains() viene passata l’espressione regolare mm$|year che significa: tutte le stringhe (in questo caso, nomi di colonne) che finiscono con mm oppure la stringa (nome di colonna) year.\n\nmask = df.columns.str.contains(\"mm$|year\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'year'], dtype='object')\n\n\n\ndf_new = df.drop(columns=columns_to_drop)\ndf_new.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n3750.0\nmale\n\n\n1\nAdelie\nTorgersen\n3800.0\nfemale\n\n\n2\nAdelie\nTorgersen\n3250.0\nfemale\n\n\n4\nAdelie\nTorgersen\n3450.0\nfemale\n\n\n5\nAdelie\nTorgersen\n3650.0\nmale\n\n\n\n\n\n\n\nIn un altro esempio, creaiamo l’elenco delle colonne che iniziano con la lettera “b”, insieme a year e sex.\n\nmask = df.columns.str.contains(\"^b|year|sex\", regex=True)\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'bill_depth_mm', 'body_mass_g', 'sex', 'year'], dtype='object')\n\n\nOppure l’elenco delle colonne che contengono il patten “length”.\n\nmask = df.columns.str.contains(\"length\")\ncolumns_to_drop = df.columns[mask]\ncolumns_to_drop\n\nIndex(['bill_length_mm', 'flipper_length_mm'], dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#creare-nuove-colonne",
    "href": "chapters/python/04_pandas.html#creare-nuove-colonne",
    "title": "6  Pandas (1)",
    "section": "6.9 Creare nuove colonne",
    "text": "6.9 Creare nuove colonne\nPer ciascuna riga, calcoliamo\n\nbill_length_mm - bill_depth_mm\nbill_length_mm / (body_mass_g / 1000)\n\nPer ottenere questo risultato possiamo usare una lambda function.\n\ndf = df.assign(\n    bill_difference=lambda x: x.bill_length_mm - x.bill_depth_mm,\n    bill_ratio=lambda x: x.bill_length_mm / (x.body_mass_g / 1000),\n)\ndf.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n\n\n\n\n\n\n\nIn maniera più semplice possiamo procedere nel modo seguente:\n\ndf[\"bill_ratio2\"] = df[\"bill_length_mm\"] / (df[\"body_mass_g\"] / 1000)\ndf.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nbill_difference\nbill_ratio\nbill_ratio2\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n20.4\n10.426667\n10.426667\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n22.1\n10.394737\n10.394737\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n22.3\n12.400000\n12.400000\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n17.4\n10.637681\n10.637681\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n18.7\n10.767123\n10.767123\n\n\n\n\n\n\n\nUn’utile funzionalità è quella che consente di aggiungere una colonna ad un DataFrame (o di mofificare una colonna già esistente) sulla base di una condizione True/False. Questo risultato può essere raggiunto usando np.where(), con la seguente sintassi:\nnp.where(condition, value if condition is true, value if condition is false)\nSupponiamo di avere un DataFrame df con due colonne, A e B, e vogliamo creare una nuova colonna C che contenga il valore di A quando questo è maggiore di 0, e il valore di B altrimenti. Possiamo utilizzare la funzione where() per ottenere ciò come segue:\n\n# Creiamo un DataFrame di esempio\ndf = pd.DataFrame({\"A\": [-1, 2, 3, -4], \"B\": [5, 6, 0, 8]})\n\n# Creiamo una nuova colonna 'C' usando la funzione where()\ndf[\"C\"] = df[\"A\"].where(df[\"A\"] &gt; 0, df[\"B\"])\n\nprint(df)\n\n   A  B  C\n0 -1  5  5\n1  2  6  2\n2  3  0  3\n3 -4  8  8",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#formato-long-e-wide",
    "href": "chapters/python/04_pandas.html#formato-long-e-wide",
    "title": "6  Pandas (1)",
    "section": "6.10 Formato long e wide",
    "text": "6.10 Formato long e wide\nNella data analysis, i termini “formato long” e “formato wide” sono usati per descrivere la struttura di un set di dati. l formato wide (in inglese “wide format”) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni variabile è rappresentata da più colonne. Un esempio è il seguente, nel quale per ciascun partecipante, identificato da Name e ID abbiamo i punteggi di un ipotetico test per 6 anni consecutivi.\n\nscores = {\n    \"Name\": [\"Maria\", \"Carlo\", \"Giovanna\", \"Irene\"],\n    \"ID\": [1, 2, 3, 4],\n    \"2017\": [85, 87, 89, 91],\n    \"2018\": [96, 98, 100, 102],\n    \"2019\": [100, 102, 106, 106],\n    \"2020\": [89, 95, 98, 100],\n    \"2021\": [94, 96, 98, 100],\n    \"2022\": [100, 104, 104, 107],\n}\n\nwide_data = pd.DataFrame(scores)\nwide_data\n\n\n\n\n\n\n\n\nName\nID\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\n0\nMaria\n1\n85\n96\n100\n89\n94\n100\n\n\n1\nCarlo\n2\n87\n98\n102\n95\n96\n104\n\n\n2\nGiovanna\n3\n89\n100\n106\n98\n98\n104\n\n\n3\nIrene\n4\n91\n102\n106\n100\n100\n107\n\n\n\n\n\n\n\nIl formato long (in inglese “long format”) rappresenta una struttura di dati in cui ogni riga rappresenta una singola osservazione e ogni colonna rappresenta una singola variabile. Questo formato è quello che viene richiesto per molte analisi statistiche. In Pandas è possibile usare la funzione melt per trasformare i dati dal formato wide al formato long. Un esempio è riportato qui sotto. Sono state mantenute le due colonne che identificano ciascun partecipante, ma i dati del test, che prima erano distribuiti su sei colonne, ora sono presenti in una singola colonna. Al DataFrame, inoltre, è stata aggiunta una colonna che riporta l’anno.\n\nlong_data = wide_data.melt(id_vars=[\"Name\", \"ID\"], var_name=\"Year\", value_name=\"Score\")\nlong_data\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n1\nCarlo\n2\n2017\n87\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n3\nIrene\n4\n2017\n91\n\n\n4\nMaria\n1\n2018\n96\n\n\n5\nCarlo\n2\n2018\n98\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n7\nIrene\n4\n2018\n102\n\n\n8\nMaria\n1\n2019\n100\n\n\n9\nCarlo\n2\n2019\n102\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n11\nIrene\n4\n2019\n106\n\n\n12\nMaria\n1\n2020\n89\n\n\n13\nCarlo\n2\n2020\n95\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n15\nIrene\n4\n2020\n100\n\n\n16\nMaria\n1\n2021\n94\n\n\n17\nCarlo\n2\n2021\n96\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n19\nIrene\n4\n2021\n100\n\n\n20\nMaria\n1\n2022\n100\n\n\n21\nCarlo\n2\n2022\n104\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n23\nIrene\n4\n2022\n107\n\n\n\n\n\n\n\nPer migliorare la leggibilità dei dati, è possibile riordinare le righe del set di dati utilizzando la funzione sort_values. In questo modo, le informazioni saranno presentate in un ordine specifico, che può rendere più facile la lettura dei dati.\n\nlong_data.sort_values(by=[\"ID\", \"Year\"])\n\n\n\n\n\n\n\n\nName\nID\nYear\nScore\n\n\n\n\n0\nMaria\n1\n2017\n85\n\n\n4\nMaria\n1\n2018\n96\n\n\n8\nMaria\n1\n2019\n100\n\n\n12\nMaria\n1\n2020\n89\n\n\n16\nMaria\n1\n2021\n94\n\n\n20\nMaria\n1\n2022\n100\n\n\n1\nCarlo\n2\n2017\n87\n\n\n5\nCarlo\n2\n2018\n98\n\n\n9\nCarlo\n2\n2019\n102\n\n\n13\nCarlo\n2\n2020\n95\n\n\n17\nCarlo\n2\n2021\n96\n\n\n21\nCarlo\n2\n2022\n104\n\n\n2\nGiovanna\n3\n2017\n89\n\n\n6\nGiovanna\n3\n2018\n100\n\n\n10\nGiovanna\n3\n2019\n106\n\n\n14\nGiovanna\n3\n2020\n98\n\n\n18\nGiovanna\n3\n2021\n98\n\n\n22\nGiovanna\n3\n2022\n104\n\n\n3\nIrene\n4\n2017\n91\n\n\n7\nIrene\n4\n2018\n102\n\n\n11\nIrene\n4\n2019\n106\n\n\n15\nIrene\n4\n2020\n100\n\n\n19\nIrene\n4\n2021\n100\n\n\n23\nIrene\n4\n2022\n107",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#copia-di-un-data-frame",
    "href": "chapters/python/04_pandas.html#copia-di-un-data-frame",
    "title": "6  Pandas (1)",
    "section": "6.11 Copia di un data frame",
    "text": "6.11 Copia di un data frame\nQuando in Python definiamo un nuovo data frame basandoci su un data frame esistente con l’istruzione new_df = old_df, è importante essere consapevoli del fatto che non stiamo creando un nuovo data frame indipendente. In realtà, new_df diventa solamente un riferimento all’oggetto originale old_df nell’ambiente corrente. Questo significa che qualsiasi modifica apportata a new_df si rifletterà automaticamente anche in old_df. In pratica, abbiamo un unico oggetto data frame accessibile attraverso due nomi diversi.\nPer creare effettivamente una copia indipendente di old_df, in modo che le modifiche apportate a questa copia non influiscano sull’originale, dobbiamo utilizzare il metodo .copy(). Questo metodo crea un nuovo oggetto data frame che è una copia del data frame originale. L’istruzione corretta per fare ciò in Python è la seguente:\nnew_df = old_df.copy()\nUtilizzando old_df.copy(), otteniamo due data frame completamente indipendenti. Modifiche apportate a new_df non avranno alcun impatto su old_df, permettendoci di lavorare con i dati in modo sicuro e senza rischi di sovrascrittura o alterazione involontaria dei dati originali. Questa pratica è fondamentale per mantenere l’integrità dei dati e per gestire correttamente le variabili all’interno di un programma Python.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/04_pandas.html#informazioni-sullambiente-di-sviluppo",
    "title": "6  Pandas (1)",
    "section": "6.12 Informazioni sull’Ambiente di Sviluppo",
    "text": "6.12 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.2\npandas: 2.1.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pandas (1)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html",
    "href": "chapters/python/05_pandas_aggregate.html",
    "title": "7  Pandas (2)",
    "section": "",
    "text": "7.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport arviz as az\nimport seaborn as sns\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nsns.set_theme(palette=\"colorblind\")\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = 'retina'",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "href": "chapters/python/05_pandas_aggregate.html#calcolo-delle-statistiche-descrittive",
    "title": "7  Pandas (2)",
    "section": "7.2 Calcolo delle statistiche descrittive",
    "text": "7.2 Calcolo delle statistiche descrittive\nAgli oggetti Pandas possono essere applicati vari metodi matematici e statistici. La maggior parte di questi rientra nella categoria della riduzione di dati o delle statistiche descrittive. Rispetto ai metodi degli array NumPy, i metodi Pandas consentono la gestione dei dati mancanti. Alcuni dei metodi disponibili per gli oggetti Pandas sono elencati di seguito.\n\n\n\n\n\n\n\nMethod\nDescription\n\n\n\n\ncount\nNumber of non-NA values\n\n\ndescribe\nCompute set of summary statistics\n\n\nmin, max\nCompute minimum and maximum values\n\n\nargmin, argmax\nCompute index locations (integers) at which minimum or maximum value is obtained, respectively; not available on DataFrame objects\n\n\nidxmin, idxmax\nCompute index labels at which minimum or maximum value is obtained, respectively\n\n\nquantile\nCompute sample quantile ranging from 0 to 1 (default: 0.5)\n\n\nsum\nSum of values\n\n\nmean\nMean of values\n\n\nmedian\nArithmetic median (50% quantile) of values\n\n\nmad\nMean absolute deviation from mean value\n\n\nprod\nProduct of all values\n\n\nvar\nSample variance of values\n\n\nstd\nSample standard deviation of values\n\n\nskew\nSample skewness (third moment) of values\n\n\nkurt\nSample kurtosis (fourth moment) of values\n\n\ncumsum\nCumulative sum of values\n\n\ncummin, cummax\nCumulative minimum or maximum of values, respectively\n\n\ncumprod\nCumulative product of values\n\n\ndiff\nCompute first arithmetic difference (useful for time series)\n\n\npct_change\nCompute percent changes\n\n\n\nTali metodi possono essere applicati a tutto il DataFrame, oppure soltanto ad una o più colonne.\nPer fare un esempio, esamineremo nuovamente i dati penguins.csv. Come in precedenza, dopo avere caricato i dati, rimuoviamo i dati mancanti.\n\ndf = pd.read_csv(\"../../data/penguins.csv\")\ndf.dropna(inplace=True)\n\nUsiamo il metodo describe() su tutto il DataFrame:\n\ndf.describe(include=\"all\")\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\ncount\n333\n333\n333.000000\n333.000000\n333.000000\n333.000000\n333\n333.000000\n\n\nunique\n3\n3\nNaN\nNaN\nNaN\nNaN\n2\nNaN\n\n\ntop\nAdelie\nBiscoe\nNaN\nNaN\nNaN\nNaN\nmale\nNaN\n\n\nfreq\n146\n163\nNaN\nNaN\nNaN\nNaN\n168\nNaN\n\n\nmean\nNaN\nNaN\n43.992793\n17.164865\n200.966967\n4207.057057\nNaN\n2008.042042\n\n\nstd\nNaN\nNaN\n5.468668\n1.969235\n14.015765\n805.215802\nNaN\n0.812944\n\n\nmin\nNaN\nNaN\n32.100000\n13.100000\n172.000000\n2700.000000\nNaN\n2007.000000\n\n\n25%\nNaN\nNaN\n39.500000\n15.600000\n190.000000\n3550.000000\nNaN\n2007.000000\n\n\n50%\nNaN\nNaN\n44.500000\n17.300000\n197.000000\n4050.000000\nNaN\n2008.000000\n\n\n75%\nNaN\nNaN\n48.600000\n18.700000\n213.000000\n4775.000000\nNaN\n2009.000000\n\n\nmax\nNaN\nNaN\n59.600000\n21.500000\n231.000000\n6300.000000\nNaN\n2009.000000\n\n\n\n\n\n\n\nSe desideriamo solo le informazioni relative alle variabili qualitative, usiamo l’argomento include='object'.\n\ndf.describe(include=\"object\")\n\n\n\n\n\n\n\n\nspecies\nisland\nsex\n\n\n\n\ncount\n333\n333\n333\n\n\nunique\n3\n3\n2\n\n\ntop\nAdelie\nBiscoe\nmale\n\n\nfreq\n146\n163\n168\n\n\n\n\n\n\n\nI valori NaN indicano dati mancanti. Ad esempio, la colonna species contiene stringhe, quindi non esiste alcun valore per mean; allo stesso modo, bill_length_mm è una variabile numerica, quindi non vengono calcolate le statistiche riassuntive per le variabili categoriali (unique, top, freq).\nEsaminimiamo le colonne singolarmente. Ad esempio, troviamo la media della colonna bill_depth_mm.\n\ndf[\"bill_depth_mm\"].mean()\n\n17.164864864864867\n\n\nPer la deviazione standard usiamo il metodo std(). Si noti l’argomento opzionale ddof:\n\ndf[\"bill_length_mm\"].std(ddof=1)\n\n5.46866834264756\n\n\nLa cella seguente fornisce l’indice della riga nella quale la colonna bill_length_mm assume il suo valore massimo:\n\ndf[\"bill_length_mm\"].idxmax()\n\n185\n\n\nLa colonna species nel DataFrame df è una variabile a livello nominale. Elenchiamo le modalità di tale variabile.\n\ndf[\"species\"].unique()\n\narray(['Adelie', 'Gentoo', 'Chinstrap'], dtype=object)\n\n\nIl metodo value_counts ritorna la distribuzione di frequenza assoluta:\n\ndf[\"species\"].value_counts()\n\nspecies\nAdelie       146\nGentoo       119\nChinstrap     68\nName: count, dtype: int64\n\n\nPer le frequenze relative si imposta l’argomento normalize=True:\n\nprint(df[\"species\"].value_counts(normalize=True))\n\nspecies\nAdelie       0.438438\nGentoo       0.357357\nChinstrap    0.204204\nName: proportion, dtype: float64\n\n\nConsideriamo la lunghezza del becco dei pinguini suddivisa per ciascuna specie. Con l’istruzione seguente, possiamo generare gli istogrammi corrispondenti che rappresentano la distribuzione della lunghezza del becco in ciascun gruppo.\n\ncolor_fill = \"#b97c7c\"\n_ = df.hist(\n    column=\"bill_length_mm\",\n    by=[\"species\"],\n    bins=20,\n    figsize=(12, 4),\n    layout=(1, 3),\n    rwidth=0.9,\n    color=color_fill\n)\n\n\n\n\n\n\n\n\n\ndf\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n333 rows × 8 columns\n\n\n\n\n7.2.1 Aggregazione dei dati\nIl riepilogo di più valori in un unico indice va sotto il nome di “aggregazione” dei dati. Il metodo aggregate() può essere applicato ai DataFrame e restituisce un nuovo DataFrame più breve contenente solo i valori aggregati. Il primo argomento di aggregate() specifica quale funzione o quali funzioni devono essere utilizzate per aggregare i dati. Molte comuni funzioni di aggregazione sono disponibili nel modulo statistics. Ad esempio:\n\nmedian(): la mediana;\nmean(): la media;\nstdev(): la deviazione standard;\n\nSe vogliamo applicare più funzioni di aggregazione, allora possiamo raccogliere prima le funzioni in una lista e poi passare la lista ad aggregate().\n\n# Lista delle funzioni statistiche di riepilogo come stringhe\nsummary_stats = [\"min\", \"median\", \"mean\", \"std\", \"max\"]\n\n# Calcola le statistiche di riepilogo per le colonne numeriche usando aggregate\nresult = df[\n    [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n].aggregate(summary_stats)\n\nprint(result)\n\n        bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\nmin          32.100000      13.100000         172.000000  2700.000000\nmedian       44.500000      17.300000         197.000000  4050.000000\nmean         43.992793      17.164865         200.966967  4207.057057\nstd           5.468668       1.969235          14.015765   805.215802\nmax          59.600000      21.500000         231.000000  6300.000000\n\n\nSi noti che Pandas ha applicato le funzioni di riepilogo a ogni colonna, ma, per alcune colonne, le statistiche riassuntive non si possono calcolare, ovvero tutte le colonne che contengono stringhe anziché numeri. Di conseguenza, vediamo che alcuni dei risultati per tali colonne sono contrassegnati con “NaN”. Questa è un’abbreviazione di “Not a Number”, talvolta utilizzata nell’analisi dei dati per rappresentare valori mancanti o non definiti.\nMolto spesso vogliamo calcolare le statistiche descrittive separatamente per ciascun gruppo di osservazioni – per esempio, nel caso presente, potremmo volere distinguere le statistiche descrittive in base alla specie dei pinguini. Questo risultato si ottiene con il metodo .groupby().\nIl nome “group by” deriva da un comando nel linguaggio del database SQL, ma forse è più semplice pensarlo nei termini coniati da Hadley Wickham: split, apply, combine. Un esempio canonico di questa operazione di split-apply-combine, in cui “apply” è un’aggregazione di sommatoria, è illustrato nella figura seguente:\n\n\n\n\n\n\nFigura 7.1: Split, apply, combine.\n\n\n\nLa figura rende chiaro ciò che si ottiene con groupby:\n\nla fase “split” prevede la suddivisione e il raggruppamento di un DataFrame in base al valore della chiave specificata;\nla fase “apply” implica il calcolo di alcune funzioni, solitamente un’aggregazione, una trasformazione o un filtro, all’interno dei singoli gruppi;\nla fase “combine” unisce i risultati di queste operazioni in una matrice di output.\n\nPer esempio, ragruppiamo le osservazioni body_mass_g in funzione delle modalità della variabile species.\n\ngrouped = df[\"body_mass_g\"].groupby(df[\"species\"])\n\nCalcoliamo ora la media della variabile body_mass_g separatamente per ciascun gruppo di osservazioni.\n\ngrouped.mean()\n\nspecies\nAdelie       3706.164384\nChinstrap    3733.088235\nGentoo       5092.436975\nName: body_mass_g, dtype: float64\n\n\nÈ possibile applicare criteri di classificazione multipli. Per fare un altro esempio, contiamo il numero di pinguini presenti sulle tre isole, distinguendoli per specie e genere.\n\ndf.groupby([\"island\", \"species\", \"sex\"]).size()\n\nisland     species    sex   \nBiscoe     Adelie     female    22\n                      male      22\n           Gentoo     female    58\n                      male      61\nDream      Adelie     female    27\n                      male      28\n           Chinstrap  female    34\n                      male      34\nTorgersen  Adelie     female    24\n                      male      23\ndtype: int64\n\n\nCon il metodo aggregate() possiamo applicare diverse funzioni di aggregazione alle osservazioni ragruppate. Ad esempio\n\nsummary_stats = [np.mean, np.std]\n# Group by \"species\" and calculate summary statistics for numeric columns\nresult = df.groupby(\"species\").agg(\n    {col: summary_stats for col in df.columns if pd.api.types.is_numeric_dtype(df[col])}\n)\n\nprint(result)\n\n          bill_length_mm           bill_depth_mm           flipper_length_mm  \\\n                    mean       std          mean       std              mean   \nspecies                                                                        \nAdelie         38.823973  2.662597     18.347260  1.219338        190.102740   \nChinstrap      48.833824  3.339256     18.420588  1.135395        195.823529   \nGentoo         47.568067  3.106116     14.996639  0.985998        217.235294   \n\n                     body_mass_g                     year            \n                std         mean         std         mean       std  \nspecies                                                              \nAdelie     6.521825  3706.164384  458.620135  2008.054795  0.811816  \nChinstrap  7.131894  3733.088235  384.335081  2007.970588  0.863360  \nGentoo     6.585431  5092.436975  501.476154  2008.067227  0.789025  \n\n\nNella cella seguente troviamo la media di body_mass_g e flipper_length_mm separatamente per ciascuna isola e ciascuna specie:\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].mean()\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n188.795455\n\n\nGentoo\n5092.436975\n217.235294\n\n\nDream\nAdelie\n3701.363636\n189.927273\n\n\nChinstrap\n3733.088235\n195.823529\n\n\nTorgersen\nAdelie\n3708.510638\n191.531915\n\n\n\n\n\n\n\nFacciamo la stessa cosa per la deviazione standard.\n\ndf.groupby([\"island\", \"species\"])[[\"body_mass_g\", \"flipper_length_mm\"]].std(ddof=1)\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\nisland\nspecies\n\n\n\n\n\n\nBiscoe\nAdelie\n487.733722\n6.729247\n\n\nGentoo\n501.476154\n6.585431\n\n\nDream\nAdelie\n448.774519\n6.480325\n\n\nChinstrap\n384.335081\n7.131894\n\n\nTorgersen\nAdelie\n451.846351\n6.220062\n\n\n\n\n\n\n\nPrestiamo attenzione alla seguente sintassi:\n\nsummary_stats = (\n    df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]\n    .groupby([\"island\", \"species\"])\n    .aggregate([\"mean\", \"std\", \"count\"])\n)\nsummary_stats\n\n\n\n\n\n\n\n\n\nbody_mass_g\nflipper_length_mm\n\n\n\n\nmean\nstd\ncount\nmean\nstd\ncount\n\n\nisland\nspecies\n\n\n\n\n\n\n\n\n\n\nBiscoe\nAdelie\n3709.659091\n487.733722\n44\n188.795455\n6.729247\n44\n\n\nGentoo\n5092.436975\n501.476154\n119\n217.235294\n6.585431\n119\n\n\nDream\nAdelie\n3701.363636\n448.774519\n55\n189.927273\n6.480325\n55\n\n\nChinstrap\n3733.088235\n384.335081\n68\n195.823529\n7.131894\n68\n\n\nTorgersen\nAdelie\n3708.510638\n451.846351\n47\n191.531915\n6.220062\n47\n\n\n\n\n\n\n\nNell’istruzione precedente selezioniamo tutte le righe (:) di tre colonne di interesse: df.loc[:, [\"island\", \"species\", \"body_mass_g\", \"flipper_length_mm\"]]. L’istruzione .groupby([\"island\", \"species\"]) ragruppa le osservazioni (righe) secondo le modalità delle variabili island e species. Infine .aggregate([\"mean\", \"std\", \"count\"]) applica i metodi statistici specificati a ciascun gruppo di osservazioni. Con questa sintassi la sequenza delle operazioni da eseguire diventa molto intuitiva.\nÈ possibile approfondire questo argomento consultanto il capitolo 10 del testo Python for Data Analysis di McKinney (2022).",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/05_pandas_aggregate.html#informazioni-sullambiente-di-sviluppo",
    "title": "7  Pandas (2)",
    "section": "7.3 Informazioni sull’Ambiente di Sviluppo",
    "text": "7.3 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.11.4\nseaborn   : 0.13.0\nnumpy     : 1.26.2\npandas    : 2.1.4\narviz     : 0.17.0\nmatplotlib: 3.8.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcKinney, W. (2022). Python for Data Analysis. \" O’Reilly Media, Inc.\".",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pandas (2)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html",
    "href": "chapters/python/06_pandas_functions.html",
    "title": "8  Pandas (3)",
    "section": "",
    "text": "8.1 pd.read_csv, pd.read_excel\nLa prima funzione da menzionare è read_csv o read_excel. Le funzioni vengono utilizzate per leggere un file CSV o un file Excel in formato DataFrame di Pandas. Qui stiamo utilizzando la funzione read_csv per leggere il dataset penguins. In precedenza abbiamo anche visto come la funzione dropna viene utilizzata per rimuovere tutte le righe del DataFrame che includono dati mancanti.\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\ndf.tail()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#columns",
    "href": "chapters/python/06_pandas_functions.html#columns",
    "title": "8  Pandas (3)",
    "section": "8.2 .columns",
    "text": "8.2 .columns\nQuando si dispone di un grande dataset, può essere difficile visualizzare tutte le colonne. Utilizzando la funzione columns, è possibile stampare tutte le colonne del dataset.\n\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex', 'year'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#drop",
    "href": "chapters/python/06_pandas_functions.html#drop",
    "title": "8  Pandas (3)",
    "section": "8.3 .drop()",
    "text": "8.3 .drop()\nÈ possibile eliminare alcune colonne non necessarie utilizzando drop.\n\ndf = df.drop(columns=[\"year\"])\ndf.columns\n\nIndex(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n       'flipper_length_mm', 'body_mass_g', 'sex'],\n      dtype='object')",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#len",
    "href": "chapters/python/06_pandas_functions.html#len",
    "title": "8  Pandas (3)",
    "section": "8.4 len()",
    "text": "8.4 len()\nFornisce il numero di righe di un DataFrame.\n\nlen(df)\n\n333",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#query",
    "href": "chapters/python/06_pandas_functions.html#query",
    "title": "8  Pandas (3)",
    "section": "8.5 .query()",
    "text": "8.5 .query()\nÈ possibile filtrare un DataFrame utilizzando un’espressione booleana.\n\ndf1 = df.query(\"species == 'Chinstrap' & island == 'Dream'\")\nlen(df1)\n\n68",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#iloc",
    "href": "chapters/python/06_pandas_functions.html#iloc",
    "title": "8  Pandas (3)",
    "section": "8.6 .iloc[]",
    "text": "8.6 .iloc[]\nQuesta funzione accetta come parametri gli indici delle righe e delle colonne, fornendo una selezione del DataFrame in base a questi. In questo caso, stiamo selezionando le prime 3 righe di dati e le colonne con indice 2, 3 e 5.\n\ndf2 = df.iloc[:3, [2, 3, 5]]\ndf2\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nbody_mass_g\n\n\n\n\n0\n39.1\n18.7\n3750.0\n\n\n1\n39.5\n17.4\n3800.0\n\n\n2\n40.3\n18.0\n3250.0",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#loc",
    "href": "chapters/python/06_pandas_functions.html#loc",
    "title": "8  Pandas (3)",
    "section": "8.7 .loc[]",
    "text": "8.7 .loc[]\nQuesta funzione compie un’operazione molto simile a quella della funzione .iloc. Tuttavia, in questo caso, abbiamo la possibilità di specificare gli indici delle righe che desideriamo, insieme ai nomi delle colonne che vogliamo includere nella nostra selezione.\n\ndf3 = df.loc[[2, 4, 6], [\"island\", \"flipper_length_mm\", \"sex\"]]\ndf3\n\n\n\n\n\n\n\n\nisland\nflipper_length_mm\nsex\n\n\n\n\n2\nTorgersen\n195.0\nfemale\n\n\n4\nTorgersen\n193.0\nfemale\n\n\n6\nTorgersen\n181.0\nfemale",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/06_pandas_functions.html#informazioni-sullambiente-di-sviluppo",
    "title": "8  Pandas (3)",
    "section": "8.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "8.8 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jan 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.0\nnumpy     : 1.26.2\narviz     : 0.17.0\npandas    : 2.1.4\nmatplotlib: 3.8.2\nscipy     : 1.11.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas (3)</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html",
    "href": "chapters/python/07_matplotlib.html",
    "title": "9  Matplotlib",
    "section": "",
    "text": "9.1 Preparazione del Notebook\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\n# Questa istruzione consente di visualizzare i grafici generati dai comandi di \n# plot direttamente all'interno del notebook.\n%config InlineBackend.figure_format = 'retina'\n\n# Questo valore viene usato come seed per il random number generator.\nRANDOM_SEED = 42\n\n# In questa riga, stai utilizzando il generatore di numeri casuali di NumPy per \n# creare una nuova istanza denominata rng. La funzione np.random.default_rng() viene \n# utilizzata per inizializzare un generatore di numeri casuali con un seme specifico, \n# che in questo caso è RANDOM_SEED.\nrng = np.random.default_rng(RANDOM_SEED)\n\n# Queste due righe di codice sono spesso utilizzate per personalizzare l'aspetto dei \n# grafici in Python utilizzando le librerie ArviZ e Seaborn.\n# Questa riga di codice utilizza il metodo use() della libreria ArviZ per impostare uno \n# stile specifico per i tuoi grafici. In particolare, sta impostando lo stile chiamato \n# \"arviz-darkgrid\". Gli stili in ArviZ determinano come saranno visualizzati i grafici, inclusi colori, linee di griglia e altri dettagli estetici.\naz.style.use(\"arviz-darkgrid\")\n\n# Questa riga di codice utilizza la libreria Seaborn per impostare il tema dei grafici. \n# In questo caso, il tema viene impostato utilizzando set_theme() con il parametro palette \n# impostato su \"colorblind\". Questo significa che i colori utilizzati nei grafici saranno \n# scelti in modo da essere adatti alle persone con deficit visivi dei colori, rendendo i \n# grafici più accessibili.\nsns.set_theme(palette=\"colorblind\")",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "href": "chapters/python/07_matplotlib.html#linterfaccia-pyplot-per-creare-grafici",
    "title": "9  Matplotlib",
    "section": "9.2 L’Interfaccia pyplot per Creare Grafici",
    "text": "9.2 L’Interfaccia pyplot per Creare Grafici\nMatplotlib è una libreria in Python famosa per la creazione di grafici, e la sua interfaccia pyplot è particolarmente apprezzata per la sua semplicità. Vediamo in dettaglio come funzionano le sue funzioni principali. Per comprendere meglio come funzionano le sue funzioni principali, possiamo fare un parallelo con il disegno su un supporto fisico.\n\nPrepariamo la Tela: Iniziamo con plt.figure(), che è analogo a ottenere una tela bianca pronta per essere dipinta. È il punto di partenza, una superficie vuota su cui creeremo il nostro grafico.\nDefiniamo le Aree di Disegno: Successivamente, utilizzando plt.subplot() o plt.axes(), creiamo delle aree specifiche o “assi” sulla nostra tela. Questi assi corrispondono a diverse sezioni in cui posizioneremo vari elementi del nostro grafico, come se suddividessimo la tela fisica in diverse parti.\nAggiungiamo Elementi al Grafico: Una volta definiti gli assi, entriamo nel processo di creazione. Usandando funzioni come plt.plot() per tracciare linee o plt.scatter() per punti, aggiungiamo elementi grafici alla nostra area di disegno. È simile a disegnare direttamente sulla tela fisica.\nRendiamo il Grafico Comprensibile: Per garantire che il grafico sia chiaro e informativo, aggiungiamo etichette e titoli con plt.xlabel(), plt.ylabel() e plt.title().",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "href": "chapters/python/07_matplotlib.html#principi-fondamentali-di-pyplot",
    "title": "9  Matplotlib",
    "section": "9.3 Principi Fondamentali di Pyplot",
    "text": "9.3 Principi Fondamentali di Pyplot\nEsploriamo le funzionalità essenziali di pyplot di Matplotlib:\n\nCreazione di Grafici Lineari: Utilizzando plt.plot(x, y), è possibile generare grafici lineari. Questa funzione necessita delle coordinate x e y per disegnare il grafico, semplificando così la rappresentazione visiva dei dati.\nDenominazione degli Assi: È fondamentale assegnare un’etichetta appropriata agli assi per migliorare la comprensione del grafico. Si possono denominare gli assi tramite plt.xlabel('Nome') per l’asse X e plt.ylabel('Nome') per l’asse Y, facilitando l’interpretazione dei dati visualizzati.\nInserimento del Titolo: Un titolo descrittivo clarifica lo scopo o il contesto del grafico. Aggiungere un titolo è semplice con plt.title('Titolo'), che aiuta a comunicare il messaggio principale del grafico in modo efficace.\nInserimento di Legende: Per grafici che includono più serie di dati o elementi distinti, l’aggiunta di una legenda è cruciale per la distinzione tra questi. La funzione plt.legend() permette di integrare una legenda, migliorando la leggibilità del grafico.\nEsposizione del Grafico: Una volta completata la composizione del grafico, il passo finale è la sua visualizzazione. Attraverso plt.show(), è possibile mostrare il grafico elaborato, offrendo una visione complessiva dei dati analizzati.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "href": "chapters/python/07_matplotlib.html#esempio-1-grafico-lineare-semplice",
    "title": "9  Matplotlib",
    "section": "9.4 Esempio 1: Grafico lineare semplice",
    "text": "9.4 Esempio 1: Grafico lineare semplice\n\nx = [1, 2, 3, 4]\ny = [10, 20, 30, 40]\n\nplt.plot(x, y)\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico Lineare Semplice\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "href": "chapters/python/07_matplotlib.html#esempio-2-grafico-con-legenda-e-stile",
    "title": "9  Matplotlib",
    "section": "9.5 Esempio 2: Grafico con legenda e stile",
    "text": "9.5 Esempio 2: Grafico con legenda e stile\n\nx = [1, 2, 3, 4]\ny1 = [10, 20, 30, 40]\ny2 = [5, 15, 25, 35]\n\nplt.plot(x, y1, label=\"Linea 1\", color=\"C0\", linestyle=\"--\")\nplt.plot(x, y2, label=\"Linea 2\", color=\"C3\", linestyle=\"-\")\nplt.xlabel(\"Asse X\")\nplt.ylabel(\"Asse Y\")\nplt.title(\"Grafico con Legenda\")\nplt.legend();",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-3-istogramma",
    "href": "chapters/python/07_matplotlib.html#esempio-3-istogramma",
    "title": "9  Matplotlib",
    "section": "9.6 Esempio 3: Istogramma",
    "text": "9.6 Esempio 3: Istogramma\n\ndata = rng.normal(100, 15, 1000)\n\nplt.hist(data, bins=20)\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Istogramma\");",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#esempio-4-pannelli-multipli",
    "href": "chapters/python/07_matplotlib.html#esempio-4-pannelli-multipli",
    "title": "9  Matplotlib",
    "section": "9.7 Esempio 4: pannelli multipli",
    "text": "9.7 Esempio 4: pannelli multipli\nFacciamo un altro esempio usando i dati penguins.csv.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\ndf.dropna(inplace=True)\n\n\nplt.figure(figsize=(9, 8))\n\nplt.subplot(2, 2, 1)\nplt.hist(df[\"bill_depth_mm\"], 10, density=True, color=\"C3\")\nplt.title(\"Bill depth (mm)\");\n\nplt.subplot(2, 2, 2)\nsns.kdeplot(df[\"bill_length_mm\"], fill=True)\nplt.title(\"KDE of Bill length (mm)\");\n\nplt.subplot(2, 2, 3)\nplt.scatter(x=df[\"bill_length_mm\"], y=df[\"bill_depth_mm\"], alpha=0.4)\nplt.title(\"Bill depth as a function of bill length\");\n\nplt.subplot(2, 2, 4)\nplt.boxplot(df[\"bill_length_mm\"])\nplt.title(\"Boxplot of Bill Length (mm)\")\n\nplt.tight_layout()\n\n/var/folders/cl/wwjrsxdd5tz7y9jr82nd5hrw0000gn/T/ipykernel_55046/1324325854.py:19: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nGli indici in plt.subplot() sono utilizzati per specificare come dividere una figura in diverse aree di tracciamento, chiamate “subplots”. La funzione plt.subplot(nrows, ncols, index) prende tre argomenti principali:\n\nnrows: Numero di righe in cui la figura sarà suddivisa.\nncols: Numero di colonne in cui la figura sarà suddivisa.\nindex: Indice del subplot su cui operare, partendo dall’angolo in alto a sinistra e proseguendo da sinistra a destra e dall’alto in basso.\n\nNel codice precedente, plt.subplot(2, 2, 1) indica che la figura sarà divisa in una griglia 2x2 (2 righe e 2 colonne) e che la funzione plt.hist() agirà sul primo subplot, che si troverà nell’angolo in alto a sinistra.\nGli altri indici (2, 3, 4) selezionano rispettivamente il secondo subplot (in alto a destra), il terzo subplot (in basso a sinistra) e il quarto subplot (in basso a destra) della griglia 2x2.\nEcco come i subplot sono organizzati sulla figura:\n+---------------------+----------------------+\n|  plt.subplot(2,2,1) |  plt.subplot(2,2,2)  |\n+---------------------+----------------------+\n|  plt.subplot(2,2,3) |  plt.subplot(2,2,4)  |\n+---------------------+----------------------+\nOgni volta che si chiama plt.subplot() con un nuovo indice, il “current axes” cambia per puntare al subplot specificato. Quindi, le funzioni di tracciamento come plt.hist(), sns.kdeplot(), plt.scatter() e plt.boxplot() saranno applicate al subplot attualmente selezionato.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/07_matplotlib.html#informazioni-sullambiente-di-sviluppo",
    "title": "9  Matplotlib",
    "section": "9.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "9.8 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Feb 03 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.19.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.2\narviz     : 0.17.0\nmatplotlib: 3.8.2\npandas    : 2.1.4\nseaborn   : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html",
    "href": "chapters/python/08_seaborn.html",
    "title": "10  Seaborn",
    "section": "",
    "text": "10.1 Elevare la Visualizzazione dei Dati con Seaborn\nNel capitolo precedente, abbiamo esaminato Matplotlib, una libreria estremamente versatile per la visualizzazione dei dati in Python. Ora esamineremo le funzionalità di Seabonrn. Seaborn, che si basa su Matplotlib, arricchisce l’esperienza di visualizzazione dei dati offrendo una gamma più ampia e specializzata di opzioni grafiche, particolarmente utili nel campo della data science.\nIl vero punto di forza di Seaborn è la sua capacità di migliorare non solo l’aspetto estetico dei grafici ma anche di facilitare la creazione di visualizzazioni più complesse. Questo rende il processo più diretto e intuitivo. La libreria è dotata di un’ampia varietà di strumenti, dalle mappe di calore ai grafici a violino, permettendo agli utenti di esplorare e rappresentare i dati in modi innovativi e informativi.\nPer chi vuole approfondire ulteriormente, i tutorial presenti sul sito ufficiale di Seaborn sono una risorsa preziosa e facilmente accessibile.",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#preparazione-del-notebook",
    "href": "chapters/python/08_seaborn.html#preparazione-del-notebook",
    "title": "10  Seaborn",
    "section": "10.2 Preparazione del Notebook",
    "text": "10.2 Preparazione del Notebook\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport arviz as az\n\n\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"seaborn\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "href": "chapters/python/08_seaborn.html#visualizzare-la-distribuzione-dei-dati",
    "title": "10  Seaborn",
    "section": "10.3 Visualizzare la distribuzione dei dati",
    "text": "10.3 Visualizzare la distribuzione dei dati\nVediamo alcuni esempi pratici per scoprire come Seaborn possa trasformare il modo in cui visualizziamo i dati.\nConsideriamo nuovamente i dati Palmer penguin.\n\ndf = pd.read_csv(\"../data/penguins.csv\")\n\nUna delle forme di visualizzazione più comuni e informative nel campo dell’analisi dei dati è l’istogramma, e la sua variante più sofisticata, l’istogramma lisciato. Vediamo dunque come generare istogrammi che, per il DataFrame df, sono stratificati sia in base alla specie che al genere dei pinguini.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n);\n\nGeneriamo la stessa figura usando questa volta gli istogrammi lisciati.\n\nsns.displot(\n    df, x=\"flipper_length_mm\", col=\"species\", row=\"sex\",\n    height=3, kind=\"kde\", facet_kws=dict(margin_titles=True),\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "href": "chapters/python/08_seaborn.html#visualizzazione-di-dati-categoriali",
    "title": "10  Seaborn",
    "section": "10.4 Visualizzazione di dati categoriali",
    "text": "10.4 Visualizzazione di dati categoriali\nConsideriamo ora il caso in cui si vuole rappresentare la relazione tra una variabile numerica e una o più variabili categoriali.\nConsideriamo, ad esempio, la massa corporea in relazione alla specie, differenziando le osservazioni per genere. Creiamo il grafico utilizzando i boxplot.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"box\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\n\n\n\n\nDai diagrammi risulta evidente che i pinguini maschi hanno un peso maggiore rispetto alle femmine in tutte le specie, e che i pinguini Gentoo hanno un peso superiore rispetto ad Adelie e Chinstrap.\nCome alternativa, possiamo utilizzare il violinplot per la rappresentazione grafica dei dati.\n\nsns.catplot(df, x=\"species\", y=\"body_mass_g\", hue=\"sex\", kind=\"violin\")\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#relazioni-tra-variabili",
    "href": "chapters/python/08_seaborn.html#relazioni-tra-variabili",
    "title": "10  Seaborn",
    "section": "10.5 Relazioni tra variabili",
    "text": "10.5 Relazioni tra variabili\nCalcoliamo la correlazione tra le variabili.\n\nvars = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\ncorr_matrix = df[vars].corr().round(2)\ncorr_matrix\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\nbill_length_mm\n1.00\n-0.24\n0.66\n0.60\n\n\nbill_depth_mm\n-0.24\n1.00\n-0.58\n-0.47\n\n\nflipper_length_mm\n0.66\n-0.58\n1.00\n0.87\n\n\nbody_mass_g\n0.60\n-0.47\n0.87\n1.00\n\n\n\n\n\n\n\nQueste informazioni possono essere comunicate in forma più diretta se usiamo una rappresentazione grafica.\n\nsns.heatmap(corr_matrix, annot=True, linecolor=\"white\", linewidths=5);\n\n\n\n\n\n\n\n\nLa lunghezza della pinna e la massa corporea mostrano un forte legame, con una correlazione di 0.87. Ciò indica che i pinguini con pinne più lunghe tendono a pesare di più.\nDi seguito è riportato un esempio di diagramma a dispersione che illustra questa relazione.\n\nsns.scatterplot(df, x=\"bill_length_mm\", y=\"bill_depth_mm\", hue=\"species\");\n\n\n\n\n\n\n\n\nEvidentemente, le osservazioni delle tre specie formano cluster distinti. Per ciascuna specie, la lunghezza e la larghezza del becco presentano un intervallo specifico.\nSpesso è vantaggioso creare grafici separati in base a diverse dimensioni dei dati; nell’esempio seguente, suddividiamo i dati in base all’isola di appartenenza.\n\ng = sns.relplot(\n    data=df,\n    x=\"bill_length_mm\",\n    y=\"bill_depth_mm\",\n    hue=\"species\",\n    row=\"sex\",\n    col=\"island\",\n    height=3,\n    facet_kws=dict(margin_titles=True),\n)\ng.set_axis_labels(\n    \"Bill length (mm)\",\n    \"Bill depth (mm)\",\n);\n\n/opt/anaconda3/envs/pymc_env/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/python/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/python/08_seaborn.html#informazioni-sullambiente-di-sviluppo",
    "title": "10  Seaborn",
    "section": "10.6 Informazioni sull’Ambiente di Sviluppo",
    "text": "10.6 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 08 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\narviz     : 0.18.0\npandas    : 2.2.2\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Python",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Seaborn</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/introduction_key_notions.html",
    "href": "chapters/key_notions/introduction_key_notions.html",
    "title": "Introduzione",
    "section": "",
    "text": "La data science è un campo che si sviluppa all’intersezione tra la statistica e l’informatica. La statistica fornisce una serie di metodologie per analizzare i dati e ottenere informazioni significative, mentre l’informatica si occupa dello sviluppo di software e strumenti per implementare tali metodologie. In questa sezione della dispensa, approfondiremo alcuni concetti fondamentali della statistica e della misurazione psicologica. Considereremo anche in termini generali quali sono gli obiettivi e i limiti dell’analisi dei dati psicologici.",
    "crumbs": [
      "Fondamenti",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html",
    "href": "chapters/key_notions/00_uncertainty.html",
    "title": "11  Abbracciare l’incertezza",
    "section": "",
    "text": "11.1 Introduzione\nL’espressione “abbracciare l’incertezza” è tra le più emblematiche nel panorama della statistica bayesiana. In questo capitolo, approfondiremo il significato di questa affermazione, seguendo la trattazione introduttiva proposta nel primo capitolo di Understanding Uncertainty di Lindley (Lindley, 2013).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "href": "chapters/key_notions/00_uncertainty.html#lincertezza-nella-ricerca-psicologica",
    "title": "11  Abbracciare l’incertezza",
    "section": "11.2 L’incertezza nella ricerca psicologica",
    "text": "11.2 L’incertezza nella ricerca psicologica\nL’incertezza rappresenta un elemento cruciale non solo nella statistica, ma in tutte le discipline scientifiche, con particolare rilievo per la psicologia, che affronta fenomeni complessi e difficili da misurare. Nell’indagare processi cognitivi, emozioni e comportamenti, i ricercatori si confrontano con dati complessi, spesso ambigui e suscettibili di interpretazioni molteplici. Sebbene alcune affermazioni possano essere sostenute con elevata confidenza o confutate con certezza, la maggior parte delle ipotesi scientifiche si colloca in una zona grigia dominata dall’incertezza.\nL’obiettivo di questo insegnamento è guidare gli studenti nella comprensione e nella gestione dell’incertezza nella ricerca psicologica, adottando l’approccio bayesiano all’analisi dei dati. Questo metodo, basato sulla quantificazione e sull’aggiornamento delle credenze alla luce di nuove evidenze, fornirà agli studenti gli strumenti per affrontare l’incertezza in modo rigoroso e sistematico, sia nella carriera accademica sia nella pratica clinica.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#la-natura-soggettiva-dellincertezza",
    "title": "11  Abbracciare l’incertezza",
    "section": "11.3 La natura soggettiva dell’incertezza",
    "text": "11.3 La natura soggettiva dell’incertezza\nUn elemento cruciale dell’incertezza, spesso trascurato, è la sua dimensione soggettiva. De Finetti (Finetti, 1970) ha evidenziato come l’incertezza sia, almeno in parte, una questione personale: ciò che è incerto per uno psicologo può non esserlo per un altro, in funzione delle loro esperienze, conoscenze pregresse e interpretazioni dei dati disponibili. Anche di fronte a una stessa questione, due ricercatori possono condividere un’incertezza comune, ma con gradi di intensità diversi.\nQuesta componente soggettiva è particolarmente significativa in psicologia, dove le differenze individuali e culturali influenzano la percezione e l’interpretazione dei fenomeni. L’approccio bayesiano offre un potente strumento per affrontare questa soggettività, consentendo di quantificare le differenze tra credenze individuali e di aggiornarle in modo coerente sulla base di nuove evidenze oggettive.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#lonnipresenza-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#lonnipresenza-dellincertezza",
    "title": "11  Abbracciare l’incertezza",
    "section": "11.4 L’onnipresenza dell’incertezza",
    "text": "11.4 L’onnipresenza dell’incertezza\nL’incertezza pervade ogni aspetto della ricerca psicologica. Ogni esperimento, misurazione o interpretazione dei dati comporta un margine di incertezza. Questa condizione è particolarmente evidente nello studio di fenomeni complessi come il comportamento umano o i processi mentali, dove innumerevoli variabili interagiscono, molte delle quali difficili da misurare o controllare con precisione.\nTuttavia, l’incertezza non deve essere vista come un ostacolo insormontabile. Al contrario, riconoscerla e quantificarla può favorire una comprensione più profonda e realistica dei fenomeni psicologici. Attraverso l’approccio bayesiano, diventa possibile integrare l’incertezza nel processo di indagine scientifica, trattandola non come un limite, ma come una risorsa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#superare-la-soppressione-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#superare-la-soppressione-dellincertezza",
    "title": "11  Abbracciare l’incertezza",
    "section": "11.5 Superare la soppressione dell’incertezza",
    "text": "11.5 Superare la soppressione dell’incertezza\nNonostante la sua onnipresenza, l’incertezza è spesso ignorata o minimizzata nella comunicazione scientifica. Questo può avvenire attraverso interpretazioni eccessivamente ottimistiche dei risultati, la presentazione di conclusioni come fatti certi, o una riluttanza a riconoscere i limiti degli studi condotti. Tale atteggiamento, sebbene comprensibile, può condurre a conclusioni errate e a una visione distorta della realtà.\nL’approccio bayesiano permette di affrontare l’incertezza in modo esplicito e costruttivo. Fornendo un quadro rigoroso per quantificarla, analizzarla e comunicarla chiaramente, migliora la trasparenza della ricerca e promuove conclusioni più oneste e accurate.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#i-benefici-dellincertezza",
    "href": "chapters/key_notions/00_uncertainty.html#i-benefici-dellincertezza",
    "title": "11  Abbracciare l’incertezza",
    "section": "11.6 I benefici dell’incertezza",
    "text": "11.6 I benefici dell’incertezza\nContrariamente a quanto si possa pensare, l’incertezza offre numerosi vantaggi per la ricerca psicologica:\n\nStimola l’esplorazione scientifica: La consapevolezza dell’incertezza incoraggia i ricercatori a formulare nuove ipotesi e a migliorare i metodi di studio.\nPromuove l’onestà intellettuale: Accettare l’incertezza rende i ricercatori più cauti e aperti a prospettive alternative.\nMigliora la qualità delle analisi: Integrare l’incertezza porta a disegni sperimentali più robusti e interpretazioni più accurate.\nFacilita la collaborazione interdisciplinare: Riconoscere i limiti delle proprie conoscenze stimola la ricerca di input da altri esperti.\nRiflette la complessità dei fenomeni psicologici: L’incertezza è intrinseca ai processi mentali e riconoscerla consente di rappresentarli in modo più realistico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#tipi-di-incertezza",
    "href": "chapters/key_notions/00_uncertainty.html#tipi-di-incertezza",
    "title": "11  Abbracciare l’incertezza",
    "section": "11.7 Tipi di incertezza",
    "text": "11.7 Tipi di incertezza\nL’incertezza nella ricerca può essere classificata in tre categorie principali, in base alla sua origine: aleatoria, epistemica e ontologica (Gansch & Adee, 2020).\n\n11.7.1 Incertezza Aleatoria\nL’incertezza aleatoria è intrinseca alla natura casuale di un processo e non può essere eliminata per un dato modello probabilistico. Essa è considerata irreducibile e viene quantificata tramite distribuzioni probabilistiche. Ad esempio, nella misurazione della risposta di un individuo a uno stimolo, la variabilità intrinseca nel comportamento umano, dovuta a fattori imprevedibili, rappresenta un caso di incertezza aleatoria. Questo tipo di incertezza è una caratteristica fondamentale di molti fenomeni psicologici e biologici.\n\n\n11.7.2 Incertezza Epistemica\nL’incertezza epistemica deriva dalla conoscenza limitata o incompleta di un fenomeno. Essa rappresenta il “noto-ignoto”, cioè ciò che sappiamo di non sapere, ed è legata alle semplificazioni insite in ogni modello scientifico. Ad esempio, un modello psicologico che non consideri le influenze culturali o ambientali potrebbe risultare incompleto, introducendo incertezza epistemica. Diversamente dall’incertezza aleatoria, l’incertezza epistemica può essere ridotta attraverso il miglioramento dei modelli, l’inclusione di variabili rilevanti o la raccolta di ulteriori dati.\n\n\n11.7.3 Incertezza Ontologica\nL’incertezza ontologica riguarda l’“ignoto-ignoto”, ovvero aspetti di un sistema che non sono ancora stati identificati. In psicologia, questo potrebbe riferirsi a variabili o processi non ancora scoperti che influenzano un comportamento. Ad esempio, studiando i disturbi mentali, potrebbero emergere nuovi fattori di rischio precedentemente sconosciuti.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "href": "chapters/key_notions/00_uncertainty.html#il-calcolo-dellincertezza-nellapproccio-bayesiano",
    "title": "11  Abbracciare l’incertezza",
    "section": "11.8 Il calcolo dell’incertezza nell’approccio bayesiano",
    "text": "11.8 Il calcolo dell’incertezza nell’approccio bayesiano\nL’insegnamento si propone di fornire agli studenti strumenti per affrontare e quantificare l’incertezza attraverso l’approccio bayesiano (Gelman et al., 1995). Fondato sul teorema di Bayes, questo metodo rappresenta un quadro teorico rigoroso e sistematico per aggiornare le credenze alla luce di nuove evidenze, configurandosi come una componente centrale della metodologia scientifica.\nIl processo si basa su quattro passaggi essenziali. In primo luogo, si parte dalla quantificazione delle credenze iniziali, note come prior, che rappresentano le conoscenze pregresse o le ipotesi relative a un determinato fenomeno psicologico. Successivamente, si analizza la forza delle evidenze empiriche fornite dai dati raccolti, formalizzata nella likelihood. Queste due informazioni vengono combinate per generare le credenze aggiornate, chiamate posterior, che sintetizzano la conoscenza disponibile integrando i dati empirici e le ipotesi iniziali. Infine, le credenze aggiornate possono essere utilizzate per prendere decisioni più informate, pianificare ricerche future e orientare interventi.\n\n11.8.1 Il ruolo delle credenze e delle decisioni nella ricerca psicologica\nLe credenze rivestono un ruolo fondamentale nella ricerca psicologica, influenzando tutte le fasi del processo scientifico, dalla progettazione degli esperimenti all’interpretazione dei risultati, fino alla scelta di interventi clinici. L’approccio bayesiano si distingue per la sua capacità di esplicitare e formalizzare queste credenze, consentendo di aggiornare il loro contenuto in modo coerente e trasparente man mano che emergono nuove evidenze.\nQuesto metodo permette non solo di ottimizzare le decisioni basandosi su informazioni aggiornate, ma anche di comunicare chiaramente l’incertezza associata alle conclusioni, evidenziandone i limiti e garantendo maggiore trasparenza scientifica. Affrontare l’incertezza come una componente intrinseca della ricerca non solo migliora la qualità dell’analisi, ma consente anche di promuovere un approccio più realistico e rigoroso nello studio dei fenomeni psicologici.\nIn sintesi, l’approccio bayesiano offre un modello operativo per integrare l’incertezza nel processo decisionale, trattandola non come un ostacolo, ma come un elemento essenziale per una comprensione più sfumata e accurata della realtà.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/00_uncertainty.html#riflessioni-conclusive",
    "href": "chapters/key_notions/00_uncertainty.html#riflessioni-conclusive",
    "title": "11  Abbracciare l’incertezza",
    "section": "11.9 Riflessioni Conclusive",
    "text": "11.9 Riflessioni Conclusive\nQuesto insegnamento fornisce gli strumenti per applicare l’analisi bayesiana nell’ambito dei dati psicologici, insegnando a considerare l’incertezza come una parte integrante e preziosa del processo scientifico. Attraverso questo approccio, gli studenti potranno acquisire una comprensione più raffinata e strutturata dei fenomeni psicologici, integrando l’incertezza come elemento fondamentale per interpretare i dati e formulare inferenze rigorose.\n\n\n\n\nFinetti, B. de. (1970). Teoria delle probabilità: sintesi introduttiva con appendice critica. Einaudi.\n\n\nGansch, R., & Adee, A. (2020). System theoretic view on uncertainties. 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), 1345–1350.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abbracciare l'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html",
    "href": "chapters/key_notions/01_key_notions.html",
    "title": "12  Concetti chiave",
    "section": "",
    "text": "Introduzione\nQuesto capitolo introduce il contesto e i principi base dell’analisi dei dati, con un focus su come le tecniche statistiche, combinate con una solida teoria dei fenomeni, siano strumentali all’avanzamento delle conoscenze scientifiche.\nL’analisi dei dati consente di sintetizzare grandi quantità di informazioni e di verificare le previsioni avanzate dalle teorie. Tuttavia, senza una teoria che dia significato ai dati, le osservazioni rimangono mere descrizioni prive di un contesto esplicativo. È attraverso l’integrazione tra dati e teoria che si raggiunge una comprensione profonda dei fenomeni e si favorisce l’avanzamento scientifico.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#introduzione",
    "href": "chapters/key_notions/01_key_notions.html#introduzione",
    "title": "12  Concetti chiave",
    "section": "",
    "text": "Most of the fundamental ideas of science are essentially simple, and may, as a rule, be expressed in a language comprehensible to everyone.\n(Einstein A and Infeld L, 1938)\n\n\n\n\n\n\n\n\nStatistica\n\n\n\nIl termine “statistica” può assumere diversi significati, a seconda del contesto in cui viene utilizzato.\n\nNel primo senso, la statistica è una scienza e una disciplina che si occupa dello studio e dell’applicazione di metodi e tecniche per la raccolta, l’organizzazione, l’analisi, l’interpretazione e la presentazione di dati.\nNel secondo senso, il termine “statistica” si riferisce a una singola misura o un valore numerico che è stato calcolato a partire da un campione di dati. Questo tipo di statistica rappresenta una caratteristica specifica del campione. Esempi comuni di statistiche in questo senso includono la media campionaria, la deviazione standard campionaria o il coefficiente di correlazione campionario.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "href": "chapters/key_notions/01_key_notions.html#la-spiegazione-scientifica",
    "title": "12  Concetti chiave",
    "section": "12.1 La Spiegazione Scientifica",
    "text": "12.1 La Spiegazione Scientifica\nLa scienza non si limita a descrivere o prevedere i fenomeni; essa mira a spiegare il perché degli eventi, fornendo una comprensione delle cause e dei meccanismi che governano il mondo. La spiegazione scientifica è quindi uno strumento essenziale per costruire teorie che non solo descrivono e prevedono, ma anche chiariscono le dinamiche causali e le connessioni tra fenomeni, aiutando così a sviluppare un controllo informato sugli stessi.\nSe prendiamo l’esempio del successo accademico in psicologia dell’educazione, possiamo osservare che i dati rivelano una forte associazione tra il livello di istruzione dei genitori e il successo scolastico dei figli. Tuttavia, una semplice previsione basata su questa associazione – “provenendo da una famiglia con basso livello d’istruzione, è improbabile che tu ottenga un titolo universitario” – non risponde alle domande fondamentali per migliorare il sistema educativo: perché esiste questa disparità? Quali interventi potrebbero ridurre questa disuguaglianza?\nPer andare oltre la previsione, la scienza deve individuare i fattori causali che contribuiscono al fenomeno, esplorare il modo in cui agire su questi fattori potrebbe alterare l’outcome, e stimare le incertezze e le dinamiche temporali di questi effetti. Ad esempio, per ridurre la disuguaglianza educativa, è necessario comprendere se e come aumentare il sostegno finanziario agli studenti possa realmente facilitare il percorso scolastico di chi proviene da contesti meno favoriti, e prevedere gli effetti di lungo termine di tali politiche. Questo approccio permette non solo di prevedere ma anche di controllare e migliorare i fenomeni studiati.\n\n12.1.1 Elementi Fondamentali della Spiegazione Scientifica\nLa filosofia della scienza ha individuato tre elementi chiave di una spiegazione scientifica:\n\nExplanandum: il fenomeno da spiegare. Ad esempio, “si è verificata una crisi petrolifera nel 1973.”\nExplanans: un insieme di affermazioni che spiegano il fenomeno. Per esempio, “gli stati membri dell’OAPEC hanno imposto un embargo sul petrolio in risposta al sostegno degli Stati Uniti a Israele nella guerra del Kippur.”\nLegame esplicativo: i principi o le leggi che descrivono il meccanismo sottostante, ossia il modo in cui l’explanans causa l’explanandum. Nel caso dell’embargo, il legame potrebbe essere: “gli stati dell’OAPEC usarono il petrolio come strumento politico per influenzare la politica estera degli Stati Uniti.”\n\nI modelli scientifici incorporano questi elementi, rappresentando una metodologia per ottenere spiegazioni scientifiche. Essi includono il fenomeno da spiegare, i fattori causali rilevanti e i meccanismi che collegano i fattori all’esito. A differenza dei modelli puramente descrittivi o predittivi, i modelli scientifici in psicologia sono progettati per rispondere a domande causali, facilitando la comprensione e il controllo dei fenomeni.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "href": "chapters/key_notions/01_key_notions.html#modelli-psicologici",
    "title": "12  Concetti chiave",
    "section": "12.2 Modelli Psicologici",
    "text": "12.2 Modelli Psicologici\nUn modello è una rappresentazione matematica semplificata di un fenomeno reale. È composto da un insieme di equazioni e ipotesi che definiscono la struttura probabilistica e le relazioni tra le variabili, cercando di cogliere gli aspetti essenziali del fenomeno senza includerne ogni dettaglio. Esistono spesso diversi modelli applicabili a uno stesso problema, e il compito della scienza dei dati è identificare quello che meglio si adatta ai dati, soddisfacendo criteri di validità e accuratezza.\nI modelli psicologici sono strumenti concettuali per descrivere, spiegare e prevedere il comportamento umano e i processi mentali. Un buon modello psicologico dovrebbe avere alcune caratteristiche fondamentali:\n\nCoerenza descrittiva: Il modello deve rappresentare in modo logico e coerente il fenomeno studiato, catturando gli aspetti chiave del processo psicologico e organizzando le osservazioni in una struttura comprensibile.\nCapacità predittiva: Un modello efficace deve essere in grado di fare previsioni accurate sui futuri sviluppi del fenomeno. Questa capacità non solo ne aumenta l’utilità, ma permette anche di testarne la validità.\nSupporto empirico: Le ipotesi e le previsioni del modello devono essere confermate da dati raccolti attraverso ricerche sistematiche e rigorose.\nFalsificabilità: Un modello scientifico deve poter essere testato e, se necessario, confutato con l’osservazione e l’esperimento. Questo principio assicura che il modello rimanga aperto alla revisione e al miglioramento in base a nuove evidenze.\nParsimonia: Il modello dovrebbe spiegare il fenomeno nel modo più semplice possibile, evitando complessità inutili.\nGeneralizzabilità: Deve essere applicabile a una vasta gamma di situazioni e contesti, non limitandosi a casi specifici o condizioni sperimentali particolari.\nUtilità pratica: Un modello efficace dovrebbe fornire spunti utili per interventi, terapie o applicazioni nel mondo reale.\n\nLa modellazione in psicologia affronta sfide uniche dovute alla natura soggettiva e variabile dell’esperienza umana. I ricercatori devono bilanciare la precisione scientifica con la flessibilità necessaria per cogliere la complessità dei fenomeni psicologici, considerando al contempo i limiti etici della sperimentazione e le potenziali implicazioni sociali dei loro modelli.\nL’analisi dei dati, attraverso tecniche statistiche, è il mezzo per valutare un modello psicologico. Oltre a stabilire se il modello riesce a spiegare i dati osservati, l’analisi verifica la capacità del modello di fare previsioni su dati non ancora raccolti. In questo modo, la modellazione non solo consente di comprendere i fenomeni psicologici ma permette anche di prevedere e, in certi casi, influenzare il comportamento e i processi mentali.\n\n12.2.1 Rappresentare i Fenomeni per Ragionare e Comunicare\nLa spiegazione scientifica, oltre a chiarire i meccanismi causali, serve anche a fornire un linguaggio per ragionare sui fenomeni e per condividere la conoscenza. In psicologia, la costruzione di modelli scientifici permette di rappresentare i fenomeni attraverso variabili, funzioni e parametri, fornendo un vocabolario per descrivere componenti, dipendenze e proprietà dei fenomeni. Un modello semplice e chiaro consente di emulare il comportamento del fenomeno senza necessità di simulazioni complesse, facilitando la comunicazione e l’intuizione.\nUn aspetto importante della spiegazione scientifica è la possibilità di utilizzare i modelli per stimolare l’intuizione e generare nuove domande. La comprensione dei fenomeni attraverso una rappresentazione scientifica accessibile permette di formulare ipotesi, collegare concetti, e trasferire conoscenze da un campo all’altro.\nIn sintesi, la spiegazione scientifica va oltre la mera previsione: mira a fornire una comprensione completa dei fenomeni, basata su nessi causali e su un linguaggio formale per ragionare e comunicare. I modelli scientifici non solo predicono eventi, ma spiegano come e perché questi eventi si verificano, offrendo una struttura con cui intervenire e influenzare i fenomeni stessi.\nNell’analisi dei dati bayesiana, questa attenzione alle cause e agli effetti trova un’applicazione naturale. La possibilità di aggiornare le proprie credenze alla luce di nuove informazioni consente di costruire modelli che non si limitano alla descrizione o alla previsione, ma che forniscono spiegazioni coerenti e profonde dei fenomeni, aiutando a sviluppare teorie sempre più raffinate e applicabili.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#ruolo-dellanalisi-dei-dati",
    "href": "chapters/key_notions/01_key_notions.html#ruolo-dellanalisi-dei-dati",
    "title": "12  Concetti chiave",
    "section": "12.3 Ruolo dell’Analisi dei Dati",
    "text": "12.3 Ruolo dell’Analisi dei Dati\nL’analisi dei dati riveste un ruolo centrale nelle scienze, specialmente in psicologia, per due ragioni principali:\n\nRiassumere grandi quantità di informazioni: consente di sintetizzare dati complessi in statistiche descrittive, grafici e altre rappresentazioni che rendono i dati accessibili e comprensibili. Questo processo evidenzia tendenze generali, variazioni e anomalie, facilitando l’identificazione di schemi comportamentali e differenze tra gruppi.\nVerificare le predizioni di un modello scientifico: permette di confrontare le aspettative teoriche con i dati osservati, valutando la validità delle ipotesi sottostanti. Questa verifica contribuisce direttamente all’avanzamento della conoscenza scientifica, sostenendo, modificando o confutando una teoria.\n\nSebbene l’analisi dei dati possa portare alla scoperta di correlazioni o schemi interessanti, questi risultati, senza una teoria, offrono solo una comprensione limitata. Per esempio, rilevare che due variabili psicologiche sono correlate non fornisce informazioni sulla natura di questa relazione o sul motivo per cui esiste. Per interpretare e attribuire un significato a queste osservazioni, è necessario un quadro teorico che le contestualizzi e proponga meccanismi causali o esplicativi.\n\n12.3.1 Carattere Multidisciplinare dell’Analisi dei Dati\nL’analisi dei dati si situa all’intersezione di tre discipline principali: statistica, teoria della probabilità e informatica. Ciascuna contribuisce con strumenti e approcci specifici essenziali per comprendere i dati, estrarre conoscenza e generare nuove ipotesi scientifiche.\n\nStatistica: offre tecniche per raccogliere, analizzare e interpretare i dati, fornendo strumenti descrittivi e inferenziali utili per trarre conclusioni e prendere decisioni.\nTeoria della probabilità: fornisce la base matematica della statistica, consentendo di modellare e quantificare l’incertezza e di comprendere i fenomeni aleatori che caratterizzano molte osservazioni in psicologia.\nInformatica: supporta l’analisi attraverso strumenti per la gestione, l’elaborazione e la visualizzazione di grandi quantità di dati. La programmazione consente di sviluppare modelli avanzati e gestire dataset complessi.\n\nQuesta natura multidisciplinare riflette la complessità dell’analisi dei dati e la necessità di integrare diverse competenze per affrontare le sfide scientifiche contemporanee.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "href": "chapters/key_notions/01_key_notions.html#concetti-chiave-nellanalisi-dei-dati",
    "title": "12  Concetti chiave",
    "section": "12.4 Concetti Chiave nell’Analisi dei Dati",
    "text": "12.4 Concetti Chiave nell’Analisi dei Dati\nPer condurre un’analisi dei dati efficace, è fondamentale comprendere alcuni concetti chiave.\n\n12.4.1 Popolazioni e Campioni\nIn ogni analisi dei dati, è fondamentale identificare la popolazione di interesse, l’insieme completo di entità o individui che rappresentano il fenomeno studiato. In psicologia, ad esempio, si può voler studiare il benessere in una popolazione generale o in una sotto-popolazione specifica, come gli individui che hanno subito un evento stressante.\nPer ottenere informazioni dettagliate su una popolazione, si utilizzano campioni: sottoinsiemi rappresentativi dai quali si possono fare inferenze sull’intera popolazione. La rappresentatività del campione è cruciale, poiché un campione non rappresentativo può portare a conclusioni errate e limitare la generalizzabilità dei risultati.\n\n\n12.4.2 Bias nella Raccolta Dati\nI bias nella raccolta e interpretazione dei dati possono influenzare profondamente i risultati di uno studio. Capire chi ha raccolto i dati, come e con quali finalità, è fondamentale per garantire una corretta interpretazione. I dati non sono mai neutri e le intenzioni che ne guidano la raccolta spesso ne influenzano l’interpretazione (Murray & Carr, 2024; Nobles, 2000)\n\n\n\nTabella creata da Ellie Murray.\n\n\n\n\n12.4.3 Variabili e Costanti\nNell’analisi statistica, le variabili rappresentano le caratteristiche osservate che possono assumere diversi valori (numerici o categorici). Al contrario, le costanti sono valori che rimangono fissi in un dato contesto. Si distinguono poi le variabili indipendenti (o predittive), che influenzano le variabili dipendenti, e le variabili dipendenti, che rappresentano gli esiti di interesse.\n\n\n12.4.4 Effetti\nIn statistica, un effetto misura il cambiamento osservato nelle variabili dipendenti in relazione alle variabili indipendenti. Ad esempio, l’efficacia di una terapia può essere valutata misurando la differenza nei sintomi prima e dopo il trattamento (Huntington-Klein, 2021).\n\n\n12.4.5 Stima e Inferenza\n\n12.4.5.1 Stima\nLa stima statistica consente di ottenere informazioni su una popolazione a partire da un campione. Si utilizzano statistiche campionarie (come la media campionaria) per stimare i parametri della popolazione (come la media vera della popolazione).\nGli stimatori devono possedere proprietà come:\n\nconsistenza: la stima converge al vero valore del parametro all’aumentare della dimensione del campione;\nnon distorsione: il valore atteso dello stimatore è uguale al vero valore del parametro;\nefficienza: lo stimatore ha la minor varianza possibile.\n\nL’accuratezza della stima dipende da vari fattori, tra cui la dimensione e la rappresentatività del campione, la variabilità nella popolazione e il metodo di campionamento utilizzato.\n\n\n\n12.4.6 Inferenza Statistica\nDopo aver ottenuto le stime, l’inferenza statistica permette di trarre conclusioni più generali sulla popolazione. Essa consente di valutare ipotesi specifiche o rispondere a domande di ricerca basate sui dati raccolti.\nAd esempio, se abbiamo stimato la media del rendimento accademico in un campione di studenti, l’inferenza statistica ci consente di quantificare l’incertezza riguardo alla differenza di rendimento tra maschi e femmine all’interno della popolazione più ampia. In questo modo, l’inferenza statistica ci fornisce gli strumenti per fare previsioni e trarre conclusioni su fenomeni che riguardano l’intera popolazione.\nEsistono due approcci principali.\nL’inferenza bayesiana:\n\nSi basa sul teorema di Bayes;\nUtilizza probabilità a priori, che riflettono conoscenze o credenze iniziali su un fenomeno;\nAggiorna queste probabilità con nuovi dati per ottenere probabilità a posteriori;\nFornisce una interpretazione delle probabilità come gradi di credenza soggettivi.\n\nL’approccio frequentista:\n\nSi fonda sulla frequenza relativa di eventi osservati in esperimenti ripetuti;\nUtilizza strumenti come il test di ipotesi nulla e gli intervalli di confidenza per trarre conclusioni;\nNon fa uso di probabilità a priori, concentrandosi esclusivamente sui dati osservati.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "href": "chapters/key_notions/01_key_notions.html#le-sfide-dellinferenza-statistica-in-psicologia",
    "title": "12  Concetti chiave",
    "section": "12.5 Le Sfide dell’Inferenza Statistica in Psicologia",
    "text": "12.5 Le Sfide dell’Inferenza Statistica in Psicologia\nSecondo Gelman et al. (2020), l’inferenza statistica in psicologia affronta tre sfide principali:\n\nGeneralizzare dai campioni alla popolazione: Questa sfida è strettamente legata al problema del campionamento di comodo, spesso usato in psicologia, ma presente in quasi tutte le applicazioni dell’inferenza statistica. La difficoltà risiede nel trarre conclusioni affidabili su una popolazione più ampia partendo da un campione limitato e, a volte, non rappresentativo.\nGeneralizzare dal gruppo trattato al gruppo di controllo: Questa sfida riguarda l’inferenza causale, un aspetto centrale per determinare l’efficacia dei trattamenti psicologici. L’obiettivo è stabilire se i risultati osservati nel gruppo trattato possano essere applicati al gruppo di controllo o ad altre popolazioni, permettendo una valutazione valida dell’effetto del trattamento.\nGeneralizzare dalle misurazioni osservate ai costrutti sottostanti: In psicologia, i dati raccolti non corrispondono mai perfettamente ai costrutti teorici di interesse. La sfida è inferire questi costrutti latenti dai dati osservati, che rappresentano spesso solo un’approssimazione imperfetta.\n\nQueste sfide evidenziano la complessità dell’inferenza in psicologia e la necessità di metodologie robuste per affrontarle.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "href": "chapters/key_notions/01_key_notions.html#riflessioni-conclusive",
    "title": "12  Concetti chiave",
    "section": "12.6 Riflessioni Conclusive",
    "text": "12.6 Riflessioni Conclusive\nIn psicologia, le teorie forniscono ipotesi testabili che spiegano il “come” e il “perché” di determinati fenomeni mentali e comportamentali. Una teoria robusta permette di formulare previsioni chiare e specifiche, che possono essere verificate empiricamente attraverso l’analisi dei dati. Ad esempio, una teoria sull’ansia potrebbe prevedere che, in un compito di esposizione graduale a stimoli ansiogeni, il livello di ansia diminuisca progressivamente. Senza una teoria che spieghi perché questo dovrebbe accadere, tale osservazione rimane solo un dato descrittivo, privo di valore esplicativo o predittivo.\nL’analisi dei dati diventa davvero potente quando è integrata a una teoria. Senza teoria, i dati possono descrivere fenomeni ma non spiegare i meccanismi sottostanti. La teoria fornisce il contesto interpretativo, orientando la raccolta e l’analisi dei dati, e permettendo una comprensione profonda dei fenomeni psicologici.\nUn esempio è l’uso della data science per analizzare l’efficacia di un trattamento psicoterapeutico. I dati possono mostrarci una diminuzione dei sintomi in seguito alla terapia, ma è solo la teoria alla base del trattamento che fornisce un quadro interpretativo per questo miglioramento, proponendo i meccanismi per cui il trattamento riduce i sintomi. La teoria orienta quindi l’analisi e permette di interpretare i dati in un contesto scientifico.\nSviluppare una teoria in psicologia è complesso a causa della notevole variabilità umana. Un buon modello psicologico deve prevedere con precisione i comportamenti osservabili e rappresentare i processi mentali latenti. Queste previsioni devono essere testabili e falsificabili (Eronen & Bringmann, 2021).\nLa relazione tra teoria e analisi dei dati è dinamica e iterativa. I modelli e le teorie si evolvono grazie alla verifica empirica. Se i dati non supportano le previsioni di una teoria, essa viene modificata o sostituita, favorendo l’avanzamento scientifico.\nIn conclusione, la teoria e l’analisi dei dati sono complementari e interdipendenti. L’analisi dei dati offre gli strumenti per testare e affinare le teorie psicologiche, mentre la teoria dà significato e contesto ai dati, rendendo possibile una comprensione profonda e utile dei fenomeni psicologici.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/key_notions/01_key_notions.html#informazioni-sullambiente-di-sviluppo",
    "title": "12  Concetti chiave",
    "section": "12.7 Informazioni sull’Ambiente di Sviluppo",
    "text": "12.7 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Tue Jul 23 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nEronen, M. I., & Bringmann, L. F. (2021). The theory crisis in psychology: How to move forward. Perspectives on Psychological Science, 16(4), 779–788.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research design and causality. Chapman; Hall/CRC.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring Racial Sentiment Using Social Media Is Harder Than It Seems. Epidemiology, 35(1), 60–63.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in modern politics. Stanford University Press.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Concetti chiave</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html",
    "href": "chapters/key_notions/02_measurement.html",
    "title": "13  La misurazione in psicologia",
    "section": "",
    "text": "13.1 Introduzione\nLa scienza si avvale di modelli per interpretare i dati, ma opera sempre con teorie incomplete e misurazioni soggette a errori. Di conseguenza, è fondamentale riconoscere le incertezze quando si cerca di estrarre informazioni dalle misurazioni utilizzando i nostri modelli. Nessuna misurazione, spiegazione o previsione è perfettamente accurata e precisa, e non possiamo mai conoscere con esattezza l’entità dei loro errori.\nQuesta incertezza viene catturata in tre equazioni fondamentali. La prima è l’Equazione di Misurazione, che riconosce l’errore osservativo: \\(y = z + ϵ_y\\), dove \\(y\\) rappresenta il valore misurato, \\(z\\) il valore reale e \\(ϵ_y\\) l’errore di misurazione. La seconda è l’Equazione di Modellazione, che esprime la presenza di un diverso tipo di errore: \\(z = f(x,θ) + ϵ_\\text{model}\\), dove \\(f\\) è il modello, \\(x\\) sono le condizioni ambientali per cui eseguiamo il modello, θ sono i valori dei parametri del modello e \\(ϵ_\\text{model}\\) rappresenta l’errore del modello, che sorge perché \\(f\\), \\(x\\) e θ saranno tutti in qualche misura imprecisi.\nCombinando queste due equazioni, otteniamo l’Equazione della Scienza: \\(y = f(x,θ) + ϵ_\\text{model} + ϵ_y\\). La scienza è il tentativo di spiegare le osservazioni \\(y\\) utilizzando un modello \\(f\\), cercando di minimizzare l’errore di misurazione \\(ϵ_y\\) e l’errore del modello \\(ϵ_\\text{model}\\), in modo che il modello possa essere utilizzato per fare previsioni sul mondo reale (\\(z\\)). L’approccio bayesiano alla scienza riconosce e quantifica le incertezze su tutti e sei gli elementi dell’Equazione della Scienza: \\(y\\), \\(f\\), \\(x\\), θ, \\(ϵ_\\text{model}\\) e \\(ϵ_y\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#la-teoria-della-misurazione",
    "href": "chapters/key_notions/02_measurement.html#la-teoria-della-misurazione",
    "title": "13  La misurazione in psicologia",
    "section": "13.2 La teoria della Misurazione",
    "text": "13.2 La teoria della Misurazione\nLa teoria della misurazione, oggetto di questo capitolo, si concentra sull’errore di misurazione e sull’equazione fondamentale \\(y = z + ϵ_y\\). Questa equazione può essere esaminata da tre prospettive distinte. La prima concerne l’affidabilità della misura, rappresentata dal termine \\(ϵ_y\\). La psicometria, branca dedicata alla teoria della misurazione psicologica, si occupa di quantificare l’affidabilità delle misure psicologiche attraverso metodi come la Teoria Classica dei Test e la Teoria di Risposta all’Item.\nLa seconda prospettiva riguarda la validità delle misure psicologiche, ovvero quanto adeguatamente la misura \\(y\\) rappresenti il costrutto \\(z\\). Questo aspetto, più complesso dell’affidabilità, non può essere risolto meramente con metodi statistici, ma richiede una profonda comprensione delle teorie psicologiche e della loro capacità di descrivere e prevedere i fenomeni psicologici.\nLa terza prospettiva si concentra sulle procedure di assegnazione dei valori a \\(y\\), esplorando quali metodi (questionari, interviste, esperimenti) siano più appropriati e come valutarne l’adeguatezza.\n\n13.2.1 Costrutti Psicologici\nLa teoria della misurazione sottolinea l’importanza di distinguere tra la procedura di misurazione e il costrutto che si intende misurare. Ad esempio, mentre la temperatura è un costrutto, il termometro è lo strumento di misurazione. Analogamente, l’abilità matematica è un costrutto, mentre un test di matematica è la procedura per misurarla.\nNelle scienze psicologiche e sociali, la misurazione presenta sfide uniche rispetto alle scienze fisiche, poiché i costrutti in esame sono spesso astratti e non direttamente osservabili. Ciò richiede una particolare attenzione alla validità e all’affidabilità degli strumenti di misurazione, nonché una costante riflessione sulle limitazioni e le potenziali fonti di errore.\nIl capitolo introduce concetti fondamentali relativi alla misurazione quantitativa delle caratteristiche psicologiche, con un focus sulla teoria delle scale di misura di Stevens (1946). Questa teoria fornisce un quadro concettuale per comprendere i diversi tipi di scale di misurazione e le operazioni matematiche appropriate per ciascuna. Inoltre, vengono esplorate alcune procedure di scaling psicologico, ovvero l’assegnazione di numeri all’intensità di fenomeni psicologici.\n\n\n13.2.2 Scaling Psicologico\nLo scaling psicologico si occupa della trasformazione dei dati empirici raccolti durante uno studio psicologico in misure o punteggi che rappresentino accuratamente le caratteristiche psicologiche oggetto di indagine.\nScaling di Guttman. Uno dei metodi di scaling più noti è lo «Scaling di Guttman», che viene utilizzato per rappresentare relazioni ordinate tra gli elementi di una scala. Ad esempio, in un questionario sui sintomi dell’ansia, le domande possono essere disposte in ordine di intensità crescente dei sintomi. Secondo il modello di Guttman, se un partecipante risponde “sì” a una domanda che riflette un sintomo più intenso, ci si aspetta che abbia risposto “sì” anche a tutte le domande precedenti, che rappresentano sintomi di intensità minore. Questo approccio consente di costruire una scala che riflette in modo sistematico e coerente la gravità dei sintomi.\nScaling Thurstoniano. Lo «Scaling Thurstoniano» è un metodo utilizzato per misurare preferenze o giudizi soggettivi. Ad esempio, per valutare la preferenza tra diversi tipi di cibi, i partecipanti confrontano due cibi alla volta ed esprimono una preferenza. Le risposte vengono poi utilizzate per assegnare punteggi che riflettono la preferenza media per ciascun cibo.\nQuestionari Likert. I questionari Likert richiedono ai partecipanti di esprimere il loro grado di accordo con una serie di affermazioni su una scala a più livelli, che va da «fortemente in disaccordo» a «fortemente d’accordo». I punteggi ottenuti vengono sommati per rappresentare la posizione complessiva dell’individuo rispetto all’oggetto di studio.\n\n\n13.2.3 Metodi di Valutazione delle Scale Psicologiche\nPer valutare le proprietà delle scale psicologiche, vengono utilizzati vari metodi. Ad esempio, l’affidabilità delle misure può essere analizzata utilizzando il coefficiente alpha di Cronbach o il coefficiente Omega di McDonald, entrambi utilizzati per misurare la coerenza interna delle risposte ai diversi item di un questionario. Inoltre, la validità delle scale può essere esaminata confrontando i risultati ottenuti con misure simili o attraverso analisi statistiche che verificano se la scala cattura accuratamente il costrutto psicologico che si intende misurare. La validità di costrutto è particolarmente cruciale, poiché riguarda la capacità della scala di misurare effettivamente il concetto psicologico che si intende esplorare.\n\n\n13.2.4 Prospettive Moderne\nNegli ultimi anni, il dibattito sulla misurazione psicologica si è arricchito di nuove prospettive, grazie all’avvento di tecnologie avanzate e all’integrazione di approcci interdisciplinari. Ecco alcune delle tendenze più rilevanti.\nTeoria della Risposta agli Item. La Teoria della Risposta agli Item (IRT) ha guadagnato popolarità per la sua capacità di fornire stime più precise delle abilità latenti rispetto ai modelli classici. La IRT considera la probabilità che un individuo risponda correttamente a un item in funzione della sua abilità e delle caratteristiche dell’item stesso, offrendo una visione più dettagliata delle proprietà psicometriche degli strumenti di misurazione.\nApprocci Bayesiani. Gli approcci bayesiani stanno rivoluzionando il campo della psicometria, permettendo di incorporare informazioni a priori nelle stime e di aggiornare le credenze sulla base di nuovi dati. Questi metodi sono particolarmente utili per affrontare la complessità e l’incertezza inerenti alla misurazione psicologica.\nAnalisi di Rete. L’analisi di rete è un’altra metodologia emergente che vede i costrutti psicologici non come variabili latenti indipendenti, ma come reti di sintomi interconnessi. Questo approccio può offrire nuove intuizioni sulla struttura delle psicopatologie e sulla dinamica dei sintomi.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#le-scale-di-misurazione",
    "title": "13  La misurazione in psicologia",
    "section": "13.3 Le scale di misurazione",
    "text": "13.3 Le scale di misurazione\nLe scale di misurazione sono strumenti fondamentali per assegnare numeri ai dati osservati, rappresentando le proprietà psicologiche. La teoria delle scale di Stevens Stevens (1946) identifica quattro tipi di scale di misurazione: nominali, ordinali, a intervalli e di rapporti. Ognuna di queste scale consente di effettuare operazioni aritmetiche diverse, poiché ciascuna di esse è in grado di “catturare” solo alcune delle proprietà dei fenomeni psicologici che si intende misurare.\n\n\n\nScale di misurazione.\n\n\n\n13.3.1 Scala nominale\nILa scala nominale è il livello di misurazione più semplice e corrisponde ad una tassonomia o classificazione delle categorie che utilizziamo per descrivere i fenomeni psicologici. I simboli o numeri che costituiscono questa scala rappresentano i nomi delle categorie e non hanno alcun valore numerico intrinseco. Con la scala nominale possiamo solo distinguere se una caratteristica psicologica è uguale o diversa da un’altra.\nI dati raccolti con la scala nominale sono suddivisi in categorie qualitative e mutuamente esclusive, in cui ogni dato appartiene ad una sola categoria. In questa scala, esiste solo la relazione di equivalenza tra le misure delle unità di studio: gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti.\nL’unica operazione algebrica consentita dalla scala nominale è quella di contare le unità di studio che appartengono ad ogni categoria e il numero totale di categorie. Di conseguenza, la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nDalla scala nominale è possibile costruire altre scale nominali equivalenti alla prima, trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle categorie, ma lasciando inalterata la suddivisione delle unità di studio nelle medesime classi di equivalenza. In altre parole, cambiando i nomi delle categorie di una variabile misurata su scala nominale, si ottiene una nuova variabile esattamente equivalente alla prima.\n\n\n13.3.2 Scala ordinale\nLa scala ordinale mantiene la caratteristica della scala nominale di classificare ogni unità di misura all’interno di una singola categoria, ma introduce la relazione di ordinamento tra le categorie. In quanto basata su una relazione di ordine, una scala ordinale descrive solo il rango di ordine tra le categorie e non fornisce informazioni sulla distanza tra di esse. Non ci dice, ad esempio, se la distanza tra le categorie \\(a\\) e \\(b\\) è uguale, maggiore o minore della distanza tra le categorie \\(b\\) e \\(c\\).\nUn esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore.\n\n\n\nLa scala di durezza dei minerali di Mohs. Un oggetto è considerato più duro di X se graffia X. Sono incluse anche misure di durezza relativa utilizzando uno sclerometro, da cui emerge la non linearità della scala di Mohs (Burchard, 2004).\n\n\n\n\n13.3.3 Scala ad intervalli\nLa scala ad intervalli di misurazione include le proprietà della scala nominale e della scala ordinale e permette di misurare le distanze tra le coppie di unità statistiche in termini di un intervallo costante, chiamato “unità di misura”, a cui viene attribuito il valore “1”. L’origine della scala, ovvero il punto zero, è scelta arbitrariamente e non indica l’assenza della proprietà che si sta misurando. Ciò significa che la scala ad intervalli consente anche valori negativi e lo zero non viene attribuito all’unità statistica in cui la proprietà risulta assente.\nLa scala ad intervalli equivalenti consente l’esecuzione di operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non possibili con le scale di misura nominale o ordinale. Tuttavia, il limite della scala ad intervalli è che non consente di calcolare il rapporto tra coppie di misure. È possibile affermare la differenza tra \\(a\\) e \\(b\\) come la metà della differenza tra \\(c\\) e \\(d\\) o che le due differenze sono uguali, ma non è possibile affermare che \\(a\\) abbia una proprietà misurata in quantità doppia rispetto a \\(b\\). In altre parole, non è possibile stabilire rapporti diretti tra le misure ottenute. Solo le differenze tra le modalità permettono tutte le operazioni aritmetiche, come la somma, l’elevazione a potenza o la divisione, che sono alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l’unità di misura è arbitraria e può essere cambiata attraverso una dilatazione, ovvero la moltiplicazione di tutti i valori della scala per una costante positiva. Inoltre, la traslazione, ovvero l’aggiunta di una costante a tutti i valori della scala, è ammessa poiché non altera le differenze tra i valori della scala. La scala rimane invariata rispetto a traslazioni e dilatazioni e dunque le uniche trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b &gt; 0.\n\\]\nInfatti, l’uguaglianza dei rapporti fra gli intervalli rimane invariata a seguito di una trasformazione lineare.\nEsempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\nÈ facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n\n13.3.4 Scala di rapporti\nNella scala a rapporti equivalenti, lo zero non è arbitrario e rappresenta l’elemento che ha intensità nulla rispetto alla proprietà misurata. Per costruire questa scala, si associa il numero 0 all’elemento con intensità nulla e si sceglie un’unità di misura \\(u\\). Ad ogni elemento si assegna un numero \\(a\\) definito come \\(a=d/u\\), dove \\(d\\) rappresenta la distanza dall’origine. In questo modo, i numeri assegnati riflettono le differenze e i rapporti tra le intensità della proprietà misurata.\nIn questa scala, è possibile effettuare operazioni aritmetiche non solo sulle differenze tra i valori della scala, ma anche sui valori stessi della scala. L’unica scelta arbitraria è l’unità di misura, ma lo zero deve sempre rappresentare l’intensità nulla della proprietà considerata.\nLe trasformazioni ammissibili in questa scala sono chiamate trasformazioni di similarità e sono del tipo \\(y' = by\\), dove \\(b&gt;0\\). In questa scala, i rapporti tra i valori rimangono invariati dopo le trasformazioni. In altre parole, se rapportiamo due valori originali e due valori trasformati, il rapporto rimane lo stesso: \\(\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}\\).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "href": "chapters/key_notions/02_measurement.html#gerarchia-dei-livelli-delle-scale-di-misurazione",
    "title": "13  La misurazione in psicologia",
    "section": "13.4 Gerarchia dei livelli delle scale di misurazione",
    "text": "13.4 Gerarchia dei livelli delle scale di misurazione\nSecondo Stevens (1946), esiste una gerarchia dei livelli delle scale di misurazione, denominati “livelli di scala”. Questi livelli sono organizzati in modo gerarchico, in cui la scala nominale rappresenta il livello più basso della misurazione, mentre la scala a rapporti equivalenti rappresenta il livello più alto.\n\nLa scala nominale è il livello più elementare, in cui le categorie o le etichette vengono assegnate agli oggetti o agli individui senza alcuna valutazione di grandezza o ordine.\nAl livello successivo si trova la scala ordinale, in cui le categorie sono ordinate in base a una qualche qualità o caratteristica. Qui, è possibile stabilire un ordine di preferenza o gerarchia tra le categorie, ma non è possibile quantificare la differenza tra di esse in modo preciso.\nLa scala intervallo rappresenta un livello successivo, in cui le categorie sono ordinate e la differenza tra di esse è quantificabile in modo preciso. In questa scala, è possibile effettuare operazioni matematiche come l’addizione e la sottrazione tra i valori, ma non è possibile stabilire un vero e proprio punto zero significativo.\nInfine, la scala a rapporti equivalenti rappresenta il livello più alto. In questa scala, le categorie sono ordinate, la differenza tra di esse è quantificabile in modo preciso e esiste un punto zero assoluto che rappresenta l’assenza totale della grandezza misurata. Questo livello di scala permette di effettuare tutte le operazioni matematiche, compresa la moltiplicazione e la divisione.\n\nPassando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\n\n\nRelazioni tra i livelli di misurazione.\n\n\nPer ciò che riguarda le trasformazioni ammissibili, più il livello di scala è basso, più le funzioni sono generali (sono minori cioè i vincoli per passare da una rappresentazione numerica ad un’altra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa più restrittiva.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "href": "chapters/key_notions/02_measurement.html#variabili-discrete-o-continue",
    "title": "13  La misurazione in psicologia",
    "section": "13.5 Variabili discrete o continue",
    "text": "13.5 Variabili discrete o continue\nLe variabili possono essere classificate come variabili a livello di intervalli o di rapporti e possono essere sia discrete che continue.\n\nLe variabili discrete assumono valori specifici ma non possono assumere valori intermedi. Una volta che l’elenco dei valori accettabili è stato definito, non vi sono casi che si trovano tra questi valori. In genere, le variabili discrete assumono valori interi, come il numero di eventi, il numero di persone o il numero di oggetti.\nD’altra parte, le variabili continue possono assumere qualsiasi valore all’interno di un intervallo specificato. Teoricamente, ciò significa che è possibile utilizzare frazioni e decimali per ottenere qualsiasi grado di precisione.\n\n\n\n\nVariabili discrete e continue.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "href": "chapters/key_notions/02_measurement.html#comprendere-gli-errori-nella-misurazione",
    "title": "13  La misurazione in psicologia",
    "section": "13.6 Comprendere gli errori nella misurazione",
    "text": "13.6 Comprendere gli errori nella misurazione\nGli errori di misurazione possono essere casuali o sistematici. Gli errori casuali sono fluttuazioni aleatorie, mentre gli errori sistematici sono costanti e derivano da problemi nel metodo di misurazione o negli strumenti.\n\n13.6.1 Precisione e Accuratezza\nLa precisione indica la coerenza tra misurazioni ripetute, mentre l’accuratezza si riferisce alla vicinanza del valore misurato al valore reale. Entrambi i concetti sono cruciali per l’assessment psicometrico.\nUtilizzando l’analogia del tiro al bersaglio, si può avere una serie di colpi vicini tra loro ma lontani dal centro (precisione senza accuratezza) oppure colpi distribuiti in modo sparso ma in media vicini al centro (accuratezza senza precisione).",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "href": "chapters/key_notions/02_measurement.html#assessment-psicometrico",
    "title": "13  La misurazione in psicologia",
    "section": "13.7 Assessment psicometrico",
    "text": "13.7 Assessment psicometrico\nL’assessment psicometrico valuta la qualità delle misurazioni psicologiche, considerando la validità e l’affidabilità.\n\n13.7.1 Validità nella Misurazione Psicologica\nLa validità è una proprietà psicometrica fondamentale dei test psicologici. Secondo gli Standards for Educational and Psychological Testing (2014), la validità si riferisce al grado in cui evidenza e teoria supportano le interpretazioni dei punteggi dei test per gli usi proposti. Questo concetto evidenzia che la validità riguarda sia il significato dei punteggi sia il loro utilizzo, rendendola “la considerazione più fondamentale nello sviluppo e nella valutazione dei test”.\n\n\n13.7.2 Evoluzione del Concetto di Validità\nTradizionalmente, la validità era suddivisa in tre categorie:\n\nValidità di Contenuto: Si riferisce alla corrispondenza tra il contenuto degli item di un test e il dominio dell’attributo psicologico che il test intende misurare. È importante che gli item siano pertinenti e rappresentativi dell’attributo misurato.\nValidità di Criterio: Valuta il grado di concordanza tra i risultati ottenuti tramite lo strumento di misurazione e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto o da un criterio esterno. Include validità concorrente e predittiva.\nValidità di Costrutto: Riguarda il grado in cui un test misura effettivamente il costrutto che si intende misurare. Si suddivide in validità convergente (accordo con strumenti che misurano lo stesso costrutto) e validità divergente (capacità di discriminare tra costrutti diversi).\n\nLa moderna teoria della validità non adotta più questa visione tripartita. Gli Standards del 2014 descrivono la validità come un concetto unitario, dove diverse forme di evidenza concorrono a supportare l’interpretazione dei punteggi del test per il loro utilizzo previsto.\n\n\n13.7.3 Tipologie di Prove di Validità\nGli Standards del 2014 identificano cinque categorie principali di prove di validità:\n\nProve Basate sul Contenuto del Test: Valutano quanto il contenuto del test rappresenti adeguatamente il dominio del costrutto da misurare.\nProve Basate sui Processi di Risposta: Analizzano se i processi cognitivi e comportamentali degli esaminandi riflettono il costrutto valutato.\nProve Basate sulla Struttura Interna: Esaminano la coerenza tra gli elementi del test e la struttura teorica del costrutto. L’analisi fattoriale è uno strumento chiave in questo contesto.\nProve Basate sulle Relazioni con Altre Variabili: Studiano la correlazione tra i punteggi del test e altre variabili teoricamente correlate, utilizzando metodi come la validità convergente e divergente.\nProve Basate sulle Conseguenze del Test: Considerano le implicazioni e gli effetti dell’uso del test, sia intenzionali che non intenzionali.\n\n\n\n13.7.4 Minacce alla Validità\nLa validità può essere compromessa quando un test non misura integralmente il costrutto di interesse (sotto-rappresentazione del costrutto) o quando include varianza estranea al costrutto. Inoltre, fattori esterni come l’ansia o la bassa motivazione degli esaminandi, e deviazioni nelle procedure di amministrazione e valutazione, possono influenzare negativamente la validità delle interpretazioni dei risultati.\n\n\n13.7.5 Integrazione delle Prove di Validità\nLa validità di un test si costruisce attraverso l’integrazione di diverse linee di evidenza. Ogni interpretazione o uso di un test deve essere validato specificamente, richiedendo una valutazione continua e accurata delle prove disponibili. Questo processo implica la costruzione di un argomento di validità che consideri attentamente la qualità tecnica del test e l’adeguatezza delle sue interpretazioni per gli scopi previsti.\nIn conclusione, la validità è un concetto complesso e integrato che richiede un’analisi continua e multidimensionale delle evidenze. La moderna teoria della validità enfatizza l’importanza di considerare diverse forme di evidenza per supportare le interpretazioni dei punteggi dei test, garantendo che siano utilizzati in modo appropriato e significativo. Gli sviluppatori e gli utilizzatori di test devono impegnarsi a valutare costantemente la validità per assicurare misurazioni psicologiche accurate e affidabili.\n\n\n13.7.6 Affidabilità\nL’affidabilità concerne la consistenza e stabilità delle misurazioni, verificata attraverso metodi come l’affidabilità test-retest, inter-rater, intra-rater e l’affidabilità interna.\n\nAffidabilità Test-Retest: Questa forma di affidabilità verifica la consistenza delle misurazioni nel tempo. Se un individuo viene testato in due momenti diversi, i risultati dovrebbero essere simili, assumendo che non ci siano stati cambiamenti significativi nel costrutto misurato.\nAffidabilità Inter-rater: In questo caso, l’affidabilità è determinata dalla concordanza tra le valutazioni di diversi esaminatori. Ad esempio, se più psicologi dovessero valutare un individuo utilizzando lo stesso strumento, le loro valutazioni dovrebbero essere simili.\nAffidabilità Intra-rater: Questa misura dell’affidabilità si riferisce alla consistenza delle valutazioni dello stesso esaminatore in momenti diversi.\nAffidabilità Interna: Si riferisce alla coerenza delle risposte all’interno dello stesso test. Ad esempio, se un test misura un costrutto come l’ansia, gli item che misurano l’ansia dovrebbero correlare positivamente l’uno con l’altro. Un modo comune per valutare l’affidabilità interna è utilizzare il coefficiente \\(\\omega\\) di McDonald.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "href": "chapters/key_notions/02_measurement.html#commenti-e-considerazioni-finali",
    "title": "13  La misurazione in psicologia",
    "section": "13.8 Commenti e considerazioni finali",
    "text": "13.8 Commenti e considerazioni finali\nLa teoria della misurazione è fondamentale nella ricerca empirica per valutare l’attendibilità e la validità delle misurazioni. È cruciale valutare l’errore nella misurazione per garantire la precisione e l’accuratezza delle misure. L’assessment psicometrico si occupa di valutare la qualità delle misurazioni psicologiche, considerando l’affidabilità e la validità per garantire misure accurate dei costrutti teorici. Le moderne tecnologie e metodologie stanno continuamente arricchendo questo campo, offrendo strumenti sempre più raffinati per la comprensione delle caratteristiche psicologiche.\n\n\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological measurement and the replication crisis: Four sacred cows. Canadian Psychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the philosophical foundations of psychological measurement. Measurement, 79, 311–320.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677–680.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>La misurazione in psicologia</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html",
    "href": "chapters/key_notions/03_data_analysis.html",
    "title": "14  L’analisi dei dati psicologici",
    "section": "",
    "text": "Introduzione\nNel panorama contemporaneo delle scienze sociali e della psicologia, gli ultimi due decenni hanno visto l’emergere di una profonda trasformazione metodologica ed epistemologica. Questo movimento, caratterizzato da concetti chiave quali “Credibility Revolution” (Angrist & Pischke, 2010), “Causal Revolution” (Pearl & Mackenzie, 2018) e “Replication Crisis” (Collaboration, 2015), ha determinato un cambiamento paradigmatico nelle pratiche delle scienze sociali e, in particolare, della psicologia (Korbmacher et al., 2023). Questa transizione verso quella che Munger (2023) definisce “Science versione 2” è stata motivata dalle lacune metodologiche precedenti e ha catalizzato l’adozione di approcci più rigorosi e replicabili.\nLa genesi di questa Riforma è radicata nella constatazione di problematiche metodologiche pervasive, tra cui la proliferazione di falsi positivi (Simmons et al., 2011), l’abuso dei “gradi di libertà dei ricercatori” (Gelman & Loken, 2013), e l’inadeguatezza delle pratiche statistiche tradizionali (Gelman & Loken, 2014). Fenomeni come il p-hacking, l’uso di campioni sottodimensionati (Button et al., 2013), e la mancanza di trasparenza nei metodi di ricerca hanno contribuito a minare la credibilità delle scoperte psicologiche (Ioannidis, 2005; Meehl, 1967), portando alla cosiddetta “Replication Crisis” (Baker, 2016; Bishop, 2019) – si veda il Capitolo 116.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano",
    "title": "14  L’analisi dei dati psicologici",
    "section": "14.1 L’Approccio Bayesiano",
    "text": "14.1 L’Approccio Bayesiano\nIn risposta a queste sfide, l’approccio bayesiano è emerso come un paradigma statistico fondamentale nella “Credibility Revolution”. Contrariamente all’inferenza frequentista basata sul Test dell’Ipotesi Nulla, la statistica bayesiana offre un framework più flessibile e intuitivo per l’analisi dei dati e l’inferenza causale. Il principio cardine dell’approccio bayesiano, l’aggiornamento delle distribuzioni di probabilità a priori (priors) alla luce di nuove evidenze, si allinea perfettamente con l’obiettivo di una scienza cumulativa e auto-correttiva.\nL’adozione di metodi bayesiani in psicologia comporta diversi vantaggi significativi:\n\nQuantificazione dell’incertezza: L’inferenza bayesiana fornisce distribuzioni di probabilità posteriori complete per i parametri di interesse, offrendo una rappresentazione più ricca e sfumata dell’incertezza rispetto agli intervalli di confidenza frequentisti.\nIncorporazione di conoscenze pregresse: Le priors bayesiane consentono l’integrazione formale di conoscenze precedenti nel processo inferenziale, promuovendo un approccio cumulativo alla ricerca.\nRobustezza alle pratiche di ricerca discutibili: I metodi bayesiani sono meno suscettibili a pratiche come il p-hacking, poiché l’inferenza si basa sull’intera distribuzione posteriore piuttosto che su soglie arbitrarie di significatività.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano-nella-ricerca",
    "href": "chapters/key_notions/03_data_analysis.html#lapproccio-bayesiano-nella-ricerca",
    "title": "14  L’analisi dei dati psicologici",
    "section": "14.2 L’approccio bayesiano nella ricerca",
    "text": "14.2 L’approccio bayesiano nella ricerca\nL’impiego delle statistiche bayesiane nella ricerca psicologica presenta notevoli vantaggi rispetto ad altri metodi statistici tradizionali, come il test di significatività dell’ipotesi nulla. Un punto di forza importante risiede nella sua indipendenza dalla teoria dei grandi campioni, rendendolo particolarmente adatto per gli studi psicologici che spesso si basano su campioni di dimensioni ridotte (Larson et al., 2023).\nLa ricerca psicologica è frequentemente caratterizzata da campioni limitati, dovuti a diversi fattori quali la bassa prevalenza di determinate condizioni, le difficoltà nel reclutamento dei partecipanti e le complessità nelle procedure di valutazione. Questi campioni di piccole dimensioni sono intrinsecamente soggetti a una maggiore eterogeneità, che si manifesta nella variabilità del fenotipo comportamentale delle condizioni psicologiche esaminate e nella discrepanza tra le stime degli effetti in diversi studi. Tale eterogeneità può condurre a stime degli effetti distorte e scarsamente riproducibili.\nL’approccio bayesiano offre una soluzione efficace a queste problematiche. In primo luogo, consente di valutare l’adeguatezza della dimensione del campione attraverso un’analisi della sensibilità dei risultati rispetto alla specificazione delle distribuzioni a priori. In secondo luogo, permette di ottenere risultati precisi anche con campioni ridotti, a condizione che le conoscenze a priori siano accurate e ben definite.\nUn ulteriore vantaggio dell’approccio bayesiano è la sua capacità di ottimizzare l’uso dei campioni di partecipanti, favorendo un’inclusione equa delle popolazioni diversificate. Questo è particolarmente rilevante per gruppi spesso sottorappresentati, come le minoranze etniche. Le statistiche bayesiane aiutano a superare questa sfida evitando di esercitare una pressione eccessiva su questi gruppi per aumentarne la partecipazione, permettendo così una ricerca più equa e rappresentativa.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "href": "chapters/key_notions/03_data_analysis.html#modellazione-formale",
    "title": "14  L’analisi dei dati psicologici",
    "section": "14.3 Modellazione Formale",
    "text": "14.3 Modellazione Formale\nLa “Credibility Revolution” ha catalizzato l’integrazione della Data Science nelle pratiche di ricerca psicologica. L’adozione di pipeline di analisi dei dati riproducibili, l’uso di controllo di versione, e la condivisione di dati e codice sono diventati standard de facto nella comunità scientifica. Questi strumenti non solo migliorano la trasparenza e la replicabilità della ricerca, ma facilitano anche la collaborazione e l’accumulo di conoscenze nel campo.\nParallelamente, si è osservato un rinnovato interesse per la modellazione formale in psicologia, che consente non solo la verifica ma anche lo sviluppo di modelli dei meccanismi sottostanti ai fenomeni psicologici (Oberauer & Lewandowsky, 2019; Van Dongen et al., 2024). Questo approccio supera la mera descrizione delle associazioni tra variabili, che era tipica della pratica dominante dell’ANOVA nel contesto pre-riforma.\nLa modellazione bayesiana si presta particolarmente bene a questo approccio, offrendo un framework unificato per la specificazione di modelli formali, l’incorporazione di incertezza parametrica, e la valutazione dell’evidenza empirica. Attraverso tecniche come il confronto tra modelli bayesiano e l’analisi di sensibilità, i ricercatori possono valutare rigorosamente la plausibilità relativa di diverse teorie psicologiche.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "href": "chapters/key_notions/03_data_analysis.html#riflessioni-epistemologiche",
    "title": "14  L’analisi dei dati psicologici",
    "section": "14.4 Riflessioni Epistemologiche",
    "text": "14.4 Riflessioni Epistemologiche\nL’adozione di metodi bayesiani e della Data Science in psicologia deve essere accompagnata da una profonda riflessione epistemologica. Come sottolineato da George Box\n\ntutti i modelli sono sbagliati, ma alcuni sono utili.\n\nQuesta massima risuona particolarmente nel contesto della ricerca psicologica, dove i fenomeni di interesse sono spesso complessi e multifattoriali.\nL’approccio bayesiano, con la sua enfasi sull’aggiornamento iterativo delle credenze alla luce di nuove evidenze, si allinea naturalmente con una visione della scienza come processo di apprendimento continuo piuttosto che come ricerca di verità assolute. Questa prospettiva riconosce i limiti intrinseci dei nostri modelli e delle nostre teorie, pur valorizzandone l’utilità euristica e predittiva (si veda la discussione nella Sezione 103.2).\nIn particolare, McElreath (2020) sottolinea l’importanza di riconoscere la dualità tra il “mondo del modello” e il mondo reale più ampio che cerchiamo di comprendere. Questa consapevolezza è cruciale per evitare la reificazione dei nostri modelli statistici e per mantenere una prospettiva critica sulle nostre inferenze.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/key_notions/03_data_analysis.html#conclusione",
    "href": "chapters/key_notions/03_data_analysis.html#conclusione",
    "title": "14  L’analisi dei dati psicologici",
    "section": "14.5 Conclusione",
    "text": "14.5 Conclusione\nL’integrazione dell’approccio bayesiano e della data science nella ricerca psicologica rappresenta una risposta promettente alle sfide poste dalla “Replication Crisis”. Offrendo un framework coerente per la modellazione formale, l’inferenza statistica e l’incorporazione di conoscenze pregresse, questi approcci promettono di elevare il rigore e la credibilità della ricerca psicologica. Tuttavia, è fondamentale che l’adozione di questi metodi sia accompagnata da una adeguata consapevolezza metodologica ed epistemologica – si veda, ad esempio, il Capitolo 87.\n\n\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution in empirical economics: How better research design is taking the con out of econometrics. Journal of economic perspectives, 24(2), 3–30.\n\n\nBaker, M. (2016). 1,500 scientists lift the lid on reproducibility. Nature, 533(7604).\n\n\nBishop, D. (2019). The psychology of experimental psychologists: Overcoming cognitive constraints to improve research.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., & Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo. Adelphi Edizioni spa.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M. (2023). A Bayesian statistics tutorial for clinical research: Prior distributions and meaningful results for small clinical samples. Journal of Clinical Psychology, 79(11), 2602–2624.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A methodological paradox. Philosophy of science, 34(2), 103–115.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research & Politics, 10(3), 20531680231187271.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: the new science of cause and effect. Basic books.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant. Psychological science, 22(11), 1359–1366.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L. van der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D. (2024). Productive explanation: A framework for evaluating explanations in psychological science. Psychological Review.",
    "crumbs": [
      "Fondamenti",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>L'analisi dei dati psicologici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/introduction_eda.html",
    "href": "chapters/eda/introduction_eda.html",
    "title": "Introduzione",
    "section": "",
    "text": "Dopo aver acquisito un dataset, è fondamentale comprendere a fondo le caratteristiche dei dati in esso contenuti. Sebbene le statistiche descrittive e altre misure numeriche siano spesso efficaci per ottenere una visione d’insieme, talvolta è un’immagine a valere più di mille parole.\nIn questa sezione della dispensa, esploreremo alcuni concetti chiave della statistica descrittiva. Oltre a fornire definizioni teoriche, presenteremo istruzioni pratiche in Python per condurre analisi statistiche su dati reali. Il capitolo si concluderà con una riflessione critica sui limiti di un approccio epistemologico basato esclusivamente sull’analisi delle associazioni tra variabili, evidenziando l’importanza di indagare le cause sottostanti ai fenomeni osservati.",
    "crumbs": [
      "EDA",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html",
    "href": "chapters/eda/01_project_structure.html",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "15.1 Introduzione\nSeguendo Yu & Barter (2024), in questo capitolo introdurremo l’analisi esplorativa dei dati situandola all’interno dell’intero ciclo di vita di un progetto di data science (DSLC). Secondo Yu & Barter (2024), ogni progetto di analisi dei dati segue una combinazione delle seguenti fasi:\nMentre quasi tutti i progetti di data science attraversano le fasi 1-2 e 4-5, non tutti includono la fase 3.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#introduzione",
    "href": "chapters/eda/01_project_structure.html#introduzione",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "",
    "text": "Formulazione del problema e raccolta dei dati.\nPulizia dei dati, preprocessing e analisi esplorativa.\nAnalisi predittiva e/o inferenziale.\nValutazione dei risultati.\nComunicazione dei risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-1-formulazione-del-problema-e-raccolta-dei-dati",
    "href": "chapters/eda/01_project_structure.html#fase-1-formulazione-del-problema-e-raccolta-dei-dati",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "15.2 Fase 1: Formulazione del Problema e Raccolta dei Dati",
    "text": "15.2 Fase 1: Formulazione del Problema e Raccolta dei Dati\nLa formulazione di una domanda di ricerca precisa è il punto di partenza di ogni progetto di data science. È cruciale che la domanda sia formulata in modo tale da poter essere risolta attraverso l’analisi dei dati disponibili. Alle volte la domanda iniziale è troppo vaga o non risolvibile. L’obiettivo è riformulare la domanda in modo tale che possa trovare una risposta utilizzando i dati a disposizione.\n\n15.2.1 Raccolta dei Dati\nAlcuni progetti utilizzano dati esistenti (da repository pubblici, database interni o esperimenti passati), mentre altri richiedono la raccolta di nuovi dati. Ogni volta che è possibile, è necessario avere ben chiaro quali analisi statistiche verranno svolte prima di raccogliere i dati. Se questo non viene fatto, può succedere che i dati raccolti non siano adeguati per rispondere alle domande di interesse, in quanto mancano informazioni cruciali, o vengono violate assunzioni richieste dai modelli statistici che si vogliono impiegare.\nÈ fondamentale sviluppare una comprensione approfondita dei processi di acquisizione dei dati e del significato delle misure ottenute. Parallelamente, è cruciale essere pienamente consapevoli degli strumenti e delle metodologie impiegate nella raccolta dei dati. In altri termini, è essenziale riconoscere e valutare i potenziali bias che possono emergere dalle tecniche e dalle procedure adottate durante il processo di raccolta dati.\n\n\n15.2.2 Terminologia dei Dati\nIn una matrice di dati (comunemente denominata “dataset”), ogni colonna rappresenta una diversa tipologia di misurazione, definita come variabile, carattere o attributo. In alcuni contesti, specialmente nell’analisi di regressione, queste possono essere anche chiamate covariate.\nGeneralmente, le variabili in un dataset si classificano in una delle seguenti categorie:\n\nQuantitative:\n\nContinue: Valori che possono assumere qualsiasi numero reale all’interno di un intervallo (es. importo di spesa, durata di permanenza su un sito web).\nDiscrete: Valori numerici interi, spesso risultato di conteggi (es. numero di visitatori di un sito web in un determinato periodo, numero di esemplari di una specie in una data località).\n\nQualitative (o Categoriche):\n\nNominali: Categorie senza un ordine intrinseco (es. partito politico, reparto ospedaliero, nazione).\nOrdinali: Categorie con un ordine naturale ma senza una metrica definita tra i livelli (es. livello di istruzione, grado di soddisfazione).\n\nTemporali: Date e orari in vari formati (es. “01/01/2020 23:00:05” o “1 gen 2020”).\nTestuali:\n\nStrutturate: Testo con formato predefinito (es. nominativo, indirizzo postale, email).\nNon strutturate: Corpo di testo esteso senza struttura predefinita (es. cartelle cliniche, recensioni, post sui social media).\n\n\nLa dimensionalità dei dati si riferisce al numero di variabili (colonne) presenti nel dataset. Si parla di “dati ad alta dimensionalità” quando il numero di variabili è elevato (generalmente superiore a 100, sebbene non esista una soglia universalmente accettata).\nOgni riga del dataset corrisponde a una singola unità statistica, anche detta caso o osservazione. Queste rappresentano le entità su cui vengono effettuate le misurazioni.\nQuesta struttura, in cui i dati sono organizzati in colonne (variabili) e righe (unità statistiche), viene definita come matrice dei dati o, in ambito informatico, come formato tabellare.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-2-pulizia-dei-dati-e-analisi-esplorativa",
    "href": "chapters/eda/01_project_structure.html#fase-2-pulizia-dei-dati-e-analisi-esplorativa",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "15.3 Fase 2: Pulizia dei Dati e Analisi Esplorativa",
    "text": "15.3 Fase 2: Pulizia dei Dati e Analisi Esplorativa\n\n15.3.1 Pulizia dei Dati\nDopo aver definito la domanda della ricerca e avere raccolto i dati rilevanti, è il momento di pulire i dati. Un dataset pulito è ordinato, formattato in modo appropriato e ha voci non ambigue. La fase iniziale di pulizia dei dati consiste nell’identificare problemi con i dati (come formattazioni anomale e valori non validi) e modificarli in modo che i valori siano validi e formattati in modo comprensibile sia per il computer che per noi. La pulizia dei dati è una fase estremamente importante di un progetto di data science perché non solo aiuta a garantire che i dati siano interpretati correttamente dal computer, ma aiuta anche a sviluppare una comprensione dettagliata delle informazioni contenute nei dati e delle loro limitazioni.\nL’obiettivo della pulizia dei dati è creare una versione dei dati che rifletta nella maniera più fedele possibile la realtà e che sia interpretata correttamente dal computer. Per garantire che il computer utilizzi fedelmente le informazioni contenute nei dati, è necessario modificare i dati (scrivendo codice, non modificando il file dati grezzo stesso) in modo che siano in linea con ciò che il computer “si aspetta”. Tuttavia, il processo di pulizia dei dati è necessariamente soggettivo e comporta fare assunzioni sulle quantità reali sottostanti misurate e decisioni su quali modifiche siano le più sensate.\n\n\n15.3.2 Preprocessing\nIl preprocessing si riferisce al processo di modifica dei dati puliti per soddisfare i requisiti di un algoritmo specifico che si desidera applicare. Ad esempio, se si utilizza un algoritmo che richiede che le variabili siano sulla stessa scala, potrebbe essere necessario trasformarle, oppure, se si utilizza un algoritmo che non consente valori mancanti, potrebbe essere necessario imputarli o rimuoverli. Durante il preprocessing, potrebbe essere utile anche definire nuove caratteristiche/variabili utilizzando le informazioni esistenti nei dati, se si ritiene che queste possano essere utili per l’analisi.\nCome per la pulizia dei dati, non esiste un unico modo corretto per pre-elaborare un dataset, e la procedura finale comporta tipicamente una serie di decisioni che dovrebbero essere documentate nel codice e nei file di documentazione.\n\n\n15.3.3 Analisi Esplorativa dei Dati\nDopo l’acquisizione dei dati, si procede con un’analisi approfondita che si articola in due fasi principali:\n\nAnalisi Esplorativa dei Dati (EDA - Exploratory Data Analysis):\nQuesta fase iniziale mira a far familiarizzare il ricercatore con il dataset e a scoprire pattern nascosti. Si realizza attraverso:\n\nLa costruzione di tabelle di frequenza e contingenza\nIl calcolo di statistiche descrittive (come indici di posizione, dispersione e forma della distribuzione)\nLa creazione di rappresentazioni grafiche preliminari\n\nL’EDA permette di generare ipotesi sui dati e di guidare le successive analisi statistiche.\nAnalisi Esplicativa:\nIn questa fase successiva, l’obiettivo è raffinare e perfezionare le analisi per comunicare efficacemente i risultati a un pubblico più ampio. Ciò comporta:\n\nL’ottimizzazione delle tabelle per una maggiore leggibilità\nIl perfezionamento delle visualizzazioni grafiche per una comunicazione chiara ed efficace\nLa selezione delle statistiche più rilevanti per supportare le conclusioni\n\nL’analisi esplicativa si concentra sulla presentazione chiara e convincente dei risultati, adattando il livello di dettaglio e il linguaggio al pubblico di riferimento.\n\nEntrambe le fasi sono cruciali: l’EDA consente di comprendere a fondo la struttura e le caratteristiche dei dati, mentre l’analisi esplicativa assicura che le scoperte siano comunicate in modo efficace e comprensibile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-3-analisi-predittiva-e-inferenziale",
    "href": "chapters/eda/01_project_structure.html#fase-3-analisi-predittiva-e-inferenziale",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "15.4 Fase 3: Analisi Predittiva e Inferenziale",
    "text": "15.4 Fase 3: Analisi Predittiva e Inferenziale\nMolte domande nella data science si presentano come problemi di inferenza e/o previsione, in cui l’obiettivo principale è utilizzare dati osservati, passati o presenti, per descrivere le caratteristiche di una popolazione più ampia o per fare previsioni su dati futuri non ancora disponibili. Questo tipo di analisi è spesso orientato a supportare decisioni nel mondo reale.\nNel corso, ci concentreremo principalmente sull’approccio bayesiano per affrontare questi problemi inferenziali, fornendo un’introduzione a come tale prospettiva possa essere applicata efficacemente in questo contesto.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-4-valutazione-dei-risultati",
    "href": "chapters/eda/01_project_structure.html#fase-4-valutazione-dei-risultati",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "15.5 Fase 4: Valutazione dei Risultati",
    "text": "15.5 Fase 4: Valutazione dei Risultati\nIn questa fase, i risultati ottenuti vengono analizzati alla luce della domanda di ricerca iniziale. Si procede a una valutazione sia quantitativa, attraverso l’applicazione di tecniche statistiche appropriate, sia qualitativa, attraverso un’attenta riflessione critica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#fase-5-comunicazione-dei-risultati",
    "href": "chapters/eda/01_project_structure.html#fase-5-comunicazione-dei-risultati",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "15.6 Fase 5: Comunicazione dei Risultati",
    "text": "15.6 Fase 5: Comunicazione dei Risultati\nL’ultima fase di un progetto di analisi dei dati consiste nel condividere i risultati con un pubblico più ampio, il che richiede la preparazione di materiali comunicativi chiari e concisi. L’obiettivo è trasformare i risultati dell’analisi in informazioni utili per supportare il processo decisionale. Questo può includere la stesura di un articolo scientifico, la creazione di un report per un team di lavoro, o la preparazione di una presentazione con diapositive.\nLa comunicazione deve essere adattata al pubblico di riferimento. Non si deve dare per scontato che il pubblico abbia familiarità con il progetto: è fondamentale spiegare l’analisi e le visualizzazioni in modo chiaro e dettagliato. Anche se per il ricercatore il messaggio principale di una figura o diapositiva può sembrare ovvio, è sempre una buona pratica guidare il pubblico nella sua interpretazione, evitando l’uso di gergo tecnico complesso.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "href": "chapters/eda/01_project_structure.html#organizzazione-del-progetto",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "15.7 Organizzazione del Progetto",
    "text": "15.7 Organizzazione del Progetto\nUn requisito fondamentale per un progetto di analisi dei dati è organizzare in modo efficiente i file sul proprio computer. Questo include i file dei dati, il codice e la documentazione del progetto. Tutti questi elementi dovrebbero essere raccolti all’interno di una singola cartella dedicata al progetto. Yu & Barter (2024) propone il seguente template per la struttura di un progetto:\n\nLe due cartelle principali sono:\n\ndata/: contiene il dataset grezzo (ad esempio, data.csv) e una sottocartella con documentazione relativa ai dati, come metadati e codebook.\ndslc_documentation/: raccoglie i file di documentazione e codice necessari per le varie fasi del progetto. Questi possono essere file .qmd (per Quarto, in R) o .ipynb (per Jupyter Notebook, in Python), utilizzati per condurre ed esplorare le analisi. I file sono prefissati da un numero per mantenerli in ordine cronologico. All’interno di questa cartella, è presente una sottocartella functions/, che contiene script .R (per R) o .py (per Python) con funzioni utili per le diverse analisi.\n\nUn file README.md descrive la struttura del progetto e riassume il contenuto di ogni file.\nUn’organizzazione come quella proposta da Yu & Barter (2024) offre un notevole vantaggio: permette di specificare i percorsi dei file in modo relativo, utilizzando come radice la cartella del progetto. Questo rende il progetto facilmente trasferibile e condivisibile tra diversi utenti o computer.\n\nEsempio 15.1 Per esplorare come gestire l’archiviazione dei dati sul computer e importarli in Python, consideriamo i dati raccolti da Zetsche et al. (2019) in uno studio che ha esaminato le aspettative negative come meccanismo chiave nel mantenimento della depressione. In questo studio, i ricercatori hanno confrontato 30 soggetti con episodi depressivi a un gruppo di controllo di 37 individui sani, utilizzando il Beck Depression Inventory (BDI-II) per valutare i livelli di depressione.\nIl file CSV contenente questi dati, così come tutti gli altri file utilizzati in questa dispensa, è memorizzato nella cartella data, situata all’interno della cartella psicometria, che rappresenta la directory principale del progetto.\nCon le istruzioni seguenti, viene specificato il percorso della directory principale del progetto in relazione alla mia directory personale:\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\nprint(project_directory)\n\n/Users/corradocaudek/_repositories/psicometria\n\n\nDopo aver definito project_directory come directory principale, è possibile indicare il percorso del file CSV contenente i dati in modo relativo a project_directory.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"data.mood.csv\")\nprint(file_path)\n\n/Users/corradocaudek/_repositories/psicometria/data/data.mood.csv\n\n\nLa seguente istruzione permette di importare i dati dal file data.mood.csv in un DataFrame di pandas.\n\ndf = pd.read_csv(file_path)\n\nPer conoscere le dimensioni del DataFrame utilizziamo il metodo .shape.\n\ndf.shape\n\n(1188, 44)\n\n\nIl DataFrame ha 1188 righe e 44 colonne. Visualizziamo il nome delle colonne con il metodo .columns.\n\ndf.columns\n\nIndex(['Unnamed: 0', 'vpn_nr', 'esm_id', 'group', 'bildung', 'bdi',\n       'nr_of_episodes', 'nobs_mood', 'trigger_counter', 'form', 'traurig_re',\n       'niedergeschlagen_re', 'unsicher_re', 'nervos_re', 'glucklich_re',\n       'frohlich_re', 'mood_sad.5', 'mood_fearful.5', 'mood_neg.5',\n       'mood_happy.5', 'cesd_sum', 'rrs_sum', 'rrs_brood', 'rrs_reflect',\n       'forecast_sad', 'forecast_fear', 'forecast_neg', 'forecast_happy',\n       'recall_sad', 'recall_fear', 'recall_neg', 'recall_happy',\n       'diff_neg.fore.5', 'diff_sad.fore.5', 'diff_fear.fore.5',\n       'diff_happy.fore.5', 'diff_neg.retro.5', 'diff_sad.retro.5',\n       'diff_fear.retro.5', 'diff_happy.retro.5', 'mood_sad5_tm1',\n       'mood_neg5_tm1', 'mood_fearful5_tm1', 'mood_happy5_tm1'],\n      dtype='object')\n\n\nDato che il DataFrame è troppo grande (1188 righe e 44 colonne), stampiamo sullo schermo solo le prime 5 righe.\n\ndf.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nvpn_nr\nesm_id\ngroup\nbildung\nbdi\nnr_of_episodes\nnobs_mood\ntrigger_counter\nform\n...\ndiff_fear.fore.5\ndiff_happy.fore.5\ndiff_neg.retro.5\ndiff_sad.retro.5\ndiff_fear.retro.5\ndiff_happy.retro.5\nmood_sad5_tm1\nmood_neg5_tm1\nmood_fearful5_tm1\nmood_happy5_tm1\n\n\n\n\n0\n1\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n5\nForecasting\n...\n0.333333\n-1.000000\n0.250000\n0.166667\n0.333333\n-1.000000\nNaN\nNaN\nNaN\nNaN\n\n\n1\n2\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n6\nForecasting\n...\n-0.666667\n-0.333333\n-0.416667\n-0.166667\n-0.666667\n-0.333333\n3.333333\n3.000000\n2.666667\n3.000000\n\n\n2\n3\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n7\nForecasting\n...\n0.666667\n-0.666667\n1.250000\n1.833333\n0.666667\n-0.666667\n3.666667\n3.666667\n3.666667\n2.333333\n\n\n3\n4\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n8\nForecasting\n...\n-0.333333\n-0.666667\n0.083333\n0.500000\n-0.333333\n-0.666667\n1.666667\n2.000000\n2.333333\n2.666667\n\n\n4\n5\n101\n10\nmdd\nabitur\n25.0\n2.0\n14\n10\nForecasting\n...\n0.333333\n-1.000000\n0.416667\n0.500000\n0.333333\n-1.000000\n3.000000\n3.166667\n3.333333\n2.666667\n\n\n\n\n5 rows × 44 columns",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "href": "chapters/eda/01_project_structure.html#riflessioni-conclusive",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "15.8 Riflessioni Conclusive",
    "text": "15.8 Riflessioni Conclusive\nLa bellezza del codice risiede nella sua riusabilità: una volta scritto, può essere utilizzato tutte le volte che si desidera. Se configurato correttamente, lo stesso codice applicato agli stessi dati produrrà sempre gli stessi risultati. Questo principio, noto come riproducibilità computazionale, offre numerosi vantaggi.\n\nTracciare le modifiche al progetto: La riproducibilità semplifica il monitoraggio delle evoluzioni e dei cambiamenti nel progetto, permettendo di vedere come si sviluppa nel tempo.\nRiprodurre il proprio lavoro: L’utente più interessato alla riproducibilità sei tu stesso. La capacità di replicare i risultati è una caratteristica essenziale, poiché in futuro potresti aver bisogno di riprendere in mano il lavoro e comprenderne i dettagli. La riproducibilità rende questo processo molto più semplice.\nCostruire su basi solide: Anche altri ricercatori possono utilizzare il tuo lavoro come punto di partenza, espandendo e approfondendo le conoscenze che hai contribuito a sviluppare.\n\nTuttavia, rendere il codice riproducibile è più difficile di quanto sembri. In questo capitolo abbiamo esplorato alcuni metodi che possono aiutare a raggiungere questo obiettivo.\n\n\n\n\n\n\nUno dei problemi più importanti nella psicologia contemporanea è la crisi di replicabilità: molti risultati di ricerca non sono replicabili (Collaboration, 2015). La riproducibilità computazionale si concentra su un obiettivo più ristretto: ottenere gli stessi risultati utilizzando lo stesso codice sugli stessi dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/01_project_structure.html#informazioni-sullambiente-di-sviluppo",
    "title": "15  Le fasi del progetto di analisi dei dati",
    "section": "15.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "15.9 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Aug 01 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The practice of responsible data analysis and decision making. MIT Press.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Le fasi del progetto di analisi dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html",
    "href": "chapters/eda/02_data_cleaning.html",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "16.1 Introduzione\nNonostante la fase più interessante di un progetto di analisi dei dati sia quella in cui si riesce a rispondere alla domanda che ha dato avvio all’indagine, gran parte del tempo di un analista è in realtà dedicata a una fase preliminare: la pulizia e il preprocessing dei dati, operazioni che vengono svolte ancor prima dell’analisi esplorativa.\nIn questo capitolo, esamineremo un caso concreto di data cleaning e preprocessing, seguendo il tutorial di Crystal Lewis. Il problema viene presentato come segue:\nCrystal Lewis elenca i seguenti passaggi da seguire nel processo di data cleaning:\nSebbene l’ordine di questi passaggi sia flessibile e possa essere adattato alle esigenze specifiche, c’è un passaggio che non dovrebbe mai essere saltato: il primo, ovvero la revisione dei dati. Senza una revisione preliminare, l’analista rischia di sprecare ore a pulire i dati per poi scoprire che mancano dei partecipanti, che i dati non sono organizzati come previsto o, peggio ancora, che sta lavorando con i dati sbagliati.\nEsamineremo questi passaggi seguendo il tutorial di Crystal Lewis.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#introduzione",
    "href": "chapters/eda/02_data_cleaning.html#introduzione",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "",
    "text": "I am managing data for a longitudinal randomized controlled trial (RCT) study. For this RCT, schools are randomized to either a treatment or control group. Students who are in a treatment school receive a program to boost their math self-efficacy. Data is collected on all students in two waves (wave 1 is in the fall of a school year, and wave 2 is collected in the spring). At this point in time, we have collected wave 1 of our student survey on a paper form and we set up a data entry database for staff to enter the information into. Data has been double-entered, checked for entry errors, and has been exported in a csv format (“w1_mathproj_stu_svy_raw.csv”) to a folder (called “data”) where it is waiting to be cleaned.\n\n\n\nRevisione dei dati.\nRegolazione del numero di casi.\nDe-identificazione dei dati.\nEliminazione delle colonne irrilevanti.\nDivisione delle colonne, se necessario.\nRidenominazione delle variabili.\nTrasformazione/normalizzazione delle variabili.\nStandardizzazione delle variabili.\nAggiornamento dei tipi di variabili, se necessario.\nRicodifica delle variabili.\nCreazione di eventuali variabili necessarie.\nGestione dei valori mancanti, se necessario.\nAggiunta di metadati, se necessario.\nValidazione dei dati.\nFusione e/o unione dei dati, se necessario.\nTrasformazione dei dati, se necessario.\nSalvataggio dei dati puliti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#importare-i-dati",
    "href": "chapters/eda/02_data_cleaning.html#importare-i-dati",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.2 Importare i Dati",
    "text": "16.2 Importare i Dati\nI dati grezzi non dovrebbero mai essere modificati direttamente. È consigliabile organizzare i dati in una struttura di cartelle all’interno di una directory chiamata data, che contiene due sottocartelle: raw e processed. I dati originali, non ancora elaborati, devono essere conservati nella cartella raw e mantenuti inalterati. I dati ripuliti e preprocessati, invece, devono essere salvati nella cartella processed.\nPer fare un esempio, importiamo i dati dal file w1_mathproj_stu_svy_raw.csv e iniziamo il processo di pulizia. È importante notare che tutte le istruzioni sono formulate in modo relativo alla home directory del progetto. Prima di tutto, definiamo il percorso della home directory del progetto.\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\nprint(project_directory)\n\n/Users/corradocaudek/_repositories/psicometria\n\n\nSpecifichiamo il percorso del file da importare rispetto alla home directory del progetto.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"w1_mathproj_stu_svy_raw.csv\")\nprint(file_path)\n\n/Users/corradocaudek/_repositories/psicometria/data/w1_mathproj_stu_svy_raw.csv",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#esaminare-i-dati",
    "href": "chapters/eda/02_data_cleaning.html#esaminare-i-dati",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.3 (1) Esaminare i Dati",
    "text": "16.3 (1) Esaminare i Dati\nProcediamo con l’importazione dei dati.\n\nsvy = pd.read_csv(file_path)\nsvy.shape\n\n(6, 7)\n\n\nÈ fondamentale esaminare visivamente le prime o le ultime righe del data frame per verificare che i dati siano stati importati correttamente.\n\nsvy.head()\n\n\n\n\n\n\n\n\nstu_id\nsvy_date\ngrade_level\nmath1\nmath2\nmath3\nmath4\n\n\n\n\n0\n1347\n2023-02-13\n9\n2\n1\n3.0\n3.0\n\n\n1\n1368\n2023-02-13\n10\n3\n2\n2.0\n2.0\n\n\n2\n1377\n2023-02-13\n9\n4\n4\n4.0\n4.0\n\n\n3\n1387\n2023-02-13\n11\n3\n3\nNaN\nNaN\n\n\n4\n1347\n2023-02-14\n9\n2\n2\n4.0\n2.0\n\n\n\n\n\n\n\n\nsvy.tail()\n\n\n\n\n\n\n\n\nstu_id\nsvy_date\ngrade_level\nmath1\nmath2\nmath3\nmath4\n\n\n\n\n1\n1368\n2023-02-13\n10\n3\n2\n2.0\n2.0\n\n\n2\n1377\n2023-02-13\n9\n4\n4\n4.0\n4.0\n\n\n3\n1387\n2023-02-13\n11\n3\n3\nNaN\nNaN\n\n\n4\n1347\n2023-02-14\n9\n2\n2\n4.0\n2.0\n\n\n5\n1399\n2023-02-14\n12\n4\n1\n3.0\n1.0",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#modifica-i-casi-secondo-necessità",
    "href": "chapters/eda/02_data_cleaning.html#modifica-i-casi-secondo-necessità",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.4 (2) Modifica i casi secondo necessità",
    "text": "16.4 (2) Modifica i casi secondo necessità\nIl secondo passo è quello in cui vengono fatte delle semplici ma necessarie modifiche al data frame. Crystal Lewis descrive così questo passo per i dati in esame:\n\nVerificare la presenza di duplicati - Il record 1347 è duplicato.\nRimuovere i duplicati.\nOrdinare per svy_date in ordine crescente.\nEsaminare i dati dopo aver rimosso i duplicati.\n\n\n# Trova i duplicati basati su 'stu_id'\nduplicates = svy[svy.duplicated(\"stu_id\", keep=False)]\n\n# Ordina per 'svy_date' in ordine crescente e rimuovi i duplicati mantenendo il primo\nsvy = svy.sort_values(\"svy_date\").drop_duplicates(\"stu_id\", keep=\"first\")\n\n# Mostra il DataFrame finale\nprint(svy)\n\n   stu_id    svy_date  grade_level  math1  math2  math3  math4\n0    1347  2023-02-13            9      2      1    3.0    3.0\n1    1368  2023-02-13           10      3      2    2.0    2.0\n2    1377  2023-02-13            9      4      4    4.0    4.0\n3    1387  2023-02-13           11      3      3    NaN    NaN\n5    1399  2023-02-14           12      4      1    3.0    1.0\n\n\n\nsvy.shape\n\n(5, 7)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#de-identificazione-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#de-identificazione-dei-dati",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.5 (3) De-identificazione dei Dati",
    "text": "16.5 (3) De-identificazione dei Dati\n\n# Rimuovi la colonna 'svy_date'\nsvy = svy.drop(columns=[\"svy_date\"])\n\n# Mostra i nomi delle colonne rimaste\nsvy.columns\n\nIndex(['stu_id', 'grade_level', 'math1', 'math2', 'math3', 'math4'], dtype='object')",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#rimuovere-le-colonne-non-necessarie",
    "href": "chapters/eda/02_data_cleaning.html#rimuovere-le-colonne-non-necessarie",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.6 (4) Rimuovere le Colonne non Necessarie",
    "text": "16.6 (4) Rimuovere le Colonne non Necessarie\nNel caso presente, la rimozione di colonne non è necessaria. Tuttavia, in molti progetti di analisi dei dati, soprattutto quando i dati vengono raccolti utilizzando software di terze parti o strumenti specifici per esperimenti psicologici, è comune trovarsi con colonne che non sono pertinenti allo studio in corso.\nQueste colonne possono includere dati come identificatori interni, timestamp generati automaticamente, informazioni di debug, o variabili che non sono rilevanti per l’analisi che si intende condurre. Quando tali colonne sono irrilevanti per la ricerca, possono essere rimosse per semplificare il dataset e ridurre il rischio di confusione o errori durante l’analisi. Rimuovere le colonne non necessarie non solo rende il dataset più gestibile, ma aiuta anche a focalizzare l’analisi sulle variabili che realmente importano per rispondere alle domande di ricerca.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dividere-le-colonne-secondo-necessità",
    "href": "chapters/eda/02_data_cleaning.html#dividere-le-colonne-secondo-necessità",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.7 (5) Dividere le Colonne Secondo Necessità",
    "text": "16.7 (5) Dividere le Colonne Secondo Necessità\nNel caso presente, questa operazione non è necessaria. Tuttavia, se si lavora con un dataset che include una colonna chiamata “NomeCompleto”, contenente sia il nome che il cognome di uno studente, è buona pratica separare questa colonna in due colonne distinte, “Nome” e “Cognome”. Questa suddivisione facilita l’analisi e la manipolazione dei dati, rendendoli più organizzati e accessibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#rinominare-le-colonne",
    "href": "chapters/eda/02_data_cleaning.html#rinominare-le-colonne",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.8 (6) Rinominare le Colonne",
    "text": "16.8 (6) Rinominare le Colonne\nÈ importante assegnare nomi chiari alle colonne del dataset. Utilizzare nomi di variabili comprensibili aiuta a rendere l’analisi dei dati più intuitiva e a ridurre il rischio di errori interpretativi.\nEsempi di buone pratiche:\n\nEvita nomi di colonne come “x” o acronimi incomprensibili. Questi possono creare confusione durante l’analisi, specialmente se il dataset viene condiviso con altri ricercatori o se viene ripreso dopo un lungo periodo di tempo.\nInvece, cerca di utilizzare nomi di variabili che descrivano chiaramente il contenuto della colonna. Ad esempio, invece di “x1” o “VAR123”, un nome come “ansia_base” o “liv_autoefficacia” è molto più comprensibile e immediato.\nPer i nomi composti, utilizza un separatore come il trattino basso _. Ad esempio, se stai lavorando con dati relativi a un test psicologico, potresti avere colonne chiamate “test_ansia_pre” e “test_ansia_post” per indicare i risultati del test di ansia prima e dopo un intervento.\n\nEsempi di nomi di colonne ben scelti:\n\nNome generico: TS, AE\n\nNome migliore: tempo_studio, auto_efficacia\n\nNome generico: S1, S2\n\nNome migliore: stress_situazione1, stress_situazione2\n\nNome generico: Q1, Q2\n\nNome migliore: qualità_sonno_sett1, qualità_sonno_sett2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#trasformare-le-variabili",
    "href": "chapters/eda/02_data_cleaning.html#trasformare-le-variabili",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.9 (7) Trasformare le Variabili",
    "text": "16.9 (7) Trasformare le Variabili\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di trasformazione delle variabili:\n\nLogaritmo di una variabile: Immaginiamo di avere una variabile che misura i tempi di reazione dei partecipanti a un esperimento. Se i tempi di reazione hanno una distribuzione fortemente asimmetrica (con alcuni valori molto elevati), potrebbe essere utile applicare una trasformazione logaritmica per rendere la distribuzione più simmetrica e migliorare l’interpretabilità dei risultati.\nCodifica delle variabili categoriche: Se è presente una variabile categorica come il “tipo di intervento” con valori come “cognitivo”, “comportamentale” e “farmacologico”, potrebbe essere necessario trasformare questa variabile in variabili dummy (ad esempio, intervento_cognitivo, intervento_comportamentale, intervento_farmacologico), dove ogni variabile assume il valore 0 o 1 a seconda della presenza o meno di quel tipo di intervento. Questo è utile quando si utilizzano tecniche di regressione.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#standardizzare-normalizzare-le-variabili",
    "href": "chapters/eda/02_data_cleaning.html#standardizzare-normalizzare-le-variabili",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.10 (8) Standardizzare / Normalizzare le Variabili",
    "text": "16.10 (8) Standardizzare / Normalizzare le Variabili\nNel caso presente non si applica, ma è un passo importante in molte analisi dei dati.\nEsempi di standardizzazione delle variabili:\n\nStandardizzazione dei punteggi: Supponiamo di avere una variabile che misura il livello di ansia su una scala da 0 a 100. Se desideriamo confrontare i livelli di ansia tra diversi gruppi o includere questa variabile in un modello di regressione, potrebbe essere utile standardizzare i punteggi (cioè, sottrarre la media e dividere per la deviazione standard) per ottenere una variabile con media 0 e deviazione standard 1. Questo processo rende i punteggi comparabili e facilita l’interpretazione dei coefficienti in un modello di regressione.\nNormalizzazione delle variabili: Se hai dati su diverse variabili come “ore di sonno”, “livello di stress” e “auto-efficacia”, e queste variabili hanno scale molto diverse, potrebbe essere utile normalizzarle (ad esempio, ridimensionarle tutte su una scala da 0 a 1) per garantire che abbiano lo stesso peso in un’analisi multivariata.\n\nTrasformare e standardizzare le variabili sono passaggi cruciali in molte analisi psicologiche, specialmente quando si confrontano dati provenienti da diverse fonti o gruppi. Questi processi aiutano a garantire che le variabili siano trattate in modo appropriato e che i risultati dell’analisi siano validi e interpretabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#aggiornare-i-tipi-delle-variabili",
    "href": "chapters/eda/02_data_cleaning.html#aggiornare-i-tipi-delle-variabili",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.11 (9) Aggiornare i Tipi delle Variabili",
    "text": "16.11 (9) Aggiornare i Tipi delle Variabili\nNel caso presente non è necessario. Supponiamo invece di avere una colonna in un dataset psicologico che contiene punteggi di un questionario, ma i dati sono stati importati come stringhe (testo) invece che come numeri. Per eseguire calcoli statistici, sarà necessario convertire questa colonna da stringa a numerico.\nIn Python, utilizzando pandas, potresti farlo con il seguente codice:\nimport pandas as pd\n\n# Supponiamo di avere un DataFrame chiamato 'df' con una colonna 'punteggio' che è stata importata come stringa\ndf['punteggio'] = pd.to_numeric(df['punteggio'], errors='coerce')\n\n# Ora la colonna 'punteggio' è stata convertita in un tipo numerico e puoi eseguire calcoli su di essa\nIn questo esempio, la funzione pd.to_numeric viene utilizzata per convertire la colonna punteggio in un formato numerico, permettendo di eseguire analisi quantitative sui dati. L’opzione errors='coerce' trasforma eventuali valori non convertibili in NaN, garantendo che i dati errati non compromettano le analisi.\nUn altro caso molto comune si verifica quando si importano dati da file Excel. Spesso capita che, all’interno di una cella di una colonna che dovrebbe contenere solo valori numerici, venga inserito erroneamente uno o più caratteri alfanumerici. Di conseguenza, l’intera colonna viene interpretata come di tipo alfanumerico, anche se i valori dovrebbero essere numerici. In questi casi, è fondamentale individuare la cella problematica, correggere il valore errato, e poi riconvertire l’intera colonna da alfanumerica a numerica.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#ricodificare-le-variabili",
    "href": "chapters/eda/02_data_cleaning.html#ricodificare-le-variabili",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.12 (10) Ricodificare le Variabili",
    "text": "16.12 (10) Ricodificare le Variabili\nAnche se in questo caso non è necessario, la ricodifica delle variabili è una pratica molto comune nelle analisi dei dati psicologici.\nPer esempio, consideriamo una variabile categoriale con modalità descritte da stringhe poco comprensibili, che vengono ricodificate con nomi più chiari e comprensibili.\nSupponiamo di avere un DataFrame chiamato df con una colonna tipo_intervento che contiene le modalità \"CT\", \"BT\", e \"MT\" per rappresentare rispettivamente “Terapia Cognitiva”, “Terapia Comportamentale” e “Terapia Mista”. Queste abbreviazioni potrebbero non essere immediatamente chiare a chiunque analizzi i dati, quindi decidiamo di ricodificarle con nomi più espliciti. Ecco come farlo in Python utilizzando pandas:\n\n# Supponiamo di avere un DataFrame chiamato 'df' con una colonna 'tipo_intervento'\ndf = pd.DataFrame({\"tipo_intervento\": [\"CT\", \"BT\", \"MT\", \"CT\", \"BT\"]})\n\n# Ricodifica delle modalità della variabile 'tipo_intervento' in nomi più comprensibili\ndf[\"tipo_intervento_ricodificato\"] = df[\"tipo_intervento\"].replace(\n    {\"CT\": \"Terapia Cognitiva\", \n     \"BT\": \"Terapia Comportamentale\", \n     \"MT\": \"Terapia Mista\"\n    }\n)\n\n# Ora la colonna 'tipo_intervento_ricodificato' contiene i nomi ricodificati\nprint(df)\n\n  tipo_intervento tipo_intervento_ricodificato\n0              CT            Terapia Cognitiva\n1              BT      Terapia Comportamentale\n2              MT                Terapia Mista\n3              CT            Terapia Cognitiva\n4              BT      Terapia Comportamentale",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#aggiungere-nuove-variabili-nel-data-frame",
    "href": "chapters/eda/02_data_cleaning.html#aggiungere-nuove-variabili-nel-data-frame",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.13 (11) Aggiungere Nuove Variabili nel Data Frame",
    "text": "16.13 (11) Aggiungere Nuove Variabili nel Data Frame\nNel caso presente non è richiesto, ma aggiungere nuove variabili a un DataFrame è un’operazione comune durante l’analisi dei dati. Un esempio è il calcolo dell’indice di massa corporea (BMI).\nSupponiamo di avere un DataFrame chiamato df che contiene le colonne peso_kg (peso in chilogrammi) e altezza_m (altezza in metri) per ciascun partecipante a uno studio psicologico. Per arricchire il dataset, possiamo calcolare il BMI per ogni partecipante e aggiungerlo come una nuova variabile.\nIl BMI si calcola con la formula:\n\\[ \\text{BMI} = \\frac{\\text{peso in kg}}{\\text{altezza in metri}^2} .\\]\nEcco come aggiungere la nuova colonna.\n\n# Supponiamo di avere un DataFrame chiamato 'df' con le colonne 'peso_kg' e 'altezza_m'\ndf = pd.DataFrame({\"peso_kg\": [70, 85, 60, 95], \"altezza_m\": [1.75, 1.80, 1.65, 1.90]})\n\n# Calcola il BMI e aggiungilo come una nuova colonna 'BMI'\ndf[\"BMI\"] = df[\"peso_kg\"] / (df[\"altezza_m\"] ** 2)\n\n# Mostra il DataFrame con la nuova variabile aggiunta\nprint(df)\n\n   peso_kg  altezza_m        BMI\n0       70       1.75  22.857143\n1       85       1.80  26.234568\n2       60       1.65  22.038567\n3       95       1.90  26.315789",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#affrontare-il-problema-dei-dati-mancanti",
    "href": "chapters/eda/02_data_cleaning.html#affrontare-il-problema-dei-dati-mancanti",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.14 (12) Affrontare il Problema dei Dati Mancanti",
    "text": "16.14 (12) Affrontare il Problema dei Dati Mancanti\nL’imputazione è una tecnica utilizzata per gestire i dati mancanti in un dataset, un problema comune in molte analisi. Lasciare i valori mancanti nel DataFrame può compromettere la qualità dell’analisi, poiché molti algoritmi statistici non sono in grado di gestire direttamente i dati incompleti, portando a risultati distorti o poco affidabili.\nI valori mancanti possono causare diversi problemi:\n\nBias dei risultati: I dati mancanti possono introdurre un bias nelle stime se i valori mancanti non sono distribuiti in modo casuale.\nRiduzione della potenza statistica: Quando si eliminano le righe con dati mancanti (rimozione listwise), si riduce la dimensione del campione, diminuendo la potenza dell’analisi.\nImpossibilità di utilizzare alcuni algoritmi: Molti algoritmi di statistica richiedono che tutti i valori siano presenti per eseguire correttamente i calcoli.\n\nEsistono vari approcci per affrontare i dati mancanti:\n\nImputazione Semplice:\n\nMedia/Mediana: Un metodo comune e semplice è sostituire i valori mancanti con la media o la mediana della colonna. Questo metodo è facile da implementare, ma può ridurre la variabilità dei dati e portare a una sottostima della varianza.\nMode (moda): Per le variabili categoriche, è possibile sostituire i valori mancanti con la moda (il valore più frequente). Tuttavia, questo può portare a una distorsione se la distribuzione dei dati è molto eterogenea.\n\nImputazione Multipla:\n\nRegressione Iterativa: L’imputazione multipla, come implementata con algoritmi come IterativeImputer, è una procedura più sofisticata che predice i valori mancanti in modo iterativo utilizzando un modello basato sulle altre variabili del dataset. Questa tecnica tiene conto delle relazioni tra le variabili, migliorando l’accuratezza delle imputazioni rispetto ai metodi semplici.\nL’imputazione multipla conserva la variabilità nei dati e riduce il bias, fornendo stime più accurate rispetto ai metodi di imputazione semplice.\n\n\nL’imputazione dei dati mancanti è essenziale per garantire che l’analisi statistica sia accurata e robusta. Sebbene i metodi semplici come la sostituzione con la media possano essere utili in alcuni casi, l’imputazione multipla offre un approccio più completo e sofisticato, particolarmente utile quando si desidera preservare le relazioni tra le variabili e mantenere l’integrità statistica del dataset. Questo argomento verrà ulteriormente discusso nel Capitolo 83.\nApplichiamo la procedura dell’imputazione multipla al caso presente.\n\nd = svy.copy()\nd = pd.DataFrame(d)\n# Conserva l'indice originale\noriginal_index = d.index\nd\n\n\n\n\n\n\n\n\nstu_id\ngrade_level\nmath1\nmath2\nmath3\nmath4\n\n\n\n\n0\n1347\n9\n2\n1\n3.0\n3.0\n\n\n1\n1368\n10\n3\n2\n2.0\n2.0\n\n\n2\n1377\n9\n4\n4\n4.0\n4.0\n\n\n3\n1387\n11\n3\n3\nNaN\nNaN\n\n\n5\n1399\n12\n4\n1\n3.0\n1.0\n\n\n\n\n\n\n\n\n# Converti solo le colonne numeriche relative ai punteggi in float per l'imputazione\nnumeric_columns = [\"math1\", \"math2\", \"math3\", \"math4\"]\nd[numeric_columns] = d[numeric_columns].astype(float)\n\n# Applica IterativeImputer per l'imputazione multipla\nimputer = IterativeImputer(max_iter=10, random_state=0)\ndf_imputed = pd.DataFrame(\n    imputer.fit_transform(d[numeric_columns]),\n    columns=numeric_columns,\n    index=original_index,  # Mantieni l'indice originale\n)\n\n# Arrotonda i valori imputati ai numeri interi più vicini\ndf_imputed = df_imputed.round()\n\n# Inserisci i valori imputati e arrotondati nel DataFrame originale\nd[numeric_columns] = df_imputed\n\n# Mostra il DataFrame dopo l'imputazione e l'arrotondamento\nprint(\"\\nDataFrame dopo l'imputazione e l'arrotondamento:\")\nprint(d)\n\n\nDataFrame dopo l'imputazione e l'arrotondamento:\n   stu_id  grade_level  math1  math2  math3  math4\n0    1347            9    2.0    1.0    3.0    3.0\n1    1368           10    3.0    2.0    2.0    2.0\n2    1377            9    4.0    4.0    4.0    4.0\n3    1387           11    3.0    3.0    3.0    4.0\n5    1399           12    4.0    1.0    3.0    1.0\n\n\nPer eseguire l’imputazione multipla in Python, utilizziamo il pacchetto sklearn con il modulo IterativeImputer, che è uno degli algoritmi più avanzati disponibili per l’imputazione dei valori mancanti. Questo algoritmo utilizza la regressione iterativa, in cui ogni valore mancante viene previsto utilizzando un modello che tiene conto di tutte le altre variabili presenti nel dataset.\n\nAbbiamo selezionato le colonne numeriche che vogliamo imputare.\nImputazione Multipla con IterativeImputer:\n\nIterativeImputer è un algoritmo che prevede i valori mancanti iterativamente. Per ciascuna colonna con valori mancanti, l’algoritmo usa una regressione basata sulle altre colonne per stimare i valori mancanti.\nIl processo viene ripetuto iterativamente fino a quando i valori imputati convergono a una soluzione stabile.\nmax_iter=10 significa che il processo verrà ripetuto fino a un massimo di 10 volte per garantire la stabilità delle imputazioni.\n\nApplicazione dell’Imputazione: Dopo aver eseguito l’imputazione, i valori imputati vengono reinseriti nel DataFrame originale.\n\nIl DataFrame risultante non ha più valori mancanti nelle colonne math3 e math4, poiché questi sono stati imputati utilizzando le relazioni con le altre variabili del dataset.\nIn conclusione, l’imputazione multipla è una tecnica potente che consente di gestire i valori mancanti nei dati senza dover eliminare intere righe o colonne. In questo caso, abbiamo utilizzato IterativeImputer per prevedere i valori mancanti basandoci sulle informazioni fornite dalle altre variabili. Questo approccio aumenta l’accuratezza e la validità delle analisi successive.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#aggiungere-i-metadati",
    "href": "chapters/eda/02_data_cleaning.html#aggiungere-i-metadati",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.15 (13) Aggiungere i Metadati",
    "text": "16.15 (13) Aggiungere i Metadati\nI metadati sono informazioni che descrivono i dati stessi, come etichette di variabili, etichette di valori, informazioni sull’origine dei dati, unità di misura e altro ancora. Questi metadati sono essenziali per comprendere, documentare e condividere correttamente un dataset.\nIn R, i metadati sono gestiti in modo molto dettagliato e strutturato attraverso pacchetti come haven, labelled, e Hmisc. Questi pacchetti consentono di associare etichette ai dati, come etichette di variabili e di valori, e persino di gestire i valori mancanti con etichette specifiche.\n\nEtichette di variabili: Si possono aggiungere direttamente alle colonne di un DataFrame usando funzioni come labelled::set_variable_labels().\nEtichette di valori: Possono essere aggiunte a variabili categoriali utilizzando labelled::labelled().\nValori mancanti: In R, è possibile etichettare specifici valori come mancanti usando labelled::na_values&lt;-.\n\nQuesti strumenti rendono molto facile documentare un dataset all’interno del processo di analisi, assicurando che tutte le informazioni critiche sui dati siano facilmente accessibili e ben documentate.\nIn Python, la gestione dei metadati non è così strutturata come in R. pandas, che è il pacchetto principale per la manipolazione dei dati in Python, non ha un supporto nativo per l’assegnazione di metadati direttamente alle colonne di un DataFrame, come etichette di variabili o etichette di valori. Tuttavia, ci sono alcuni approcci che si possono adottare:\n\nEtichette di variabili: Poiché pandas non supporta nativamente le etichette di variabili, un modo comune per gestirle è utilizzare il campo attrs di un DataFrame. attrs è un dizionario che può contenere metadati personalizzati, come le etichette delle variabili. Ad esempio, si possono aggiungere descrizioni per ciascuna variabile all’interno di attrs['variable_labels'].\nEtichette di valori: Le variabili categoriali in pandas possono avere categorie ordinate o non ordinate con nomi significativi, ma queste non sono considerate come “etichette di valori” nel senso in cui R le gestisce. Tuttavia, è possibile simulare questo comportamento rinominando le categorie di una variabile categoriale.\nValori mancanti: pandas tratta i valori mancanti utilizzando NaN, ma non c’è una funzionalità nativa per etichettare valori specifici come mancanti con una descrizione. Si può gestire questo manualmente, utilizzando una combinazione di sostituzioni (replace()) e l’uso di valori speciali.\n\n\n16.15.1 Confronto R vs Python\n\nR ffre un supporto più robusto e dettagliato per i metadati, con pacchetti specializzati che permettono di etichettare variabili, valori e gestire i dati mancanti in modo intuitivo e strutturato. I metadati possono essere direttamente integrati nei DataFrame e sono parte integrante del workflow di analisi in R.\nMentre pandas offre alcune capacità di manipolazione e annotazione dei dati, il supporto per i metadati è meno strutturato e richiede soluzioni personalizzate. Python si basa più su convenzioni e personalizzazioni tramite campi come attrs per conservare i metadati. Anche se Python è estremamente flessibile, la gestione dei metadati richiede spesso soluzioni creative rispetto alla semplicità e alla coerenza offerte da R.\n\nIn sintesi, sebbene Python sia molto potente per l’elaborazione dei dati, l’ecosistema R offre strumenti più raffinati e specializzati per la gestione dei metadati all’interno di un processo di data cleaning e analisi.\n\n# Creazione del DataFrame 'svy'\ndata = {\n    \"stu_id\": [1347, 1368, 1377, 1387, 1399],\n    \"grade_level\": [9, 10, 9, 11, 12],\n    \"math1\": [2, 3, 4, 3, 4],\n    \"math2\": [1, 2, 4, 3, 1],\n    \"math3\": [3.0, 2.0, 4.0, np.nan, 3.0],\n    \"math4\": [3.0, 2.0, 4.0, np.nan, 1.0],\n    \"int\": [1, 0, 1, 0, 1],\n}\n\nsvy = pd.DataFrame(data)\n\n# Aggiungi etichette di valore alle colonne math1:math4\nvalue_labels_math = {\n    1: \"strongly disagree\",\n    2: \"disagree\",\n    3: \"agree\",\n    4: \"strongly agree\",\n}\n\nfor col in [\"math1\", \"math2\", \"math3\", \"math4\"]:\n    svy[col] = svy[col].astype(\n        pd.CategoricalDtype(categories=value_labels_math.keys(), ordered=True)\n    )\n    svy[col] = svy[col].cat.rename_categories(value_labels_math)\n\n# Aggiungi etichette di valore alla colonna 'int'\nvalue_labels_int = {1: \"treatment\", 0: \"control\"}\nsvy[\"int\"] = svy[\"int\"].astype(\n    pd.CategoricalDtype(categories=value_labels_int.keys(), ordered=True)\n)\nsvy[\"int\"] = svy[\"int\"].cat.rename_categories(value_labels_int)\n\n# Verifica delle etichette di valore\nfor col in [\"math1\", \"math2\", \"math3\", \"math4\", \"int\"]:\n    print(f\"Value labels for {col}:\")\n    print(svy[col].cat.categories)\n    print()\n\n# Aggiungi etichette per valori mancanti\nna_value = -99\nsvy = svy.replace(np.nan, na_value)\n\n# Aggiungi etichette di variabili utilizzando un dizionario dati (esempio semplificato)\nvar_labels = {\n    \"stu_id\": \"Student ID\",\n    \"grade_level\": \"Grade Level\",\n    \"math1\": \"Math Response 1\",\n    \"math2\": \"Math Response 2\",\n    \"math3\": \"Math Response 3\",\n    \"math4\": \"Math Response 4\",\n    \"int\": \"Intervention Group\",\n}\n\n# Assegna etichette di variabili al DataFrame (non nativo in pandas, gestito come metadati)\nsvy.attrs[\"variable_labels\"] = var_labels\n\n# Verifica delle etichette di variabili\nprint(\"\\nVariable labels:\")\nfor var, label in svy.attrs[\"variable_labels\"].items():\n    print(f\"{var}: {label}\")\n\nValue labels for math1:\nIndex(['strongly disagree', 'disagree', 'agree', 'strongly agree'], dtype='object')\n\nValue labels for math2:\nIndex(['strongly disagree', 'disagree', 'agree', 'strongly agree'], dtype='object')\n\nValue labels for math3:\nIndex(['strongly disagree', 'disagree', 'agree', 'strongly agree'], dtype='object')\n\nValue labels for math4:\nIndex(['strongly disagree', 'disagree', 'agree', 'strongly agree'], dtype='object')\n\nValue labels for int:\nIndex(['treatment', 'control'], dtype='object')\n\n\nVariable labels:\nstu_id: Student ID\ngrade_level: Grade Level\nmath1: Math Response 1\nmath2: Math Response 2\nmath3: Math Response 3\nmath4: Math Response 4\nint: Intervention Group",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#validazione-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#validazione-dei-dati",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.16 (14) Validazione dei Dati",
    "text": "16.16 (14) Validazione dei Dati\nL’obiettivo è creare un report che mostri se i dati soddisfano i criteri attesi. Utilizzando il dizionario dei dati come riferimento, si possono aggiungere diversi controlli:\n\nLe osservazioni (righe) sono tutti distinte? Ci sono ancora ID duplicati?\nGli ID sono tutti validi (rientrano nell’intervallo previsto)?\nLe variabili grade_level, int e math contengono tutti valori che rientrano nel set di valori atteso?\n\n\n# Funzione per controllare se le righe sono uniche per una specifica colonna\ndef check_rows_distinct(df, column):\n    duplicates = df[df.duplicated(column, keep=False)]\n    if len(duplicates) &gt; 0:\n        print(f\"Le righe duplicate trovate per la colonna {column}:\")\n        print(duplicates)\n    else:\n        print(f\"Tutte le righe sono uniche per la colonna {column}.\")\n\n\n# Funzione per controllare se i valori sono compresi in un intervallo\ndef check_col_vals_between(df, column, left, right):\n    outside_range = df[(df[column] &lt; left) | (df[column] &gt; right)]\n    if len(outside_range) &gt; 0:\n        print(f\"Valori fuori dall'intervallo trovati in {column}:\")\n        print(outside_range)\n    else:\n        print(f\"Tutti i valori in {column} sono compresi tra {left} e {right}.\")\n\n\n# Funzione per controllare se i valori appartengono a un insieme specifico\ndef check_col_vals_in_set(df, column, valid_set):\n    invalid_vals = df[~df[column].isin(valid_set)]\n    if len(invalid_vals) &gt; 0:\n        print(f\"Valori non validi trovati in {column}:\")\n        print(invalid_vals)\n    else:\n        print(f\"Tutti i valori in {column} appartengono all'insieme {valid_set}.\")\n\n\n# Esegui le verifiche\ncheck_rows_distinct(svy, \"stu_id\")\ncheck_col_vals_between(svy, \"stu_id\", 1300, 1400)\ncheck_col_vals_in_set(svy, \"grade_level\", {9, 10, 11, 12, pd.NA})\ncheck_col_vals_in_set(svy, \"math1\", {1, 2, 3, 4, pd.NA})\ncheck_col_vals_in_set(svy, \"math2\", {1, 2, 3, 4, pd.NA})\ncheck_col_vals_in_set(svy, \"math3\", {1, 2, 3, 4, pd.NA})\ncheck_col_vals_in_set(svy, \"math4\", {1, 2, 3, 4, pd.NA})\n\nprint(\"Validazione completata.\")\n\nTutte le righe sono uniche per la colonna stu_id.\nTutti i valori in stu_id sono compresi tra 1300 e 1400.\nTutti i valori in grade_level appartengono all'insieme {9, 10, 11, 12, &lt;NA&gt;}.\nTutti i valori in math1 appartengono all'insieme {1, 2, 3, 4, &lt;NA&gt;}.\nTutti i valori in math2 appartengono all'insieme {1, 2, 3, 4, &lt;NA&gt;}.\nValori non validi trovati in math3:\n   stu_id  grade_level  math1  math2  math3  math4\n3    1387           11      3      3    NaN    NaN\nValori non validi trovati in math4:\n   stu_id  grade_level  math1  math2  math3  math4\n3    1387           11      3      3    NaN    NaN\nValidazione completata.\n\n\nIn R, la procedura precedente può essere gestita in modo più semplice utilizzando il pacchetto pointblank, che offre strumenti dedicati per facilitare questo processo.\nIl dataset ripulito soddisfa tutte le aspettative delineate da Crystal Lewis.\n\nCompleto: Tutti i dati raccolti sono stati inseriti e/o recuperati. Non dovrebbero esserci dati estranei che non appartengono al dataset (come duplicati o partecipanti non autorizzati).\nValido: Le variabili rispettano i vincoli definiti nel tuo dizionario dei dati. Ricorda che il dizionario dei dati specifica i nomi delle variabili, i tipi, i range, le categorie e altre informazioni attese.\nAccurato: Sebbene non sia sempre possibile determinare l’accuratezza dei valori durante il processo di pulizia dei dati (ovvero, se un valore è realmente corretto o meno), in alcuni casi è possibile valutarla sulla base della conoscenza pregressa riguardante quel partecipante o caso specifico.\nCoerente: I valori sono allineati tra le varie fonti. Ad esempio, la data di nascita raccolta attraverso un sondaggio studentesco dovrebbe avere un formato corrispondere alla data di nascita raccolta dal distretto scolastico.\nUniforme: I dati sono standardizzati attraverso i moduli e nel tempo. Ad esempio, lo stato di partecipazione ai programmi di pranzo gratuito o a prezzo ridotto è sempre fornito come una variabile numerica con la stessa rappresentazione, oppure il nome della scuola è sempre scritto in modo coerente in tutto il dataset.\nDe-identificato: Tutte le informazioni personali identificabili (PII) sono state rimosse dal dataset per proteggere la riservatezza dei partecipanti (se richiesto dal comitato etico/consenso informato).\nInterpretabile: I dati hanno nomi di variabili leggibili sia da umani che dal computer, e sono presenti etichette di variabili e valori laddove necessario per facilitare l’interpretazione.\nAnalizzabile: Il dataset è in un formato rettangolare (righe e colonne), leggibile dal computer e conforme alle regole di base della struttura dei dati.\n\nUna volta completati i 14 passaggi precedenti, è possibile esportare questo dataset ripulito nella cartella processed per le successive analisi statistiche.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#unire-eo-aggiungere-dati-se-necessario",
    "href": "chapters/eda/02_data_cleaning.html#unire-eo-aggiungere-dati-se-necessario",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.17 (15) Unire e/o aggiungere dati se necessario",
    "text": "16.17 (15) Unire e/o aggiungere dati se necessario\nIn questo passaggio, è possibile unire o aggiungere colonne o righe presenti in file diversi. È importante eseguire nuovamente i controlli di validazione dopo l’unione/aggiunta di nuovi dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#trasformare-i-dati-se-necessario",
    "href": "chapters/eda/02_data_cleaning.html#trasformare-i-dati-se-necessario",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.18 (16) Trasformare i dati se necessario",
    "text": "16.18 (16) Trasformare i dati se necessario\nEsistono vari motivi per cui potrebbe essere utile memorizzare i dati in formato long o wide. In questo passaggio, è possibile ristrutturare i dati secondo le esigenze.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#salvare-il-dataset-pulito-finale",
    "href": "chapters/eda/02_data_cleaning.html#salvare-il-dataset-pulito-finale",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.19 (17) Salvare il dataset pulito finale",
    "text": "16.19 (17) Salvare il dataset pulito finale\nL’ultimo passaggio del processo di pulizia consiste nell’esportare o salvare il dataset pulito. Come accennato in precedenza, può essere utile esportare/salvare il dataset in più di un formato di file (ad esempio, un file .csv e un file .parquet).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "href": "chapters/eda/02_data_cleaning.html#organizzazione-dei-file-e-informazioni-aggiuntive",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.20 Organizzazione dei file e informazioni aggiuntive",
    "text": "16.20 Organizzazione dei file e informazioni aggiuntive\nInfine, è essenziale includere una documentazione adeguata per garantire che le informazioni siano interpretate correttamente, sia da altri utenti che da te stesso, se dovessi tornare a lavorare su questo progetto in futuro. La documentazione minima da fornire dovrebbe includere:\n\nDocumentazione a livello di progetto: Questa sezione fornisce informazioni contestuali sul perché e come i dati sono stati raccolti. È utile per chiunque voglia comprendere lo scopo e la metodologia del progetto.\nMetadati a livello di progetto: Se condividi i dati in un repository pubblico o privato, è importante includere metadati a livello di progetto. Questi metadati forniscono informazioni dettagliate che facilitano la ricerca, la comprensione e la consultabilità dei dati. I metadati a livello di progetto possono includere descrizioni generali del progetto, parole chiave, e riferimenti bibliografici.\nDizionario dei dati: Un documento che descrive tutte le variabili presenti nel dataset, inclusi i loro nomi, tipi, range di valori, categorie e qualsiasi altra informazione rilevante. Questo strumento è fondamentale per chiunque voglia comprendere o analizzare i dati.\nREADME: Un file che fornisce una panoramica rapida dei file inclusi nel progetto, spiegando cosa contengono e come sono interconnessi. Il README è spesso il primo documento consultato e serve a orientare l’utente tra i vari file e risorse del progetto.\n\nQuesta documentazione non solo aiuta a mantenere il progetto organizzato, ma è anche cruciale per facilitare la collaborazione e l’archiviazione a lungo termine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "href": "chapters/eda/02_data_cleaning.html#dizionario-dei-dati",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.21 Dizionario dei Dati",
    "text": "16.21 Dizionario dei Dati\nApprofondiamo qui il problema della creazione del Dizionario dei dati.\nUn dizionario dei dati è un documento che descrive le caratteristiche di ciascuna variabile in un dataset. Include informazioni come il nome della variabile, il tipo di dato, il range di valori, le categorie (per le variabili categoriche), e altre informazioni rilevanti. Questo strumento è essenziale per comprendere e analizzare correttamente il dataset.\nSi presti particolare attenzione alle guide di stile per la denominazione delle variabili e la codifica dei valori delle risposte.\n\n16.21.1 Passi per Creare un Dizionario dei Dati\n\nIdentificare le variabili: Elenca tutte le variabili nel dataset.\nDescrivere ogni variabile: Per ciascuna variabile, identifica il tipo (ad esempio, int, float, datetime, category), il range di valori accettabili e, se applicabile, le categorie.\nSalvare il dizionario dei dati: Il dizionario dei dati può essere salvato in un file .csv o .xlsx per facilitarne la consultazione.\n\nPer fare un esempio, utilizzeremo il dataset del tutorial di Crystal Lewis. Il codice seguente creerà due file:\n\ndata_dictionary.csv: Un file CSV contenente il dizionario dei dati.\ndata_dictionary.xlsx: Un file Excel contenente lo stesso dizionario dei dati.\n\n\n# Creazione del Dizionario dei Dati\ndata_dict = {\n    \"Variable Name\": [\n        \"stu_id\",\n        \"svy_date\",\n        \"grade_level\",\n        \"math1\",\n        \"math2\",\n        \"math3\",\n        \"math4\",\n    ],\n    \"Type\": [\"int\", \"datetime\", \"int\", \"int\", \"int\", \"float\", \"float\"],\n    \"Description\": [\n        \"Student ID\",\n        \"Survey Date\",\n        \"Grade Level\",\n        \"Math Response 1 (1: Strongly Disagree, 4: Strongly Agree)\",\n        \"Math Response 2 (1: Strongly Disagree, 4: Strongly Agree)\",\n        \"Math Response 3 (1: Strongly Disagree, 4: Strongly Agree)\",\n        \"Math Response 4 (1: Strongly Disagree, 4: Strongly Agree)\",\n    ],\n    \"Range/Values\": [\n        \"1347-1399\",\n        \"2023-02-13 to 2023-02-14\",\n        \"9-12\",\n        \"1-4\",\n        \"1-4\",\n        \"1.0-4.0 (NaN allowed)\",\n        \"1.0-4.0 (NaN allowed)\",\n    ],\n}\n\ndata_dict_df = pd.DataFrame(data_dict)\n\nprint(data_dict_df)\n\n  Variable Name      Type                                        Description  \\\n0        stu_id       int                                         Student ID   \n1      svy_date  datetime                                        Survey Date   \n2   grade_level       int                                        Grade Level   \n3         math1       int  Math Response 1 (1: Strongly Disagree, 4: Stro...   \n4         math2       int  Math Response 2 (1: Strongly Disagree, 4: Stro...   \n5         math3     float  Math Response 3 (1: Strongly Disagree, 4: Stro...   \n6         math4     float  Math Response 4 (1: Strongly Disagree, 4: Stro...   \n\n               Range/Values  \n0                 1347-1399  \n1  2023-02-13 to 2023-02-14  \n2                      9-12  \n3                       1-4  \n4                       1-4  \n5     1.0-4.0 (NaN allowed)  \n6     1.0-4.0 (NaN allowed)  \n\n\nUna volta creato il Dizionario dei dati lo possiamo salvare in un file CSV o Excel:\n# Salva il Dizionario dei Dati in un file CSV\ndata_dict_df.to_csv(\"data_dictionary.csv\", index=False)\n\n# Opzionalmente, salva il Dizionario dei Dati in un file Excel\ndata_dict_df.to_excel(\"data_dictionary.xlsx\", index=False)\nQuesti file forniscono una documentazione chiara e strutturata del dataset, utile per qualsiasi analisi successiva o per la condivisione con altri.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#guide-di-stile",
    "href": "chapters/eda/02_data_cleaning.html#guide-di-stile",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.22 Guide di Stile",
    "text": "16.22 Guide di Stile\nLe guide di stile possono essere applicate a diversi aspetti di un progetto di analisi dei dati, non soltanto al dizionario dei dati. Un’ottima introduzione alle regole di stile per un progetto di analisi dei dati è fornita in questo capitolo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#python-e-r",
    "href": "chapters/eda/02_data_cleaning.html#python-e-r",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.23 Python e R",
    "text": "16.23 Python e R\nNella discussione precedente, abbiamo accennato alle differenze tra Python e R per quanto riguarda la fase di pulizia e pre-elaborazione dei dati. Sebbene Python, tramite la libreria Pandas, offra strumenti potenti e flessibili per la manipolazione dei dati, R si distingue per la sua capacità di semplificare e ottimizzare queste operazioni, specialmente quando si tratta di progetti complessi.\nR è stato progettato specificamente per l’analisi statistica, e molte delle sue funzioni native sono state sviluppate con un focus particolare sulla semplicità d’uso e l’efficienza nei processi di cleaning e preprocessing. Un esempio emblematico di questa facilità è la creazione di un Dizionario dei Dati, un’operazione essenziale per documentare e descrivere accuratamente il dataset utilizzato in un progetto di analisi. In R, questa operazione può essere completata con una singola istruzione utilizzando pacchetti specifici. Per esempio, il pacchetto datadictionary permette di generare un dizionario dei dati in modo rapido ed efficiente, come illustrato nel file README. Questo rende R particolarmente vantaggioso quando si lavora con dataset complessi che richiedono una documentazione dettagliata e strutturata.\nD’altra parte, Python, con Pandas, è estremamente flessibile e può essere adattato a una vasta gamma di esigenze di pulizia e manipolazione dei dati. Tuttavia, la flessibilità di Pandas richiede spesso un approccio più manuale e dettagliato per compiti che in R potrebbero essere gestiti con comandi più concisi e specifici. Ad esempio, in Python, come abbiamo visto in precedenza, la creazione di un dizionario dei dati richiede una serie di passaggi personalizzati che possono includere la costruzione manuale di tabelle, la gestione delle categorie e dei metadati, e la documentazione. Questa flessibilità rende Python particolarmente adatto a progetti che richiedono un elevato grado di personalizzazione o l’integrazione di dati provenienti da diverse fonti. Tuttavia, può risultare più laborioso e meno intuitivo rispetto a R per operazioni standardizzate di cleaning e preprocessing.\nIn definitiva, la scelta tra Python e R per la pulizia e pre-elaborazione dei dati dipende dalle specifiche esigenze del progetto e dalle competenze dell’analista. R offre strumenti altamente ottimizzati per un’analisi statistica rapida e strutturata, rendendolo ideale per progetti che richiedono una documentazione dettagliata e una gestione intuitiva dei dati. Python, con la sua flessibilità e potenza, è preferibile per progetti che richiedono personalizzazioni complesse o integrazioni con altri strumenti di analisi dei dati e sviluppo software.\nQuando si tratta di progetti di analisi dei dati, è importante considerare non solo la potenza degli strumenti disponibili, ma anche la loro capacità di semplificare e rendere efficienti le operazioni di pulizia e pre-elaborazione. Scegliere lo strumento giusto può fare una grande differenza in termini di tempo, efficienza e qualità dei risultati ottenuti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "href": "chapters/eda/02_data_cleaning.html#riflessioni-conclusive",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "16.24 Riflessioni Conclusive",
    "text": "16.24 Riflessioni Conclusive\nNel processo di analisi dei dati, la fase di pulizia e pre-elaborazione è cruciale per garantire la qualità e l’integrità dei risultati finali. Sebbene questa fase possa sembrare meno interessante rispetto all’analisi vera e propria, essa costituisce la base su cui si costruiscono tutte le successive elaborazioni e interpretazioni. Attraverso una serie di passaggi strutturati, come quelli illustrati in questo capitolo, è possibile trasformare dati grezzi e disordinati in un dataset pulito, coerente e pronto per l’analisi. La cura nella gestione dei dati, dalla rimozione di duplicati alla creazione di un dizionario dei dati, è fondamentale per ottenere risultati affidabili e riproducibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/02_data_cleaning.html#informazioni-sullambiente-di-sviluppo",
    "title": "16  Flusso di lavoro per la pulizia dei dati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Sun Aug 18 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\npandas    : 2.2.2\nsklearn   : 1.5.1\n\n\n\n\n\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash, H., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B. (2021). Getting started creating data dictionaries: How to create a shareable data set. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920928007.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Flusso di lavoro per la pulizia dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html",
    "href": "chapters/eda/04_exploring_qualitative_data.html",
    "title": "18  Esplorare i dati qualitativi",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati qualitativi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "href": "chapters/eda/04_exploring_qualitative_data.html#il-dataset-penguins",
    "title": "18  Esplorare i dati qualitativi",
    "section": "18.1 Il dataset penguins",
    "text": "18.1 Il dataset penguins\nPer fornire esempi pratici, in questo capitolo utilizzeremo il dataset palmerpenguins, messo a disposizione da Allison Horst. I dati sono stati raccolti e resi disponibili da Dr. Kristen Gorman e dalla Palmer Station, parte del programma di ricerca ecologica a lungo termine Long Term Ecological Research Network. Il dataset contiene informazioni su 344 pinguini, appartenenti a 3 diverse specie, raccolte su 3 isole dell’arcipelago di Palmer, in Antartide. Per semplicità, i dati sono organizzati nel file penguins.csv.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "href": "chapters/eda/04_exploring_qualitative_data.html#importare-i-dati",
    "title": "18  Esplorare i dati qualitativi",
    "section": "18.2 Importare i Dati",
    "text": "18.2 Importare i Dati\nSupponimo di essere interessati alla distribuzione di una singola variabili quantitativa. Per fare un esempio, considereremo i dati palmerpenguins.\nCome illustrato nel capitolo precedente, dopo aver definito project_directory come la directory di root utilizzando:\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\n\ne impostato il percorso del file penguins.csv in modo relativo rispetto alla root:\n\nfile_path = os.path.join(project_directory, \"data\", \"penguins.csv\")\n\npossiamo caricare i dati grezzi dal file penguins.csv in un DataFrame di pandas con il seguente comando:\n\ndat = pd.read_csv(file_path)\n\nEsaminiamo i dati.\n\ndat.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\nyear                   int64\ndtype: object\n\n\n\ndat.shape\n\n(344, 8)\n\n\n\ndat.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\nPer semplicità, rimuoviamo le righe con valori mancanti con la seguente istruzione:\n\ndf = dat.dropna()\ndf.shape\n\n(333, 8)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "href": "chapters/eda/04_exploring_qualitative_data.html#tabelle-di-contingenza",
    "title": "18  Esplorare i dati qualitativi",
    "section": "18.3 Tabelle di Contingenza",
    "text": "18.3 Tabelle di Contingenza\nUna tabella di contingenza è uno strumento utilizzato per riassumere i dati di due variabili categoriali, ovvero variabili qualitative che assumono valori all’interno di un insieme finito di categorie. In una tabella di contingenza, ogni cella mostra quante volte si è verificata una combinazione specifica di categorie per le due variabili considerate.\nPer esempio, se prendiamo in esame due variabili categoriali come “island” e “species” all’interno di un DataFrame df, ciascuna delle quali rappresenta rispettivamente l’isola di provenienza e la specie dei pinguini, possiamo costruire una tabella che mostra quante volte ciascuna combinazione di “island” e “species” appare nel nostro campione. In altre parole, la tabella di contingenza ci permette di vedere quante osservazioni ci sono per ogni combinazione di categorie tra queste due variabili.\n\ncontingency_table = pd.crosstab(df[\"island\"], df[\"species\"])\n\n# Mostra la tabella di contingenza\ncontingency_table\n\n\n\n\n\n\n\nspecies\nAdelie\nChinstrap\nGentoo\n\n\nisland\n\n\n\n\n\n\n\nBiscoe\n44\n0\n119\n\n\nDream\n55\n68\n0\n\n\nTorgersen\n47\n0\n0\n\n\n\n\n\n\n\nQuesta tabella di contingenza mostra la distribuzione di tre specie di pinguini (Adelie, Chinstrap, Gentoo) rispetto a tre isole (Biscoe, Dream, Torgersen). Ogni cella rappresenta il numero di pinguini di una determinata specie presenti su ciascuna isola. Ecco un’interpretazione dettagliata:\n\nIsola Biscoe: Qui troviamo 44 pinguini della specie Adelie e 119 pinguini della specie Gentoo, mentre non sono presenti pinguini Chinstrap.\nIsola Dream: Questa isola ospita 55 pinguini Adelie e 68 pinguini Chinstrap, ma nessun pinguino della specie Gentoo.\nIsola Torgersen: Su quest’isola sono presenti solo 47 pinguini della specie Adelie, e nessun pinguino delle specie Chinstrap o Gentoo.\n\nPossiamo dunque commentare dicendo:\n\nLa specie Adelie è distribuita su tutte e tre le isole, con numeri notevoli sia su Biscoe (44), Dream (55), che Torgersen (47).\nLa specie Chinstrap si trova solo sull’isola Dream (68 esemplari) e non è presente sulle altre due isole.\nLa specie Gentoo si trova esclusivamente sull’isola Biscoe (119 esemplari), non essendo presente su Dream e Torgersen.\n\nQuesto suggerisce una distribuzione geografica specifica delle diverse specie di pinguini, con alcune specie limitate a determinate isole e altre distribuite più ampiamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "href": "chapters/eda/04_exploring_qualitative_data.html#grafico-a-barre",
    "title": "18  Esplorare i dati qualitativi",
    "section": "18.4 Grafico a barre",
    "text": "18.4 Grafico a barre\n\n18.4.1 Grafico a Barre con una Singola Variabile\nUn grafico a barre è uno strumento comunemente utilizzato per rappresentare visivamente una singola variabile categoriale. Questo tipo di grafico mostra le diverse categorie su uno degli assi (solitamente l’asse orizzontale) e utilizza barre di altezza proporzionale per rappresentare la frequenza o il conteggio di ciascuna categoria sull’altro asse (solitamente l’asse verticale).\nAd esempio, in un dataset che contiene informazioni su diverse specie di pinguini, un grafico a barre potrebbe mostrare il numero di pinguini per ciascuna specie. Le specie vengono visualizzate come etichette lungo l’asse delle ascisse, mentre l’altezza delle barre rappresenta il numero di pinguini osservati per ciascuna specie.\nIl grafico a barre consente di confrontare le dimensioni delle categorie in modo semplice e intuitivo.\nPer i dati in esame, creiamo un grafico a barre che rappresenta il numero totale di pinguini per isola.\n\ncontingency_table_sum = contingency_table.sum(axis=1).reset_index()\nplt.bar(contingency_table_sum[\"island\"], contingency_table_sum[0], alpha=0.5)\nplt.title(\"Numero totale di pinguini per isola\")\nplt.xlabel(\"Isola\")\nplt.ylabel(\"Numero di pinguini\")\nplt.show()\n\n\n\n\n\n\n\n\nUn secondo grafico a barre mostra il numero totale di pinguini per specie.\n\ncontingency_table_species_sum = contingency_table.sum(axis=0).reset_index()\nplt.bar(\n    contingency_table_species_sum[\"species\"],\n    contingency_table_species_sum[0],\n    alpha=0.5,\n)\nplt.title(\"Numero totale di pinguini per specie\")\nplt.xlabel(\"Specie\")\nplt.ylabel(\"Numero di pinguini\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n18.4.2 Grafico a Barre con Due Variabili\nÈ possibile visualizzare contemporaneamente le distribuzioni di due variabili categoriali utilizzando un grafico a barre. Questo tipo di grafico è particolarmente utile per esaminare la relazione tra due variabili categoriali.\nIn un grafico a barre con due variabili, una delle variabili viene rappresentata sull’asse orizzontale come categoria principale, mentre la seconda variabile è distinta tramite colori diversi o barre impilate. In questo modo, possiamo confrontare facilmente le frequenze o le proporzioni delle categorie della prima variabile, osservando allo stesso tempo come sono distribuite le categorie della seconda variabile all’interno di ciascuna categoria principale.\nAd esempio, visualizziamo il numero di pinguini per specie e isola. A qusto fine possiamo creare un grafico a barre dove le isole sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle specie su ciascuna isola. Questo approccio consente di esplorare come le due variabili categoriali (specie e isola) interagiscono visivamente.\n\ncontingency_table.plot(kind=\"bar\", stacked=True, figsize=(10, 6), colormap=\"viridis\")\nplt.title(\"Numero di pinguini per specie e isola\")\nplt.xlabel(\"Isola\")\nplt.ylabel(\"Numero di pinguini\")\nplt.legend(title=\"Specie\")\nplt.show()\n\n\n\n\n\n\n\n\nIn alternativa, è possibile creare un grafico a barre dove le specie sono rappresentate sull’asse delle ascisse e i diversi colori delle barre mostrano la distribuzione delle isole per ciascuna specie.\n\ncontingency_table.T.plot(kind=\"bar\", stacked=True, figsize=(10, 6), colormap=\"viridis\")\nplt.title(\"Numero di pinguini per isola e specie\")\nplt.xlabel(\"Specie\")\nplt.ylabel(\"Numero di pinguini\")\nplt.legend(title=\"Isola\")\nplt.show()\n\n\n\n\n\n\n\n\nIn alternativa all’uso delle frequenze assolute, possiamo rappresentare i dati utilizzando le frequenze relative. Questo approccio permette di confrontare meglio le categorie indipendentemente dal numero totale di osservazioni. Nella figura seguente, ad esempio, viene mostrata la proporzione di pinguini di ciascuna specie per ogni isola, evidenziando la distribuzione relativa delle specie su ogni isola, anziché il conteggio assoluto. Questa rappresentazione aiuta a visualizzare le differenze nella composizione delle specie, anche se il numero complessivo di pinguini varia tra le isole.\n\n# Trasformazione della tabella di contingenza in proporzioni per ogni riga (isola)\ncontingency_table_prop = contingency_table.div(contingency_table.sum(axis=1), axis=0)\n\n# Rappresentazione visiva in termini proporzionali\nax = contingency_table_prop.plot(\n    kind=\"bar\", stacked=True, figsize=(10, 6), colormap=\"viridis\"\n)\n\n# Modifichiamo la leggenda per posizionarla al di fuori del grafico\nplt.title(\"Proporzione di pinguini per specie e isola\")\nplt.xlabel(\"Isola\")\nplt.ylabel(\"Proporzione\")\n\n# Posizioniamo la leggenda al di fuori del grafico per migliorare la leggibilità\nplt.legend(title=\"Specie\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_47978/957400763.py:17: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "href": "chapters/eda/04_exploring_qualitative_data.html#mosaic-plots",
    "title": "18  Esplorare i dati qualitativi",
    "section": "18.5 Mosaic plots",
    "text": "18.5 Mosaic plots\nIl Mosaic plot è una tecnica di visualizzazione particolarmente adatta per rappresentare tabelle di contingenza. Questo tipo di grafico somiglia a un grafico a barre impilate standard, ma con un vantaggio importante: oltre a visualizzare la suddivisione interna delle categorie, permette di vedere anche le dimensioni relative dei gruppi della variabile principale.\nIn altre parole, il Mosaic plot non solo mostra come si distribuiscono le categorie di una variabile secondaria all’interno di ogni gruppo della variabile principale, ma fornisce anche un’idea visiva della grandezza complessiva dei gruppi. Questo lo rende uno strumento utile per analizzare e interpretare le relazioni tra due variabili categoriali, evidenziando sia la proporzione all’interno di ciascun gruppo, sia la grandezza relativa tra i gruppi stessi.\n\n# Funzione per personalizzare le etichette (evita di mostrare etichette troppo piccole)\ndef labelizer(key):\n    species, island = key\n    count = df[(df[\"species\"] == species) & (df[\"island\"] == island)].shape[0]\n    if count &gt; 1:  # Definisci una soglia per visualizzare le etichette\n        return f\"{species}\\n{count}\"\n    else:\n        return \"\"\n\n\nmosaic(df, [\"species\", \"island\"], labelizer=labelizer)\nplt.title(\"Mosaic Plot of Species and Island\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "href": "chapters/eda/04_exploring_qualitative_data.html#proporzioni-di-riga-e-colonna",
    "title": "18  Esplorare i dati qualitativi",
    "section": "18.6 Proporzioni di Riga e Colonna",
    "text": "18.6 Proporzioni di Riga e Colonna\nNelle sezioni precedenti abbiamo esaminato la visualizzazione di due variabili categoriali utilizzando grafici a barre e Mosaic plot. Tuttavia, non abbiamo ancora discusso come vengono calcolate le proporzioni mostrate in questi grafici. In questa sezione ci concentreremo sulla suddivisione frazionaria di una variabile rispetto a un’altra, esplorando come possiamo modificare la nostra tabella di contingenza per ottenere una visione più dettagliata delle proporzioni.\nQuesto ci permetterà di comprendere meglio le relazioni tra le due variabili, visualizzando non solo i conteggi assoluti, ma anche le proporzioni relative per riga o per colonna. Le proporzioni di riga mostrano la distribuzione di una variabile all’interno delle categorie di un’altra, mentre le proporzioni di colonna evidenziano la distribuzione inversa.\nCalcoliamo le proporzioni di specie per isola.\n\nrow_proportions = contingency_table.div(contingency_table.sum(axis=1), axis=0)\n\n# Aggiungiamo una colonna \"Totale\" che rappresenta il totale di ciascuna riga\nrow_proportions_with_total = row_proportions.copy()\nrow_proportions_with_total[\"Totale\"] = row_proportions.sum(axis=1)\n\n# Mostra la tabella con le proporzioni di riga e il totale\nprint(row_proportions_with_total)\n\nspecies      Adelie  Chinstrap    Gentoo  Totale\nisland                                          \nBiscoe     0.269939   0.000000  0.730061     1.0\nDream      0.447154   0.552846  0.000000     1.0\nTorgersen  1.000000   0.000000  0.000000     1.0\n\n\nCalcoliamo nuovamente le proporzioni, ma questa volta in funzione delle colonne (per isola).\n\ncolumn_proportions = contingency_table.div(contingency_table.sum(axis=0), axis=1)\n\n# Aggiungiamo una riga \"Totale\" che rappresenta il totale di ciascuna colonna\ncolumn_proportions_with_total = column_proportions.copy()\ncolumn_proportions_with_total.loc[\"Totale\"] = column_proportions.sum(axis=0)\n\n# Mostra la tabella con le proporzioni di colonna e il totale\nprint(column_proportions_with_total)\n\nspecies      Adelie  Chinstrap  Gentoo\nisland                                \nBiscoe     0.301370        0.0     1.0\nDream      0.376712        1.0     0.0\nTorgersen  0.321918        0.0     0.0\nTotale     1.000000        1.0     1.0",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "href": "chapters/eda/04_exploring_qualitative_data.html#confronto-tra-gruppi",
    "title": "18  Esplorare i dati qualitativi",
    "section": "18.7 Confronto tra Gruppi",
    "text": "18.7 Confronto tra Gruppi\nAlcune delle analisi più interessanti emergono confrontando i dati numerici tra diversi gruppi. In questa sezione approfondiremo alcune delle tecniche che abbiamo già esplorato per visualizzare i dati numerici di più gruppi su uno stesso grafico e introdurremo nuovi metodi per confrontare i dati numerici tra gruppi. Queste tecniche ci permetteranno di osservare meglio le differenze e le somiglianze tra gruppi, mettendo in evidenza tendenze, variazioni e altre caratteristiche rilevanti.\nIniziamo considerando due variabili qualitative. Creiamo un grafico a barre per confrontare la distribuzione del genere per specie.\n\nsns.countplot(data=df, x=\"species\", hue=\"sex\")\nplt.title(\"Distribuzione del genere per specie\")\nplt.xlabel(\"Specie\")\nplt.ylabel(\"Conteggio\")\nplt.show()\n\n\n\n\n\n\n\n\nMolto spesso i confronti più interessanti sono quelli che riguardano la distribuzione di una variabile numerica in funzione di una o più variabili qualitative.\nPer fare un esempio, generiamo un grafico che confronta la distribuzione del peso corporeo (body_mass_g) in funzione della specie e del genere. Le diverse aree colorate rappresentano la distribuzione del peso per maschi e femmine all’interno di ciascuna specie.\n\nsns.violinplot(\n    data=df,\n    x=\"body_mass_g\",\n    y=\"species\",\n    hue=\"sex\",\n    split=True,\n    inner=\"quart\",\n    palette=\"viridis\",\n)\n\nplt.title(\"Distribuzione di Body Mass in funzione di specie e genere\")\nplt.xlabel(\"Body Mass (g)\")\nplt.ylabel(\"Specie\")\n\nplt.legend(title=\"Genere\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_47978/2495003544.py:16: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#codice-r",
    "href": "chapters/eda/04_exploring_qualitative_data.html#codice-r",
    "title": "18  Esplorare i dati qualitativi",
    "section": "18.8 Codice R",
    "text": "18.8 Codice R\nPuoi accedere alla versione in R del codice di questo notebook qui.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/04_exploring_qualitative_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "18  Esplorare i dati qualitativi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Sep 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\narviz     : 0.18.0\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Esplorare i dati qualitativi</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html",
    "href": "chapters/eda/05_exploring_numeric_data.html",
    "title": "19  Esplorare i dati numerici",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci concentreremo sull’analisi dei dati numerici. In particolare, esamineremo le distribuzioni di frequenza e i quantili, insieme alle tecniche di visualizzazione più comuni, come l’istogramma, l’istogramma smussato e il box-plot. Tratteremo sia gli aspetti computazionali che quelli interpretativi di queste misure, fornendo strumenti utili non solo per una comprensione personale, ma anche per la comunicazione efficace dei risultati, in particolare con chi utilizza questi dati per prendere decisioni pratiche nel mondo reale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "href": "chapters/eda/05_exploring_numeric_data.html#i-dati-sulle-aspettative-negative-nella-depressione",
    "title": "19  Esplorare i dati numerici",
    "section": "19.1 I dati sulle aspettative negative nella depressione",
    "text": "19.1 I dati sulle aspettative negative nella depressione\nSupponimo di essere interessati alla distribuzione di una singola variabili quantitativa. Per fare un esempio, consideriamo i dati sulle aspettative negative come meccanismo chiave nel mantenimento della depressione (Zetsche et al., 2019). Come abbiamo visto nel capitolo precedente, avendo definito project_directory come root\n\n# Get the home directory\nhome_directory = os.path.expanduser(\"~\")\n# Construct the path to the Quarto project directory\nproject_directory = os.path.join(home_directory, \"_repositories\", \"psicometria\")\n\nè possibile specificare il percorso del file CSV che contiene i dati in relazione a project_directory:\n\nfile_path = os.path.join(project_directory, \"data\", \"data.mood.csv\")\n\nImportiamo i dati grezzi del file data.mood.csv in un DataFrame pandas:\n\ndf = pd.read_csv(file_path)\n\nPer questo esercizio, ci concentreremo sulle colonne esm_id (il codice del soggetto), group (il gruppo) e bdi (il valore BDI-II).\n\ndf = df[[\"esm_id\", \"group\", \"bdi\"]]\ndf.head()\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n1\n10\nmdd\n25.0\n\n\n2\n10\nmdd\n25.0\n\n\n3\n10\nmdd\n25.0\n\n\n4\n10\nmdd\n25.0\n\n\n\n\n\n\n\nUna delle prime cose da fare, quando esaminiamo un dataset, è capire che tipo di variabili sono incluse.\n\ndf.dtypes\n\nesm_id      int64\ngroup      object\nbdi       float64\ndtype: object\n\n\nNel caso specifico, notiamo che la variabile group è di tipo object, quindi è una variabile qualitativa, mentre le altre variabili sono numeriche, rappresentate come numeri interi (int64) o a virgola mobile (bdi).\nSe elenchiamo le modalità presenti in group utilizzando il metodo unique(), scopriamo che corrispondono a mdd (pazienti) e ctl (controlli sani).\n\ndf[\"group\"].unique()\n\narray(['mdd', 'ctl'], dtype=object)\n\n\nRimuoviamo i duplicati per ottenere un unico valore BDI-II per ogni soggetto:\n\ndf = df.drop_duplicates(keep=\"first\")\n\nVerifichiamo di avere ottenuto il risultato desiderato.\n\ndf.shape\n\n(67, 3)\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nesm_id\ngroup\nbdi\n\n\n\n\n0\n10\nmdd\n25.0\n\n\n14\n9\nmdd\n30.0\n\n\n29\n6\nmdd\n26.0\n\n\n45\n7\nmdd\n35.0\n\n\n64\n12\nmdd\n44.0\n\n\n\n\n\n\n\nSi noti che il nuovo DataFrame (con 67 righe) conserva il “nome” delle righe (ovvero, l’indice di riga) del DataFrame originario (con 1188 righe). Per esempio, il secondo soggetto (con codice identificativo 9) si trova sulla seconda riga del DataFrame, ma il suo indice di riga è 15. Questo non ha nessuna conseguenza perché non useremo l’indice di riga nelle analisi seguenti.\nEliminiamo eventuali valori mancanti:\n\ndf = df[pd.notnull(df[\"bdi\"])]\n\nOtteniamo così il DataFrame finale per gli scopi presenti (66 righe e 3 colonne):\n\ndf.shape\n\n(66, 3)\n\n\nStampiamo i valori BDI-II presentandoli ordinati dal più piccolo al più grande:\n\nprint(df[\"bdi\"].sort_values())\n\n682     0.0\n455     0.0\n465     0.0\n485     0.0\n540     0.0\n       ... \n190    39.0\n810    41.0\n150    43.0\n135    43.0\n64     44.0\nName: bdi, Length: 66, dtype: float64\n\n\nNel linguaggio statistico, un’osservazione rappresenta l’informazione raccolta da un singolo individuo o entità che partecipa allo studio. Nel caso del dataset utilizzato da Zetsche et al. (2019), l’unità di osservazione è costituita dai partecipanti allo studio. Ogni riga del DataFrame, denominato df, corrisponde quindi a un individuo distinto incluso nell’analisi.\nLe variabili, invece, riflettono le diverse caratteristiche degli individui o delle entità considerate. Per i dati in esame, questo concetto si esprime così:\n\nOgni colonna di df rappresenta una variabile che descrive una specifica proprietà comune ai partecipanti.\nLe variabili sono identificate da etichette nelle colonne, come esa_id (l’identificativo del soggetto), mdd (il gruppo di appartenenza), e bdi (il punteggio del test BDI-II).\n\nIn termini simbolisi, per indicare una singola osservazione della variabile generica \\(X\\), si utilizza la notazione \\(X_i\\), dove \\(i\\) rappresenta l’indice dell’osservazione. Questo implica che abbiamo un valore diverso di \\(X\\) per ogni differente \\(i\\). Nel caso presente, con 67 osservazioni, \\(i\\) varia da 1 a 67. Così, per rappresentare la seconda osservazione (quella con \\(i=2\\)), useremo la notazione \\(X_2\\). È importante notare che, sebbene in Python gli indici inizino da 0, nella notazione matematica tradizionale, come \\(X_i\\), l’indice parte da 1.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "href": "chapters/eda/05_exploring_numeric_data.html#distribuzioni-di-frequenza",
    "title": "19  Esplorare i dati numerici",
    "section": "19.2 Distribuzioni di frequenza",
    "text": "19.2 Distribuzioni di frequenza\nCome osservato nell’output della sezione precedente, i dati grezzi non forniscono un’interpretazione immediata. Per rendere i dati più comprensibili e sintetici, è utile costruire una distribuzione di frequenza.\nUna distribuzione di frequenza mostra quante volte i valori di una variabile si verificano all’interno di intervalli specifici. Nel caso dei punteggi BDI-II, possiamo raggruppare i punteggi in quattro classi:\n\n0–13: depressione minima\n14–19: depressione lieve-moderata\n20–28: depressione moderata-severa\n29–63: depressione severa\n\nOgni classe, denotata come \\(\\Delta_i\\), rappresenta un intervallo di valori, definito come \\([a_i, b_i)\\) (aperto a destra) o \\((a_i, b_i]\\) (aperto a sinistra), dove \\(a_i\\) e \\(b_i\\) sono rispettivamente il limite inferiore e superiore della classe. A ciascuna classe si associa un’ampiezza, data da \\(b_i - a_i\\), e un valore centrale, indicato con \\(\\bar{x}_i\\). Poiché ogni osservazione \\(x_i\\) appartiene a una sola classe \\(\\Delta_i\\), possiamo calcolare le seguenti quantità:\n\nFrequenza assoluta \\(n_i\\): il numero di osservazioni che rientrano nella classe \\(\\Delta_i\\).\n\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\), dove \\(n\\) è il numero totale di osservazioni.\n\nFrequenza relativa \\(f_i\\): la proporzione di osservazioni in ciascuna classe, calcolata come \\(f_i = n_i/n\\).\n\nProprietà: \\(f_1 + f_2 + \\dots + f_m = 1\\).\n\nFrequenza cumulata \\(N_i\\): il numero totale di osservazioni che rientrano nelle classi fino alla \\(i\\)-esima inclusa, calcolata come \\(N_i = \\sum_{j=1}^i n_j\\).\nFrequenza cumulata relativa \\(F_i\\): la somma delle frequenze relative fino alla \\(i\\)-esima classe, data da \\(F_i = \\frac{N_i}{n} = \\sum_{j=1}^i f_j\\).\n\nQueste misure permettono di riassumere in modo efficace la distribuzione dei punteggi e facilitano l’interpretazione delle caratteristiche del campione.\n\n19.2.1 Frequenze Assolute e Relative\nPer ottenere la distribuzione di frequenza assoluta e relativa dei valori BDI-II nel dataset di zetsche_2019future, è necessario prima aggiungere al DataFrame df una colonna che contenga una variabile categoriale che classifichi ciascuna osservazione in una delle quattro classi che descrivono la gravità della depressione. Questo risultato si ottiene con il metodo pandas.cut().\nIn pandas.cut(), il primo argomento x è un array unidimensionale (lista python, numpy.ndarray o pandas.Series) che contiene i dati e il secondo argomento bins specifica gli intervalli delle classi. La funzione restituisce un array che specifica la classe di appartenenza di ogni elemento dell’array x. L’argomento include_lowest=True specifica classi chiuse a destra (nel nostro caso è irrilevante dato che nessuna osservazione coincide con il limite di una classe).\n\n19.2.1.1 Frequenze assolute\n\ndf[\"bdi_class\"] = pd.cut(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], include_lowest=True)\ndf[\"bdi_class\"].value_counts()\n\nbdi_class\n(-0.001, 13.5]    36\n(28.5, 63.0]      17\n(19.5, 28.5]      12\n(13.5, 19.5]       1\nName: count, dtype: int64\n\n\n\n\n19.2.1.2 Frequenze relative\n\nabs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=[\"Abs. freq.\"])\nrel_freq = abs_freq / abs_freq.sum()\nrel_freq = rel_freq.round(2)\nrel_freq\n\n\n\n\n\n\n\ncol_0\nAbs. freq.\n\n\nbdi_class\n\n\n\n\n\n(-0.001, 13.5]\n0.55\n\n\n(13.5, 19.5]\n0.02\n\n\n(19.5, 28.5]\n0.18\n\n\n(28.5, 63.0]\n0.26\n\n\n\n\n\n\n\nControlliamo\n\nrel_freq.sum()\n\ncol_0\nAbs. freq.    1.01\ndtype: float64\n\n\n\ngrp_freq = pd.crosstab(index=df[\"group\"], columns=[\"Abs. freq.\"], colnames=[\"\"])\ngrp_freq\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nctl\n36\n\n\nmdd\n30\n\n\n\n\n\n\n\nVolendo modificare tale ordine è possibile accedere al DataFrame tramite loc e specificando come secondo argomento una lista dei valori nell’ordine desiderato:\n\ngrp_freq.loc[[\"mdd\", \"ctl\"], :]\n\n\n\n\n\n\n\n\nAbs. freq.\n\n\ngroup\n\n\n\n\n\nmdd\n30\n\n\nctl\n36\n\n\n\n\n\n\n\nIn Python, il simbolo : utilizzato all’interno delle parentesi quadre permette di ottenere uno slicing corrispondente all’intera lista.\n\n\n\n19.2.2 Distribuzioni congiunte\nLe variabili possono anche essere analizzate insieme tramite le distribuzioni congiunte di frequenze. Queste distribuzioni rappresentano l’insieme delle frequenze assolute o relative ad ogni possibile combinazione di valori delle variabili. Ad esempio, se l’insieme di variabili \\(V\\) è composto da due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali può assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) potrebbe essere espressa come \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), e \\(f(X = 2, Y = 2) = 0.2\\). Come nel caso delle distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1.\nPer i dati dell’esempio precedente, la funzione pd.crosstab può essere utilizzata anche per produrre questo tipo di tabella: basta indicare le serie corrispondenti alle variabili considerate come valori degli argomenti index e columns.\n\nbdi_group_abs_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"])\nbdi_group_abs_freq\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n36\n0\n\n\n(13.5, 19.5]\n0\n1\n\n\n(19.5, 28.5]\n0\n12\n\n\n(28.5, 63.0]\n0\n17\n\n\n\n\n\n\n\nOppure:\n\nbdi_group_rel_freq = pd.crosstab(index=df[\"bdi_class\"], columns=df[\"group\"], normalize=True)\nbdi_group_rel_freq\n\n\n\n\n\n\n\ngroup\nctl\nmdd\n\n\nbdi_class\n\n\n\n\n\n\n(-0.001, 13.5]\n0.545455\n0.000000\n\n\n(13.5, 19.5]\n0.000000\n0.015152\n\n\n(19.5, 28.5]\n0.000000\n0.181818\n\n\n(28.5, 63.0]\n0.000000\n0.257576\n\n\n\n\n\n\n\nInvocando il metodo plot.bar sulla tabella, otteniamo un grafico a barre nel quale le barre relative a uno stesso valore bdi_class risultino affiancate. Nel caso presente, le due distribuzioni sono completamente separate, quindi non abbiamo mai due barre affiancate:\n\nbdi_group_rel_freq.plot.bar();",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "href": "chapters/eda/05_exploring_numeric_data.html#istogramma",
    "title": "19  Esplorare i dati numerici",
    "section": "19.3 Istogramma",
    "text": "19.3 Istogramma\nUn istogramma rappresenta graficamente una distribuzione di frequenze. Un istogramma mostra sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate la densità della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\). La densità della frequenza relativa è misurata dalla funzione costante a tratti \\(\\varphi_n(x)= \\frac{f_i}{b_i-a_i}\\), dove \\(f_i\\) è la frequenza relativa della classe \\(\\Delta_i\\) e \\(b_i - a_i\\) rappresenta l’ampiezza della classe. In questo modo, l’area del rettangolo associato alla classe \\(\\Delta_i\\) sull’istogramma sarà proporzionale alla frequenza relativa \\(f_i\\). È importante notare che l’area totale dell’istogramma delle frequenze relative è uguale a 1.0, poiché rappresenta la somma delle aree dei singoli rettangoli.\nPer fare un esempio, costruiamo un istogramma per i valori BDI-II di Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II creo una prima versione dell’istogramma – si notino le frequenze assolute sull’asse delle ordinate.\n\nplt.hist(df[\"bdi\"], bins=[0, 13.5, 19.5, 28.5, 63], density=True, alpha=0.5)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()\n\n\n\n\n\n\n\n\nAnche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.\n\nplt.hist(df[\"bdi\"], density=True, alpha=0.5)\nplt.xlabel(\"BDI\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI Scores\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "href": "chapters/eda/05_exploring_numeric_data.html#kernel-density-plot",
    "title": "19  Esplorare i dati numerici",
    "section": "19.4 Kernel density plot",
    "text": "19.4 Kernel density plot\nConfrontando le due figure precedenti, emerge chiaramente una limitazione dell’istogramma: la sua forma dipende dall’arbitrarietà con cui vengono scelti il numero e l’ampiezza delle classi, rendendo difficile interpretare correttamente la distribuzione dei dati.\nPer superare questa difficoltà, possiamo utilizzare una tecnica alternativa chiamata stima della densità kernel (KDE) – si veda l’Appendice L. Mentre l’istogramma utilizza barre per rappresentare i dati, la KDE crea un profilo smussato che fornisce una visione più continua e meno dipendente dall’arbitrarietà delle classi.\nImmaginiamo un istogramma con classi di ampiezza molto piccola, tanto da avere una curva continua invece di barre discrete. Questo è ciò che fa la KDE: smussa il profilo dell’istogramma per ottenere una rappresentazione continua dei dati. Invece di utilizzare barre, la KDE posiziona una piccola curva (detta kernel) su ogni osservazione nel dataset. Queste curve possono essere gaussiane (a forma di campana) o di altro tipo. Ogni kernel ha un’altezza e una larghezza determinate da parametri di smussamento (o bandwidth), che controllano quanto deve essere larga e alta la curva. Tutte le curve kernel vengono sommate per creare una singola curva complessiva. Questa curva rappresenta la densità dei dati, mostrando come i dati sono distribuiti lungo il range dei valori.\nLa curva risultante dal KDE mostra la proporzione di casi per ciascun intervallo di valori. L’area sotto la curva in un determinato intervallo rappresenta la proporzione di casi della distribuzione che ricadono in quell’intervallo. Per esempio, se un intervallo ha un’area maggiore sotto la curva rispetto ad altri, significa che in quell’intervallo c’è una maggiore concentrazione di dati.\nLa curva di densità ottenuta tramite KDE fornisce dunque un’idea chiara di come i dati sono distribuiti senza dipendere dall’arbitrarietà della scelta delle classi dell’istogramma.\nCrediamo un kernel density plot per ciascuno dei due gruppi di valori BDI-II riportati da {cite:t}zetsche_2019future.\n\nsns.kdeplot(data=df, x=\"bdi\", hue=\"group\", common_norm=False)\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.title(\"Density Histogram of BDI-II Scores\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "href": "chapters/eda/05_exploring_numeric_data.html#consigli-per-creare-visualizzazioni-di-dati-efficaci",
    "title": "19  Esplorare i dati numerici",
    "section": "19.5 Consigli per Creare Visualizzazioni di Dati Efficaci",
    "text": "19.5 Consigli per Creare Visualizzazioni di Dati Efficaci\nEcco alcuni suggerimenti per creare visualizzazioni di dati esplicative, efficaci e di qualità adatta alle presentazioni:\n\nMessaggio chiaro: Assicurati che il grafico trasmetta un messaggio chiaro e immediato (ad esempio, “Il livello di benessere psicologico dei partecipanti aumenta nel tempo”).\nUso del colore:\n\nUtilizza i colori in modo ponderato e con moderazione.\nNon eccedere nell’uso dei colori solo perché è possibile farlo.\nLimita l’uso a non più di cinque o sei colori in una singola figura.\nVerifica che le scelte cromatiche non distorcano le conclusioni della figura.\nEvita l’uso contemporaneo di rosso e verde nello stesso grafico, poiché queste tonalità sono difficili da distinguere per le persone daltoniche.\n\nGuidare l’attenzione:\n\nUtilizza dimensioni, colori e testo per guidare l’attenzione del pubblico.\nEvidenzia elementi particolari del grafico per enfatizzare punti chiave.\n\nGestione del sovraccarico visivo:\n\nUtilizza la trasparenza per ridurre il “sovrapplotting” (che si verifica quando ci sono molti elementi sovrapposti nel grafico, come punti o linee, rendendo difficile individuare i pattern).\nQuesta tecnica è particolarmente utile quando si visualizza una grande quantità di dati.\nSe il dataset è molto ampio e l’aggiunta di trasparenza non è sufficiente, considera la visualizzazione di un sottocampione dei dati (un campione casuale di punti dati, scelto senza sostituzione). Questa tecnica è nota come sottocampionamento.\n\nElementi testuali:\n\nI titoli, le etichette degli assi e il testo delle legende devono essere chiari e facilmente comprensibili.\nGli elementi della legenda dovrebbero essere ordinati in modo logico e coerente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "href": "chapters/eda/05_exploring_numeric_data.html#forma-di-una-distribuzione",
    "title": "19  Esplorare i dati numerici",
    "section": "19.6 Forma di una Distribuzione",
    "text": "19.6 Forma di una Distribuzione\nIn statistica, la forma di una distribuzione descrive come i dati sono distribuiti intorno ai valori centrali. Si distingue tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali e multimodali. Un’illustrazione grafica è fornita nella figura seguente. Nel pannello 1, la distribuzione è unimodale con asimmetria negativa; nel pannello 2, la distribuzione è unimodale con asimmetria positiva; nel pannello 3, la distribuzione è simmetrica e unimodale; nel pannello 4, la distribuzione è bimodale.\n\n\n\nDistribuzioni\n\n\nIl grafico della densità di kernel (Kernel Density Plot) dei valori BDI-II nel campione di Zetsche et al. (2019) è bimodale. Questo indica che le osservazioni della distribuzione si raggruppano in due cluster distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l’altro gruppo tende ad avere valori BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "href": "chapters/eda/05_exploring_numeric_data.html#indici-di-posizione",
    "title": "19  Esplorare i dati numerici",
    "section": "19.7 Indici di posizione",
    "text": "19.7 Indici di posizione\n\n19.7.1 Quantili\nLa distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere sintetizzata attraverso l’uso dei quantili, che sono valori caratteristici che suddividono i dati in parti ugualmente numerose. I quartili sono tre quantili specifici: il primo quartile, \\(q_1\\), divide i dati in due parti, lasciando a sinistra il 25% del campione; il secondo quartile, \\(q_2\\), corrisponde alla mediana e divide i dati in due parti uguali; il terzo quartile lascia a sinistra il 75% del campione.\nInoltre, ci sono altri indici di posizione chiamati decili e percentili che suddividono i dati in parti di dimensioni uguali a 10% e 1%, rispettivamente.\nPer calcolare i quantili, i dati vengono prima ordinati in modo crescente e poi viene determinato il valore di \\(np\\), dove \\(n\\) è la dimensione del campione e \\(p\\) è l’ordine del quantile. Se \\(np\\) non è un intero, il valore del quantile corrisponde al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\). Se \\(np\\) è un intero, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(k\\) e \\(k+1\\), dove \\(k\\) è la parte intera di \\(np\\).\nGli indici di posizione possono essere utilizzati per creare un box-plot, una rappresentazione grafica della distribuzione dei dati che è molto popolare e può essere utilizzata in alternativa ad un istogramma.\nAd esempio, per calcolare la mediana della distribuzione dei nove soggetti con un unico episodio di depressione maggiore del campione clinico di Zetsche et al. (2019), si determina il valore di \\(np = 9 \\cdot 0.5 = 4.5\\), che non è un intero. Pertanto, il valore del secondo quartile è pari al valore del dato che si trova alla posizione successiva alla parte intera di \\(np\\), ovvero \\(q_2 = x_{4 + 1} = 27\\). Per calcolare il quantile di ordine \\(2/3\\), si determina il valore di \\(np = 9 \\cdot 2/3 = 6\\), che è un intero. Quindi, il valore del quantile corrisponde alla media dei dati nelle posizioni \\(6\\) e \\(7\\), ovvero \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\nUsiamo numpy per trovare la soluzione dell’esercizio precedente.\n\nx = [19, 26, 27, 28, 28, 33, 33, 41, 43]\nnp.quantile(x, 2 / 3)\n\n33.0",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "href": "chapters/eda/05_exploring_numeric_data.html#mostrare-i-dati",
    "title": "19  Esplorare i dati numerici",
    "section": "19.8 Mostrare i dati",
    "text": "19.8 Mostrare i dati\n\n19.8.1 Diagramma a scatola\nIl box plot è uno strumento grafico che visualizza la dispersione di una distribuzione. Per creare un box plot, si disegna un rettangolo (la “scatola”) di altezza arbitraria, basato sulla distanza interquartile (IQR), che corrisponde alla differenza tra il terzo quartile (\\(q_{0.75}\\)) e il primo quartile (\\(q_{0.25}\\)). La mediana (\\(q_{0.5}\\)) è rappresentata da una linea all’interno del rettangolo.\nAi lati della scatola, vengono tracciati due segmenti di retta, detti “baffi”, che rappresentano i valori adiacenti inferiore e superiore. Il valore adiacente inferiore è il valore più basso tra le osservazioni che è maggiore o uguale al primo quartile meno 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più alto tra le osservazioni che è minore o uguale al terzo quartile più 1.5 volte la distanza interquartile.\nSe ci sono dei valori che cadono al di fuori dei valori adiacenti, vengono chiamati “valori anomali” e sono rappresentati individualmente nel box plot per evidenziare la loro presenza e posizione. In questo modo, il box plot fornisce una rappresentazione visiva della distribuzione dei dati, permettendo di individuare facilmente eventuali valori anomali e di comprendere la dispersione dei dati.\n\nUtilizziamo un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\n\nsns.boxplot(x=\"group\", y=\"bdi\", data=df)\nplt.xlabel(\"Group\")\nplt.ylabel(\"BDI-II\")\nplt.title(\"Boxplot of BDI-II Scores by Group\")\nplt.show()\n\n\n\n\n\n\n\n\nUn risultato migliore si ottiene utilizzando un grafico a violino (violin plot) e includendo anche i dati grezzi.\n\n\n19.8.2 Grafico a Violino\nI grafici a violino combinano le caratteristiche dei box plot e dei grafici di densità di kernel (KDE plot) per offrire una rappresentazione più dettagliata dei dati. A questi grafici vengono sovrapposti i dati grezzi, fornendo una visione completa della distribuzione e delle caratteristiche dei dati.\n\nsns.violinplot(x=\"group\", y=\"bdi\", data=df, color=\"lightgray\")\nsns.stripplot(x=\"group\", y=\"bdi\", data=df, color=\"black\", size=5, jitter=True, alpha=0.3)\nplt.ylabel(\"BDI-II\")\nplt.xlabel(\"Group\")\nplt.title(\"Violin Plot with Overlay of Individual Data Points of BDI-II Scores by Group\")\nplt.show()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/05_exploring_numeric_data.html#commenti-e-considerazioni-finali",
    "title": "19  Esplorare i dati numerici",
    "section": "19.9 Commenti e considerazioni finali",
    "text": "19.9 Commenti e considerazioni finali\nAbbiamo esplorato diverse tecniche per sintetizzare e visualizzare i dati, includendo distribuzioni di frequenze, istogrammi e grafici di densità. Questi strumenti sono essenziali per comprendere meglio i dati e presentare risultati in modo chiaro e informativo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/05_exploring_numeric_data.html#informazioni-sullambiente-di-sviluppo",
    "title": "19  Esplorare i dati numerici",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Aug 31 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\npandas    : 2.2.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Esplorare i dati numerici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html",
    "href": "chapters/eda/06_data_visualization.html",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "",
    "text": "Introduzione\nIn questo capitolo verranno introdotti i principi fondamentali della visualizzazione dei dati, accompagnati da una descrizione concisa. Per un approfondimento su ciascun principio, si rimanda al capitolo Data Visualization del libro Introduction to Data Science.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "href": "chapters/eda/06_data_visualization.html#codificare-i-dati-attraverso-segnali-visivi",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.1 Codificare i dati attraverso segnali visivi",
    "text": "20.1 Codificare i dati attraverso segnali visivi\nIniziamo con una panoramica dei principali segnali visivi utilizzati per codificare i dati: posizione, lunghezza, angoli, area, luminosità e tonalità del colore. Tra questi, posizione e lunghezza sono i segnali visivi più efficaci e intuitivi, poiché il cervello umano è particolarmente abile nel riconoscere variazioni spaziali. Questo rende la posizione e la lunghezza strumenti potenti per la rappresentazione quantitativa. In altre parole, le persone riescono a confrontare con maggiore precisione altezze e lunghezze (come le barre in un barplot) rispetto ad angoli o aree (come in un grafico a torta).\nAngoli e aree, sebbene comunemente usati, sono segnali visivi meno efficaci. Grafici come i pie chart, che si basano su angoli e aree per rappresentare quantità, risultano spesso meno precisi e più difficili da interpretare, specialmente quando le differenze sono piccole. Anche l’uso dell’area, ad esempio nei bubble plot, può distorcere la percezione delle differenze tra i dati, a meno che non venga gestita correttamente. Anche se l’area di una bolla può essere proporzionale al valore rappresentato, la percezione umana tende a sovrastimare le differenze tra aree più grandi.\nLuminosità e tonalità del colore sono utili per rappresentare variabili qualitative o categoriali, ma possono risultare difficili da interpretare quando si tratta di confrontare quantità precise. Tuttavia, il colore gioca un ruolo cruciale nelle visualizzazioni multidimensionali, come le heatmap, dove è necessario rappresentare più di due variabili contemporaneamente. È importante, però, usare il colore con attenzione, soprattutto per garantire l’accessibilità a persone con problemi di daltonismo.\nLe tabelle sono utili quando si ha una quantità limitata di dati e si richiede una precisione numerica rigorosa. Tuttavia, per set di dati più grandi o per evidenziare tendenze e differenze, i grafici (come i barplot) sono generalmente più efficaci. Le tabelle non offrono lo stesso impatto visivo immediato e rendono più difficile l’individuazione di pattern complessi.\n\n20.1.1 Ulteriori considerazioni sulla scelta della visualizzazione\nLa scelta della visualizzazione più appropriata dipende sia dalla natura dei dati che dallo scopo della comunicazione. Per esempio:\n\nBarplot o dot plot sono ideali per confrontare valori quantitativi tra categorie.\nIstogrammi, boxplot e raincloud plots sono più adatti per descrivere la distribuzione di dati continui e fare confronti tra categorie.\nGrafici di dispersione (scatter plot) sono eccellenti per esplorare relazioni tra due variabili continue.\n\nLa chiarezza e la leggibilità sono principi fondamentali nella creazione di visualizzazioni efficaci. L’aggiunta di elementi visivi eccessivi, come decorazioni superflue o troppi colori, può distrarre dal messaggio principale. Un buon grafico deve essere semplice, ma allo stesso tempo completo, includendo solo gli elementi visivi necessari per trasmettere il messaggio desiderato.\nIn conclusione, scegliere i segnali visivi adeguati e il tipo di grafico più appropriato non solo migliora l’accuratezza della comunicazione, ma rende le informazioni più accessibili e comprensibili per il pubblico.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "href": "chapters/eda/06_data_visualization.html#quando-includere-lo-zero",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.2 Quando includere lo zero",
    "text": "20.2 Quando includere lo zero\nQuando si usa la lunghezza come segnale visivo, come nei barplot, è essenziale che l’asse parta da zero. Non farlo può essere fuorviante e far sembrare le differenze più grandi di quanto non siano in realtà. Questo errore viene spesso sfruttato nei media per esagerare differenze apparentemente significative.\nTuttavia, quando si usa la posizione (ad esempio in un grafico a dispersione), non è sempre necessario includere lo zero, soprattutto se l’interesse principale è il confronto tra gruppi rispetto alla variabilità interna.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-le-distorsioni",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.3 Evitare le distorsioni",
    "text": "20.3 Evitare le distorsioni\nUna distorsione comune si verifica quando le differenze tra quantità sono rappresentate utilizzando aree, come nei bubble plot, dove il raggio dei cerchi è proporzionale al dato. Il problema è che, poiché l’area di un cerchio è proporzionale al quadrato del raggio, le differenze sembrano molto più ampie di quanto siano realmente. Per evitare queste distorsioni, è meglio utilizzare la posizione o la lunghezza, come in un grafico a barre, per confrontare direttamente le quantità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "href": "chapters/eda/06_data_visualization.html#ordinare-le-categorie",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.4 Ordinare le categorie",
    "text": "20.4 Ordinare le categorie\nQuando si visualizzano categorie, come nei barplot o nei boxplot, è opportuno ordinarle in base al valore della variabile di interesse, anziché in ordine alfabetico. Questo aiuta a evidenziare pattern significativi e facilita il confronto tra categorie.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "href": "chapters/eda/06_data_visualization.html#evitare-i-dynamite-plots",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.5 Evitare i Dynamite Plots",
    "text": "20.5 Evitare i Dynamite Plots\nI dynamite plots, che mostrano la media e l’errore standard (o la deviazione standard), sono spesso utilizzati in psicologia ma sono fuorvianti. Questi grafici tendono a esagerare le differenze e possono indurre false interpretazioni. È preferibile mostrare tutti i dati, ad esempio tramite un dot plot, che fornisce un’immagine più chiara della distribuzione dei dati (Butler, 2022).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "href": "chapters/eda/06_data_visualization.html#facilitare-i-confronti",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.6 Facilitare i confronti",
    "text": "20.6 Facilitare i confronti\nQuando si confrontano due distribuzioni, come in un istogramma, è fondamentale mantenere gli stessi assi per entrambi i grafici. Se le distribuzioni sono presentate su assi con scale diverse, il confronto diventa difficile e potrebbe portare a conclusioni errate. Allineare i grafici verticalmente o orizzontalmente consente di percepire più facilmente le differenze tra i gruppi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "href": "chapters/eda/06_data_visualization.html#trasformazioni-logaritmiche",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.7 Trasformazioni logaritmiche",
    "text": "20.7 Trasformazioni logaritmiche\nLe trasformazioni logaritmiche sono utili quando si lavora con dati distribuiti su più ordini di grandezza o quando le variazioni tra le quantità sono moltiplicative (West, 2022). L’uso della scala logaritmica in un grafico a barre o a dispersione può ridurre le distorsioni visive e migliorare l’interpretazione dei dati. Questo approccio è particolarmente utile quando alcuni valori estremi potrebbero dominare il grafico, nascondendo dettagli rilevanti.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "href": "chapters/eda/06_data_visualization.html#codificare-una-terza-variabile",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.8 Codificare una terza variabile",
    "text": "20.8 Codificare una terza variabile\nPer rappresentare tre variabili, è possibile utilizzare un grafico di dispersione con variabili codificate attraverso dimensioni aggiuntive come il colore, la dimensione o la forma dei punti. Ad esempio, in un grafico che confronta aspettativa di vita e reddito, la dimensione dei punti potrebbe rappresentare la popolazione e il colore la regione geografica. Quando si utilizza il colore per rappresentare una variabile, è importante scegliere palette cromatiche accessibili anche per chi è affetto da daltonismo, evitando combinazioni problematiche come rosso-verde.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "href": "chapters/eda/06_data_visualization.html#evitare-pseudo-tre-dimensioni",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.9 Evitare pseudo-tre dimensioni",
    "text": "20.9 Evitare pseudo-tre dimensioni\nGrafici tridimensionali, come barre o pie chart 3D, spesso aggiungono confusione senza fornire informazioni aggiuntive significative. Sebbene visivamente accattivanti, questi grafici distorcono la percezione e rendono difficile l’interpretazione accurata dei dati. È preferibile mantenere le visualizzazioni bidimensionali, a meno che la terza dimensione non rappresenti effettivamente una variabile aggiuntiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "href": "chapters/eda/06_data_visualization.html#scegliere-il-numero-giusto-di-cifre-significative",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.10 Scegliere il numero giusto di cifre significative",
    "text": "20.10 Scegliere il numero giusto di cifre significative\nÈ importante evitare l’uso di troppe cifre decimali nelle tabelle e nei grafici. Spesso, una o due cifre significative sono sufficienti per rappresentare accuratamente i dati, mentre l’aggiunta di cifre inutili può confondere il lettore e dare un falso senso di precisione. Limitiamoci a mostrare solo le cifre necessarie per trasmettere il messaggio in modo chiaro.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "href": "chapters/eda/06_data_visualization.html#conoscere-il-pubblico",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.11 Conoscere il pubblico",
    "text": "20.11 Conoscere il pubblico\nInfine, è fondamentale adattare la visualizzazione dei dati al pubblico di riferimento. Grafici progettati per l’analisi esplorativa interna possono contenere dettagli tecnici complessi, ma quando si comunica a un pubblico più ampio o non specializzato, è necessario semplificare. Ad esempio, utilizzare una scala logaritmica può essere utile per un pubblico esperto, ma confondere un pubblico generale. In questi casi, mantenere la scala lineare e spiegare chiaramente i dati aiuta a evitare malintesi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/06_data_visualization.html#conclusioni",
    "href": "chapters/eda/06_data_visualization.html#conclusioni",
    "title": "20  Principi della visualizzazione dei dati",
    "section": "20.12 Conclusioni",
    "text": "20.12 Conclusioni\nI principi di visualizzazione dei dati trattati in questo capitolo sono strumenti fondamentali per garantire chiarezza e accuratezza nella rappresentazione delle informazioni. Scelte appropriate di grafici, segnali visivi e trasformazioni facilitano la comprensione, riducendo la possibilità di distorsioni o interpretazioni errate.\n\n\n\n\nButler, R. C. (2022). Popularity leads to bad habits: Alternatives to «the statistics» routine of significance,«alphabet soup» and dynamite plots. In Annals of Applied Biology (Fasc. 2; Vol. 180, pp. 182–195). Wiley Online Library.\n\n\nHealy, K. (2018). Data visualization: a practical introduction. Princeton University Press.\n\n\nWest, R. M. (2022). Best practice in statistics: The use of log transformation. Annals of Clinical Biochemistry, 59(3), 162–165.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science. \" O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: a primer on making informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Principi della visualizzazione dei dati</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html",
    "href": "chapters/eda/07_loc_scale.html",
    "title": "21  Indicatori di tendenza centrale e variabilità",
    "section": "",
    "text": "21.1 Introduzione\nLa visualizzazione grafica dei dati rappresenta il pilastro fondamentale di ogni analisi quantitativa. Grazie alle rappresentazioni grafiche adeguate, è possibile individuare importanti caratteristiche di una distribuzione, quali la simmetria o l’asimmetria, nonché la presenza di una o più mode. Successivamente, al fine di descrivere sinteticamente le principali caratteristiche dei dati, si rende necessario l’utilizzo di specifici indici numerici. In questo capitolo, verranno presentati i principali indicatori della statistica descrittiva.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "href": "chapters/eda/07_loc_scale.html#indici-di-tendenza-centrale",
    "title": "21  Indicatori di tendenza centrale e variabilità",
    "section": "21.2 Indici di tendenza centrale",
    "text": "21.2 Indici di tendenza centrale\nGli indici di tendenza centrale sono misure statistiche che cercano di rappresentare un valore tipico o centrale all’interno di un insieme di dati. Sono utilizzati per ottenere una comprensione immediata della distribuzione dei dati senza dover analizzare l’intero insieme. Gli indici di tendenza centrale sono fondamentali nell’analisi statistica, in quanto forniscono una sintesi semplice e comprensibile delle caratteristiche principali di un insieme di dati. I principali indici di tendenza centrale sono:\n\nMedia: La media è la somma di tutti i valori divisa per il numero totale di valori. È spesso utilizzata come misura generale di tendenza centrale, ma è sensibile agli estremi (valori molto alti o molto bassi).\nMediana: La mediana è il valore che divide l’insieme di dati in due parti uguali. A differenza della media, non è influenzata da valori estremi ed è quindi più robusta in presenza di outlier.\nModa: La moda è il valore che appare più frequentemente in un insieme di dati. In alcuni casi, può non essere presente o esserci più di una moda.\n\nLa scelta dell’indice di tendenza centrale appropriato dipende dalla natura dei dati e dall’obiettivo dell’analisi. Ad esempio, la mediana potrebbe essere preferita alla media se l’insieme di dati contiene valori anomali che potrebbero distorcere la rappresentazione centrale. La conoscenza e l’applicazione corretta di questi indici possono fornire una preziosa intuizione sulle caratteristiche centrali di una distribuzione di dati.\n\n21.2.1 Media\nLa media aritmetica di un insieme di valori rappresenta il punto centrale o il baricentro della distribuzione dei dati. È calcolata come la somma di tutti i valori divisa per il numero totale di valori, ed è espressa dalla formula:\n\\[\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i,\n\\tag{21.1}\\]\ndove \\(x_i\\) rappresenta i valori nell’insieme, \\(n\\) è il numero totale di valori, e \\(\\sum\\) indica la sommatoria.\n\n21.2.1.1 Proprietà della media\nUna proprietà fondamentale della media è che la somma degli scarti di ciascun valore dalla media è zero:\n\\[\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\tag{21.2}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nQuesta proprietà implica che i dati sono equamente distribuiti intorno alla media.\n\n\n21.2.1.2 La media come centro di gravità dell’istogramma\nLa media aritmetica può essere interpretata come il centro di gravità o il punto di equilibrio della distribuzione dei dati. In termini fisici, il centro di gravità è il punto in cui la massa di un sistema è equilibrata o concentrata.\nIn termini statistici, possiamo considerare la media come il punto in cui la distribuzione dei dati è in equilibrio. Ogni valore dell’insieme di dati può essere visto come un punto materiale con una massa proporzionale al suo valore. Se immaginiamo questi punti disposti su una linea, con valori più grandi a destra e più piccoli a sinistra, la media corrisponderà esattamente al punto in cui la distribuzione sarebbe in equilibrio.\n\n\n21.2.1.3 Principio dei minimi quadrati\nLa posizione della media minimizza la somma delle distanze quadrate dai dati, un principio noto come “metodo dei minimi quadrati”. Matematicamente, questo si traduce nel fatto che la somma dei quadrati degli scarti tra ciascun valore e la media è minima. Questo principio è alla base dell’analisi statistica dei modelli di regressione e conferma l’interpretazione della media come centro di gravità dell’istogramma.\n\n\n21.2.1.4 Calcolo della media con NumPy\nPer calcolare la media di un piccolo numero di valori in Python, possiamo utilizzare la somma di questi valori e dividerla per il numero totale di elementi. Consideriamo ad esempio i valori 12, 44, 21, 62, 24:\n\n(12 + 44 + 21 + 62 + 24) / 5\n\n32.6\n\n\novvero\n\nx = np.array([12, 44, 21, 62, 24])\nnp.mean(x)\n\n32.6\n\n\n\nnp.average(x)\n\n32.6\n\n\n\n\n21.2.1.5 Le proporzioni sono medie\nSe una collezione consiste solo di uni e zeri, allora la somma della collezione è il numero di uni in essa, e la media della collezione è la proporzione di uni.\n\nzero_one = np.array([1, 1, 1, 0])\nresult = sum(zero_one)\nprint(result) \n\n3\n\n\n\nnp.mean(zero_one)\n\n0.75\n\n\nÈ possibile sostituire 1 con il valore booleano True e 0 con False:\n\nnp.mean(np.array([(True, True, True, False)]))\n\n0.75\n\n\n\n\n21.2.1.6 Limiti della media aritmetica\nLa media aritmetica, tuttavia, ha alcune limitazioni: non sempre è l’indice più adeguato per descrivere accuratamente la tendenza centrale della distribuzione, specialmente quando si verificano asimmetrie o valori anomali (outlier). In queste situazioni, è più indicato utilizzare la mediana o la media spuntata (come spiegheremo successivamente).\n\n\n21.2.1.7 Medie per gruppi\nMolto spesso però i nostri dati sono contenuti in file e inserire i dati manualmente non è fattibile. Per fare un esempio, considereremo i dati del Progetto STAR, contenuti nel file STAR.csv, che rappresentano un’importante indagine sulle prestazioni degli studenti in relazione alla dimensione delle classi. Negli anni ’80, i legislatori del Tennessee considerarono la possibilità di ridurre le dimensioni delle classi per migliorare il rendimento degli studenti. Al fine di prendere decisioni informate, commissionarono lo studio multimilionario “Progetto Student-Teacher Achievement Ratio” (Project STAR). Lo studio coinvolgeva bambini della scuola materna assegnati casualmente a classi piccole, con 13-17 studenti, o classi di dimensioni regolari, con 22-25 studenti, fino alla fine della terza elementare. I ricercatori hanno seguito il progresso degli studenti nel tempo, concentrandosi su variabili di risultato, come i punteggi dei test standardizzati di lettura (reading) e matematica (math) alla terza elementare, oltre ai tassi di diploma di scuola superiore (graduated, con valore 1 per sì e 0 per no).\nPoniamoci il problema di calcolare la media dei punteggi math calcolata separatamente per i due gruppi di studenti: coloro che hanno completato la scuola superiore e coloro che non l’hanno completata.\nProcediamo all’importazione dei dati per iniziare l’analisi.\n\ndf = pd.read_csv(\"../../data/STAR.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\nEsaminiamo la numerosità di ciascun gruppo.\n\ndf.groupby(\"graduated\").size()\n\ngraduated\n0     166\n1    1108\ndtype: int64\n\n\nOra procediamo al calcolo delle medie dei punteggi math all’interno dei due gruppi. Per rendere la risposta più concisa, useremo la funzione round() per stampare solo 2 valori decimali.\n\ndf.groupby(\"graduated\")[\"math\"].mean().round(2)\n\ngraduated\n0    606.64\n1    635.33\nName: math, dtype: float64\n\n\nIn alternativa, possiamo usare il metodo .describe():\n\ndf.groupby(\"graduated\")[\"math\"].describe().round(1)\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\ngraduated\n\n\n\n\n\n\n\n\n\n\n\n\n0\n166.0\n606.6\n34.1\n526.0\n580.5\n606.0\n629.0\n711.0\n\n\n1\n1108.0\n635.3\n38.1\n515.0\n609.5\n634.0\n659.0\n774.0\n\n\n\n\n\n\n\n\n\n\n21.2.2 Media spuntata\nLa media spuntata, indicata come \\(\\bar{x}_t\\) o trimmed mean, è un metodo di calcolo della media che prevede l’eliminazione di una determinata percentuale di dati estremi prima di effettuare la media aritmetica. Solitamente, viene eliminato il 10% dei dati, ovvero il 5% all’inizio e alla fine della distribuzione. Per ottenere la media spuntata, i dati vengono ordinati in modo crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), e quindi viene eliminato il primo 5% e l’ultimo 5% dei dati nella sequenza ordinata. Infine, la media spuntata è calcolata come la media aritmetica dei dati rimanenti. Questo approccio è utile quando ci sono valori anomali o quando la distribuzione è asimmetrica e la media aritmetica non rappresenta adeguatamente la tendenza centrale dei dati.\nA titolo di esempio, procediamo al calcolo della media spuntata dei valori math per i due gruppi definiti dalla variabile graduated, escludendo il 10% dei valori più estremi.\n\nnot_graduated = df[df[\"graduated\"] == 0].math\nstats.trim_mean(not_graduated, 0.10)\n\n605.6492537313433\n\n\n\ngraduated = df[df[\"graduated\"] == 1].math\nstats.trim_mean(graduated, 0.10)\n\n634.4403153153153\n\n\n\n\n21.2.3 Quantili\nIl quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\) rappresenta il valore che divide la distribuzione dei dati in modo tale che una frazione \\(p\\) dei dati si trovi al di sotto di esso.\nLa formula per calcolare il quantile non interpolato è la seguente:\n\\[\n    q_p = x_{(k)},\n\\]\ndove \\(x_{(k)}\\) è l’elemento \\(k\\)-esimo nell’insieme di dati ordinato in modo crescente, e \\(k\\) è calcolato come:\n\\[\nk = \\lceil p \\cdot n \\rceil,\n\\]\ndove \\(n\\) è il numero totale di dati nel campione, e \\(\\lceil \\cdot \\rceil\\) rappresenta la funzione di arrotondamento all’intero successivo. In questa definizione, il quantile non interpolato corrisponde al valore effettivo nell’insieme di dati, senza effettuare alcuna interpolazione tra i valori circostanti.\nAd esempio, consideriamo il seguente insieme di dati: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}\\). Supponiamo di voler calcolare il quantile non interpolato di ordine \\(p = 0.3\\) (cioè il 30° percentile).\nOrdiniamo i dati in modo crescente: \\(\\{ 15, 20, 23, 25, 28, 30, 35, 40, 45, 50 \\}.\\) Calcoliamo \\(k\\) utilizzando la formula \\(k = \\lceil p \\cdot n \\rceil\\), dove \\(n\\) è il numero totale di dati nel campione. Nel nostro caso, \\(n = 10\\) e \\(p = 0.3\\):\n\\[\nk = \\lceil 0.3 \\cdot 10 \\rceil = \\lceil 3 \\rceil = 3.\n\\]\nIl quantile non interpolato corrisponde al valore \\(x_{(k)}\\), ovvero l’elemento \\(k\\)-esimo nell’insieme ordinato: \\(q_{0.3} = x_{(3)} = 23.\\)\nOltre al quantile non interpolato, esiste anche il concetto di quantile interpolato. A differenza del quantile non interpolato, il quantile interpolato può essere calcolato anche per percentili che non corrispondono esattamente a valori presenti nell’insieme di dati. Per ottenere il valore del quantile interpolato, viene utilizzato un procedimento di interpolazione lineare tra i valori adiacenti. In genere, il calcolo del quantile interpolato viene eseguito mediante l’uso di software dedicati.\nOra, procediamo al calcolo dei quantili di ordine 0.10 e 0.90 per i valori math all’interno dei due gruppi. I quantili sono dei valori che dividono la distribuzione dei dati in parti specifiche. Ad esempio, il quantile di ordine 0.10 corrisponde al valore al di sotto del quale si trova il 10% dei dati, mentre il quantile di ordine 0.90 rappresenta il valore al di sotto del quale si trova il 90% dei dati.\nCalcoliamo i quantili di ordine 0.1 e 0.9 della distribuzione dei punteggi math nei due gruppi definiti dalla variabile graduated.\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.1), \n    df[df[\"graduated\"] == 1][\"math\"].quantile(0.9)\n]\n\n[588.0, 684.0]\n\n\n\n# Quantili di ordine 0.1 e 0.9 per il gruppo di studenti che non hanno completato la scuola superiore\n[\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.1),\n    df[df[\"graduated\"] == 0][\"math\"].quantile(0.9),\n]\n\n[564.5, 651.0]\n\n\n\n\n21.2.4 Moda e mediana\nIn precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la moda (Mo), che rappresenta il valore centrale della classe con la frequenza massima (in alcune distribuzioni può esserci più di una moda, rendendola multimodale e facendo perdere a questo indice il suo significato di indicatore di tendenza centrale); e la mediana (\\(\\tilde{x}\\)), che rappresenta il valore corrispondente al quantile di ordine 0.5 della distribuzione.\n\n\n21.2.5 Quando usare media, moda, mediana\nLa moda può essere utilizzata per dati a livello nominale o ordinale ed è l’unica tra le tre statistiche che può essere calcolata in questi casi.\nLa media, d’altra parte, è una buona misura di tendenza centrale solo se la distribuzione dei dati è simmetrica, ossia se i valori sono distribuiti uniformemente a sinistra e a destra della media. Tuttavia, se ci sono valori anomali o se la distribuzione è asimmetrica, la media può essere influenzata in modo significativo e, pertanto, potrebbe non essere la scelta migliore come misura di tendenza centrale.\nIn queste situazioni, la mediana può fornire una misura migliore di tendenza centrale rispetto alla media poiché è meno influenzata dai valori anomali e si basa esclusivamente sul valore centrale dell’insieme di dati. Di conseguenza, la scelta tra media e mediana dipende dal tipo di distribuzione dei dati e dagli obiettivi dell’analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#indici-di-dispersione",
    "href": "chapters/eda/07_loc_scale.html#indici-di-dispersione",
    "title": "21  Indicatori di tendenza centrale e variabilità",
    "section": "21.3 Indici di dispersione",
    "text": "21.3 Indici di dispersione\nLe misure di posizione descritte in precedenza, come le medie e gli indici di posizione, offrono una sintesi dei dati mettendo in evidenza la tendenza centrale delle osservazioni. Tuttavia, trascurano un aspetto importante della distribuzione dei dati: la variabilità dei valori numerici della variabile statistica. Pertanto, è essenziale completare la descrizione della distribuzione di una variabile statistica utilizzando anche indicatori che valutino la dispersione delle unità statistiche. In questo modo, otterremo una visione più completa e approfondita delle caratteristiche del campione analizzato.\n\n21.3.1 Indici basati sull’ordinamento dei dati\nPer valutare la variabilità dei dati, è possibile utilizzare indici basati sull’ordinamento dei dati. L’indice più semplice è l’intervallo di variazione, che corrisponde alla differenza tra il valore massimo e il valore minimo di una distribuzione di dati. Tuttavia, questo indice ha il limite di essere calcolato basandosi solo su due valori della distribuzione, e non tiene conto di tutte le informazioni disponibili. Inoltre, l’intervallo di variazione può essere fortemente influenzato dalla presenza di valori anomali.\nUn altro indice basato sull’ordinamento dei dati è la differenza interquartile, già incontrata in precedenza. Anche se questo indice utilizza più informazioni rispetto all’intervallo di variazione, presenta comunque il limite di essere calcolato basandosi solo su due valori della distribuzione, ossia il primo quartile \\(Q_1\\) e il terzo quartile \\(Q_3\\).\nPer valutare la variabilità in modo più completo, è necessario utilizzare altri indici di variabilità che tengano conto di tutti i dati disponibili. In questo modo, si otterrà una valutazione più accurata della dispersione dei valori nella distribuzione e si potranno individuare eventuali pattern o tendenze nascoste.\n\n\n21.3.2 Varianza\nDate le limitazioni delle statistiche descritte in precedenza, è più comune utilizzare una misura di variabilità che tenga conto della dispersione dei dati rispetto a un indice di tendenza centrale. La varianza è la misura di variabilità più utilizzata per valutare la variabilità di una variabile statistica. Essa è definita come la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione, come segue:\n\\[\n\\begin{equation}\nS^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2.\n\\end{equation}\n\\tag{21.3}\\]\nLa varianza è una misura di dispersione più completa rispetto a quelle descritte in precedenza. Tuttavia, è appropriata solo nel caso di distribuzioni simmetriche ed è fortemente influenzata dai valori anomali, come altre misure di dispersione. Inoltre, la varianza è espressa in un’unità di misura che è il quadrato dell’unità di misura dei dati originali, pertanto, potrebbe non essere facilmente interpretata in modo intuitivo.\nCalcoliamo la varianza dei valori math per i dati del progetto STAR. Applicando l’equazione della varianza, otteniamo:\n\nsum((df[\"math\"] - np.mean(df[\"math\"])) ** 2) / len(df[\"math\"])\n\n1507.2328523125225\n\n\nPiù semplicemente, possiamo usare la funzione np.var():\n\nnp.var(df[\"math\"])\n\n1507.2328523125225\n\n\n\n21.3.2.1 Stima della varianza della popolazione\nSi noti il denominatore della formula della varianza. Nell’Equazione 21.3, ho utilizzato \\(n\\) come denominatore (l’ampiezza campionaria, ovvero il numero di osservazioni nel campione). In questo modo, otteniamo la varianza come statistica descrittiva del campione. Tuttavia, è possibile utilizzare \\(n-1\\) come denominatore alternativo:\n\\[\n\\begin{equation}\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\n\\end{equation}\n\\tag{21.4}\\]\nIn questo secondo caso, otteniamo la varianza come stimatore della varianza della popolazione. Si può dimostrare che l’Equazione 21.4 fornisce una stima corretta (ovvero, non distorta) della varianza della popolazione da cui abbiamo ottenuto il campione, mentre l’Equazione 21.3 fornisce (in media) una stima troppo piccola della varianza della popolazione. Si presti attenzione alla notazione: \\(S^2\\) rappresenta la varianza come statistica descrittiva, mentre \\(s^2\\) rappresenta la varianza come stimatore.\nPer illustrare questo punto, svolgiamo una simulazione. Consideriamo la distribuzione dei punteggi del quoziente di intelligenza (QI). I valori del QI seguono una particolare distribuzione chiamata distribuzione normale, con media 100 e deviazione standard 15. La forma di questa distribuzione è illustrata nella figura seguente.\n\nx = np.arange(100 - 4 * 15, 100 + 4 * 15, 0.001)\n\nmu = 100\nsigma = 15\n\npdf = stats.norm.pdf(x, mu, sigma)\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()\n\n\n\n\n\n\n\n\nSupponiamo di estrarre un campione casuale di 4 osservazioni dalla popolazione del quoziente di intelligenza – in altre parole, supponiamo di misurare il quoziente di intelligenza di 4 persone prese a caso dalla popolazione.\n\nx = rng.normal(loc=100, scale=15, size=4)\nprint(x)\n\n[133.75543403 101.43900843  94.59994101  92.23138768]\n\n\nCalcoliamo la varianza usando \\(n\\) al denominatore. Si noti che la vera varianza del quoziente di intelligenza è \\(15^2\\) = 225.\n\nnp.var(x)\n\n277.4320993427046\n\n\nConsideriamo ora 10 campioni casuali del QI, ciascuno di ampiezza 4.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nIl primo campione è\n\nrandom_samples[0]\n\narray([105.84924945, 124.12259109,  95.58010071,  76.35634967])\n\n\nIl decimo campione è\n\nrandom_samples[9]\n\narray([ 89.29531757, 106.32615516,  91.6023182 ,  90.68549989])\n\n\nStampiamo i valori di tutti i 10 campioni.\n\nrs = np.array(random_samples)\nrs\n\narray([[105.84924945, 124.12259109,  95.58010071,  76.35634967],\n       [ 80.23586783, 114.3021062 ,  98.54492676,  91.47149307],\n       [114.26794026,  86.66403178,  79.74954446, 102.23174837],\n       [110.22926012,  80.75554712, 100.93634803,  83.44336602],\n       [ 80.68461566, 122.39378237, 115.0707391 ,  85.53365763],\n       [ 82.42398628,  99.06628072,  95.40790879,  95.03682044],\n       [ 86.56471564,  97.82411638,  98.28650923,  99.23388255],\n       [120.24780337,  94.92211176,  87.6421954 ,  89.48037814],\n       [ 89.06126415, 109.72357033, 119.31191461, 125.38475089],\n       [ 89.29531757, 106.32615516,  91.6023182 ,  90.68549989]])\n\n\nPer ciascun campione (ovvero, per ciascuna riga della matrice precedente), calcoliamo la varianza usando la formula con \\(n\\) al denominatore. Otteniamo così 10 stime della varianza della popolazione del QI.\n\nx_var = np.var(rs, axis=1)  # applichiamo la funzione su ciascuna riga\nprint(x_var)\n\n[298.44010918 152.5955359  180.87367224 149.56472568 326.89426388\n  39.64935846  26.73631903 171.07120901 189.71979388  47.47289476]\n\n\nNotiamo due cose:\n\nle stime sono molto diverse tra loro; questo fenomeno è noto con il nome di variabilità campionaria;\nin media le stime sembrano troppo piccole.\n\nPer aumentare la sicurezza riguardo al secondo punto menzionato in precedenza, ripeteremo la simulazione utilizzando un numero di iterazioni maggiore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=0, axis=1)\n\nEsaminiamo la distribuzione dei valori ottenuti.\n\nplt.hist(x_var, bins=10, alpha=0.5)\nplt.xlabel(\"Varianza\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Varianza del QI in campioni di n = 4\")\nplt.show()\n\n\n\n\n\n\n\n\nLa stima più verosimile della varianza del QI è dato dalla media di questa distribuzione.\n\nnp.mean(x_var)\n\n170.04960311858687\n\n\nSi noti che il nostro spospetto è stato confermato: il valore medio della stima della varianza ottenuta con l’Equazione 21.3 è troppo piccolo rispetto al valore corretto di \\(15^2 = 225\\).\nRipetiamo ora la simulazione usando la formula della varianza con \\(n-1\\) al denominatore.\n\nmu = 100\nsigma = 15\nsize = 4\nniter = 10000\nrandom_samples = []\n\nfor i in range(niter):\n    one_sample = rng.normal(loc=mu, scale=sigma, size=size)\n    random_samples.append(one_sample)\n\nrs = np.array(random_samples)\nx_var = np.var(rs, ddof=1, axis=1)\n\nnp.mean(x_var)\n\n226.57333153886847\n\n\nNel secondo caso, se utilizziamo \\(n-1\\) come denominatore per calcolare la stima della varianza, il valore atteso di questa stima è molto vicino al valore corretto di 225. Se il numero di campioni fosse infinito, i due valori sarebbero identici.\nIn conclusione, le due formule della varianza hanno scopi diversi. La formula della varianza con \\(n\\) al denominatore viene utilizzata come statistica descrittiva per descrivere la variabilità di un particolare campione di osservazioni. D’altro canto, la formula della varianza con \\(n-1\\) al denominatore viene utilizzata come stimatore per ottenere la migliore stima della varianza della popolazione da cui quel campione è stato estratto.\n\n\n\n21.3.3 Deviazione standard\nPer interpretare la varianza in modo più intuitivo, si può calcolare la deviazione standard (o scarto quadratico medio o scarto tipo) prendendo la radice quadrata della varianza. La deviazione standard è espressa nell’unità di misura originaria dei dati, a differenza della varianza che è espressa nel quadrato dell’unità di misura dei dati. La deviazione standard fornisce una misura della dispersione dei dati attorno alla media, rendendo più facile la comprensione della variabilità dei dati.\nLa deviazione standard (o scarto quadratico medio, o scarto tipo) è definita come:\n\\[\ns^2 = \\sqrt{(n-1)^{-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\n\\tag{21.5}\\]\nQuando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s &gt; 0\\).\n\n\n\n\n\n\nIl termine standard deviation è stato introdotto in statistica da Pearson nel 1894 assieme alla lettera greca \\(\\sigma\\) che lo rappresenta. Il termine italiano “deviazione standard” ne è la traduzione più utilizzata nel linguaggio comune; il termine dell’Ente Nazionale Italiano di Unificazione è tuttavia “scarto tipo”, definito come la radice quadrata positiva della varianza.\n\n\n\nLa deviazione standard \\(s\\) dovrebbe essere utilizzata solo quando la media è una misura appropriata per descrivere il centro della distribuzione, ad esempio nel caso di distribuzioni simmetriche. Tuttavia, è importante tener conto che, come la media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dalla presenza di dati anomali, ovvero pochi valori che si discostano notevolmente dalla media rispetto agli altri dati della distribuzione. In presenza di dati anomali, la deviazione standard può risultare ingannevole e non rappresentare accuratamente la variabilità complessiva della distribuzione. Pertanto, è fondamentale considerare attentamente il contesto e le caratteristiche dei dati prima di utilizzare la deviazione standard come misura di dispersione. In alcune situazioni, potrebbe essere più appropriato ricorrere a misure di dispersione robuste o ad altre statistiche descrittive per caratterizzare la variabilità dei dati in modo più accurato e affidabile.\nPer fare un esempio, calcoliamo la deviazione standard per i valori math del campione di dati del progetto STAR. Applicando l’Equazione 21.5, per tutto il campione abbiamo\n\nnp.std(df.math)\n\n38.82309689234648\n\n\nPer ciascun gruppo, abbiamo:\n\ndf.groupby(\"graduated\")[\"math\"].std()\n\ngraduated\n0    34.105746\n1    38.130136\nName: math, dtype: float64\n\n\n\n21.3.3.1 Interpretazione\nLa deviazione standard può essere interpretata in modo semplice: essa rappresenta la dispersione dei dati rispetto alla media aritmetica. È simile allo scarto semplice medio campionario, cioè alla media aritmetica dei valori assoluti degli scarti tra ciascuna osservazione e la media, anche se non è identica. La deviazione standard ci fornisce un’indicazione di quanto, in media, le singole osservazioni si discostino dal centro della distribuzione.\nPer verificare l’interpretazione della deviazione standard, utilizziamo i valori math del campione di dati del progetto STAR.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nLa deviazione standard calcolata per questi dati è \\(\\approx 38.8\\). Questo valore ci indica che, in media, ogni osservazione si discosta di circa 38.8 punti dalla media aritmetica dei punteggi math. Maggiore è il valore della deviazione standard, maggiore è la dispersione dei dati attorno alla media, mentre un valore più piccolo indica che i dati sono più concentrati vicino alla media. La deviazione standard ci offre quindi una misura quantitativa della variabilità dei dati nella distribuzione.\nPer questi dati, lo scarto semplice medio campionario è\n\nnp.mean(np.abs(df.math - np.mean(df.math)))\n\n30.9682664274501\n\n\nSi noti che i due valori sono simili, ma non identici.\n\n\n\n21.3.4 Deviazione mediana assoluta\nUna misura robusta della dispersione statistica di un campione è la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana. Matematicamente, la formula per calcolare la MAD è:\n\\[\n\\text{MAD} = \\text{median} \\left( |X_i - \\text{median}(X)| \\right)\n\\tag{21.6}\\]\nLa deviazione mediana assoluta è particolarmente utile quando si affrontano distribuzioni con presenza di dati anomali o asimmetrie, poiché è meno influenzata da questi valori estremi rispetto alla deviazione standard.\nQuando i dati seguono una distribuzione gaussiana (normale), esiste una relazione specifica tra MAD e la deviazione standard (si veda il Capitolo {ref}cont-rv-distr-notebook). In una distribuzione normale, la MAD è proporzionale alla deviazione standard. La costante di proporzionalità dipende dalla forma esatta della distribuzione normale, ma in generale, la relazione è data da:\n\\[\n\\sigma \\approx k \\times \\text{MAD},\n\\]\ndove:\n\n\\(\\sigma\\) è la deviazione standard.\nMAD è la Mediana della Deviazione Assoluta.\n\\(k\\) è una costante che, per una distribuzione normale, è tipicamente presa come circa 1.4826.\n\nQuesta costante di 1.4826 è derivata dal fatto che, in una distribuzione normale, circa il 50% dei valori si trova entro 0.6745 deviazioni standard dalla media. Quindi, per convertire la MAD (basata sulla mediana) nella deviazione standard (basata sulla media), si usa il reciproco di 0.6745, che è approssimativamente 1.4826.\nLa formula completa per convertire la MAD in una stima della deviazione standard in una distribuzione normale è:\n\\[\n\\sigma \\approx 1.4826 \\times \\text{MAD}\n\\]\nQuesta relazione è utile per stimare la deviazione standard in modo più robusto, specialmente quando si sospetta la presenza di outlier o si ha a che fare con campioni piccoli. Di conseguenza, molti software restituiscono il valore MAD moltiplicato per questa costante per fornire un’indicazione più intuitiva della variabilità dei dati. Tuttavia, è importante notare che questa relazione si mantiene accurata solo per le distribuzioni che sono effettivamente normali. In presenza di distribuzioni fortemente asimmetriche o con elevati outlier, la deviazione standard e la MAD possono fornire indicazioni molto diverse sulla variabilità dei dati.\nPer verificare questo principio, calcoliamo la deviazione mediana assoluta dei valori math del campione di dati del progetto STAR.\n\n1.4826 * np.median(np.abs(df[\"math\"] - np.median(df[\"math\"])))\n\n41.5128\n\n\nIn questo caso, la MAD per i punteggi di matematica è simile alla deviazione standard.\n\nnp.std(df[\"math\"])\n\n38.82309689234648\n\n\nInfatti, la distribuzione dei punteggi math è approssimativamente gaussiana.\n\nplt.hist(df[\"math\"], bins=10, alpha=0.5)\nplt.xlabel(\"math\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione dei Punteggi di Matematica\")\nplt.show()\n\n\n\n\n\n\n\n\nVerifichiamo nuovamente il principio usando un campione di dati estratto da una popolazione normale. Usiamo, ad esempio, la distribuzione \\(\\mathcal{N}(100, 15)\\):\n\nx = np.random.normal(loc=100, scale=15, size=10000)\n1.4826 * np.median(np.abs(x - np.median(x)))\n\n14.934302366472156\n\n\n\n\n21.3.5 Quando usare la deviazione standard e MAD\nLa deviazione standard e la MAD sono entrambe misure di dispersione che forniscono informazioni su quanto i dati in un insieme si discostano dalla tendenza centrale. Tuttavia, ci sono alcune differenze tra le due misure e situazioni in cui può essere più appropriato utilizzare una rispetto all’altra.\n\nDeviazione standard: Questa misura è particolarmente utile per descrivere la dispersione dei dati in una distribuzione normale. La deviazione standard è una scelta appropriata se si vuole sapere quanto i dati sono distribuiti intorno alla media, o se si vuole confrontare la dispersione di due o più set di dati. Tuttavia, la deviazione standard è fortemente influenzata dalla presenza di dati anomali, e questo può rappresentare una limitazione in casi in cui sono presenti valori estremi nell’insieme di dati.\nDeviazione mediana assoluta (MAD): La MAD è meno sensibile ai valori anomali rispetto alla deviazione standard, il che la rende una scelta migliore quando ci sono valori anomali nell’insieme di dati. Inoltre, la MAD può essere una buona scelta quando si lavora con dati non normalmente distribuiti, poiché non assume una distribuzione specifica dei dati. La MAD è calcolata utilizzando la mediana e i valori assoluti delle deviazioni dei dati dalla mediana, il che la rende una misura robusta di dispersione.\n\nIn sintesi, se si sta lavorando con dati normalmente distribuiti, la deviazione standard è la misura di dispersione più appropriata. Se si lavora con dati non normalmente distribuiti o si hanno valori anomali nell’insieme di dati, la MAD può essere una scelta migliore. In ogni caso, la scelta tra le due misure dipende dal tipo di dati che si sta analizzando e dall’obiettivo dell’analisi.\n\n\n21.3.6 Indici di variabilità relativi\nA volte può essere necessario confrontare la variabilità di grandezze incommensurabili, ovvero di caratteri misurati con differenti unità di misura. In queste situazioni, le misure di variabilità descritte in precedenza diventano inadeguate poiché dipendono dall’unità di misura utilizzata. Per superare questo problema, si ricorre a specifici numeri adimensionali chiamati indici relativi di variabilità.\nIl più importante di questi indici è il coefficiente di variazione (\\(C_v\\)), definito come il rapporto tra la deviazione standard (\\(\\sigma\\)) e la media dei dati (\\(\\bar{x}\\)):\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}.\n\\tag{21.7}\\]\nIl coefficiente di variazione è un numero puro e permette di confrontare la variabilità di distribuzioni con unità di misura diverse.\nUn altro indice relativo di variabilità è la differenza interquartile rapportata a uno dei tre quartili (primo quartile, terzo quartile o mediana). Questo indice è definito come:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]\nQuesti indici relativi di variabilità forniscono una misura adimensionale della dispersione dei dati, rendendo possibile il confronto tra grandezze con diverse unità di misura e facilitando l’analisi delle differenze di variabilità tra i dati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "href": "chapters/eda/07_loc_scale.html#la-fallacia-ergodica",
    "title": "21  Indicatori di tendenza centrale e variabilità",
    "section": "21.4 La fallacia ergodica",
    "text": "21.4 La fallacia ergodica\nSebbene il concetto di “media” possa sembrare chiaro, ciò non implica che il suo utilizzo non presenti delle problematiche nell’ambito della pratica psicologica. Un aspetto su cui vale la pena soffermarsi è ciò che viene definito “fallacia ergodica”.\nIl concetto di “fallacia ergodica” (Speelman et al., 2024) si riferisce all’errore compiuto dai ricercatori quando assumono che le caratteristiche medie di un gruppo di individui possano essere applicate a ciascun individuo all’interno di quel gruppo, senza considerare le differenze individuali o le variazioni nel tempo. Questa fallacia emerge dalla pratica comune nella ricerca psicologica di raccogliere dati aggregati da gruppi di persone per stimare parametri della popolazione, al fine di confrontare comportamenti in condizioni diverse o esplorare associazioni tra diverse misurazioni della stessa persona.\nIl problema di questo approccio è che l’uso dei risultati basati sul gruppo per caratterizzare le caratteristiche degli individui o per estrapolare a persone simili a quelle del gruppo è ingiustificato, poiché le medie di gruppo possono fornire informazioni solo sui risultati collettivi, come la performance media del gruppo, e non consentono di fare affermazioni accurate sugli individui che compongono quel gruppo. La fallacia ergodica si basa sull’assunzione che per utilizzare legittimamente una statistica aggregata (ad esempio, la media) derivata da un gruppo per descrivere un individuo di quel gruppo, due condizioni devono essere soddisfatte: gli individui devono essere così simili da essere praticamente interscambiabili, e le caratteristiche degli individui devono essere temporalmente stabili.\nTuttavia, i fenomeni e i processi psicologici di interesse per i ricercatori sono per natura non uniformi tra gli individui e variabili nel tempo, sia all’interno degli individui che tra di loro. Di conseguenza, i risultati ottenuti dalla media di misure di comportamenti, cognizioni o stati emotivi di più individui non descrivono accuratamente nessuno di quegli individui in un dato momento, né possono tenere conto dei cambiamenti in quelle variabili per un individuo nel tempo.\nSpeelman et al. (2024) osservano che la stragrande maggioranza degli articoli che hanno analizzato include conclusioni nelle sezioni degli Abstract e/o delle Discussioni che implicano che i risultati trovati con dati aggregati di gruppo si applichino anche agli individui in quei gruppi e/o si applichino agli individui nella popolazione. Questa pratica riflette la fallacia ergodica, che consiste nell’assumere che i campioni siano sistemi ergodici quando non lo sono.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "href": "chapters/eda/07_loc_scale.html#riflessioni-conclusive",
    "title": "21  Indicatori di tendenza centrale e variabilità",
    "section": "21.5 Riflessioni Conclusive",
    "text": "21.5 Riflessioni Conclusive\nLe statistiche descrittive ci permettono di ottenere indicatori sintetici che riassumono i dati di una popolazione o di un campione estratto da essa. Questi indicatori includono misure di tendenza centrale, come la media, la mediana e la moda, che ci forniscono informazioni sulla posizione centrale dei dati rispetto alla distribuzione. Inoltre, ci sono gli indici di dispersione, come la deviazione standard e la varianza, che ci indicano quanto i dati si disperdono attorno alla tendenza centrale. Questi indici ci aiutano a comprendere quanto i valori si discostano dalla media, e quindi ci forniscono un’idea della variabilità dei dati. In conclusione, le statistiche descrittive ci offrono un quadro sintetico delle caratteristiche principali dei dati, consentendoci di comprendere meglio la loro distribuzione e variabilità.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/07_loc_scale.html#informazioni-sullambiente-di-sviluppo",
    "title": "21  Indicatori di tendenza centrale e variabilità",
    "section": "21.6 Informazioni sull’Ambiente di Sviluppo",
    "text": "21.6 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Sep 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\narviz     : 0.18.0\nscipy     : 1.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024). Most Psychological Researchers Assume Their Samples Are Ergodic: Evidence From a Year of Articles in Three Major Journals. Collabra: Psychology, 10(1).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Indicatori di tendenza centrale e variabilità</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html",
    "href": "chapters/eda/08_correlation.html",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "",
    "text": "Introduzione\nNonostante sia un’operazione di base, l’analisi delle associazioni tra variabili rappresenta uno degli aspetti più controversi nell’ambito dell’analisi dei dati psicologici. Sebbene possa sembrare un passaggio naturale dopo l’analisi univariata, questo processo solleva numerose questioni metodologiche e concettuali.\nTradizionalmente, in psicologia, l’analisi delle associazioni tra variabili è stata considerata come l’obiettivo finale del processo di ricerca. Questa visione si basa sull’idea che la descrizione delle relazioni tra variabili fornisca una spiegazione esaustiva dei fenomeni psicologici. Tale approccio trova le sue radici storiche nel pensiero di Karl Pearson (1911), il quale sosteneva che la spiegazione scientifica si esaurisse una volta delineate le associazioni tra le variabili osservate:\nSebbene sia indubbio che rispondere alla seconda domanda posta da Pearson sia relativamente semplice, è altresì evidente che la nostra comprensione di un fenomeno non può dipendere unicamente dalle informazioni fornite dalle correlazioni.\nIn contrasto con questa visione tradizionale, la “Causal Revolution” propone un paradigma radicalmente diverso secondo il quale le associazioni tra variabili sono considerate come epifenomeni, mentre l’obiettivo principale della ricerca è l’identificazione e la comprensione delle relazioni causali: per comprendere veramente i fenomeni psicologici è essenziale indagare le cause sottostanti, andando oltre la mera descrizione delle associazioni.\nLa discussione dei metodi utilizzati per individuare le relazioni causali sarà trattata successivamente. In questo capitolo, ci concentreremo sui concetti statistici fondamentali necessari per descrivere le associazioni lineari tra variabili. È importante sottolineare che, sebbene esistano indici statistici per quantificare associazioni non lineari, la maggior parte degli psicologi si limita all’utilizzo di indici lineari.\nNel linguaggio comune, termini come “dipendenza”, “associazione” e “correlazione” vengono spesso usati in modo intercambiabile. Tuttavia, da un punto di vista tecnico, è importante distinguere questi concetti:\nÈ cruciale comprendere che non tutte le associazioni sono correlazioni e, soprattutto, che la correlazione non implica necessariamente causalità. Questa distinzione è fondamentale per interpretare correttamente i dati e evitare conclusioni errate sulle relazioni tra variabili.\nIn questo capitolo, esamineremo due misure statistiche fondamentali per valutare la relazione lineare tra due variabili: la covarianza e la correlazione. Questi indici ci permettono di descrivere il grado e la direzione dell’associazione lineare tra variabili, quantificando come queste variano congiuntamente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#introduzione",
    "href": "chapters/eda/08_correlation.html#introduzione",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "",
    "text": "Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’. Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\n\n\n\n\n\nAssociazione: questo termine indica una relazione generale tra variabili, dove la conoscenza del valore di una variabile fornisce informazioni su un’altra.\nCorrelazione: descrive una relazione specifica e quantificabile, indicando se due variabili tendono a variare insieme in modo sistematico. Ad esempio, in una correlazione positiva, se \\(X &gt; \\mu_X\\), è probabile che anche \\(Y &gt; \\mu_Y\\). La correlazione specifica il segno e l’intensità di una relazione lineare.\nDipendenza: indica una relazione causale tra le variabili, dove la variazione della variabile causale porta probabilisticamente alla variazione della variabile dipendente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "href": "chapters/eda/08_correlation.html#i-dati-grezzi",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.1 I dati grezzi",
    "text": "22.1 I dati grezzi\nPer illustrare la correlazione e la covarianza, analizzeremo i dati raccolti da Zetsche et al. (2019) in uno studio che indaga le aspettative negative come meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello specifico, i ricercatori si sono proposti di determinare se gli individui depressi sviluppano aspettative accurate riguardo al loro umore futuro o se tali aspettative sono distortamente negative.\nUno dei loro studi ha coinvolto un campione di 30 soggetti con almeno un episodio depressivo maggiore, confrontati con un gruppo di controllo composto da 37 individui sani. La misurazione del livello di depressione è stata effettuata tramite il Beck Depression Inventory (BDI-II).\nIl BDI-II è uno strumento di autovalutazione utilizzato per valutare la gravità della depressione in adulti e adolescenti. Il test è stato sviluppato per identificare e misurare l’intensità dei sintomi depressivi sperimentati nelle ultime due settimane. I 21 item del test sono valutati su una scala a 4 punti, dove 0 rappresenta il grado più basso e 3 il grado più elevato di sintomatologia depressiva.\nNell’esercizio successivo, ci proponiamo di analizzare i punteggi di depressione BDI-II nel campione di dati fornito da Zetsche et al. (2019).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "href": "chapters/eda/08_correlation.html#definizione-delle-relazioni-tra-variabili",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.2 Definizione delle relazioni tra variabili",
    "text": "22.2 Definizione delle relazioni tra variabili\nNel contesto delle indagini statistiche, spesso non ci limitiamo a esaminare la distribuzione di una singola variabile. Invece, il nostro interesse si concentra sulla relazione che emerge nei dati tra due o più variabili. Ma cosa significa esattamente quando diciamo che due variabili hanno una relazione?\nPer comprendere ciò, prendiamo ad esempio l’altezza e l’età tra un gruppo di bambini. In generale, è possibile notare che all’aumentare dell’età di un bambino, aumenta anche la sua altezza. Pertanto, conoscere l’età di un bambino, ad esempio tredici anni, e l’età di un altro, sei anni, ci fornisce un’indicazione su quale dei due bambini sia più alto.\nNel linguaggio statistico, definiamo questa relazione tra altezza e età come positiva, il che significa che all’aumentare dei valori di una delle variabili (in questo caso, l’età), ci aspettiamo di vedere valori più elevati anche nell’altra variabile (l’altezza). Tuttavia, esistono anche relazioni negative, in cui l’aumento di una variabile è associato a un diminuzione dell’altra (ad esempio, più età è correlata a meno pianto).\nNon si tratta solo di relazioni positive o negative; ci sono anche situazioni in cui le variabili non hanno alcuna relazione tra loro, definendo così una relazione nulla. Inoltre, le relazioni possono variare nel tempo, passando da positive a negative o da fortemente positive a appena positiva. In alcuni casi, una delle variabili può essere categorica, rendendo difficile parlare di “maggioranza” o “minoranza” ma piuttosto di “differente” (ad esempio, i bambini più grandi potrebbero semplicemente avere diverse preferenze rispetto ai bambini più piccoli, senza necessariamente essere “migliori” o “peggiori”).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "href": "chapters/eda/08_correlation.html#sec-scatter-plot",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.3 Grafico a dispersione",
    "text": "22.3 Grafico a dispersione\nIl metodo più diretto per visualizzare la relazione tra due variabili continue è tramite un grafico a dispersione, comunemente noto come “scatterplot”. Questo tipo di diagramma rappresenta le coppie di dati ottenute da due variabili, posizionandole sull’asse delle ascisse (orizzontale) e delle ordinate (verticale).\nPer rendere l’idea più chiara, consideriamo i dati dello studio condotto da Zetsche et al. (2019), in cui i ricercatori hanno utilizzato due scale psicometriche, il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D), per misurare il livello di depressione nei partecipanti. Il BDI-II è uno strumento di autovalutazione che valuta la presenza e l’intensità dei sintomi depressivi in pazienti adulti e adolescenti con diagnosi psichiatrica, mentre la CES-D è una scala di autovalutazione progettata per misurare i sintomi depressivi sperimentati nella settimana precedente nella popolazione generale, in particolare negli adolescenti e nei giovani adulti. Poiché entrambe le scale misurano lo stesso costrutto, ovvero la depressione, ci aspettiamo una relazione tra i punteggi ottenuti dal BDI-II e dalla CES-D. Un diagramma a dispersione ci consente di esaminare questa relazione in modo visuale e intuitivo.\n\n# Leggi i dati dal file CSV\ndf = pd.read_csv(\"../../data/data.mood.csv\", index_col=0)\n\n# Seleziona le colonne di interesse\ndf = df[[\"esm_id\", \"group\", \"bdi\", \"cesd_sum\"]]\n\n# Rimuovi le righe duplicate\ndf = df.drop_duplicates(keep=\"first\")\n\n# Rimuovi le righe con valori mancanti nella colonna \"bdi\"\ndf = df.dropna(subset=[\"bdi\"])\n\nPosizionando i valori del BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate, ogni punto sul grafico rappresenta un individuo, di cui conosciamo il livello di depressione misurato dalle due scale. È evidente che i valori delle scale BDI-II e CES-D non possono coincidere per due motivi principali: (1) la presenza di errori di misurazione e (2) l’utilizzo di unità di misura arbitrarie per le due variabili. L’errore di misurazione è una componente inevitabile che influisce in parte su qualsiasi misurazione, ed è particolarmente rilevante in psicologia, dove la precisione degli strumenti di misurazione è generalmente inferiore rispetto ad altre discipline, come la fisica. Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere identici è che l’unità di misura della depressione è una questione arbitraria e non standardizzata. Tuttavia, nonostante le differenze dovute agli errori di misurazione e all’uso di unità di misura diverse, ci aspettiamo che, se le due scale misurano lo stesso costrutto (la depressione), i valori prodotti dalle due scale dovrebbero essere associati linearmente tra di loro. Per comprendere meglio il concetto di “associazione lineare”, è possibile esaminare i dati attraverso l’utilizzo di un diagramma a dispersione.\n\n# Crea uno scatterplot con colori diversi per i due gruppi\nplt.scatter(df[df[\"group\"] == \"mdd\"][\"bdi\"], df[df[\"group\"] == \"mdd\"][\"cesd_sum\"], label=\"Pazienti\", c=\"C0\")\nplt.scatter(df[df[\"group\"] == \"ctl\"][\"bdi\"], df[df[\"group\"] == \"ctl\"][\"cesd_sum\"], label=\"Controlli\", c=\"C2\")\n\n# Calcola i coefficienti della retta dei minimi quadrati\ncoeff_combined = np.polyfit(df[\"bdi\"], df[\"cesd_sum\"], 1)\n\n# Calcola la retta dei minimi quadrati\nline_combined = np.poly1d(coeff_combined)\n\n# Disegna la retta dei minimi quadrati\nx_values = np.linspace(df[\"bdi\"].min(), df[\"bdi\"].max(), 100)\nplt.plot(x_values, line_combined(x_values), linestyle='--', color='C3')\n\n# Etichette degli assi\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"CESD\")\n\n# Linee verticali ed orizzontali per le medie\nplt.axvline(np.mean(df[df[\"group\"] == \"mdd\"][\"bdi\"]), alpha=0.2, color=\"blue\")\nplt.axvline(np.mean(df[df[\"group\"] == \"ctl\"][\"bdi\"]), alpha=0.2, color=\"red\")\nplt.axhline(np.mean(df[df[\"group\"] == \"mdd\"][\"cesd_sum\"]), alpha=0.2, color=\"blue\")\nplt.axhline(np.mean(df[df[\"group\"] == \"ctl\"][\"cesd_sum\"]), alpha=0.2, color=\"red\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nOsservando il grafico a dispersione, è evidente che i dati mostrano una tendenza a distribuirsi in modo approssimativamente lineare. In termini statistici, ciò suggerisce una relazione di associazione lineare tra i punteggi CES-D e BDI-II.\nTuttavia, è importante notare che la relazione lineare tra le due variabili è lontana dall’essere perfetta. In una relazione lineare perfetta, tutti i punti nel grafico sarebbero allineati in modo preciso lungo una retta. Nella realtà, la dispersione dei punti dal comportamento lineare ideale è evidente.\nDi conseguenza, sorge la necessità di quantificare numericamente la forza e la direzione della relazione lineare tra le due variabili e di misurare quanto i punti si discostino da una relazione lineare ideale. Esistono vari indici statistici a disposizione per raggiungere questo obiettivo.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#covarianza",
    "href": "chapters/eda/08_correlation.html#covarianza",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.4 Covarianza",
    "text": "22.4 Covarianza\nIniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrata in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nLa varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa”. Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, ci chiediamo come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{22.1}\\]\nL’Equazione 22.1 ci fornisce la definizione della covarianza.\n\n22.4.1 Interpretazione\nPer capire il significato dell’Equazione 22.1, supponiamo di dividere il grafico riportato nella Sezione 22.3 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza avrà segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza avrà segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa.\nEsercizio. Implemento l’Equazione 22.1 in Python.\n\ndef cov_value(x, y):\n\n    mean_x = sum(x) / float(len(x))\n    mean_y = sum(y) / float(len(y))\n\n    sub_x = [i - mean_x for i in x]\n    sub_y = [i - mean_y for i in y]\n\n    sum_value = sum([sub_y[i] * sub_x[i] for i in range(len(x))])\n    denom = float(len(x))\n\n    cov = sum_value / denom\n    return cov\n\nPer i dati mostrati nel diagramma, la covarianza tra BDI-II e CESD è 207.4\n\nx = df[\"bdi\"]\ny = df[\"cesd_sum\"]\n\ncov_value(x, y)\n\n207.4265381083563\n\n\nOppure, in maniera più semplice:\n\nnp.mean((x - np.mean(x)) * (y - np.mean(y)))\n\n207.42653810835628\n\n\nLo stesso risultato si ottiene con la funzione cov di NumPy.\n\nnp.cov(x, y, ddof=0)\n\narray([[236.23875115, 207.42653811],\n       [207.42653811, 222.83379247]])\n\n\nLa funzione np.cov(x, y, ddof=0) in Python, utilizzata tramite la libreria NumPy, calcola la covarianza tra due array, x e y. L’argomento ddof (Delta Degrees of Freedom) specifica il “correttore” da applicare al denominatore della formula di covarianza.\nQuando si imposta ddof=0, la formula utilizzata per il calcolo della covarianza divide la somma dei prodotti delle deviazioni dalla media per n, dove n è il numero totale degli elementi nel campione (ovvero, la dimensione del campione). Questo approccio assume che i dati forniti rappresentino l’intera popolazione da cui si vuole stimare la covarianza, producendo una stima non corretta (bias) se i dati sono effettivamente un campione di una popolazione più ampia. Il “bias” in questo contesto si riferisce al fatto che la stima tende sistematicamente a essere più piccola rispetto alla vera covarianza della popolazione da cui il campione è stato estratto.\nPer correggere questo errore sistematico e ottenere una stima non distorta (unbiased) della covarianza di una popolazione più ampia basandosi su un campione, si utilizza ddof=1. Questo significa che al denominatore della formula si sottrae 1 a n, dividendo quindi per n-1. Il correttore n-1 è noto come correttore di Bessel, e l’uso di ddof=1 rende la stima della covarianza non distorta nel contesto di un campione prelevato da una popolazione. La correzione è importante in statistica perché fornisce una stima più accurata delle proprietà della popolazione, soprattutto quando la dimensione del campione è piccola.\nIn sintesi: - Con ddof=0, si divide per n, assumendo che i dati rappresentino l’intera popolazione. Questo può introdurre un bias nella stima della covarianza se i dati sono in realtà un campione. - Con ddof=1, si divide per n-1, correggendo il bias e ottenendo una stima non distorta (unbiased) della covarianza se i dati rappresentano un campione di una popolazione più grande. Questo approccio è generalmente preferito per la stima delle proprietà della popolazione basata su campioni.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione",
    "href": "chapters/eda/08_correlation.html#correlazione",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.5 Correlazione",
    "text": "22.5 Correlazione\nLa direzione della relazione tra le variabili è indicata dal segno della covarianza, ma il valore assoluto di questo indice non fornisce informazioni utili poiché dipende dall’unità di misura delle variabili. Ad esempio, considerando l’altezza e il peso delle persone, la covarianza sarà più grande se l’altezza è misurata in millimetri e il peso in grammi, rispetto al caso in cui l’altezza è in metri e il peso in chilogrammi. Pertanto, per descrivere la forza e la direzione della relazione lineare tra due variabili in modo adimensionale, si utilizza l’indice di correlazione.\nLa correlazione è ottenuta standardizzando la covarianza tramite la divisione delle deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr = \\frac{S_{XY}}{S_X S_Y}.\n\\tag{22.2}\\]\nLa quantità che si ottiene dall’Equazione 22.2 viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, l’hanno introdotta).\nIn maniera equivalente, per una lista di coppie di valori \\((x_1, y_1), \\dots, (x_n, y_n)\\), il coefficiente di correlazione è definito come la media del prodotto dei valori standardizzati:\n\\[\nr = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right),\n\\tag{22.3}\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) rappresentano, rispettivamente, le medie dei valori \\(x\\) e \\(y\\), e \\(\\sigma_x\\) e \\(\\sigma_y\\) sono le rispettive deviazioni standard.\nNell’Equazione 22.3, i valori \\(x_i\\) e \\(y_i\\) vengono prima standardizzati sottraendo la media e dividendo per la deviazione standard, e poi si calcola la media del prodotto di questi valori standardizzati.\n\n22.5.1 Proprietà\nIl coefficiente di correlazione ha le seguenti proprietà:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\nè un numero puro, cioè non dipende dall’unità di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\n\n\n22.5.2 Interpretazione\nAll’indice di correlazione possiamo assegnare la seguente interpretazione:\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa;\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\nEsercizio. Per i dati riportati nel diagramma della sezione {ref}sec-zetsche-scatter, la covarianza è 207.4. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire quale sia l’intensità della relazione lineare calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva.\nTroviamo la correlazione con la funzione corrcoef():\n\nnp.corrcoef(x, y)\n\narray([[1.        , 0.90406202],\n       [0.90406202, 1.        ]])\n\n\nReplichiamo il risultato implementando l’eq. {eq}eq-cor-def:\n\ns_xy = np.mean((x - np.mean(x)) * (y - np.mean(y)))\ns_x = x.std(ddof=0)\ns_y = y.std(ddof=0)\nr_xy = s_xy / (s_x * s_y)\nprint(r_xy)\n\n0.9040620189474861\n\n\nUn altro modo ancora per trovare la correlazione tra i punteggi BDI-II e CESD è quello di applicare l’Equazione 22.3:\n\nz_x = (x - np.mean(x)) / np.std(x, ddof=0)\nz_y = (y - np.mean(y)) / np.std(y, ddof=0)\nnp.mean(z_x * z_y)\n\n0.9040620189474862\n\n\nEsempio. Un uso interessante delle correlazioni viene fatto in un recente articolo di Guilbeault et al. (2024). Il concetto di “gender bias” si riferisce alla tendenza sistematica di favorire un sesso rispetto all’altro, spesso a scapito delle donne. Lo studio di Guilbeault et al. (2024) analizza come le immagini online influenzino la diffusione su vasta scala di questo preconcetto di genere.\nAttraverso un vasto insieme di immagini e testi raccolti online, gli autori dimostrano che sia le misurazioni basate sulle immagini che quelle basate sui testi catturano la frequenza con cui varie categorie sociali sono associate a rappresentazioni di genere, valutate su una scala da -1 (femminile) a 1 (maschile), con 0 che indica una neutralità di genere. Questo consente di quantificare il preconcetto di genere come una forma di bias statistico lungo tre dimensioni: la tendenza delle categorie sociali ad associarsi a un genere specifico nelle immagini e nei testi, la rappresentazione relativa delle donne rispetto agli uomini in tutte le categorie sociali nelle immagini e nei testi, e il confronto tra le associazioni di genere nei dati delle immagini e dei testi con la distribuzione empirica delle donne e degli uomini nella società. Il lavoro di Guilbeault et al. (2024) evidenzia che il preconcetto di genere è molto più evidente nelle immagini rispetto ai testi, come mostrato nella {numref}gender-bias-1-fig C.\nSi noti che, nel grafico della {numref}gender-bias-1-fig C, ogni punto può essere interpretato come una misura di correlazione. La misura utilizzata da Guilbeault et al. (2024) riflette il grado di associazione tra le categorie sociali e le rappresentazioni di genere presenti nelle immagini e nei testi analizzati. Quando la misura è vicina a +1, indica una forte associazione positiva tra una categoria sociale specifica e una rappresentazione di genere maschile, mentre un valore vicino a -1 indica una forte associazione negativa con una rappresentazione di genere femminile. Un valore di 0, invece, suggerisce che non vi è alcuna associazione tra la categoria sociale considerata e un genere specifico, indicando una sorta di neutralità di genere. In sostanza, questa misura di frequenza può essere interpretata come una correlazione che riflette la tendenza delle categorie sociali a essere rappresentate in un modo o nell’altro nelle immagini e nei testi analizzati, rispetto ai concetti di genere femminile e maschile.\n\n\n\nIl preconcetto di genere è più prevalente nelle immagini online (da Google Immagini) e nei testi online (da Google News). A. La correlazione tra le associazioni di genere nelle immagini da Google Immagini e nei testi da Google News per tutte le categorie sociali (n = 2.986), organizzate per decili. B. La forza dell’associazione di genere in queste immagini e testi online per tutte le categorie (n = 2.986), suddivisa in base al fatto che queste categorie siano inclinate verso il femminile o il maschile. C. Le associazioni di genere per un campione di occupazioni secondo queste immagini e testi online; questo campione è stato selezionato manualmente per evidenziare i tipi di categorie sociali e preconcetti di genere esaminati. (Figura tratta da Guilbeault et al. (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "href": "chapters/eda/08_correlation.html#correlazione-di-spearman",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.6 Correlazione di Spearman",
    "text": "22.6 Correlazione di Spearman\nUn’alternativa per valutare la relazione lineare tra due variabili è il coefficiente di correlazione di Spearman, che si basa esclusivamente sull’ordine dei dati e non sugli specifici valori. Questo indice di associazione è particolarmente adatto quando gli psicologi sono in grado di misurare solo le relazioni di ordine tra diverse modalità di risposta dei soggetti, ma non l’intensità della risposta stessa. Tali variabili psicologiche che presentano questa caratteristica sono definite come “ordinali”.\n\n\n\n\n\n\nÈ importante ricordare che, nel caso di una variabile ordinale, non è possibile utilizzare le statistiche descrittive convenzionali come la media e la varianza per sintetizzare le osservazioni. Tuttavia, è possibile riassumere le osservazioni attraverso una distribuzione di frequenze delle diverse modalità di risposta. Come abbiamo appena visto, la direzione e l’intensità dell’associazione tra due variabili ordinali possono essere descritte utilizzando il coefficiente di correlazione di Spearman.\n\n\n\nPer fornire un esempio, consideriamo due variabili di scala ordinale e calcoliamo la correlazione di Spearman tra di esse.\n\nstats.spearmanr([1, 2, 3, 4, 5], [5, 6, 7, 8, 7])\n\nSignificanceResult(statistic=0.8207826816681233, pvalue=0.08858700531354381)",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#correlazione-nulla",
    "href": "chapters/eda/08_correlation.html#correlazione-nulla",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.7 Correlazione nulla",
    "text": "22.7 Correlazione nulla\nUn aspetto finale da sottolineare riguardo alla correlazione è che essa descrive la direzione e l’intensità della relazione lineare tra due variabili. Tuttavia, la correlazione non cattura relazioni non lineari tra le variabili, anche se possono essere molto forti. È fondamentale comprendere che una correlazione pari a zero non implica l’assenza di una relazione tra le due variabili, ma indica solamente l’assenza di una relazione lineare tra di esse.\nLa figura seguente fornisce tredici esempi di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili. In questi tredici insiemi di dati i coefficienti di correlazione di Pearson sono sempre uguali a 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili.\n\ndatasaurus_data = pd.read_csv(\"../../data/datasaurus.csv\")\ndatasaurus_data.groupby(\"dataset\").agg(\n    {\"x\": [\"count\", \"mean\", \"std\"], \"y\": [\"count\", \"mean\", \"std\"]}\n)\n\n\n\n\n\n\n\n\nx\ny\n\n\n\ncount\nmean\nstd\ncount\nmean\nstd\n\n\ndataset\n\n\n\n\n\n\n\n\n\n\naway\n142\n54.266100\n16.769825\n142\n47.834721\n26.939743\n\n\nbullseye\n142\n54.268730\n16.769239\n142\n47.830823\n26.935727\n\n\ncircle\n142\n54.267320\n16.760013\n142\n47.837717\n26.930036\n\n\ndino\n142\n54.263273\n16.765142\n142\n47.832253\n26.935403\n\n\ndots\n142\n54.260303\n16.767735\n142\n47.839829\n26.930192\n\n\nh_lines\n142\n54.261442\n16.765898\n142\n47.830252\n26.939876\n\n\nhigh_lines\n142\n54.268805\n16.766704\n142\n47.835450\n26.939998\n\n\nslant_down\n142\n54.267849\n16.766759\n142\n47.835896\n26.936105\n\n\nslant_up\n142\n54.265882\n16.768853\n142\n47.831496\n26.938608\n\n\nstar\n142\n54.267341\n16.768959\n142\n47.839545\n26.930275\n\n\nv_lines\n142\n54.269927\n16.769959\n142\n47.836988\n26.937684\n\n\nwide_lines\n142\n54.266916\n16.770000\n142\n47.831602\n26.937902\n\n\nx_shape\n142\n54.260150\n16.769958\n142\n47.839717\n26.930002\n\n\n\n\n\n\n\n\nfig, axs = plt.subplots(4, 4, figsize=(15, 15))\ndatasets = datasaurus_data[\"dataset\"].unique()\n\nfor i, dataset in enumerate(datasets):\n    row = i // 4\n    col = i % 4\n    ax = axs[row, col]\n    subset = datasaurus_data[datasaurus_data[\"dataset\"] == dataset]\n    ax.scatter(subset[\"x\"], subset[\"y\"], alpha=0.7)\n    ax.set_title(dataset)\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_61607/188333220.py:14: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#due-paradossi-comuni",
    "href": "chapters/eda/08_correlation.html#due-paradossi-comuni",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.8 Due Paradossi Comuni",
    "text": "22.8 Due Paradossi Comuni\nEsistono due situazioni comuni in cui le associazioni tra variabili possono ingannarci, e che vale la pena esaminare esplicitamente: il paradosso di Simpson e il paradosso di Berkson.\n\n22.8.1 Paradosso di Simpson\nIl paradosso di Simpson si verifica quando stimiamo una relazione per sottoinsiemi dei nostri dati, ma otteniamo una relazione diversa considerando l’intero dataset (Simpson 1951). È un caso particolare della fallacia ecologica, che si verifica quando cerchiamo di fare affermazioni sugli individui basandoci sui loro gruppi. Ad esempio, potrebbe esserci una relazione positiva tra i voti universitari e la performance alla scuola di specializzazione in due dipartimenti considerati individualmente. Tuttavia, se i voti universitari tendono a essere più alti in un dipartimento rispetto all’altro, mentre la performance alla scuola di specializzazione tende a essere opposta, potremmo trovare una relazione negativa tra i voti universitari e la performance alla scuola di specializzazione.\n\n\n22.8.2 Paradosso di Berkson\nIl paradosso di Berkson si verifica quando stimiamo una relazione basandoci sul dataset che abbiamo, ma a causa della selezione del dataset, la relazione risulta diversa in un dataset più generale (Berkson 1946). Ad esempio, se abbiamo un dataset di ciclisti professionisti, potremmo non trovare una relazione tra il loro VO2 max e la possibilità di vincere una gara di ciclismo (Coyle et al. 1988; Podlogar, Leo, and Spragg 2022). Tuttavia, se avessimo un dataset della popolazione generale, potremmo trovare una relazione tra queste due variabili. Il dataset professionale è così selezionato che la relazione scompare; non si può diventare ciclisti professionisti senza avere un VO2 max adeguato, ma tra i ciclisti professionisti, tutti hanno un VO2 max sufficiente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#considerazioni-conclusive",
    "href": "chapters/eda/08_correlation.html#considerazioni-conclusive",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.9 Considerazioni conclusive",
    "text": "22.9 Considerazioni conclusive\nIn questo capitolo, abbiamo approfondito i concetti di correlazione e covarianza, strumenti chiave per quantificare le relazioni tra variabili nei fenomeni psicologici. L’aspetto cruciale non risiede tanto nel saper calcolare queste misure, quanto nel comprendere le informazioni che esse offrono. È fondamentale ricordare che le associazioni osservate non indicano necessariamente i meccanismi causali sottostanti.\nLe relazioni tra variabili possono presentarsi in diversi scenari:\n\nCausalità diretta: Quando una variabile \\(X\\) influisce direttamente su una variabile \\(Y\\), l’associazione tra le due sarà evidente. In un contesto ideale, con un effetto causale lineare e isolato, la correlazione rifletterebbe esattamente la forza e la direzione dell’effetto causale. Tuttavia, questo scenario è teorico e raramente applicabile ai fenomeni psicologici complessi.\nInfluenza di altre variabili: Nella realtà, anche quando esiste una relazione causale diretta tra \\(X\\) e \\(Y\\), l’intervento di altre variabili può modificare l’associazione osservata. Come vedremo nel prossimo capitolo, la struttura delle relazioni causali può portare a correlazioni positive, nulle o persino negative, pur in presenza di un effetto causale positivo.\nAssociazioni spurie: È possibile riscontrare associazioni tra variabili che non sono causate da una relazione diretta tra di esse. Questo fenomeno evidenzia l’importanza di non confondere correlazione e causalità, e di essere cauti nelle interpretazioni.\n\nQuesti scenari mettono in luce un principio fondamentale: l’osservazione di un’associazione tra due variabili non è sufficiente per inferire una relazione causale. Le associazioni, considerate isolatamente, forniscono informazioni limitate sul fenomeno in esame.\nTuttavia, in alcuni contesti, le associazioni possono rivelarsi utili:\n\nquando vengono misurate molteplici variabili e si utilizzano tecniche psicometriche come l’analisi fattoriale o lo scaling psicologico;\nquando si ha una chiara comprensione dei meccanismi causali che regolano il dominio di studio, permettendo di controllare le variabili confondenti tramite l’uso di metodi statistici avanzati.\n\nNel capitolo successivo, ci concentreremo su queste tematiche, esplorando strumenti e metodologie che ci consentiranno di andare oltre la semplice osservazione delle associazioni, per avvicinarci a una comprensione più profonda e causale dei fenomeni psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/08_correlation.html#informazioni-sullambiente-di-sviluppo",
    "title": "22  Relazioni tra variabili: correlazione e covarianza",
    "section": "22.10 Informazioni sull’Ambiente di Sviluppo",
    "text": "22.10 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 31 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\narviz     : 0.18.0\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.14.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Relazioni tra variabili: correlazione e covarianza</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html",
    "href": "chapters/eda/09_causality.html",
    "title": "23  Causalità dai dati osservazionali",
    "section": "",
    "text": "Introduzione\nLa pura osservazione dei dati può rivelare correlazioni e pattern nei dati, ma senza un’indagine sulle cause che stanno alla base di tali correlazioni, le conclusioni tratte possono essere fuorvianti o incomplete.\nRichard McElreath, nel suo libro “Statistical Rethinking” (McElreath, 2020), utilizza l’analogia dei Golem - creature potenti ma prive di saggezza - per descrivere un approccio metodologico che è stato a lungo predominante in psicologia. Questo approccio si basa esclusivamente sull’analisi delle associazioni statistiche tra variabili, trascurando considerazioni più profonde sulla causalità.\nIl metodo in questione si concentra principalmente sul test delle ipotesi nulle, senza stabilire una chiara connessione tra le domande di ricerca riguardanti relazioni causali e i test statistici impiegati. Questa disconnessione è evidente nella figura successiva, tratta da un manuale di analisi dati di impostazione frequentista, che illustra la procedura raccomandata dai sostenitori di questo approccio per descrivere le associazioni tra variabili.\nÈ importante notare come tale procedura non fornisca strumenti utili per identificare le effettive cause sottostanti ai fenomeni osservati. Questa limitazione metodologica è stata identificata come uno dei fattori principali che hanno contribuito alla crisi di replicabilità nella ricerca psicologica, come approfondito nel Capitolo 116. L’approccio descritto, pur essendo potente nell’individuare correlazioni, manca della “saggezza” necessaria per distinguere tra semplici associazioni e vere relazioni causali, analogamente ai Golem della metafora di McElreath.\nUn problema evidenziato da McElreath (2020) è che processi causali completamente distinti possono generare la stessa distribuzione di risultati osservati. Pertanto, un approccio focalizzato esclusivamente sull’analisi delle associazioni mediante il test dell’ipotesi nulla non è in grado di distinguere tra questi diversi scenari, come spiegato nel Capitolo 87.\nL’approccio frequentista, che si limita a descrivere le associazioni tra le variabili, ha una scarsa capacità di rilevare le caratteristiche cruciali dei fenomeni studiati e tende a produrre un alto tasso di falsi positivi (Zwet et al., 2023). È invece necessario utilizzare una metodologia che non si limiti a confutare ipotesi nulle, ma sia in grado di sviluppare modelli causali che rispondano direttamente alle domande di ricerca. In questo capitolo, ci concentreremo sull’introduzione dei concetti fondamentali dell’analisi causale.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#introduzione",
    "href": "chapters/eda/09_causality.html#introduzione",
    "title": "23  Causalità dai dati osservazionali",
    "section": "",
    "text": "Esempio di albero decisionale per la selezione di una procedura statistica appropriata. Iniziando dall’alto, l’utente risponde a una serie di domande riguardanti la misurazione e l’intento, arrivando infine al nome di una procedura. Sono possibili molti alberi decisionali simili. (Figura tratta da McElreath (2020)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#cosè-la-causalità",
    "href": "chapters/eda/09_causality.html#cosè-la-causalità",
    "title": "23  Causalità dai dati osservazionali",
    "section": "23.1 Cos’è la causalità?",
    "text": "23.1 Cos’è la causalità?\nHardt & Recht (2022) introducono il concetto di causalità distinguendo tra osservazione e azione. Ciò che vediamo nell’osservazione passiva è il modo in cui le persone seguono i loro comportamenti abituali, le loro inclinazioni naturali, proiettando lo stato del mondo su un insieme di caratteristiche che abbiamo scelto di evidenziare. Tuttavia, le domande più importanti spesso non riguardano semplici osservazioni.\n\nNon ci basta sapere che le persone che praticano regolarmente attività fisica soffrono meno d’ansia; vogliamo capire se l’attività fisica riduce effettivamente i livelli d’ansia.\nNon ci accontentiamo di osservare che chi segue una terapia cognitivo-comportamentale (CBT) presenta meno sintomi depressivi; desideriamo verificare se la CBT riduce realmente questi sintomi.\nNon ci limitiamo a constatare che l’uso frequente dei social media è associato a un calo del benessere mentale; vogliamo determinare se l’uso intensivo dei social media causa effettivamente una diminuzione del benessere mentale.\n\nAlla base, il ragionamento causale è un quadro concettuale per affrontare domande sugli effetti di azioni o interventi ipotetici. Una volta compreso quale sia l’effetto di un’azione, possiamo invertire la domanda e chiederci quale azione plausibile abbia causato un determinato evento.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#effetto-causale",
    "href": "chapters/eda/09_causality.html#effetto-causale",
    "title": "23  Causalità dai dati osservazionali",
    "section": "23.2 Effetto Causale",
    "text": "23.2 Effetto Causale\nSebbene non esista una definizione univoca di causalità, possiamo concettualizzarla in modo pratico: diciamo che X causa Y se, intervenendo e modificando il valore di X (il trattamento), la distribuzione di Y cambia di conseguenza. Questa definizione sottolinea l’importanza cruciale dell’azione o dell’intervento nel determinare una relazione causale.\nQuando X è una variabile binaria, rappresentante la presenza o l’assenza del trattamento, la conseguenza dell’intervento su X è denominata effetto medio del trattamento. Questo ci indica quanto il trattamento (azione X = 1) aumenta l’aspettativa di Y rispetto all’assenza di trattamento (azione X = 0).\nÈ importante notare che gli effetti causali sono quantità relative alla popolazione. Si riferiscono a effetti mediati sull’intera popolazione in esame. Tuttavia, spesso l’effetto del trattamento può variare significativamente da un individuo all’altro o tra gruppi di individui. In questi casi, parliamo di effetti di trattamento eterogenei.\nPer chiarire questo concetto, consideriamo un esempio concreto: supponiamo che la terapia cognitivo-comportamentale (CBT) riduca l’ansia. Se un gruppo di persone ansiose non riceve alcun trattamento, i loro livelli d’ansia rimarranno presumibilmente invariati. Se invece interveniamo introducendo la CBT (modificando così il valore di X), i livelli d’ansia nel gruppo tenderanno a diminuire (cambiando quindi il valore di Y). Questo esempio illustra la distinzione tra semplice correlazione, basata sull’osservazione passiva, e causalità, che implica un’azione o un intervento.\nLa definizione di causalità può essere applicata anche per collegare variabili apparentemente distanti. Ad esempio, l’autoefficacia potrebbe non avere un effetto causale diretto sulle prestazioni accademiche. Tuttavia, se aumentiamo l’autoefficacia attraverso interventi mirati, è probabile che osserviamo un miglioramento nell’impegno allo studio. Questo aumento dell’impegno, a sua volta, tende a migliorare le prestazioni accademiche. Di conseguenza, possiamo affermare che l’autoefficacia influisce indirettamente sulle prestazioni accademiche attraverso una catena causale.\nÈ importante precisare che affermiamo l’esistenza di una relazione causale tra X e Y anche quando modificare X non porta necessariamente a un cambiamento immediato o deterministico in Y, ma altera la probabilità che Y si verifichi in un certo modo, modificando quindi la distribuzione di Y. Questa prospettiva probabilistica della causalità è particolarmente rilevante in campi come la psicologia, dove le relazioni tra variabili sono spesso complesse e influenzate da molteplici fattori.\n\n23.2.1 I Limiti dell’Osservazione\nPer comprendere i limiti dell’osservazione passiva, e quindi la necessità di comprendere le relazioni causali sottostanti, Hardt & Recht (2022) si riferiscono all’esempio storico delle ammissioni ai corsi di laurea dell’Università della California, Berkeley, nel 1973. In quell’anno, 12,763 candidati furono considerati per l’ammissione in uno dei 101 dipartimenti o major interdipartimentali. Di questi, 4,321 erano donne e 8,442 erano uomini. I dati mostrano che circa il 35% delle donne fu ammesso, rispetto al 44% degli uomini. Test di significatività statistica indicano che questa differenza non è attribuibile al caso, suggerendo una disparità nei tassi di ammissione tra i generi.\nUna tendenza simile si osserva quando si analizzano le decisioni aggregate di ammissione nei sei maggiori dipartimenti. Il tasso di ammissione complessivo per gli uomini era di circa il 44%, mentre per le donne era solo il 30%, un’altra differenza significativa. Tuttavia, poiché i dipartimenti hanno autonomia nelle loro decisioni di ammissione, è utile esaminare il possibile bias di genere a livello di singolo dipartimento.\nUomini\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n825\n62\n\n\nB\n520\n60\n\n\nC\n325\n37\n\n\nD\n417\n33\n\n\nE\n191\n28\n\n\nF\n373\n6\n\n\n\nDonne\n\n\n\nDipartimento\nCandidati\nAmmessi (%)\n\n\n\n\nA\n108\n82\n\n\nB\n25\n68\n\n\nC\n593\n34\n\n\nD\n375\n35\n\n\nE\n393\n24\n\n\nF\n341\n7\n\n\n\nDall’osservazione di questi dati, emerge che quattro dei sei maggiori dipartimenti mostrano un tasso di ammissione più elevato per le donne, mentre due mostrano un tasso più elevato per gli uomini. Tuttavia, questi due dipartimenti non possono giustificare la sostanziale differenza nei tassi di ammissione osservata nei dati aggregati. Questo suggerisce che la tendenza generale di un tasso di ammissione più alto per gli uomini sembra invertita quando i dati sono disaggregati per dipartimento.\nQuesto fenomeno è noto come paradosso di Simpson, un paradosso statistico in cui una tendenza che appare in sottopopolazioni si inverte o scompare quando i dati vengono aggregati. Nel contesto attuale, il paradosso di Simpson si manifesta nel fatto che, mentre i dati aggregati sembrano indicare una discriminazione di genere contro le donne, l’analisi dei dati disaggregati per dipartimento rivela che in alcuni casi le donne sono favorite in termini di ammissioni.\nLa domanda fondamentale è se questi dati indicano effettivamente un problema di discriminazione di genere o se, come suggerito dallo studio originale, il bias di genere nelle ammissioni fosse principalmente dovuto al fatto che “le donne sono indirizzate dalla loro socializzazione e istruzione verso campi di studio generalmente più affollati, meno produttivi in termini di completamento dei diplomi, meno finanziati e che spesso offrono prospettive professionali peggiori.” In altre parole, il problema risiederebbe in differenze sistemiche e strutturali tra i campi di studio scelti dalle donne e quelli scelti dagli uomini.\nIl paradosso di Simpson crea disagio proprio perché l’intuizione suggerisce che una tendenza valida per tutte le sottopopolazioni dovrebbe esserlo anche a livello aggregato. Tuttavia, questo paradosso evidenzia un errore comune nell’interpretazione delle probabilità condizionate: confondere l’osservazione passiva con l’analisi causale. I dati che abbiamo rappresentano solo un’istantanea del comportamento normale di uomini e donne che si candidavano per l’ammissione a UC Berkeley nel 1973.\nNon possiamo trarre conclusioni definitive da questi dati. Possiamo solo riconoscere che l’analisi iniziale solleva ulteriori domande, come ad esempio la necessità di progettare nuovi studi per raccogliere dati più completi, che potrebbero portare a conclusioni più definitive. In alternativa, potremmo discutere su quale scenario sia più verosimile in base alle nostre convinzioni e alle notre ipotesi sul mondo.\nL’inferenza causale può essere utile in entrambi i casi. Da un lato, può guidare la progettazione di nuovi studi, aiutandoci a scegliere quali variabili includere, quali escludere e quali mantenere costanti. Dall’altro, i modelli causali possono fungere da meccanismo per incorporare le conoscenze scientifiche del dominio e passare da ipotesi plausibili a conclusioni plausibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#variabili-confondenti",
    "href": "chapters/eda/09_causality.html#variabili-confondenti",
    "title": "23  Causalità dai dati osservazionali",
    "section": "23.3 Variabili confondenti",
    "text": "23.3 Variabili confondenti\nSebbene gli esperimenti controllati offrano un elevato grado di certezza nell’identificazione di queste relazioni, molte domande di ricerca non possono essere affrontate sperimentalmente a causa di limitazioni etiche o pratiche. In questi casi, i ricercatori ricorrono a disegni osservazionali, che offrono maggiore flessibilità e applicabilità. Tuttavia, l’uso di dati osservazionali comporta una sfida significativa: la difficoltà di trarre conclusioni causali affidabili.\nAl centro di questa complessità si trovano le variabili confondenti. Possiamo dire che una variabile confondente è presente quando l’associazione osservata tra due variabili X e Y non riflette accuratamente la vera relazione causale tra di esse. In altre parole, la variabile confondente influenza sia X che Y, creando l’apparenza di una relazione diretta tra le due che potrebbe essere fuorviante o inesatta.\nNegli studi osservazionali, se le variabili confondenti non vengono misurate e controllate adeguatamente, possono distorcere le stime degli effetti causali, introducendo bias nei risultati e impedendo di riflettere il vero valore dell’effetto. In pratica, la presenza di variabili confondenti può portare a conclusioni errate quando si confrontano semplicemente i risultati osservati in diversi gruppi. Ciò che si osserva nei dati potrebbe non corrispondere a ciò che accadrebbe se si potesse manipolare direttamente la variabile di interesse in un esperimento controllato.\nUn approccio apparentemente semplice per affrontare questo problema potrebbe essere quello di controllare statisticamente tutte le variabili confondenti. In questo metodo, si stima l’effetto di X su Y separatamente in ogni segmento della popolazione definito da una condizione Z = z per ogni possibile valore di z. Successivamente, si calcola la media di questi effetti stimati nelle sottopopolazioni, ponderandoli per la probabilità di Z = z nella popolazione. Tuttavia, questo metodo presenta due difficoltà fondamentali: richiede la conoscenza di tutte le possibili variabili confondenti e la capacità di misurare ciascuna di esse, cosa che spesso non è praticabile.\nIl controllo delle variabili confondenti è cruciale per stabilire relazioni causali, poiché permette di isolare gli effetti delle variabili indipendenti da quelli delle variabili confondenti che potrebbero influenzare le variabili dipendenti. Esistono due principali metodologie di controllo:\n\nIl controllo sperimentale, implementato attraverso il disegno sperimentale e basato principalmente sulla randomizzazione.\nIl controllo statistico, applicato durante l’analisi dei dati, con l’obiettivo di neutralizzare o quantificare l’influenza delle variabili estranee.\n\nA causa di queste difficoltà, l’inferenza causale basata su dati osservazionali è spesso considerata problematica, dando origine al famoso detto “la correlazione non implica causalità”. Tuttavia, è importante notare che in alcune circostanze, è possibile fare inferenze causali anche a partire da dati osservazionali.\nL’obiettivo dell’analisi causale moderna è proprio quello di fornire gli strumenti concettuali e metodologici per affrontare queste sfide. Attraverso l’uso di tecniche avanzate come i modelli causali strutturali, i grafi aciclici diretti (DAG) e i metodi di identificazione degli effetti causali, i ricercatori possono spesso superare le limitazioni dei dati osservazionali e trarre conclusioni causali più robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "href": "chapters/eda/09_causality.html#modelli-causali-strutturali",
    "title": "23  Causalità dai dati osservazionali",
    "section": "23.4 Modelli Causali Strutturali",
    "text": "23.4 Modelli Causali Strutturali\nI modelli causali sono strumenti essenziali per l’analisi dei dati osservazionali, poiché consentono di rappresentare il processo sottostante a un fenomeno e di prevedere gli effetti di un intervento. Questi modelli non solo permettono di anticipare le conseguenze di una causa, ma offrono anche la possibilità di esplorare scenari controfattuali, immaginando esiti alternativi che si sarebbero potuti verificare in presenza di decisioni diverse.\nUn modello causale strutturale (Structural Causal Model, SCM) è un approccio che rappresenta le relazioni causali tra variabili. Esso si basa su una serie di assegnazioni che, partendo da variabili di rumore indipendenti (note anche come variabili esogene), generano una distribuzione di probabilità congiunta.\nLe variabili di rumore indipendenti svolgono un ruolo cruciale negli SCM. Esse rappresentano fonti di incertezza o variabilità all’interno del sistema e non sono influenzate da altre variabili del modello. Queste variabili sono mutuamente indipendenti, il che significa che il loro valore non fornisce informazioni sul valore delle altre.\nLa costruzione di un SCM segue una sequenza specifica: si parte dalle variabili di rumore indipendenti, si applicano una serie di assegnazioni che descrivono gli effetti causali delle variabili esogene su altre variabili, e si genera progressivamente un insieme di variabili casuali che dà origine a una distribuzione congiunta.\nIl principale vantaggio di un SCM risiede nella sua duplice natura: da un lato, fornisce una distribuzione di probabilità congiunta delle variabili, e dall’altro, descrive il processo generativo che porta alla formazione di tale distribuzione, partendo dalle variabili di rumore elementari.\nQuesta struttura consente non solo di modellare le relazioni probabilistiche tra le variabili, ma anche di rappresentare in modo esplicito i meccanismi causali che le governano.\nI SCM possono essere rappresentati graficamente attraverso Grafi Aciclici Direzionati (Directed Acyclic Graphs, DAG). Questi DAG visualizzano le relazioni causali tra le variabili all’interno di un SCM, facilitando l’identificazione delle variabili confondenti e il loro impatto sull’analisi.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "href": "chapters/eda/09_causality.html#bias-da-variabile-omessa",
    "title": "23  Causalità dai dati osservazionali",
    "section": "23.5 Bias da Variabile Omessa",
    "text": "23.5 Bias da Variabile Omessa\nPossiamo introdurre i DAG facendo riferiento al bias da variabile omessa (Omitted Variable Bias, o OVB; Wilms et al. (2021)). Come discusso da Byrnes & Dee (2024), l’omissione dall’analisi statistica di variabili confondenti note ma non misurate, o sconosciute e non misurate, può portare a stime errate della magnitudine degli effetti, errori nel segno delle stime (stimatori distorti), correlazioni spurie, e al mascheramento delle vere relazioni causali.\nUn illustrazione di questa situazione è fornita nella Figura 23.1. La figura mostra tre DAG che illustrano diversi scenari in cui le variabili non osservate non influenzano i risultati del modello o potrebbero creare problemi a causa della confusione. Una variabile di risposta di interesse (Y) è causata sia da una variabile misurata (X) che da una variabile non misurata (U). Nel pannello di sinistra, la variabile non osservata (U) non è una variabile confondente. Nel pannello centrale, la variabile non osservata (U) è una variabile confondente e causa il bias da variabile omessa. Nel pannello di destra la variabile non osservata (U) causa il bias da variabile omessa in maniera indiretta.\n\n\n\n\n\n\nFigura 23.1: Nel pannello di sinistra, X e U sono non correlate, quindi la mancata inclusione di U in un modello statistico aumenterebbe l’errore standard della stima (riducendo la precisione del modello) ma non porterebbe a bias nella stima dell’effetto di X su Y. Tuttavia, se U influenza anche X come nel pannello centrale, o se U e X sono influenzati da un fattore comune Z come nel pannello di destra, allora omettere U da un modello statistico causa il bias da variabile omessa nella stima dell’effetto di X su Y. I casi illustrati dal pannello centrale e dal pannello di destra sono esempi di sistemi in cui le cause comuni di confusione (U e Z rispettivamente) devono essere controllate per effettuare inferenze causali non distorte (la figura è ispirata da Byrnes & Dee (2024)).\n\n\n\nAffrontare i problemi creati dalle variabili confondenti non misurate rappresenta una sfida primaria nell’inferenza causale dai dati osservazionali. A differenza dell’errore di misurazione nelle variabili predittive, che produce un bias costante verso lo zero e può essere corretto o modellato (McElreath, 2020; Schennach, 2016), con l’OVB non possiamo conoscere la grandezza o la direzione del bias senza conoscere tutte le possibili variabili confondenti e le loro relazioni nel sistema.\nNonostante queste sfide, non è necessario abbandonare l’uso dei dati osservazionali per l’inferenza causale in psicologia. È invece necessario ricorrere all’adozione delle tecniche dei SCM per potere comunque svolgere l’inferenza causale.\nÈ evidente che questo approccio porterà a conclusioni inevitabilmente parziali, destinate ad essere perfezionate da studi successivi. Tuttavia, tale metodologia offre il vantaggio di esplicitare il “modello generativo dei dati”, ovvero la struttura causale sottostante ai fenomeni psicologici oggetto di studio.\nI progressi nella ricerca empirica conducono a una maggiore comprensione e, di conseguenza, a modifiche nelle ipotesi sui meccanismi causali. Questo processo rappresenta un’evoluzione della conoscenza scientifica. Tale sviluppo è reso possibile proprio perché le ipotesi causali sono formulate in termini di modelli formali, che descrivono in modo preciso i meccanismi ipotizzati.\nAl contrario, limitarsi alla mera descrizione delle associazioni tra variabili non consente questo tipo di avanzamento conoscitivo. La formulazione di modelli causali espliciti permette infatti di testare, raffinare e, se necessario, rivedere le ipotesi sui meccanismi sottostanti ai fenomeni osservati, portando a una comprensione più profonda e dinamica dei processi psicologici.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "href": "chapters/eda/09_causality.html#grafi-aciclici-diretti",
    "title": "23  Causalità dai dati osservazionali",
    "section": "23.6 Grafi Aciclici Diretti",
    "text": "23.6 Grafi Aciclici Diretti\nI DAG sono uno strumento fondamentale per l’inferenza causale, offrendo una rappresentazione visiva delle relazioni causali ipotizzate tra variabili. Questi grafi sono definiti “diretti” perché le variabili, rappresentate da nodi, sono collegate da frecce orientate anziché da semplici linee. Sono inoltre chiamati “aciclici” poiché non è possibile tornare a un nodo di partenza seguendo il percorso delle frecce.\nIn un DAG, una freccia che va da X a Y indica un’influenza probabilistica di X su Y. La terminologia delle relazioni all’interno del grafo è importante: il nodo di origine di una freccia è chiamato “genitore”, mentre il nodo di destinazione è detto “figlio”. Quando è possibile raggiungere un nodo B partendo da un nodo A seguendo una successione di frecce, A è definito “antenato” di B, e B è considerato “discendente” di A.\nI DAG consentono di distinguere chiaramente tra cause dirette e indirette. Una causa diretta è rappresentata da un nodo genitore, mentre una causa indiretta può essere qualsiasi antenato di un nodo nel grafo causale. Questa struttura permette di differenziare efficacemente causa ed effetto basandosi sulla posizione relativa dei nodi all’interno del grafo, ovvero se un nodo è antenato o discendente di un altro.\nQuesti grafi sono particolarmente utili per identificare variabili confondenti, basandosi sulla teoria sviluppata da Judea Pearl (Pearl, 2009). È cruciale rappresentare in un DAG tutte le possibili relazioni causali, poiché l’assenza di una freccia tra due nodi implica la certezza dell’assenza di una relazione causale diretta tra le variabili corrispondenti.\nNella teoria dei DAG, due concetti fondamentali sono la d-separazione e il criterio del back-door.\n\nLa d-separazione\nLa d-separazione ci aiuta a determinare quando due variabili in un grafo causale sono indipendenti condizionatamente a un insieme di altre variabili. Questo concetto è cruciale per comprendere come l’informazione o l’influenza si propaga tra le variabili in un modello causale.\nIn termini più semplici, la d-separazione ci permette di identificare se esiste un “blocco” nel flusso di informazioni tra due variabili, dato un certo insieme di altre variabili (che chiameremo Λ). Quando due variabili sono d-separate da Λ, significa che non c’è flusso di informazioni tra di loro, condizionatamente a Λ.\nPer comprendere meglio la d-separazione, consideriamo tre situazioni principali che possono verificarsi in un DAG:\n\nCatena (X → Z → Y): In questo caso, Z è un mediatore tra X e Y. Se Z appartiene all’insieme Λ (cioè, se controlliamo o condizioniamo su Z), blocchiamo il flusso di informazioni da X a Y attraverso questo percorso. Per esempio, se X è “esercizio fisico”, Z è “pressione sanguigna” e Y è “rischio di malattie cardiache”, controllando per la pressione sanguigna (Z) blocchiamo il percorso attraverso il quale l’esercizio fisico influenza il rischio di malattie cardiache.\nFork (X ← Z → Y): Qui, Z è una causa comune sia di X che di Y. Se Z appartiene a Λ, blocchiamo la correlazione spuria tra X e Y che deriva dalla loro causa comune. Per esempio, se Z è “status socioeconomico”, X è “livello di istruzione” e Y è “stato di salute”, controllando per lo status socioeconomico (Z) eliminiamo la correlazione apparente tra istruzione e salute che potrebbe derivare dal fatto che entrambe sono influenzate dallo status socioeconomico.\nCollider (X → Z ← Y): In questa situazione, Z è un effetto comune di X e Y. Sorprendentemente, se né Z né i suoi discendenti appartengono a Λ, il percorso è già bloccato. Controllare per Z (o i suoi discendenti) in realtà aprirebbe un percorso tra X e Y, creando una correlazione spuria. Per esempio, se X è “intelligenza”, Y è “bellezza” e Z è “successo in una carriera di attore”, controllare per il successo nella carriera di attore (Z) creerebbe una correlazione apparente tra intelligenza e bellezza, anche se queste potrebbero essere indipendenti nella popolazione generale.\n\nIn sintesi, la d-separazione ci permette di determinare, dato un certo insieme di variabili Λ, se due variabili X e Y sono indipendenti condizionatamente a Λ. Questo ci aiuta a identificare quali variabili dobbiamo controllare (e quali non dobbiamo controllare) per ottenere stime causali non distorte, facilitando così l’inferenza causale corretta. La d-separazione è quindi uno strumento potente che ci permette di leggere le indipendenze condizionali direttamente dal grafo, senza dover fare calcoli probabilistici complessi.\n\n\nIl criterio del back-door\nIl criterio del back-door consente di identificare un insieme di variabili che, se controllate adeguatamente, permettono di stimare gli effetti causali in modo non distorto. L’obiettivo principale di questo criterio è eliminare l’influenza di percorsi non causali tra la variabile di esposizione (causa potenziale) e l’outcome (effetto), mantenendo aperto solo il percorso causale diretto di interesse.\nIn questo contesto, due variabili sono considerate “confuse” se esiste tra di esse un percorso di tipo back-door. Un back-door path da X a Y è definito come qualsiasi percorso che inizia da X con una freccia entrante in X. Per esempio, consideriamo il seguente percorso:\nX ← A → B ← C → Y\nIn questo caso, il percorso rappresenta un flusso di informazioni da X a Y che non è causale, ma potrebbe creare l’apparenza di una relazione causale.\nPer “deconfondere” una coppia di variabili, è necessario selezionare un insieme di variabili (chiamato back-door set) che “blocchi” tutti i back-door paths tra i due nodi di interesse. Il blocco di questi percorsi avviene in modi diversi a seconda della struttura del percorso:\n\nUn back-door path che coinvolge una catena di variabili (ad esempio, A → B → C) può essere bloccato controllando per la variabile intermedia (in questo caso, B).\nUn percorso che coinvolge un “collider” (una variabile che riceve frecce da entrambe le direzioni, come in A → B ← C) è naturalmente bloccato e non permette il flusso di informazioni.\n\nÈ importante notare che bisogna prestare attenzione a non aprire involontariamente un flusso di informazioni attraverso un collider. Questo può accadere se si condiziona l’analisi sul collider stesso o su un suo discendente, il che potrebbe erroneamente aprire il percorso e introdurre bias nell’analisi.\n\nPunti chiave:\n\nIl criterio del back-door aiuta a identificare il set minimale di variabili da controllare.\nNon tutte le variabili associate sia all’esposizione che all’outcome devono essere controllate; solo quelle che creano percorsi back-door.\nIn alcuni casi, potrebbe non essere necessario controllare alcuna variabile (se non ci sono percorsi back-door aperti).\nIn altri casi, potrebbe essere impossibile bloccare tutti i percorsi back-door con le variabili disponibili, indicando che l’effetto causale non può essere identificato con i dati a disposizione.\n\nUtilizzando il criterio del back-door in combinazione con i DAG, i ricercatori possono fare scelte più informate su quali variabili includere nelle loro analisi, migliorando così la validità delle loro inferenze causali.\n\n\n\n23.6.1 Applicazioni\nConsideriamo nuovamente la struttura causale illustrata nella Figura 23.1, pannello centrale. Dopo aver costruito un DAG come descritto nella sezione precedente, è possibile identificare le potenziali fonti di bias da variabili omesse, inclusi i confondenti non misurati (ad esempio, U). Non controllare per le variabili confondenti apre una “back-door” permettendo alla variazione confondente di influenzare la relazione tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009). In altre parole, omettere una variabile confondente come U nella Figura 23.1 (pannello centrale) in un’analisi statistica significa che questa viene incorporata nel termine di errore del modello statistico, insieme alle fonti di errore casuali. La Figura 23.2 illustra le conseguenze di un confondente U che ha un effetto positivo su X ma un effetto negativo su Y. Se adattiamo un modello come mostrato nella Figura 23.2 bi, l’effetto stimato di X su Y è positivo quando si controlla per U. Tuttavia, se non si controlla per U, come mostrato nella Figura 23.2 bii, U viene incorporato nel termine di errore, inducendo una correlazione tra l’errore e X, come illustrato nella Figura 23.2 biii, portando a una stima errata. Pertanto, il termine di errore del modello e X risultano correlati, il che viola un’assunzione fondamentale dei modelli lineari (ovvero, il teorema di Gauss-Markov; Abdallah et al., 2015; Antonakis et al., 2010). Questo produce una stima errata, evidenziata in blu.\n\n\n\n\n\n\nFigura 23.2: Una visualizzazione del bias da variabile omessa e delle conseguenze per l’inferenza causale. (A) mostra un DAG di un sistema in cui X ha un effetto positivo su Y, e una variabile confondente U ha un effetto positivo su Y ma un effetto negativo su X. Le variabili non osservate (cioè non misurate) sono rappresentate in ellissi, come la variabile U e il termine di errore e nel pannello B. (B) illustra diverse stime del DAG in (A) utilizzando un’analisi del percorso. Vedi Box 1 per una breve spiegazione delle principali differenze tra DAG e diagrammi dei percorsi. Presumiamo che U non sia misurata. In (Bi), presumiamo di poter misurare e controllare U, rappresentata dalla freccia a doppia testa tra U e X, che rappresenta la correlazione tra le due variabili considerata dal modello. La variabile non misurata e è la fonte residua di variazione che si presume non sia correlata con nessun predittore. La freccia rossa rappresenta il percorso stimato. Al contrario, (Bii) e (Biii) rappresentano la realtà, dove non abbiamo una misurazione di U e non la controlliamo nel modello dei percorsi. Il ricercatore pensa di adattare il modello in (Bii) ma in realtà sta adattando il modello in (Biii), dove il termine di errore non è solo e, ma la somma di e e la variazione dovuta alla variabile omessa U. A causa di ciò, c’è un percorso diretto dal termine di errore del modello a X (e quindi X è endogeno). (C) mostra le relazioni stimate risultanti dai modelli in (Bi) rispetto a (Bii). Le linee rappresentano la relazione stimata tra X e Y dai rispettivi modelli. La linea rossa è la vera relazione causale, stimata da (Bi), mentre la linea blu contiene il bias da variabile omessa, poiché non si tiene conto della variabile confondente U, come stimato dal modello in Bii/Biii (Figura tratta da Byrnes & Dee (2024)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "href": "chapters/eda/09_causality.html#commenti-e-considerazioni-finali",
    "title": "23  Causalità dai dati osservazionali",
    "section": "23.7 Commenti e Considerazioni Finali",
    "text": "23.7 Commenti e Considerazioni Finali\nI diagrammi causali sono uno dei primi strumenti per identificare il bias da variabili omesse (Pearl, 1995; Pearl et al., 2016). I diagrammi causali, sotto forma di DAG, visualizzano la nostra comprensione delle relazioni causali e delle variabili confondenti all’interno di un sistema. In questo modo, i DAG chiariscono in modo trasparente le assunzioni dietro le affermazioni causali derivate dai dati e mostrano le potenziali fonti di bias derivanti da variabili confondenti.\nÈ fondamentale che i DAG includano tutte le cause comuni di un predittore e della risposta di interesse, comprendendo tutte le variabili confondenti misurate e non misurate. Questo significa che l’inferenza causale è possibile solo quando il ricercatore dispone di adeguate conoscenze del dominio.\nDopo aver costruito un DAG, è possibile determinare le potenziali fonti di bias da variabili omesse, incluse quelle derivanti da variabili confondenti non misurate (es., U nella figura fig-byrnes-dee-1, pannello centrale). Non controllare le variabili confondenti apre una “back-door” per la variazione confondente, permettendo a quest’ultima di fluire tra la variabile causale e la variabile di risposta di interesse attraverso un percorso non valutato (Pearl, 2009).\nPertanto, un diagramma causale è un primo passo fondamentale per identificare potenziali bias da variabili omesse. I DAG giustificano anche la scelta delle variabili di controllo, rendendo trasparenti le assunzioni che un ricercatore fa su come funziona il sistema oggetto di studio.\nÈ importante notare che i DAG possono essere incorretti o non includere variabili confondenti sconosciute. Infatti, un DAG rappresenta solo la comprensione attuale e le assunzioni del ricercatore riguardo alle relazioni causali all’interno di un sistema.\nUn sommario ironico di questi concetti è fornito nella vignetta di xkcd.\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with observational data and unobserved confounding variables. bioRxiv, 2024–2002.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPearl, J. (1995). Causal diagrams for empirical research. Biometrika, 82(4), 669–688.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference in statistics: A primer. John Wiley & Sons.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts. https://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error literature. Annual Review of Economics, 8(1), 341–377.\n\n\nWilms, R., Mäthner, E., Winnen, L., & Lanwehr, R. (2021). Omitted variable bias: A threat to estimating causal relationships. Methods in Psychology, 5, 100075.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., & Goodman, S. N. (2023). A New Look at P Values for Randomized Clinical Trials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Causalità dai dati osservazionali</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html",
    "href": "chapters/eda/10_estimand.html",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "Introduzione\nIn questo capitolo abbiamo esplorato diverse tecniche di analisi esplorativa dei dati, utili per sintetizzare grandi quantità di informazioni e visualizzare le distribuzioni delle variabili e le relazioni tra esse. Abbiamo presunto che le variabili siano state misurate correttamente per rispondere a una specifica domanda teorica. Tuttavia, invece di considerare questo legame tra estimandi empirici e teorici come scontato, è importante riflettere criticamente su tale relazione. A tal fine, esamineremo l’articolo di Lundberg et al. (2021), intitolato “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory”. Il punto centrale dell’articolo è l’importanza di definire con chiarezza l’estimando chiave in qualsiasi studio quantitativo, affinché questo possa rispondere in modo preciso alla domanda di ricerca.\nL’estimando è la quantità che uno studio intende stimare, fungendo da collegamento tra teoria ed evidenza statistica. Gli autori propongono un approccio metodologico articolato in tre fasi principali:\nQuesto approccio chiarisce come le evidenze empiriche possano rispondere alle domande teoriche alla base della ricerca. In sintesi, Lundberg et al. (2021) esortano i ricercatori a definire con precisione l’estimando teorico, indipendentemente dal modello statistico utilizzato, per rendere esplicito il collegamento tra teoria ed evidenza empirica.\nIn altre parole, gli autori sottolineano che non è sufficiente affermare che lo scopo di uno studio è verificare se un coefficiente di regressione sia “significativamente diverso da zero”, poiché in questo caso l’estimando è definito solo in relazione al modello statistico. Al contrario, è necessario distinguere tra estimando teorico (l’obiettivo concettuale della ricerca, ad esempio l’apprendimento associativo) ed estimando empirico (la misura osservabile). Ad esempio, l’estimando empirico potrebbe essere rappresentato dal tasso di apprendimento \\(\\alpha\\) o dalla temperatura inversa \\(\\beta\\), parametri del modello Rescorla-Wagner applicato ai dati di un compito di Probabilistic Reversal Learning (PRL). Questi parametri spiegano l’apprendimento associativo in termini di predisposizione del soggetto a modificare il valore attribuito agli stimoli o la sua strategia di scelta (esplorazione vs sfruttamento) — si veda la sezione Capitolo 106.\nÈ cruciale riconoscere che gli estimandi empirici possono essere calcolati in modi diversi. Il modello Rescorla-Wagner è solo uno dei tanti modelli per rappresentare l’apprendimento associativo, e i parametri possono essere stimati attraverso vari metodi. Inoltre, i dati su cui si basano queste analisi possono essere raccolti in esperimenti progettati in modi differenti o applicati a popolazioni diverse. Pertanto, l’estimando empirico, ossia il valore numerico che rappresenta la capacità di apprendimento associativo, può variare a seconda del modello, delle tecniche di stima e del design sperimentale utilizzati.\nIn definitiva, Lundberg et al. (2021) sottolineano che i ricercatori devono definire la loro domanda di ricerca in termini di un estimando teorico che sia indipendente dal metodo di analisi dei dati. Successivamente, devono giustificare la scelta di uno specifico estimando empirico, spiegando perché, dati i dati disponibili, hanno optato per una particolare strategia di stima piuttosto che per altre, visto che molteplici opzioni sono generalmente disponibili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#introduzione",
    "href": "chapters/eda/10_estimand.html#introduzione",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "",
    "text": "Definire un estimando teorico, collegandolo chiaramente alla teoria che guida la ricerca.\nCollegare l’estimando teorico a un estimando empirico, ossia una misura ottenuta dai dati osservabili che fornisca informazioni sull’estimando teorico, considerando una serie di assunzioni di identificazione.\nApprendere dai dati, scegliendo strategie di stima appropriate per ottenere l’estimando empirico in modo rigoroso.\n\n\n\n\n\n\n\n\n\n\n\nIn italiano, la traduzione comunemente usata di “estimand” nella letteratura scientifica è estimando. Questo termine viene utilizzato per riferirsi alla quantità o al parametro che si desidera stimare in un’analisi statistica.\nStimatore, invece, è la traduzione di “estimator” e si riferisce alla regola o alla funzione utilizzata per calcolare una stima basata sui dati osservati. Quindi, “estimando” e “stimatore” sono termini distinti: l’“estimando” è l’oggetto dell’inferenza statistica, mentre lo “stimatore” è il metodo o la formula usata per ottenere l’inferenza.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "href": "chapters/eda/10_estimand.html#limiti-dellapproccio-attuale",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "24.1 Limiti dell’Approccio Attuale",
    "text": "24.1 Limiti dell’Approccio Attuale\nLundberg et al. (2021) osservano che spesso i ricercatori sociali omettono il passaggio cruciale della definizione dell’estimando, concentrandosi direttamente sui dati e sulle procedure statistiche. Questo approccio può causare una mancanza di chiarezza riguardo a ciò che si intende effettivamente stimare, limitando anche l’uso di modelli statistici alternativi che potrebbero essere più adatti a rispondere alla domanda di ricerca. Sebbene Lundberg et al. (2021) facciano riferimento alla letteratura sociologica, questi stessi argomenti sono applicabili anche alla psicologia.\nIl problema del collegamento tra estimandi teorici ed empirici (si veda la figura seguente) può essere illustrato con un esempio in psicologia riguardante l’intelligenza. La distinzione tra estimandi teorici ed empirici è cruciale: gli estimandi teorici possono includere quantità non osservabili, come i costrutti latenti, ad esempio l’intelligenza come concetto astratto. Gli estimandi empirici, invece, riguardano esclusivamente dati osservabili, come i punteggi ottenuti in un test di intelligenza.\nNel caso dell’intelligenza, la scelta dell’estimando teorico richiede un’argomentazione sostanziale riguardo alla teoria dell’intelligenza adottata e agli obiettivi della ricerca. Ad esempio, se si vuole studiare l’intelligenza generale (fattore g), bisogna chiarire come questo costrutto viene teoricamente definito e perché è rilevante per lo studio.\nD’altra parte, la scelta dell’estimando empirico richiede un’argomentazione concettuale su come i dati osservabili, come i risultati dei test di intelligenza, possano rappresentare il costrutto latente di interesse. È necessario spiegare quali dati vengono utilizzati per inferire il costrutto teorico e quali assunzioni si fanno riguardo al rapporto tra le misure osservate e il costrutto latente.\nInfine, la scelta delle strategie di stima, come l’uso di modelli di equazioni strutturali per stimare l’intelligenza generale da diversi test, è una decisione separata, che può essere in parte guidata dai dati disponibili e dalle caratteristiche della misurazione. Separare chiaramente questi passaggi aiuta i ricercatori a fare scelte informate e fondate, consente ai lettori di valutare in modo critico le affermazioni fatte e permette alla comunità scientifica di costruire su basi solide per futuri sviluppi della ricerca.\n\n\n\nTre Scelte Critiche nelle Argomentazioni delle Scienze Sociali Quantitative. La prima scelta riguarda gli estimandi teorici, che definiscono gli obiettivi dell’inferenza. È necessario un argomento che colleghi gli estimandi teorici alla teoria più ampia. La seconda scelta riguarda gli estimandi empirici, che collegano questi obiettivi ai dati osservabili. Questo collegamento richiede delle assunzioni sostanziali, che possono essere formalizzate attraverso grafici aciclici diretti. La terza scelta riguarda le strategie di stima, che determinano come verranno effettivamente utilizzati i dati. La selezione delle strategie di stima si basa sui dati disponibili (figura tratta da Lundberg et al. (2021)).",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "href": "chapters/eda/10_estimand.html#definizione-dellestimando-teorico",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "24.2 Definizione dell’Estimando Teorico",
    "text": "24.2 Definizione dell’Estimando Teorico\nLa definizione dell’estimando teorico è cruciale per determinare la natura dello studio perché specifica chiaramente quale tipo di relazione tra le variabili stiamo cercando di indagare. In altre parole, l’estimando teorico indica se lo studio mira a descrivere, prevedere o stabilire una relazione causale. Vediamo come questo funziona in pratica con esempi legati all’intelligenza e all’allenamento cognitivo.\n\n24.2.1 1. Estimando Teorico in uno Studio Descrittivo\nUno studio descrittivo ha come obiettivo semplicemente quello di caratterizzare o descrivere una certa realtà o fenomeno senza inferire relazioni di causa-effetto. In questo caso, l’estimando teorico potrebbe essere una misura che riassume una caratteristica della popolazione.\nEsempio: Qual è il punteggio medio di intelligenza tra le persone che hanno partecipato a un programma di allenamento cognitivo rispetto a quelle che non l’hanno fatto?\nEstimando Teorico: La differenza media nei punteggi di intelligenza tra i due gruppi. Questo tipo di estimando descrive la distribuzione dei punteggi di intelligenza nei gruppi, ma non implica che l’allenamento abbia causato le differenze osservate.\n\n\n24.2.2 2. Estimando Teorico in uno Studio Predittivo\nUno studio predittivo si concentra sulla capacità di prevedere un risultato basato su dati osservabili. Qui, l’estimando teorico riguarda la capacità del modello di predire correttamente i risultati futuri, ma senza implicazioni causali.\nEsempio: In che misura la partecipazione a un programma di allenamento cognitivo può prevedere il punteggio di intelligenza futuro di una persona?\nEstimando Teorico: La previsione del punteggio di intelligenza basata sulla partecipazione all’allenamento cognitivo. Questo estimando si basa su modelli statistici che utilizzano variabili osservabili per fare previsioni, ma non determinano la causalità tra allenamento e punteggi di intelligenza.\n\n\n24.2.3 3. Estimando Teorico in uno Studio Causale\nUno studio causale cerca di stabilire un nesso diretto di causa-effetto tra variabili. L’estimando teorico in questo caso riguarda l’effetto diretto di una variabile indipendente su una variabile dipendente, tenendo conto di altre variabili confondenti.\nEsempio: L’allenamento cognitivo causa un aumento nei punteggi di intelligenza?\nEstimando Teorico: La differenza media nei punteggi di intelligenza che si attribuisce direttamente all’effetto dell’allenamento cognitivo, controllando per tutte le altre variabili confondenti. Questo estimando implica l’uso di un disegno di ricerca che isola l’effetto dell’allenamento, come un esperimento con assegnazione casuale.\n\n\n24.2.4 Come l’Estimando Teorico Chiarisce la Natura dello Studio\nDefinire l’estimando teorico in modo preciso aiuta a chiarire la natura dello studio perché specifica esattamente quale relazione tra le variabili viene studiata:\n\nStudi Descrittivi: L’estimando teorico è una semplice descrizione di dati, come una media o una differenza, senza inferire causalità.\nStudi Predittivi: L’estimando teorico si concentra sulla capacità di un modello di fare previsioni basate sui dati, senza implicazioni causali.\nStudi Causali: L’estimando teorico cerca di determinare l’effetto diretto di una variabile su un’altra, richiedendo un disegno di studio che possa controllare variabili confondenti per isolare la causalità.\n\nIn sintesi, l’estimando teorico orienta il ricercatore nel definire chiaramente se lo scopo dello studio è descrittivo, predittivo o causale, e guida il disegno dello studio e l’analisi dei dati di conseguenza.\n\n\n24.2.5 Importanza dei DAG nel Contesto degli Estimandi Teorici\nNella figura 2 dell’articolo di Lundberg et al. (2021), i Grafici Aciclici Diretti (DAG) vengono utilizzati per illustrare le relazioni causali tra variabili all’interno di uno studio. I DAG sono strumenti visivi che aiutano i ricercatori a rappresentare e comprendere le assunzioni causali sottostanti ai loro studi, fornendo una chiara rappresentazione grafica di come le variabili si influenzano a vicenda. Questo è particolarmente importante quando si definiscono estimandi teorici, perché i DAG consentono di identificare chiaramente le variabili confondenti e di stabilire le relazioni di causalità.\nI DAG possono contribuire alla definizione degli estimandi teorici in molti modi.\n\nChiarificazione delle Relazioni Causali: I DAG aiutano a chiarire quali variabili sono considerate come cause potenziali e quali come effetti. Questo è fondamentale per definire l’estimando teorico, soprattutto in uno studio causale, dove è importante distinguere tra correlazione e causalità. Ad esempio, se si studia l’effetto dell’allenamento cognitivo sull’intelligenza, un DAG può mostrare come l’allenamento influisce direttamente sull’intelligenza, identificando al contempo variabili confondenti come il background educativo o la motivazione.\nIdentificazione delle Variabili Confondenti: Uno dei principali vantaggi dell’utilizzo dei DAG è la loro capacità di identificare le variabili confondenti che possono influenzare entrambe le variabili di interesse. Nel contesto degli estimandi teorici, riconoscere e controllare queste variabili confondenti è cruciale per stabilire una relazione causale valida. Ad esempio, un DAG potrebbe rivelare che la motivazione personale influisce sia sulla partecipazione all’allenamento cognitivo che sui punteggi di intelligenza, indicando che questa variabile deve essere controllata per ottenere un estimando causale corretto.\nGuida nella Costruzione del Disegno di Ricerca: I DAG sono strumenti utili nella pianificazione del disegno di ricerca perché aiutano a determinare quali variabili devono essere misurate e controllate. Definendo chiaramente le relazioni tra le variabili, i ricercatori possono progettare esperimenti o studi osservazionali che minimizzano i bias e migliorano la validità interna dello studio. Ad esempio, un DAG può suggerire la necessità di randomizzare l’assegnazione all’allenamento cognitivo per garantire che l’effetto osservato sui punteggi di intelligenza sia realmente causato dall’allenamento e non da un’altra variabile.\nSupporto nella Selezione delle Strategie di Stima: Una volta definite le relazioni tra le variabili attraverso un DAG, i ricercatori possono scegliere strategie di stima appropriate per gli estimandi teorici ed empirici. Per esempio, se un DAG indica che non ci sono percorsi diretti tra alcune variabili, si possono utilizzare metodi statistici che presuppongono l’indipendenza condizionale, come la regressione lineare o i modelli di equazioni strutturali.\n\nIn sintesi, nel contesto della definizione degli estimandi teorici, i DAG sono strumenti essenziali che consentono ai ricercatori di visualizzare e comprendere le relazioni causali e le variabili confondenti all’interno di uno studio. Essi facilitano la costruzione di disegni di ricerca solidi, la selezione di strategie di stima appropriate e la comunicazione chiara delle assunzioni causali sottostanti. Utilizzando i DAG, i ricercatori possono garantire che gli estimandi teorici siano ben definiti e che le inferenze tratte dai dati siano valide e affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "href": "chapters/eda/10_estimand.html#collegamento-tra-estimando-teorico-ed-empirico",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "24.3 Collegamento tra Estimando Teorico ed Empirico",
    "text": "24.3 Collegamento tra Estimando Teorico ed Empirico\nLundberg et al. (2021) sottolineano l’importanza di collegare chiaramente l’estimando teorico all’estimando empirico, utilizzando assunzioni sostanziali e metodi appropriati per garantire che le conclusioni tratte dai dati siano valide.\nEstimando Empirico: L’estimando empirico è la quantità che viene effettivamente calcolata dai dati osservati. Mentre l’estimando teorico rappresenta l’obiettivo concettuale dello studio (come l’effetto dell’allenamento cognitivo sull’intelligenza), l’estimando empirico è ciò che viene effettivamente misurato nel contesto dei dati disponibili.\nPer tradurre un estimando teorico in uno empirico, è essenziale formulare assunzioni che rendano possibile l’inferenza causale. Queste assunzioni possono essere formalizzate attraverso l’uso dei Grafici Aciclici Diretti (DAG) per garantire che le variabili confondenti siano adeguatamente controllate. L’identificazione corretta assicura che le conclusioni derivate dai dati osservati siano valide rispetto all’effetto causale che si sta cercando di stimare.\nConsideriamo uno studio psicologico sull’effetto dell’allenamento cognitivo sui punteggi di intelligenza:\n\nEstimando Teorico: Il nostro obiettivo teorico potrebbe essere stimare l’effetto causale dell’allenamento cognitivo sull’aumento del punteggio di intelligenza in una popolazione adulta. L’estimando teorico qui sarebbe la differenza media nei punteggi di intelligenza tra gli individui che hanno partecipato all’allenamento e quelli che non lo hanno fatto, supponendo che l’unica differenza tra i gruppi sia l’allenamento stesso.\nEstimando Empirico: Per passare all’estimando empirico, dobbiamo considerare cosa possiamo effettivamente misurare. Supponiamo di avere dati da un campione di adulti, alcuni dei quali hanno partecipato all’allenamento cognitivo e altri no. L’estimando empirico potrebbe essere la differenza osservata nei punteggi di intelligenza tra questi due gruppi nel campione disponibile.\nAssunzioni per l’Identificazione:\n\nAssunzione di Nessuna Confusione (No Confounding): Dobbiamo assumere che non vi siano variabili non misurate che influenzano sia la partecipazione all’allenamento che i punteggi di intelligenza. Per esempio, la motivazione personale potrebbe influenzare sia la decisione di partecipare all’allenamento che il punteggio di intelligenza. Se questa variabile non è controllata, l’estimando empirico potrebbe sovrastimare o sottostimare l’effetto dell’allenamento.\nAssunzione di Non-Interferenza (Stable Unit Treatment Value Assumption, SUTVA): Dobbiamo assumere che la partecipazione di un individuo all’allenamento non influisca sui punteggi di intelligenza di altri individui. Questa assunzione potrebbe essere violata, ad esempio, se i partecipanti condividono tecniche apprese con amici che non hanno partecipato.\n\nUtilizzo dei DAG per la Chiarificazione:\n\nUn DAG può aiutare a visualizzare queste assunzioni mostrando le relazioni tra le variabili. In un DAG ben costruito, l’allenamento cognitivo influenzerebbe direttamente il punteggio di intelligenza, mentre altre variabili come l’educazione o la motivazione sarebbero rappresentate come confondenti da controllare. Se il DAG indica che ci sono variabili confondenti che non possiamo osservare o misurare, dovremo usare metodi statistici specifici, come i modelli di equazioni strutturali o l’uso di variabili strumentali, per isolare l’effetto dell’allenamento cognitivo.\n\n\nIn sintesi, collegare correttamente l’estimando teorico a uno empirico è un passo cruciale per garantire la validità delle inferenze causali in uno studio. Utilizzando l’esempio relativo all’effetto dell’allenamento cognitivo sull’intelligenza, possiamo vedere come le assunzioni sostanziali e gli strumenti come i DAG siano essenziali per identificare correttamente le relazioni causali e assicurare che i risultati siano interpretabili in modo affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "href": "chapters/eda/10_estimand.html#dedurre-lestimando-empirico-dai-dati-osservati",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "24.4 Dedurre l’Estimando Empirico dai Dati Osservati",
    "text": "24.4 Dedurre l’Estimando Empirico dai Dati Osservati\nDopo aver chiaramente definito l’estimando teorico e stabilito il collegamento con l’estimando empirico attraverso l’identificazione, il passo successivo è utilizzare tecniche statistiche per ottenere stime valide dai dati raccolti.\nRiprendiamo l’esempio psicologico sull’effetto dell’allenamento cognitivo sui punteggi di intelligenza per illustrare come l’approccio bayesiano può essere utilizzato per stimare l’estimando empirico:\n\nDefinizione dell’Estimando Empirico:\n\nL’estimando empirico in questo contesto è la differenza media nei punteggi di intelligenza tra il gruppo di individui che ha partecipato all’allenamento cognitivo e il gruppo che non ha partecipato.\n\nStrategie di Stima Appropriate:\n\nRegressione Lineare: Se ipotizziamo che i punteggi di intelligenza dipendano linearmente dalla partecipazione all’allenamento cognitivo e da altre variabili confondenti controllate, potremmo utilizzare una regressione lineare per stimare l’effetto dell’allenamento. In questa regressione, la partecipazione all’allenamento sarebbe una variabile indipendente, e i punteggi di intelligenza la variabile dipendente.\nMatching: Se i dati disponibili includono molte variabili confondenti misurate, potremmo utilizzare una tecnica di matching per creare coppie di individui simili (matchati) tra i gruppi di trattamento e controllo, basati su queste variabili. Questo metodo aiuta a bilanciare le differenze tra i gruppi che potrebbero influenzare i risultati, cercando di rendere le stime dell’effetto più affidabili.\nPropensity Score Matching: Invece di confrontare direttamente individui basandosi su caratteristiche osservabili, possiamo calcolare un punteggio di propensione per ciascun individuo, che rappresenta la probabilità di partecipare all’allenamento in base alle covariate osservate. Gli individui con punteggi di propensione simili vengono quindi confrontati, aiutando a controllare per le variabili confondenti.\nModelli di Equazioni Strutturali (SEM): Se ci sono molteplici relazioni tra variabili latenti e osservate, un modello di equazioni strutturali può essere utilizzato per stimare simultaneamente questi effetti complessi e isolare l’effetto diretto dell’allenamento cognitivo sui punteggi di intelligenza.\nRandomizzazione: In un disegno sperimentale ideale, l’assegnazione casuale dell’allenamento cognitivo elimina l’influenza delle variabili confondenti, permettendo una stima non distorta dell’effetto causale. Se i dati derivano da un esperimento randomizzato, potremmo semplicemente confrontare le medie dei due gruppi.\n\nInterpreting the Results:\n\nStime Non Distorte: Utilizzando la strategia di stima appropriata, possiamo ottenere una stima non distorta dell’effetto dell’allenamento cognitivo sui punteggi di intelligenza. Ad esempio, se utilizziamo una regressione lineare e controlliamo correttamente per tutte le variabili confondenti, l’effetto stimato rappresenterà l’effetto causale dell’allenamento.\n\n\nLa fase di stima è cruciale per trasformare i dati osservati in stime valide dell’estimando empirico. Nel contesto psicologico dell’allenamento cognitivo e dell’intelligenza, la scelta della strategia di stima appropriata dipende dalle assunzioni fatte sulla causalità e dalla natura dei dati disponibili. Utilizzando tecniche come la regressione, il matching, o i modelli di equazioni strutturali, i ricercatori possono ottenere stime precise e affidabili, garantendo che le conclusioni tratte siano valide e scientificamente robuste.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "href": "chapters/eda/10_estimand.html#implicazioni-per-la-ricerca",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "24.5 Implicazioni per la Ricerca",
    "text": "24.5 Implicazioni per la Ricerca\nLundberg et al. (2021) sottolineano l’importanza di una chiara comunicazione e dell’uso del framework presentato per migliorare la pratica della ricerca quantitativa.\n\n24.5.1 Importanza della Trasparenza e della Chiarezza nella Ricerca\nGli autori sottolineano che per garantire la validità e la replicabilità dei risultati di ricerca, è fondamentale che i ricercatori siano trasparenti e chiari su tutte le fasi del loro lavoro. Questo significa esplicitare le assunzioni fatte, il modo in cui l’estimando teorico è stato tradotto in un estimando empirico, e come i dati sono stati analizzati.\nPer esempio, in uno studio sull’effetto di una terapia cognitivo-comportamentale (CBT) sui livelli di ansia, è essenziale che i ricercatori definiscano chiaramente l’estimando teorico, ad esempio, “l’effetto medio della CBT sulla riduzione dell’ansia nella popolazione target di adulti con disturbo d’ansia generalizzato”. Devono poi descrivere come questo estimando è stato misurato empiricamente, ad esempio, utilizzando questionari standardizzati per l’ansia prima e dopo l’intervento. Infine, devono spiegare le assunzioni fatte e le tecniche utilizzate per l’analisi dei dati, come un modello bayesiano per gestire la variabilità individuale nella risposta alla terapia.\n\n\n24.5.2 Benefici dell’Utilizzo di Estimandi Chiaramente Definiti\nL’articolo discute come l’uso di estimandi chiaramente definiti può migliorare la comprensione dei risultati e facilitare il confronto tra studi diversi. Quando i ricercatori definiscono in modo preciso ciò che stanno stimando, diventa più facile per altri replicare lo studio, confrontare risultati e costruire un corpus di conoscenza cumulativo.\nPer esempio, consideriamo due studi sull’efficacia di diversi tipi di training di memoria per migliorare le funzioni cognitive negli anziani. Se entrambi gli studi definiscono chiaramente il loro estimando teorico (ad esempio, “l’effetto del training di memoria verbale sul punteggio del test di memoria a lungo termine”) e empirico (ad esempio, “la differenza media nei punteggi del test di memoria tra il gruppo che ha ricevuto il training e un gruppo di controllo”), sarà più semplice confrontare i risultati e capire quale tipo di training è più efficace.\n\n\n24.5.3 Adattabilità e Flessibilità del Framework\nIl framework proposto dagli autori è adattabile a diversi contesti di ricerca, permettendo ai ricercatori di applicare questi principi in una varietà di studi quantitativi, indipendentemente dal dominio specifico.\nPer esempio, in uno studio che esplora l’effetto della privazione del sonno sulla capacità di attenzione nei bambini, il framework potrebbe essere utilizzato per definire l’estimando teorico come “l’effetto della privazione di 8 ore di sonno sulla capacità di mantenere l’attenzione in attività ripetitive”, e l’estimando empirico potrebbe essere “la differenza media nei punteggi di attenzione tra bambini che hanno dormito 8 ore e quelli che non hanno dormito”. Questo approccio garantisce che le conclusioni siano fondate su basi metodologiche solide e che altri ricercatori possano replicare lo studio per verificare i risultati.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#conclusioni-e-implicazioni-per-la-ricerca-futura",
    "href": "chapters/eda/10_estimand.html#conclusioni-e-implicazioni-per-la-ricerca-futura",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "24.6 Conclusioni e Implicazioni per la Ricerca Futura",
    "text": "24.6 Conclusioni e Implicazioni per la Ricerca Futura\nL’adozione del framework proposto da Lundberg et al. (2021) per la definizione degli estimandi teorici ed empirici, la chiara identificazione delle assunzioni e l’utilizzo di metodi di stima appropriati può migliorare la qualità e l’affidabilità della ricerca quantitativa nelle scienze sociali. Questo approccio promuove una pratica di ricerca più rigorosa e trasparente.\nSe la comunità psicologica integrasse questo framework, studi sugli interventi psicologici, come quelli sulla terapia cognitivo-comportamentale (CBT) discusso nell’esempio sopra, potrebbero diventare più comparabili e replicabili. Ciò migliorerebbe la nostra comprensione dell’efficacia e dei limiti di tali interventi. Ad esempio, definendo chiaramente cosa si intende per “efficacia” della CBT (come la riduzione del punteggio su una scala di ansia standardizzata) e utilizzando metodi bayesiani per incorporare dati preesistenti e nuove osservazioni, è possibile ottenere stime più robuste e interpretabili. Queste stime rifletterebbero meglio l’efficacia reale della terapia nella pratica clinica.\nLe proposte di Lundberg et al. (2021) sono in linea con le raccomandazioni di altri studiosi. Andrew Gelman, ad esempio, sottolinea spesso l’importanza di definire con precisione cosa si sta cercando di stimare in un’analisi statistica. Gelman sostiene che una definizione vaga o mal definita dell’estimando teorico può portare a interpretazioni errate e conclusioni fuorvianti. La chiara definizione dell’estimando teorico, come evidenziato nell’articolo di Lundberg et al., è cruciale per determinare se uno studio è descrittivo, predittivo o causale, e per comprendere la natura dell’inferenza da trarre dai dati (Gelman & Imbens, 2013).\nSia McElreath (2020), nel suo testo “Statistical Rethinking,” sia Andrew Gelman, enfatizzano l’importanza dell’utilizzo dei Grafici Aciclici Diretti (DAG) per rappresentare visivamente le assunzioni causali e le relazioni tra variabili in un modello statistico. Questo tipo di approccio aiuta i ricercatori a identificare variabili confondenti e a chiarire le relazioni causali, migliorando così la validità delle inferenze.\nGelman discute anche frequentemente l’importanza della trasparenza nella comunicazione dei risultati di ricerca, un principio centrale anche nell’articolo di Lundberg et al. Egli insiste sul fatto che i ricercatori dovrebbero essere espliciti riguardo alle assunzioni fatte, ai metodi utilizzati e alle limitazioni dei loro studi (Gelman et al., 1995).\nIn sintesi, sia Lundberg et al. che altri ricercatori evidenziano l’importanza di una chiara definizione degli estimandi, dell’uso dei DAG per rappresentare le assunzioni causali e della scelta di strategie di stima appropriate. L’approccio bayesiano, in particolare, offre un metodo potente e flessibile per gestire l’incertezza e aggiornare le inferenze alla luce di nuove evidenze. Adottando queste pratiche, i ricercatori nelle scienze sociali e nella psicologia possono migliorare la validità, la replicabilità e la trasparenza delle loro ricerche, contribuendo a una conoscenza scientifica più solida e affidabile.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/eda/10_estimand.html#considerazioni-conclusive",
    "href": "chapters/eda/10_estimand.html#considerazioni-conclusive",
    "title": "24  Estimandi teorici e estimandi empirici",
    "section": "24.7 Considerazioni Conclusive",
    "text": "24.7 Considerazioni Conclusive\nIn questo capitolo abbiamo esaminato l’importanza della definizione dell’estimando in uno studio quantitativo, come evidenziato nell’articolo di Lundberg et al. (2021). Il concetto centrale è la distinzione tra estimando teorico ed estimando empirico e il loro collegamento, che facilita l’interpretazione dei risultati e rende l’inferenza statistica più rigorosa.\nL’articolo propone un framework strutturato in tre fasi principali:\n\nDefinire un estimando teorico collegato alla teoria sottostante.\nTradurre questo estimando in un estimando empirico, basato su dati osservabili e assunzioni di identificazione.\nScegliere le strategie di stima adeguate per ottenere stime affidabili.\n\nL’adozione di questo approccio consente di migliorare la chiarezza e la trasparenza nella ricerca, rendendo più facili il confronto tra studi diversi e la replicabilità dei risultati. La corretta definizione dell’estimando guida l’intero processo di ricerca, dalla progettazione dello studio alla scelta delle tecniche di stima e all’interpretazione dei risultati, garantendo che la teoria e le evidenze empiriche siano strettamente collegate.\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., & Imbens, G. (2013). Why ask why? Forward causal inference and reverse causal questions. National Bureau of Economic Research.\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your estimand? Defining the target quantity connects statistical evidence to theory. American Sociological Review, 86(3), 532–565.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Estimandi teorici e estimandi empirici</span>"
    ]
  },
  {
    "objectID": "chapters/probability/introduction_probability.html",
    "href": "chapters/probability/introduction_probability.html",
    "title": "Introduzione",
    "section": "",
    "text": "Questa sezione della dispensa introduce la teoria della probabilità, una componente essenziale per la ricerca scientifica. Nell’ambito della scienza, l’inferenza induttiva è di fondamentale importanza, e la probabilità svolge un ruolo cruciale in questo processo. Sebbene non possiamo ottenere una certezza assoluta riguardo alla veridicità di un’ipotesi o teoria, possiamo assegnare loro un grado di certezza probabilistica. L’approccio bayesiano utilizza la probabilità per quantificare il grado di fiducia che possiamo attribuire a una determinata proposizione.\nL’inferenza statistica bayesiana mira a quantificare la fiducia nell’ipotesi \\(H\\) dopo aver osservato un dato di evidenza \\(O\\). Per affrontare adeguatamente l’inferenza statistica bayesiana, è quindi essenziale avere una solida comprensione della teoria delle probabilità, almeno nei suoi concetti fondamentali.\nIn questa sezione esamineremo le definizioni di probabilità, la probabilità condizionale e il teorema di Bayes. Approfondiremo inoltre le proprietà delle variabili casuali e le principali distribuzioni di massa e densità di probabilità. Concluderemo presentando la funzione di verosimiglianza, un concetto fondamentale sia nell’inferenza bayesiana sia nell’inferenza frequentista.",
    "crumbs": [
      "Probabilità",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html",
    "href": "chapters/probability/01_intro_prob.html",
    "title": "25  Interpretazione della probabilità",
    "section": "",
    "text": "Introduzione\nNel corso di questo capitolo, esploreremo varie concezioni della probabilità, tra cui la visione classica, frequentista e bayesiana. Inoltre, introdurremo la simulazione con Python per una migliore comprensione della legge dei grandi numeri, un concetto fondamentale nell’ambito della probabilità. Iniziamo introducendo il concetto di causalità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#introduzione",
    "href": "chapters/probability/01_intro_prob.html#introduzione",
    "title": "25  Interpretazione della probabilità",
    "section": "",
    "text": "“La probabilità è il concetto più importante nella scienza moderna, soprattutto considerando che nessuno ha la minima idea di cosa significhi davvero.” (Attribuito a Bertrand Russell, 1929)\n\n\n\n25.0.1 Il Concetto di Casualità e la Teoria della Probabilità\n\n\n25.0.2 L’Emersione del Concetto di Casualità\nLa casualità emerge ogni volta che ci troviamo in una situazione caratterizzata da incertezza, in cui non possiamo prevedere con certezza l’esito di un evento. Questo concetto è fondamentale in molteplici contesti, dai giochi d’azzardo alla ricerca scientifica, e rappresenta un modello che ci aiuta a gestire l’imprevedibilità intrinseca in molti fenomeni. La casualità è il nostro modo di comprendere ciò che è incerto, permettendoci di trattare e quantificare eventi che, pur non potendo essere previsti singolarmente, seguono comunque schemi riconoscibili.\n\n\n25.0.3 L’Urna come Modello di Casualità\nUn modo semplice ma efficace per rappresentare la casualità è il classico modello dell’urna. Immaginiamo un’urna contenente numerose palline identiche, ciascuna numerata consecutivamente. Supponiamo che ogni pallina abbia la stessa probabilità di essere estratta. Definiremo quindi l’estrazione come “casuale”, perché ogni pallina ha uguali possibilità di essere selezionata. In questo contesto, non possiamo anticipare quale pallina verrà estratta, ma sappiamo che ognuna ha la stessa probabilità di esserlo.\nQuesto modello apparentemente semplice, basato sull’equivalenza delle probabilità, rappresenta in realtà l’essenza della casualità. Ci consente di estendere questo concetto per spiegare situazioni molto più complesse, dove possiamo applicare il principio della casualità a fenomeni ben oltre l’estrazione di palline, come il comportamento umano o i risultati di un esperimento scientifico.\n\n\n25.0.4 Applicazioni del Concetto di Casualità\nLa casualità trova applicazione in diversi ambiti, e il modello dell’urna offre una base di comprensione per i seguenti contesti:\n\nGiochi d’azzardo: Per garantire un ambiente “equo” per i giocatori, si cerca di fare in modo che ogni numero o risultato abbia la stessa probabilità di verificarsi. La casualità è qui fondamentale per assicurare che nessun risultato sia predeterminato.\nIndagini statistiche: Nei sondaggi o nelle ricerche demografiche, il campionamento casuale consente di ottenere un campione rappresentativo di una popolazione più ampia, riducendo il rischio di bias di selezione e offrendo inferenze generalizzabili.\nSperimentazione scientifica: La randomizzazione è utilizzata per distribuire casualmente i partecipanti tra i diversi gruppi sperimentali, permettendo così di controllare variabili confondenti e assicurare che le differenze osservate siano imputabili all’intervento e non ad altri fattori.\nCrittografia: Molti sistemi di sicurezza informatica si basano sulla generazione di numeri casuali per creare chiavi crittografiche robuste, che risultino difficili da prevedere e quindi da decifrare.\nSimulazioni: In vari campi scientifici, come la fisica o la psicologia, i modelli basati sulla casualità permettono di simulare sistemi complessi e di fare previsioni sugli esiti possibili.\n\n\n\n25.0.5 Dalla Casualità alla Teoria della Probabilità\nIl concetto di casualità rappresenta il fondamento della teoria della probabilità, che fornisce gli strumenti matematici per quantificare e analizzare rigorosamente l’incertezza. La teoria della probabilità, infatti, consente di trasformare la nostra intuizione della casualità in un modello matematico, attraverso il quale possiamo fare previsioni, calcolare rischi e prendere decisioni in condizioni di incertezza.\nIn particolare, la teoria della probabilità ci permette di:\n\nQuantificare l’incertezza: Assegnando un valore numerico a ciascun esito possibile, possiamo esprimere in modo preciso quanto riteniamo probabile ciascun risultato.\nCombinare informazioni: Attraverso regole matematiche come la somma e il prodotto delle probabilità, possiamo calcolare la probabilità di eventi complessi derivati da eventi più semplici.\nAggiornare le credenze: Quando emergono nuove informazioni, la teoria della probabilità (soprattutto in ambito bayesiano) ci fornisce metodi per aggiornare le nostre stime di probabilità in modo coerente e razionale.\nPrendere decisioni informate: La probabilità ci aiuta a valutare rischi e benefici attesi in situazioni incerte, orientando le nostre scelte in maniera ottimale.\n\n\n\n25.0.6 L’Importanza della Quantificazione dell’Incertezza\nQuantificare l’incertezza attraverso la teoria della probabilità è cruciale in molti campi:\n\nRicerca scientifica: La probabilità permette di valutare la solidità dell’evidenza raccolta a supporto di un’ipotesi.\nPsicologia: In ambito clinico e sperimentale, la probabilità aiuta a valutare l’efficacia dei trattamenti e a prendere decisioni informate su interventi terapeutici.\nEconomia e finanza: La teoria della probabilità è fondamentale per la gestione del rischio e la valutazione di investimenti.\nPrevisioni meteorologiche: Permette di comunicare l’incertezza legata alle previsioni, dando una stima del margine di errore.\n\nIn sintesi, il concetto di casualità e la teoria della probabilità costituiscono strumenti potenti per navigare un mondo intrinsecamente incerto. Forniscono un linguaggio preciso per descrivere l’incertezza e un quadro rigoroso per ragionare su di essa. Comprendere questi concetti è essenziale non solo per matematici o statistici, ma per chiunque desideri prendere decisioni razionali in condizioni di incertezza, che si tratti di ricercatori, psicologi o cittadini comuni.\nNei capitoli seguenti, esploreremo in dettaglio come questi concetti si applicano all’analisi dei dati, con un focus particolare sull’approccio bayesiano. Questo metodo offre un modo naturale e intuitivo di ragionare sull’incertezza, aggiornando progressivamente le conoscenze alla luce di nuove evidenze.\n\n\n25.0.7 Storia e Definizioni della Probabilità\nLa probabilità è un concetto cardine nella matematica e nelle scienze, utilizzato per misurare l’incertezza e studiare fenomeni aleatori. Nel corso del tempo, la sua definizione si è evoluta, passando da intuizioni di tipo qualitativo a formulazioni formali e rigorose.\nLa probabilità nasce dal bisogno di distinguere gli eventi deterministici, il cui esito è prevedibile, da quelli casuali, caratterizzati dall’imprevedibilità. Un evento deterministico, almeno in teoria, produce sempre lo stesso risultato nelle stesse condizioni, mentre un evento casuale ha esiti che non possiamo prevedere con certezza. Questa distinzione ha portato alla necessità di quantificare l’incertezza associata agli eventi casuali, utilizzando il concetto di probabilità.\n\n\n25.0.8 Fonti dell’Incertezza\nL’incertezza nei fenomeni casuali può derivare da due fonti principali:\n\nIncertezza epistemica: Questa forma di incertezza è legata alla nostra conoscenza limitata. Ad esempio, in un esperimento scientifico complesso, la nostra impossibilità di controllare tutte le variabili può introdurre incertezza nei risultati.\nIncertezza ontologica: Si riferisce alla casualità intrinseca di alcuni fenomeni, come in fisica quantistica, dove l’indeterminazione sembra essere una caratteristica fondamentale della realtà stessa. Un esempio intuitivo è il lancio di un dado: indipendentemente da quanto conosciamo le condizioni, non possiamo prevedere con assoluta precisione il risultato.\n\nIl fisico danese Niels Bohr ha offerto un’interpretazione illuminante su questo tema: la fisica, secondo Bohr, non mira a rivelare una verità assoluta sulla natura, ma a capire cosa possiamo dire su di essa. Questa visione riconosce che l’incertezza – sia epistemica che ontologica – riflette i limiti del nostro linguaggio e delle nostre conoscenze. Questo approccio si allinea bene con l’interpretazione soggettiva della probabilità, secondo la quale la probabilità rappresenta il grado di fiducia che un individuo ha riguardo al verificarsi di un evento, basata sulle informazioni di cui dispone.\n\n\n25.0.9 Assiomatizzazione della Probabilità\nNel 1933, il matematico Andrey Kolmogorov fornì una definizione formale della probabilità, introducendo un sistema assiomatico che costituì la base della moderna teoria della probabilità. Questa formulazione ha trasformato la probabilità in una disciplina matematica rigorosa, offrendo uno strumento essenziale per quantificare l’incertezza in contesti scientifici. Da semplice metodo per analizzare i giochi d’azzardo nel XVII secolo, la probabilità è diventata una pietra miliare del ragionamento scientifico, fornendo un linguaggio universale per descrivere e analizzare l’incertezza in numerosi campi del sapere.\n\n\n25.0.10 Interpretazioni Frequentiste e Bayesiane\nLe due principali interpretazioni della probabilità sono:\n\nInterpretazione frequentista: In questo approccio, la probabilità di un evento è definita come il limite della frequenza relativa con cui l’evento si verifica in una lunga serie di esperimenti identici. Questa visione oggettiva considera la probabilità come una proprietà intrinseca del fenomeno, indipendente dalle informazioni dell’osservatore.\nInterpretazione bayesiana: Al contrario, la probabilità è vista come una credenza soggettiva sul verificarsi di un evento. In questa visione, la probabilità rappresenta il grado di fiducia di un osservatore, dipendente dalle informazioni disponibili e dal contesto. L’approccio bayesiano permette quindi di aggiornare le stime probabilistiche man mano che nuove evidenze vengono acquisite, rendendo la probabilità una misura flessibile della conoscenza.\n\n\n\n25.0.11 La Storia della Probabilità\nLa probabilità moderna nacque da una domanda posta da Antoine Gombaud (Chevalier de Méré) a Blaise Pascal nel XVII secolo su come dividere equamente le puntate di un gioco d’azzardo interrotto.\n\n25.0.11.1 Il Problema dei Punti\nIl problema può essere riassunto come segue:\n\nImmaginiamo due persone, A e B, che partecipano a un gioco in cui il primo che vince sei round consecutivi ottiene un premio. Dopo sei round, A ha vinto cinque round e B uno. Poiché il gioco si interrompe prima di assegnare il premio, come dovrebbero dividere il premio in modo equo?\n\nQuesta domanda diede origine a una corrispondenza tra Pascal e Fermat, che svilupparono una soluzione matematica basata sulle probabilità di vittoria per ciascun giocatore. Se, per esempio, A aveva una probabilità del 97% di vincere, mentre B una del 3%, sembrava equo assegnare il 97% del premio ad A. La loro corrispondenza ispirò l’opera di Christian Huygens, “De Ratiociniis in Ludo Aleae” (1657), che rimase un riferimento in probabilità per mezzo secolo.\n\n\n25.0.11.2 Sviluppi Successivi\nNel 1713, Jacob Bernoulli pubblicò postumo “L’Arte della Congettura”, introducendo la legge dei grandi numeri e ponendo le basi per l’applicazione della probabilità al di fuori dei giochi d’azzardo, ad esempio nello studio della mortalità e della giustizia penale.\n\n\n\n25.0.12 Interpretazione Classica\nLa definizione classica di probabilità fu proposta da Pierre-Simon Laplace (1749-1827), che basò il concetto sul calcolo combinatorio. Secondo Laplace, la probabilità di un evento è data dal rapporto tra i casi favorevoli e il numero totale di casi possibili, assumendo che tutti siano equiprobabili. Ad esempio, la probabilità di ottenere un “3” lanciando un dado è \\(\\frac{1}{6}\\), poiché solo uno dei sei risultati è favorevole. Tuttavia, questa definizione è limitata, poiché si basa sull’assunzione che ogni evento sia equiprobabile, il che non è sempre vero. Inoltre, è parzialmente circolare, poiché presuppone una conoscenza implicita del concetto di probabilità.\n\n\n25.0.13 Interpretazione Frequentista\nL’approccio frequentista, nato dalla necessità di evitare le limitazioni dell’interpretazione classica, definisce la probabilità come il limite della frequenza relativa con cui un evento si verifica in una serie infinita di prove. Per esempio, la probabilità di ottenere “testa” in un lancio di moneta può essere stimata come la frequenza relativa di “testa” sul totale dei lanci, quando il numero di lanci tende all’infinito. Questa definizione è utile, ma impraticabile in molte situazioni, poiché richiede un numero infinito di ripetizioni e assume che gli eventi futuri siano identici a quelli passati.\n\ndef coin_flips(n, run_label):\n    # Genera un array di 0 e 1 dove 1 rappresenta 'testa' e 0 'croce'\n    # usando una distribuzione binomiale.\n    heads = np.random.binomial(1, 0.5, n)\n    \n    # Calcola la proporzione cumulativa di teste.\n    flips = np.arange(1, n + 1) \n    proportion_heads = np.cumsum(heads) / flips\n    \n    # Crea un DataFrame per un facile accesso e visualizzazione dei dati.\n    df = pd.DataFrame({'flips': flips, 'proportion_heads': proportion_heads, 'run': run_label})\n\n    return df\n\nn = 1000\n\ndf = pd.concat([coin_flips(n, f'run{i+1}') for i in range(4)], axis=0)\nax = sns.lineplot(data = df, x = 'flips', y = 'proportion_heads', hue = 'run')\n\n\n\n\n\n\n\n\n\n\n25.0.14 La Legge dei Grandi Numeri\nLa simulazione precedente fornisce un esempio della Legge dei grandi numeri. La Legge dei Grandi Numeri afferma che, man mano che il numero di esperimenti casuali ripetuti aumenta, la stima della probabilità di un evento \\(P(Y=y)\\) diventa sempre più accurata.\nIl teorema sostiene che, con l’aumento del numero di ripetizioni di un esperimento casuale, la media dei risultati osservati tende a convergere al valore atteso teorico della variabile casuale. In altre parole, la media empirica dei risultati osservati si avvicina sempre di più al valore medio teorico.\nQuesta legge è cruciale perché garantisce che, con un numero sufficientemente grande di prove, la stima empirica della probabilità di un evento si avvicina al valore reale. Questo rende le stime probabilistiche più precise e affidabili.\nDal punto di vista pratico, la Legge dei Grandi Numeri consente di utilizzare modelli probabilistici per interpretare fenomeni reali. Anche se le osservazioni singole possono variare in modo casuale, la media delle osservazioni su un ampio numero di ripetizioni rifletterà fedelmente le probabilità teoriche.\nFormalmente, data una serie di variabili casuali indipendenti \\(X_1, X_2, \\ldots, X_n\\), ciascuna con media \\(\\mu\\), la Legge dei Grandi Numeri è espressa come:\n\\[\n\\lim_{{n \\to \\infty}} P\\left(\\left|\\frac{X_1 + X_2 + \\ldots + X_n}{n} - \\mu\\right| &lt; \\epsilon\\right) = 1,\n\\]\ndove \\(\\epsilon\\) è un valore positivo arbitrariamente piccolo e \\(P(\\cdot)\\) indica la probabilità. Questo significa che, con un numero molto grande di ripetizioni, la media campionaria osservata sarà vicina alla media teorica attesa, permettendo inferenze affidabili sulla probabilità degli eventi.\nIn sintesi, la Legge dei Grandi Numeri assicura che, aumentando il numero di prove, le stime empiriche delle probabilità diventano sempre più precise, allineandosi con i valori teorici attesi.\n\n25.0.14.1 Problema del caso singolo\nNell’ambito dell’approccio frequentista alla probabilità, basato sulla concezione delle frequenze relative di eventi osservati su lunghe serie di ripetizioni, emerge un limite concettuale nel trattare la probabilità di eventi singolari e non ripetibili. Secondo questa prospettiva, infatti, non risulta rigorosamente appropriato discutere di probabilità relative a eventi unici e non replicabili nel tempo. Esempi emblematici di tali eventi includono la possibilità che Alcaraz vinca contro Djokovic nella finale di Wimbledon del 2023 o che si verifichi pioggia a Firenze il giorno di Ferragosto del 2024. Questi scenari, essendo unici e circoscritti a un preciso momento storico, sfuggono alla logica frequentista che richiede, per definizione, la possibilità di osservazione ripetuta degli eventi per valutarne la probabilità. Nonostante ciò, nel linguaggio comune non specialistico, è comune l’uso del termine “probabilità” per riferirsi anche a tali eventi specifici e non ripetibili, evidenziando così una discrepanza tra l’uso tecnico e quello colloquiale del concetto di probabilità.\n\n\n\n25.0.15 Collegamento tra probabilità e statistica\nDurante gli anni ’20 del Novecento, Ronald A. Fisher propose un nuovo framework teorico per l’inferenza statistica, basato sulla concettualizzazione della frequenza. Fisher introdusse concetti chiave come la massima verosimiglianza, i test di significatività, i metodi di campionamento, l’analisi della varianza e il disegno sperimentale.\nNegli anni ’30, Jerzy Neyman ed Egon Pearson fecero ulteriori progressi nel campo con lo sviluppo di una teoria della decisione statistica, basata sul principio della verosimiglianza e sull’interpretazione frequentista della probabilità. Definirono due tipologie di errori decisionali e utilizzarono il test di significatività di Fisher, interpretando i valori-\\(p\\) come indicatori dei tassi di errore a lungo termine.\n\n\n25.0.16 La riscoperta dei metodi Monte Carlo Markov chain\nFisher assunse una prospettiva critica nei confronti della “probabilità inversa” (ossia, i metodi bayesiani), nonostante questa fosse stata la metodologia predominante per l’inferenza statistica per quasi un secolo e mezzo. Il suo approccio frequentista ebbe un profondo impatto sullo sviluppo della statistica sia teorica che sperimentale, contribuendo a un decremento nell’utilizzo dell’inferenza basata sul metodo della probabilità inversa, originariamente proposto da Laplace.\nNel 1939, il libro di Harold Jeffreys intitolato “Theory of Probability” rappresentò una delle prime esposizioni moderne dei metodi bayesiani. Tuttavia, la rinascita del framework bayesiano fu rinviata fino alla scoperta dei metodi Monte Carlo Markov chain alla fine degli anni ’80. Questi metodi hanno reso fattibile il calcolo di risultati precedentemente non ottenibili, consentendo un rinnovato interesse e sviluppo nei metodi bayesiani. Per una storia dell’approccio bayesiano, si veda Bayesian Methods: General Background oppure Philosophy of Statistics.\n\n\n25.0.17 Interpretazione soggettivista\nUna visione alternativa della probabilità la considera come una credenza soggettiva. Finetti (1970) ha proposto un’interpretazione in cui la probabilità non è vista come una caratteristica oggettiva degli eventi, ma piuttosto come una misura della credenza soggettiva, suggerendo di trattare \\(p(·)\\) come una probabilità soggettiva. È interessante notare che de Finetti era un soggettivista radicale. Infatti, la frase di apertura del suo trattato in due volumi sulla probabilità afferma che “La probabilità non esiste”, intendendo che la probabilità non ha uno status oggettivo, ma rappresenta piuttosto la quantificazione della nostra esperienza di incertezza. Riteneva che l’idea di una probabilità esterna all’individuo, con uno status oggettivo, fosse pura superstizione, paragonabile al credere in “Etere cosmico, Spazio e Tempo assoluti, …, o Fate e Streghe…”. Secondo de Finetti, “… esistono solo probabilità soggettive - cioè, il grado di credenza nell’occorrenza di un evento attribuito da una determinata persona in un dato momento con un dato insieme di informazioni.”\nCome sottolineato da Press (2009), la prima menzione della probabilità come grado di credenza soggettiva fu fatta da Ramsey (1926), ed è questa nozione di probabilità come credenza soggettiva che ha portato a una notevole resistenza alle idee bayesiane. Una trattazione dettagliata degli assiomi della probabilità soggettiva si trova in Fishburn (1986).\nLa denominazione “soggettivo” legata alla probabilità potrebbe risultare infelice, poiché potrebbe suggerire un ragionamento vago o non scientifico. Lindley (2013) condivide queste riserve, proponendo l’alternativa “probabilità personale” rispetto a “probabilità soggettiva”. Analogamente, Howson & Urbach (2006) preferiscono utilizzare l’espressione “probabilità epistemica”, che riflette il grado di incertezza di un individuo di fronte al problema trattato. In sostanza, la probabilità epistemica si riferisce all’incertezza personale riguardo a variabili sconosciute. Questa terminologia viene adottata anche nel testo di Kaplan (2023), fornendo un linguaggio più neutro per discutere di questi concetti.\nVa inoltre notato che l’interpretazione soggettiva si adatta bene a eventi singoli, permettendo di esprimere una convinzione su eventi specifici, come la probabilità di pioggia in un dato giorno o l’esito di una competizione sportiva.\n\n\n\n\n\n\nPer chi desidera approfondire, il primo capitolo del testo Bernoulli’s Fallacy (Clayton, 2021) offre un’introduzione molto leggibile alle tematiche della definizione della probabilità nella storia della scienza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/01_intro_prob.html#commenti-e-considerazioni-finali",
    "title": "25  Interpretazione della probabilità",
    "section": "25.1 Commenti e Considerazioni Finali",
    "text": "25.1 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esplorato il significato filosofico della nozione di probabilità e introdotto la simulazione come metodo per approssimare le probabilità empiriche quando non è possibile ottenere soluzioni analitiche.\nNel prossimo capitolo, esamineremo la probabilità dal punto di vista matematico.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/01_intro_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "25  Interpretazione della probabilità",
    "section": "25.2 Informazioni sull’Ambiente di Sviluppo",
    "text": "25.2 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.14.0\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nClayton, A. (2021). Bernoulli’s Fallacy: Statistical Illogic and the Crisis of Modern Science. Columbia University Press.\n\n\nFinetti, B. de. (1970). Teoria delle probabilità (pp. VIII, 350–769). G. Einaudi.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability. Statistical Science, 1(3), 335–345.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: the Bayesian approach. Open Court Publishing.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences. Guilford Publications.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons.\n\n\nPress, S. J. (2009). Subjective and objective Bayesian statistics: Principles, models, and applications. John Wiley & Sons.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in Formal Epistemology: Sourcebook (pp. 21–45). Springer.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Interpretazione della probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html",
    "href": "chapters/probability/02_prob_spaces.html",
    "title": "26  Misura di Probabilità",
    "section": "",
    "text": "26.1 Introduzione alle Probabilità: Origine e Definizione\nDa dove derivano matematicamente i numeri che chiamiamo “probabilità”? Per rispondere, in questo capitolo faremo riferimento alla trattazione di Michael Betancourt. Questo capitolo offre una versione semplificata del suo lavoro, mantenendo la notazione e le figure originali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "href": "chapters/probability/02_prob_spaces.html#insiemi-finiti",
    "title": "26  Misura di Probabilità",
    "section": "26.2 Insiemi Finiti",
    "text": "26.2 Insiemi Finiti\nPer semplificare, Betancourt introduce i fondamenti della teoria della probabilità utilizzando uno spazio campionario composto da un numero finito di elementi.\nUn insieme finito è costituito da un numero finito di elementi distinti,\n\\[\nX = \\{x_1, ..., x_N\\}.\n\\]\nQui, l’indice numerico serve a distinguere gli \\(N\\) elementi individuali, senza implicare necessariamente un ordine particolare tra di essi. Per evitare qualsiasi presunzione di ordine, Betancourt utilizza il seguente insieme arbitrario di cinque elementi quale esempio:\n\\[\nX = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}.\n\\]\n\n\n\n\n\n\nFigura 26.1: Un insieme finito contiene un numero finito di elementi. Questo particolare insieme ne contiene cinque.\n\n\n\nNelle applicazioni pratiche della teoria della probabilità, gli elementi astratti \\(x_{n}\\) rappresentano oggetti concreti. Tuttavia, in questo capitolo, ci si concentrerà esclusivamente sui concetti matematici, evitando qualsiasi interpretazione particolare. Quando l’insieme \\(X\\) rappresenta tutti gli oggetti di interesse in una data applicazione, viene denominato spazio campionario. Una volta definito lo spazio campionario, possiamo organizzare e manipolare i suoi elementi in vari modi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.3 Sottoinsiemi",
    "text": "26.3 Sottoinsiemi\nUn sottoinsieme di \\(X\\) è qualsiasi collezione di elementi in \\(X\\). Per evitare ambiguità, Betancourt usa le lettere romane minuscole \\(x\\) per indicare un elemento variabile nello spazio campionario \\(X\\) e le lettere minuscole sans serif \\(\\mathsf{x}\\) per indicare un sottoinsieme variabile.\nAd esempio, \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) è un sottoinsieme di \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\). Importante notare che nel concetto di sottoinsieme non esiste la nozione di molteplicità, solo di appartenenza: un sottoinsieme può includere un elemento \\(x_{n}\\) ma non può includerlo più volte.\n\n\n\n\n\n\nFigura 26.2: Un sottoinsieme \\(\\mathsf{x} \\subset X\\) è qualsiasi collezione di elementi dallo spazio campionario \\(X\\). Qui \\(\\mathsf{x} = \\{\\Box, \\diamondsuit, \\heartsuit\\}\\) contiene solo tre dei cinque elementi in $X = {, , , , }.\n\n\n\nSe \\(\\mathsf{x}\\) è un sottoinsieme dello spazio campionario \\(X\\) allora scriviamo \\(\\mathsf{x} \\subset X\\). Quando \\(\\mathsf{x}\\) contiene tutti gli elementi di \\(X\\), ovvero \\(\\mathsf{x} = X\\), allora scriviamo \\(\\mathsf{x} \\subseteq X\\).\nIndipendentemente da quanti elementi un insieme finito \\(X\\) contiene, possiamo sempre costruire tre tipi speciali di sottoinsiemi. L’insieme vuoto \\(\\emptyset = \\{\\}\\) non contiene alcun elemento. D’altra parte, l’intero insieme stesso può essere considerato un sottoinsieme contenente tutti gli elementi. Un sottoinsieme contenente un singolo elemento è denotato \\(\\{ x_{n} \\}\\) ed è chiamato insieme atomico.\nCi sono\n\\[\n{N \\choose n} = \\frac{ N! }{ n! (N - n)!}\n\\]\nmodi per selezionare \\(n\\) elementi da un insieme finito di \\(N\\) elementi totali, e quindi \\({N \\choose n}\\) sottoinsiemi totali di dimensione \\(n\\). Ad esempio, esiste un solo sottoinsieme che non contiene alcun elemento,\n\\[\n{N \\choose 0} = \\frac{ N! }{ 0! (N - 0)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned è l’insieme vuoto. Allo stesso modo, esiste un solo sottoinsieme che contiene tutti gli elementi,\n\\[\n{N \\choose N} = \\frac{ N! }{ N! (N - N)!} = \\frac{ N! }{ N! } = 1,\n\\]\ned è l’insieme completo stesso. D’altra parte, ci sono\n\\[\n{N \\choose 1} = \\frac{ N! }{ 1! (N - 1)!} = N\n\\]\ninsiemi atomici distinti che contengono un solo elemento, uno per ciascun elemento in \\(X\\).\nContando tutti i sottoinsiemi di tutte le dimensioni possibili si ottiene\n\\[\n\\sum_{n = 0}^{N} {N \\choose n} = 2^{N}\n\\]\nsottoinsiemi possibili che possiamo costruire da un insieme finito con \\(N\\) elementi.\nLa collezione di tutti i sottoinsiemi è essa stessa un insieme finito con \\(2^{N}\\) elementi. Chiamiamo questo insieme insieme potenza di \\(X\\) e lo denotiamo \\(2^{X}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#operazioni-sui-sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.4 Operazioni sui Sottoinsiemi",
    "text": "26.4 Operazioni sui Sottoinsiemi\nPossiamo sempre costruire sottoinsiemi elemento per elemento, ma possiamo anche costruirli manipolando sottoinsiemi esistenti.\nAd esempio, dato un sottoinsieme \\(\\mathsf{x} \\subset X\\) possiamo costruire il suo complemento raccogliendo tutti gli elementi in \\(X\\) che non sono già in \\(\\mathsf{x}\\). L’insieme atomico \\(\\mathsf{x} = \\{ \\diamondsuit \\}\\) contiene l’unico elemento \\(\\diamondsuit\\) e il suo complemento contiene i rimanenti elementi \\[\n\\mathsf{x}^{c} = \\{ \\Box, \\clubsuit, \\heartsuit, \\spadesuit \\}.\n\\] Per costruzione, il complemento dell’insieme vuoto è l’intero insieme, \\(\\emptyset^{c} = X\\), e il complemento dell’insieme completo è l’insieme vuoto, \\(X^{c} = \\emptyset\\).\n\n\n\n\n\n\nFigura 26.3: Il complemento di un sottoinsieme \\(\\mathsf{x}\\) è il sottoinsieme \\(\\mathsf{x}^{c}\\) costituito da tutti gli elementi nello spazio campionario che non sono in \\(\\mathsf{x}\\).\n\n\n\nAd esempio, applicando l’operatore di complemento al sottoinsieme \\(\\mathsf{x} = \\{ \\clubsuit, \\spadesuit \\}\\) otteniamo \\[\n\\mathsf{x}^{c}\n= \\{ \\clubsuit, \\spadesuit \\}^{c}\n= \\{ \\Box, \\diamondsuit, \\heartsuit \\}.\n\\]\nPossiamo anche costruire sottoinsiemi da più di un sottoinsieme. Consideriamo, ad esempio, due sottoinsiemi \\(\\mathsf{x}_1 = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_2 = \\{ \\Box, \\spadesuit \\}\\). La collezione di tutti gli elementi che sono contenuti in uno qualsiasi dei due sottoinsiemi è essa stessa un sottoinsieme, \\[\n\\{ \\Box, \\heartsuit, \\spadesuit \\} \\subset X,\n\\] così come la collezione di tutti gli elementi che sono contenuti in entrambi i sottoinsiemi, \\[\n\\{ \\Box \\} \\subset X.\n\\] Questi sottoinsiemi derivati sono chiamati rispettivamente unione, \\[\n\\mathsf{x}_1 \\cup \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box, \\heartsuit, \\spadesuit \\},\n\\] e intersezione, \\[\n\\mathsf{x}_1 \\cap \\mathsf{x}_2\n= \\{ \\Box, \\heartsuit \\} \\cap \\{ \\Box, \\spadesuit \\}\n= \\{ \\Box \\}.\n\\]\n\n\n\n\n\n\nFigura 26.4: Possiamo manipolare due sottoinsiemi in vari modi per ottenere un nuovo sottoinsieme.\n\n\n\n\n\n\n\n\n\nFigura 26.5: L’unione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cup \\mathsf{x}_2\\), è un sottoinsieme contenente tutti gli elementi di entrambi i sottoinsiemi in input. D’altra parte, l’intersezione di due sottoinsiemi, \\(\\mathsf{x}_1 \\cap \\mathsf{x}_2\\), è un sottoinsieme contenente solo gli elementi che compaiono in entrambi i sottoinsiemi in input.\n\n\n\nDue sottoinsiemi sono disgiunti se non condividono alcun elemento; in questo caso la loro intersezione è l’insieme vuoto, \\[\n\\mathsf{x}_{1} \\cap \\mathsf{x}_{2} = \\emptyset.\n\\] L’unione e l’intersezione di un sottoinsieme con se stesso restituiscono quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\mathsf{x} = \\mathsf{x} \\cap \\mathsf{x} = \\mathsf{x}.\n\\] Poiché l’insieme vuoto non contiene alcun elemento, la sua unione con qualsiasi sottoinsieme restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cup \\emptyset = \\emptyset \\cup \\mathsf{x} = \\mathsf{x},\n\\] e la sua intersezione con qualsiasi sottoinsieme restituisce l’insieme vuoto, \\[\n\\mathsf{x} \\cap \\emptyset = \\emptyset \\cap \\mathsf{x} = \\emptyset.\n\\] Allo stesso modo, l’unione di un sottoinsieme con l’insieme completo restituisce l’insieme completo, \\[\n\\mathsf{x} \\cup X = X \\cup \\mathsf{x} = X,\n\\] e l’intersezione di un sottoinsieme con l’insieme completo restituisce quel sottoinsieme, \\[\n\\mathsf{x} \\cap X = X \\cap \\mathsf{x} = \\mathsf{x}.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sugli-elementi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sugli-elementi",
    "title": "26  Misura di Probabilità",
    "section": "26.5 Misura e Probabilità sugli Elementi",
    "text": "26.5 Misura e Probabilità sugli Elementi\nDa un punto di vista matematico, la teoria della misura riguarda l’allocazione coerente di una qualche quantità astratta attraverso lo spazio campionario. Consideriamo un serbatoio (il termine standard in questo contesto sarebbe “misura totale” o “massa totale”) di una qualche quantità positiva, continua e conservata, \\(M \\in [0, \\infty]\\). Poiché \\(M\\) è conservato, qualsiasi quantità \\(m_{n}\\) che viene allocata all’elemento \\(x_{n} \\in X\\) deve essere detratta dal serbatoio, lasciando meno da allocare agli altri elementi.\nUn caso particolare si verifica quando il contenuto totale del serbatoio \\(M\\) è infinito. In questo scenario, possiamo allocare una quantità infinita dal serbatoio pur avendo ancora una quantità infinita rimanente. Allo stesso tempo, allocare una quantità infinita può esaurire completamente il serbatoio o lasciare qualsiasi quantità finita residua. L’infinito è un concetto matematicamente complesso da trattare.\n\n\n\n\n\n\nFigura 26.6: La teoria della misura riguarda l’allocazione di una qualche quantità continua e positiva \\(M\\) sugli elementi individuali dello spazio campionario.\n\n\n\nUn’allocazione esaustiva di \\(M\\) su tutto lo spazio campionario assicura che il serbatoio sia completamente svuotato. In altre parole, l’intero valore di \\(M\\) deve essere distribuito tra gli elementi \\(x_{n} \\in X\\).\nPer illustrare questo concetto, consideriamo il nostro spazio campionario dimostrativo \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit \\}\\). Il processo di allocazione può essere descritto come segue:\n\nAllocchiamo \\(m_\\Box\\) a \\(\\Box\\), lasciando \\(M - m_\\Box\\) nel serbatoio.\nAssegniamo \\(m_\\clubsuit\\) a \\(\\clubsuit\\), riducendo ulteriormente il contenuto del serbatoio a \\(M - m_\\Box - m_\\clubsuit\\).\nContinuiamo questo processo per \\(\\diamondsuit\\) e \\(\\heartsuit\\).\nInfine, per svuotare completamente il serbatoio, dobbiamo allocare tutto ciò che rimane a \\(\\spadesuit\\).\n\nMatematicamente, l’ammontare finale allocato a \\(\\spadesuit\\) sarà:\n\\[\nM - m_{\\Box} - m_{\\clubsuit} - m_{\\diamondsuit} - m_{\\heartsuit}.\n\\]\nQuesta allocazione finale assicura che la somma di tutte le quantità distribuite sia esattamente uguale a \\(M\\), svuotando così completamente il serbatoio.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n \n\n\n\n\nFigura 26.7: Poiché la quantità totale \\(M\\) è conservata, ogni allocazione \\(m_{n}\\) a un elemento \\(x_{n} \\in X\\) riduce la quantità disponibile per l’allocazione agli altri elementi. Un’allocazione esaustiva non lascia nulla nel serbatoio iniziale dopo che ciascun elemento ha ricevuto la sua allocazione.\n\n\n\nUna misura è qualsiasi allocazione coerente della quantità \\(M\\) agli elementi di uno spazio campionario. Matematicamente, qualsiasi misura su un insieme finito può essere caratterizzata da \\(N\\) numeri \\[\n\\mu = \\{ m_{1}, \\ldots, m_{N} \\}\n\\] che soddisfano \\[\n0 \\le m_{n}\n\\] e \\[\n\\sum_{n = 1}^{N} m_{n} = M.\n\\] Ad esempio, qualsiasi misura sui cinque elementi dell’insieme \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\) è specificata da cinque numeri positivi \\(\\{ m_\\Box, m_\\clubsuit, m_\\diamondsuit, m_\\heartsuit, m_\\spadesuit \\}\\) che soddisfano \\[\nm_\\Box + m_\\clubsuit + m_\\diamondsuit + m_\\heartsuit + m_\\spadesuit = M.\n\\]\n\n\n\n\n\n\nFigura 26.8: Una misura \\(\\mu\\) su un insieme finito \\(X\\) è qualsiasi allocazione coerente di \\(M\\) agli elementi $x_{n} X. Ogni misura può essere caratterizzata da \\(N\\) numeri \\(m_{n}\\) che sommano a \\(M\\), o equivalentemente una funzione che mappa ogni elemento \\(x_{n}\\) alla sua misura allocata \\(m_{n}\\).\n\n\n\nPiù grande è \\(m_{n}\\), più di \\(M\\) viene allocato all’elemento \\(x_{n}\\). Seguendo questa terminologia, chiameremo anche \\(M\\) come la misura totale e \\(m_{n}\\) come la misura allocata a \\(x_{n}\\).\nIn questa discussione, ci occuperemo solo di misure finite, dove la misura totale \\(M\\) è un numero positivo e finito (\\(0 \\leq M \\leq \\infty\\)). Non tratteremo il caso di misure infinite (\\(M = \\infty\\)), poiché richiede considerazioni più complesse che vanno oltre lo scopo di questa trattazione.\nUna misura \\(\\mu\\) su uno spazio campionario \\(X\\) può essere vista come una funzione che assegna un valore numerico non negativo (la misura) a ogni elemento dello spazio:\n\\[\n\\begin{alignat*}{6}\n\\mu :\\; & X & &\\rightarrow& \\; & [0, \\infty] &\n\\\\\n& x_{n} & &\\mapsto& & m_{n} = \\mu(x_{n}) &,\n\\end{alignat*}\n\\] dove:\n\n\\(X\\) è lo spazio campionario,\n\\(x_n\\) è un elemento di \\(X\\),\n\\(m_n\\) è la misura assegnata a \\(x_n\\).\n\nQuesto approccio funzionale ci permette di considerare ogni elemento dello spazio campionario separatamente, valutando \\(\\mu(x_{n})\\) per ciascun \\(x_{n}\\), invece di dover gestire tutte le allocazioni contemporaneamente.\nÈ importante notare che esistono molti modi diversi per distribuire una misura totale \\(M\\) tra gli elementi di un insieme finito. L’insieme di tutte le possibili misure su \\(X\\) si indica con \\(\\mathcal{M}(X)\\).\nAll’interno di questa collezione ci sono alcuni esempi notevoli. Ad esempio, una misura singolare alloca la misura totale \\(M\\) a un singolo elemento, lasciando il resto con niente. D’altra parte, una misura uniforme alloca la stessa misura \\(M / N\\) a ciascun elemento. Su insiemi finiti ci sono \\(N\\) misure singolari distinte, una per ciascun elemento distinto, e una misura uniforme unica.\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\nFigura 26.9: Una misura singolare (a) alloca la misura totale a un singolo elemento, mentre la misura uniforme (b) distribuisce la misura totale uniformemente a ciascun elemento.\n\n\n\nLe misure finite sono una categoria particolarmente importante nel campo della teoria della misura. Una misura si definisce finita quando la sua misura totale \\(M\\) è un numero positivo e limitato, ovvero \\(0 &lt; M &lt; \\infty\\).\nL’importanza delle misure finite risiede nella possibilità di esprimere le allocazioni in termini relativi anziché assoluti. Questo significa che possiamo rappresentare la misura di ciascun elemento come una frazione o una percentuale della misura totale, invece di usare il valore assoluto. Invece di considerare la misura assoluta allocata a ciascun elemento \\(m_{n}\\), possiamo considerare la proporzione della misura totale allocata a ciascun elemento \\[\np_{n} = m_{n} / M.\n\\] Per costruzione, le proporzioni sono confinate all’intervallo unitario \\([0, 1]\\). Come per qualsiasi quantità che assume valori in \\([0, 1]\\), possiamo rappresentare le proporzioni altrettanto bene con decimali, ad esempio \\(p_{n} = 0.2\\), e percentuali, \\(p_{n} = 20\\%\\).\nQuesto approccio relativo offre diversi vantaggi: permette di confrontare facilmente l’importanza relativa di diversi elementi, facilita la comprensione della distribuzione della misura sull’intero spazio campionario e consente di normalizzare misure diverse, rendendo più semplice il confronto tra sistemi diversi. In sintesi, le misure finite ci permettono di passare da una visione “assoluta” a una “relativa” della distribuzione della misura, offrendo una prospettiva più intuitiva e utile per l’analisi.\n\n\n\n\n\n\nFigura 26.10: Ogni misura finita può essere caratterizzata da un’allocazione proporzionale.\n\n\n\nIn altre parole, una misura proporzionale definisce la funzione \\[\n\\begin{alignat*}{6}\n\\pi :\\; & X & &\\rightarrow& \\; & [0, 1] &\n\\\\\n& x_{n} & &\\mapsto& & p_{n} = \\pi(x_{n}) &\n\\end{alignat*}\n\\] con \\[\n0 \\le p_{n} \\le 1\n\\] e \\[\n\\sum_{n = 1}^{N} p_{n} = 1.\n\\] Una collezione di variabili \\(\\{ p_{1}, \\ldots, p_{N} \\}\\) che soddisfano queste proprietà è chiamata simplex.\n\n\n\n\n\n\nFigura 26.11: Un’allocazione proporzionale è anche conosciuta come distribuzione di probabilità.\n\n\n\nPiù importante, una misura proporzionale \\(\\pi\\) è anche conosciuta come distribuzione di probabilità, e le allocazioni proporzionali \\(p_{n}\\) sono chiamate probabilità. Sebbene il termine “probabilità” sia spesso carico di significati interpretativi e filosofici, la sua struttura matematica è piuttosto semplice: su un insieme finito, una probabilità rappresenta semplicemente la proporzione di una quantità finita assegnata a ciascun elemento individuale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sui-sottoinsiemi",
    "href": "chapters/probability/02_prob_spaces.html#misura-e-probabilità-sui-sottoinsiemi",
    "title": "26  Misura di Probabilità",
    "section": "26.6 Misura e Probabilità sui Sottoinsiemi",
    "text": "26.6 Misura e Probabilità sui Sottoinsiemi\nSugli insiemi finiti, qualsiasi allocazione, sia assoluta che proporzionale, agli elementi individuali \\(x \\in X\\) determina anche un’allocazione per i sottoinsiemi \\(\\mathsf{x} \\in 2^{X}\\). La misura assegnata a un sottoinsieme è semplicemente la somma delle misure assegnate agli elementi che lo compongono. Ad esempio, la misura assegnata al sottoinsieme \\(\\mathsf{x} = \\{ \\Box, \\clubsuit, \\heartsuit \\}\\) è \\(m_{\\Box} + m_{\\clubsuit} + m_{\\heartsuit}\\).\n\n\n\n\n\n\nFigura 26.12: Su un insieme finito, un’allocazione sugli elementi individuali definisce anche un’allocazione su qualsiasi sottoinsieme.\n\n\n\nPer costruzione, qualsiasi misura sui sottoinsiemi e distribuzione di probabilità soddisfano una serie di proprietà utili. Ad esempio, per qualsiasi misura \\[\n\\mu( \\emptyset ) = 0\n\\] e \\[\n\\mu( X ) = \\sum_{n = 1}^{N} \\mu(x_{n}) = M,\n\\] mentre per qualsiasi distribuzione di probabilità abbiamo \\(\\pi( \\emptyset ) = 0\\) e \\(\\pi( X ) = 1\\).\nLe allocazioni sui sottoinsiemi si combinano in modo naturale con le operazioni sui sottoinsiemi. Consideriamo, ad esempio, i due sottoinsiemi disgiunti \\(\\mathsf{x}_{1} = \\{ \\Box, \\diamondsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\clubsuit, \\spadesuit \\}\\). Poiché i due sottoinsiemi sono disgiunti, la loro unione include semplicemente tutti i loro elementi:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2}\n=\n\\{ \\Box, \\diamondsuit \\} \\cup \\{ \\clubsuit, \\spadesuit \\}\n=\n\\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\},\n\\]\ne la misura di questa unione è solo la somma delle misure dei due sottoinsiemi:\n\\[\n\\begin{align*}\n\\mu ( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} )\n&=\n\\mu ( \\{ \\Box, \\clubsuit, \\diamondsuit, \\spadesuit \\} )\n\\\\\n&=\nm_{\\Box} + m_{\\clubsuit} + m_{\\diamondsuit} + m_{\\spadesuit}\n\\\\\n&=\n( m_{\\Box} + m_{\\diamondsuit} ) + ( m_{\\clubsuit} + m_{\\spadesuit} )\n\\\\\n&=\n\\mu( \\mathsf{x}_{1} ) + \\mu( \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nPiù in generale, per qualsiasi collezione di sottoinsiemi\n\\[\n\\mathsf{x}_{1}, \\ldots, \\mathsf{x}_{K}\n\\]\nche sono reciprocamente disgiunti,\n\\[\n\\mathsf{x}_{k} \\cap \\mathsf{x}_{k'} = \\emptyset \\quad \\text{per} \\quad k \\ne k',\n\\]\nabbiamo\n\\[\n\\mu ( \\cup_{k = 1}^{K} \\mathsf{x}_{k} )\n=\n\\sum_{k = 1}^{K} \\mu ( \\mathsf{x}_{k} ).\n\\]\nIn altre parole, se possiamo scomporre un sottoinsieme in una collezione di sottoinsiemi più piccoli e disgiunti, possiamo anche scomporre la misura allocata a quel sottoinsieme iniziale nelle misure allocate ai sottoinsiemi componenti. Questa proprietà di coerenza è chiamata additività.\nUn sottoinsieme \\(\\mathsf{x}\\) e il suo complemento \\(\\mathsf{x}^{c}\\) sono sempre disgiunti, ovvero \\(\\mathsf{x} \\cap \\mathsf{x}^{c} = \\emptyset\\). Allo stesso tempo, la loro unione copre l’intero insieme: \\(\\mathsf{x} \\cup \\mathsf{x}^{c} = X\\). Di conseguenza, l’additività implica che:\n\\[\n\\begin{align*}\nM &= \\mu (X) \\\\\n  &= \\mu ( \\mathsf{x} \\cup \\mathsf{x}^{c} ) \\\\\n  &= \\mu ( \\mathsf{x} ) + \\mu ( \\mathsf{x}^{c} ),\n\\end{align*}\n\\]\nda cui segue che:\n\\[\n\\mu ( \\mathsf{x}^{c} ) = M - \\mu ( \\mathsf{x} ).\n\\]\nIn altre parole, la misura assegnata al complemento di un sottoinsieme è la misura totale meno la misura assegnata a quel sottoinsieme. Per le distribuzioni di probabilità, questo concetto è ancora più evidente:\n\\[\n\\pi ( \\mathsf{x}^{c} ) = 1 - \\pi ( \\mathsf{x} ).\n\\]\nQuando due sottoinsiemi si sovrappongono, dobbiamo considerare che la somma delle loro misure \\(\\mu (\\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} )\\) conta due volte la misura degli elementi condivisi tra di essi. Ad esempio, se \\(\\mathsf{x}_{1} = \\{ \\Box, \\heartsuit \\}\\) e \\(\\mathsf{x}_{2} = \\{ \\Box, \\spadesuit \\}\\), allora l’unione include l’elemento sovrapposto \\(\\Box\\) solo una volta:\n\\[\n\\mathsf{x}_{1} \\cup \\mathsf{x}_{2} = \\{ \\Box, \\heartsuit \\} \\cup \\{ \\Box, \\spadesuit \\} = \\{ \\Box, \\heartsuit, \\spadesuit \\}.\n\\]\nDi conseguenza:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) &= \\mu( \\{ \\Box, \\heartsuit, \\spadesuit \\} ) \\\\\n&= m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit}.\n\\end{align*}\n\\]\nSommando le misure allocate ai due sottoinsiemi individualmente, tuttavia, otteniamo:\n\\[\n\\begin{align*}\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) &= (m_{\\Box} + m_{\\heartsuit} ) + ( m_{\\Box} + m_{\\spadesuit} ) \\\\\n&= m_{\\Box} + m_{\\Box} + m_{\\heartsuit} + m_{\\spadesuit} \\\\\n&= m_{\\Box} + \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ).\n\\end{align*}\n\\]\nL’elemento che viene contato due volte è esattamente l’unico elemento nell’intersezione dei due sottoinsiemi:\n\\[\nm_{\\Box} = \\mu( \\{ \\Box \\} ) = \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nIn altre parole, possiamo scrivere:\n\\[\n\\mu( \\mathsf{x}_{1} ) + \\mu ( \\mathsf{x}_{2} ) = \\mu( \\mathsf{x}_{1} \\cup \\mathsf{x}_{2} ) + \\mu( \\mathsf{x}_{1} \\cap \\mathsf{x}_{2} ).\n\\]\nQuesta relazione vale per qualsiasi due sottoinsiemi, indipendentemente dalla loro sovrapposizione.\n\n\n\n\n\n\nFigura 26.13: Quando due sottoinsiemi si sovrappongono, la misura allocata a ciascuno conta doppio la misura allocata a qualsiasi elemento sovrapposto, qui \\(\\Box\\), ma la misura allocata alla loro unione no. Questo risulta in una relazione importante tra le misure allocate ai due sottoinsiemi, la misura allocata alla loro unione e la misura allocata alla loro intersezione.\n\n\n\nQueste proprietà dei sottoinsiemi ci permettono di costruire una misura in molti modi diversi, ciascuno dei quali può essere utile in circostanze diverse. Questa flessibilità è molto comoda quando si applica la teoria della misura e la teoria della probabilità nella pratica.\nAd esempio, possiamo specificare una misura in due modi principali:\n\nAllocazione globale: possiamo assegnare le misure a tutti gli elementi individuali contemporaneamente. Questo metodo considera l’intero insieme fin dall’inizio e assegna una misura a ciascun elemento.\n\n\n\n\n\n\n\nFigura 26.14: Le misure possono essere costruite specificando le allocazioni degli elementi individuali tutte insieme.\n\n\n\n\nAllocazione locale: possiamo assegnare la misura a ciascun elemento uno alla volta. Questo metodo permette di concentrarsi su un elemento alla volta, aggiungendo gradualmente le misure agli altri elementi.\n\n\n\n\n\n\n\nFigura 26.15: Allo stesso tempo, le misure possono essere costruite specificando le allocazioni degli elementi individuali uno alla volta.\n\n\n\nInoltre, non è sempre necessario partire dalle allocazioni individuali. Un altro metodo consiste nel:\n\nAllocazione iterativa: possiamo iniziare allocando la misura totale a sottoinsiemi disgiunti e poi affinare iterativamente questa allocazione suddividendo i sottoinsiemi in parti sempre più piccole fino a raggiungere gli elementi individuali.\n\n\n\n\n\n\n\nFigura 26.16: Le misure possono anche essere costruite allocando la misura totale a sottoinsiemi disgiunti e poi raffinando iterativamente tale allocazione a sottoinsiemi sempre più piccoli.\n\n\n\nQuesta flessibilità nelle modalità di costruzione delle misure è particolarmente utile perché permette di adattare l’approccio alle specifiche necessità del problema in questione. Ad esempio, nella pratica, potremmo trovare più semplice allocare inizialmente misure a grandi gruppi di elementi e poi suddividere questi gruppi, oppure potremmo voler assegnare le misure a ciascun elemento uno per uno a seconda delle esigenze del contesto.\nInfine, la definizione di misura sui sottoinsiemi \\(\\mu : 2^{X} \\rightarrow [0, \\infty]\\) è cruciale per estendere la teoria della misura oltre gli insiemi finiti. Questa estensione è necessaria per definire misure in modo coerente su insiemi matematicamente più complessi, come la retta reale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "href": "chapters/probability/02_prob_spaces.html#riflessioni-conclusive",
    "title": "26  Misura di Probabilità",
    "section": "26.7 Riflessioni Conclusive",
    "text": "26.7 Riflessioni Conclusive\nIl significato applicativo delle nozioni di misura e distribuzione di probabilità è centrale per comprendere come utilizzare questi concetti nella pratica, in particolare nella statistica bayesiana. Il punto cruciale è capire cosa rappresenta \\(M\\), la “misura totale”. Nelle applicazioni bayesiane, \\(M\\) rappresenta la nostra certezza complessiva.\nQuando si lavora con distribuzioni di probabilità, stiamo effettivamente allocando questa certezza complessiva tra diversi eventi possibili. Una distribuzione (di massa) di probabilità è quindi l’allocazione relativa della nostra certezza tra un insieme di eventi disgiunti. Ogni probabilità individuale, \\(p_n\\), rappresenta la proporzione della nostra certezza totale che assegniamo a un particolare evento.\nNella teoria bayesiana, la “misura totale” \\(M\\) è interpretata come la somma totale delle probabilità, che è sempre uguale a 1. Questo riflette il fatto che la somma delle nostre certezze relative per tutti gli eventi possibili deve essere completa: siamo completamente certi che uno degli eventi nel nostro spazio campionario si verificherà.\nQuando creiamo una distribuzione di probabilità, stiamo dividendo questa certezza totale tra i vari eventi possibili nel nostro spazio campionario. Ad esempio, se stiamo analizzando un problema con cinque possibili esiti distinti, dobbiamo allocare l’intera certezza (pari a 1) tra questi esiti. Ogni valore di probabilità \\(p_n\\) rappresenta la frazione della nostra certezza totale che attribuiamo a un particolare esito.\nLe nozioni di misura e distribuzione di probabilità trovano numerose applicazioni pratiche. Ad esempio:\n\nInferenza bayesiana: Utilizziamo distribuzioni di probabilità per rappresentare le nostre incertezze sui parametri di interesse. Dopo aver osservato i dati, aggiorniamo queste distribuzioni tramite il teorema di Bayes.\nModellizzazione probabilistica: Costruiamo modelli che descrivono il comportamento di sistemi complessi assegnando probabilità agli eventi possibili. Questo ci permette di fare previsioni e prendere decisioni informate basate sulle probabilità assegnate.\n\nIn conclusione, le nozioni di misura e distribuzione di probabilità sono strumenti potenti per allocare e manipolare la nostra certezza tra diversi eventi possibili. Comprendere questi concetti è fondamentale per comprendere le applicazioni della teoria della probabilità e della statistica bayesiana. La “misura totale” \\(M\\) rappresenta la nostra certezza complessiva, e le distribuzioni di probabilità ci permettono di distribuire questa certezza in modo coerente e informato tra gli eventi possibili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Misura di Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html",
    "href": "chapters/probability/03_prob_on_general_spaces.html",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "",
    "text": "Introduzione\nNel Capitolo 26 abbiamo introdotto la teoria della misura e della probabilità su insiemi con un numero finito di elementi. Tuttavia, molti degli spazi matematici che incontriamo nelle applicazioni pratiche, come gli interi e la retta reale, non hanno un numero finito di elementi, ma piuttosto un numero numerabile infinito o addirittura non numerabile infinito di elementi. Sfortunatamente, estendere la teoria della misura e della probabilità a spazi più generali come questi non è sempre semplice.\nSenza entrare nei dettagli, è stato dimostrato che la forma più generale della teoria della misura e della probabilità applicabile a qualsiasi spazio matematico è chiamata \\(\\sigma\\)-algebra. In questo capitolo, forniremo un’introduzione intuitiva ai vincoli delle \\(\\sigma\\)-algebre ed esamineremo alcune notevoli applicazioni. In particolare, introdurremo i concetti di variabile casuale, funzioni di massa di probabilità e funzioni di ripartizione.\nQuesti concetti sono fondamentali per comprendere come la probabilità e la misura possono essere utilizzate in contesti più complessi, permettendo di estendere le nostre analisi a insiemi infiniti e spazi continui, che sono comuni nelle applicazioni psicologiche.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#sigma-algebra",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.1 \\(\\sigma\\)-Algebra",
    "text": "27.1 \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra è una struttura matematica che permette di definire in modo coerente quali sottoinsiemi di un insieme sono “misurabili”.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "href": "chapters/probability/03_prob_on_general_spaces.html#definizione-di-sigma-algebra",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.2 Definizione di \\(\\sigma\\)-Algebra",
    "text": "27.2 Definizione di \\(\\sigma\\)-Algebra\nUna \\(\\sigma\\)-algebra è una collezione di sottoinsiemi di uno spazio \\(X\\) che soddisfa le seguenti proprietà:\n\nChiusura rispetto al complemento: Se un sottoinsieme \\(A\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche il suo complemento \\(A^c\\) appartiene a \\(\\mathcal{F}\\). Questo significa che se \\(\\mathcal{F}\\) contiene un certo sottoinsieme, deve contenere anche tutti gli elementi che non sono in quel sottoinsieme.\nChiusura rispetto alle unioni numerabili: Se una sequenza numerabile di sottoinsiemi \\(A_1, A_2, A_3, \\ldots\\) appartiene alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\), allora anche l’unione di tutti questi sottoinsiemi appartiene a \\(\\mathcal{F}\\). Questo implica che se \\(\\mathcal{F}\\) contiene una serie di sottoinsiemi, deve contenere anche il loro insieme unito.\nInclusione dello spazio campionario: Lo spazio campionario \\(X\\) stesso deve appartenere alla \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). In altre parole, l’intero insieme \\(X\\) è considerato un sottoinsieme misurabile.\n\nLa chiusura in questo contesto significa che la collezione \\(\\mathcal{F}\\) è stabile rispetto a determinate operazioni insiemistiche. In particolare, se si applicano le operazioni di complemento o di unione numerabile a elementi della \\(\\sigma\\)-algebra, i risultati di queste operazioni rimarranno all’interno della stessa \\(\\sigma\\)-algebra. Questo garantisce che la \\(\\sigma\\)-algebra non “perda” elementi a causa di queste operazioni, mantenendo così la coerenza e la completezza della collezione di sottoinsiemi.\n\n27.2.1 Spazio Misurabile\nUn insieme dotato di una \\(\\sigma\\)-algebra, \\((X, \\mathcal{X})\\), è detto spazio misurabile. Gli elementi di una \\(\\sigma\\)-algebra sono noti come sottoinsiemi misurabili, mentre i sottoinsiemi non appartenenti alla \\(\\sigma\\)-algebra sono detti non misurabili. La distinzione tra sottoinsiemi misurabili e non misurabili è cruciale per evitare comportamenti anomali e controintuitivi nella teoria della misura e della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "href": "chapters/probability/03_prob_on_general_spaces.html#gli-assiomi-di-kolmogorov",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.3 Gli Assiomi di Kolmogorov",
    "text": "27.3 Gli Assiomi di Kolmogorov\nI tre assiomi di Kolmogorov definiscono le proprietà fondamentali di una misura di probabilità e richiedono l’esistenza di una \\(\\sigma\\)-algebra.\n\nNon negatività: Per qualsiasi evento \\(A\\) nello spazio campionario \\(\\Omega\\), la probabilità di \\(A\\) è non negativa. \\[\nP(A) \\geq 0.\n\\]\nNormalizzazione: La probabilità dell’intero spazio campionario \\(\\Omega\\) è 1. \\[\nP(\\Omega) = 1.\n\\]\nAdditività numerabile: Per qualsiasi sequenza numerabile di eventi mutuamente esclusivi \\(A_1, A_2, A_3, \\ldots\\), la probabilità della loro unione è la somma delle loro probabilità. \\[\nP\\left(\\bigcup_{i=1}^{\\infty} A_i\\right) = \\sum_{i=1}^{\\infty} P(A_i).\n\\]\n\n\n27.3.1 Connessione tra gli Assiomi di Kolmogorov e le \\(\\sigma\\)-Algebre\nGli assiomi di Kolmogorov sono definiti rispetto a una misura di probabilità \\(P\\) su uno spazio campionario \\(\\Omega\\) e implicano l’esistenza di una \\(\\sigma\\)-algebra \\(\\mathcal{F}\\). La \\(\\sigma\\)-algebra \\(\\mathcal{F}\\) è la collezione di eventi (sottoinsiemi di \\(\\Omega\\)) per i quali la misura di probabilità \\(P\\) è definita.\n\nNon negatività garantisce che \\(P\\) assegni un valore non negativo a ogni evento nella \\(\\sigma\\)-algebra.\nNormalizzazione garantisce che \\(P(\\Omega) = 1\\), assicurando che \\(\\Omega\\) sia un elemento della \\(\\sigma\\)-algebra.\nAdditività numerabile garantisce che la \\(\\sigma\\)-algebra sia chiusa rispetto alle unioni numerabili di insiemi disgiunti.\n\nIn sintesi, gli assiomi di Kolmogorov richiedono una \\(\\sigma\\)-algebra come struttura all’interno della quale queste proprietà valgono. La \\(\\sigma\\)-algebra è quindi la collezione di eventi per i quali la misura di probabilità è ben definita e coerente con gli assiomi di Kolmogorov.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilità",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilità",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.4 Probabilità",
    "text": "27.4 Probabilità\nUna volta definiti gli assiomi di Kolmogorov, è possibile introdurre la definizione di probabilità.\nLa probabilità di un evento è una misura numerica che indica la possibilità che tale evento si verifichi, in accordo con gli assiomi di Kolmogorov.\n\nSe \\(P(A) = 0\\), l’evento \\(A\\) è impossibile.\nSe \\(P(A) = 1\\), l’evento \\(A\\) è certo.\n\nPer denotare la probabilità che un evento \\(A\\) non si verifichi, si usa la notazione \\(P(A^c)\\), dove: \\[\nP(A^c) = 1 - P(A).\n\\]\n\n27.4.1 Proprietà Derivate dagli Assiomi di Kolmogorov\nAlcune proprietà importanti derivate dagli assiomi includono:\n\n\\(P(\\varnothing) = 0\\),\nSe \\(A \\subset B\\), allora \\(P(A) \\leq P(B)\\),\n\\(0 \\leq P(A) \\leq 1\\),\n\\(P(A^c) = 1 - P(A)\\),\nSe \\(A \\cap B = \\varnothing\\), allora \\(P(A \\cup B) = P(A) + P(B)\\).\n\n\n\n27.4.2 Regole di Addizione per Eventi\nPer eventi non mutuamente esclusivi, la probabilità della loro unione è data da: \\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\]\nUtilizzando il terzo assioma della probabilità, si ottiene: \\[\nP(A \\cup B) = P(A \\cap B^c) + P(B \\cap A^c) + P(A \\cap B).\n\\]\nQuando \\(A\\) e \\(B\\) sono mutuamente esclusivi, \\(P(A \\cap B) = 0\\), e quindi: \\[\nP(A \\cup B) = P(A) + P(B).\n\\]\nLa legge della probabilità totale permette di scrivere: \\[\nP(A) = P(A \\cap B) + P(A \\cap B^c),\n\\] e analogamente per \\(B\\): \\[\nP(B) = P(B \\cap A) + P(B \\cap A^c).\n\\]\nIn conclusione, gli assiomi di Kolmogorov forniscono la base per definire la probabilità su una \\(\\sigma\\)-algebra, garantendo che le proprietà fondamentali della probabilità siano rispettate e che la probabilità sia ben definita per una collezione coerente di sottoinsiemi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#probabilità-e-calcolo-combinatorio",
    "href": "chapters/probability/03_prob_on_general_spaces.html#probabilità-e-calcolo-combinatorio",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.5 Probabilità e Calcolo Combinatorio",
    "text": "27.5 Probabilità e Calcolo Combinatorio\nI problemi scolastici più comuni sulle probabilità richiedono l’uso del calcolo combinatorio. La struttura generale di questi problemi è sempre la stessa: dobbiamo contare il numero di modi in cui un evento compatibile con l’evento di “successo” definito dal problema si realizza e poi trovare la proporzione di tali eventi rispetto a tutti gli eventi possibili (inclusi quelli di “insuccesso”) che possono verificarsi nello spazio campionario. Questi problemi presentano due difficoltà principali:\n\nTrasformare la descrizione verbale del problema in una formulazione matematica chiara, suddividendo gli eventi possibili nello spazio campionario in base alle condizioni di successo e insuccesso definite dal problema.\nContare il numero di successi e il numero totale di eventi.\n\nPer risolvere questi problemi, dobbiamo utilizzare tecniche del calcolo combinatorio, come le permutazioni e le combinazioni, che ci permettono di contare in modo preciso il numero di possibilità.\nConsideriamo un esempio semplice e intuitivo per chiarire il concetto. Supponiamo di avere una scatola con 10 palline numerate da 1 a 10. Vogliamo calcolare la probabilità di estrarre una pallina con un numero pari.\n\nDefinizione degli eventi: In questo caso, l’evento di “successo” è l’estrazione di una pallina con un numero pari.\n\nEventi di successo: {2, 4, 6, 8, 10}\nEventi totali: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n\nConteggio delle possibilità:\n\nNumero di eventi di successo: 5\nNumero totale di eventi: 10\n\nCalcolo della probabilità: \\[\nP(\\text{numero pari}) = \\frac{\\text{numero di eventi di successo}}{\\text{numero totale di eventi}} = \\frac{5}{10} = 0.5.\n\\]\n\nPer problemi più complessi, come il calcolo della probabilità di ottenere una determinata combinazione di carte da un mazzo o di formare un particolare gruppo di persone da una popolazione più grande, utilizziamo strumenti del calcolo combinatorio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "href": "chapters/probability/03_prob_on_general_spaces.html#il-problema-dei-fratelli-bernoulli",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.6 Il Problema dei Fratelli Bernoulli",
    "text": "27.6 Il Problema dei Fratelli Bernoulli\nLa soluzione dei problemi di probabilità non è sempre semplice e nella storia della matematica ci sono molti esempi di celebri matematici che hanno commesso errori. Uno di questi aneddoti riguarda Jakob Bernoulli, uno dei pionieri della teoria della probabilità.\nJakob Bernoulli si interessò al calcolo delle probabilità mentre cercava di formalizzare le leggi del caso nel suo libro “Ars Conjectandi”, pubblicato postumo nel 1713. Uno dei problemi che affrontò riguardava il calcolo della probabilità di ottenere almeno una testa in 8 lanci di una moneta equa. Nonostante il suo approccio iniziale fosse corretto, Bernoulli commise un errore nel calcolo combinatorio durante il processo.\nPer risolvere il problema di calcolare la probabilità di ottenere almeno una testa in 8 lanci, bisogna considerare la probabilità complementare, ovvero la probabilità di non ottenere alcuna testa (ottenere solo croci) in 8 lanci, e poi sottrarla da 1:\n\nCalcolo della probabilità complementare: La probabilità di ottenere solo croci in un singolo lancio è \\(\\frac{1}{2}\\). La probabilità di ottenere solo croci in 8 lanci consecutivi è: \\[\n\\left(\\frac{1}{2}\\right)^8 = \\frac{1}{256}.\n\\]\nCalcolo della probabilità di ottenere almeno una testa: \\[\nP(\\text{almeno una testa}) = 1 - P(\\text{nessuna testa}) = 1 - \\frac{1}{256} = \\frac{255}{256}.\n\\]\n\nJakob Bernoulli commise un errore nel calcolo combinatorio che lo portò a una soluzione errata. Egli sottostimò la probabilità di ottenere almeno una testa, probabilmente a causa di un errore nel conteggio delle possibili combinazioni di successi e insuccessi.\nQuesto errore fu successivamente corretto da altri matematici, tra cui suo nipote Daniel Bernoulli, che dimostrarono il metodo corretto per risolvere tali problemi utilizzando il calcolo combinatorio in modo appropriato.\nLa storia del calcolo combinatorio e della probabilità è ricca di aneddoti, come quello di Jakob Bernoulli, che mettono in luce quanto i problemi di probabilità possano essere estremamente controintuitivi, persino per i grandi matematici. Oggi, grazie al lavoro e alle correzioni apportate dai matematici del passato, siamo in grado di risolvere molti di questi problemi con maggiore facilità. La teoria della probabilità, come molte altre discipline scientifiche, è il risultato di un lungo processo di sviluppo e comprensione, che ha richiesto tempo e sforzi considerevoli.\nUna delle sfide della probabilità è che spesso i problemi non si prestano a soluzioni immediate o intuitive. Tuttavia, esistono due approcci fondamentali per affrontarli. Il primo consiste nell’applicare i teoremi della teoria della probabilità, un metodo che, come abbiamo visto, può risultare controintuitivo. Il secondo approccio è quello della simulazione Monte Carlo, che consente di ottenere una soluzione approssimata, ma molto vicina al valore reale, seguendo una procedura più intuitiva. Il nome di questo metodo deriva dal famoso Casinò di Monte Carlo a Monaco, ma possiamo semplicemente riferirci ad esso come metodo di simulazione.\nLa simulazione Monte Carlo è una classe generale di metodi stocastici, in contrasto con i metodi deterministici, utilizzati per risolvere approssimativamente problemi analitici attraverso la generazione casuale delle quantità di interesse. Tra i metodi comunemente utilizzati troviamo il campionamento con reinserimento, in cui la stessa unità può essere selezionata più volte, e il campionamento senza reinserimento, in cui ogni unità può essere selezionata una sola volta. Questi strumenti offrono un potente mezzo per affrontare problemi complessi in modo pratico e accessibile.\n\nEsempio 27.1 Consideriamo il seguente esercizio che presenta un “classico” problema di calcolo delle probabilità.\n“Un’urna contiene 10 palline rosse, 10 palline blu e 20 palline verdi. Se si estraggono 5 palline a caso senza reinserimento, qual è la probabilità che venga selezionata almeno una pallina di ciascun colore?”\nLa soluzione al problema consiste nel contare il numero di modi in cui possono verificarsi gli eventi incompatibili con la condizione richiesta, dividere per il numero totale di modi in cui 5 palline possono essere estratte da un’urna con 40 palline, e sottrarre tale risultato da 1.\nIniziamo dal denominatore (“in quanti modi possono essere estratte 5 palline da un’urna che ne contiene 40”). La soluzione è data dal coefficiente binomiale: \\(\\binom{40}{5}\\).\nDobbiamo poi enumerare tutti i casi incompatibili con la condizione espressa dal problema; al numeratore avremo quindi: (modi di ottenere nessuna pallina rossa) + (modi di ottenere nessuna pallina blu) + (modi di ottenere nessuna pallina verde) - (modi di ottenere nessuna pallina rossa o blu) - (modi di ottenere nessuna pallina rossa o verde) - (modi di ottenere nessuna pallina blu o verde).\nLa soluzione è dunque:\n\\[\nP(\\text{almeno una rossa, blu e verde}) = \\frac{\n\\binom{30}{5} + \\binom{30}{5} + \\binom{20}{5} - \\binom{20}{5} - \\binom{10}{5} - \\binom{10}{5}\n}{\\binom{40}{5}}.\n\\]\nSvolgiamo i calcoli usando Python.\n\n# Funzione per calcolare il coefficiente binomiale\ndef choose(n, k):\n    return math.comb(n, k)\n\n\n# Calcoli\nno_red = choose(30, 5)\nno_blue = choose(30, 5)\nno_green = choose(20, 5)\n\n# Modi per estrarre 5 palline senza ottenere due colori specifici\nno_red_blue = choose(20, 5)\nno_red_green = choose(10, 5)\nno_blue_green = choose(10, 5)\n\n# Modi totali per estrarre 5 palline in generale\ntotal_ways = choose(40, 5)\n\n# Probabilità di estrarre almeno 1 pallina di ciascun colore\nprob_real = (\n    1\n    - (no_red + no_blue + no_green - no_red_blue - no_red_green - no_blue_green)\n    / total_ways\n)\nprob_real\n\n0.567622278148594\n\n\nLo stesso risultato si ottiene con una simulazione.\n\nrandom.seed(12345)\n\n# Creare un'urna con le palline\nurn = [\"red\"] * 10 + [\"blue\"] * 10 + [\"green\"] * 20\n\n# Numero di simulazioni\nsimulations = 100000\n\ncount = 0\nfor _ in range(simulations):\n    # Estrarre 5 palline dall'urna\n    draw = random.sample(urn, 5)\n\n    # Verificare se c'è almeno una pallina di ogni colore (red, blue, green)\n    if \"red\" in draw and \"blue\" in draw and \"green\" in draw:\n        count += 1\n\n# Calcolare la probabilità simulata\nprob_simulated = count / simulations\nprob_simulated\n\n0.56767\n\n\n\nIl metodo di simulazione consente di risolvere problemi che implicano il calcolo delle probabilità relative a vari eventi generati dal lancio dei dadi.\n\nEsempio 27.2 Nel caso del lancio di un dado, è facile calcolare la probabilità di ottenere un 1 o un 5. Questa probabilità è \\(\\frac{2}{6}\\). Tuttavia, quando lanciamo due dadi, la situazione si complica perché ci interessa ottenere almeno un 1 o un 5, e c’è la possibilità di ottenere entrambi. Invece di calcolare direttamente questa probabilità, possiamo considerare la probabilità di non ottenere né un 1 né un 5 e sottrarla da 1. Con 2 dadi, la probabilità di non ottenere né un 1 né un 5 è \\(\\frac{4}{6}\\) o \\(\\frac{2}{3}\\) per ogni dado. Per calcolare la probabilità congiunta, possiamo moltiplicare la probabilità per ciascun dado: \\(1 - (\\frac{2}{3} \\times \\frac{2}{3}) = 0.555\\). Questo significa che c’è il 55% di probabilità di ottenere almeno un 1 o un 5 quando si lanciano 2 dadi.\nInvece di calcolare matematicamente la probabilità di ottenere almeno un 1 o un 5, possiamo utilizzare il metodo Monte Carlo, simulando un grande numero di lanci di dadi e ottenendo la risposta attraverso un approccio di forza bruta. Ecco il procedimento generale:\n\nLancia 2 dadi per 100.000 volte (o per il numero di volte che preferisci).\nConta quante volte appare almeno un 1 o un 5 in ciascun lancio.\nDividi questo conteggio per 100.000. Questa sarà la probabilità.\n\n\n# Numero di simulazioni\nsimulations = 100_000\nsuccess_count = 0\n\n# Simulazione dei lanci\nfor _ in range(simulations):\n    # Lancia due dadi\n    dice_rolls = [random.randint(1, 6) for _ in range(2)]\n\n    # Verifica se c'è almeno un 1 o un 5\n    if 1 in dice_rolls or 5 in dice_rolls:\n        success_count += 1\n\n# Calcola la probabilità simulata\nprobability = success_count / simulations\nprint(f\"La probabilità di ottenere almeno un 1 o un 5 è: {probability:.3f}\")\n\nLa probabilità di ottenere almeno un 1 o un 5 è: 0.555\n\n\n\nUsiamo un ciclo for per simulare i lanci. In ogni iterazione, generiamo due numeri casuali tra 1 e 6, che rappresentano i risultati dei due dadi.\nControlliamo se in ciascun lancio appare almeno un 1 o un 5. Se è così, incrementiamo il contatore success_count.\nAlla fine, la probabilità viene calcolata dividendo success_count per il numero totale di simulazioni, e poi stampiamo il risultato.\n\nQuesto approccio, basato sulla simulazione, permette di ottenere un’ottima approssimazione della probabilità in modo intuitivo, senza dover ricorrere a calcoli matematici complessi.\nÈ facile cambiare la simulazione per consdierare il caso di un numero maggiore di dadi. Per esempio, per il caso del lancio di tre dadi, basta modificare il codice in modo che vengano lanciati tre dadi invece di due. Questo si ottiene cambiando range(2) in range(3) nel ciclo che genera i lanci dei dadi. Questa modifica consente di calcolare la probabilità di ottenere almeno un 1 o un 5 con tre dadi, utilizzando lo stesso approccio basato sulla simulazione.\nQuesto approccio basato sulla simulazione è anche al centro della statistica bayesiana moderna. Poiché il calcolo degli integrali complessi necessari per determinare le distribuzioni posteriori è estremamente difficile, possiamo impiegare processi di Markov Chain Monte Carlo (MCMC) per esplorare lo spazio plausibile della distribuzione posteriore, fino a raggiungere una convergenza su un valore stabile.\n\n\nEsempio 27.3 Il problema dei compleanni, generalmente attribuito a Richard von Mises, è un noto esempio controintuitivo di calcolo delle probabilità che utilizza il calcolo combinatorio, in particolare le permutazioni. Il problema chiede quanti individui sono necessari affinché la probabilità che almeno due persone abbiano lo stesso compleanno superi il 50%, assumendo che ogni giorno dell’anno sia ugualmente probabile come compleanno. Sorprendentemente, la risposta è solo 23 persone, molto meno di quanto la maggior parte delle persone immagina.\nPer risolvere il problema dei compleanni utilizzando le permutazioni, consideriamo la seguente relazione:\n\\[\n\\begin{align*}\nP(\\text{almeno due persone hanno lo stesso compleanno}) &= \\\\\n1 - P(\\text{nessuno ha lo stesso compleanno}).\n\\end{align*}\n\\]\nQuesta uguaglianza è valida perché l’evento “nessuno ha lo stesso compleanno” è il complemento dell’evento “almeno due persone hanno lo stesso compleanno”. Pertanto, dobbiamo calcolare la probabilità che nessuno abbia lo stesso compleanno.\nSia \\(k\\) il numero di persone. Per calcolare la probabilità che nessuno abbia lo stesso compleanno, dobbiamo contare il numero di modi in cui \\(k\\) persone possono avere compleanni diversi. Poiché ogni compleanno è ugualmente probabile, possiamo usare le permutazioni per contare il numero di modi in cui \\(k\\) compleanni unici possono essere disposti su 365 giorni:\n\\[\n365P_k = \\frac{365!}{(365 - k)!}.\n\\]\nDividiamo questo numero per il numero totale di elementi nello spazio campionario, che è il numero totale di modi in cui \\(k\\) compleanni possono essere disposti su 365 giorni:\n\\[\n365^k.\n\\]\nQuindi, la probabilità che nessuno abbia lo stesso compleanno è:\n\\[\nP(\\text{nessuno ha lo stesso compleanno}) = \\frac{365P_k}{365^k} = \\frac{365!}{365^k (365 - k)!}.\n\\]\nUsando questa formula, la probabilità che almeno due persone abbiano lo stesso compleanno è:\n\\[\nP(\\text{almeno due persone hanno lo stesso compleanno}) = 1 - \\frac{365!}{365^k (365 - k)!}.\n\\]\nIn sintesi, calcolando questa probabilità, si scopre che bastano solo 23 persone affinché la probabilità che almeno due di loro abbiano lo stesso compleanno superi il 50%, un risultato sorprendente rispetto all’intuizione comune.\n\ndef birthday(k):\n    logdenom = k * math.log(365) + math.lgamma(365 - k + 1) # log denominatore\n    lognumer = math.lgamma(366) # log numeratore\n    pr = 1 - np.exp(lognumer - logdenom) # trasformazione inversa\n    return pr\n\nk = np.arange(1, 51)\nbday = [birthday(i) for i in k]\n\nplt.plot(k, bday, marker=\"o\", alpha=0.5)\nplt.xlabel('Numero di persone')\nplt.ylabel('Probabilità che almeno due persone\\nabbiano lo stesso compleanno')\nplt.axhline(\n    y=0.5,\n    linestyle=\"--\",\n    color=\"gray\"\n)\nplt.xlim(0, 50)\nplt.ylim(0, 1)\nplt.title('Probabilità del Problema dei Compleanni')\nplt.show()\n\nprint(\"Probabilità per 20-25 persone:\", bday[19:25])\n\n\n\n\n\n\n\n\nProbabilità per 20-25 persone: [0.41143838358049944, 0.44368833516523465, 0.47569530766240553, 0.507297234324024, 0.5383442579144757, 0.5686997039694264]\n\n\nOsserviamo che quando il numero di persone è 23, la probabilità che almeno due persone abbiano lo stesso compleanno supera 0.5. Quando il numero di persone è più di 50, questa probabilità è quasi 1.\n\n\nEsempio 27.4 In precedenza, abbiamo derivato la soluzione analitica esatta per il problema dei compleanni, ma possiamo ottenere una soluzione approssimata in modo più intuitivo utilizzando il metodo della simulazione Monte Carlo.\nPer affrontare il problema dei compleanni, campioniamo \\(k\\) compleanni, che potrebbero non essere unici, tra i 365 giorni dell’anno e verifichiamo se i \\(k\\) compleanni campionati sono tutti diversi. Utilizziamo il campionamento con reinserimento, poiché ogni giorno dei 365 ha la stessa probabilità di essere scelto, indipendentemente dai giorni estratti in precedenza. In altre parole, il fatto che una persona sia nata in un determinato giorno dell’anno non esclude che qualcun altro possa essere nato nello stesso giorno.\nDopo aver ripetuto questa procedura di campionamento molte volte, calcoliamo la frazione di simulazioni in cui almeno due compleanni coincidono. Questa frazione serve come stima della probabilità cercata. Questa procedura di simulazione è intuitiva perché riproduce il processo di generazione dei dati descritto nel problema dei compleanni.\nPer implementare il campionamento con o senza reinserimento in Python, utilizziamo la funzione numpy.random.choice. Nel caso del campionamento con reinserimento, impostiamo l’argomento replace su True. Il campionamento senza reinserimento significa che, una volta campionato un elemento, questo non sarà disponibile per estrazioni successive.\n\nk = 23  # numero di persone\nsims = 1000  # numero di simulazioni\nevent = 0  # contatore eventi\n\nfor _ in range(sims):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event += 1\n\n# frazione di prove in cui almeno due compleanni sono uguali\nanswer = event / sims\nprint(f\"Stima della probabilità: {answer}\")\n\n# Aumentare il numero di simulazioni a un milione per maggiore accuratezza\nsims_large = 1000000\nevent_large = 0\n\nfor _ in range(sims_large):\n    days = np.random.choice(365, k, replace=True)\n    unique_days = np.unique(days)\n    if len(unique_days) &lt; k:\n        event_large += 1\n\nanswer_large = event_large / sims_large\nprint(f\"Stima con un milione di simulazioni: {answer_large}\")\n\nStima della probabilità: 0.507\nStima con un milione di simulazioni: 0.507865\n\n\nNel codice sopra, abbiamo impostato il numero di simulazioni a un milione. Osserviamo che quando il numero di persone è 23, la probabilità che almeno due persone abbiano lo stesso compleanno è superiore a 0.5. Quando il numero di persone supera 50, questa probabilità è vicina a 1.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#le-assunzioni-nella-soluzione-dei-problemi",
    "href": "chapters/probability/03_prob_on_general_spaces.html#le-assunzioni-nella-soluzione-dei-problemi",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.7 Le Assunzioni nella Soluzione dei Problemi",
    "text": "27.7 Le Assunzioni nella Soluzione dei Problemi\nNella realtà, i compleanni non seguono una distribuzione uniforme. Una soluzione migliore al problema dei compleanni sarebbe quella di estrarre i compleanni dalla distribuzione effettiva piuttosto che da una distribuzione uniforme in cui ogni giorno ha la stessa probabilità. Non esiste un metodo matematico standard per calcolare questa probabilità; l’unico modo per farlo è attraverso la simulazione.\nNegli Stati Uniti, il CDC e la Social Security Administration monitorano il numero di nascite giornaliere. Nel 2016, FiveThirtyEight ha pubblicato un articolo sulle frequenze giornaliere di nascita e ha reso disponibili i dati in un file CSV su GitHub. Utilizzando il codice fornito da Andrew Heiss, possiamo caricare quei dati e calcolare le probabilità giornaliere dei compleanni negli Stati Uniti.\n\n# Leggi i dati\nbirths_1994_1999 = pd.read_csv(\n    \"https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_1994-2003_CDC_NCHS.csv\"\n)\nbirths_1994_1999 = births_1994_1999[births_1994_1999[\"year\"] &lt; 2000]\n\nbirths_2000_2014 = pd.read_csv(\n    \"https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_2000-2014_SSA.csv\"\n)\n\n# Unisci i dataset\nbirths_combined = pd.concat([births_1994_1999, births_2000_2014])\n\n# Crea la colonna 'full_date' con un anno fittizio 2024 per mantenere la corretta relazione giorno/mese\nbirths_combined[\"full_date\"] = pd.to_datetime(\n    {\n        \"year\": 2024,\n        \"month\": births_combined[\"month\"],\n        \"day\": births_combined[\"date_of_month\"],\n    }\n)\n\n# Aggiungi la colonna 'day_of_year' per la verifica (non necessaria per la visualizzazione)\nbirths_combined[\"day_of_year\"] = births_combined[\"full_date\"].dt.dayofyear\n\n# Crea la colonna 'month_categorical' per avere il nome completo del mese\nbirths_combined[\"month_categorical\"] = births_combined[\"full_date\"].dt.month_name()\n\n# Calcola la media delle nascite per ciascun giorno del mese per ogni mese\navg_births_month_day = (\n    births_combined.groupby([\"month_categorical\", \"date_of_month\"])\n    .agg(avg_births=(\"births\", \"mean\"))\n    .reset_index()\n)\n\n# Correggi l'ordine dei mesi per l'asse Y\navg_births_month_day[\"month_categorical\"] = pd.Categorical(\n    avg_births_month_day[\"month_categorical\"],\n    categories=list(calendar.month_name)[1:],\n    ordered=True,\n)\n\n# Visualizza i dati con un heatmap\nplt.figure(figsize=(12, 10))\navg_births_pivot = avg_births_month_day.pivot(\n    index=\"month_categorical\", columns=\"date_of_month\", values=\"avg_births\"\n)\n\nsns.heatmap(\n    avg_births_pivot,\n    cmap=\"rocket\",\n    cbar_kws={\"orientation\": \"horizontal\", \"shrink\": 0.5, \"label\": \"Average births\"},\n)\n\n# Configura l'asse delle y per mostrare i mesi in ordine corretto\nplt.yticks(rotation=0)\nplt.title(\"Average births per day\", fontsize=16)\nplt.suptitle(\"1994–2014\", fontsize=12)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nSi noti che i dati rivelano alcuni pattern evidenti:\n\nNessuno sembra voler avere figli durante le festività di Natale o Capodanno. Il giorno di Natale, la vigilia di Natale e il giorno di Capodanno presentano il numero medio di nascite più basso.\nAnche la vigilia di Capodanno, Halloween, il 4 luglio, il 1° aprile e l’intera settimana del Ringraziamento mostrano medie particolarmente basse.\nIl 13 di ogni mese registra leggermente meno nascite rispetto alla media—la colonna relativa al giorno 13 è particolarmente evidente in questo contesto.\nI giorni con il numero medio di nascite più alto si trovano a metà settembre, dal 9 al 20, ad eccezione dell’11 settembre.\n\nImmagino che in Italia i pattern siano, almeno in parte, diversi.\nNon è l’obiettivo qui riformulare la soluzione del problema dei compleanni utilizzando la distribuzione effettiva delle nascite piuttosto che quella uniforme, ma piuttosto sottolineare che le procedure di risoluzione dei problemi si basano su assunzioni—nel caso del problema dei compleanni, l’assunzione che la distribuzione dei compleanni sia uniforme, quando in realtà non lo è. Le soluzioni che otteniamo nei problemi probabilistici descrivono le regolarità osservabili nel mondo empirico tanto meglio quanto più sono ragionevoli le assunzioni formulate.\nIn tutti i modelli probabilistici (e quindi, in tutti i modelli scientifici, dato che esistono solo modelli probabilistici) è fondamentale prestare particolare attenzione alla plausibilità delle assunzioni su cui tali modelli si basano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/03_prob_on_general_spaces.html#commenti-e-considerazioni-finali",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.8 Commenti e considerazioni finali",
    "text": "27.8 Commenti e considerazioni finali\nLa teoria delle probabilità è un pilastro fondamentale della statistica, con applicazioni pratiche in numerosi campi, tra cui la psicologia. Comprendere le probabilità ci consente di prendere decisioni informate in situazioni di incertezza e di formulare previsioni affidabili. Una solida conoscenza delle basi della probabilità ci permette di affrontare una vasta gamma di problemi e di fare scelte ponderate basate sulla probabilità dei vari esiti possibili. Tuttavia, è importante ricordare che i modelli probabilistici sono solo approssimazioni della realtà e possono essere influenzati da semplificazioni o dalle limitazioni dei dati disponibili. Pertanto, è fondamentale interpretare i risultati con cautela e avere piena consapevolezza delle assunzioni che sottendono le analisi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#esercizi",
    "href": "chapters/probability/03_prob_on_general_spaces.html#esercizi",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.9 Esercizi",
    "text": "27.9 Esercizi\n\nEsercizio 27.1 Supponiamo di dover formare una commissione di 5 psicologi su un gruppo di 20 persone (10 psicologi clinici e 10 psicologi del lavoro). Qual è la probabilità che almeno 2 psicologi clinici siano nella commissione? Risolvi il problema usando una simulazione Monte Carlo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/03_prob_on_general_spaces.html#informazioni-sullambiente-di-sviluppo",
    "title": "27  Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra",
    "section": "27.10 Informazioni sull’Ambiente di Sviluppo",
    "text": "27.10 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\narviz     : 0.18.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nscipy     : 1.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Fondamenti della probabilità: assiomi di Kolmogorov e sigma-algebra</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html",
    "href": "chapters/probability/04_conditional_prob.html",
    "title": "28  Probabilità condizionata",
    "section": "",
    "text": "Introduzione\nLa probabilità è un linguaggio che ci consente di esprimere il nostro grado di credenza o incertezza riguardo all’occorrenza di eventi futuri. Questo concetto è strettamente legato all’idea di probabilità condizionata, che è fondamentale nella teoria della probabilità.\nLa probabilità condizionata si riferisce al calcolo della probabilità di un evento, tenendo conto che un altro evento si è già verificato. Questo concetto è cruciale perché riflette come aggiorniamo le nostre credenze alla luce di nuove evidenze o informazioni. Per esempio, immaginiamo di voler stimare la probabilità di pioggia per domani. La nostra stima iniziale cambia se oggi osserviamo un cielo nuvoloso. Il fatto che oggi sia nuvoloso “condiziona” la nostra valutazione della probabilità di pioggia per domani.\nQuesto processo di aggiornamento delle nostre credenze in base a nuove osservazioni è continuo. Una nuova evidenza coerente con una credenza esistente potrebbe rafforzarla, mentre un’osservazione inaspettata potrebbe metterla in discussione. La probabilità condizionata non è solo un concetto teorico, ma ha applicazioni pratiche sia nella vita quotidiana che in ambito scientifico. In realtà, si potrebbe argomentare che tutte le probabilità sono in qualche modo condizionate da un certo contesto o da informazioni preesistenti, anche se non sempre lo specifichiamo esplicitamente.\nIn sintesi, la probabilità condizionata ci fornisce un framework per comprendere e quantificare come le nostre credenze dovrebbero evolversi man mano che acquisiamo nuove informazioni, rendendo il concetto di probabilità uno strumento dinamico e potente per gestire l’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "href": "chapters/probability/04_conditional_prob.html#indipendenza-stocastica",
    "title": "28  Probabilità condizionata",
    "section": "28.1 Indipendenza Stocastica",
    "text": "28.1 Indipendenza Stocastica\nNel contesto della probabilità condizionata, il concetto di indipendenza gioca un ruolo fondamentale. Questa caratteristica permette di semplificare notevolmente il calcolo delle probabilità in molti problemi, evidenziando come la conoscenza di un evento non fornisca alcuna informazione aggiuntiva sull’altro.\n\n28.1.1 Indipendenza di Due Eventi\nDue eventi \\(A\\) e \\(B\\) sono detti indipendenti se il verificarsi di uno non influenza la probabilità di verificarsi dell’altro. Formalmente, questa condizione è espressa come:\n\\[\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B),\\]\ndove \\(\\mathbb{P}(A \\cap B)\\) rappresenta la probabilità che entrambi gli eventi \\(A\\) e \\(B\\) si verifichino simultaneamente.\nSe questa condizione è soddisfatta, scriviamo \\(A \\text{ ⫫ } B\\), il che significa “A è indipendente da B”.\n\n\n28.1.2 Indipendenza di un Insieme di Eventi\nL’indipendenza stocastica è un concetto fondamentale nell’applicazione della probabilità in campo statistico. Un insieme di eventi \\(\\{ A_i : i \\in I \\}\\) è detto indipendente se per ogni sottoinsieme finito \\(J\\) di \\(I\\), la probabilità dell’intersezione degli eventi nel sottoinsieme \\(J\\) è uguale al prodotto delle loro singole probabilità. Formalmente:\n\\[\\mathbb{P} \\left( \\cap_{i \\in J} A_i \\right) = \\prod_{i \\in J} \\mathbb{P}(A_i).\\]\nQuesto significa che ogni combinazione finita di eventi nell’insieme è indipendente.\nL’indipendenza può essere assunta o derivata a seconda del contesto. In alcuni modelli o situazioni, assumiamo che certi eventi siano indipendenti perché questa assunzione semplifica i calcoli o riflette una conoscenza previa. In altri casi, l’indipendenza può essere derivata dai dati o da altre proprietà del modello.\n\n\n28.1.3 Eventi Disgiunti e Indipendenza\nEventi disgiunti (o mutuamente esclusivi) sono quelli che non possono verificarsi simultaneamente, cioè \\(\\mathbb{P}(A \\cap B) = 0\\). Se due eventi disgiunti hanno una probabilità positiva di verificarsi, allora non possono essere indipendenti. Questo perché per eventi disgiunti con \\(\\mathbb{P}(A) &gt; 0\\) e \\(\\mathbb{P}(B) &gt; 0\\), l’equazione di indipendenza \\(\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\\) non può essere soddisfatta, dato che \\(\\mathbb{P}(A \\cap B) = 0\\) e \\(\\mathbb{P}(A) \\mathbb{P}(B) &gt; 0\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#sec-v",
    "href": "chapters/probability/04_conditional_prob.html#sec-v",
    "title": "28  Probabilità condizionata",
    "section": "28.2 Probabilità condizionata su altri eventi",
    "text": "28.2 Probabilità condizionata su altri eventi\nLa probabilità di un evento è intrinsecamente condizionata dal nostro stato di informazione. In presenza di un determinato insieme di informazioni, attribuiamo a un evento una probabilità specifica di occorrenza. Tuttavia, qualora il nostro stato informativo subisca una modifica, anche la probabilità associata all’evento verrà corrispondentemente aggiornata.\nIn realtà, tutte le probabilità possono essere intese come probabilità condizionate, anche quando la variabile o l’evento condizionante non è esplicitamente specificato. Ciò implica che le probabilità sono sempre contestualizzate e dipendono dal set informativo disponibile in un dato scenario.\nQuesto quadro concettuale ci induce a considerare le probabilità come una ‘misura di plausibilità’ che riflette la nostra conoscenza corrente del sistema o del fenomeno sotto indagine. A seguito dell’acquisizione di nuove informazioni o di cambiamenti nel contesto, la nostra misura di plausibilità, e quindi la probabilità attribuita agli eventi, può essere rivista.\n\nTeorema 28.1 Siano \\(A\\) e \\(B\\) due eventi definiti su uno spazio campionario \\(S\\). Supponendo che l’evento \\(B\\) si verifichi, la probabilità condizionata di \\(A\\) dato \\(B\\) è data da\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{per}\\, P(B) &gt; 0,\n\\tag{28.1}\\]\ndove \\(P(A \\cap B)\\) rappresenta la probabilità congiunta dei due eventi, ovvero la probabilità che entrambi si verifichino.\n\nNell’Equazione 28.1, \\(P(A \\cap B)\\) è la probabilità congiunta che entrambi gli eventi si verifichino, mentre \\(P(B)\\) è la probabilità marginale dell’evento \\(B\\). Riorganizzando i termini, otteniamo la regola della moltiplicazione:\n\\[\nP(A \\cap B) = P(A \\mid B)P(B) = P(B \\mid A)P(A).\n\\]\nUtilizzando questa regola, possiamo derivare una forma alternativa della legge della probabilità totale:\n\\[\nP(A) = P(A \\mid B)P(B) + P(A \\mid B^c)P(B^c).\n\\]\nDove \\(B^c\\) rappresenta il complemento dell’evento \\(B\\).\nÈ importante notare che \\(P(A \\mid B)\\) non è definita se \\(P(B) = 0\\).\nLa probabilità condizionata può essere interpretata come una ricalibrazione dello spazio campionario da \\(S\\) a \\(B\\). Per spazi campionari discreti, la probabilità condizionata è espressa come\n\\[\nP(A \\mid B) = \\frac{| A \\cap B |}{| B |}.\n\\]\n\nEsempio 28.1 Lanciamo due dadi equilibrati e vogliamo calcolare la probabilità che la somma dei punteggi ottenuti sia minore di 8.\nInizialmente, quando non abbiamo ulteriori informazioni, possiamo calcolare la probabilità in modo tradizionale. Ci sono 21 risultati possibili con somma minore di 8. Poiché ci sono 36 possibili combinazioni di lancio dei due dadi, la probabilità di ottenere una somma minore di 8 è 21/36, che equivale a circa 0.58.\nSupponiamo ora di sapere che la somma del lancio di due dadi ha prodotto un risultato dispari. In questo caso, ci sono solo 18 possibili combinazioni di lancio dei due dadi (dato che abbiamo escluso i risultati pari). Tra essi, vi sono 12 risultati che soddisfano la condizione per cui la somma è minore di 8. Quindi, la probabilità di ottenere una somma minore di 8 cambia da circa 0.58 a 12/18, ovvero 0.67 quando consideriamo l’informazione aggiuntiva del risultato dispari.\nSvolgiamo il problema in Python.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nsample\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (2, 6),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (4, 6),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\n\nevent = [roll for roll in sample if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample)}\")\n\n21 / 36\n\n\n\nsample_odd = [roll for roll in sample if (sum(roll) % 2) != 0]\nsample_odd\n\n[(1, 2),\n (1, 4),\n (1, 6),\n (2, 1),\n (2, 3),\n (2, 5),\n (3, 2),\n (3, 4),\n (3, 6),\n (4, 1),\n (4, 3),\n (4, 5),\n (5, 2),\n (5, 4),\n (5, 6),\n (6, 1),\n (6, 3),\n (6, 5)]\n\n\n\nevent = [roll for roll in sample_odd if sum(roll) &lt; 8]\nprint(f\"{len(event)} / {len(sample_odd)}\")\n\n12 / 18\n\n\nSe applichiamo l’Equazione 28.1, abbiamo: \\(P(A \\cap B)\\) = 12/36, \\(P(B)\\) = 18/36 e\n\\[\nP(A \\mid B) = \\frac{12}{18}.\n\\]\nQuesto esempio illustra come la probabilità di un evento possa variare in base alle informazioni aggiuntive di cui disponiamo. Nel secondo caso, avendo l’informazione che la somma è dispari, la probabilità di ottenere una somma minore di 8 aumenta notevolmente rispetto al caso iniziale in cui non avevamo questa informazione.\n\n\nEsempio 28.2 Consideriamo uno screening per la diagnosi precoce del tumore mammario utilizzando un test con determinate caratteristiche:\n\nSensibilità del test: 90%. Questo significa che il test classifica correttamente come positivo il 90% delle donne colpite dal cancro al seno.\nSpecificità del test: 90%. Ciò indica che il test classifica correttamente come negativo il 90% delle donne che non hanno il cancro al seno.\nPrevalenza del cancro al seno nella popolazione sottoposta allo screening: 1% (0.01). Questo è il 1% delle donne che ha effettivamente il cancro al seno, mentre il restante 99% (0.99) non ne è affetto.\n\nOra cerchiamo di rispondere alle seguenti domande:\n\nQual è la probabilità che una donna scelta a caso ottenga una mammografia positiva? Poiché il 1% delle donne ha il cancro al seno, la probabilità di ottenere una mammografia positiva (test positivo) è pari alla sensibilità del test, ovvero 0.90 (cioè 90%).\nSe la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?\n\nPer risolvere questo problema, consideriamo un campione di 1000 donne sottoposte al test di screening per il tumore al seno. Di queste 1000 donne:\n\n10 donne (1% del campione) hanno effettivamente il cancro al seno. Per queste 10 donne con il cancro, il test darà un risultato positivo (vera positività) in 9 casi (90%).\nPer le restanti 990 donne (99% del campione) che non hanno il cancro al seno, il test darà un risultato positivo (falsa positività) in 99 casi (10%).\n\nQuesta situazione può essere rappresentata graficamente nel seguente modo:\n\n\n\n\n\n\nFigura 28.1: Esiti della mammografia per 1000 donne.\n\n\n\nCombinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non lo hanno, per un totale di 108 risultati positivi su 1000. Pertanto, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 0.108.\nTuttavia, tra le 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno effettivamente il cancro al seno. Quindi, la probabilità di avere il cancro al seno, dato un risultato positivo al test, è pari a \\(\\frac{9}{108}\\) = 0.083, corrispondente all’8.3%.\nIn questo esempio, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, poiché calcoliamo semplicemente la proporzione di risultati positivi nel campione totale. D’altra parte, la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata, poiché calcoliamo la proporzione delle donne con il cancro al seno tra quelle che hanno ottenuto un risultato positivo al test.\nQuesto esempio illustra come la conoscenza di ulteriori informazioni (il risultato positivo al test) può influenzare la probabilità di un evento (avere il cancro al seno), mostrando chiaramente la differenza tra probabilità condizionate e non condizionate.\n\n\nEsempio 28.3 Il problema di Monty Hall è diventato famoso grazie alla rubrica tenuta da Marilyn vos Savant nella rivista Parade, che rispose alla seguente lettera, pubblicata il 9 settembre 1990:\n\n“Supponiamo che tu sia in un quiz televisivo, e ti venga data la scelta tra tre porte. Dietro una delle porte c’è un’auto, dietro le altre due ci sono delle capre. Tu scegli una porta, diciamo la numero 1, e il conduttore, che sa cosa c’è dietro ogni porta, apre un’altra porta, diciamo la numero 3, che contiene una capra. Il conduttore ti chiede quindi se vuoi cambiare la tua scelta e passare alla porta numero 2. È vantaggioso cambiare la scelta?” Craig. F. Whitaker, Columbia, MD\n\nLa situazione descritta nella lettera è simile a quella che i concorrenti affrontavano nel quiz televisivo degli anni ’70 Let’s Make a Deal, condotto da Monty Hall e Carol Merrill. Marilyn rispose che il concorrente dovrebbe cambiare la scelta, poiché se l’auto è dietro una delle due porte non scelte (il che è due volte più probabile rispetto alla porta inizialmente scelta), il concorrente vince cambiando porta. Tuttavia, la sua risposta suscitò una reazione a catena, con molte lettere, persino da parte di matematici, che affermavano che avesse torto. Questo episodio diede origine al problema di Monty Hall e innescò migliaia di ore di dibattiti.\nQuesto incidente sottolinea un aspetto fondamentale della probabilità: spesso, l’intuizione porta a conclusioni completamente errate. Fino a quando non si affinano le capacità nel trattare problemi di probabilità, un approccio rigoroso e sistematico è utile per evitare errori.\nChiarire il Problema\nLa lettera originale di Craig Whitaker è un po’ vaga, quindi dobbiamo fare delle ipotesi per poter modellare formalmente il gioco. Supponiamo che:\n\nL’auto sia nascosta in modo casuale ed equiprobabile dietro una delle tre porte.\nIl giocatore scelga una delle tre porte in modo casuale, indipendentemente dalla posizione dell’auto.\nDopo che il giocatore ha scelto una porta, il conduttore apre un’altra porta, che contiene una capra, e offre al giocatore la possibilità di mantenere la scelta o cambiarla.\nSe il conduttore ha la possibilità di scegliere quale porta aprire (ossia, se ci sono due capre disponibili), sceglie casualmente quale porta aprire.\n\nCon queste assunzioni, possiamo affrontare la domanda: “Qual è la probabilità che un giocatore che cambia porta vinca l’auto?”\nIl Metodo in Quattro Passi\nOgni problema di probabilità riguarda un esperimento o un processo casuale. In questi casi, il problema può essere suddiviso in quattro fasi distinte.\nPasso 1: Trovare lo Spazio Campionario\nIl primo passo è identificare tutti i possibili esiti dell’esperimento. Nel problema di Monty Hall, ci sono tre quantità determinate casualmente:\n\nLa porta che nasconde l’auto.\nLa porta scelta inizialmente dal giocatore.\nLa porta che il conduttore apre per rivelare una capra.\n\nUn diagramma ad albero può aiutarci a visualizzare il problema, dato che il numero di esiti non è troppo grande e la struttura è semplice. Il primo evento casuale è la posizione dell’auto, che rappresentiamo con tre rami in un albero. Ogni ramo corrisponde a una delle porte. La seconda quantità casuale è la porta scelta dal giocatore, rappresentata nel secondo livello dell’albero, e la terza quantità casuale è la porta che il conduttore apre, mostrata nel terzo livello.\nEcco un esempio di diagramma ad albero in Python che rappresenta questa situazione:\n\n\n\n\n\n\nFigura 28.2: Il diagramma ad albero per il Problema di Monty Hall mostra le probabilità associate a ogni possibile esito. I pesi sugli archi rappresentano la probabilità di seguire quel particolare percorso, dato che ci troviamo nel nodo padre. Ad esempio, se l’auto si trova dietro la porta A, la probabilità che il giocatore scelga inizialmente la porta B è pari a 1/3. La colonna più a destra del diagramma mostra la probabilità di ciascun esito finale. Ogni probabilità di esito è calcolata moltiplicando le probabilità lungo il percorso che parte dalla radice (auto dietro una certa porta) e termina alla foglia (esito finale) (Figura tratta da Lehman, Leighton e Meyer, 2018).\n\n\n\nNel diagramma ad albero, i rami rappresentano le possibili combinazioni delle porte, e le foglie rappresentano gli esiti dell’esperimento. Ogni foglia dell’albero rappresenta un esito dello spazio campionario, che nel nostro caso è composto da 12 esiti. Per esempio, (Car A, Pick B, Reveal C).\nPasso 2: Definire gli Eventi di Interesse\nL’evento di interesse è “il giocatore vince cambiando porta”. Questo significa che, se la porta scelta dal giocatore inizialmente non contiene l’auto, e il giocatore decide di cambiare porta, allora vincerà. Gli esiti favorevoli sono quelli in cui la porta inizialmente scelta dal giocatore non nasconde l’auto, e cambiando porta il giocatore sceglie correttamente la porta che nasconde l’auto.\nGli esiti che soddisfano questa condizione sono:\n\n(Car A, Pick B, Reveal C)\n(Car A, Pick C, Reveal B)\n(Car B, Pick A, Reveal C)\n(Car B, Pick C, Reveal A)\n(Car C, Pick A, Reveal B)\n(Car C, Pick B, Reveal A)\n\nQuesti esiti sono 6 in totale.\nPasso 3: Calcolare le Probabilità degli Esiti\nOgni esito ha una certa probabilità di verificarsi. Il modo per determinare la probabilità di ciascun esito è moltiplicare le probabilità lungo il percorso nell’albero.\nEsempio di calcolo per l’esito (Car A, Pick B, Reveal C):\n\nLa probabilità che l’auto sia dietro la porta A è \\(\\frac{1}{3}\\).\nLa probabilità che il giocatore scelga la porta B è \\(\\frac{1}{3}\\).\nLa probabilità che il conduttore apra la porta C (che contiene una capra) è \\(1\\) (poiché il conduttore deve aprire una porta con una capra, e la porta C è l’unica possibile).\n\nLa probabilità totale per questo esito è:\n\\[\nP(\\text{Car A, Pick B, Reveal C}) = \\frac{1}{3} \\times \\frac{1}{3} \\times 1 = \\frac{1}{9}.\n\\]\nProcedendo in modo simile per tutti gli altri esiti, otteniamo le probabilità per tutti i 12 esiti.\nPasso 4: Calcolare le Probabilità degli Eventi\nLa probabilità di vincere cambiando porta è data dalla somma delle probabilità degli esiti favorevoli elencati sopra.\n\\[\n\\begin{aligned}\nP&(\\text{vincere cambiando porta}) = \\notag \\\\\n&\\quad P(\\text{Car A, Pick B, Reveal C}) + P(\\text{Car A, Pick C, Reveal B}) + \\notag\\\\  \n&\\quad P(\\text{Car B, Pick A, Reveal C}) + \\dots \\notag\n\\end{aligned}\n\\]\n\\[\n= \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} + \\frac{1}{9} = \\frac{6}{9} = \\frac{2}{3}.\n\\]\nLa probabilità di vincere mantenendo la scelta originale è semplicemente il complemento:\n\\[\nP(\\text{vincere mantenendo la scelta}) = 1 - P(\\text{vincere cambiando porta}) = 1 - \\frac{2}{3} = \\frac{1}{3}.\n\\]\nLa conclusione è che il giocatore ha una probabilità di vincere pari a \\(\\frac{2}{3}\\) se cambia porta, contro una probabilità di \\(\\frac{1}{3}\\) se mantiene la sua scelta iniziale. Cambiare porta è quindi la strategia vincente. Questo risultato controintuitivo è il motivo per cui il problema di Monty Hall ha causato tanta confusione inizialmente.\nIl problema di Monty Hall è un classico esempio di probabilità condizionata perché la probabilità di vincere l’auto dipende da informazioni aggiuntive ottenute durante il gioco, cioè la porta che il conduttore apre. Inizialmente, la probabilità di trovare l’auto dietro la porta scelta dal giocatore è \\(\\frac{1}{3}\\), mentre la probabilità che l’auto sia dietro una delle altre due porte è \\(\\frac{2}{3}\\).\nQuando il conduttore apre una porta mostrando una capra, fornisce nuove informazioni che cambiano le probabilità. Questa nuova informazione condiziona la probabilità che l’auto sia dietro la porta non scelta dal giocatore, facendo sì che la probabilità di vincere cambiando porta diventi \\(\\frac{2}{3}\\). Quindi, il problema di Monty Hall è un esempio di probabilità condizionata perché l’aggiornamento delle probabilità dipende da un evento intermedio (la scelta della porta aperta dal conduttore).\n\n\nEsempio 28.4 Per confermare il risultato inaspettato del Problema di Monty Hall, è possibile eseguire una simulazione. In questa simulazione, consideriamo due scenari: uno in cui il concorrente mantiene la sua scelta iniziale e un altro in cui cambia la sua scelta dopo che Monty Hall ha svelato una capra. Ripetendo questa simulazione migliaia di volte, possiamo confrontare i risultati empirici e confermare come effettivamente il cambiamento di scelta aumenti le probabilità del concorrente di vincere l’automobile.\nDi seguito è riportato lo script di una simulazione progettata per illustrare il paradosso di Monty Hall.\n\nporte = [\n    \"capra1\",\n    \"capra2\",\n    \"macchina\",\n]  # definisco il gioco, scelgo una porta a caso per n volte\ncounter = 0\ncontatore_cambio = 0\nn = 10000\nporta_vincente = \"macchina\"\nfor i in range(n):\n    scelta_casuale = random.choice(porte)\n    porte_rimaste = [x for x in porte if x != scelta_casuale]\n    porta_rivelata = random.choice([x for x in porte_rimaste if x != porta_vincente])\n    porta_alternativa = [\n        x for x in porte if x != scelta_casuale and x != porta_rivelata\n    ]\n    if \"macchina\" in porta_alternativa:\n        contatore_cambio += 1\n    if scelta_casuale == \"macchina\":\n        counter += 1\n\nprint(counter / n)  # quante volte vinco non cambiando porta\nprint(contatore_cambio / n)  # quante volte vinco cambiando porta\n\n0.3322\n0.6678\n\n\nQuesto script Python è stato creato da un gruppo di studenti di Psicometria nell’AA 2023-2023. La simulazione mostra che, effettivamente, la probabilità di vincere la macchina aumenta quando il concorrente sceglie di cambiare porta.\n\n\n28.2.1 Il paradosso di Simpson\nNel campo della probabilità condizionata, uno dei fenomeni più interessanti e, nel contempo, più controintuitivi, è rappresentato dal paradosso di Simpson. Il paradosso di Simpson è un fenomeno statistico in cui una tendenza che appare in diversi gruppi separati di dati scompare o si inverte quando i dati vengono combinati. Questo paradosso mette in luce l’importanza di considerare le variabili confondenti e di analizzare i dati con attenzione per evitare conclusioni errate.\n\nEsempio 28.5 Due psicoterapeuti, Rossi e Bianchi, praticano due tipi di terapie: terapia per disturbi d’ansia e coaching per migliorare le prestazioni lavorative. Ogni terapia può avere un esito positivo o negativo.\nI rispettivi bilanci dei due terapeuti sono riportati nelle seguenti tabelle.\nRossi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d’ansia\n70\n20\n\n\nCoaching lavorativo\n10\n0\n\n\nTotale\n80\n20\n\n\n\nBianchi\n\n\n\nTipo di terapia\nSuccesso\nFallimento\n\n\n\n\nDisturbi d’ansia\n2\n8\n\n\nCoaching lavorativo\n81\n9\n\n\nTotale\n83\n17\n\n\n\nRossi ha un tasso di successo superiore a Bianchi nella terapia per i disturbi d’ansia: 70 su 90 rispetto a 2 su 10. Anche nel coaching lavorativo, Rossi ha un tasso di successo superiore: 10 su 10 rispetto a 81 su 90. Tuttavia, se aggregiamo i dati dei due tipi di terapia per confrontare i tassi di successo globali, Rossi è efficace in 80 su 100 terapie, mentre Bianchi in 83 su 100: il tasso di successo globale di Bianchi risulta superiore!\nQuesto fenomeno è un esempio del paradosso di Simpson, dove una tendenza osservata in diversi gruppi si inverte quando i gruppi sono combinati.\nPer essere più precisi, possiamo calcolare i tassi di successo per ciascun terapeuta e per ciascun tipo di terapia, oltre al tasso di successo globale.\n\nRossi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{70}{70+20} = \\frac{70}{90} \\approx 0.778\\)\nTasso di successo in coaching lavorativo: \\(\\frac{10}{10+0} = \\frac{10}{10} = 1\\)\nTasso di successo globale: \\(\\frac{70+10}{70+20+10+0} = \\frac{80}{100} = 0.8\\)\n\nBianchi\n\nTasso di successo in terapia per disturbi d’ansia: \\(\\frac{2}{2+8} = \\frac{2}{10} = 0.2\\)\nTasso di successo in coaching lavorativo: \\(\\frac{81}{81+9} = \\frac{81}{90} \\approx 0.9\\)\nTasso di successo globale: \\(\\frac{2+81}{2+8+81+9} = \\frac{83}{100} = 0.83\\)\n\n\nQuello che sta succedendo è che Rossi, presumibilmente a causa della sua reputazione come terapeuta più esperto, sta effettuando un numero maggiore di terapie per disturbi d’ansia, che sono intrinsecamente più complesse e con una probabilità di successo variabile rispetto al coaching lavorativo. Il suo tasso di successo globale è inferiore non a causa di una minore abilità in un particolare tipo di terapia, ma perché una frazione maggiore delle sue terapie riguarda casi più complessi.\nL’aggregazione dei dati tra diversi tipi di terapia presenta un quadro fuorviante delle abilità dei terapeuti perché perdiamo l’informazione su quale terapeuta tende a effettuare quale tipo di terapia. Quando sospettiamo la presenza di variabili di confondimento, come ad esempio il tipo di terapia in questo contesto, è fondamentale analizzare i dati in modo disaggregato per comprendere con precisione la dinamica in atto.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-composta",
    "href": "chapters/probability/04_conditional_prob.html#teorema-della-probabilità-composta",
    "title": "28  Probabilità condizionata",
    "section": "28.3 Teorema della probabilità composta",
    "text": "28.3 Teorema della probabilità composta\nÈ possibile scrivere l’Equazione 28.1 nella forma:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{28.2}\\]\nQuesto secondo modo di scrivere l’Equazione 28.1 è chiamato teorema della probabilità composta (o regola moltiplicativa, o regola della catena). La legge della probabilità composta ci dice che la probabilità che si verifichino contemporaneamente due eventi \\(A\\) e \\(B\\) è pari alla probabilità di uno dei due eventi moltiplicata per la probabilità dell’altro evento condizionata al verificarsi del primo.\nL’l’Equazione 28.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right).\n\\tag{28.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(&A_1 \\cap A_2 \\cap A_3 \\cap A_4) =  \\\\\n& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 28.6 Per fare un esempio, consideriamo il problema seguente. Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 28.2, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per l’Equazione 28.3, vale\n\\[\n\\begin{aligned}\nP(B_1 \\cap B_2 \\cap B_3) &=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2) \\notag\\\\\n&=\\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} \\notag\\\\\n&= \\frac{1}{6}.\n\\end{aligned}\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} \\notag\\\\\n&= \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilità-totale",
    "href": "chapters/probability/04_conditional_prob.html#il-teorema-della-probabilità-totale",
    "title": "28  Probabilità condizionata",
    "section": "28.4 Il teorema della probabilità totale",
    "text": "28.4 Il teorema della probabilità totale\nIl teorema della probabilità totale (detto anche teorema delle partizioni) afferma che se abbiamo una partizione di uno spazio campionario \\(\\Omega\\) in \\(n\\) eventi mutualmente esclusivi e tali che la loro unione formi \\(\\Omega\\), allora la probabilità di un qualsiasi evento in \\(\\Omega\\) può essere calcolata sommando la probabilità dell’evento su ciascun sottoinsieme della partizione, pesata in base alla probabilità del sottoinsieme.\nIn altre parole, se \\(H_1, H_2, \\dots, H_n\\) sono eventi mutualmente esclusivi e tali che \\(\\bigcup_{i=1}^n H_i = \\Omega\\), allora per ogni evento \\(E \\subseteq \\Omega\\), la probabilità di \\(E\\) è data dalla formula:\n\\[\nP(E) = \\sum_{i=1}^n P(E \\mid H_i)P(H_i),\n\\tag{28.4}\\]\ndove \\(P(E \\mid H_i)\\) rappresenta la probabilità condizionata di \\(E\\) dato che si è verificato l’evento \\(H_i\\), e \\(P(H_i)\\) è la probabilità dell’evento \\(H_i\\).\nIl teorema della probabilità totale riveste un ruolo fondamentale in quanto fornisce il denominatore nel teorema di Bayes, svolgendo la funzione di costante di normalizzazione. Questa costante di normalizzazione è di vitale importanza per assicurare che la distribuzione a posteriori sia una distribuzione di probabilità valida. Per ulteriori dettagli e approfondimenti, è possibile fare riferimento al Capitolo 42.\nNell’ambito della probabilità discreta, questo teorema viene usato quando abbiamo una partizione dello spazio campionario e vogliamo calcolare la probabilità di un evento, sfruttando le probabilità dei singoli eventi della partizione. Il caso più semplice è quello di una partizione dello spazio campione in due sottoinsiemi: \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\).\n\n\n\n\n\n\nFigura 28.3: Partizione dello spazio campionario per il teorema di Bayes.\n\n\n\nIn tali circostanza abbiamo che\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2).\n\\]\nL’Equazione 28.4 è utile per calcolare \\(P(E)\\), se \\(P(E \\mid H_i)\\) e \\(P(H_i)\\) sono facili da trovare.\n\nEsempio 28.7 Abbiamo tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?\nSia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]\n\n\n28.4.1 Indipendenza e probabilità condizionata\nL’indipendenza tra due eventi \\(A\\) e \\(B\\) può essere espressa in modo intuitivo utilizzando la probabilità condizionata. Se \\(A\\) e \\(B\\) sono indipendenti, il verificarsi di uno degli eventi non influisce sulla probabilità del verificarsi dell’altro. In altre parole, la probabilità che \\(A\\) accada non cambia se sappiamo che \\(B\\) è avvenuto, e viceversa.\nPossiamo esprimere questa idea con le seguenti equazioni:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A \\cap B)}{P(A)} = P(B).\n\\]\nQuindi, due eventi \\(A\\) e \\(B\\) sono indipendenti se soddisfano le condizioni:\n\\[\nP(A \\mid B) = P(A),\n\\]\n\\[\nP(B \\mid A) = P(B).\n\\]\nQuesto significa che la probabilità di \\(A\\) rimane invariata indipendentemente dal fatto che \\(B\\) sia accaduto o meno, e lo stesso vale per \\(B\\).\n\n28.4.1.1 Indipendenza di Tre Eventi\nTre eventi \\(A\\), \\(B\\) e \\(C\\) sono indipendenti se soddisfano le seguenti condizioni:\n\\[\n\\begin{align}\nP(A \\cap B) &= P(A) P(B), \\\\\nP(A \\cap C) &= P(A) P(C), \\\\\nP(B \\cap C) &= P(B) P(C), \\\\\nP(A \\cap B \\cap C) &= P(A) P(B) P(C).\n\\end{align}\n\\]\nLe prime tre condizioni verificano l’indipendenza a due a due, ovvero l’indipendenza di ciascuna coppia di eventi. Tuttavia, per essere completamente indipendenti, deve essere soddisfatta anche l’ultima condizione, che riguarda l’intersezione di tutti e tre gli eventi. Solo se tutte queste condizioni sono soddisfatte possiamo dire che \\(A\\), \\(B\\) e \\(C\\) sono completamente indipendenti.\nIn sintesi, l’indipendenza tra eventi implica che la conoscenza del verificarsi di uno non fornisce alcuna informazione sulla probabilità del verificarsi degli altri.\n\nEsempio 28.8 Consideriamo un esempio utilizzando un mazzo di 52 carte. Ogni seme contiene 13 carte e ci sono 4 regine in totale. Definiamo i seguenti eventi:\n\nEvento A: pescare una carta di picche,\nEvento B: pescare una regina.\n\nProbabilità con un mazzo completo\nIn un mazzo completo, la probabilità di pescare una carta di picche (\\(P(A)\\)) è \\(\\frac{13}{52} = \\frac{1}{4}\\), poiché ci sono 13 picche su 52 carte totali. La probabilità di pescare una regina (\\(P(B)\\)) è \\(\\frac{4}{52} = \\frac{1}{13}\\), poiché ci sono 4 regine su 52 carte.\nOra consideriamo la probabilità congiunta di pescare la regina di picche (\\(P(AB)\\)). Poiché esiste solo una regina di picche nel mazzo, la probabilità di pescare questa specifica carta è \\(\\frac{1}{52}\\).\nSecondo la definizione di indipendenza, se gli eventi \\(A\\) e \\(B\\) sono indipendenti, allora:\n\\[ P(AB) = P(A)P(B) \\]\nCalcoliamo \\(P(A)P(B)\\):\n\\[ P(A)P(B) = \\left( \\frac{1}{4} \\right) \\left( \\frac{1}{13} \\right) = \\frac{1}{52} \\]\nPoiché \\(P(AB) = \\frac{1}{52}\\) è uguale a \\(P(A)P(B)\\), possiamo affermare che gli eventi \\(A\\) e \\(B\\) sono indipendenti con un mazzo completo di 52 carte.\nProbabilità dopo la rimozione di una carta\nConsideriamo ora un mazzo con una carta in meno, ad esempio il due di quadri, riducendo il numero totale di carte a 51. Ricalcoliamo le probabilità con questo mazzo ridotto:\nLa probabilità di pescare la regina di picche (\\(P(AB)\\)) è ora \\(\\frac{1}{51}\\), poiché ci sono 51 carte nel mazzo.\nRicalcoliamo anche \\(P(A)\\) e \\(P(B)\\):\n\n\\(P(A)\\) diventa \\(\\frac{13}{51}\\), poiché ci sono ancora 13 picche, ma su 51 carte.\n\\(P(B)\\) diventa \\(\\frac{4}{51}\\), poiché ci sono ancora 4 regine, ma su 51 carte.\n\nOra calcoliamo il prodotto \\(P(A)P(B)\\) con queste nuove probabilità:\n\\[ P(A)P(B) = \\left( \\frac{13}{51} \\right) \\left( \\frac{4}{51} \\right) = \\frac{52}{2601} \\]\nConfrontiamo \\(P(AB)\\) e \\(P(A)P(B)\\):\n\\[ \\frac{1}{51} \\neq \\frac{52}{2601} \\]\nPoiché \\(\\frac{1}{51} \\neq \\frac{52}{2601}\\), gli eventi \\(A\\) e \\(B\\) non sono più indipendenti dopo la rimozione del due di quadri.\nQuesto esempio mostra come l’indipendenza tra due eventi dipenda dal contesto. Con un mazzo completo, i due eventi sono indipendenti. Tuttavia, rimuovendo una carta dal mazzo, le probabilità cambiano e gli eventi non sono più indipendenti. Questo evidenzia l’importanza di considerare la composizione e le condizioni iniziali quando si analizzano probabilità e indipendenza. Modifiche nella composizione del mazzo possono alterare le probabilità, influenzando le relazioni di indipendenza tra eventi specifici.\nIn generale, l’indipendenza tra due eventi significa che la probabilità di uno non è influenzata dal verificarsi dell’altro. Questo concetto è cruciale per analisi probabilistiche e modelli statistici più complessi.\n\n\nEsempio 28.9 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = “esce un 1 o un 2 nel primo lancio” e \\(B\\) = “il punteggio totale è 8”. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nCalcoliamo \\(P(A)\\):\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\nA = [roll for roll in sample if roll[0] == 1 or roll[0] == 2]\nprint(A)\nprint(f\"{len(A)} / {len(sample)}\")\n\n[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6)]\n12 / 36\n\n\nCalcoliamo \\(P(B)\\):\n\nB = [roll for roll in sample if roll[0] + roll[1] == 8]\nprint(B)\nprint(f\"{len(B)} / {len(sample)}\")\n\n[(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)]\n5 / 36\n\n\nCalcoliamo \\(P(A \\cap B)\\):\n\nI = [\n    roll\n    for roll in sample\n    if (roll[0] == 1 or roll[0] == 2) and (roll[0] + roll[1] == 8)\n]\nprint(I)\nprint(f\"{len(I)} / {len(sample)}\")\n\n[(2, 6)]\n1 / 36\n\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti dato che \\(P(A \\cap B) \\neq P(A)P(B)\\):\n\n12/36 * 5/36 == 1/36\n\nFalse",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/04_conditional_prob.html#commenti-e-considerazioni-finali",
    "title": "28  Probabilità condizionata",
    "section": "28.5 Commenti e considerazioni finali",
    "text": "28.5 Commenti e considerazioni finali\nLa probabilità condizionata riveste un ruolo fondamentale in statistica, poiché consente di definire con precisione il concetto di indipendenza statistica. Uno degli aspetti cruciali dell’analisi statistica è la valutazione dell’associazione tra due variabili. In questo capitolo, ci siamo focalizzati sul concetto di indipendenza, che indica l’assenza di relazione tra le variabili. Tuttavia, in futuro esploreremo come effettuare inferenze sulla correlazione tra variabili, ovvero come determinare se esiste una relazione statistica credibile tra di esse.\nIl concetto di probabilità condizionata ci permette di enunciare due regole fondamentali della probabilità:\n\nLa regola della congiunzione (regola del “e” o del prodotto):\n\\[\nP(A \\cap B\\,|\\,C) = P(A\\,|\\,C) \\times P(B\\,|\\,A, C) = P(B\\,|\\,C) \\times P(A\\,|\\,B, C).\n\\]\nLa regola della disgiunzione (regola del “o” o della somma):\n\\[\nP(A \\cup B\\,|\\,C) = P(A\\,|\\,C) + P(B\\,|\\,C) - P(A \\cap B\\,|\\,C).\n\\]\n\nUn’altra importante regola della probabilità è la legge della probabilità totale, che gioca un ruolo cruciale nel teorema di Bayes.\nNel contesto dell’inferenza bayesiana, il condizionamento è uno strumento essenziale. Questo approccio statistico utilizza il condizionamento per rivedere e aggiornare le credenze o incertezze riguardo a determinate ipotesi, basandosi sull’introduzione di nuove informazioni.\n\n\nIn sintesi, la probabilità condizionata non solo è fondamentale per comprendere l’indipendenza statistica, ma anche per applicare metodi inferenziali avanzati come l’inferenza bayesiana. Questa forma di inferenza ci permette di aggiornare continuamente le nostre conoscenze e credenze alla luce di nuove informazioni, rendendo il processo decisionale statistico dinamico e adattabile.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/04_conditional_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "28  Probabilità condizionata",
    "section": "28.6 Informazioni sull’Ambiente di Sviluppo",
    "text": "28.6 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Feb 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.7\nIPython version      : 8.21.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\npandas: 2.2.0\nnumpy : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Probabilità condizionata</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html",
    "href": "chapters/probability/05_random_var.html",
    "title": "29  Variabili casuali",
    "section": "",
    "text": "Introduzione\nFinora, ci siamo concentrati sulle probabilità degli eventi. Ad esempio, abbiamo calcolato la probabilità di vincere il gioco di Monty Hall o di avere una rara condizione medica dato che il test è risultato positivo. Ma, in molti casi, vorremmo sapere di più. Ad esempio, quanti concorrenti devono giocare al gioco di Monty Hall fino a quando uno di loro finalmente vince? Quanto durerà questa condizione? Quanto perderò giocando d’azzardo con un dado sbilanciato tutta la notte? Per rispondere a queste domande, dobbiamo lavorare con le variabili casuali. In questo capitolo, introduciamo le variabili casuali e le loro proprietà.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#definizione",
    "href": "chapters/probability/05_random_var.html#definizione",
    "title": "29  Variabili casuali",
    "section": "29.1 Definizione",
    "text": "29.1 Definizione\nLe variabili casuali sono risultati numerici derivanti da processi aleatori. Esse ci consentono di trasformare risultati qualitativi (ad esempio \\(X = \\{\\Box, \\clubsuit, \\diamondsuit, \\heartsuit, \\spadesuit\\}\\)) in valori numerici, semplificando così l’analisi matematica.\nFormalmente, una variabile casuale è definita come una funzione che associa ogni elemento di uno spazio campionario \\(S\\) a un valore in un sottoinsieme dei numeri reali \\(\\mathbb{R}\\). Questa definizione consente di esprimere numericamente gli esiti di un fenomeno aleatorio, associando un valore specifico a ciascun possibile risultato dell’esperimento.\n\nEsempio 29.1 Un esempio è la variabile casuale \\(X\\), che rappresenta il risultato del lancio di un dado. Se definiamo \\(X = 1\\) per indicare che il risultato del lancio è un numero dispari (1, 3 o 5) e \\(X = 0\\) per indicare che il risultato è un numero pari (2, 4 o 6), abbiamo trasformato un’osservazione fisica (il lancio del dado) in un valore numerico che rappresenta una determinata categoria di eventi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "href": "chapters/probability/05_random_var.html#tipologie-di-variabili-casuali",
    "title": "29  Variabili casuali",
    "section": "29.2 Tipologie di Variabili Casuali",
    "text": "29.2 Tipologie di Variabili Casuali\nLe variabili casuali possono essere suddivise in due categorie principali: discrete e continue. Una variabile casuale discreta assume valori all’interno di un insieme finito o al massimo numerabile, il che significa che i suoi possibili esiti possono essere contati, anche se l’insieme è infinito. Al contrario, una variabile casuale continua può assumere un’infinità di valori all’interno di un intervallo, essendo in grado di coprire ogni punto di quell’intervallo senza interruzioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "href": "chapters/probability/05_random_var.html#convenzioni-notazionali",
    "title": "29  Variabili casuali",
    "section": "29.3 Convenzioni Notazionali",
    "text": "29.3 Convenzioni Notazionali\nNella teoria della probabilità, è usuale adottare una specifica convenzione di notazione per le variabili casuali e i loro esiti. Comunemente, si utilizzano le lettere maiuscole, come \\(X\\), per indicare una variabile casuale, ovvero un concetto che rappresenta una serie di possibili esiti di un fenomeno aleatorio. D’altro canto, la corrispondente lettera minuscola, \\(x\\) nel nostro esempio, è impiegata per denotare una specifica realizzazione o un esito particolare che la variabile casuale può assumere. Questa distinzione aiuta a chiarire se si sta parlando della variabile casuale nel suo insieme (\\(X\\)) o di un suo specifico valore (\\(x\\)).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "href": "chapters/probability/05_random_var.html#variabili-casuali-multiple",
    "title": "29  Variabili casuali",
    "section": "29.4 Variabili casuali multiple",
    "text": "29.4 Variabili casuali multiple\nNella teoria della probabilità, le variabili casuali spesso interagiscono o si combinano tra loro. Consideriamo l’esempio di tre lanci di una moneta bilanciata, rappresentati da variabili casuali indipendenti \\(X_1\\), \\(X_2\\), e \\(X_3\\). Per ogni lancio:\n\n\\(P(X_n = 1)\\) (testa) = 0.5,\n\\(P(X_n = 0)\\) (croce) = 0.5,\n\ndove \\(n = 1, 2, 3\\).\nCombinando queste variabili, possiamo creare nuove variabili casuali. Ad esempio, definiamo \\(Z\\) come la somma dei risultati:\n\\[\nZ = X_1 + X_2 + X_3.\n\\]\n\\(Z\\) è una variabile casuale discreta che rappresenta il numero totale di teste ottenute nei tre lanci. I suoi possibili valori sono 0, 1, 2, e 3.\nQuesto esempio illustra come variabili casuali indipendenti possano essere combinate per creare nuove variabili casuali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#sec-fun-mass-prob",
    "href": "chapters/probability/05_random_var.html#sec-fun-mass-prob",
    "title": "29  Variabili casuali",
    "section": "29.5 Distribuzione di Probabilità",
    "text": "29.5 Distribuzione di Probabilità\nLa distribuzione di probabilità è un concetto fondamentale nella teoria della probabilità, che descrive come le probabilità si distribuiscono tra i possibili esiti di una variabile casuale. La sua rappresentazione varia a seconda che si tratti di variabili casuali discrete o continue.\n\n29.5.1 Variabili Casuali Discrete\nPer le variabili casuali discrete, che assumono valori specifici e contabili, la distribuzione di probabilità è rappresentata dalla funzione di massa di probabilità, indicata come \\(P(\\cdot)\\).\n\n29.5.1.1 Funzione di Massa di Probabilità\nLa funzione di massa di probabilità assegna una probabilità precisa a ciascun possibile esito della variabile casuale discreta. Ad esempio, per il lancio di un dado equilibrato:\n\\(P(Y = 1) = \\frac{1}{6}\\).\nQuesto significa che la probabilità di ottenere “1” in un singolo lancio è 1/6.\n\n\n29.5.1.2 Istogrammi per Variabili Discrete\nGli istogrammi sono strumenti visivi efficaci per rappresentare la distribuzione di probabilità delle variabili casuali discrete. Per queste variabili, possiamo impostare ciascun bin dell’istogramma in modo che copra un singolo valore della variabile casuale. L’altezza di ogni bin corrisponde alla probabilità di quel valore specifico.\nGli istogrammi ci permettono di identificare rapidamente caratteristiche importanti della distribuzione, come:\n\nunimodalità: concentrazione attorno a un singolo punto;\nmultimodalità: concentrazione attorno a più punti;\nsimmetria o asimmetria della distribuzione;\ndispersione dei valori.\n\n\n\n\n29.5.2 Variabili Casuali Continue\nPer le variabili casuali continue, che possono assumere un’infinità di valori in un intervallo, si utilizza la funzione di densità di probabilità, indicata come \\(p(\\cdot)\\).\n\n29.5.2.1 Funzione di Densità di Probabilità\nLa funzione di densità di probabilità non assegna probabilità a singoli valori (che sarebbe zero per una variabile continua), ma determina la probabilità che la variabile si trovi all’interno di un intervallo specifico.\n\n\n29.5.2.2 Istogrammi per Variabili Continue\nAnche per le variabili continue possiamo usare istogrammi, ma in questo caso i bin devono sempre coprire intervalli di valori. Riducendo progressivamente la larghezza dei bin, il profilo dell’istogramma tende a coincidere con la funzione di densità di probabilità della variabile casuale.\n\n\n\n29.5.3 Supporto della Variabile Casuale\nIl supporto di una variabile casuale è l’insieme di tutti i valori che la variabile può effettivamente assumere. Ad esempio:\n\nper un dado a sei facce: {1, 2, 3, 4, 5, 6};\nper una distribuzione gaussiana: l’intero insieme dei numeri reali.\n\n\n\n29.5.4 Assegnazione di Probabilità\n\nPer variabili discrete: si specifica la probabilità di ogni possibile valore.\nPer variabili continue: si utilizza la densità di probabilità per calcolare la probabilità di intervalli di valori.\n\nLa distribuzione di probabilità, sia per variabili discrete che continue, fornisce una descrizione completa del comportamento probabilistico della variabile casuale, permettendo analisi e previsioni accurate in vari campi di applicazione.\n\nEsempio 29.2 Consideriamo l’esperimento casuale costituito dal lancio di due dadi equilibrati. Definiamo la variabile casuale \\(X\\) come la somma dei punti ottenuti dai due dadi.\nLo spazio campionario \\(S\\) è l’insieme di tutte le possibili coppie ordinate \\((a,b)\\), dove \\(a\\) e \\(b\\) rappresentano i risultati del primo e del secondo dado rispettivamente:\n\\[\nS = {(1,1), (1,2), ..., (1,6), (2,1), (2,2), ..., (2,6), ..., (6,1), (6,2), ..., (6,6)}.\n\\]\nIn totale, ci sono 6 × 6 = 36 possibili esiti.\nLa variabile casuale \\(X\\) è definita come la somma dei punti dei due dadi. Quindi:\n\\[\nX = a + b, \\quad \\text{dove } (a,b) \\in S.\n\\]\n\\(X\\) può assumere valori interi da 2 (1+1) a 12 (6+6).\nLa distribuzione della variabile casuale \\(X\\) è una funzione che associa a ogni possibile valore di \\(X\\) la sua probabilità. In questo caso, poiché \\(X\\) è discreta, usiamo una funzione di massa di probabilità.\nPer calcolare la probabilità di ogni valore di \\(X\\), contiamo il numero di casi favorevoli e lo dividiamo per il numero totale di casi possibili (36).\n\n\n\n\n\n\n\n\n\nX\nCasi favorevoli\nNumero di casi\nProbabilità P(X = x)\n\n\n\n\n2\n(1,1)\n1\n1/36\n\n\n3\n(1,2), (2,1)\n2\n2/36 = 1/18\n\n\n4\n(1,3), (2,2), (3,1)\n3\n3/36 = 1/12\n\n\n5\n(1,4), (2,3), (3,2), (4,1)\n4\n4/36 = 1/9\n\n\n6\n(1,5), (2,4), (3,3), (4,2), (5,1)\n5\n5/36\n\n\n7\n(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\n6\n6/36 = 1/6\n\n\n8\n(2,6), (3,5), (4,4), (5,3), (6,2)\n5\n5/36\n\n\n9\n(3,6), (4,5), (5,4), (6,3)\n4\n4/36 = 1/9\n\n\n10\n(4,6), (5,5), (6,4)\n3\n3/36 = 1/12\n\n\n11\n(5,6), (6,5)\n2\n2/36 = 1/18\n\n\n12\n(6,6)\n1\n1/36\n\n\n\nQuesta tabella rappresenta la distribuzione completa della variabile casuale \\(X\\).\nIn conclusione, la distribuzione di una variabile casuale discreta, come nell’esempio della somma dei punti di due dadi, fornisce una descrizione completa delle proprietà probabilistiche della variabile. Essa associa a ogni possibile valore della variabile la sua probabilità di verificarsi.\nIn questo caso, la distribuzione ci dice, per esempio, che la probabilità di ottenere una somma di 7 è 1/6, la più alta tra tutti i possibili risultati. Questo è dovuto al fatto che ci sono più combinazioni che producono una somma di 7 rispetto a qualsiasi altro risultato.\nLa distribuzione ci permette di rispondere a domande come:\n\nQual è la probabilità di ottenere una somma pari? (Sommando le probabilità di 2, 4, 6, 8, 10, 12).\nQual è la probabilità di ottenere una somma maggiore o uguale a 10? (Sommando le probabilità di 10, 11, 12).\n\nLa distribuzione di massa di probabilità della variabile casuale \\(X\\) può essere rappresentata visivamente utilizzando un istogramma. Un istogramma permette di vedere immediatamente la probabilità associata a ciascun valore di \\(X\\), rendendo chiaro quali risultati sono più probabili e quali lo sono meno.\nLe istruzioni Python necessarie per generare questo istogramma sono fornite di seguito.\n\n\n# Valori possibili della variabile casuale X\nvalori_X = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n\n# Probabilità associate a ciascun valore di X\nprobabilita_X = [\n    1 / 36,\n    2 / 36,\n    3 / 36,\n    4 / 36,\n    5 / 36,\n    6 / 36,\n    5 / 36,\n    4 / 36,\n    3 / 36,\n    2 / 36,\n    1 / 36,\n]\n\n# Creazione dell'istogramma\nplt.bar(valori_X, probabilita_X, alpha = 0.5, edgecolor=\"black\")\nplt.xlabel(\"Valore della variabile casuale X\")\nplt.ylabel(\"Probabilità P(X = x)\")\nplt.title(\"Distribuzione di Massa di Probabilità della Variabile Casuale X\")\nplt.show()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "href": "chapters/probability/05_random_var.html#funzione-di-distribuzione-cumulativa-cdf",
    "title": "29  Variabili casuali",
    "section": "29.6 Funzione di Distribuzione Cumulativa (CDF)",
    "text": "29.6 Funzione di Distribuzione Cumulativa (CDF)\nLa Funzione di Distribuzione Cumulativa (CDF) è uno strumento fondamentale nella teoria della probabilità per descrivere la distribuzione di una variabile casuale.\n\n29.6.1 Definizione\nPer una variabile casuale \\(X\\), la funzione di distribuzione cumulativa \\(F(x)\\) è definita come:\n\\[\nF(x) = P(X \\leq x),\n\\]\ndove:\n\n\\(X\\) è la variabile casuale.\n\\(P(X \\leq x)\\) rappresenta la probabilità che \\(X\\) assuma un valore minore o uguale a \\(x\\).\n\nIn altre parole, \\(F(x)\\) quantifica la probabilità cumulativa dall’estremo inferiore dello spazio di probabilità fino al punto \\(x\\).\n\n\n29.6.2 Proprietà della CDF\n\nMonotonia non decrescente:\n\nPer \\(x_1 &lt; x_2\\), \\(F(x_1) \\leq F(x_2)\\).\nLa CDF non diminuisce mai quando ci si sposta da sinistra a destra lungo l’asse \\(x\\).\n\nNormalizzazione:\n\n\\(\\lim_{{x \\to -\\infty}} F(x) = 0 \\quad \\text{e} \\quad \\lim_{{x \\to +\\infty}} F(x) = 1\\).\nLa CDF parte da 0 quando \\(x\\) tende a \\(-\\infty\\) e raggiunge 1 quando \\(x\\) tende a \\(+\\infty\\).\n\nContinuità a destra:\n\n\\(F(x) = \\lim_{{y \\to x^+}} F(y)\\).\nLa CDF è continua da destra, il che significa che non presenta salti improvvisi quando ci si avvicina a un punto da destra.\n\n\n\n\n29.6.3 CDF per Variabili Casuali Discrete\nPer una variabile casuale discreta \\(X\\), la CDF (anche chiamata funzione di ripartizione cumulativa) è definita come:\n\\[\nF(x) = P(X \\leq x) = \\sum_{x_i \\leq x} P(X = x_i),\n\\]\ndove la somma è calcolata su tutti i valori \\(x_i\\) minori o uguali a \\(x\\).\n\n\n29.6.4 Importanza e Applicazioni\n\nLa CDF offre una rappresentazione visiva di come le probabilità si accumulano lungo l’intero intervallo dei possibili valori della variabile casuale.\nLa CDF permette di calcolare facilmente la probabilità che \\(X\\) cada in un intervallo specifico:\n\n\\[\nP(a &lt; X \\leq b) = F(b) - F(a).\n\\]\n\nLa CDF è utilizzata in vari metodi di generazione di variabili casuali, come il metodo della trasformazione inversa.\nLe CDF facilitano il confronto tra diverse distribuzioni di probabilità, consentendo di valutare differenze nelle loro caratteristiche cumulative.\n\nIn conclusione, la CDF è uno strumento versatile e potente che fornisce una descrizione completa della distribuzione di probabilità di una variabile casuale, sia essa discreta o continua.\n\nEsempio 29.3 Nel caso del lancio di due dadi, con la variabile casuale \\(Z\\) definita come la somma dei loro valori, la funzione di distribuzione cumulativa \\(F(z)\\) può essere illustrata come segue:\n\n\n\n\\(z\\)\n\\(P(Z = z)\\)\n\\(F(z)\\)\n\n\n\n\n2\n\\(\\frac{1}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n3\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\n\n4\n\\(\\frac{3}{36}\\)\n\\(\\frac{6}{36}\\)\n\n\n5\n\\(\\frac{4}{36}\\)\n\\(\\frac{10}{36}\\)\n\n\n6\n\\(\\frac{5}{36}\\)\n\\(\\frac{15}{36}\\)\n\n\n7\n\\(\\frac{6}{36}\\)\n\\(\\frac{21}{36}\\)\n\n\n8\n\\(\\frac{5}{36}\\)\n\\(\\frac{26}{36}\\)\n\n\n9\n\\(\\frac{4}{36}\\)\n\\(\\frac{30}{36}\\)\n\n\n10\n\\(\\frac{3}{36}\\)\n\\(\\frac{33}{36}\\)\n\n\n11\n\\(\\frac{2}{36}\\)\n\\(\\frac{35}{36}\\)\n\n\n12\n\\(\\frac{1}{36}\\)\n\\(\\frac{36}{36}\\)\n\n\n\nIn questa tabella:\n\n\\(P(Z = z)\\) rappresenta la probabilità che la somma dei due dadi sia esattamente \\(z\\).\n\\(F(z)\\) è la funzione di distribuzione cumulativa, che fornisce la probabilità che la somma \\(Z\\) sia minore o uguale a \\(z\\).\n\nQuesta tabella mostra come le probabilità cumulative si accumulano per la variabile casuale \\(Z\\), evidenziando la distribuzione delle somme possibili quando si lanciano due dadi. Ad esempio, \\(F(7) = \\frac{21}{36}\\) indica che la probabilità che la somma sia 7 o inferiore è \\(\\frac{21}{36}\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilità-attraverso-una-simulazione",
    "href": "chapters/probability/05_random_var.html#trovare-la-distribuzione-di-probabilità-attraverso-una-simulazione",
    "title": "29  Variabili casuali",
    "section": "29.7 Trovare la Distribuzione di Probabilità attraverso una Simulazione",
    "text": "29.7 Trovare la Distribuzione di Probabilità attraverso una Simulazione\nLa distribuzione di probabilità che abbiamo calcolato in precedenza per il lancio di due dadi è corretta, ma esiste un’alternativa per ottenere un risultato simile: la simulazione. Questo metodo consiste nel ripetere l’esperimento casuale un numero elevato di volte e analizzare le frequenze relative dei risultati ottenuti. In altre parole, simulando l’esperimento migliaia o milioni di volte, possiamo approssimare una distribuzione di probabilità empirica. Questa distribuzione empirica diventa sempre più vicina a quella teorica man mano che aumentiamo il numero di ripetizioni.\nLa simulazione è una tecnica ampiamente utilizzata in statistica, soprattutto quando la distribuzione di probabilità teorica è difficile da calcolare o troppo complessa per essere trattata analiticamente. Attraverso la simulazione, possiamo esplorare le proprietà di sistemi aleatori complessi e ottenere stime accurate delle probabilità, anche in situazioni in cui un approccio teorico diretto sarebbe impraticabile.\n\nEsempio 29.4 Nel Capitolo 3 abbiamo visto come creare una funzione che ritorna il risultato del lancio di un dado:\n\ndef roll_die():\n    \"\"\"\n    returns a random int between 1 and 6\n    \"\"\"\n    return rng.choice([1, 2, 3, 4, 5, 6])\n\nPossiamo ora definire una funzione che ritorna la somma dei punti prodotti dal lancio di due dadi. La funzione ha come argomento il numero di ripetizioni di questo esperimento casuale.\n\ndef roll_two_dice(n):\n    \"\"\"\n    returns a random int between 2 and 12\n    \"\"\"\n    rolls = []\n    for i in range(n):\n        two_dice = roll_die() + roll_die()\n        rolls.append(two_dice)\n    \n    return rolls\n\nEseguiamo 100,000 ripetizioni dell’esperimento casuale e memorizzo i risultati ottenuti.\n\nnrolls = 100000\nres = roll_two_dice(nrolls)\nprint(*res[1:20])\n\n12 10 7 10 7 9 8 7 5 9 8 7 4 9 7 2 10 10 5\n\n\nCreiamo un DataFrame che contiene la variabile y corrispondente ai risultati delle 10,000 ripetizioni dell’esperimento casuale.\n\ndf = pd.DataFrame()\ndf[\"y\"] = res \n\nUtilizziamo dunque il metodo value_counts(), che può essere applicato a un DataFrame, come abbiamo visto nel Capitolo 19, per trovare le frequenze assolute di ciascuno dei possibili risultati dell’esperimento casuale (cioè, 2, 3, …, 12). Dividendo per il numero totale delle ripetizioni, otterremo una stima empirica della probabilità. Si noti che i risultati saranno simili a quelli teorici ottenuti in precedenza.\n\nabs_freqs = df[\"y\"].value_counts().sort_index()\npx = abs_freqs / nrolls\nlist(zip(list(range(2, 13)), px))\n\n[(2, 0.02775),\n (3, 0.05625),\n (4, 0.08331),\n (5, 0.11109),\n (6, 0.13915),\n (7, 0.16824),\n (8, 0.13751),\n (9, 0.11167),\n (10, 0.08238),\n (11, 0.05567),\n (12, 0.02698)]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/05_random_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "29  Variabili casuali",
    "section": "29.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "29.8 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html",
    "href": "chapters/probability/06_expval_var.html",
    "title": "30  Proprietà delle variabili casuali",
    "section": "",
    "text": "Introduzione\nSintetizzare la distribuzione di una variabile casuale attraverso indicatori caratteristici è spesso molto utile. Questi indicatori consentono di cogliere le principali proprietà della distribuzione, come la posizione centrale (ovvero il “baricentro”) e la variabilità (ossia la dispersione attorno al centro). In questo modo, è possibile ottenere una descrizione sintetica e significativa della distribuzione di probabilità della variabile casuale.\nIn questo capitolo, introdurremo i concetti fondamentali di valore atteso e varianza di una variabile casuale, che sono strumenti essenziali per comprendere e riassumere le proprietà di una distribuzione probabilistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#valore-atteso",
    "href": "chapters/probability/06_expval_var.html#valore-atteso",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.1 Valore Atteso",
    "text": "30.1 Valore Atteso\nQuando vogliamo comprendere il comportamento tipico di una variabile casuale, ci interessa spesso determinare il suo “valore tipico”. Tuttavia, questa nozione può essere interpretata in diversi modi:\n\nMedia: La somma dei valori divisa per il numero dei valori.\nMediana: Il valore centrale della distribuzione, quando i dati sono ordinati in senso crescente o decrescente.\nModa: Il valore che si verifica con maggiore frequenza.\n\nAd esempio, per il set di valori \\(\\{3, 1, 4, 1, 5\\}\\), la media è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è 3, e la moda è 1. Tuttavia, quando ci occupiamo di variabili casuali, anziché di semplici sequenze di numeri, diventa necessario chiarire cosa intendiamo per “valore tipico” in questo contesto. Questo ci porta alla definizione formale del valore atteso.\n\nDefinizione 30.1 Sia \\(X\\) una variabile casuale discreta che assume i valori \\(x_1, \\dots, x_n\\) con probabilità \\(P(X = x_i) = p(x_i)\\). Il valore atteso di \\(X\\), denotato con \\(\\mathbb{E}(X)\\), è definito come:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^n x_i \\cdot p(x_i).\n\\]\n\nIn altre parole, il valore atteso (noto anche come speranza matematica o aspettazione) di una variabile casuale è la somma di tutti i valori che la variabile può assumere, ciascuno ponderato dalla probabilità con cui esso si verifica.\n\nEsempio 30.1 Calcoliamo il valore atteso della variabile casuale \\(X\\) corrispondente al lancio di una moneta equilibrata, dove testa corrisponde a \\(X = 1\\) e croce corrisponde a \\(X = 0\\):\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{2} x_i \\cdot P(x_i) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = 0.5.\n\\]\n\n\nEsempio 30.2 Calcoliamo il valore atteso della variabile casuale \\(X\\) che rappresenta la somma dei punti ottenuti dal lancio di due dadi equilibrati a sei facce.\nCome abbiamo visto nel Capitolo 29, \\(X\\) può assumere i valori [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] con una distribuzione di massa di probabilità pari a [1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36]. Applicando la formula del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\sum_{i=1}^{11} x_i \\cdot P(x_i) = 2 \\cdot \\frac{1}{36} + 3 \\cdot \\frac{2}{36} + \\dots + 12 \\cdot \\frac{1}{36} = 7.0.\n\\]\n\n\nEsempio 30.3 Vediamo ora come eseguire i calcoli del valore atteso utilizzando Python. Per prima cosa, definiamo i valori della variabile casuale e li trasformiamo in un array NumPy:\n\nx = np.array(list(range(2, 13)))\nx\n\narray([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])\n\n\nSuccessivamente, calcoliamo la distribuzione di massa della variabile casuale \\(X\\), come visto nel Capitolo 25.\n\nr = range(1, 7)\nsample = [(i, j) for i in r for j in r]\n\npx = []\n\nfor i in range(2, 13):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n\npx = np.array(px)\npx\n\narray([0.02777778, 0.05555556, 0.08333333, 0.11111111, 0.13888889,\n       0.16666667, 0.13888889, 0.11111111, 0.08333333, 0.05555556,\n       0.02777778])\n\n\nOra, possiamo calcolare il valore atteso di \\(X\\) utilizzando la formula del valore atteso per variabili casuali discrete:\n\nex = np.sum(x * px)\nex.round(3)\n\n7.0\n\n\nIn alternativa, possiamo utilizzare le funzioni del modulo rv_discrete della libreria scipy.stats per ottenere il valore atteso:\n\nx = np.arange(2, 13)\npx = np.array([1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36])\nX = stats.rv_discrete(values=(x, px))\n\nUna volta definito l’oggetto \\(X\\) con rv_discrete(), possiamo calcolare il valore atteso utilizzando la funzione expect():\n\nx_ev = X.expect()\nround(x_ev, 3)\n\n7.0\n\n\nQuesti metodi dimostrano come sia possibile calcolare il valore atteso di una variabile casuale sia attraverso un approccio diretto con NumPy, sia utilizzando gli strumenti avanzati di scipy.stats.\n\n\n30.1.1 Interpretazione\nIl valore atteso di una variabile casuale corrisponde alla media aritmetica di un ampio numero di realizzazioni indipendenti della variabile stessa.\nPer chiarire questo concetto, consideriamo nuovamente l’esempio del lancio di due dadi bilanciati a sei facce, dove la variabile casuale \\(X\\) rappresenta la “somma dei due dadi”. Per interpretare il valore atteso, possiamo simulare un grande numero di realizzazioni indipendenti di \\(X\\) utilizzando la funzione np.random.choice() della libreria NumPy. Questa funzione permette di generare campioni casuali basati sui valori della variabile casuale, sul numero di ripetizioni indipendenti (qui 1.000.000) e sulla distribuzione di massa di probabilità associata:\nx_samples = np.random.choice(x, size=1000000, p=px)\nL’istruzione np.random.choice(x, size=1000000, p=px) utilizza NumPy per generare un array di 1.000.000 di elementi (specificato dal parametro size), selezionati casualmente dall’array x secondo le probabilità specificate nell’array px. In questo contesto, x è l’array contenente i possibili valori di \\(X\\), mentre px è un array che rappresenta le probabilità associate a ciascun valore di \\(x\\).\nCome ci si aspetterebbe, quando il numero di realizzazioni indipendenti è sufficientemente grande, la media aritmetica dei campioni generati si avvicina al valore atteso della variabile casuale:\n\nnp.mean(x_samples).round(3)\n\n7.002\n\n\nQuesto risultato conferma che, con un numero elevato di simulazioni, la media aritmetica dei valori ottenuti fornisce una buona approssimazione del valore atteso teorico di \\(X\\).\n\n\n30.1.2 Proprietà del Valore Atteso\nUna delle proprietà più importanti del valore atteso è la sua linearità: il valore atteso della somma di due variabili casuali è uguale alla somma dei loro rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{30.1}\\]\nQuesta proprietà, espressa dalla formula sopra, è intuitiva quando \\(X\\) e \\(Y\\) sono variabili casuali indipendenti, ma è valida anche nel caso in cui \\(X\\) e \\(Y\\) siano correlate.\nInoltre, se moltiplichiamo una variabile casuale per una costante \\(c\\), il valore atteso del prodotto è uguale alla costante moltiplicata per il valore atteso della variabile casuale:\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{30.2}\\]\nQuesta proprietà ci dice che una costante può essere “estratta” dall’operatore di valore atteso, e si applica a qualunque numero di variabili casuali.\nUn’altra proprietà significativa riguarda il prodotto di variabili casuali indipendenti. Se \\(X\\) e \\(Y\\) sono indipendenti, allora il valore atteso del loro prodotto è uguale al prodotto dei loro valori attesi:\n\\[\n\\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{30.3}\\]\nInfine, consideriamo la media aritmetica \\(\\bar{X} = \\frac{X_1 + \\ldots + X_n}{n}\\) di \\(n\\) variabili casuali indipendenti con la stessa distribuzione e con valore atteso \\(\\mu\\). Il valore atteso della media aritmetica è:\n\\[\n\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\left(\\mathbb{E}(X_1) + \\dots + \\mathbb{E}(X_n)\\right) = \\frac{1}{n} \\cdot n \\cdot \\mathbb{E}(X) = \\mu.\n\\]\nQuesto risultato conferma che la media aritmetica di un campione di variabili casuali indipendenti ha lo stesso valore atteso della distribuzione originaria, rendendo il valore atteso uno strumento cruciale per l’analisi statistica e probabilistica.\n\nEsempio 30.4 Consideriamo il seguente esperimento casuale. Sia \\(Y\\) il numero che si ottiene dal lancio di un dado equilibrato a sei facce e \\(Y\\) il numero di teste prodotto dal lancio di una moneta equilibrata (0 oppure 1). Troviamo il valore atteso di \\(X+Y\\).\nPer risolvere il problema iniziamo a costruire lo spazio campione dell’esperimento casuale.\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\n\\(x /\\ y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campione avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nSi ottiene lo stesso risultato usando l’Equazione 30.1:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsempio 30.5 Svolgiamo ora l’esercizio in Python.\n\ncoin = range(0, 2)\ndie = range(1, 7)\n\nsample = [(c, d) for c in coin for d in die]\nlist(sample)\n\n[(0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (0, 5),\n (0, 6),\n (1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6)]\n\n\n\npx = []\nfor i in range(1, 8):\n    event = [roll for roll in sample if sum(roll) == i]\n    px.append(len(event) / len(sample))\n    print(f\"P(X + Y = {i}) = {len(event)} / {len(sample)}\")\n\nP(X + Y = 1) = 1 / 12\nP(X + Y = 2) = 2 / 12\nP(X + Y = 3) = 2 / 12\nP(X + Y = 4) = 2 / 12\nP(X + Y = 5) = 2 / 12\nP(X + Y = 6) = 2 / 12\nP(X + Y = 7) = 1 / 12\n\n\n\nx = np.arange(1, 8)\nsum(x * px)\n\n4.0\n\n\n\n\nEsempio 30.6 Consideriamo le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso di \\(Z = X \\cdot Y\\).\nLa distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\n\\(x /\\ y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(Z) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare l’Equazione 30.3. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n\n30.1.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(X\\), il valore atteso è definito come:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x \\cdot p(x) \\, \\mathrm{d}x.\n\\]\nAnche in questo contesto, il valore atteso rappresenta una media ponderata dei valori di \\(x\\), dove ogni possibile valore di \\(x\\) è ponderato in base alla densità di probabilità \\(p(x)\\).\nL’integrale può essere interpretato analogamente a una somma continua, in cui \\(x\\) rappresenta la posizione delle barre infinitamente strette di un istogramma, e \\(p(x)\\) rappresenta l’altezza di tali barre. La notazione \\(\\int_{-\\infty}^{+\\infty}\\) indica che si sta sommando il contributo di ogni valore possibile di \\(x\\) lungo l’intero asse reale.\nQuesta interpretazione rende chiaro come l’integrale calcoli una somma ponderata che si estende su tutti i possibili valori di \\(x\\), fornendo una misura centrale della distribuzione della variabile casuale continua. Per ulteriori dettagli sulla notazione dell’integrale, si veda l’Appendice K.\n\n30.1.3.1 Moda\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda di \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\nMo(Y) = \\text{argmax}_y p(y).\n\\tag{30.4}\\]\n\n\n\n\n\n\nLa notazione \\(\\text{argmax}_y p(y)\\) significa: il valore \\(y\\) tale per cui la funzione \\(p(y)\\) assume il suo valore massimo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#varianza",
    "href": "chapters/probability/06_expval_var.html#varianza",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.2 Varianza",
    "text": "30.2 Varianza\nDopo il valore atteso, la seconda proprietà più importante di una variabile casuale è la varianza.\n\nDefinizione 30.2 Se \\(X\\) è una variabile casuale discreta con distribuzione \\(p(x)\\), la varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), è definita come:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big].\n\\tag{30.5}\\]\n\nIn altre parole, la varianza misura la deviazione media quadratica dei valori della variabile rispetto alla sua media. Se denotiamo il valore atteso di \\(X\\) con \\(\\mu = \\mathbb{E}(X)\\), la varianza \\(\\mathbb{V}(X)\\) diventa il valore atteso di \\((X - \\mu)^2\\).\n\n30.2.1 Interpretazione della Varianza\nLa varianza rappresenta una misura della “dispersione” dei valori di \\(X\\) intorno al suo valore atteso. Quando calcoliamo la varianza, stiamo effettivamente misurando quanto i valori di \\(X\\) tendono a differire dalla media \\(\\mu\\).\nPer capire meglio, consideriamo la variabile casuale \\(X - \\mathbb{E}(X)\\), detta scarto o deviazione dalla media. Questa variabile rappresenta le “distanze” tra i valori di \\(X\\) e il valore atteso \\(\\mathbb{E}(X)\\). Tuttavia, poiché lo scarto può essere positivo o negativo, la media dello scarto è sempre zero, il che lo rende inadatto a quantificare la dispersione.\nPer risolvere questo problema, eleviamo al quadrato gli scarti, ottenendo \\((X - \\mathbb{E}(X))^2\\), che rende tutte le deviazioni positive. La varianza è quindi la media di questi scarti al quadrato, fornendo una misura efficace della dispersione complessiva dei valori di \\(X\\) rispetto alla sua media.\nQuesto concetto è fondamentale per comprendere la variabilità di una distribuzione e per applicare strumenti statistici che richiedono una conoscenza approfondita della distribuzione dei dati.\n\nEsempio 30.7 Posta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\nLa variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(s - \\mathbb{E}(S)\\right)^2 \\cdot P(s) \\notag\\\\\n&= (2 - 7)^2 \\cdot \\frac{1}{36} + (3-7)^2 \\cdot \\frac{3}{36} + \\dots + (12 - 7)^2 \\cdot \\frac{1}{36} \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\nEsempio 30.8 Svolgiamo l’esercizio in Python.\n\nx = np.arange(2, 13)\npx = np.array(\n    [\n        1 / 36,\n        2 / 36,\n        3 / 36,\n        4 / 36,\n        5 / 36,\n        6 / 36,\n        5 / 36,\n        4 / 36,\n        3 / 36,\n        2 / 36,\n        1 / 36,\n    ]\n)\nX = stats.rv_discrete(values=(x, px))\nex = X.expect()\nex\n\n6.999999999999998\n\n\nApplichiamo l’Equazione 30.5:\n\n((x - ex) ** 2 * px).sum()\n\n5.833333333333333\n\n\nUsiamo la funzione var() di rv_discrete:\n\nX.var()\n\n5.833333333333364\n\n\n\n\n\n30.2.2 Formula Alternativa per la Varianza\nEsiste un metodo più semplice e diretto per calcolare la varianza di una variabile casuale \\(X\\):\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(X - \\mathbb{E}(X)\\big)^2\\Big] &= \\mathbb{E}\\big(X^2 - 2Y\\mathbb{E}(X) + \\mathbb{E}(X)^2\\big) \\notag\\\\\n&= \\mathbb{E}(X^2) - 2\\mathbb{E}(Y)\\mathbb{E}(X) + \\mathbb{E}(X)^2,\n\\end{align}\n\\]\ndove \\(\\mathbb{E}(X)\\) è una costante. Semplificando ulteriormente, otteniamo:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(X)\\big)^2.\n\\tag{30.6}\\]\nIn altre parole, la varianza è data dalla differenza tra la media dei quadrati dei valori di \\(X\\) e il quadrato della media di \\(X\\).\nQuesta formula è utile perché permette di calcolare la varianza senza dover prima determinare lo scarto quadratico medio per ciascun valore di \\(X\\). Invece, si può calcolare direttamente la media dei quadrati e sottrarre il quadrato della media, il che spesso semplifica i calcoli e riduce il rischio di errori.\n\nEsempio 30.9 Consideriamo la variabile casuale \\(X\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\nIl valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(X) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(X^2\\) è\n\\[\n\\mathbb{E}(X^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\nEsempio 30.10 Svolgiamo l’esercizio in Python:\n\nx = np.array([0, 1])\npx = np.array([0.2, 0.8])\n\nsum(x**2 * px) - (sum(x * px)) ** 2\n\n0.15999999999999992\n\n\n\n\n\n30.2.3 Proprietà\nSegno della varianza. La varianza di una variabile aleatoria non è mai negativa, ed è zero solamente quando la variabile assume un solo valore.\nInvarianza per traslazione. La varianza è invariante per traslazione, che lascia fisse le distanze dalla media, e cambia quadraticamente per riscalamento:\n\\[\n\\mathbb{V}(a + bX) = b^2\\mathbb{V}(X).\n\\]\nDimostrazione. Iniziamo a scrivere\n\\[\n(aX+b)-{\\mathbb{E}}[aX+b]=aX+b-a{\\mathbb{E}}[X]-b=a(X-{\\mathbb  {E}}[X]).\n\\]\nQuindi\n\\[\n\\sigma _{{aX+b}}^{2}={\\mathbb{E}}[a^{2}(X-{\\mathbb  {E}}[X])^{2}]=a^{2}\\sigma _{X}^{2}.\n\\]\nEsaminiamo una dimostrazione numerica.\n\nx = np.array([2, 1, 4, 7])\ny = 100 + 2 * x\n\nnp.var(y) == 2**2 * np.var(x)\n\nTrue\n\n\nVarianza della somma di due variabili indipendenti. La varianza della somma di due variabili indipendenti o anche solo incorrelate è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione. Se \\(\\mathbb{E}(X) = \\mathbb{E}(Y) = 0\\), allora \\(\\mathbb{E}(X+Y) = 0\\) e\n\\[\\mathbb{V}(X+Y) = \\mathbb{E}((X+Y)^2) = \\mathbb{E}(X^2) + 2 \\mathbb{E}(XY) + \\mathbb{E}(Y^2).\\]\nSiccome le variabili sono indipendenti risulta \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y) = 0\\).\nVarianza della differenza di due variabili indipendenti. La varianza della differenza di due variabili indipendenti è pari alla somma delle loro varianze:\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nDimostrazione.\n\\[\n\\mathbb{V}(X-Y) = \\mathbb{V}(X +(-Y)) = \\mathbb{V}(X) + \\mathbb{V}(-Y) = \\mathbb{V}(X) + \\mathbb{V}(Y).\n\\]\nVarianza della somma di due variabili non indipendenti. Se \\(X\\) e \\(Y\\) non sono indipendenti, la formula viene corretta dalla loro covarianza:\n\\[\n\\mathbb{V}(X+Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) + 2 Cov(X,Y),\n\\]\ndove \\(Cov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nUna dimostrazione numerica di questo principio è fornita sotto.\n\nx = np.array([2, 1, 4, 7])\ny = np.array([1, 3, 5, 11])\n\nnp.var(x + y, ddof=0)\n\n35.25\n\n\n\nnp.var(x, ddof=0) + np.var(y, ddof=0) + 2 * np.cov(x, y, ddof=0)[0, 1]\n\n35.25\n\n\nVarianza della media di variabili indipendenti. La media aritmetica \\(\\textstyle {\\bar  {X}}={\\frac  {X_{1}+\\ldots +X_{n}}{n}}\\) di \\(n\\) variabili casuali indipendenti aventi la medesima distribuzione, ha varianza\n\\[\n\\mathbb{V}(\\bar{X}) = \\frac{1}{n^2} \\mathbb{V}(X_1)+ \\dots \\mathbb{V}(X_n) = \\frac{1}{n^2} n \\mathbb{V}(X) = \\frac{1}{n} \\mathbb{V}(X).\n\\]\nIl principio precedente è illustrato dalla seguente simulazione.\n\n# Set up the population distribution\npopulation = np.random.normal(loc=50, scale=10, size=10000)\n\n# Set up the sample size and number of samples\nsample_size = 30\nnum_samples = 100000\n\n# Create an array to hold the sample means\nsample_means = np.zeros(num_samples)\n\n# Generate the samples and compute their means\nfor i in range(num_samples):\n    sample = np.random.choice(population, size=sample_size)\n    sample_means[i] = np.mean(sample)\n\n# Calculate the variance of the sample means\nsampling_dist_mean_var = np.var(sample_means)\nsampling_dist_mean_var\n\n3.4103710835201433\n\n\nIl valore teorico della varianza della distribuzione campionaria della media è\n\n10**2 / 30\n\n3.3333333333333335\n\n\n\n\n30.2.4 Variabili casuali continue\nPer una variabile casuale continua \\(X\\), la varianza è definita come:\n\\[\n\\mathbb{V}(X) = \\int_{-\\infty}^{+\\infty} \\large[x - \\mathbb{E}(X)\\large]^2 p(x) \\,\\operatorname {d}\\!x.\n\\tag{30.7}\\]\nAnalogamente al caso discreto, la varianza di una variabile casuale continua \\(X\\) una misura della dispersione, ovvero la “distanza” media quadratica attesa dei valori \\(x\\) rispetto alla loro media \\(\\mathbb{E}(X)\\). In altre parole, la varianza quantifica quanto i valori della variabile casuale si discostano tipicamente dal loro valore medio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#deviazione-standard",
    "href": "chapters/probability/06_expval_var.html#deviazione-standard",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.3 Deviazione Standard",
    "text": "30.3 Deviazione Standard\nQuando si lavora con le varianze, i valori sono elevati al quadrato, il che può rendere i numeri significativamente più grandi (o più piccoli) rispetto ai dati originali. Per riportare questi valori all’unità di misura della scala originale, si prende la radice quadrata della varianza. Il risultato ottenuto è chiamato deviazione standard ed è comunemente indicato con la lettera greca \\(\\sigma\\).\n\nDefinizione 30.3 La deviazione standard, o scarto quadratico medio, è definita come la radice quadrata della varianza:\n\\[\n\\sigma_X = \\sqrt{\\mathbb{V}(X)}.\n\\]\n\nCome nella statistica descrittiva, la deviazione standard di una variabile casuale fornisce una misura della dispersione, ossia la “distanza” tipica o prevista dei valori \\(x\\) rispetto alla loro media.\n\nEsempio 30.11 Per i dadi equilibrati dell’esempio precedente, la deviazione standard della variabile casuale \\(S\\) è pari a \\(\\sqrt{5.833} = 2.415\\). Questo valore indica quanto i risultati della somma dei due dadi tendono a variare attorno alla loro media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#standardizzazione",
    "href": "chapters/probability/06_expval_var.html#standardizzazione",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.4 Standardizzazione",
    "text": "30.4 Standardizzazione\n\nDefinizione 30.4 Data una variabile casuale \\(X\\), si dice variabile standardizzata di \\(X\\) l’espressione\n\\[\nZ = \\frac{X - \\mathbb{E}(X)}{\\sigma_X}.\n\\tag{30.8}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "href": "chapters/probability/06_expval_var.html#il-teorema-di-chebyshev",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.5 Il Teorema di Chebyshev",
    "text": "30.5 Il Teorema di Chebyshev\nIl Teorema di Chebyshev ci permette di stimare la probabilità che una variabile aleatoria si discosti dal suo valore atteso (media) di una certa quantità. In altre parole, ci fornisce un limite superiore alla probabilità che una variabile aleatoria assuma valori “estremi”.\nIl teorema di Chebyshev afferma che, per qualsiasi variabile aleatoria X con media E(X) e varianza Var(X), e per qualsiasi numero reale k &gt; 0, si ha:\n\\[\nP(|X - E(X)| ≥ kσ) ≤ 1/k^2,\n\\]\ndove:\n\nP(|X - E(X)| ≥ kσ) è la probabilità che lo scarto assoluto tra X e la sua media sia maggiore o uguale a k volte la deviazione standard (σ).\nσ è la radice quadrata della varianza, ovvero la deviazione standard.\n\nCosa ci dice questo teorema?\n\nLimite superiore: Il teorema ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di più di k deviazioni standard.\nQualsiasi distribuzione: La bellezza di questo teorema è che vale per qualsiasi distribuzione di probabilità, a patto che la media e la varianza esistano.\nUtilizzo: Il teorema di Chebyshev è molto utile quando non conosciamo la distribuzione esatta di una variabile aleatoria, ma conosciamo la sua media e la sua varianza.\n\nIn sintesi, il teorema di Chebyshev ci fornisce un limite superiore alla probabilità che una variabile aleatoria si discosti dalla sua media di una certa quantità, in base alla sua varianza. Il teorema di Chebyshev ci permette quindi di fare inferenze sulla distribuzione di una variabile aleatoria anche quando abbiamo informazioni limitate.\n\nEsempio 30.12 Supponiamo di avere una variabile aleatoria X con media 100 e varianza 25. Vogliamo stimare la probabilità che X assuma valori al di fuori dell’intervallo [90, 110]. In questo caso, k = 2 (poiché 10 è uguale a 2 volte la deviazione standard, che è 5). Applicando il teorema di Chebyshev, otteniamo:\nP(|X - 100| ≥ 10) ≤ 1/2^2 = 0.25\nQuindi, possiamo affermare con certezza che al massimo il 25% dei valori di X saranno al di fuori dell’intervallo [90, 110].",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "href": "chapters/probability/06_expval_var.html#momenti-di-variabili-casuali",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.6 Momenti di variabili casuali",
    "text": "30.6 Momenti di variabili casuali\n\nDefinizione 30.5 Si chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{30.9}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i),\n\\tag{30.10}\\]\ndove:\n\n\\(E(X^q)\\) rappresenta il valore atteso di \\(X\\) elevato alla \\(q\\)-esima potenza.\n\\(x_i\\) sono i possibili valori della variabile discreta.\n\\(P(x_i)\\) è la probabilità associata a ciascun valore discreto.\n\n\nI momenti sono parametri statistici che forniscono informazioni importanti sulle caratteristiche di una variabile casuale. Tra questi, i più noti e utilizzati sono:\n\nIl momento del primo ordine (\\(q\\) = 1): corrisponde al valore atteso (o media) della variabile casuale \\(X\\).\nIl momento del secondo ordine (\\(q\\) = 2): quando calcolato rispetto alla media, corrisponde alla varianza.\n\nPer i momenti di ordine superiore al primo, è comune calcolarli rispetto al valore medio di \\(X\\). Questo si ottiene applicando una traslazione: \\(x_0 = x − \\mathbb{E}(X)\\), dove \\(x_0\\) rappresenta lo scarto dalla media. In particolare, il momento centrale del secondo ordine, calcolato con questa traslazione, corrisponde alla definizione di varianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#alcuni-esempi-in-python",
    "href": "chapters/probability/06_expval_var.html#alcuni-esempi-in-python",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.7 Alcuni esempi in Python",
    "text": "30.7 Alcuni esempi in Python\nUtilizzando il modulo stats di scipy, è possibile semplificare i calcoli del valore atteso e della varianza di variabili casuali discrete.\nConsideriamo ad esempio una variabile casuale \\(X\\) che rappresenta i valori ottenuti dal lancio di un dado non equilibrato, con valori possibili da 0 a 6, e con la seguente distribuzione di massa di probabilità: 0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2.\nIniziamo a definire un vettore che contiene i valori della v.c.:\n\nx = np.arange(7)\nprint(x)\n\n[0 1 2 3 4 5 6]\n\n\nIl vettore px conterrà le probabilità associate ai valori x:\n\npx = [0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\nprint(px)\n\n[0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2]\n\n\nControlliamo che la somma sia 1:\n\nnp.sum(px)\n\n1.0\n\n\nUsiamo ora la funzione rv_discrete() che è una funzione della libreria stats di Python. Tale funzione viene utilizzata per creare una distribuzione discreta personalizzata. La funzione richiede che vengano forniti dei valori discreti (ossia interi) e le rispettive probabilità di occorrenza.\nUna volta definita la distribuzione discreta, rv_discrete() permette di eseguire operazioni come la generazione di numeri casuali dalla distribuzione, il calcolo della funzione di probabilità cumulativa (CDF) e della funzione di densità di probabilità (PDF), e la valutazione della media, della varianza e di altre statistiche della distribuzione.\nLa sintassi di base della funzione rv_discrete() è la seguente:\nrv = stats.rv_discrete(name='rv', values=(xk, pk))\ndove name è il nome della distribuzione discreta, xk sono i valori discreti e pk sono le rispettive probabilità di occorrenza. Ad esempio, creiamo la variabile casuale X:\n\nX = stats.rv_discrete(name='rv', values=(x, px))\n\n\n# Distribuzione di massa di probabilità di X.\nprint(X.pmf(x))\n\n[0.1 0.2 0.3 0.1 0.1 0.  0.2]\n\n\n\n# Distribuzione comulativa di probabilità di X.\nprint(X.cdf(x))\n\n[0.1 0.3 0.6 0.7 0.8 0.8 1. ]\n\n\nGeneriamo un grafico che rappresenta la distribuzione di massa con Matplotlib.\n\ncolor_fill = \"#B17F7D\"\ncolor_edge = \"#832F2B\"\nplt.plot(x, X.pmf(x), \"o\", ms=6, color=color_fill, markeredgecolor=color_edge)\nplt.vlines(x, 0, X.pmf(x), lw=2, colors=color_edge)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo il valore atteso di \\(X\\) implementando la formula del valore atteso, ovvero utilizzando i vettori x e px.\n\nx_ev = (x * px).sum()\nx_ev\n\n2.7\n\n\nLo stesso risultato si ottience applicando il metodo .expect() all’oggetto X.\n\nx_ev = X.expect()\nx_ev\n\n2.7\n\n\nCalcoliamo la varianza di \\(X\\) usando i vettori x e px.\n\nx_var = ((x - x_ev)**2 * X.pmf(x)).sum()\nx_var\n\n3.8100000000000005\n\n\nOtteniamo lo stesso risultato applicando il metodo .var() all’oggetto X.\n\nX.var()\n\n3.8099999999999987\n\n\nCalcoliamo la deviazione standard di \\(X\\) prendento la radice quadrata della varianza.\n\nnp.sqrt(x_var)\n\n1.9519221295943137\n\n\nOppure, in maniera equivalente, applicando il metodo .std() all’oggetto X.\n\nX.std()\n\n1.9519221295943132",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#considerazioni-conclusive",
    "href": "chapters/probability/06_expval_var.html#considerazioni-conclusive",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.8 Considerazioni Conclusive",
    "text": "30.8 Considerazioni Conclusive\nIn conclusione, i concetti di valore atteso e varianza sono fondamentali per comprendere il comportamento delle variabili casuali. Il valore atteso fornisce una misura centrale, rappresentando il “valore tipico” che ci si aspetta di osservare, mentre la varianza quantifica la dispersione dei valori attorno a questa media, offrendo una visione più completa della distribuzione. Questi strumenti sono essenziali per l’analisi e la modellizzazione statistica, fornendo le basi per valutare e interpretare la variabilità nei fenomeni aleatori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/06_expval_var.html#informazioni-sullambiente-di-sviluppo",
    "title": "30  Proprietà delle variabili casuali",
    "section": "30.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "30.9 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nscipy     : 1.14.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Proprietà delle variabili casuali</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html",
    "href": "chapters/probability/07_bayes_theorem.html",
    "title": "31  Il teorema di Bayes",
    "section": "",
    "text": "Introduzione\nIl teorema di Bayes offre una soluzione ottimale ai problemi induttivi, che spaziano dall’identificazione della struttura tridimensionale del mondo basata su dati sensoriali limitati, all’inferenza dei pensieri altrui a partire dal loro comportamento. Questa regola si rivela particolarmente utile in situazioni in cui i dati osservati sono insufficienti per distinguere in modo definitivo tra diverse ipotesi.\nNonostante ciò, tutte le previsioni basate su questo metodo mantengono un certo grado di incertezza. Anche se l’universo fosse completamente deterministico, la nostra conoscenza di esso rimarrebbe imperfetta: non possiamo conoscere la posizione e lo stato di ogni singola particella che lo compone. Le informazioni a nostra disposizione sono inevitabilmente parziali e imprecise, ottenute attraverso i nostri sensi limitati.\nLa vita reale non è paragonabile a una partita di scacchi, un gioco con informazioni perfette che può essere “risolto” in linea di principio. Assomiglia piuttosto al poker, dove le decisioni vengono prese utilizzando le informazioni limitate a disposizione dei giocatori. Questo capitolo si concentra sull’equazione che ci permette di fare proprio questo: il teorema di Bayes. Esso descrive come modifichiamo le nostre convinzioni riguardo a un’ipotesi in una situazione in cui i dati disponibili non consentono una decisione certa.\nQuesto processo è noto come inferenza induttiva, che ci permette di trarre conclusioni generali da dati specifici e limitati. Il teorema di Bayes fornisce quindi un framework matematico per aggiornare le nostre credenze alla luce di nuove evidenze, permettendoci di prendere decisioni informate in un mondo caratterizzato dall’incertezza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "href": "chapters/probability/07_bayes_theorem.html#la-regola-di-bayes",
    "title": "31  Il teorema di Bayes",
    "section": "32.1 La Regola di Bayes",
    "text": "32.1 La Regola di Bayes\nL’inferenza bayesiana si basa su una formula fondamentale nota come regola di Bayes. Sebbene possa sembrare un semplice risultato della teoria delle probabilità, la sua applicazione ha implicazioni profonde in molti campi, inclusa la scienza cognitiva e l’apprendimento automatico. Supponiamo di avere due variabili casuali, \\(A\\) e \\(B\\). Un principio della probabilità, chiamato regola della catena, ci consente di esprimere la probabilità congiunta di queste due variabili \\(P(a, b)\\) come il prodotto della probabilità condizionale di \\(A\\) dato \\(B\\), e la probabilità marginale di \\(B\\). In termini formali:\n\\[\nP(a, b) = P(a \\mid b) P(b).\n\\tag{32.1}\\]\nNon vi è nulla di speciale nel trattare \\(A\\) prima di \\(B\\); possiamo infatti anche scrivere:\n\\[\nP(a, b) = P(b \\mid a) P(a).\n\\tag{32.2}\\]\nDalle due equazioni precedenti, possiamo derivare la regola di Bayes riorganizzando i termini:\n\\[\nP(b \\mid a) = \\frac{P(a \\mid b) P(b)}{P(a)}.\n\\tag{32.3}\\]\nQuesta espressione, nota come regola di Bayes, ci permette di calcolare la probabilità condizionale di \\(b\\) dato \\(a\\), usando la probabilità condizionale opposta \\(P(a \\mid b)\\), la probabilità a priori \\(P(b)\\), e la probabilità marginale \\(P(a)\\).\n\n32.1.1 Applicazioni della Regola di Bayes\nLa forza della regola di Bayes si manifesta pienamente quando la applichiamo a un contesto di inferenza. Supponiamo di avere un agente che tenta di inferire quale processo ha generato alcuni dati \\(d\\). Lasciamo che \\(h\\) rappresenti un’ipotesi su tale processo. L’agente usa le probabilità per rappresentare il grado di credenza in \\(h\\) e in altre ipotesi alternative \\(h'\\), e indichiamo con \\(P(h)\\) la probabilità a priori dell’ipotesi \\(h\\), ovvero la credenza che l’agente attribuisce a \\(h\\) prima di osservare i dati.\nA questo punto, l’agente vuole aggiornare questa credenza alla luce dei nuovi dati \\(d\\), ottenendo la probabilità a posteriori \\(P(h \\mid d)\\). Usando la regola di Bayes, possiamo calcolare questa probabilità nel seguente modo:\n\\[\nP(h \\mid d) = \\frac{P(d \\mid h) P(h)}{P(d)}.\n\\tag{32.4}\\]\nQui, \\(P(d \\mid h)\\) rappresenta la verosimiglianza, ovvero la probabilità di osservare i dati \\(d\\) supponendo che l’ipotesi \\(h\\) sia vera. La verosimiglianza gioca un ruolo cruciale nell’aggiornamento delle nostre credenze: essa “ri-pesa” ogni ipotesi in base alla sua capacità di predire i dati osservati.\n\n\n32.1.2 La Marginalizzazione\nLa teoria delle probabilità ci permette anche di calcolare la probabilità marginale associata a una singola variabile sommando o integrando su altre variabili in una distribuzione congiunta. Ad esempio, la probabilità marginale di \\(b\\) è data da:\n\\[\nP(b) = \\sum_a P(a, b).\n\\]\nQuesto processo è chiamato marginalizzazione. Utilizzando questo principio, possiamo riscrivere la regola di Bayes in un formato che include esplicitamente la somma su tutte le ipotesi alternative \\(h' \\in H\\) considerate dall’agente:\n\\[\nP(h \\mid d) = \\frac{P(d \\mid h) P(h)}{\\sum_{h' \\in H} P(d \\mid h') P(h')}.\n\\tag{32.5}\\]\nIn questo caso, \\(H\\) rappresenta l’insieme di tutte le ipotesi possibili, a volte chiamato spazio delle ipotesi, e la somma al denominatore assicura che le probabilità a posteriori siano normalizzate, cioè che la loro somma sia pari a uno.\n\n\n\n\n\n\n\n\n\n\n\n32.1.3 Estensione al Caso Continuo\nQuando le ipotesi non sono discrete ma fanno parte di un continuum, la formula di Bayes assume una forma integrale:\n\\[\nP(h_i \\mid d) = \\frac{P(d \\mid h_i) \\cdot P(h_i)}{\\int P(d \\mid H) \\cdot P(H) \\, dH}.\n\\tag{32.6}\\]\nIn questo caso, l’integrale nel denominatore somma tutte le ipotesi possibili, ponderandole per le loro probabilità a priori e verosimiglianze. Questo permette di aggiornare le credenze anche per ipotesi continue.\n\n\n32.1.4 Componenti Chiave della Formula di Bayes\nLa formula di Bayes si basa su tre elementi principali:\n\nProbabilità a Priori \\(P(h_i)\\): Questa rappresenta la credenza iniziale sull’ipotesi \\(h_i\\), prima di osservare i dati. È una stima preliminare basata su informazioni preesistenti.\nVerosimiglianza \\(P(d \\mid h_i)\\): Indica la probabilità di osservare i dati \\(d\\), dato che l’ipotesi \\(h_i\\) sia vera. Questa componente quantifica quanto l’ipotesi predice correttamente i dati osservati.\nProbabilità a Posteriori \\(P(h_i \\mid d)\\): Questa è la credenza aggiornata in \\(h_i\\), dopo aver considerato l’evidenza \\(d\\). È il prodotto della probabilità a priori e della verosimiglianza, normalizzato in modo che tutte le ipotesi abbiano probabilità totale pari a uno.\n\nIn conclusione, la regola di Bayes fornisce un quadro potente per aggiornare le credenze in modo coerente e sistematico man mano che si accumulano nuove informazioni, permettendo di affinare le nostre decisioni e previsioni.\nGrazie alla regola di Bayes, possiamo aggiornare costantemente le nostre credenze man mano che nuove informazioni diventano disponibili. Questo processo dinamico di aggiornamento ci permette di affinare le nostre convinzioni e le nostre previsioni, rendendo il modello bayesiano particolarmente utile nelle situazioni in cui le informazioni sono incomplete o incerte. Questo approccio non solo ci consente di prendere decisioni più informate, ma ci permette anche di sviluppare modelli più accurati della realtà basati sulle evidenze.\n\n\n32.1.5 Applicazioni dei modelli bayesiani\nCome discusso da Griffiths et al. (2024), negli ultimi anni, i modelli bayesiani hanno acquisito un’importanza crescente in vari campi delle scienze cognitive. Questi modelli sono stati applicati allo studio dell’apprendimento animale (Courville, Daw, & Touretzky, 2006), dell’apprendimento induttivo umano e della generalizzazione (Tenenbaum, Griffiths, & Kemp, 2006), della percezione visiva (Yuille & Kersten, 2006), del controllo motorio (Kording & Wolpert, 2006), della memoria semantica (Steyvers, Griffiths, & Dennis, 2006), dell’acquisizione e del processamento del linguaggio (Chater & Manning, 2006; Xu & Tenenbaum, in press), del ragionamento simbolico (Oaksford & Chater, 2001), dell’apprendimento causale (Steyvers, Tenenbaum, Wagenmakers, & Blum, 2003; Griffiths & Tenenbaum, 2005, 2007a), e della cognizione sociale (Baker, Tenenbaum, & Saxe, 2007), tra molti altri argomenti.\nDietro questi diversi programmi di ricerca emerge una domanda centrale: come fa la mente umana ad andare oltre i dati dell’esperienza? In altre parole, come riesce la mente a costruire modelli complessi e astratti del mondo, partendo solo da dati sparsi e rumorosi, osservati attraverso i nostri sensi? La risposta proposta dall’approccio bayesiano è che la mente umana utilizza un processo di inferenza probabilistica per aggiornare le proprie credenze sulla base delle nuove evidenze, creando così modelli del mondo sempre più accurati e raffinati.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#alcuni-esempi",
    "href": "chapters/probability/07_bayes_theorem.html#alcuni-esempi",
    "title": "31  Il teorema di Bayes",
    "section": "32.2 Alcuni esempi",
    "text": "32.2 Alcuni esempi\n\nEsempio 32.1 Il modo più comune per spiegare il teorema di Bayes è attraverso i test medici. Prendiamo come esempio il caso della mammografia e la diagnosi del cancro al seno che abbiamo già discusso in precedenza.\nSupponiamo di avere un test di mammografia con una sensibilità del 90% e una specificità del 90%. Questo significa che:\n\nIn presenza di cancro al seno, la probabilità che il test lo rilevi correttamente è del 90%.\nIn assenza di cancro al seno, la probabilità che il test confermi correttamente l’assenza della malattia è del 90%.\n\nIn altri termini, il test ha un tasso di falsi negativi del 10% e un tasso di falsi positivi anch’esso del 10%.\nDefiniamo due ipotesi:\n\n\\(M^+\\): presenza della malattia\n\\(M^-\\): assenza della malattia\n\nL’evidenza è rappresentata dal risultato positivo di un test di mammografia, che indichiamo con \\(T^+\\).\nApplicando il teorema di Bayes, possiamo calcolare la probabilità di avere il cancro al seno dato un risultato positivo al test, come segue:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)},\n\\]\ndove:\n\n\\(P(M^+ \\mid T^+)\\) è la probabilità di avere il cancro (\\(M^+\\)) dato un risultato positivo al test (\\(T^+\\)).\n\\(P(T^+ \\mid M^+)\\) rappresenta la sensibilità del test, ovvero la probabilità che il test risulti positivo in presenza effettiva del cancro. In questo caso, è pari a 0.90.\n\\(P(M^+)\\) è la probabilità a priori che una persona abbia il cancro, ovvero la prevalenza della malattia nella popolazione.\n\\(P(T^+ \\mid M^-)\\) indica la probabilità di un falso positivo, cioè la probabilità che il test risulti positivo in assenza di cancro. Con una specificità del 90%, questa probabilità si calcola come:\n\\[\nP(T^+ \\mid M^-) = 1 - \\text{Specificità} = 1 - 0.90 = 0.10\n\\]\nQuesto significa che c’è una probabilità del 10% che il test diagnostichi erroneamente la presenza del cancro in una persona sana.\n\\(P(M^-)\\) è la probabilità a priori che una persona non sia affetta da cancro prima di effettuare il test.\n\nQuesta formulazione del teorema di Bayes ci permette di calcolare la probabilità effettiva di avere il cancro al seno, dato un risultato positivo al test di mammografia, tenendo conto sia della sensibilità e specificità del test, sia della prevalenza della malattia nella popolazione.\nInserendo nella formula i del problema, otteniamo:\n\\[\n\\begin{align}\nP(M^+ \\mid T^+) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]\nI calcoli effettuati evidenziano come, in presenza di una mammografia positiva ottenuta con un test avente sensibilità e specificità pari al 90%, la probabilità di effettiva positività al tumore al seno si attesta intorno all’8.3%. Tale risultato conferma quanto precedentemente ottenuto nel Capitolo 28, attraverso un metodo di calcolo alternativo.\n\n\n32.2.1 Il Valore Predittivo di un Test di Laboratorio\nPer semplicità, possiamo riscrivere il teorema di Bayes in due modi distinti per calcolare ciò che viene chiamato valore predittivo del test positivo e valore predittivo del test negativo.\nLa comprensione di tre elementi è fondamentale per questo calcolo: la prevalenza della malattia, la sensibilità e la specificità del test.\n\nPrevalenza: Si riferisce alla percentuale di individui in una popolazione affetti da una certa malattia in un determinato momento. Viene espressa come percentuale o frazione della popolazione. Per esempio, una prevalenza dello 0,5% indica che su mille persone, cinque sono affette dalla malattia.\nSensibilità: Indica la capacità del test di identificare correttamente la malattia negli individui malati. Viene calcolata come la frazione di veri positivi (individui malati correttamente identificati) sul totale degli individui malati. La formula della sensibilità (\\(Sens\\)) è la seguente:\n\\[ \\text{Sensibilità} = \\frac{TP}{TP + FN}, \\]\ndove \\(TP\\) rappresenta i veri positivi e \\(FN\\) i falsi negativi. Pertanto, la sensibilità misura la probabilità che il test risulti positivo se la malattia è effettivamente presente.\nSpecificità: Misura la capacità del test di riconoscere gli individui sani, producendo un risultato negativo per chi non è affetto dalla malattia. Si calcola come la frazione di veri negativi (individui sani correttamente identificati) sul totale degli individui sani. La specificità (\\(Spec\\)) si definisce come:\n\\[ \\text{Specificità} = \\frac{TN}{TN + FP}, \\]\ndove \\(TN\\) sono i veri negativi e \\(FP\\) i falsi positivi. Così, la specificità rappresenta la probabilità che il test risulti negativo in assenza della malattia.\n\nQuesta tabella riassume la terminologia:\n\n\n\n\n\n\n\n\n\n\n\\(T^+\\)\n\\(T^-\\)\nTotale\n\n\n\n\n\\(M^+\\)\n\\(P(T^+ \\cap M^+)\\)  (Sensibilità)\n\\(P(T^- \\cap M^+)\\)  (1 - Sensibilità)\n\\(P(M^+)\\)\n\n\n\\(M^-\\)\n\\(P(T^+ \\cap M^-)\\)  (1 - Specificità)\n\\(P(T^- \\cap M^-)\\)  (Specificità)\n\\(P(M^-)\\)\n\n\nTotale\n\\(P(T^+)\\)\n\\(P(T^-)\\)\n1\n\n\n\ndove \\(T^+\\) e \\(T^-\\) indicano rispettivamente un risultato positivo o negativo del test, mentre \\(M^+\\) e \\(M^-\\) la presenza o assenza effettiva della malattia. In questa tabella, i totali marginali rappresentano:\n\nTotale per \\(M^+\\) e \\(M^-\\) (ultima colonna): La probabilità totale di avere la malattia (\\(P(M^+)\\)) e la probabilità totale di non avere la malattia (\\(P(M^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna riga.\nTotale per \\(T^+\\) e \\(T^-\\) (ultima riga): La probabilità totale di un risultato positivo al test (\\(P(T^+)\\)) e la probabilità totale di un risultato negativo al test (\\(P(T^-)\\)), rispettivamente. Questi valori sono calcolati sommando le probabilità all’interno di ciascuna colonna.\nTotale generale (angolo in basso a destra): La somma di tutte le probabilità, che per definizione è 1, rappresentando l’intera popolazione o il set di casi considerati.\n\nMediante il teorema di Bayes, possiamo usare queste informazioni per stimare la probabilità post-test di avere o non avere la malattia basandoci sul risultato del test.\nIl valore predittivo positivo (VPP) del test, cioè la probabilità post-test che un individuo sia malato dato un risultato positivo del test, è calcolato come:\n\\[\nP(M^+ \\mid T^+) = \\frac{P(T^+ \\mid M^+) \\cdot P(M^+)}{P(T^+ \\mid M^+) \\cdot P(M^+) + P(T^+ \\mid M^-) \\cdot P(M^-)}.\n\\]\novvero,\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nAnalogamente, il valore predittivo negativo (VPN), che è la probabilità che un individuo non sia malato dato un risultato negativo del test, si calcola come:\n\\[\nP(M^- \\mid T^-) = \\frac{P(T^- \\mid M^-) \\cdot (1 - P(M^+))}{P(T^- \\mid M^-) \\cdot (1 - P(M^+)) + P(T^- \\mid M^+) \\cdot P(M^+)}.\n\\]\novvero,\n\\[ NPV = \\frac{\\text{Specificità} \\cdot (1 - \\text{Prevalenza})}{\\text{Specificità} \\cdot (1 - \\text{Prevalenza}) + (1 - \\text{Sensibilità}) \\cdot \\text{Prevalenza}}. \\]\n\nEsempio 32.2 Implementiamo le formule del valore predittivo positivo e del valore predittivo negativo del test in Python e usiamo gli stessi dati dell’esercizio precedente.\n\ndef positive_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (sens * prev) / (sens * prev + (1 - spec) * (1 - prev))\n\n\ndef negative_predictive_value_of_diagnostic_test(sens, spec, prev):\n    return (spec * (1 - prev)) / (spec * (1 - prev) + (1 - sens) * prev)\n\nInseriamo i dati del problema.\n\nsens = 0.9  # sensibilità\nspec = 0.9  # specificità\nprev = 0.01  # prevalenza\n\nIl valore predittivo del test positivo è:\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.083\n\n\nIl valore predittivo del test negativo è:\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\n\n\nEsempio 32.3 La simulazione seguente ha lo scopo di aiutare a visualizzare il teorema di Bayes, utilizzando come esempio gli stessi dati della mammografia che abbiamo analizzato in precedenza.\n\n# Parametri\nsensitivity = 0.90  # Sensibilità del test (P(T+ | M+))\nspecificity = 0.90  # Specificità del test (P(T- | M-))\nprev_cancer = 0.01  # Prevalenza (P(M+))\n\n# La simulazione considera una popolazione di 100_000 persone.\nN_mammography = 100_000\n\n# Si genera un campione casuale di 100.000 persone, dove ogni persona viene\n# etichettata come \"Cancer\" (cancro) o \"Healthy\" (sana), sulla base della\n# prevalenza definita (1% per il cancro, 99% per i sani).\n# np.random.choice sceglie tra le due opzioni (\"Cancer\", \"Healthy\") per ogni persona,\n# con una probabilità di 0.01 per il cancro e 0.99 per essere sani.\noutcome_mammography = np.random.choice(\n    [\"Cancer\", \"Healthy\"], N_mammography, p=[prev_cancer, 1 - prev_cancer]\n)\n\n# Conteggio delle persone con e senza cancro.\n# N_C: numero di persone con cancro nella simulazione.\n# N_H: numero di persone sane nella simulazione.\nN_C = np.sum(outcome_mammography == \"Cancer\")\nN_H = np.sum(outcome_mammography == \"Healthy\")\n\n# Si inizializza un array vuoto per memorizzare i risultati del test\n# (positivo \"+\" o negativo \"-\").\ntest_mammography = np.empty(N_mammography, dtype=str)\n\n# Per le persone con cancro, il risultato del test viene simulato utilizzando la\n# sensibilità del test (90% positivo se hanno il cancro).\ntest_mammography[outcome_mammography == \"Cancer\"] = np.random.choice(\n    [\"+\", \"-\"], N_C, p=[sensitivity, 1 - sensitivity]\n)\n\n# Per le persone sane, il risultato del test viene simulato utilizzando la\n# specificità del test (90% negativo se sono sane).\ntest_mammography[outcome_mammography == \"Healthy\"] = np.random.choice(\n    [\"-\", \"+\"], N_H, p=[specificity, 1 - specificity]\n)\n\n# Creazione di un DataFrame per memorizzare i risultati.\ndf_mammography = pd.DataFrame(\n    {\"outcome\": outcome_mammography, \"test\": test_mammography}\n)\n\n# Creazione di una tabella di contingenza. La tabella di contingenza mostra \n# il numero di persone in ogni combinazione di esito (cancro o sano) e risultato \n# del test (positivo o negativo). Questa tabella fornisce il conteggio dei veri \n# positivi, falsi positivi, falsi negativi e veri negativi.\ncontingency_table_mammography = pd.crosstab(\n    df_mammography[\"outcome\"], df_mammography[\"test\"]\n)\ncontingency_table_mammography\n\n\n\n\n\n\n\ntest\n+\n-\n\n\noutcome\n\n\n\n\n\n\nCancer\n863\n89\n\n\nHealthy\n9879\n89169\n\n\n\n\n\n\n\n\n# I risultati nella tabella di contingenza vengono usati per calcolare\n# le probabilità sulla base della simulazione.\n\n# Veri positivi (cancro e risultato positivo al test) \ntrue_positives = contingency_table_mammography.loc[\"Cancer\", \"+\"]\n\n# Falsi positivi (sani e risultato positivo al test) \nfalse_positives = contingency_table_mammography.loc[\"Healthy\", \"+\"]\n\n# Frequenza totale dei risultati positivi \ntotal_positives = true_positives + false_positives\n\n# Applicazione del teorema di Bayes sui dati simulati \nP_M_given_T = true_positives / total_positives\nP_M_given_T\n\n0.08033885682368275\n\n\nUtilizzando i dati della simulazione, la probabilità che una persona abbia il cancro al seno dato un risultato positivo al test è molto vicina al valore teorico calcolato in precedenza (circa 8.3%). Se eseguissimo la simulazione nuovamente, il valore ottenuto potrebbe variare leggermente a causa della casualità intrinseca nel campionamento. Tuttavia, ripetendo la simulazione molte volte, i risultati tenderanno a convergere verso il valore teorico, grazie alla legge dei grandi numeri. Questo conferma che il modello teorico è coerente con i risultati simulati.\n\n\nEsempio 32.4 Poniamoci il problema di capire quanto sia affidabile un test per l’HIV. Per fare questo, utilizzeremo le seguenti informazioni (Petersen, 2024):\n\nTasso di base dell’HIV (P(HIV)): 0.3% (0.003). Questa è la probabilità che una persona nella popolazione generale abbia l’HIV.\nSensibilità del test (P(Test+ HIV)): 95% (0.95). Questa è la probabilità che il test risulti positivo se la persona ha effettivamente l’HIV.\nSpecificità del test (P(Test- ¬HIV)): 99.28% (0.9928). Questa è la probabilità che il test risulti negativo se la persona non ha l’HIV.\n\nCalcolo della probabilità di HIV dato un test positivo.\nPer calcolare la probabilità di avere l’HIV dato un test positivo (P(HIV Test+)), utilizziamo il teorema di Bayes:\n\\[\nP(HIV \\mid Test+) = \\frac{P(Test+ \\mid HIV) \\times P(HIV)}{P(Test+)}.\n\\]\nAbbiamo bisogno di calcolare il denominatore, ovvero la probabilità complessiva di ottenere un test positivo (P(Test+)). Questo valore include sia i veri positivi che i falsi positivi:\n\\[\nP(Test+) = P(Test+ \\mid HIV) \\times P(HIV) + P(Test+ \\mid \\neg HIV) \\times P(\\neg HIV),\n\\]\ndove:\n\n\\(P(Test+ \\mid \\neg HIV) = 1 - P(Test- \\mid \\neg HIV) = 1 - 0.9928 = 0.0072\\) (tasso di falsi positivi),\n\\(P(\\neg HIV) = 1 - P(HIV) = 1 - 0.003 = 0.997\\).\n\nCalcoliamo \\(P(Test+)\\):\n\\[\nP(Test+) = (0.95 \\times 0.003) + (0.0072 \\times 0.997) \\approx 0.010027.\n\\]\nOra possiamo calcolare \\(P(HIV \\mid Test+)\\):\n\\[\nP(HIV \\mid Test+) = \\frac{0.95 \\times 0.003}{0.010027} \\approx 0.2844 \\text{ o 28.44\\%}.\n\\]\nQuindi, se il test risulta positivo, la probabilità di avere l’HIV è circa il 28.44%.\nCalcolo della probabilità di un secondo test positivo.\nDopo un primo test positivo, la probabilità di avere l’HIV è aumentata al 28.44%. Ora calcoleremo la probabilità che un secondo test risulti positivo e la conseguente probabilità di avere l’HIV dopo due test positivi consecutivi.\nPer calcolare \\(P(\\text{Secondo Test+})\\), consideriamo due scenari:\n\nLa persona ha effettivamente l’HIV:\n\nProbabilità: \\(P(HIV \\mid Test+) = 0.2844\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid HIV) = 0.95\\) (sensibilità del test).\n\nLa persona non ha l’HIV:\n\nProbabilità: \\(P(\\neg HIV \\mid Test+) = 1 - P(HIV \\mid Test+) = 0.7156\\).\nProbabilità di un test positivo: \\(P(\\text{Test+} \\mid \\neg HIV) = 0.0072\\) (tasso di falsi positivi).\n\n\nUtilizziamo la formula della probabilità totale:\n\\[\n\\begin{aligned}\nP(\\text{Secondo Test+}) &= P(\\text{Test+} \\mid HIV) \\times P(HIV \\mid Test+) + \\\\\n&\\quad P(\\text{Test+} \\mid \\neg HIV) \\times P(\\neg HIV \\mid Test+).\n\\end{aligned}\n\\]\nSostituendo i valori:\n\\[\nP(\\text{Secondo Test+}) = (0.95 \\times 0.2844) + (0.0072 \\times 0.7156) \\approx 0.2753.\n\\]\nApplichiamo nuovamente il teorema di Bayes per calcolare la probabilità di avere l’HIV dopo un secondo test positivo:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{P(\\text{Secondo Test+} \\mid HIV) \\times P(HIV \\mid Test+)}{P(\\text{Secondo Test+})}.\n\\]\nSostituendo i valori:\n\\[\nP(HIV \\mid \\text{Secondo Test+}) = \\frac{0.95 \\times 0.2844}{0.2753} \\approx 0.981.\n\\]\nDopo un secondo test positivo, la probabilità di avere l’HIV aumenta significativamente, passando dal 28.44% al 98.1%. Questo aumento drastico dimostra l’importanza di:\n\nConsiderare il tasso di base (prevalenza) nella popolazione.\nAggiornare progressivamente le probabilità con nuove evidenze.\nInterpretare i risultati di test diagnostici multipli in modo bayesiano.\n\nL’analisi evidenzia come l’accumulo di evidenze attraverso test ripetuti, in linea con i principi del teorema di Bayes, possa portare a una stima molto più accurata della probabilità di avere una condizione medica, riducendo significativamente l’incertezza iniziale.\n\n\nEsempio 32.5 Consideriamo ora un altro esempio relativo ai test medici e analizziamo i risultati del test antigenico rapido per il virus SARS-CoV-2 alla luce del teorema di Bayes. Questo test può essere eseguito mediante tampone nasale, tampone naso-orofaringeo o campione di saliva. L’Istituto Superiore di Sanità, nel documento pubblicato il 5 novembre 2020, sottolinea che, fino a quel momento, i dati disponibili sui vari test erano quelli forniti dai produttori: la sensibilità varia tra il 70% e l’86%, mentre la specificità si attesta tra il 95% e il 97%.\nPrendiamo un esempio specifico: nella settimana tra il 17 e il 23 marzo 2023, in Italia, il numero di individui positivi al virus è stato stimato essere di 138.599 (fonte: Il Sole 24 Ore). Questo dato corrisponde a una prevalenza di circa lo 0,2% su una popolazione totale di circa 59 milioni di persone.\n\n prev = 138599 / 59000000\n prev\n\n0.002349135593220339\n\n\nL’obiettivo è determinare la probabilità di essere effettivamente affetti da Covid-19, dato un risultato positivo al test antigenico rapido, ossia \\(P(M^+ \\mid T^+)\\). Per raggiungere questo scopo, useremo la formula relativa al valore predittivo positivo del test.\n\nsens = (0.7 + 0.86) / 2  # sensibilità\nspec = (0.95 + 0.97) / 2 # specificità\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.044\n\n\nPertanto, se il risultato del tampone è positivo, la probabilità di essere effettivamente affetti da Covid-19 è solo del 4.4%.\nSe la prevalenza fosse 100 volte superiore (cioè, pari al 23.5%), la probabilità di avere il Covid-19, dato un risultato positivo del tampone, aumenterebbe notevolmente e sarebbe pari a circa l’86%.\n\nprev = 138599 / 59000000 * 100\n\nres_pos = positive_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M+ | T+) = {round(res_pos, 3)}\")\n\nP(M+ | T+) = 0.857\n\n\nSe il risultato del test fosse negativo, considerando la prevalenza stimata del Covid-19 nella settimana dal 17 al 23 marzo 2023, la probabilità di non essere infetto sarebbe del 99.9%.\n\nsens = (0.7 + 0.86) / 2  # sensibilità\nspec = (0.95 + 0.97) / 2  # specificità\nprev = 138599 / 59000000  # prevalenza\n\nres_neg = negative_predictive_value_of_diagnostic_test(sens, spec, prev)\nprint(f\"P(M- | T-) = {round(res_neg, 3)}\")\n\nP(M- | T-) = 0.999\n\n\nTuttavia, un’esito del genere non dovrebbe sorprenderci, considerando che la prevalenza della malattia è molto bassa; in altre parole, il risultato negativo conferma una situazione già presunta prima di sottoporsi al test. Il vero ostacolo, specialmente nel caso di malattie rare come il Covid-19 in quel periodo specifico, non risiede tanto nell’asserire l’assenza della malattia quanto piuttosto nel confermarne la presenza.\n\n\nEsempio 32.6 Consideriamo le persone in attesa di un figlio. Il teorema di Bayes gioca un ruolo cruciale nell’interpretazione dei test prenatali non invasivi (NIPT), un esame del sangue materno usato per rilevare anomalie cromosomiche fetali. Sebbene il NIPT sia spesso pubblicizzato con un’accuratezza del 99%, la sua affidabilità varia significativamente a seconda della condizione testata e della popolazione esaminata.\nParametri chiave del NIPT:\n\nSensibilità:\n\nSindrome di Down: 99%\nSindrome di Edwards: 97%\nSindrome di Patau: 91%\n\nSpecificità: circa 99.9% per tutte le condizioni citate\nPrevalenza nelle nascite:\n\nSindrome di Down: 1 su 700 (0.14%)\nSindrome di Edwards: 1 su 5,000 (0.02%)\nSindrome di Patau: 1 su 10,000 (0.01%)\n\n\nNonostante l’alta sensibilità e specificità, il VPP può essere sorprendentemente basso, soprattutto nella popolazione generale. Questo implica che molti risultati positivi potrebbero essere falsi positivi, in particolare per le condizioni più rare.\nPer calcolare il VPP, utilizziamo il teorema di Bayes:\n\\[ VPP = \\frac{(\\text{Sensibilità} \\times \\text{Prevalenza})}{(\\text{Sensibilità} \\times \\text{Prevalenza}) + (1 - \\text{Specificità}) \\times (1 - \\text{Prevalenza})} \\]\nApplicando questa formula alla popolazione generale:\n\nSindrome di Down: \\[ VPP = \\frac{(0.99 \\times 0.0014)}{(0.99 \\times 0.0014) + (1 - 0.999) \\times (1 - 0.0014)} \\approx 58\\% \\]\nSindrome di Edwards: \\[ VPP = \\frac{(0.97 \\times 0.0002)}{(0.97 \\times 0.0002) + (1 - 0.999) \\times (1 - 0.0002)} \\approx 16.2\\% \\]\nSindrome di Patau: \\[ VPP = \\frac{(0.91 \\times 0.0001)}{(0.91 \\times 0.0001) + (1 - 0.999) \\times (1 - 0.0001)} \\approx 8.3\\% \\]\n\nQuesti calcoli rivelano VPP molto bassi, specialmente per condizioni molto rare come la sindrome di Patau. Anche in questo caso, dunque, il teorema di Bayes ci mostra che la probabilità che un risultato positivo sia effettivamente corretto dipende non solo dall’accuratezza del test, ma anche dalla prevalenza della condizione nella popolazione testata. Per questo motivo, il NIPT risulta più affidabile nelle categorie ad alto rischio.\nIn conclusione, mentre il NIPT è uno strumento prezioso per lo screening prenatale, è fondamentale interpretare i risultati con cautela, considerando il contesto specifico di ogni paziente e la prevalenza della condizione nella popolazione di riferimento.\n\n\nEsempio 32.7 Il teorema di Bayes non è rilevante solo in medicina. In ambito legale è presente un fenomeno noto come la Fallacia del Procuratore. La “fallacia del procuratore” è un errore logico che si verifica quando si confonde la probabilità di un evento dato un certo risultato con la probabilità di quel risultato dato l’evento. In ambito legale, si tratta spesso di confondere la probabilità di ottenere un risultato di un test (ad esempio, una corrispondenza del DNA) se una persona è innocente, con la probabilità che una persona sia innocente dato che il test ha mostrato una corrispondenza.\nSupponiamo di avere i seguenti parametri per un test del DNA:\n\nSensibilità: 99% (probabilità di identificare correttamente il colpevole).\nSpecificità: 99.99997% (probabilità di identificare correttamente un innocente).\nPrevalenza: 1 su 65 milioni (probabilità a priori che una persona qualsiasi sia il colpevole, data una popolazione di 65 milioni).\n\nImmaginiamo che ci sia stato un crimine e che un campione di DNA sia stato trovato sulla scena del crimine. Il campione è confrontato con il DNA di una persona nel database.\nSvolgiamo i calcoli:\n\nProbabilità a Priori (Prevalenza):\n\nLa prevalenza \\(P(C)\\) che una persona casuale sia il colpevole è \\(\\frac{1}{65.000.000}\\).\n\nSensibilità e Specificità:\n\nSensibilità \\(P(T+|C) = 0.99\\).\nSpecificità \\(P(T-|I) = 0.9999997\\).\n\nProbabilità del Test Positivo:\n\nProbabilità di ottenere un test positivo \\(P(T+)\\) è la somma della probabilità di ottenere un positivo dai veri colpevoli e dai falsi positivi:\n\n\n\\[ P(T+) = P(T+|C) \\cdot P(C) + P(T+|I) \\cdot P(I), \\]\n\ndove \\(P(T+|I)\\) è \\(1 - \\text{Specificità}\\) e \\(P(I)\\) è la probabilità di essere innocente (\\(1 - P(C)\\)).\n\n\\[ P(T+) = 0.99 \\cdot \\frac{1}{65.000.000} + (1 - 0.9999997) \\cdot \\frac{64.999.999}{65.000.000} \\]\n\\[ P(T+) \\approx 0.99 \\cdot 1.5385 \\times 10^{-8} + 0.0000003 \\cdot 0.9999999 \\]\n\\[ P(T+) \\approx 1.5231 \\times 10^{-8} + 2.9999997 \\times 10^{-7} \\]\n\\[ P(T+) \\approx 3.1523 \\times 10^{-7} \\]\n\nProbabilità Condizionale che il Sospetto sia Colpevole Dato un Test Positivo:\n\nUtilizzando il teorema di Bayes:\n\n\n\\[ P(C|T+) = \\frac{P(T+|C) \\cdot P(C)}{P(T+)} \\]\n\\[ P(C|T+) = \\frac{0.99 \\cdot \\frac{1}{65.000.000}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) = \\frac{0.99 \\times 1.5385 \\times 10^{-8}}{3.1523 \\times 10^{-7}} \\]\n\\[ P(C|T+) \\approx 0.0483 \\]\nQuindi, la probabilità che il sospetto sia effettivamente il colpevole, dato che il test del DNA è positivo, è circa 4.83%, nonostante l’alta specificità del test.\nIn sintesi, quando si afferma che c’è solo una probabilità su 3 milioni che il sospetto sia innocente (ovvero la specificità), si commette la fallacia del procuratore. In realtà, la probabilità che il sospetto sia colpevole, data una corrispondenza del DNA, è molto inferiore, come dimostrato nell’esempio numerico (circa 4.83%).\nQuesta fallacia può portare a errori giudiziari perché non si considera la bassa prevalenza del colpevole nella popolazione generale e si confonde la specificità del test con la probabilità condizionale di colpevolezza. In altre parole, non si riconosce che le due domande ‘Quanto è probabile che il DNA di una persona corrisponda al campione, se è innocente?’ e ‘Quanto è probabile che qualcuno sia innocente, dato che il suo DNA corrisponde al campione?’ non sono equivalenti. È come confondere ‘Quanto è probabile che un determinato essere umano sia il papa?’ con ‘Quanto è probabile che il papa sia un essere umano?’.\n\n\nEsempio 32.8 Due dadi equi vengono lanciati e ti viene detto che la somma dei loro punteggi è 9. Qual è la distribuzione a posteriori dei punteggi di ciascun dado? (Questo esempio è tratto da Taylan Cemgil ed è discusso da Barber (2012)).\nIndichiamo il punteggio del dado \\(a\\) con \\(s_a\\), dove \\(\\text{dom}(s_a) = \\{1,2,3,4,5,6\\}\\), e in modo simile per \\(s_b\\). Le tre variabili coinvolte sono quindi \\(s_a\\), \\(s_b\\) e la somma totale, \\(t = s_a + s_b\\). Un modello per queste tre variabili assume la forma:\n\\[\np(t, s_a, s_b) = p(t | s_a, s_b) p(s_a, s_b),\n\\]\ndove:\n\nLikelihood: \\(p(t | s_a, s_b)\\) rappresenta la probabilità che la somma dei dadi sia \\(t\\) dato \\(s_a\\) e \\(s_b\\).\nPrior: \\(p(s_a, s_b)\\) è la probabilità congiunta dei punteggi \\(s_a\\) e \\(s_b\\) senza conoscere la somma \\(t\\).\n\nAssumiamo che i dadi siano equi e indipendenti, quindi la probabilità congiunta \\(p(s_a, s_b)\\) è il prodotto delle distribuzioni uniformi di \\(s_a\\) e \\(s_b\\):\n\\[\np(s_a, s_b) = p(s_a) p(s_b) = \\frac{1}{6} \\times \\frac{1}{6} = \\frac{1}{36}.\n\\]\nIl termine di likelihood è dato da:\n\\[\np(t | s_a, s_b) = I[t = s_a + s_b],\n\\]\ndove \\(I[A]\\) è la funzione indicatrice che vale 1 se la condizione \\(A\\) è vera e 0 altrimenti.\nAbbiamo che \\(p(t = 9 | s_a, s_b)\\) è 1 se la somma di \\(s_a\\) e \\(s_b\\) è 9, altrimenti è 0. Quindi la likelihood è data dalla seguente tabella:\n\n\n\n\\(s_b\\) \\\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(s_a\\)\n\n\n\n\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n1\n\n\n4\n0\n0\n0\n0\n1\n0\n\n\n5\n0\n0\n0\n1\n0\n0\n\n\n6\n0\n0\n1\n0\n0\n0\n\n\n\nLe combinazioni possibili sono quindi \\((3,6), (4,5), (5,4), (6,3)\\).\nLa distribuzione a posteriori dei punteggi dei dadi, data la somma \\(t = 9\\), si calcola con:\n\\[\np(s_a, s_b | t = 9) = \\frac{p(t = 9 | s_a, s_b) p(s_a) p(s_b)}{p(t = 9)}.\n\\]\nIl denominatore \\(p(t = 9)\\) è la somma dei termini non nulli del numeratore:\n\\[\np(t = 9) = \\sum_{s_a, s_b} p(t = 9 | s_a, s_b) p(s_a) p(s_b) = 4 \\times \\frac{1}{36} = \\frac{1}{9}.\n\\]\nQuindi, la distribuzione a posteriori è:\n\n\n\n\\(s_b\\) \\\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(s_a\\)\n\n\n\n\n\n\n\n\n1\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n1/4\n\n\n4\n0\n0\n0\n0\n1/4\n0\n\n\n5\n0\n0\n0\n1/4\n0\n0\n\n\n6\n0\n0\n1/4\n0\n0\n0\n\n\n\nIn questo caso, le uniche combinazioni con probabilità non nulla sono quelle in cui la somma è 9, e ciascuna di queste ha probabilità \\(1/4\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#probabilità-inversa",
    "href": "chapters/probability/07_bayes_theorem.html#probabilità-inversa",
    "title": "31  Il teorema di Bayes",
    "section": "32.3 Probabilità Inversa",
    "text": "32.3 Probabilità Inversa\nGli esempi precedenti evidenziano la differenza tra due domande fondamentali. La prima è: “Qual è la probabilità di osservare un determinato risultato, supponendo che una certa ipotesi sia vera?” La seconda, invece, è: “Qual è la probabilità che un’ipotesi sia vera, dato il risultato osservato?”\nUn esempio che risponde alla prima domanda potrebbe essere questo: supponiamo che la probabilità di ottenere testa nel lancio di una moneta sia 0,5 (ipotesi). Qual è la probabilità di ottenere 0 teste in cinque lanci?\nPer la seconda domanda, un esempio potrebbe essere: supponiamo di aver ottenuto 0 teste in 5 lanci di una moneta (evidenza). Qual è la probabilità che la moneta sia effettivamente bilanciata, alla luce di questa osservazione?\nPer molto tempo, lo studio della probabilità si è concentrato principalmente sulla prima domanda. Tuttavia, nel XVIII secolo, il reverendo Thomas Bayes iniziò a riflettere sulla seconda domanda, dando origine a quello che oggi chiamiamo probabilità inversa.\nQuesto approccio ha generato numerose controversie nella storia della statistica, in gran parte perché influenza molti ambiti. Ad esempio, possiamo chiederci: quanto è probabile che un’ipotesi scientifica sia vera, dato il risultato di un esperimento? Per stimare questa probabilità — un compito che molti scienziati ritengono essenziale per la statistica moderna — è necessario fare uso del teorema di Bayes e delle probabilità a priori.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "href": "chapters/probability/07_bayes_theorem.html#riflessioni-conclusive",
    "title": "31  Il teorema di Bayes",
    "section": "32.4 Riflessioni Conclusive",
    "text": "32.4 Riflessioni Conclusive\nIn questo capitolo abbiamo esplorato vari esempi, principalmente nel campo medico e forense, per illustrare come il teorema di Bayes permetta di combinare le informazioni derivate dalle osservazioni con le conoscenze precedenti (priori), aggiornando così il nostro grado di convinzione rispetto a un’ipotesi. Il teorema di Bayes fornisce un meccanismo razionale, noto come “aggiornamento bayesiano”, che ci consente di ricalibrare le nostre convinzioni iniziali alla luce di nuove evidenze.\nUna lezione fondamentale che il teorema di Bayes ci insegna, sia nella ricerca scientifica che nella vita quotidiana, è che spesso non ci interessa tanto conoscere la probabilità che qualcosa accada assumendo vera un’ipotesi, quanto piuttosto la probabilità che un’ipotesi sia vera, dato che abbiamo osservato una certa evidenza. In altre parole, la forza del teorema di Bayes sta nella sua capacità di affrontare direttamente il problema inverso, cioè come dedurre la verità di un’ipotesi a partire dalle osservazioni.\nIl framework bayesiano per l’inferenza probabilistica offre un approccio generale per comprendere come i problemi di induzione possano essere risolti in linea di principio e, forse, anche come possano essere affrontati dalla mente umana.\nIn questo capitolo ci siamo concentrati sull’applicazione del teorema di Bayes utilizzando probabilità puntuali. Tuttavia, il teorema esprime pienamente il suo potenziale quando sia l’evidenza che i gradi di certezza a priori delle ipotesi sono rappresentati attraverso distribuzioni di probabilità continue. Questo sarà l’argomento centrale nel Capitolo 40, dove approfondiremo il flusso di lavoro bayesiano e l’uso di distribuzioni continue nell’aggiornamento bayesiano.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/07_bayes_theorem.html#informazioni-sullambiente-di-sviluppo",
    "title": "31  Il teorema di Bayes",
    "section": "32.5 Informazioni sull’Ambiente di Sviluppo",
    "text": "32.5 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\narviz     : 0.17.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBarber, D. (2012). Bayesian reasoning and machine learning. Cambridge University Press.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024). Bayesian models of cognition: reverse engineering the mind. MIT Press.\n\n\nPetersen, I. T. (2024). Principles of psychological assessment: With applied examples in R. CRC Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Il teorema di Bayes</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html",
    "href": "chapters/probability/08_sampling_distr.html",
    "title": "32  Stime, stimatori e parametri",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà verranno utilizzate per costruire gli strumenti fondamentali dell’inferenza frequentista: gli intervalli di fiducia e i test di ipotesi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "href": "chapters/probability/08_sampling_distr.html#popolazione-e-campioni",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.1 Popolazione e campioni",
    "text": "32.1 Popolazione e campioni\nNell’analisi dei dati, l’obiettivo spesso è comprendere una quantità specifica a livello di popolazione, ma in genere abbiamo accesso solo a un campione di osservazioni. La quantità sconosciuta che vogliamo determinare viene chiamata parametro. Quando usiamo i dati del campione per calcolare una misura di questo parametro, la misura ottenuta è chiamata stima, e la formula che utilizziamo per ottenerla è conosciuta come stimatore. In termini formali, uno stimatore è una funzione dei dati osservati, utilizzata per fornire un’approssimazione del parametro di interesse.\nIn pratica, quando analizziamo un campione di dati, il nostro obiettivo è inferire determinate proprietà della popolazione intera dalla quale il campione è stato tratto. Il parametro è l’indicatore numerico di queste proprietà, ma poiché spesso non possiamo calcolarlo direttamente sulla popolazione, ricorriamo alle osservazioni del campione per stimarlo. La stima, quindi, rappresenta il valore approssimato del parametro ottenuto dal campione, mentre lo stimatore è la regola o la formula matematica che usiamo per arrivare a questa approssimazione.\nÈ importante riconoscere che le stime possono non corrispondere esattamente ai parametri che vogliamo comprendere. In altre parole, le stime sono solo approssimazioni del parametro a causa della natura aleatoria del campionamento.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "href": "chapters/probability/08_sampling_distr.html#la-relazione-tra-stime-e-parametri",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.2 La relazione tra stime e parametri",
    "text": "32.2 La relazione tra stime e parametri\nIn questo capitolo, ci concentreremo sulla relazione tra le stime ottenute dai campioni e i parametri reali della popolazione, esplorando in particolare la connessione tra la media di un campione e la media della popolazione, denotata con \\(\\mu\\). Il nostro obiettivo è capire e caratterizzare l’incertezza che deriva dalla natura aleatoria delle stime, e per farlo, adotteremo l’approccio frequentista, facendo uso di un importante strumento statistico chiamato distribuzione campionaria.\n\n32.2.1 Distribuzione campionaria\nPer illustrare il concetto di distribuzione campionaria, possiamo iniziare considerando un caso semplice e specifico: una popolazione finita di dimensioni ridotte. Sebbene stiamo esaminando un caso particolare, è fondamentale notare che le proprietà e i principi che analizzeremo in questo contesto sono perfettamente applicabili a popolazioni di qualsiasi dimensione.\nLa distribuzione campionaria ci dà una visione della variazione che potremmo aspettarci nelle stime derivate da diversi campioni estratti dalla stessa popolazione. Ogni volta che preleviamo un campione, otteniamo una stima diversa per il parametro di interesse (come la media). La distribuzione campionaria ci mostra come queste stime sono distribuite e ci aiuta a comprendere quanto siano affidabili.\nIn termini pratici, se vogliamo calcolare la media della popolazione, non possiamo farlo direttamente (a meno di non avere accesso all’intera popolazione). Invece, possiamo estrarre un campione casuale e calcolare la media del campione come stima di \\(\\mu\\). Tuttavia, un altro campione fornirà una stima leggermente diversa. La distribuzione campionaria ci aiuta a capire quanto queste stime varino da campione a campione e ci fornisce un quadro completo dell’incertezza legata al processo di stima.\nNella simulazione seguente, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL’istogramma seguente descrive la distribuzione di frequenza della popolazione.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nconteggi, intervalli, _ = plt.hist(\n    x,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nStampiamo gli intervalli utilizzati per l’istogramma.\n\nprint(\"Intervalli utilizzati per l'istogramma:\", intervalli)\nprint(\"Frequenze relative utilizzate per l'istogramma:\", conteggi)\n\nIntervalli utilizzati per l'istogramma: [2.  2.7 3.4 4.1 4.8 5.5]\nFrequenze relative utilizzate per l'istogramma: [0.35714286 0.         0.         0.35714286 0.71428571]\n\n\nLe frequenze assolute si ottengono usando l’argomento density=False.\n\nconteggi, intervalli, _ = plt.hist(\n    x,\n    bins=5,\n    density=False,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\nprint(\"Frequenze assolute utilizzate per l'istogramma:\", conteggi)\n\n\n\n\n\n\n\n\nFrequenze assolute utilizzate per l'istogramma: [1. 0. 0. 1. 2.]\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nSupponiamo ora di voler considerare l’estrazione di tutti i possibili campioni di dimensione \\(n\\) = 2 da una popolazione rappresentata dall’array x. Per fare ciò, possiamo fare uso di uno strumento di programmazione, come la funzione product del modulo itertools in Python.\nSpecificamente, possiamo utilizzare product con l’argomento repeat impostato a 2, che indica che vogliamo formare tutte le possibili coppie di valori. In altre parole, stiamo cercando tutte le combinazioni in cui ogni valore nell’array x può essere abbinato a se stesso o a un altro valore nell’array.\nDopo aver utilizzato la funzione product, otteniamo una lista di tuple, che rappresenta tutte le possibili coppie di valori. Possiamo convertire questa lista in un array NumPy più maneggevole utilizzando la funzione np.array. Stampando il risultato, otteniamo un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie che possono essere formate dall’array x.\nQuesta rappresentazione di tutte le possibili coppie è coerente con un concetto matematico fondamentale: se stiamo scegliendo 2 elementi da un insieme di 4, e ogni elemento può essere scelto più di una volta (ossia con ripetizione), il numero totale di possibili combinazioni sarà $4^2 = 16 $. Questo si spiega dal fatto che ci sono 4 scelte per il primo elemento e 4 scelte per il secondo elemento, risultando in un totale di \\(4 \\times 4 = 16\\) possibili coppie.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nConvertiamo l’output di itertools.product in un array NumPy per sfruttare le funzionalità di questa libreria. L’array risultante, samples, è un array 2D, dove ogni riga rappresenta una coppia di valori.\n\nsamples.shape\n\n(16, 2)\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), possiamo utilizzare la funzione mean del modulo NumPy e applicarla lungo l’asse delle colonne dell’array di coppie di valori. In questo modo otterremo un array unidimensionale contenente la media di ciascuna coppia di valori. Questo insieme di valori costituisce la distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nLa funzione np.mean(samples, axis=1) calcola la media lungo l’asse specificato, che in questo caso è l’asse 1. In NumPy, l’asse 0 rappresenta le righe (verticale) e l’asse 1 rappresenta le colonne (orizzontale).\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x è fornita qui sotto.\n\nplt.hist(\n    means,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\n_ = plt.show()\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x.\n\n\n32.2.2 Valore atteso della media campionaria\nSupponiamo che $ X_1, X_2, , X_n $ siano variabili aleatorie iid con valore atteso $ $ e varianza $ ^2 $. Vogliamo trovare il valore atteso della media campionaria:\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\]\nEcco la dimostrazione:\n\\[\n\\begin{align*}\n\\mathbb{E}(\\bar{X}) & = \\mathbb{E}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\mathbb{E}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) \\\\\n& = \\frac{1}{n} \\sum_{i=1}^n \\mu \\\\\n& = \\frac{1}{n} \\cdot n \\cdot \\mu \\\\\n& = \\mu\n\\end{align*}\n\\]\nQuindi, il valore atteso della media campionaria di $ n $ variabili iid è uguale al valore atteso di ciascuna variabile singola, che in questo caso è $ $.\nVerifichiamo che ciò sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\n\n\n32.2.3 Varianza della media campionaria\nDato che le variabili \\(X_1, X_2, \\ldots, X_n\\) sono indipendenti ed identicamente distribuite (iid) con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), possiamo calcolare la varianza della media campionaria \\(\\bar{X}\\) come segue:\n\\[\n\\begin{align*}\n\\text{Var}(\\bar{X}) & = \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\text{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(X_i) \\quad \\text{(dato che le $X_i$ sono indipendenti, i termini incrociati si annullano)} \\\\\n& = \\frac{1}{n^2} \\sum_{i=1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2} \\cdot n \\cdot \\sigma^2 \\\\\n& = \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nQuindi, la varianza della media campionaria di \\(n\\) variabili iid è uguale alla varianza di ciascuna variabile singola divisa per \\(n\\), che in questo caso è \\(\\sigma^2/n\\).\nPer l’esempio in discussione, il valore della varianza delle medie dei campioni è dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione è diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione è diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, possiamo sottolineare due risultati centrali che emergono dall’analisi delle medie campionarie:\n\nMedia delle medie campionarie e media della popolazione: La media della distribuzione delle medie campionarie è identica alla media della popolazione. In termini matematici, questo significa che il valore atteso della media dei campioni (con ripetizione) da una popolazione (finita o infinita) con media $ $ è:\n\n\\[\n   \\mathbb{E}(\\bar{X}_n) = \\mu.\n\\]\n\nVarianza delle medie campionarie e varianza della popolazione: La varianza della distribuzione delle medie campionarie è inferiore alla varianza della popolazione e, precisamente, è pari alla varianza della popolazione divisa per la dimensione del campione:\n\n\\[\n   \\mathbb{V}(\\bar{X}_n) = \\frac{\\sigma^2}{n}.\n\\]\nQuesti risultati, che abbiamo verificato empiricamente attraverso la simulazione, ci offrono una comprensione profonda del comportamento delle medie campionarie.\nInoltre, è importante notare che il comportamento della distribuzione delle medie campionarie dipende dalla forma della distribuzione della popolazione stessa:\n\nSe la popolazione segue una distribuzione normale, allora la distribuzione delle medie dei campioni sarà anch’essa normale.\nSe la popolazione non segue una distribuzione normale, il teorema del limite centrale entra in gioco, assicurando che, man mano che le dimensioni del campione aumentano, la distribuzione delle medie dei campioni converga a una distribuzione normale.\n\nQuesti principi sono fondamentali in statistica e forniscono la base per molte tecniche di inferenza e modellazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "href": "chapters/probability/08_sampling_distr.html#errore-standard-e-rappresentazione-dellincertezza-inferenziale",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.3 Errore standard e rappresentazione dell’incertezza inferenziale",
    "text": "32.3 Errore standard e rappresentazione dell’incertezza inferenziale\nNella statistica inferenziale, l’errore standard è una misura frequentemente utilizzata per rappresentare l’incertezza legata a un parametro stimato, conosciuta anche come incertezza inferenziale. L’errore standard quantifica quanto possa variare la stima di una statistica da un campione all’altro; un errore standard minore indica una stima più precisa, mentre uno maggiore implica maggiore incertezza. Spesso, le rappresentazioni grafiche includono gli errori standard nella forma di “media più o meno uno (o due) errori standard.” Questa espressione fornisce una gamma di valori entro cui è plausibile che ricada il valore vero del parametro della popolazione.\nL’uso dell’errore standard nei grafici non è soltanto una convenzione; esso è uno strumento per quantificare e visualizzare l’incertezza inferenziale. Contribuisce alla comprensione dell’affidabilità delle stime ottenute dai dati campionari, permettendo di valutare quanto le stime possano variare se si prendesse un altro campione dalla stessa popolazione. Tuttavia, è importante notare che questo utilizzo dell’errore standard può essere problematico (Ward & Mann, 2022).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "href": "chapters/probability/08_sampling_distr.html#legge-dei-grandi-numeri",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.4 Legge dei Grandi Numeri",
    "text": "32.4 Legge dei Grandi Numeri\nLa Legge dei Grandi Numeri (LLN) è un principio fondamentale della teoria delle probabilità che stabilisce come, incrementando il numero \\(n\\) di osservazioni, la media campionaria \\(\\bar{X}_n\\) tenda asintoticamente alla media teorica \\(\\mu\\). La LLN si articola in due varianti: la versione “forte” e quella “debole”, le quali differiscono per il tipo di convergenza verso la media attesa.\n\n32.4.1 Versione Forte della Legge dei Grandi Numeri (SLLN)\nLa SLLN afferma che la media campionaria $ {X}_n $ converge quasi certamente alla media teorica \\(\\mu\\), ovvero la convergenza avviene con probabilità 1. Questo implica che, per quasi ogni possibile sequenza di eventi nell’insieme campionario \\(S\\), \\(\\bar{X}_n(s)\\) tende a \\(\\mu\\), ad eccezione di un insieme di eventi \\(B_0\\) la cui probabilità è zero. In termini tecnici, si dice che \\(\\bar{X}_n\\) converge a \\(\\mu\\) “quasi certamente”.\n\n\n32.4.2 Versione Debole della Legge dei Grandi Numeri (WLLN)\nLa WLLN afferma che, per ogni \\(\\epsilon &gt; 0\\), la probabilità che la media campionaria \\(\\bar{X}_n\\) si discosti da \\(\\mu\\) di una quantità maggiore di \\(\\epsilon\\) tende a zero all’aumentare di \\(n\\). Questo fenomeno è definito come convergenza in probabilità verso la media teorica \\(\\mu\\).\n\n\n32.4.3 Implicazioni e Applicazioni\nLa Legge dei Grandi Numeri riveste un ruolo cruciale nel campo delle simulazioni, della statistica e, più in generale, nelle discipline scientifiche. La generazione di dati attraverso numerose repliche indipendenti di un esperimento, sia in ambito simulativo che empirico, implica l’utilizzo della media campionaria come stima affidabile della media teorica della variabile di interesse. In pratica, la LLN fornisce una base teorica per l’affidabilità delle stime medie ottenute da grandi campioni di dati, sottolineando come, a fronte di un numero elevato di osservazioni, le fluttuazioni casuali tendano ad annullarsi, convergendo verso un valore stabile e prevedibile.\n\nEsempio 32.1 Siano \\(X_1, X_2, \\ldots\\) variabili aleatorie indipendenti e identicamente distribuite secondo una distribuzione di Bernoulli con parametro \\(1/2\\). Interpretando gli \\(X_j\\) come indicatori di “Testa” in una sequenza di lanci di una moneta equa, \\(\\bar{X}_n\\) rappresenta la proporzione di “Testa” dopo \\(n\\) lanci. La Legge Forte dei Grandi Numeri (SLLN) afferma che, con probabilità 1, la sequenza di variabili aleatorie \\(\\bar{X}_1, \\bar{X}_2, \\bar{X}_3, \\ldots\\) convergerà a \\(1/2\\) quando si cristallizza in una sequenza di numeri reali. Matematicamente parlando, esistono scenari improbabili come una sequenza infinita di “Testa” (HHHHHH…) o sequenze irregolari come HHTHHTHHTHHT…, ma queste hanno una probabilità collettiva di zero di verificarsi. La Legge Debole dei Grandi Numeri (WLLN) stabilisce che, per ogni \\(\\epsilon &gt; 0\\), la probabilità che \\(\\bar{X}_n\\) sia distante più di \\(\\epsilon\\) da \\(1/2\\) può essere resa arbitrariamente piccola aumentando \\(n\\).\nCome illustrazione, abbiamo simulato sei sequenze di lanci di una moneta equa e, per ciascuna sequenza, abbiamo calcolato \\(\\bar{X}_n\\) in funzione di \\(n\\). Ovviamente, nella realtà non possiamo effettuare un numero infinito di lanci, quindi ci siamo fermati dopo 300 lanci. Il grafico seguente mostra \\(\\bar{X}_n\\) in funzione di $ n $ per ciascuna delle sei sequenze. All’inizio, notiamo una certa variazione nella proporzione cumulativa di “Testa”. Tuttavia, con l’aumentare del numero di lanci, la varianza $ ({X}_n) $ diminuisce progressivamente e \\(\\bar{X}_n\\) tende a \\(1/2\\).\n\n# Number of sequences\nnum_sequences = 6\n# Number of tosses\nnum_tosses = 300\n# Initialize a figure\nplt.figure()\n\n# Loop through each sequence\nfor i in range(num_sequences):\n    \n    # Generate a sequence of fair coin tosses (Heads=1, Tails=0)\n    coin_tosses = np.random.choice([0, 1], num_tosses)\n    \n    # Calculate the running proportion of Heads\n    running_proportion = np.cumsum(coin_tosses) / np.arange(1, num_tosses + 1)\n    \n    # Plot the running proportion as a function of the number of tosses\n    plt.plot(np.arange(1, num_tosses + 1), running_proportion, label=f'Sequence {i+1}')\n\n# Plotting the true mean (1/2)\nplt.axhline(y=0.5, color='r', linestyle='--', label='True Mean (1/2)')\n\n# Adding labels and title\nplt.xlabel('Number of Tosses')\nplt.ylabel('Running Proportion of Heads')\nplt.title('Running Proportion of Heads in Six Sequences of Fair Coin Tosses')\nplt.legend()\nplt.legend(fontsize='small')\nplt.show()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "href": "chapters/probability/08_sampling_distr.html#teorema-del-limite-centrale",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.5 Teorema del Limite Centrale",
    "text": "32.5 Teorema del Limite Centrale\nIl teorema del limite centrale è un risultato fondamentale in statistica che è stato dimostrato per la prima volta da Laplace nel 1812. Esso fornisce una spiegazione matematica per il motivo per cui la distribuzione normale appare così frequentemente nei fenomeni naturali. Ecco la formulazione essenziale:\n\n32.5.1 Enunciato\nSupponiamo di avere una sequenza di variabili aleatorie indipendenti ed identicamente distribuite (i.i.d.), \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\), ciascuna con valore atteso \\(\\mathbb{E}(Y_i) = \\mu\\) e deviazione standard \\(SD(Y_i) = \\sigma\\). Definiamo una nuova variabile casuale come la media aritmetica di queste variabili:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nAllora, quando \\(n\\) tende all’infinito, la distribuzione di \\(Z\\) convergerà a una distribuzione normale con media \\(\\mu\\) e deviazione standard ridotta di un fattore \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\n\n\n32.5.2 Significato e generalizzazione\nIl TLC non si applica solo alle variabili casuali con la stessa distribuzione, ma può essere esteso a variabili casuali indipendenti con aspettative e varianze finite. La potenza del teorema sta nella sua capacità di descrivere fenomeni che sono il risultato di molteplici effetti additivi indipendenti. Anche se questi effetti possono avere distribuzioni diverse, la loro somma tende a una distribuzione normale.\nAd esempio, l’altezza degli esseri umani adulti può essere vista come la somma di molti fattori genetici e ambientali indipendenti. Indipendentemente dalla distribuzione individuale di questi fattori, la loro combinazione tende a formare una distribuzione normale. Questa universalità rende la distribuzione normale una buona approssimazione per molti fenomeni naturali.\n\nEsempio 32.2 Per visualizzare il TLC in azione, si può condurre una simulazione. Immaginiamo una popolazione iniziale con una distribuzione asimmetrica, come una Beta(2, 1). Estraiamo 50.000 campioni di dimensione \\(n\\) da questa popolazione e osserviamo come la distribuzione campionaria di tali medie converga a una distribuzione normale. Questa simulazione fornirà un’illustrazione concreta dell’efficacia del TLC nell’approssimare distribuzioni reali.\n\n# parameters of the beta distribution\na=2\nb=1\n\ndef plot_samples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n            v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together\n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(\n        sample_means,\n        color=color_fill,\n        edgecolor=color_edge,\n    )\n    ax2 = ax.twinx()\n    sns.lineplot(x=x, y=y, ax=ax2, color=color_edge)\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l’ampiezza campionaria è 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplot_samples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non è certamente Normale, inizia ad avvicinarsi alla gaussianità.\n\nplot_samples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c’è ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l’approssimazione migliora.\n\nplot_samples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplot_samples(30)\n\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) stabilisce che, a meno che non si stia lavorando con campioni estremamente piccoli, è possibile approssimare con buona precisione la distribuzione campionaria della media dei campioni utilizzando la distribuzione Normale. Questo vale indipendentemente dalla forma specifica della distribuzione della popolazione da cui sono tratti i campioni. In altre parole, quando si lavora con campioni di dimensioni sufficienti, il TLC offre una formula concreta per descrivere la forma della distribuzione campionaria della media dei campioni. Ciò avviene anche se non si hanno informazioni dettagliate sulla popolazione, come la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\), ed è espresso dalla relazione \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/probability/08_sampling_distr.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.6 Distribuzioni campionarie di altre statistiche",
    "text": "32.6 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente è possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l’approssimazione empirica della distribuzione campionaria del valore massimo del campione. È chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sarà maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax, color=color_fill)\nax2 = ax.twinx()\nsns.lineplot(x=x, y=y, ax=ax2, color=color_edge);\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni è particolarmente interessante. Usiamo la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nUna volta compresa la procedura, possiamo creare un grafico che rappresenta l’approssimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza. Sapendo che la varianza della popolazione è uguale a \\(15^2\\), abbiamo utilizzato la simulazione per stimare la varianza della popolazione. Tuttavia, il risultato ottenuto è stato interessante: in media, l’utilizzo della formula precedente ha portato a una stima della varianza della popolazione troppo piccola. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard\n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find\n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax, color=color_fill)\n\nnp.mean(sample_vars)\n\n177.69769879129643\n\n\n\n\n\n\n\n\n\nAbbiamo già visto come questo problema trova una semplice soluzione nel momento in cui usiamo \\(n-1\\) al denominatore.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax, color=color_fill)\n\nnp.mean(sample_vars)\n\n226.51417694562372\n\n\n\n\n\n\n\n\n\nLa differenza tra la stima di un parametro e il valore vero del parametro è chiamata errore della stima. Uno stimatore si dice non distorto (unbiased) se la media delle sue stime su molteplici campioni ipotetici è uguale al valore del parametro che si vuole stimare. In altre parole, l’errore medio di stima è zero.\nIn questo capitolo abbiamo visto che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) è uno stimatore non distorto di \\(\\mu\\) e che \\(\\frac{\\sum_{i=1}^n{(^2)}}{n-1}\\) è uno stimatore non distorto di \\(\\sigma^2\\). Questo significa che tali stimatori hanno una distribuzione campionaria centrata sul vero valore del parametro.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#considerazioni-conclusive",
    "href": "chapters/probability/08_sampling_distr.html#considerazioni-conclusive",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.7 Considerazioni conclusive",
    "text": "32.7 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/08_sampling_distr.html#watermark",
    "href": "chapters/probability/08_sampling_distr.html#watermark",
    "title": "32  Stime, stimatori e parametri",
    "section": "32.8 Watermark",
    "text": "32.8 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nWard, A., & Mann, T. (2022). Control yourself: Broad implications of narrowed attention. Perspectives on Psychological Science, 17(6), 1692–1703.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Stime, stimatori e parametri</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html",
    "href": "chapters/probability/09_joint_prob.html",
    "title": "33  Probabilità congiunta",
    "section": "",
    "text": "Introduzione\nIn questo capitolo ci proponiamo di analizzare in dettaglio il concetto di probabilità congiunta, focalizzando l’attenzione sul caso di variabili aleatorie discrete. La probabilità congiunta rappresenta la misura della probabilità che due o più eventi si verifichino simultaneamente.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#sec-fun-join-prob",
    "href": "chapters/probability/09_joint_prob.html#sec-fun-join-prob",
    "title": "33  Probabilità congiunta",
    "section": "33.1 Funzione di Probabilità Congiunta",
    "text": "33.1 Funzione di Probabilità Congiunta\nFinora abbiamo analizzato la probabilità associata a un singolo evento, o più precisamente, a un singolo valore assunto da una variabile aleatoria. Tuttavia, spesso siamo interessati a studiare la relazione tra due o più eventi. La funzione di probabilità congiunta ci permette di estendere il concetto di probabilità al caso di più variabili aleatorie, descrivendo la probabilità che queste assumano specifici valori contemporaneamente.\n\n33.1.1 Esempio: Lancio di Tre Monete Equilibrate\nPer comprendere meglio il concetto di probabilità congiunta, immaginiamo di lanciare tre monete. Tutti i possibili risultati di questo esperimento (ad esempio, tre teste, due teste e una croce, ecc.) costituiscono quello che chiamiamo spazio campionario. In questo caso, lo spazio campionario \\(\\Omega\\) è dato da:\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\},\n\\]\ndove \\(T\\) indica “testa” e \\(C\\) indica “croce”. Assumendo che ogni lancio sia indipendente dagli altri, ogni risultato nello spazio campionario \\(\\Omega\\) ha la stessa probabilità di verificarsi, ovvero \\(1/8\\).\nDefiniamo ora le seguenti variabili casuali sullo spazio campionario \\(\\Omega\\):\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) rappresenta il numero totale di teste ottenute nei tre lanci.\n\\(Y \\in \\{0, 1\\}\\) indica se il primo lancio ha dato testa (\\(1\\)) oppure croce (\\(0\\)).\n\nLa tabella seguente mostra lo spazio campionario con i valori di \\(X\\) e \\(Y\\) associati a ciascun esito, insieme alla probabilità di ciascun evento \\(\\omega\\):\n\n\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\nOra possiamo determinare la probabilità congiunta per ogni coppia \\((X, Y)\\), che rappresenta la probabilità di ottenere un determinato numero di teste \\(X\\) e un determinato risultato per il primo lancio \\(Y\\). Ad esempio:\n\\[P(X=0, Y=0) = P(\\text{CCC}) = 1/8,\\]\ne così via per le altre coppie.\nLe probabilità congiunte per tutte le possibili combinazioni \\((X, Y)\\) sono calcolate come segue:\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= 1/8, \\\\\nP(X = 1, Y = 0) &= P(\\text{CCT}) + P(\\text{CTC}) = 1/4, \\\\\nP(X = 1, Y = 1) &= P(\\text{TCC}) = 1/8, \\\\\nP(X = 2, Y = 0) &= P(\\text{CTT}) = 1/8, \\\\\nP(X = 2, Y = 1) &= P(\\text{TTC}) + P(\\text{TCT}) = 1/4, \\\\\nP(X = 3, Y = 1) &= P(\\text{TTT}) = 1/8.\n\\end{aligned}\n\\]\nQueste probabilità costituiscono la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) (numero di teste) e \\(Y\\) (testa al primo lancio). Questa distribuzione fornisce un quadro completo delle probabilità per tutte le combinazioni di risultati di queste due variabili.\n\n\n33.1.2 Definizione: Funzione di Probabilità Congiunta\nLa funzione di probabilità congiunta di due variabili casuali \\(X\\) e \\(Y\\) associa a ogni coppia \\((x, y)\\) una probabilità \\(P(X = x, Y = y)\\).\n\n\n33.1.3 Proprietà\nUna distribuzione di probabilità congiunta deve soddisfare:\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\) per ogni coppia \\((x_i, y_j)\\),\n\\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1\\), ovvero la somma delle probabilità su tutte le coppie deve essere 1.\n\n\n\n33.1.4 Calcolo della Probabilità di Eventi Specifici\nData la distribuzione di probabilità congiunta, possiamo determinare la probabilità di eventi definiti in termini delle variabili aleatorie \\(X\\) e \\(Y\\). Ad esempio, per trovare la probabilità che \\(X + Y \\leq 1\\), sommiamo le probabilità di tutte le coppie \\((x, y)\\) che soddisfano questa condizione, ottenendo \\(P(X+Y \\leq 1) = 3/8\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "href": "chapters/probability/09_joint_prob.html#marginalizzazione",
    "title": "33  Probabilità congiunta",
    "section": "33.2 Marginalizzazione",
    "text": "33.2 Marginalizzazione\nImmagina di condurre uno studio sul livello di stress tra studenti universitari, raccogliendo dati su variabili come l’anno di corso, il genere, il supporto sociale e il livello di stress. Se desideri comprendere come il livello di stress varia in funzione dell’anno di corso, indipendentemente dal genere e dal supporto sociale, puoi utilizzare la marginalizzazione.\nLa marginalizzazione consente di ottenere una distribuzione di probabilità focalizzata su una o più variabili di interesse, “eliminando” dal calcolo le variabili non rilevanti. Nel nostro esempio, per ottenere la distribuzione marginale del livello di stress rispetto all’anno di corso, occorre sommare (o integrare, nel caso di variabili continue) le probabilità associate a tutte le combinazioni di genere e supporto sociale, mantenendo fisso l’anno di corso. In questo modo, otteniamo una distribuzione che descrive come il livello di stress varia solo in relazione all’anno di corso.\nIl termine “marginalizzazione” deriva dalle tabelle di contingenza: quando rappresentiamo una distribuzione di probabilità congiunta in una tabella, le probabilità marginali—che descrivono la distribuzione di una variabile indipendentemente dalle altre—si trovano nei margini della tabella (ovvero nelle righe e colonne finali).\n\n33.2.1 Formalizzazione della Marginalizzazione\nData una distribuzione di probabilità congiunta \\(P(X, Y)\\) di due variabili casuali \\(X\\) e \\(Y\\), possiamo ottenere la distribuzione marginale di \\(X\\) sommando tutte le probabilità associate a \\(Y\\). Formalmente:\n\\[\nP(X = x) = \\sum_y P(X = x, Y = y),\n\\]\ndove \\(P(X = x, Y = y)\\) rappresenta la probabilità congiunta di \\(X\\) e \\(Y\\). La marginalizzazione garantisce inoltre che le distribuzioni siano normalizzate, cioè che le somme delle probabilità marginali per ciascuna variabile siano uguali a 1:\n\\[\n\\sum_x P(X = x) = 1 \\quad \\text{e} \\quad \\sum_y P(Y = y) = 1.\n\\]\nNel caso di variabili continue, questa operazione di somma viene sostituita dall’integrazione.\nPer chiarire, consideriamo il seguente esempio. Supponiamo di studiare l’efficacia di una terapia cognitivo-comportamentale per l’ansia, includendo variabili come l’età dei partecipanti e il livello iniziale di ansia. Se vogliamo valutare l’efficacia della terapia a prescindere dall’età e dal livello di ansia iniziale, marginalizziamo rispetto a queste due variabili, ottenendo così una distribuzione che riflette solo l’associazione tra terapia e riduzione dell’ansia.\nIn sintesi, la marginalizzazione:\n\npermette di estrarre distribuzioni di probabilità per variabili specifiche, “dimenticando” quelle non rilevanti;\nconsiste nel sommare o integrare le probabilità attraverso tutte le possibili combinazioni delle variabili non rilevanti, concentrandosi su quelle di interesse.\n\nIn conclusione, la marginalizzazione è uno strumento essenziale per l’analisi statistica, facilitando lo studio delle relazioni tra variabili complesse e aiutandoci a isolare gli effetti delle variabili di interesse in modo rigoroso.\n\nEsempio 33.1 Per fare un esempio, prendiamo come riferimento l’esperimento del lancio di tre monete equilibrate descritto precedentemente. Per calcolare le probabilità marginali di \\(X\\) e \\(Y\\), sommiamo le probabilità congiunte su una dimensione. La probabilità marginale di \\(X\\), \\(P_X\\), si ottiene sommando le probabilità lungo le colonne per ciascun valore fisso di \\(X\\); analogamente, la probabilità marginale di \\(Y\\), \\(P_Y\\), si calcola sommando le probabilità lungo le righe per ciascun valore fisso di \\(Y\\).\nLa tabella seguente mostra la distribuzione di probabilità congiunta \\(P(X, Y)\\) e le probabilità marginali \\(P(X)\\) e \\(P(Y)\\):\n\n\n\n\\(x \\setminus y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n33.2.2 Marginalizzazione per Variabili Casuali Continue\nNell’ambito della statistica bayesiana, il concetto di marginalizzazione gioca un ruolo cruciale. Un esempio di equazione che emerge da questo processo è:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) \\, d\\theta = \\int_{\\theta} p(y \\mid \\theta) p(\\theta) \\, d\\theta,\n\\]\ndove \\(y\\) e \\(\\theta\\) sono variabili casuali continue, con \\(y\\) che rappresenta i dati osservati e \\(\\theta\\) i parametri di un modello statistico. Questa equazione illustra come, in un contesto continuo, la marginalizzazione possa essere vista come l’estensione dell’approccio discreto a un continuum di valori per le variabili in esame.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "href": "chapters/probability/09_joint_prob.html#indipendenza-tra-variabili-casuali",
    "title": "33  Probabilità congiunta",
    "section": "33.3 Indipendenza tra Variabili Casuali",
    "text": "33.3 Indipendenza tra Variabili Casuali\nL’indipendenza tra variabili casuali è un concetto fondamentale in statistica e probabilità, parallelo all’idea di indipendenza tra eventi. Due variabili casuali si considerano indipendenti quando l’informazione su una non altera in alcun modo la distribuzione di probabilità dell’altra. Questa sezione offre una formalizzazione dell’indipendenza tra due variabili casuali discrete, basata sulla loro distribuzione di probabilità congiunta.\n\n33.3.1 Definizione di Indipendenza\nDue variabili casuali \\(X\\) e \\(Y\\), con una distribuzione congiunta, sono definite indipendenti se, e solo se, per ogni coppia di valori \\((x, y)\\) si verifica che:\n\\[\nP_{X, Y}(x, y) = P_X(x) \\cdot P_Y(y).\n\\]\nIn termini pratici, ciò significa che se \\(X\\) e \\(Y\\) sono variabili casuali discrete indipendenti, la loro distribuzione di probabilità congiunta è il prodotto delle rispettive distribuzioni di probabilità marginali. Se invece \\(P_{X, Y}(x, y) \\neq P_X(x) \\cdot P_Y(y)\\), le variabili non sono indipendenti e si dicono associate o dipendenti.\nQuesto concetto si applica anche alle variabili casuali continue, mantenendo la stessa logica: l’indipendenza si verifica quando la funzione di densità congiunta è il prodotto delle funzioni di densità marginali.\n\n\n33.3.2 Associazione tra Variabili Casuali\nQuando due variabili casuali non sono indipendenti, si descrivono come associate o dipendenti. In questo contesto, è utile introdurre il concetto di covarianza (e correlazione) come misura del grado di associazione lineare tra due variabili casuali. La covarianza e la correlazione quantificano in che modo la variazione di una variabile è associata alla variazione dell’altra, fornendo un indice della loro interdipendenza lineare.\nRiepilogando, l’indipendenza tra variabili casuali è un concetto chiave per comprendere le relazioni tra fenomeni aleatori. Riconoscere se due variabili sono indipendenti o associate è fondamentale per l’analisi statistica e per la modellazione di relazioni causali o di correlazione tra variabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#covarianza",
    "href": "chapters/probability/09_joint_prob.html#covarianza",
    "title": "33  Probabilità congiunta",
    "section": "33.4 Covarianza",
    "text": "33.4 Covarianza\nLa covarianza è un parametro statistico che quantifica il grado e la direzione della relazione lineare tra due variabili casuali, \\(X\\) e \\(Y\\). In termini semplici, misura come le variazioni di una variabile si accompagnano a quelle dell’altra. Per esempio, considerando l’altezza e il peso di giraffe, scopriremmo che queste due misure tendono ad aumentare insieme, evidenziando così una covarianza positiva. La covarianza è denotata come \\(Cov(X, Y) = \\sigma_{xy}\\).\n\n33.4.1 Definizione di Covarianza\nLa covarianza tra due variabili casuali \\(X\\) e \\(Y\\) è definita come:\n\\[\nCov(X, Y) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right],\n\\]\ndove \\(\\mathbb{E}[X]\\) e \\(\\mathbb{E}[Y]\\) rappresentano i valori attesi (o medie) di \\(X\\) ed \\(Y\\), rispettivamente.\nIn termini più espliciti, la covarianza può essere espressa come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y),\n\\]\ndove \\(\\mu_X\\) e \\(\\mu_Y\\) sono le medie di \\(X\\) ed \\(Y\\), e \\(f(x, y)\\) è la funzione di probabilità congiunta delle variabili.\nQuesta definizione mostra una stretta analogia con la varianza, che è la covarianza di una variabile con se stessa:\n\\[\n\\mathbb{V}(X) = Cov(X, X).\n\\]\nInoltre, la covarianza può essere calcolata attraverso la relazione:\n\\[\nCov(X, Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\]\n\n\n33.4.2 Dimostrazione\nLa formula alternativa per la covarianza si dimostra come segue:\n\\[\n\\begin{align}\nCov(X, Y) &= \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right) \\left(Y - \\mathbb{E}[Y]\\right)\\right]\\\\\n&= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y).\n\\end{align}\n\\]\n\n\n33.4.3 Esempio di Calcolo della Covarianza\nConsideriamo le variabili casuali \\(X\\) e \\(Y\\) con medie \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). La covarianza di \\(X\\) e \\(Y\\) si calcola come:\n\\[\nCov(X, Y) = \\sum_{(x, y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y) = \\frac{1}{4}.\n\\]\nQuesto risultato si può ottenere anche dalla formula alternativa, calcolando prima \\(\\mathbb{E}(XY)\\):\n\\[\n\\mathbb{E}(XY) = 1.0.\n\\]\nAllora, la covarianza tra \\(X\\) e \\(Y\\) è:\n\\[\nCov(X, Y) = 1 - 1.5 \\cdot 0.5 = 0.25.\n\\]\n\nEsempio 33.2 Per fare un esempio con Python, consideriamo l’esempio precedente nel quale \\(X\\) è il numero che si ottiene dal lancio di tre monete equilibrate e \\(Y\\) è il numero di teste al primo lancio. Troviamo \\(Cov(X, Y)\\).\nCreiamo il prodotto cartesiano che si ottiene per tutti i possibili valori \\(X\\) e i possibili valori \\(Y\\).\n\nc3 = np.arange(0, 4)\nc1 = np.arange(0, 2)\nsample = [(i, j) for i in c1 for j in c3]\nsample\n\nIl primo numero di ogni coppia rappresenta il valore di \\(Y\\), mentre il secondo numero è il valore di \\(X\\). Come abbiamo visto in precedenza, però, quete coppie di valori \\(X, Y\\) non hanno tutte la stessa probabilità di verificarsi. Infatti, la probabilità che ciascuna coppia \\(X, Y\\) si osservi è data, in sequenza, dai valori 1/8, 2/8, 1/8, 0, 0, 1/8, 2/8, 1/8. Questi valori rappresentano la distribuzione di massa di probabilità congiunta delle variabili casuali \\(X\\) e \\(Y\\). Possiamo quindi applicare l’eq. {eq}eq-cov-def-rv:\n\nres = []\n\npmf = np.array([1 / 8, 2 / 8, 1 / 8, 0, 0, 1 / 8, 2 / 8, 1 / 8])\n\nfor i in range(8):\n    res.append((sample[i][0] - 0.5) * (sample[i][1] - 1.5) * pmf[i])\n\nsum(res)\n\nLa covarianza tra \\(X\\) e \\(Y\\) è dunque uguale a 0.25.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#correlazione",
    "href": "chapters/probability/09_joint_prob.html#correlazione",
    "title": "33  Probabilità congiunta",
    "section": "33.5 Correlazione",
    "text": "33.5 Correlazione\nMentre la covarianza fornisce un’indicazione della tendenza di due variabili casuali a variare insieme, essa è influenzata dalle unità di misura delle variabili, rendendo difficile valutare l’intensità della loro relazione lineare. Per ovviare a questo, si utilizza la correlazione, che normalizza la covarianza attraverso le deviazioni standard delle variabili, offrendo così una misura standardizzata dell’associazione lineare tra di esse.\n\nDefinizione 33.1 Il coefficiente di correlazione tra due variabili casuali \\(X\\) e \\(Y\\), denotato come \\(\\rho(X,Y)\\) o \\(\\rho_{X,Y}\\), è definito come:\n\\[\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}},\n\\]\ndove \\(\\mathbb{V}(X)\\) e \\(\\mathbb{V}(Y)\\) rappresentano le varianze di \\(X\\) e \\(Y\\), rispettivamente.\n\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un valore adimensionale, ovvero non dipende dalle unità di misura delle variabili, e varia nell’intervallo \\(-1 \\leq \\rho \\leq 1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#proprietà-1",
    "href": "chapters/probability/09_joint_prob.html#proprietà-1",
    "title": "33  Probabilità congiunta",
    "section": "33.6 Proprietà",
    "text": "33.6 Proprietà\n\nCovarianza con una Costante: La covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è sempre nulla: \\(Cov(c, X) = 0\\).\nSimmetria: La covarianza è simmetrica: \\(Cov(X,Y) = Cov(Y,X)\\).\nIntervallo di Correlazione: Il coefficiente di correlazione \\(\\rho\\) varia tra -1 e 1: \\(-1 \\leq \\rho(X,Y) \\leq 1\\).\nIndipendenza dalle Unità di Misura: La correlazione è indipendente dalle unità di misura: \\(\\rho(aX, bY) = \\rho(X,Y)\\) per ogni \\(a, b &gt; 0\\).\nRelazione Lineare Perfetta: Se \\(Y = a + bX\\) è una funzione lineare di \\(X\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\).\nCovarianza e Costanti: La covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è \\(Cov(aX, bY) = ab \\, Cov(X,Y)\\).\nVarianza della Somma/Differenza: \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2Cov(X,Y)\\).\nCovarianza e Somma di Variabili: \\(Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z)\\).\nVarianza di una Somma di Variabili Aleatorie: Per variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}(\\sum_{i=1}^n X_i) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i&lt;j} Cov(X_i, X_j)\\).\nCovarianza e Somme di Prodotti: \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_j Y_j) = \\sum_{i=1}^n \\sum_{j=1}^m a_i b_j Cov(X_i, Y_j)\\).\nIndipendenza e Covarianza di Somme: Se \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(Cov(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_j X_j) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i)\\).\n\n\n33.6.1 Incorrelazione\nDue variabili casuali \\(X\\) ed \\(Y\\) si dicono incorrelate, o linearmente indipendenti, se la loro covarianza è nulla:\n\\[\nCov(X,Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)] = 0,\n\\]\nequivalente a dire che \\(\\rho_{XY} = 0\\) e \\(\\mathbb{E}(XY) = \\mathbb{E}(X)\\mathbb{E}(Y)\\).\nQuesta condizione indica una forma di indipendenza più debole rispetto all’indipendenza stocastica. Tuttavia, \\(Cov(X, Y) = 0\\) non implica necessariamente che \\(X\\) ed \\(Y\\) siano stocasticamente indipendenti.\n\nEsempio 33.3 Consideriamo una distribuzione di probabilità congiunta di due variabili aleatorie, \\(X\\) e \\(Y\\), definita come:\n\\[\nf_{XY}(x,y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}, \\\\\n0 & \\text{altrimenti.}\n\\end{array}\n\\right.\n\\]\nQuesto implica che le variabili aleatorie \\(X\\) e \\(Y\\) assumono valori specifici con probabilità uniforme solo per determinate coppie \\((x, y)\\) e zero in tutti gli altri casi.\nDistribuzioni Marginali\nLa distribuzione marginale di \\(X\\) si ottiene sommando le probabilità congiunte su tutti i possibili valori di \\(Y\\), e viceversa per \\(Y\\). Le distribuzioni marginali risultano essere:\n\nPer \\(X\\):\n\\[\nf_X(x) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } x=0, \\\\\n\\frac{1}{2} & \\text{per } x=1, \\\\\n\\frac{1}{4} & \\text{per } x=2.\n\\end{array}\n\\right.\n\\]\nPer \\(Y\\):\n\\[\nf_Y(y) = \\left\\{\n\\begin{array}{ll}\n\\frac{1}{4} & \\text{per } y=-1, \\\\\n\\frac{1}{2} & \\text{per } y=0, \\\\\n\\frac{1}{4} & \\text{per } y=1.\n\\end{array}\n\\right.\n\\]\n\nMedie e Varianze\nCalcoliamo ora le medie e le varianze di \\(X\\) e \\(Y\\):\n\nMedia di \\(X\\):\n\\[\n\\mathbb{E}(X) = 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 1.\n\\]\nVarianza di \\(X\\):\n\\[\n\\mathbb{V}(X) = \\left(0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(X)^2 = \\frac{3}{2} - 1 = \\frac{1}{2}.\n\\]\nMedia di \\(Y\\):\n\\[\n\\mathbb{E}(Y) = (-1) \\cdot \\frac{1}{4} + 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{4} = 0.\n\\]\nVarianza di \\(Y\\):\n\\[\n\\mathbb{V}(Y) = \\left((-1)^2 \\cdot \\frac{1}{4} + 0^2 \\cdot \\frac{1}{2} + 1^2 \\cdot \\frac{1}{4}\\right) - \\mathbb{E}(Y)^2 = \\frac{1}{2}.\n\\]\n\nCovarianza tra X e Y\nLa covarianza si calcola come:\n\\[\nCov(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y),\n\\]\ndove \\(\\mathbb{E}(XY)\\) si trova sommando il prodotto delle coppie di valori \\((x, y)\\) per la loro probabilità congiunta:\n\\[\n\\mathbb{E}(XY) = 0.\n\\]\nDi conseguenza, la covarianza tra \\(X\\) e \\(Y\\) è zero:\n\\[\nCov(X,Y) = 0 - 1 \\cdot 0 = 0.\n\\]\nConclusioni\nSebbene \\(X\\) e \\(Y\\) siano incorrelate (covarianza nulla), ciò non implica la loro indipendenza. L’indipendenza richiede che la funzione di probabilità congiunta si possa esprimere come il prodotto delle funzioni di probabilità marginali per ogni \\(x\\) e \\(y\\), condizione che non si verifica in questo caso. Quindi, nonostante l’assenza di correlazione, \\(X\\) e \\(Y\\) non sono indipendenti, dimostrando che l’incorrelazione non garantisce l’indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#variabili-continue",
    "href": "chapters/probability/09_joint_prob.html#variabili-continue",
    "title": "33  Probabilità congiunta",
    "section": "33.7 Variabili continue",
    "text": "33.7 Variabili continue\nConsideriamo ora le distribuzioni di densità. Nella figura successiva, tratta da Martin (2024), vediamo una rappresentazione della relazione tra la probabilità congiunta \\(p(A,B)\\), le probabilità marginali \\(p(A)\\) e \\(p(B)\\), e le probabilità condizionali \\(p(A \\mid B)\\).\n\n\n\nDistribuzioni di densità (figura tratta da Martin (2024)).\n\n\n\nProbabilità congiunta \\(p(A,B)\\): rappresenta la probabilità che A e B assumano certi valori contemporaneamente. Per le variabili continue, questa è data dall’integrazione della funzione di densità congiunta su un’area o volume di interesse.\nProbabilità marginale \\(p(A)\\) e \\(p(B)\\): è la probabilità di osservare un particolare valore di A (o B) indipendentemente dal valore di B (o A). Si ottiene integrando la funzione di densità congiunta sull’intero intervallo di valori dell’altra variabile.\nProbabilità condizionale \\(p(A \\mid B)\\): esprime la probabilità di A dato B. Si calcola dividendo la probabilità congiunta per la probabilità marginale di B, applicando la definizione di probabilità condizionale anche nel contesto continuo.\n\nLa transizione dal trattamento delle variabili discrete a quello delle variabili continue richiede un cambiamento di strumenti matematici da somme ad integrali, ma i concetti fondamentali di probabilità congiunta, marginale e condizionale rimangono applicabili.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/09_joint_prob.html#commenti-e-considerazioni-finali",
    "title": "33  Probabilità congiunta",
    "section": "33.8 Commenti e considerazioni finali",
    "text": "33.8 Commenti e considerazioni finali\nIn alcune situazioni, ogni singolo elemento di una popolazione può essere associato a diverse variabili casuali. Ad esempio, consideriamo l’elenco di tutti gli studenti iscritti a un’università e immaginiamo di selezionare uno studente a caso per misurare la sua altezza e il suo peso. In questo caso, ogni individuo della popolazione è associato a due variabili casuali, l’altezza e il peso. Quando si hanno due o più variabili casuali associate ad ogni elemento di una popolazione, è possibile studiare la distribuzione congiunta di tali variabili casuali. In questo capitolo abbiamo esaminato come rappresentare la distribuzione di massa di probabilità congiunta di due variabili casuali discrete e come ottenere le distribuzioni marginali delle due variabili. Inoltre, abbiamo discusso i concetti di incorrelazione e indipendenza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/09_joint_prob.html#informazioni-sullambiente-di-sviluppo",
    "title": "33  Probabilità congiunta",
    "section": "33.9 Informazioni sull’Ambiente di Sviluppo",
    "text": "33.9 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Sat Mar 16 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy : 1.26.4\npandas: 2.2.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt Publishing Ltd.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probabilità congiunta</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html",
    "href": "chapters/probability/10_density_func.html",
    "title": "34  La funzione di densità di probabilità",
    "section": "",
    "text": "Introduzione\nIn precedenza abbiamo trattato solo variabili casuali discrete, ossia variabili che assumono solo valori interi. Tuttavia, se vogliamo rappresentare grandezze come lunghezze, volumi, distanze o qualsiasi altra proprietà continua del mondo fisico o psicologico, è necessario generalizzare l’approccio utilizzato finora.\nLe variabili casuali continue assumono valori reali, e l’insieme dei numeri reali è non numerabile in quanto è più grande dell’insieme degli interi.1 Le leggi della probabilità valgono sia per le variabili casuali discrete che per quelle continue. Tuttavia, la nozione di funzione di massa di probabilità deve essere sostituita dal suo equivalente continuo, la funzione di densità di probabilità. In questo capitolo, il nostro obiettivo è chiarire il significato di questa nozione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "chapters/probability/10_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.1 Spinner e variabili casuali continue uniformi",
    "text": "34.1 Spinner e variabili casuali continue uniformi\nConsideriamo l’esperimento casuale in cui facciamo ruotare ad alta velocità uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma, identificata dall’angolo acuto con segno tra il suo asse e l’asse orizzontale del goniometro. Denotiamo con \\(\\Theta\\) la variabile casuale corrispondente alla “pendenza dello spinner”. In questo contesto, l’assunzione che lo spinner sia simmetrico implica che, in ogni prova, la rotazione produce un angolo qualunque da 0 a 360 gradi con la stessa probabilità. In altre parole, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilità di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, dal momento che 36 gradi corrisponde a un decimo del percorso intorno al cerchio, la probabilità di ottenere un qualsiasi intervallo di 36 gradi sarà sempre uguale al 10%. Più precisamente, si ha \\(P(0 \\leq \\Theta \\leq 36) = \\frac{1}{10}\\) e \\(P(200 \\leq \\Theta \\leq 236) = \\frac{1}{10}\\).\nÈ importante sottolineare che le probabilità sopra menzionate non si riferiscono al fatto che la variabile casuale \\(\\Theta\\) assuma un valore specifico, ma piuttosto all’evento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilità che la pendenza \\(\\Theta\\) cada in un intervallo specificato è data dalla frazione del cerchio rappresentata dall’intervallo, cioè \\(P(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}\\), per ogni intervallo \\([\\theta_1, \\theta_2]\\) tale che \\(0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360\\).\nNel caso di una variabile casuale continua, come l’angolo dello spinner, dunque, è facile capire come assegnare una probabilità all’evento in cui la variabile casuale assuma un valore compreso in un intervallo.\n\n34.1.1 Distribuzione uniforme\nL’esempio dello spinner rappresenta il “meccanismo generatore dei dati” della variabile casuale continua più semplice, ovvero la distribuzione continua uniforme. In teoria della probabilità, la distribuzione continua uniforme è una distribuzione di probabilità continua che assegna la stessa probabilità a tutti i punti appartenenti ad un intervallo [a, b] contenuto in un certo insieme.\nLa distribuzione uniforme continua definita sull’intervallo \\({\\displaystyle S=[a,b]\\subset \\mathbb {R}}\\) viene denotata con \\({\\displaystyle {\\mathcal {U}}(a,b)={\\mathcal {U}}([a,b])}\\). La sua densità di probabilità è\n\\[\nf(x) = \\frac{1}{b-a}, \\quad a \\leq x \\leq b\n\\]\ne 0 altrimenti. La distribuzione uniforme continua è caratterizzata dalla sua proprietà di equidistribuzione: tutti gli intervalli di pari lunghezza all’interno dell’intervallo [a, b] hanno la stessa probabilità. In altre parole, se \\({\\displaystyle [c,d]}\\) è un sottointervallo di \\({\\displaystyle [a,b]}\\), allora la probabilità che una variabile casuale continua con distribuzione uniforme in \\({\\displaystyle [a,b]}\\) cada in \\({\\displaystyle [c,d]}\\) è \\({\\displaystyle (d-c)/(b-a)}\\).\nSvolgiamo un esercizio con Python in cui, per continuare il nostro esempio dello spinner, consideriamo una \\(\\mathcal {U}(0, 360)\\).\n\na = 0\nb = 360\nsize = 101\nx = np.linspace(a, b, size)\ny = st.uniform.pdf(x, loc=a, scale=b)\n\nplt.figure()\nplt.plot(x, y)\nplt.xlabel(\"X\")\nplt.ylabel(\"Densità\");\n\n\n\n\n\n\n\n\nGeneriamo 100,000 valori casuali di una v.c. \\(\\Theta \\sim \\mathcal {U}(0, 360)\\).\n\ndata = rng.uniform(0, 360, size=100000)\n\nL’istogramma delle 100,000 realizzazioni di \\(\\Theta\\) è il seguente.\n\nplt.figure()\nplt.hist(data, density=True, alpha=0.5)\nplt.xlabel(\"Theta ~ U[0, 360]\")\nplt.ylabel(\"Densità\")\nplt.title(\"Distribuzione uniforme\")\nplt.show()\n\n\n\n\n\n\n\n\nÈ chiaro che, all’aumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell’istogramma tenderà a diventare una linea retta. Ciò significa che la funzione di densità di una variabile casuale uniforme continua è una costante: \\(f(\\Theta) = c\\).\nDalla figura precedente vediamo che l’area sottesa alla funzione di densità è \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densità di una variabile casuale uniforme continua non dipende da \\(\\theta\\) – è costante e identica per ogni possibile valore \\(\\theta\\).\nIl valore atteso di \\(X \\sim \\mathcal {U}(a,b)\\) è dato da\n\\[\n\\mathbb{E} = \\frac{b - a}{2}.\n\\]\nNel caso della presente simulazione otteniamo\n\ndata.mean()\n\n180.44171561785456\n\n\nSvolgiamo un altro semplice esercizio. Consideriamo una variabile casuale uniforme \\(X\\) definita sull’intervallo [0, 100]. Poniamoci il problema di trovare la probabilità \\(P(20 &lt; X &lt; 60)\\).\nPer trovare la soluzione è sufficiente calcolare l’area di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilità cercata è dunque \\(P(20 &lt; X &lt; 60) = 40 \\cdot 0.01 = 0.4\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "href": "chapters/probability/10_density_func.html#il-paradosso-delle-variabili-casuali-continue",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.2 Il paradosso delle variabili casuali continue",
    "text": "34.2 Il paradosso delle variabili casuali continue\nConsideriamo ora la probabilità che la variabile casuale continua assuma un valore specifico, come ad esempio una pendenza dello spinner esattamente uguale a 36 gradi. Sorprendentemente, la risposta è zero:\n\\[\nP(\\Theta = 36) = 0.\n\\]\nCiò è dovuto al fatto che se la probabilità di un valore specifico fosse maggiore di zero, allora ogni altro possibile valore dovrebbe avere la stessa probabilità, poiché abbiamo assunto che tutti i valori \\(\\Theta\\) sono egualmente probabili. Ma se sommiamo tutte queste probabilità, il totale sarebbe maggiore di uno, il che è impossibile.\nNel caso delle variabili casuali continue, dobbiamo quindi rinunciare all’idea che ogni singolo valore della variabile casuale possa avere una massa di probabilità maggiore di zero. Invece, una massa di probabilità viene assegnata alla realizzazione della variabile casuale in un intervallo di valori. Questo è ciò che differenzia le variabili casuali continue dalle variabili casuali discrete, dove ogni singolo valore ha una probabilità di massa non nulla. In sintesi, le variabili casuali continue non hanno una massa di probabilità, ma una densità di probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densità",
    "href": "chapters/probability/10_density_func.html#dagli-istogrammi-alle-densità",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.3 Dagli istogrammi alle densità",
    "text": "34.3 Dagli istogrammi alle densità\nLe considerazioni precedenti ci fanno comprendere che, a differenza delle variabili casuali discrete, non esiste l’equivalente di una funzione di massa di probabilità per le variabili casuali continue. Invece, esiste una funzione di densità di probabilità che può essere definita in termini di una simulazione. Considerando un numero enorme di casi e facendo tendere l’ampiezza \\(\\Delta\\) di ciascuna classe a 0, il profilo dell’istogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) è detta funzione di densità di probabilità.\nIn un istogramma, l’area di ogni barra è proporzionale alla frequenza relativa delle osservazioni nell’intervallo considerato. Dato che tutti gli intervalli hanno la stessa ampiezza, l’altezza di ogni barra sarà proporzionale alla frequenza relativa delle osservazioni nell’intervallo. Nella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore nell’intervallo considerato. Con l’aumentare del numero di osservazioni \\(M\\), le probabilità stimate si avvicinano sempre di più ai valori effettivi della probabilità. Inoltre, all’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo tende a 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è appunto la funzione di densità di probabilità della variabile casuale.\nIn precedenza, nella statistica descrittiva, abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico utilizzato per stimare la funzione di densità di probabilità di una variabile casuale.\nPer fare un esempio, generiamo 50 valori dalla distribuzione del quoziente di intelligenza. Stampiamo i primi 5 valori.\n\nmu, sigma = 100, 15\nsize = 50\nx = rng.normal(loc=mu, scale=sigma, size=size)\nx[:5]\n\narray([ 67.65579413,  96.10487389, 143.34602461, 120.29576608,\n        97.5740431 ])\n\n\nCreiamo ora un istogramma a cui sovrapponiamo la funzione di densità Normale con parametri corrispondenti alla media e deviazione standard del campione. Con poche osservazioni, non c’è una buona corrispondenza tra l’istogramma e la curva continua che abbiamo chiamato “funzione di densità”.\n\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=25, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 98.05 e 16.59')\n\n\n\n\n\n\n\n\n\nOra aumentiamo il numero di osservazioni. In questo caso consideriamo 20,000 valori del QI. Generiamo dunque una figura simile alla precedente, solo considerando un campione di dati più grande.\n\nsize = 10000\nx = rng.normal(loc=mu, scale=sigma, size=size)\nmu, std = st.norm.fit(x)\nplt.figure()\nplt.hist(x, bins=50, density=True, alpha=0.6)\n\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = st.norm.pdf(x, mu, std)\nplt.plot(x, p, \"k\", linewidth=2)\ntitle = \"Media e deviazione standard: {:.2f} e {:.2f}\".format(mu, std)\nplt.title(title)\n\nText(0.5, 1.0, 'Media e deviazione standard: 98.05 e 14.98')\n\n\n\n\n\n\n\n\n\nOra vediamo che c’è una corrispondenza molto buona tra il profilo dell’istogramma e la curva continua. Questo ci consente la seguente interpretazione: la funzione di densità è una curva che approssima il profilo di un istogramma, quando consideriamo un grande numero di osservazioni. In altre parole, una funzione di densità non è altro che un (profilo di un) istogramma nel caso di un numero infinito di osservazioni e intervalli di ampiezza \\(\\Delta\\) infinitamente piccoli.\nIn un istogramma, l’area di ciascuna barra è proporzionale alla frequenza relativa delle osservazioni in quel’intervallo. Perché tutti gli intervalli hanno la stessa ampiezza, anche l’altezza di ciascuna barra sarà proporzionale alla frequenza relativa delle osservazioni in quel’intervallo.\nNella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore compreso nell’intervallo considerato. All’aumentare del numero \\(M\\) di osservazioni, le probabilità stimate si avvicinano sempre di più ai veri valori della probabilità. All’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo \\(\\rightarrow\\) 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è la funzione di densità di probabilità della variabile casuale.\nNella statistica descrittiva abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico per stimare la funzione di densità di probabilità di una variabile casuale.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densità-di-probabilità-pdf",
    "href": "chapters/probability/10_density_func.html#interpretazioni-bayesiana-e-frequentista-della-funzione-di-densità-di-probabilità-pdf",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.4 Interpretazioni Bayesiana e Frequentista della Funzione di Densità di Probabilità (PDF)",
    "text": "34.4 Interpretazioni Bayesiana e Frequentista della Funzione di Densità di Probabilità (PDF)\nAbbiamo introdotto la funzione di densità di probabilità come limite del profilo di un istogramma, una descrizione intuitiva e utile per comprendere il concetto di densità. Questa interpretazione corrisponde, tuttavia, alla visione frequentista della densità di probabilità. Nella statistica Bayesiana, l’interpretazione è diversa e merita una spiegazione separata.\nNell’approccio Bayesiano, un parametro è considerato una “variabile casuale” che segue una distribuzione di valori, anziché un valore fisso. La Figura 34.1, vedi 34.1 illustra le diverse interpretazioni di una PDF per una quantità reale \\(x\\). Queste interpretazioni valgono sia che \\(x\\) rappresenti un parametro incognito sia che si tratti di un dato osservato.\nNel pannello di sinistra, vediamo l’interpretazione frequentista di \\(p(x)\\): la PDF rappresenta una collezione ipotetica di ripetizioni di esperimenti, in cui \\(x\\) può assumere diversi valori. La PDF corrisponde quindi a un istogramma limite di questi valori, distribuiti secondo \\(p(x)\\).\nIl pannello di destra, invece, raffigura l’interpretazione Bayesiana, in cui la PDF rappresenta l’incertezza sul valore di \\(x\\) per un singolo caso specifico. In questo caso, la probabilità si distribuisce lungo i possibili valori che \\(x\\) potrebbe assumere, visualizzata dalla sfumatura lungo l’asse \\(x\\).\nIn altre parole, nell’interpretazione frequentista, è il valore di \\(x\\) a essere distribuito in \\(p(x)\\) (attraverso ripetizioni dell’esperimento), mentre nell’interpretazione Bayesiana è la probabilità stessa a distribuirsi sui possibili valori di \\(x\\) nel caso analizzato. Una PDF Bayesiana può essere vista come analoga a una densità di materia \\(\\rho(x)\\) in meccanica classica: è la probabilità che si distribuisce lungo i possibili valori, e non i valori stessi di \\(x\\).\n\n\n\n\n\n\nFigura 34.1: Interpretazioni frequentista e bayesiana di una PDF (curva blu) per una quantità reale \\(x\\). A sinistra: interpretazione frequentista come istogramma limite dei valori di \\(x\\) nelle ripetizioni; i valori di \\(x\\) sono distribuiti secondo la PDF. A destra: interpretazione bayesiana, con \\(x\\) che assume un valore fisso ma incerto per il caso specifico (rappresentato dal punto sull’asse \\(x\\)), con la probabilità distribuita sui valori possibili (raffigurata con una sfumatura lungo l’asse \\(x\\)). (Figura tratta da Loredo & Wolpert, 2024)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#funzione-di-densità-di-probabilità",
    "href": "chapters/probability/10_density_func.html#funzione-di-densità-di-probabilità",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.5 Funzione di densità di probabilità",
    "text": "34.5 Funzione di densità di probabilità\nDa un punto di vista matematico, l’intuizione precedente si può esprimere nel modo seguente.\nPer descrivere le probabilità che possono essere associate ad una variabile casuale continua \\(X\\) è necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due proprietà:\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l’ordinata della funzione di densità è 0 o positiva;\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l’area sottesa dalla \\(p(x)\\) è unitaria2;\n\\(p(a &lt; x &lt; b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l’area sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilità che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. È possibile che \\(p(x) &gt; 1\\), quindi una densità di probabilità non può essere interpretata come una probabilità. Piuttosto, la densità \\(p(x)\\) può essere utilizzata per confrontare la credibilità relativa che può essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui è disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) &gt; p(x_l)\\), allora possiamo concludere che è più credibile, in termini relativi, osservare realizzazioni \\(X\\) nell’intorno di \\(x_k\\) piuttosto che nell’intorno di \\(x_l\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "chapters/probability/10_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.6 La funzione di ripartizione per una variabile casuale continua",
    "text": "34.6 La funzione di ripartizione per una variabile casuale continua\nPer le variabili casuali continue, la funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = P(\\Theta \\leq \\theta).\n\\]\nCioè, è la probabilità che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\).\nCome nel caso discreto, la funzione di ripartizione di una v.c. continua può essere utilizzata per calcolare la probabilità che la v.c. assuma valori in un certo intervallo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#considerazioni-conclusive",
    "href": "chapters/probability/10_density_func.html#considerazioni-conclusive",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.7 Considerazioni Conclusive",
    "text": "34.7 Considerazioni Conclusive\nLa funzione di densità di probabilità (PDF) è uno strumento fondamentale per descrivere distribuzioni di variabili continue. Un principio essenziale alla base di questa funzione è che la probabilità che una variabile aleatoria continua assuma un valore esatto è pari a zero. Matematicamente, ciò deriva dal fatto che l’area sotto la curva di densità in un punto singolo è sempre zero.\nQuesta concezione implica due conseguenze importanti:\n\nLa probabilità può essere calcolata solo per intervalli di valori, non per punti specifici.\nEventi con probabilità zero non sono necessariamente impossibili.\n\nDa questa seconda implicazione emerge un apparente paradosso: come possiamo conciliare il fatto che eventi osservabili (ad esempio, colpire il centro esatto di un bersaglio) abbiano probabilità zero?\nQuesto paradosso solleva due domande cruciali:\n\nÈ possibile confrontare le “possibilità” di eventi diversi che hanno tutti probabilità zero?\nCome può l’unione di infiniti eventi con probabilità zero (ogni punto specifico di un intervallo) dare origine a un evento certo (scegliere un punto qualsiasi nell’intervallo)?\n\nIl “paradosso della probabilità zero” richiama alla mente il famoso paradosso di Zenone sulla freccia: se in ogni istante la freccia è ferma, come può essa muoversi? In entrambi i casi, siamo posti di fronte a una sfida concettuale: come può una somma di “nulla” (eventi con probabilità zero) dare origine a “qualcosa” (un evento con probabilità certa)?\nUna soluzione moderna a questo enigma è emersa negli anni ’60 con il lavoro di Abraham Robinson sugli infinitesimi. Gli infinitesimi sono numeri infinitamente piccoli ma non nulli, che esistono tra zero e qualsiasi numero positivo reale. Questa teoria consente di assegnare probabilità infinitesimali a eventi che, nella teoria classica, avrebbero probabilità zero.\nApplicando questa idea al nostro paradosso, possiamo concludere che:\n\nLa probabilità di colpire un punto specifico non è zero, ma infinitesimale.\nLa probabilità di colpire uno tra due punti specifici è maggiore di quella di colpire un singolo punto, anche se la differenza è infinitesimale.\n\nQuesto approccio risolve il paradosso permettendo di distinguere tra eventi che nella teoria classica erano tutti assegnati a probabilità zero. Inoltre, spiega come l’unione di molti eventi con probabilità infinitesimale possa portare a un evento con probabilità uno.\nL’introduzione degli infinitesimi non è solo un artificio matematico, ma rappresenta un ritorno alle idee originarie di Newton e Leibniz, fornendo una base rigorosa per trattare l’infinitamente piccolo in matematica. Questa teoria offre un nuovo modo di concepire concetti come l’infinito e la continuità, con applicazioni che si estendono ben oltre la teoria della probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/10_density_func.html#informazioni-sullambiente-di-sviluppo",
    "title": "34  La funzione di densità di probabilità",
    "section": "34.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "34.8 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Oct 04 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.14.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: more than Bayes’s theorem. Frontiers in Astronomy and Space Sciences, 11, 1326926.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/10_density_func.html#footnotes",
    "href": "chapters/probability/10_density_func.html#footnotes",
    "title": "34  La funzione di densità di probabilità",
    "section": "",
    "text": "Georg Cantor dimostrò che era impossibile mappare uno a uno i reali negli interi, dimostrando così che l’insieme dei reali è non numerabile.↩︎\nPer quel che riguarda la notazione dell’integrale, ovvero \\(\\int_x \\,\\operatorname {d}\\!x\\), rimando alla discussione di S.P. Thompson: https://calculusmadeeasy.org/1.html↩︎",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>La funzione di densità di probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html",
    "href": "chapters/probability/11_discr_rv_distr.html",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Introduzione\nLa previsione è un processo che ci permette di formulare ipotesi su eventi incerti, sfruttando le regolarità osservate nei processi naturali, sociali e psicologici. Uno degli obiettivi principali della data science è proprio quello di prevedere fenomeni di cui non abbiamo ancora certezza, inclusi, ma non limitati a, eventi futuri.\nLa capacità di fare previsioni senza considerare ogni possibile risultato dipende dalla conoscenza della popolazione di riferimento. Gli esseri umani organizzano e rappresentano questa conoscenza in vari modi. In questo capitolo, esploreremo le implicazioni di un approccio specifico alla rappresentazione delle popolazioni: le distribuzioni di probabilità.\nSupponiamo di avere una distribuzione di probabilità \\(p(x)\\) associata a una variabile casuale \\(X\\). Consideriamo che questa distribuzione rappresenti la variabilità osservata all’interno di una popolazione. Se selezionassimo un’istanza in modo uniforme e casuale dalla popolazione, quale valore della variabile \\(X\\) dovremmo aspettarci? Ci aspettiamo che un campione estratto casualmente dalla popolazione segua la distribuzione \\(p(x)\\). In altre parole, questa distribuzione è ciò che definiamo un modello statistico, o più semplicemente, un modello della popolazione. Il termine “modello” sottolinea che la distribuzione non è la popolazione stessa, ma una rappresentazione astratta che utilizziamo per fare previsioni.\nIn particolare, ci concentreremo sulle distribuzioni di probabilità discrete, essenziali per comprendere i fenomeni aleatori che presentano un numero finito o numerabile di esiti. Queste distribuzioni sono cruciali nella modellazione e nell’analisi di eventi che si verificano in contesti discreti, fornendo le basi per una comprensione più profonda delle dinamiche probabilistiche che governano tali fenomeni.\nOgni distribuzione di probabilità è caratterizzata da uno o più parametri, che consentono di controllare specifici aspetti della distribuzione stessa. Esploreremo diverse distribuzioni discrete, ciascuna con le sue caratteristiche e applicazioni:\nIn sintesi, attraverso lo studio di queste distribuzioni, acquisiremo gli strumenti necessari per analizzare e prevedere una vasta gamma di situazioni reali.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "href": "chapters/probability/11_discr_rv_distr.html#introduzione",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "",
    "text": "Distribuzione di Bernoulli\n\nRappresenta esperimenti con due possibili esiti: “successo” o “insuccesso”\nCostituisce il nucleo dei processi Bernoulliani\nParametro chiave: probabilità di successo in ciascuna prova\n\nDistribuzione Binomiale\n\nDescrive il numero totale di successi in un numero fisso di prove Bernoulliane\nNasce dalla somma di prove Bernoulliane indipendenti\nParametri: probabilità di successo in ciascuna prova e numero totale di prove\n\nDistribuzione di Poisson\n\nModella eventi rari o che si verificano su intervalli di tempo o spazio variabili\nAdatta quando il numero di prove è una variabile casuale\nParametro: tasso medio di successo per unità di tempo o spazio\n\nDistribuzione Beta-Binomiale\n\nUtilizzata quando la probabilità di successo in una serie di prove Bernoulliane non è costante\nOffre una rappresentazione più flessibile rispetto alla distribuzione binomiale\nParametri: derivati dalla distribuzione Beta sottostante\n\nDistribuzione Uniforme Discreta\n\nOgni evento all’interno di un determinato intervallo finito ha la stessa probabilità\nUtile quando non ci sono motivi per privilegiare un risultato rispetto a un altro\nNon dipende da parametri una volta stabilito il supporto della distribuzione",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-bernoulli",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.1 Distribuzione di Bernoulli",
    "text": "35.1 Distribuzione di Bernoulli\nIn statistica, un esperimento che ammette solo due esiti possibili è modellato attraverso quella che viene chiamata “prova Bernoulliana”. Un esempio tipico è il lancio di una moneta, che può dare come risultato testa o croce.\n\nDefinizione 35.1 Una variabile casuale \\(X\\) che assume valori in \\(\\{0, 1\\}\\) è detta variabile di Bernoulli. La sua distribuzione di probabilità è definita come:\n\\[\nP(X \\mid \\theta) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$ (successo)}, \\\\\n    1 - p & \\text{se $X = 0$ (insuccesso)},\n  \\end{cases}\n\\]\ndove \\(0 \\leq p \\leq 1\\). Il parametro \\(p\\) rappresenta la probabilità del “successo” (\\(X = 1\\)), mentre \\(1 - p\\) è la probabilità dell’“insuccesso” (\\(X = 0\\)).\n\nLa distribuzione di Bernoulli descrive quindi un contesto in cui la probabilità di osservare l’esito 1 è \\(p\\) e quella di osservare l’esito 0 è \\(1 - p\\). Viene utilizzata per modellare situazioni binarie, come una risposta “sì” o “no”, oppure un “successo” o “insuccesso”.\nCalcolando il valore atteso e la varianza, otteniamo:\n\\[\n\\begin{align}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p, \\\\\n\\mathbb{V}(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{align}\n\\tag{35.1}\\]\nEsplicitando ulteriormente la formula della varianza con \\(P(YX=0) = 1 - p\\) e \\(P(X=1) = p\\), abbiamo:\n\\[ \\mathbb{V}(X) = (0 - p)^2 \\cdot (1 - p) + (1 - p)^2 \\cdot p \\]\nCalcoliamo ora le singole parti dell’espressione: 1. \\((0 - p)^2 = p^2\\) 2. \\((1 - p)^2 = 1 - 2p + p^2\\)\nSostituendo queste espressioni nell’equazione della varianza, otteniamo:\n\\[ \\mathbb{V}(X) = p^2 \\cdot (1 - p) + (1 - 2p + p^2) \\cdot p \\]\n\\[ \\mathbb{V}(X) = p^2 - p^3 + p - 2p^2 + p^3 \\]\nSemplificando:\n\\[ \\mathbb{V}(X) = p - p^2 \\]\n\\[ \\mathbb{V}(X) = p(1-p). \\]\nIn sintesi, la varianza di una variabile aleatoria binaria \\(X\\), distribuita secondo Bernoulli con parametro \\(p\\), è data da \\(p(1-p)\\). Tale risultato mostra come la varianza massima si ottenga per \\(p = 0.5\\), condizione che corrisponde alla massima incertezza intrinseca nel processo, ossia quando la probabilità di successo eguaglia quella di insuccesso.\n\n# Define p values between 0 and 1\np = np.linspace(0, 1, 100)\n\n# Variance of a Bernoulli distribution is theta(1-theta)\nvariance = p * (1 - p)\n\nplt.plot(p, variance, label='Varianza', color='blue')\nplt.title('Varianza di una variabile Bernoulliana in funzione di $p$')\nplt.xlabel('$p$')\nplt.ylabel('Varianza')\nplt.show()\n\n\n\n\n\n\n\n\nPer indicare che la variabile casuale \\(X\\) segue una distribuzione Bernoulliana di parametro \\(p\\) Utilizziamo la notazione \\(X \\sim \\mathcal{Bern}(p)\\), o in maniera equivalente \\(\\mathcal{Bern}(X \\mid p)\\).\nAd esempio, nel caso del lancio di una moneta equilibrata, la variabile di Bernoulli assume i valori \\(0\\) e \\(1\\) con uguale probabilità di \\(\\frac{1}{2}\\). Pertanto, la funzione di massa di probabilità assegna una probabilità di \\(\\frac{1}{2}\\) sia per \\(X = 0\\) che per \\(X = 1\\), mentre la funzione di distribuzione cumulativa risulta essere \\(\\frac{1}{2}\\) per \\(X = 0\\) e \\(1\\) per \\(X = 1\\).\nGeneriamo dei valori casuali dalla distribuzione di Bernoulli. Iniziamo con un singolo valore:\n\n# Probabilità di successo (p)\np = 0.5\n\n# Genera un valore casuale dalla distribuzione di Bernoulli\nbernoulli_sample = rng.binomial(n=1, p=p)\nprint(bernoulli_sample)\n\n1\n\n\nGeneriamo un campione di 10 valori:\n\n# Genera un campione di 10 valori dalla distribuzione di Bernoulli\nbernoulli_sample = rng.binomial(n=1, p=p, size=10)\nprint(bernoulli_sample)\n\n[0 0 1 1 1 1 1 0 1 0]",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-binomiale",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.2 Distribuzione Binomiale",
    "text": "35.2 Distribuzione Binomiale\nLa distribuzione binomiale è una distribuzione di probabilità discreta che modella il numero di successi \\(y\\) in un numero fissato \\(n\\) di prove di Bernoulli indipendenti e identiche, dove ciascuna prova ha solo due esiti possibili: “successo” (rappresentato da “1”) con probabilità \\(p\\) o “insuccesso” (rappresentato da “0”) con probabilità \\(1 - p\\). La notazione utilizzata è la seguente:\n\\[\nY \\sim \\mathcal{Binom}(n, p).\n\\]\n\nDefinizione 35.2 La distribuzione binomiale descrive la probabilità di osservare esattamente \\(y\\) successi in \\(n\\) prove di Bernoulli indipendenti:\n\\[\nP(Y = y) = \\binom{n}{y} p^{y} (1 - p)^{n - y} = \\frac{n!}{y!(n - y)!} p^{y} (1 - p)^{n - y},\n\\tag{35.2}\\]\ndove \\(\\binom{n}{y}\\), noto come coefficiente binomiale, rappresenta il numero di modi possibili per ottenere \\(y\\) successi in \\(n\\) prove, e \\(p\\) è la probabilità di successo in ciascuna prova.\n\nLa distribuzione binomiale si presta bene a esempi classici come il lancio ripetuto di una moneta o l’estrazione di biglie da un’urna. Ad esempio, nel caso del lancio di una moneta, questa distribuzione descrive la probabilità di ottenere un determinato numero di “teste” in un certo numero di lanci, con ogni lancio che segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUna caratteristica interessante della distribuzione binomiale è la sua proprietà di riproducibilità: se due variabili casuali indipendenti, \\(y_1\\) e \\(y_2\\), seguono entrambe distribuzioni binomiali con lo stesso parametro \\(p\\), ma con un diverso numero di prove (\\(n_1\\) e \\(n_2\\)), la loro somma, \\(y = y_1 + y_2\\), sarà ancora distribuita binomialmente, con parametri \\(n_1 + n_2\\) e \\(p\\).\n\n35.2.1 Calcolo delle Probabilità\nPer chiarire il calcolo delle probabilità nella distribuzione binomiale, consideriamo una serie di prove di Bernoulli. Supponiamo di avere \\(n\\) prove, con \\(y\\) successi. La configurazione di questi risultati può essere rappresentata come:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ successi} \\overbrace{II\\dots I}^\\text{$n - y$ insuccessi}\n\\]\nLa probabilità di ottenere esattamente \\(y\\) successi in una sequenza specifica di prove è pari a:\n\\[\np^y \\cdot (1 - p)^{n - y},\n\\]\ndove \\(p^y\\) è la probabilità di ottenere \\(y\\) successi, e \\((1 - p)^{n - y}\\) è la probabilità di ottenere \\(n - y\\) insuccessi.\nTuttavia, siamo interessati alla probabilità complessiva di ottenere esattamente \\(y\\) successi in qualsiasi ordine. Il numero di modi in cui ciò può avvenire è dato dal coefficiente binomiale \\(\\binom{n}{y}\\), che rappresenta tutte le possibili disposizioni dei successi e degli insuccessi nelle \\(n\\) prove.\nQuindi, moltiplicando la probabilità di una singola sequenza per il numero di sequenze possibili, otteniamo la probabilità di osservare esattamente \\(y\\) successi:\n\\[\nP(Y = y) = \\binom{n}{y} p^y (1 - p)^{n - y}.\n\\]\nQuesto risultato corrisponde alla formula della distribuzione binomiale.\n\n\n35.2.2 Applicazioni Pratiche della Distribuzione Binomiale\nConsideriamo un esempio pratico per illustrare l’applicazione della distribuzione binomiale. Supponiamo di osservare 2 successi in 4 prove Bernoulliane, dove la probabilità di successo in ogni prova è \\(p = 0.2\\). La probabilità di ottenere questo risultato specifico è calcolata utilizzando l’eq. {eq}eq-binom-distr:\n\\[\nP(Y=2) = \\frac{4!}{2!(4-2)!} \\cdot 0.2^{2} \\cdot (1-0.2)^{4-2} = 0.1536.\n\\]\nQuesto calcolo può essere replicato in Python. Utilizzando il modulo math, possiamo calcolare direttamente:\n\nn = 4\np = 0.2\ny = 2\n\nprob = math.comb(n, y) * p**y * (1 - p) ** (n - y)\nprint(prob)\n\n0.15360000000000007\n\n\nIn alternativa, possiamo sfruttare la libreria SciPy per eseguire calcoli analoghi. SciPy offre una vasta gamma di funzioni per la gestione delle distribuzioni statistiche, tra cui la distribuzione binomiale.\n\nstats.binom.pmf(y, n, p)\n\n0.15359999999999993\n\n\nUtilizzando scipy.stats.binom.pmf(y, n, p), possiamo trovare le probabilità per ogni possibile valore \\(y\\) in una distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\ny = np.arange(0, n + 1)\nprint(y)\n\n[0 1 2 3 4]\n\n\n\nprobabilities = stats.binom.pmf(y, n, p)\nprint(probabilities.round(3))\n\n[0.41  0.41  0.154 0.026 0.002]\n\n\nVisualizziamo la distribuzione di massa di probabilità:\n\nplt.figure()\nplt.plot(y, probabilities, \"o\", ms=8)\nplt.vlines(y, 0, probabilities, linestyles=\"-\", lw=1)\nplt.title(f\"Distribuzione binomiale: $n$={n}, $p$={p}\")\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilità\")\nplt.xlim(-0.5, n + 0.5)\nplt.ylim(0, max(probabilities) + 0.05)\nplt.show()\n\n\n\n\n\n\n\n\nPer esplorare ulteriormente, consideriamo la distribuzione di probabilità di diverse distribuzioni binomiali per due valori di \\(n\\) e \\(\\theta\\). La seguente visualizzazione mostra come cambia la distribuzione al variare di \\(\\theta\\):\n\nplt.figure()\n\nfor p in np.arange(0.3, 1.0, 0.3):\n    y = np.arange(0, 25)\n    binom_dist = stats.binom.pmf(y, 20, p)\n    plt.plot(y, binom_dist, \"-o\", label=f\"theta = {p:.1f}\")\n\nplt.xlabel(\"Numero di successi y\")\nplt.ylabel(\"Probabilità\")\nplt.title(\"Distribuzione binomiale al variare di $p$\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nConsideriamo un altro esempio. Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca testa almeno due volte? Troviamo la soluzione usando stats.binom.pmf().\n\nstats.binom.pmf(2, n=5, p=0.5) + stats.binom.pmf(3, n=5, p=0.5) + stats.binom.pmf(4, n=5, p=0.5) +  stats.binom.pmf(5, n=5, p=0.5)\n\n0.8125\n\n\n\nnp.sum([stats.binom.pmf(k, n=5, p=0.5) for k in range(2, 6)])\n\n0.8125\n\n\nPiù facilmente, si trova la risposta usando la funzione di ripartizione stats.binom.cdf.\n\n1 - stats.binom.cdf(1, n=5, p=0.5) \n\n0.8125\n\n\nRappresentiamo graficamente la funzione di ripartizione per una Binomiale di ordine \\(n\\) = 5 e \\(\\theta\\) = 0.5.\n\nn = 5\ntheta = 0.5\ny = np.arange(0, n+1)\n\nplt.figure()\nplt.plot(y, stats.binom.cdf(y, n=n, p=p))\nplt.scatter(y, stats.binom.cdf(y, n=n, p=p))\nplt.axhline(1, color=\"k\", alpha=0.7, linestyle=\"--\", lw=1)\nplt.title(f\"Funzione di ripartizione binomiale: $n$={n}, $p$={p}\", loc=\"left\")\nplt.xlabel(\"y\")\n_ = plt.ylabel(\"Probabilità\")\n\n\n\n\n\n\n\n\nUn’altra funzione utile è quella che trova il numero di successi in una distribuzione binomiale che corrisponde ad una data probabilità (nella coda sinistra della funzione ripartizione). Per l’esempio presente:\n\ntarget_probability = 1 - 0.8125\nstats.binom.ppf(target_probability, n, p)\n\n1.0\n\n\nUtilizzando la funzione punto percentuale (PPF), che è l’inverso della funzione di distribuzione cumulativa (CDF), possiamo trovare il numero di successi corrispondente alla probabilità target di \\(1 - 0.8125 = 0.1875\\) in una distribuzione binomiale con parametri \\(n = 5\\) e \\(p = 0.5\\). Il risultato mostra che il numero di successi cercato per questa probabilità target è 1.\nFacciamo un altro esempio. Consideriamo la probabilità cumulativa \\(P(Y \\leq 4)\\) per una variabile casuale \\(Y\\) che segue una distribuzione binomiale con numero di prove \\(n = 10\\) e probabilità di successo \\(p = 0.2\\). La funzione stats.binom.cdf(4, n=10, p=0.2) calcola la probabilità che ci siano al massimo 4 successi in 10 tentativi, dove la probabilità di successo in ogni tentativo è del 20%.\n\ntarget_probability = stats.binom.cdf(4, n=10, p=0.2)\ntarget_probability\n\n0.9672065024\n\n\nDi conseguenza, la funzione inversa è:\n\nstats.binom.ppf(target_probability, n=10, p=0.2)\n\n4.0\n\n\nPer generare una sequenza di valori casuali seguendo una distribuzione binomiale possiamo utilizzare la funzione random() di NumPy. Dopo aver inizializzato rng = np.random.default_rng(RANDOM_SEED), per esempio,\n\nrng = np.random.default_rng(42)\n\npossiamo impiegare rng per generare valori casuali da una distribuzione binomiale:\n\nx = rng.binomial(p=0.5, n=5, size=30)\nprint(*x)\n\n3 2 4 3 1 5 3 3 1 2 2 4 3 4 2 2 3 1 4 3 3 2 5 4 3 2 2 1 1 3\n\n\nPer una discussione sulla generazione di numeri pseudo-casuali in Python, si veda il capitolo {ref}appendix-rng.\n\n\n35.2.3 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si calcolano nel seguente modo:\n\\[\n\\begin{align}\n\\mu    &= np,  \\notag \\\\\n\\sigma &= \\sqrt{np(1-p)}.\n\\end{align}\n\\tag{35.3}\\]\nDimostrazione. Dato che \\(Y\\) rappresenta la somma di \\(n\\) prove di Bernoulli indipendenti \\(Y_i\\), possiamo scrivere:\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = np, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = np(1-p).\n\\end{align}\n\\]\nPertanto, la deviazione standard è data da \\(\\sigma = \\sqrt{np(1-p)}\\).\nPer esempio, prendiamo in considerazione il caso di un esperimento in cui vengono lanciate quattro monete, ciascuna con una probabilità di ottenere testa (successo) pari a \\(p = 0.2\\). Calcoliamo il valore atteso e la varianza per questo esperimento.\nIl valore atteso, \\(\\mu\\), rappresenta il numero medio di teste che ci aspettiamo di ottenere in ciascun lancio. Per la distribuzione binomiale, questo è dato da \\(\\mu = n p\\), dove \\(n\\) è il numero di prove (lanci di monete). Nel nostro caso, con \\(n = 4\\) e \\(p = 0.2\\), abbiamo:\n\\[\n\\mu = n p = 4 \\times 0.2 = 0.8.\n\\]\nQuesto significa che, in media, ci aspettiamo di ottenere circa 0.8 teste per ogni serie di quattro lanci.\nPer quanto riguarda la varianza, che misura quanto i risultati individuali tendono a differire dalla media, nella distribuzione binomiale è calcolata come \\(n p (1-p)\\). Pertanto, per il nostro esperimento:\n\\[\n\\text{Varianza} = n p (1-p) = 4 \\times 0.2 \\times (1 - 0.2) = 0.64.\n\\]\nLa varianza di 0.64 suggerisce una certa dispersione intorno al valore medio di 0.8 teste.\nPer confermare queste aspettative teoriche, possiamo eseguire una simulazione. Creiamo una serie di esperimenti simulati in cui lanciamo quattro monete per un gran numero di volte, registrando il numero di teste ottenute in ogni serie. Calcoliamo poi la media e la varianza dei risultati ottenuti per vedere quanto si avvicinano ai valori teorici calcolati.\n\nx = rng.binomial(p=.2, n=4, size=1000000)\n\n\nnp.mean(x)\n\n0.79956\n\n\n\nnp.var(x, ddof=0)\n\n0.6397598064000003\n\n\n\n\n35.2.4 Funzioni Python associate alle distribuzioni di probabilità\nLa seguente tabella riassume le funzioni di Python utilizzate per manipolare le distribuzioni di probabilità, illustrando i casi della distribuzione Binomiale e della Normale.\n\n\n\n\n\n\n\n\nTipo\nEsempio: Binomiale (y | n, p)\nEsempio: Normale (y | μ, σ)\n\n\n\n\nFunzione di verosimiglianza\nbinom.pmf(y, n, p)\nnorm.pdf(y, μ, σ)\n\n\nProb Y=y\nbinom.pmf(y, n, p)\nsempre 0 per variabili continue\n\n\nProb Y ≥ y, Y ≤ y, y1 &lt; Y &lt; y2\nbinom.cdf(y, n, p) o binom.sf(y, n, p)\nnorm.cdf(y, μ, σ) o norm.sf(y, μ, σ)\n\n\nInversa della CDF\nbinom.ppf(q, n, p)\nnorm.ppf(q, μ, σ)\n\n\nGenerazione di dati simulati\nrng.binomial(n, p, size)\nrng.normal(μ, σ, size)\n\n\n\nIn seguito, useremo altre distribuzioni come Uniforme, Beta, ecc., ognuna delle quali ha un proprio insieme di funzioni disponibili in Python tramite il modulo scipy.stats. Potete trovare una lista completa di queste distribuzioni nella documentazione ufficiale.\n\npmf (probability mass function) viene utilizzata per distribuzioni discrete come la Binomiale, mentre pdf (probability density function) si applica alle distribuzioni continue, come la Normale.\ncdf (cumulative distribution function) e sf (survival function, che corrisponde a \\(1 - \\text{cdf}\\)) permettono di calcolare le probabilità cumulative.\nppf (percent point function) è l’inversa della cdf, e si usa per determinare il valore della variabile corrispondente a una certa percentuale di osservazioni.\nrvs (random variates) serve a generare campioni casuali simulati secondo una determinata distribuzione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.3 Distribuzione Discreta Uniforme",
    "text": "35.3 Distribuzione Discreta Uniforme\nLa distribuzione discreta uniforme è un tipo particolare di distribuzione di probabilità, dove ogni risultato in un insieme finito e discreto \\(S\\) ha la stessa probabilità \\(p\\) di verificarsi. Questa distribuzione è caratterizzata dalla sua semplicità e dalla sua proprietà fondamentale di equiprobabilità.\nConsideriamo un esempio pratico con una variabile casuale discreta \\(X\\), che può assumere valori nell’insieme \\(\\{1, 2, \\dots, N\\}\\). Un’istanza classica di questa distribuzione si verifica quando si sceglie casualmente un numero intero tra 1 e \\(N\\), inclusi. Se \\(X\\) rappresenta il numero selezionato, allora la somma delle probabilità di tutti i possibili valori di \\(X\\) deve totalizzare 1, come indicato dalla formula di normalizzazione:\n\\[\n\\sum_{i=1}^N P(X_i) = Np = 1.\n\\]\nDi conseguenza, la probabilità che \\(X\\) assuma un valore specifico \\(x\\) è uniformemente distribuita:\n\\[\nP(X = x) = \\frac{1}{N},\n\\]\nindicando che ogni evento ha la stessa probabilità di verificarsi.\nIl valore atteso, o la media, di \\(X\\) ci dà un’idea del risultato medio atteso e si calcola come:\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^N x \\cdot \\frac{1}{N} = \\frac{1}{N} \\cdot \\sum_{x=1}^N x.\n\\]\nA questo punto, dobbiamo calcolare la somma \\(\\sum_{x=1}^{N} x\\), che è la somma dei primi \\(N\\) numeri naturali. Questa somma è data dalla formula:\n\\[\n\\sum_{x=1}^{N} x = \\frac{N(N + 1)}{2}.\n\\]\nSostituendo questa formula nel nostro calcolo del valore atteso, otteniamo:\n\\[\n\\mathbb{E}(X) = \\frac{1}{N} \\cdot \\frac{N(N + 1)}{2} = \\frac{N + 1}{2}.\n\\]\nQuindi, abbiamo dimostrato che il valore atteso $ (X) $ per una variabile casuale \\(X\\) che assume valori interi uniformemente distribuiti da 1 a \\(N\\) è \\(\\frac{N + 1}{2}\\).\nPer determinare quanto i valori di \\(X\\) si disperdono attorno al valore medio, calcoliamo la varianza. Il primo passo è calcolare \\(\\mathbb{E}(X^2)\\), il valore atteso del quadrato di \\(X\\). Per una variabile casuale discreta uniforme, questo si ottiene moltiplicando ogni valore al quadrato per la sua probabilità (che è \\(1/N\\) per tutti i valori) e sommando i risultati:\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\sum_{x=1}^N x^2\n\\]\nUsando l’identità per la somma dei quadrati dei primi \\(N\\) numeri naturali:\n\\[\n1^2 + 2^2 + \\dots + N^2 = \\frac{N(N + 1)(2N + 1)}{6}\n\\]\npossiamo sostituirla per trovare \\(\\mathbb{E}(X^2)\\):\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{N} \\cdot \\frac{N(N + 1)(2N + 1)}{6} = \\frac{(N + 1)(2N + 1)}{6}\n\\]\nLa varianza di \\(X\\), denotata con \\(\\mathbb{V}(X)\\), si calcola usando la formula:\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2\n\\]\nAbbiamo già stabilito che \\(\\mathbb{E}(X) = \\frac{N + 1}{2}\\) e \\(\\mathbb{E}(X^2) = \\frac{(N + 1)(2N + 1)}{6}\\). Sostituendo questi valori nella formula della varianza, otteniamo:\n\\[\n\\mathbb{V}(X) = \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2\n\\]\nPer semplicare l’espressione della varianza, dobbiamo sottrarre il quadrato di \\(\\mathbb{E}(X)\\) da \\(\\mathbb{E}(X^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{V}(X) &= \\frac{(N + 1)(2N + 1)}{6} - \\left(\\frac{N + 1}{2}\\right)^2 \\\\\n&= \\frac{(N + 1)(2N + 1)}{6} - \\frac{(N + 1)^2}{4} \\\\\n&= \\frac{2(N + 1)(2N + 1)}{12} - \\frac{3(N + 1)^2}{12} \\\\\n&= \\frac{(N + 1)(2(2N + 1) - 3(N + 1))}{12} \\\\\n&= \\frac{(N + 1)(4N + 2 - 3N - 3)}{12} \\\\\n&= \\frac{(N + 1)(N - 1)}{12}\n\\end{align*}\n\\]\nQuindi, la varianza \\(\\mathbb{V}(X)\\) di una variabile casuale uniforme discreta \\(X\\) che assume valori da 1 a \\(N\\) è \\(\\frac{(N + 1)(N - 1)}{12}\\), il che mostra come la dispersione dei valori attorno al loro valore medio dipenda dalla grandezza di \\(N\\). Questa formula fornisce la varianza di una variabile casuale in una distribuzione discreta uniforme, offrendo una misura quantitativa della dispersione dei valori attorno al loro valore medio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-poisson",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-di-poisson",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.4 Distribuzione di Poisson",
    "text": "35.4 Distribuzione di Poisson\nLa distribuzione di Poisson è una distribuzione di probabilità discreta utilizzata per modellare il numero di eventi che si verificano in un dato intervallo di tempo o spazio, quando tali eventi sono indipendenti e accadono a un tasso costante.\nSiméon Denis Poisson, un matematico francese, sviluppò questa teoria nel 1837. La distribuzione prende il suo nome perché descrive il processo di conteggio degli eventi casuali che si verificano indipendentemente l’uno dall’altro in un determinato intervallo.\nLa variabile casuale \\(Y\\) denota il numero di eventi, e il parametro \\(\\lambda\\) rappresenta il tasso medio di occorrenza degli eventi in quell’intervallo.\nLa funzione di massa di probabilità della distribuzione di Poisson è:\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\]\ndove:\n\n\\(P(Y = y \\mid \\lambda)\\) è la probabilità di osservare esattamente \\(y\\) eventi,\n\\(\\lambda\\) è il tasso medio di eventi,\n\\(y\\) è il numero di eventi, un intero non negativo.\n\nUna proprietà chiave della distribuzione di Poisson è che il valore atteso (\\(E[Y]\\)) e la varianza (\\(Var[Y]\\)) sono entrambi pari a \\(\\lambda\\). Questo implica che con l’aumento di \\(\\lambda\\), la variabilità degli eventi aumenta proporzionalmente, riflettendo una maggiore dispersione dei dati attorno al valore medio.\nQuale esempio, presentiamo qui sotto un grafico con la distribuzione di Poisson di parametro \\(\\lambda\\) = 2.\n\n# Tasso medio di occorrenza di eventi\nlambda_value = 2\n\n# Creazione della distribuzione di Poisson con il tasso medio specificato\npoisson_dist = stats.poisson(mu=lambda_value)\n\n# Calcolo della probabilità di avere un certo numero di eventi\nk_values = range(0, 11)  # Consideriamo valori da 0 a 10\n\n# Calcolo delle probabilità corrispondenti\nprobabilities = poisson_dist.pmf(k_values)\n\nplt.figure()\n\n# Plot della distribuzione di massa di probabilità\nplt.bar(k_values, probabilities, alpha=0.5)\nplt.xlabel('Numero di Eventi (k)')\nplt.ylabel('Probabilità')\nplt.title('Distribuzione di Massa di Probabilità di Poisson')\nplt.show()\n\n\n\n\n\n\n\n\nLa probabilità di ottenere un singolo valore \\(y\\) si calcola utilizzando la funzione di massa di probabilità (pmf), dove l’argomento k rappresenta il numero di eventi (\\(y\\)) e mu è uguale a \\(\\lambda\\). Ad esempio, per determinare la probabilità di osservare esattamente tre eventi (\\(y = 3\\)) con un tasso di occorrenza \\(\\lambda\\) = 2, indicata come \\(P(Y = 3)\\), si utilizza la seguente istruzione:\n\nstats.poisson.pmf(k=3, mu=2)\n\n0.18044704431548356\n\n\nLa probabilità di non più di 3 eventi, indicata come \\(P(Y \\leq 3)\\), si ottiene nel modo seguente:\n\np = stats.poisson.pmf(k=0, mu=2) + stats.poisson.pmf(k=1, mu=2) + stats.poisson.pmf(k=2, mu=2) + stats.poisson.pmf(k=3, mu=2)\np\n\n0.857123460498547\n\n\nLa funzione ppf, con la probabilità e \\(\\lambda\\) come argomenti, restituisce il quantile della distribuzione di Poisson. Ad esempio, nel caso precedente, abbiamo:\n\nstats.poisson.ppf(p, mu=2)\n\n3.0\n\n\nLa funzione di distribuzione cumulativa si calcola utilizzando cdf. Ad esempio, per calcolare \\(P(Y \\leq 3)\\) si utilizza:\n\nstats.poisson.cdf(3, mu=2)\n\n0.857123460498547\n\n\nLa generazione di numeri casuali dalla distribuzione di Poisson può essere ottenuta utilizzando rng. Ad esempio:\n\nmu = 2\nx = rng.poisson(mu, 1000000)\n\nVerifichiamo:\n\nnp.mean(x)\n\n1.998219\n\n\n\nnp.var(x, ddof=0)\n\n1.996941828039\n\n\nEsempio. I dati provenienti dal reparto di maternità di un certo ospedale mostrano che c’è una media storica di 4.5 bambini nati in questo ospedale ogni giorno. Qual è la probabilità che domani nascano 6 bambini in questo ospedale?\nPer prima cosa, calcoliamo la probabilità teorica di questo evento utilizzando dpois(). Il numero di successi che stiamo considerando è 6, quindi imposteremo x = 6. Inoltre, questa media storica di 4,5 nascite al giorno è il nostro valore per lambda, quindi imposteremo lambda = 6.\n\np = stats.poisson.pmf(k=6, mu=4.5)\nprint(f\"La probabilità che domani in questo ospedale nasceranno 6 bambini è: {p:.4f}\")\n\nLa probabilità che domani in questo ospedale nasceranno 6 bambini è: 0.1281\n\n\nSimuliamo le nascite in questo ospedale per un anno (n = 365) utilizzando la funzione np.random.poisson e confrontiamo la proporzione di giorni in cui ci sono stati 6 nascite con la probabilità teorica che abbiamo calcolato in precedenza.\n\n# Simuliamo le nascite in un anno (365 giorni) con una media storica di 4.5 nascite al giorno\nn_days = 365\nmean_births_per_day = 4.5\nsimulated_births = rng.poisson(mean_births_per_day, n_days)\n\n# Calcoliamo la proporzione di giorni in cui sono nati esattamente 6 bambini nella simulazione\nproportion_six_births = np.mean(simulated_births == 6)\n\n# Stampiamo la proporzione calcolata\nprint(f\"La proporzione di giorni in cui, nella simulazione, sono nati 6 bambini è: {proportion_six_births:.4f}\")\n\nLa proporzione di giorni in cui, nella simulazione, sono nati 6 bambini è: 0.1342\n\n\nVisualizziamo i risultati della simulazione.\n\n# Visualizziamo l'istogramma delle nascite simulate\nplt.hist(simulated_births, bins=np.arange(12) - 0.5, density=True, alpha=0.5)\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\nplt.xticks(np.arange(11));\n\n\n\n\n\n\n\n\nCalcoliamo la probabilità teorica della nascita di più di 6 bambini in un giorno.\n\nprob_more_than_six = 1 - stats.poisson.cdf(6, mean_births_per_day)\nprint(f\"La probabilità teorica di più di 6 bambini nati è: {prob_more_than_six:.4f}\")\n\nLa probabilità teorica di più di 6 bambini nati è: 0.1689\n\n\nCalcoliamo la proporzione corrispondente nella simulazione\n\nproportion_more_than_six = np.mean(simulated_births &gt; 6)\nprint(f\"La proporzione di giorni con più di 6 bambini nati nella simulazione è: {proportion_more_than_six:.4f}\")\n\nLa proporzione di giorni con più di 6 bambini nati nella simulazione è: 0.1808\n\n\n\nbins = np.arange(12) - 0.5\nhist, edges = np.histogram(simulated_births, bins=bins, density=True)\n\n# Disegna l'istogramma\nfor i in range(len(hist)):\n    if edges[i] &gt;= 6:\n        color = 'red'  # Colore per x &gt; 6\n    else:\n        color = 'blue'  # Colore per x &lt;= 6\n    plt.bar(edges[i], hist[i], width=1, align='edge', color=color, alpha=0.5)\n\n# Imposta etichette e titolo\nplt.xlabel('Numero di bambini nati per periodo')\nplt.ylabel('Proporzione')\nplt.title('365 nascite simulate in un ospedale con Poisson($\\\\mu$ = 4.5)')\n_ = plt.xticks(np.arange(11))",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "chapters/probability/11_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.5 Distribuzione Beta-Binomiale",
    "text": "35.5 Distribuzione Beta-Binomiale\nLa distribuzione beta-binomiale rappresenta una estensione della distribuzione binomiale che tiene conto della variabilità nella probabilità di successo tra i vari tentativi. Viene descritta da tre parametri principali: \\(N\\), \\(\\alpha\\) e \\(\\beta\\).\nNel dettaglio, la funzione di massa di probabilità per la distribuzione beta-binomiale è data da:\n\\[\n\\text{BetaBinomiale}(y | N, \\alpha, \\beta) = \\binom{N}{y} \\cdot \\frac{B(y + \\alpha, N - y + \\beta)}{B(\\alpha, \\beta)},\n\\tag{35.4}\\]\ndove:\n\n\\(y\\) indica il numero di successi osservati.\n\\(N\\) rappresenta il numero totale di tentativi.\n\\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione beta, che modellano la variabilità nella probabilità di successo tra i tentativi.\n\nLa funzione \\(B(u, v)\\), nota come funzione beta, è definita tramite l’uso della funzione gamma \\(\\Gamma\\), secondo la formula:\n\\[\nB(u, v) = \\frac{\\Gamma(u) \\Gamma(v)}{\\Gamma(u + v)},\n\\]\ndove la funzione gamma \\(\\Gamma\\) generalizza il concetto di fattoriale a numeri reali e complessi.\nL’importanza della distribuzione beta-binomiale deriva dalla sua capacità di modellare situazioni in cui la probabilità di successo non è fissa, ma segue una distribuzione di probabilità, specificatamente una distribuzione beta. Ciò la rende particolarmente adatta per applicazioni in cui le probabilità di successo cambiano in maniera incerta da un tentativo all’altro, come può avvenire in contesti di ricerca clinica o in studi comportamentali. Rispetto alla distribuzione binomiale, che assume una probabilità di successo costante per tutti i tentativi, la beta-binomiale offre una rappresentazione più realistica e flessibile per dati empirici che presentano variabilità nelle probabilità di successo.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-categorica",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.6 La Distribuzione Categorica",
    "text": "35.6 La Distribuzione Categorica\nLa distribuzione categorica è una distribuzione di probabilità discreta utilizzata per modellare eventi con più esiti distinti e non ordinati. È una generalizzazione della distribuzione Bernoulliana, che si limita a due esiti (successo e fallimento), ed è utile in situazioni in cui un evento può produrre uno tra molti esiti, ciascuno con una probabilità associata.\n\n35.6.1 Definizione e Funzione di Massa di Probabilità\nLa distribuzione categorica può essere caratterizzata dalla sua funzione di massa di probabilità (PMF):\n\\[\np(X = x) = \\mathcal{Categorical}(X \\mid p) = \\prod_{k=1}^K p_k^{I_{x=k}},\n\\]\ndove:\n\n\\(K\\) è il numero di esiti possibili,\n\\(p_k\\) è la probabilità associata al \\(k\\)-esimo esito,\n\\(I_{x=k}\\) è una funzione indicatrice che vale 1 se \\(x = k\\) e 0 altrimenti.\n\nLe probabilità \\(p_k\\) formano un vettore:\n\\[\np =\n\\begin{pmatrix}\np_1\\\\\np_2\\\\\n\\dots \\\\\np_K\n\\end{pmatrix},\n\\]\nche soddisfa la condizione:\n\\[\n\\sum_{k=1}^K p_k = 1.\n\\]\nIn altre parole, la somma delle probabilità di tutti i possibili esiti è pari a 1, come richiesto da qualsiasi distribuzione di probabilità.\n\n\n35.6.2 Proprietà Principali\n\nEsiti Multipli: La distribuzione categorica è adatta per modellare eventi con più di due esiti distinti. Un esempio classico è il lancio di un dado a sei facce, dove ciascun esito ha una probabilità di \\(\\frac{1}{6}\\) nel caso di un dado equo.\nGeneralizzazione della Distribuzione Bernoulliana: La distribuzione categorica è una generalizzazione della distribuzione Bernoulliana. In particolare, la distribuzione Bernoulliana rappresenta un caso speciale della distribuzione categorica con due sole categorie (\\(K = 2\\)), come il risultato di un lancio di una moneta (testa o croce).\nProbabilità in Forma di Simplex: Le probabilità degli esiti nella distribuzione categorica sono rappresentate da un vettore simplex. Un simplex è un vettore di probabilità non negative che sommano a 1, rispettando la condizione fondamentale delle distribuzioni di probabilità.\n\n\n\n35.6.3 Utilizzo della Distribuzione Categorica in Stan\nIn Stan, la distribuzione categorica è impiegata per modellare la probabilità di un singolo esito tra diversi possibili risultati. Questo è particolarmente utile in contesti come le catene di Markov, dove ogni stato può evolvere verso uno tra molti altri stati con una certa probabilità.\nAd esempio, supponiamo di avere una matrice di transizione \\(P\\) che descrive le probabilità di passaggio tra stati in una catena di Markov. Ogni riga della matrice \\(P\\) rappresenta una distribuzione categorica, in cui le voci corrispondono alle probabilità di transizione dallo stato corrente agli stati successivi. La distribuzione categorical può essere utilizzata per modellare la probabilità di osservare una specifica transizione.\nConsideriamo un esempio pratico: se uno studente si trova nello stato \\(A\\) al tempo \\(t\\), e le probabilità di transizione agli stati \\(A\\), \\(B\\) e \\(C\\) sono rispettivamente \\(0.7\\), \\(0.2\\) e \\(0.1\\), possiamo modellare la probabilità che l’evento successivo sia una transizione verso uno di questi stati usando la distribuzione categorica:\n\\[\nX \\sim \\text{categorical}(0.7, 0.2, 0.1)\n\\]\nQui, la variabile aleatoria \\(X\\) segue una distribuzione categorical con le probabilità assegnate ai tre possibili esiti (stati \\(A\\), \\(B\\), e \\(C\\)). Questo consente di simulare il prossimo stato in base alle probabilità specificate.\n\n35.6.3.1 Applicazione nelle Catene di Markov\nLa distribuzione categorical è particolarmente efficace nei modelli di catene di Markov, dove descrive le transizioni tra stati in un sistema dinamico. Ogni transizione tra stati è trattata come un evento discreto con più esiti possibili, ciascuno con la propria probabilità. Questo approccio è utile per modellare sistemi con molteplici stati e transizioni complesse, garantendo flessibilità e precisione nella simulazione delle dinamiche del sistema.\nIn sintesi, la distribuzione categorica in Stan permette di modellare eventi con molteplici esiti in modo semplice ed efficace, rendendola uno strumento prezioso per descrivere fenomeni dinamici, come le catene di Markov o qualsiasi altro processo con transizioni probabilistiche tra stati.\nDi seguito, esaminiamo come simulare una distribuzione categorica utilizzando numpy e come creare un istogramma per visualizzare la distribuzione di massa:\n\n# Definire le probabilità della distribuzione categorica\nprobabilities = [0.6, 0.3, 0.1]  # Le probabilità per ciascun esito\n\n# Definire le categorie\ncategories = [\"A\", \"B\", \"C\"]\n\n# Numero di campioni da generare\nn_samples = 1000\n\n# Simulare la distribuzione categorica\nsamples = np.random.choice(categories, size=n_samples, p=probabilities)\n\n# Creare un istogramma dei risultati\nplt.hist(samples, bins=np.arange(len(categories) + 1) - 0.5, edgecolor=\"black\")\nplt.xticks(range(len(categories)), categories)\nplt.xlabel(\"Categorie\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Istogramma della Distribuzione Categorica Simulata\")\nplt.show()\n\n\n\n\n\n\n\n\nConcludiamo chiarendo la relazione tra la distribuzione categorica e quella multinomiale.\nLa distribuzione categorica descrive l’esito di una singola prova con \\(K\\) categorie, ciascuna con una probabilità associata. È una generalizzazione della distribuzione Bernoulliana, che prevede solo due esiti (successo o fallimento).\nEsempio: Lanciare un dado a sei facce una volta. Ciascuna faccia ha una probabilità di \\(\\frac{1}{6}\\).\nLa distribuzione multinomiale estende la distribuzione binomiale a più categorie e descrive il numero di esiti su un insieme di prove indipendenti che seguono una distribuzione categorica.\nEsempio: Lanciare un dado dieci volte e contare quante volte appare ciascuna faccia.\nLa distribuzione categorica è un caso particolare della multinomiale quando si effettua una sola prova (\\(n = 1\\)). Nella distribuzione categorica otteniamo un singolo esito, mentre nella multinomiale otteniamo un conteggio di esiti su più prove.\n\n\n\n35.6.4 Implementazioni in NumPy\n\nnumpy.random.choice: Campiona da una distribuzione categorica, restituendo uno o più esiti secondo le probabilità specificate.\nnumpy.random.multinomial: Usata per la distribuzione multinomiale, può simulare una distribuzione categorica impostando \\(n = 1\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "href": "chapters/probability/11_discr_rv_distr.html#la-distribuzione-geometrica",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.7 La Distribuzione Geometrica",
    "text": "35.7 La Distribuzione Geometrica\nLa distribuzione geometrica è una distribuzione discreta che modella il numero di tentativi necessari per ottenere il primo successo in una sequenza di prove Bernoulliane indipendenti. Ogni prova ha due possibili esiti: successo (con probabilità \\(p\\)) o fallimento (con probabilità \\(1 - p\\)).\nIn termini pratici, la distribuzione geometrica può essere utilizzata per rispondere alla domanda: “Quante prove falliscono prima di ottenere il primo successo?”.\n\n35.7.1 Funzione di Massa di Probabilità\nLa funzione di massa di probabilità (PMF) della distribuzione geometrica è definita come:\n\\[\nP(X = k) = (1 - p)^{k-1} \\cdot p\n\\]\ndove:\n\n\\(X\\) è il numero di tentativi fino al primo successo (incluso il tentativo in cui si ottiene il successo).\n\\(p\\) è la probabilità di successo in ogni prova.\n\\(k\\) è il numero di prove necessarie per ottenere il primo successo (un numero intero positivo, \\(k \\geq 1\\)).\n\n\n\n35.7.2 Proprietà della Distribuzione Geometrica\n\nValore Atteso (Media): La media del numero di prove fino al primo successo è data da:\n\n\\[\n\\mathbb{E}[X] = \\frac{1}{p}.\n\\]\nQuesto significa che, in media, ci si aspetta di avere \\(\\frac{1}{p}\\) prove prima di ottenere un successo.\n\nVarianza: La varianza della distribuzione geometrica è:\n\n\\[\n\\text{Var}(X) = \\frac{1 - p}{p^2}.\n\\]\n\nMemoria Assente: La distribuzione geometrica ha una proprietà interessante chiamata “assenza di memoria”. Ciò significa che, dato che non si è verificato alcun successo fino a un certo punto, la probabilità di successo nelle prove future è indipendente dal passato e rimane sempre \\(p\\).\n\n\n\n35.7.3 Applicazione nel Modello\nAd esempio, supponiamo di voler modellare quanti giorni passano prima che un animale venga adottato in un rifugio. Se la probabilità giornaliera di essere adottato è \\(p\\), la distribuzione geometrica può dirci quanto tempo ci aspettiamo prima che l’adozione avvenga. Se, ad esempio, \\(p = 0.2\\), significa che c’è il 20% di probabilità di adozione ogni giorno, e possiamo modellare il numero di giorni fino all’adozione usando una distribuzione geometrica.\nNel nostro modello di adozione, stiamo utilizzando la distribuzione geometrica per modellare i giorni fino all’adozione. La probabilità \\(p\\) rappresenta la probabilità giornaliera che un animale venga adottato, e la distribuzione geometrica ci permette di modellare il numero di giorni fino a quando avviene il successo (adozione).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#considerazioni-conclusive",
    "href": "chapters/probability/11_discr_rv_distr.html#considerazioni-conclusive",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.8 Considerazioni Conclusive",
    "text": "35.8 Considerazioni Conclusive\nIn questo capitolo, abbiamo esplorato diverse distribuzioni discrete fondamentali, ciascuna con le sue specifiche applicazioni e peculiarità. Abbiamo iniziato con la distribuzione Bernoulliana, che modella esperimenti con due possibili esiti, come il lancio di una moneta. Abbiamo poi approfondito la distribuzione Binomiale, una generalizzazione della Bernoulliana, che si focalizza sul conteggio del numero di successi in un dato numero di prove indipendenti.\nAbbiamo anche esaminato la distribuzione Beta-Binomiale, che estende ulteriormente il modello Binomiale incorporando la variabilità nella probabilità di successo, e la distribuzione di Poisson, utilizzata per modellare il numero di eventi che si verificano in un intervallo di tempo o spazio, quando questi eventi sono rari e indipendenti.\nInfine, abbiamo discusso la distribuzione Discreta Uniforme, che attribuisce la stessa probabilità a ogni evento in un insieme finito e discreto. Questa distribuzione è particolarmente utile quando non abbiamo ragioni per assegnare probabilità diverse ai diversi esiti.\nQueste distribuzioni formano il cuore dell’analisi statistica discreta e trovano applicazione in un’ampia gamma di settori. In particolare, nel contesto dell’analisi bayesiana, la comprensione della distribuzione Binomiale e Beta-Binomiale è cruciale, poiché queste distribuzioni forniscono le basi per l’aggiornamento bayesiano, un concetto chiave che sarà esplorato nei capitoli successivi.\nPer coloro interessati a tecniche più avanzate, la generazione di valori casuali a partire da queste distribuzioni è trattata nell’appendice {ref}rng-appendix. Questa sezione fornisce strumenti e approfondimenti utili per l’applicazione pratica di questi modelli probabilistici.\nIn conclusione, le distribuzioni discrete forniscono strumenti essenziali e versatili per modellare e analizzare fenomeni caratterizzati da eventi distinti e quantificabili. La comprensione approfondita di queste distribuzioni è cruciale per chiunque desideri esplorare il vasto campo della probabilità e della statistica.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "href": "chapters/probability/11_discr_rv_distr.html#esercizi",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.9 Esercizi",
    "text": "35.9 Esercizi\n\nEsercizio 35.1 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizza Python per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/11_discr_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "35  Distribuzioni di v.c. discrete",
    "section": "35.10 Informazioni sull’Ambiente di Sviluppo",
    "text": "35.10 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue May 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Distribuzioni di v.c. discrete</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html",
    "href": "chapters/probability/12_cont_rv_distr.html",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "",
    "text": "Introduzione\nAnalogamente a quanto avviene per le variabili casuali discrete, anche per le variabili casuali continue possiamo rappresentare la variabilità all’interno di una popolazione attraverso un modello statistico, ma in questo caso utilizziamo le densità di probabilità – si veda il Capitolo 34. Mentre le distribuzioni di probabilità discrete si applicano a fenomeni con un numero finito o numerabile di esiti, le densità di probabilità sono fondamentali per descrivere variabili che possono assumere un continuum di valori.\nLa funzione di densità di probabilità \\(f(x)\\) associata a una variabile casuale continua \\(X\\) rappresenta la distribuzione della probabilità all’interno della popolazione. Questa funzione non fornisce la probabilità esatta di un singolo valore, ma piuttosto la probabilità di osservare valori di \\(X\\) all’interno di un intervallo specifico. Così come per le distribuzioni discrete, anche le densità di probabilità costituiscono un modello della popolazione, una rappresentazione matematica che ci consente di fare previsioni e di comprendere meglio i fenomeni aleatori continui.\nIniziamo con la distribuzione continua uniforme.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-uniforme",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-uniforme",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.1 Distribuzione uniforme",
    "text": "36.1 Distribuzione uniforme\nLa distribuzione uniforme è la più sempilce funzione di densità di probabilità. Consideriamo nuovamente l’esperimento con lo spinner che abbiamo introdotto nel Capitolo 34. Simuliamo 20 valori che potrebbero essere ottenuti facendo ruotare lo spinner e li rappresentiamo con un istogramma.\n\ny = rng.uniform(low=0, high=360, size=20)\nprint(y)\n\n[272.91158643 127.62934853 349.45128878 321.52360368 280.21805895\n  70.06993483 168.01956134  15.76935568  55.54421714 245.89762317\n 268.11437613 348.30350368 117.29712893 133.36549417 169.04009206\n  68.20968927  46.77174192 171.25377344  81.68736566 241.13303809]\n\n\n\nplt.figure()\ncount, bins, ignored = plt.hist(y, bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\nplt.ylabel(\"Frequenza relativa\");\n\n\n\n\n\n\n\n\nSebbene possiamo pensare che sia ugualmente probabile che si verifichi qualsiasi risultato tra 0 e 360, l’istogramma non sembra suggerire questo. Ma lo spinner è stato fatto ruotare solo 20 volte. Proviamo con 100,000 ripetizioni.\n\nplt.figure()\ncount, bins, ignored = plt.hist(rng.uniform(0, 360, 100000), bins=36, density=True, alpha=0.5)\nplt.xlabel(\"Risultato dello spinner\")\n_ = plt.ylabel(\"Frequenza relativa\")\n\n\n\n\n\n\n\n\nIn questo caso, anche se c’è una variazione nelle altezze delle barre (con \\(\\Delta\\) = 10), la forma generale dell’istogramma sembra essere piuttosto piatta, ovvero uniforme, nell’intero intervallo dei valori possibili di \\(X\\), ovvero \\(0 &lt;= X &lt;= 360\\). Se potessimo ottenere un numero enorme di risultati dello spinner, il profilo dell’istogramma assumerebbe la forma della funzione di densità uniforme mostratra nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 100)\nplt.plot(x, stats.uniform.pdf(x, 0, 360), lw=2, label=\"uniform pdf\")\nplt.xlabel(\"x\")\nplt.ylabel(\"p(x)\");\n\n\n\n\n\n\n\n\nQuando la variabile casuale \\(X\\) è continua, come nel caso del risultato della rotazione dello spinner, allora per rappresentare le probabilità usiamo una curva chiamata funzione di densità di probabilità. Poiché la scala dello spinner va da 0 a 360, sappiamo che tutti i risultati possibili devono cadere in questo intervallo, quindi la probabilità che \\(X\\) assuma un valore nell’intervallo [0, 360] è 1.0. Questa probabilità è rappresentata dall’area totale sotto la funzione di densità della figura precedente tra 0 e 360. Poiché l’area di questo rettangolo è data dall’altezza per la base e la base è uguale a 360, l’altezza di questa curva di densità deve essere 1/360 = 0.00278. L’ordinata della funzione di densità (qui 0.00278 nell’intervallo [0, 360] e 0 altrove) è chiamata densità.\nLe probabilità corrispondono alle aree sottese alla curva di densità nell’intervallo di valori \\(X\\) specificato. Per esempio, nell’esperimento dello spinner possiamo chiederci quale sia la probabilità di ottenere un numero compreso tra 150 e 250, ovvero \\(P(150 &lt; X &lt; 250)\\). Per trovare la risposta dobbiamo calcolare l’area di un rettangolo. La base è 250 - 150 = 100. L’altezza è 0.00278. Dunque, la probabilità è\n\n100*1/360\n\n0.2777777777777778\n\n\nPer svolgere questo calcolo i software utilizzano la funzione di ripartizione, \\(P(X &lt; x)\\). Per trovare l’area in un intervallo è necessario sottrarre due aree. Nel caso presente abbiamo \\(P(x &lt; 250) - P(x &lt; 150)\\), ovvero:\n\nstats.uniform.cdf(250, 0, 360) - stats.uniform.cdf(150, 0, 360)\n\n0.27777777777777773\n\n\nLa probabilità cercata è rappresentata dal rettangolo indicato nella figura seguente.\n\nplt.figure()\nx = np.linspace(0, 360, 1000)\nfx = stats.uniform.pdf(x, 0, 360)\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 150) & (x &lt;= 250), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera più formale possiamo dire che la distribuzione continua uniforme è una distribuzione di probabilità continua che assegna lo stesso grado di fiducia a tutti i possibili valori di una variabile definita in un certo intervallo \\(S=[a,b]\\subset {\\mathbb  {R}}\\). La distribuzione continua uniforme viene indicata con \\({\\mathcal  {U}}(a,b)={\\mathcal  {U}}([a,b])\\). Come intervallo \\([a,b]\\) viene spesso preso l’intervallo unitario \\(I=[0,1]\\).\nLa densità di probabilità di una variabile casuale continua uniforme \\({\\mathcal  {U}}(a,b)\\) è\n\\[\nf(x)={\\frac  {1}{b-a}} \\quad \\text{su}\\; [a, b].\n\\]\nIl suo valore attesto è\n\\[\n\\displaystyle E(X)={\\frac {1}{2}}(b+a).\n\\]\nLa sua varianza è\n\\[\nV(X)={\\frac {1}{12}}(b-a)^{2}.\n\\]\nIn Python è possibile manipolare la distribuzione uniforme mediante la funzione uniform del modulo scipy.stats. Di default, la funzione scipy.stats.uniform() è un’istanziazione di \\({\\mathcal{U}}(0,1)\\). Se utilizziamo la funzione pdf() (probability density function) otteniamo l’ordinata della funzione di densità \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei valori \\(x\\) passati in input. Per esempio, esaminiamo la funzione di densità \\({\\mathcal{U}}(0,1)\\) in corrispondenza di 0.5, 0.8 e 1.2. Per i primi due valori ci aspettiamo di ottenere 1; in corrispondenza di 1.2 ci aspettiamo di ottenere 0, poiché questo valore è al di fuori dell’intervallo \\([ 0, 1]\\).\n\nstats.uniform.pdf([0.5, 0.8, 1.2])\n\narray([1., 1., 0.])\n\n\nCon la funzione cdf() (cumulative density function) otteniamo la funzione di ripartizione. Per esempio, per \\({\\mathcal{U}}(0,1)\\) in corrispondenza dei punti 0.5 e 0.8 otteniamo\n\nstats.uniform.cdf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nUsando la funzione di ripartizione è possibile calcolare la probabilità che la variabile casuale continua assuma un valore nell’intervallo specificato. Per esempio, per \\({\\mathcal{U}}(0,1)\\) troviamo \\(P(0.5 &lt; x &lt; 0.8)\\)\n\nstats.uniform.cdf(0.8) - stats.uniform.cdf(0.5)\n\n0.30000000000000004\n\n\nI quantili di una funzione di densità (ovvero, il valore della variabile casuale \\(X\\) in corrispondenza del valore della funzione di ripartizione fornito in input) si ottengono con la funzione ppf() (probability point function). Per esempio, troviamo i quantili di ordine 0.5 e 0.8 di una \\({\\mathcal  {U}}(0,1)\\).\n\nstats.uniform.ppf([0.5, 0.8])\n\narray([0.5, 0.8])\n\n\nInfine, è possibile simulare dei valori casuali della distribuzione \\({\\mathcal{U}}(0,1)\\) usando la funzione stats.uniform(). Se vogliamo 5 valori da una \\({\\mathcal{U}}(0,1)\\), scriviamo:\n\nrng.uniform(0, 1, 5)\n\narray([0.51383373, 0.32883263, 0.16402071, 0.13786892, 0.15572435])\n\n\nVerifico il valore atteso di 100,000 realizzazioni di \\({\\mathcal {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).mean()\n\n0.4993283752250098\n\n\nVerifico la varianza di 100,000 realizzazioni di \\({\\mathcal  {U}}(0,1)\\).\n\nrng.uniform(0, 1, 100000).var()\n\n0.0832097723457758\n\n\n\n1 / 12\n\n0.08333333333333333",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.2 Distribuzione esponenziale",
    "text": "36.2 Distribuzione esponenziale\nUn’altra distribuzione di densità molto semplice è la distribuzione esponenziale. La distribuzione esponenziale viene spesso utilizzata per modellare il tempo trascorso prima che un evento si verifichi (tempo di attesa).\nLa distribuzione esponenziale è l’unica distribuzione di probabilità continua che possiede la proprietà di assenza di memoria. Ad esempio, ipotizziamo che il tempo necessario affinché un bicchiere da vino si rompa dopo il primo utilizzo segua una distribuzione esponenziale. Supponiamo inoltre che ci sia un bicchiere da vino che non si è rotto dopo 3 anni dal primo utilizzo. L’assenza di memoria significa che la probabilità che questo bicchiere da vino non si rompa nel prossimo anno è la stessa della probabilità che un altro bicchiere da vino nuovo non si rompa nel primo anno di utilizzo.\nChiamiamo \\(X\\) il tempo di attesa. Sia \\(\\mu = \\mathbb{E}(X)\\) il tempo di attesa medio. La funzione di densità esponenziale è\n\\[\nf(x) = \\lambda {\\rm e}^{-\\lambda x}, \\quad \\text{con} \\; \\lambda = 1/\\mu,\\, \\lambda &gt; 0,\\, x &gt; 0,\n\\tag{36.1}\\]\novvero\n\\[\nf(x) = \\frac{1}{\\mu} {\\rm e}^{-x/\\mu}.\n\\]\nLa media di una distribuzione esponenziale è\n\\[\nE(X) = \\frac{1}{\\lambda}.\n\\]\nLa varianza di una distribuzione esponenziale è\n\\[\nV(X) = \\mu = \\frac{1}{\\lambda^2}.\n\\]\nLa deviazione standard è dunque uguale alla media:\n\\[\n\\sigma_X = \\frac{1}{\\lambda} = \\mu.\n\\]\nAd esempio, il tempo di attesa della pubblicazione del voto di un esame scritto segue una distribuzione esponenziale. Supponiamo che, in questo Corso di Laurea, il tempo di attesa medio per conoscere il risultato di un esame scritto sia di 4 giorni. La funzione esponenziale diventa\n\\[\nf(x) = \\frac{1}{4} \\exp^{-x/4}.\n\\]\nPer disegnare un grafico della funzione esponenziale possiamo usare la funzione stats.expon(). La densità è data da pdf(x, loc, scale), laddove il parametro loc è 0 e scale è la deviazione standard. Nel caso presente abbiamo:\n\nx = np.arange(0, 20, 0.01)\nmu = 4\nlam = 1 / mu\nstdev = 1 / lam\npdf = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\");\n\n\n\n\n\n\n\n\nChiediamoci, ad esempio, quale sia la probabilità di dovere aspettare non più di un giorno e mezzo per conoscere il voto dell’esame. La risposta a questa domanda è data dalla funzione di ripartizione in corrispondenza di 1.5, ovvero \\(F(1.5) = P(X \\leq 1.5)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 0) & (x &lt;= 1.5), color=\"0.75\");\n\n\n\n\n\n\n\n\nPossiamo trovare la risposta usando la funzione cdf():\n\nstats.expon.cdf(1.5, loc=0, scale=stdev) \n\n0.3127107212090278\n\n\nChiediamoci, ad esempio quale sia la probabilità di conoscere il voto in un tempo compreso tra 1 e 6 giorni. Dobbiamo trovare l’area sottesa alla funzione di densità nell’intervallo [1, 6]. Usando la fuzione di ripartizione, calcoliamo \\(F(6) - F(1) = P(X &lt;= 6) - P(X &lt;= 1)\\).\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1) & (x &lt;= 6), color=\"0.75\");\n\n\n\n\n\n\n\n\n\nstats.expon.cdf(6, loc=0, scale=stdev) - stats.expon.cdf(1, loc=0, scale=stdev)\n\n0.5556706229229751\n\n\nTroviamo la probabilità di dovere aspettare almeno 5 giorni e mezzo.\n\nfx = stats.expon.pdf(x, loc=0, scale=stdev)\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 5.5) & (x &lt;= 21), color=\"0.75\");\n\n\n\n\n\n\n\n\nLa probabilità cercata è data dalla probabilità dell’evento complementare di quello fornito dalla funzione di ripartizione.\n\n1 - stats.expon.cdf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\n\nstats.expon.sf(5.5, loc=0, scale=stdev) \n\n0.25283959580474646\n\n\nSe la media del tempo di attesa nel Corso di Laurea fosse di 4 giorni, allora circa una volta su 4 lo studente dovrà aspettare almeno 5.5 giorni per conoscere il voto dello scritto.\nLa figura seguente mostra un istogramma di 1000000 valori casuali estratti dalla distribuzione esponenziale di parametro \\(\\lambda = 1/4\\). All’istogramma è sovrapposta la funzione di densità.\n\nsamps = rng.exponential(stdev, 100000)\n\nplt.figure()\ncount, bins, ignored = plt.hist(samps, bins=100, density=True, alpha=0.5)\nplt.plot(x, fx)\nplt.xlim([0, 20])\nplt.ylabel(\"Frequenza relativa\")\nplt.xlabel(\"Tempo di attesa\");",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.3 Distribuzione Gaussiana",
    "text": "36.3 Distribuzione Gaussiana\nLa più importante distribuzione di densità è la Gaussiana. Non c’è un’unica distribuzione gaussiana (o Normale): la distribuzione gaussiana è una famiglia di distribuzioni. Tali distribuzioni sono dette “gaussiane” in onore di Carl Friedrich Gauss (uno dei più grandi matematici della storia il quale, tra le altre cose, scoprì l’utilità di tale funzione di densità per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densità alle misurazioni dell’uomo. Karl Pearson usò per primo il termine “distribuzione normale” anche se ammise che questa espressione “ha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell’altro, non siano normali.”\n\n36.3.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre notò che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Per esempio, con 10 prove e una probabilità di successo di 0.9, la distribuzione è chiaramente asimmetrica.\n\nn = 10\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist);\n\n\n\n\n\n\n\n\nQuando il numero di prove N viene aumentato di un fattore di 100 a N = 1000, mantenendo costante la probabilità di successo del 90%, si osserva che la distribuzione assume una forma campanulare quasi simmetrica. Questa osservazione porta a una scoperta di de Moivre: quando N diventa grande, la funzione gaussiana, nonostante rappresenti la densità di variabili casuali continue, offre una buona approssimazione alla funzione di massa di probabilità binomiale.\n\nn = 1000\np = 0.9\nr_values = list(range(n + 1))\ndist = [stats.binom.pmf(r, n, p) for r in r_values]\n\nplt.figure()\nplt.bar(r_values, dist)\nplt.xlim(850, 950);\n\n\n\n\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "href": "chapters/probability/12_cont_rv_distr.html#la-normale-prodotta-con-una-simulazione",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.4 La Normale prodotta con una simulazione",
    "text": "36.4 La Normale prodotta con una simulazione\nIl libro “Rethinking Statistics” di McElreath (2020) spiega come sia possibile ottenere la distribuzione normale attraverso una simulazione. Immaginiamo di avere duemila persone che si trovano allineate su una linea di partenza. Quando viene dato il segnale di partenza, ogni persona lancia una moneta e compie un passo avanti o indietro a seconda del risultato del lancio. La lunghezza di ogni passo può variare da 0 a 1 metro. Ogni persona lancia la moneta 16 volte e quindi compie 16 passi.\nI risultati ottenuti da una serie di passeggiate casuali si traducono in varie distanze dall’origine, che è il punto da cui si parte, contrassegnato come zero, dopo un numero specificato di passi. Queste distanze sono rappresentate numericamente. Al termine di queste passeggiate, non è possibile determinare la posizione esatta di ogni individuo, ma è possibile descrivere accuratamente le caratteristiche della distribuzione delle 1000 distanze dall’origine.\nAd esempio, è possibile prevedere con precisione la frazione di individui che si sono mossi verso in avanti o indietro, o la proporzione di persone che si troveranno a una distanza specifica dal punto di partenza, come a 1.5 metri dall’origine. Queste previsioni sono fattibili perché la distribuzione delle distanze segue una distribuzione Normale.\nIl codice presentato di seguito genera passeggiate casuali utilizzando un generatore di numeri casuali e ne traccia i percorsi risultanti. Il codice inizia inizializzando un oggetto generatore di numeri casuali con la funzione np.random.default_rng() della libreria numpy. Questo generatore sarà usato per produrre numeri casuali uniformemente distribuiti tra -1 e 1, simulando così il lancio di una moneta.\nLa variabile steps specifica il numero di passi per ogni passeggiata casuale, mentre repetitions indica il numero di passeggiate da generare. La variabile show_steps è un elenco di numeri di passi in cui il codice traccerà linee verticali sul grafico.\nSuccessivamente, il codice crea un array bidimensionale di NumPy chiamato x con righe pari a steps + 1 e colonne pari a repetitions. La prima colonna di questo array è riempita di zeri, e le colonne rimanenti sono riempite con la somma cumulativa dei passi, ottenuti da numeri casuali uniformemente distribuiti generati dal generatore di numeri casuali. Questo array verrà utilizzato per memorizzare le posizioni della passeggiata casuale ad ogni passo.\nIl codice poi prepara una figura per tracciare tutte le passeggiate casuali. Il codice traccia anche la prima passeggiata casuale in nero.\n\n# Parametri della simulazione\nnumero_passi = 16  # Numero di passi per passeggiata\nripetizioni = 1000  # Numero di passeggiate da generare\npunti_da_evidenziare = [4, 8, 16]  # Punti da evidenziare sul grafico\n\n# Inizializza l'array per registrare le passeggiate casuali\nx = np.zeros((numero_passi + 1, ripetizioni))\n\n# Genera le passeggiate casuali\nfor i in range(ripetizioni):\n    passi = rng.uniform(-1, 1, numero_passi)  # Genera passi casuali\n    x[1:, i] = np.cumsum(passi)  # Calcola la posizione cumulativa\n\n# Prepara il grafico\nfig, ax = plt.subplots()\nplt.plot(x, color=\"blue\", alpha=0.05)  # Disegna tutte le passeggiate\nplt.plot(x[:, 0], color=\"black\")  # Evidenzia la prima passeggiata\n\n# Evidenzia i punti specifici\nfor punto in punti_da_evidenziare:\n    plt.axvline(punto, linestyle=\"--\", color=\"black\", alpha=0.5)\n\n# Imposta etichette e aspetti del grafico\nplt.xlabel(\"Numero di passi\")\nplt.ylabel(\"Distanza dall'origine\")\nax.set_xticks(punti_da_evidenziare)\nplt.xlim(0, numero_passi + 0.1)\n\n# Mostra il grafico\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico riportato qui sotto visualizza la distribuzione dei passi a partire dalla linea mediana dopo 4, 8 e 16 lanci di moneta/passi. Quello che si nota è che, man mano che procediamo nel numero di passi, le densità iniziano a somigliare alla curva a campana associata alle distribuzioni Gaussiane.\n\n# Crea una figura con 3 subplots in orizzontale, condividendo l'asse X\nfig, axs = plt.subplots(1, 3, figsize=(9, 3), sharex=True)\n\n# Itera sui punti da evidenziare e sugli assi corrispondenti\nfor step, ax in zip(punti_da_evidenziare, axs):\n    # Estrae le posizioni al passo specificato per tutte le ripetizioni\n    posizioni_al_passo = x[step, :]\n    \n    az.plot_kde(posizioni_al_passo, bw=0.01, ax=ax)\n    \n    ax.set_title(f\"{step} passi\")\n    ax.set_ylabel(\"Densità\")\n    ax.set_xlabel(\"Posizioni\")\n    ax.set_xlim(-6, 6)\n    ax.set_xticks([-6, -3, 0, 3, 6])\n\nplt.tight_layout() \nplt.show()\n\n\n\n\n\n\n\n\nLa chiarezza dell’informazione presentata nei grafici precedenti può essere migliorata utilizzando un KDE plot.\n\n# Genera la distribuzione uniforme e calcola la somma come prima\npos = rng.uniform(-1, 1, size=(16, 1000)).sum(0)\n\n# Calcola media e deviazione standard dei dati generati\nmedia, dev_std = np.mean(pos), np.std(pos)\n\n# Spazio dei valori per la distribuzione normale\nvalori = np.linspace(np.min(pos), np.max(pos), 1000)\n\n# Calcola la distribuzione normale con la stessa media e deviazione standard\ndistribuzione_normale = stats.norm.pdf(valori, media, dev_std)\n\n# Disegna la stima della densità kernel dei dati\naz.plot_kde(pos, label='Distribuzione KDE')\n\n# Sovrappone la distribuzione normale\nplt.plot(valori, distribuzione_normale, label='Distribuzione Normale', color = \"C1\", linestyle='--')\n\nplt.xlabel(\"Posizione\")\nplt.ylabel(\"Densità\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nQuesta simulazione in luce un principio fondamentale della teoria delle probabilità: ogni processo che coinvolge la somma di una sequenza di valori casuali, tutti estratti dalla stessa distribuzione, inevitabilmente tende verso una distribuzione normale, comunemente conosciuta come curva gaussiana. Questa tendenza si verifica indipendentemente dalla configurazione iniziale della distribuzione di partenza, che può essere uniforme, come nell’esempio menzionato, o di qualsiasi altro tipo. La forma specifica della distribuzione iniziale influisce sulla velocità con cui si verifica questa convergenza verso il comportamento gaussiano, con variazioni significative nella velocità di convergenza: alcuni processi possono manifestare una convergenza lenta, mentre altri possono convergere estremamente rapidamente. Un esempio emblematico di questo fenomeno è rappresentato dal dispositivo conosciuto come Galton box, il quale offre una rappresentazione visiva e fisica di come la somma di valori casuali generi una distribuzione normale.\nUn modo per razionalizzare la distribuzione Gaussiana è quello di pensare alle medie. Qualunque sia il valore medio della distribuzione di origine, ogni campione da essa può essere considerato una fluttuazione rispetto a quel valore medio. Tuttavia, quando sommiamo queste fluttuazioni insieme, esse si annullano a vicenda. E, facendo ciò, queste fluttuazioni convergono eventualmente alla media delle osservazioni collettive. Non importa quale sia la forma della distribuzione sottostante. A seconda della forma, le somme cumulative convergeranno inevitabilmente sulla media, alcune distribuzioni più lentamente di altre.\nDal punto di vista formale, possiamo definire una variabile casuale continua \\(Y\\) come avente una distribuzione normale se la sua densità di probabilità è distribuita secondo la seguente equazione\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{36.2}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma &gt; 0\\) sono i parametri della distribuzione.\nLa densità normale è unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densità in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell’eq. {eq}eq-normal-formula viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densità Normali con medie -1, -0.5, 0, 1 e con deviazioni standard 0.25, 0.5, 1 e 2 è fornita nella figura seguente.\n\nx = np.arange(-5, 6, 0.001)\n\nmus = [-1.0, -0.5, 0.0, 1.0]\nsigmas = [0.25, 0.5, 1, 2]\n\nplt.figure()\n\nfor mu, sigma in zip(mus, sigmas):\n    pdf = stats.norm.pdf(x, mu, sigma)\n    plt.plot(x, pdf, label=r\"$\\mu$ = {}, $\\sigma$ = {}\".format(mu, sigma))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n36.4.1 Concentrazione\nÈ istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma &lt; Y &lt; \\mu + \\sigma) &= P (-1 &lt; Z &lt; 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma &lt; Y &lt; \\mu + 2\\sigma) &= P (-2 &lt; Z &lt; 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma &lt; Y &lt; \\mu + 3\\sigma) &= P (-3 &lt; Z &lt; 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media è superiore a 3 volte la deviazione standard presenti un carattere di eccezionalità perché meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n\n36.4.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) è l’area sottesa alla curva di densità \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\] (eq-gaussian-rip-formula)\npertanto le probabilità \\(P(Y &lt; y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\nEsaminiamo le funzioni per la densità Normale. Il metodo rng.normal(loc, scale, size) produce size valori casuali estratti dalla distribuzione Normale specificata. Per esempio, un singolo valore casuale dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\) è:\n\nrng.normal(loc=100, scale=15, size=1)\n\narray([77.8271813])\n\n\nEstraiamo ora 10 valori a caso dalla \\(\\mathcal{N}(100, 15)\\):\n\nqi = rng.normal(loc=100, scale=15, size=10)\nprint(qi)\n\n[107.37134121  74.33288092  70.05953321 100.16099998  67.01041676\n 102.19573565 114.68076458  58.88627549  69.38274746 112.14401099]\n\n\nPer trovare la probabilità che un’osservazione estratta a caso dalla \\(\\mathcal{N}(100, 15)\\) abbia un valore minore o uguale a, diciamo, 115, troviamo il valore della funzione di ripartizione (o funzione cumulativa di densità) nel punto 115.\n\nstats.norm.cdf(115, 100, 15)\n\n0.8413447460685429\n\n\nQuesta è l’area sottesa alla funzione di densità nell’intervallo \\([-\\infty, 115]\\), come indicato nella figura seguente.\n\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\n\nplt.figure()\nplt.plot(x, fx)\n_ = plt.fill_between(x, fx, where=x &lt;= 115, color=\"0.75\")\n\n\n\n\n\n\n\n\nSolo per fare un esempio, qui di seguito fornisco il codice Python per calcolare l’integrale che stiamo discutendo per mezzo della funzione quad della libreria SciPy:\n\ndef gaussian(x, mu, sig):\n    return (\n        1.0 / (np.sqrt(2.0 * np.pi) * sig) * np.exp(-np.power((x - mu) / sig, 2.0) / 2)\n    )\n\nmu = 100\nsigma = 15\nresult, error = quad(gaussian, -1000, 115, args=(mu, sigma))\nprint(\"Il risultato è\", result, \"con errore\", error)\n\nIl risultato è 0.8413447460685429 con errore 4.0191197364560644e-10\n\n\nIl risultato replica quello prodotto da .norm.cdf().\nPer trovare la proporzione di persone nella popolazione che hanno un QI maggiore di 2 deviazioni standard dalla media consideriamo l’evento complementare:\n\n1 - stats.norm.cdf(130, 100, 15)\n\n0.02275013194817921\n\n\n\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=x &gt;= 130, color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo usare la Survival Function:\n\nstats.norm.sf(130, 100, 15)\n\n0.022750131948179198\n\n\nLa funzione ppf restituisce il quantile della Normale. Ad esempio:\n\nstats.norm.ppf(1 - 0.022750131948179195, 100, 15)\n\n130.0\n\n\n\n\n36.4.3 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale è l’insieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL’area sottesa alla curva di densità di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) è uguale all’area sottesa alla densità Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) è il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l’area sottesa nella semiretta \\([1, \\infty)\\) è uguale all’area sottesa nella semiretta \\((-\\infty, 1]\\) e quest’ultima coincide con \\(F(-1)\\). Analogamente, l’area sottesa nell’intervallo \\([y_a, y_b]\\), con \\(y_a &lt; y_b\\), è pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema è quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z &lt; z) = p\\). Il valore \\(z\\) cercato è detto quantile di ordine \\(p\\) della Normale standard e può essere trovato mediante un software.\nSupponiamo che l’altezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un’altezza compresa tra \\(1.7\\) e \\(1.8\\) m.\nIl problema ci chiede di trovare l’area sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell’intervallo \\([1.7, 1.8]\\):\n\nstats.norm.cdf(1.8, 1.7, 0.1) - stats.norm.cdf(1.7, 1.7, 0.1)\n\n0.34134474606854315\n\n\n\nmu = 1.7\nsigma = 0.1\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 10000)\nfx = stats.norm.pdf(x, mu, sigma)\nplt.figure()\nplt.plot(x, fx)\nplt.fill_between(x, fx, where=(x &gt;= 1.7) & (x &lt;= 1.8), color=\"0.75\");\n\n\n\n\n\n\n\n\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l’intervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell’intervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\nstats.norm.cdf(1.0, 0, 1) - stats.norm.cdf(0, 0, 1)\n\n0.3413447460685429\n\n\nIl modo più semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilità richiesta non è altro che la metà dell’area sottesa dalle distribuzioni Normali nell’intervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\nConsideriamo ora la visualizzazione della PDF, la CDF e l’inverso della CDF della distribuzione normale.\n\n# Definisco i parametri della distribuzione\nmu = 100\nsigma = 15\n\n# Creo un range di valori su cui calcolare le funzioni\nx = np.linspace(mu - 3*sigma, mu + 3*sigma, 1000)\n\n# Calcolo la PDF, CDF, e l'inverso della CDF\npdf = stats.norm.pdf(x, mu, sigma)\ncdf = stats.norm.cdf(x, mu, sigma)\nppf = stats.norm.ppf(np.linspace(0.01, 0.99, 100), mu, sigma)  # Evitiamo 0 e 1 per l'inverso\n\n# Creo i grafici in una sola riga\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\n# Grafico della PDF\naxs[0].plot(x, pdf, label='PDF')\naxs[0].set_title('PDF')\naxs[0].set_xlabel('Valori')\naxs[0].set_ylabel('Probabilità')\naxs[0].legend()\n\n# Grafico della CDF\naxs[1].plot(x, cdf, label='CDF', color='orange')\naxs[1].set_title('CDF')\naxs[1].set_xlabel('Valori')\naxs[1].set_ylabel('Cumulativa')\naxs[1].legend()\n\n# Grafico dell'inverso della CDF\naxs[2].plot(np.linspace(0.01, 0.99, 100), ppf, label='Inverse CDF', color='green')\naxs[2].set_title('Inverse CDF')\naxs[2].set_xlabel('Probabilità')\naxs[2].set_ylabel('Valori')\naxs[2].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nDovrebbe essere chiaro dalla figura che queste sono tre diverse modalità di osservare la stessa informazione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.5 Distribuzione Chi-quadrato",
    "text": "36.5 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libertà descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libertà. La densità di probabilità di \\(\\chi^2_{~\\nu}\\) è\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x &gt; 0,\n\\]\ndove \\(C_{\\nu}\\) è una costante positiva.\nLa figura seguente mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\).\n\nx = np.arange(0, 40, 0.1)\n\nnus = [2, 4, 8, 16]\nplt.figure()\nfor nu in nus:\n    pdf = stats.chi2.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n36.5.1 Proprietà\n\nLa distribuzione di densità \\(\\chi^2_{~\\nu}\\) è asimmetrica.\nIl valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) è uguale a \\(\\nu\\).\nLa varianza di una variabile \\(\\chi^2_{~\\nu}\\) è uguale a \\(2\\nu\\).\nPer \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).\nSe \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libertà, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti.\n\nPer fare un esempio, consideriamo la v.c. \\(\\chi^2_5\\).\n\n# Set the degrees of freedom\ndf = 5\n\n# Create a chi-square distribution object\nchi2_dist = stats.chi2(df)\n\n# Generate x values for the plot\nx = np.linspace(0, 20, 200)\n\n# Calculate the probability density function (PDF) of the chi-square distribution for x values\npdf = chi2_dist.pdf(x)\n\n# Plot the PDF\nplt.figure()\nplt.plot(x, pdf)\nplt.title('Chi-Square Distribution (df=5)')\nplt.xlabel('x')\nplt.ylabel('PDF');\n\n\n\n\n\n\n\n\nGeneriamo 1000000 valori da questa distribuzione.\n\nx = rng.chisquare(5, 1000000)\nx[0:20]\n\narray([3.66284512, 2.96353593, 4.93609572, 4.67151242, 4.10927523,\n       4.16530706, 3.36823832, 9.92342755, 7.02541475, 3.23262943,\n       2.73771833, 3.01973299, 4.83304038, 3.16952063, 5.98040985,\n       6.26951139, 8.73351727, 7.28411818, 7.75225854, 5.77346535])\n\n\nCalcoliamo la media di questi valori.\n\nnp.mean(x)\n\n5.0050584059950385\n\n\nCalcolo la varianza.\n\nnp.var(x, ddof=0)\n\n10.013703149640937",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.6 Distribuzione \\(t\\) di Student",
    "text": "36.6 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un’altra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\tag{36.3}\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libertà. Si usa scrivere \\(T \\sim t_{\\nu}\\). L’andamento della distribuzione \\(t\\) di Student è simile a quello della distribuzione Normale, ma ha una dispersione maggiore (ha le code più pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa seguente mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\nx = np.arange(-5, 5, 0.1)\n\nnus = [1, 2, 5, 30]\n\nplt.figure()\nfor nu in nus:\n    pdf = stats.t.pdf(x, nu)\n    plt.plot(x, pdf, label=r\"$\\nu$ = {}\".format(nu))\nplt.plot(x, stats.norm.pdf(x, 0, 1), label=\"N(μ = 0, σ = 1)\")\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.legend(loc=1);\n\n\n\n\n\n\n\n\n\n36.6.1 Proprietà\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti proprietà:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu &gt; 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\); pertanto è sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\).\n\nPer esempio, calcoliamo il valore della funzione di ripartizione di ordine 0.025 nel caso di una \\(t_{30}\\).\n\nstats.t.ppf(0.025, 30)\n\n-2.042272456301238\n\n\nAumentiamo i gradi di libertà: \\(\\nu\\) = 1000.\n\nstats.t.ppf(0.025, 1000)\n\n-1.9623390808264078\n\n\nQuesto valore è quasi identico a quello della Normale stanardizzata.\n\nstats.norm.ppf(0.025, 0, 1)\n\n-1.9599639845400545\n\n\nLa ragione per cui il quantile della distribuzione \\(t\\) con \\(\\nu=30\\) è maggiore (in valore assoluto) del quantile omotetico della distribuzione Normale Standard è che la distribuzione \\(t\\) ha una varianza maggiore rispetto alla distribuzione Normale Standard.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "href": "chapters/probability/12_cont_rv_distr.html#funzione-beta-di-eulero",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.7 Funzione Beta di Eulero",
    "text": "36.7 Funzione Beta di Eulero\nLa funzione Beta di Eulero è una funzione matematica, non una densità di probabilità. La menzioniamo qui perché viene utilizzata nella densità di probabilità Beta. La funzione Beta di Eulero, comunemente indicata con il simbolo \\(B(\\alpha, \\beta)\\), si può scrivere in molti modi diversi; per i nostri scopi la presentiamo così:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{36.4}\\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, ovvero il fattoriale discendente, cioè\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione Beta di Eulero assume il valore\n\nalpha = 3\nbeta = 9\nsc.beta(alpha, beta)\n\n0.00202020202020202\n\n\nSi noti che abbiamo usato la funzione beta della libreria scipy.special. Lo stesso risultato si ottiene svolgendo i calcoli in maniera esplicita:\n\n((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n\n0.00202020202020202\n\n\n\n(math.factorial(alpha-1)*math.factorial(beta-1)) / math.factorial(alpha+beta-1)\n\n0.00202020202020202\n\n\noppure usando la funzione gamma di scipy.special:\n\nsc.gamma(alpha) * sc.gamma(beta) / sc.gamma(alpha + beta)\n\n0.00202020202020202",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-beta",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.8 Distribuzione Beta",
    "text": "36.8 Distribuzione Beta\nLa distribuzione di probabilità Beta, denotata comunemente come \\(Beta(\\alpha, \\beta)\\), è utilizzata per modellare fenomeni che sono espressi in percentuali o proporzioni. Un aspetto cruciale di questa distribuzione è la sua definizione esclusiva nell’intervallo \\((0, 1)\\). In pratica, ciò significa che essa considera valori compresi strettamente tra 0 e 1, escludendo sia lo 0 che l’1 come estremi.\n\n36.8.1 Definizione Formale\nConsideriamo una variabile casuale \\(\\theta\\), la quale può assumere qualunque valore nell’intervallo aperto \\((0, 1)\\). Se diciamo che \\(\\theta\\) segue una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) (indicato come \\(\\theta \\sim \\text{Beta}(\\alpha, \\beta)\\)), intendiamo che la sua funzione di densità è descritta dalla seguente formula:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} =  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} \\quad \\text{per } \\theta \\in (0, 1)\\,,\n\\]\ndove \\(B(\\alpha, \\beta)\\) è la funzione beta di Eulero, definita come \\(\\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\).\n\n\n36.8.2 I Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) giocano un ruolo cruciale nella distribuzione Beta, influenzando direttamente la sua forma e il suo comportamento. È essenziale che entrambi questi parametri siano positivi.\n\n\n36.8.3 Intuizione e Collegamento con la Distribuzione Binomiale\nLa distribuzione Beta può essere meglio compresa quando la si osserva in relazione con la distribuzione binomiale. Mentre la distribuzione binomiale modella il numero di successi in una serie di prove, la distribuzione Beta si focalizza sulla probabilità di successo in queste prove.\nNel contesto della distribuzione binomiale, la probabilità di successo è un parametro fisso; nella distribuzione Beta, questa probabilità diventa una variabile aleatoria.\n\n\n36.8.4 Interpretazione dei Parametri \\(\\alpha\\) e \\(\\beta\\)\nI parametri \\(\\alpha\\) e \\(\\beta\\) possono essere interpretati come rappresentanti il numero di successi e insuccessi, rispettivamente. Questa interpretazione è analoga ai termini \\(n\\) e \\(n-x\\) nella distribuzione binomiale.\nLa scelta di \\(\\alpha\\) e \\(\\beta\\) dipende dall’aspettativa iniziale della probabilità di successo: - Se si presume un’alta probabilità di successo (ad esempio, 90%), si potrebbe scegliere \\(\\alpha = 90\\) e \\(\\beta = 10\\). - Al contrario, per una bassa aspettativa di successo, si potrebbe impostare \\(\\alpha = 10\\) e \\(\\beta = 90\\).\nUn aumento di \\(\\alpha\\) (successi) sposta la distribuzione verso destra, mentre un aumento di \\(\\beta\\) (insuccessi) la sposta verso sinistra. Inoltre, se sia \\(\\alpha\\) sia \\(\\beta\\) aumentano, la distribuzione diventa più stretta, indicando una maggiore certezza.\nQuesta interpretazione consente di utilizzare la distribuzione Beta per esprimere le nostre credenze a priori riguardo a una sequenza di prove di Bernoulli, dove il rapporto tra successi e tentativi totali è dato da:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un’illustrazione è fornita dalla seguente GIF animata.\nLa figura seguente mostra la distribuzione \\(Beta(x \\mid \\alpha, \\beta)\\) per \\(\\alpha\\) = 0.5, 5.0, 1.0, 2.0, 2.0 e \\(\\beta\\) = 5, 1.0, 3.0, 2.0, 5.0.\n\nx = np.linspace(0, 1, 200)\nalphas = [0.5, 5.0, 1.0, 2.0, 2.0]\nbetas = [0.5, 1.0, 3.0, 2.0, 5.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.beta.pdf(x, a, b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.ylim(0, 4.5)\nplt.legend(loc=9);\n\n\n\n\n\n\n\n\n\n\n36.8.5 Costante di normalizzazione\nLa relazione \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) definisce il reciproco della funzione Beta di Eulero, \\(B(\\alpha, \\beta)\\), come una costante di normalizzazione. Qui, \\(\\Gamma(\\cdot)\\) denota la funzione Gamma di Eulero. Questa costante di normalizzazione garantisce che\n\\[\n\\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} d\\theta = 1\\,,\n\\]\nper \\(\\alpha, \\beta &gt; 0\\). Questa integrazione conferma che \\(\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\\), quando moltiplicata per la costante di normalizzazione, forma una densità di probabilità che si estende sull’intervallo \\([0,1]\\), con l’area sottesa dalla curva (l’integrale) uguale a 1.\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamo\n\ndef integrand(p, a, b):\n    return p ** (a - 1) * (1 - p) ** (b - 1)\n\na = 3\nb = 9\nresult, error = quad(integrand, 0, 1, args=(a, b))\nprint(result)\n\n0.00202020202020202\n\n\novvero\n\nresult = (math.gamma(a) * math.gamma(b)) / math.gamma(a + b)\nprint(result)\n\n0.00202020202020202\n\n\novvero, usando la funzione beta di Eulero di scipy.special\n\nsc.beta(a, b)\n\n0.00202020202020202\n\n\n\n\n36.8.6 Proprietà\nIl valore atteso, la moda e la varianza di una densità di probabilità Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\theta) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\] (eq-beta-mean)\n\\[\nMo(\\theta) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\] (eq-beta-mode)\n\\[\n\\mathbb{V}(\\theta) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\] (eq-beta-var)\nUsando le formule precedenti, possiamo definire la funzione beta_mean_mode_variance() in Python per calcolare la media, la moda e la varianza di una distribuzione di probabilità Beta:\n\ndef beta_mean_mode_variance(alpha, beta):\n    mean = alpha / (alpha + beta)\n    mode = (alpha - 1) / (alpha + beta - 2)\n    variance = alpha * beta / ((alpha + beta) ** 2 * (alpha + beta + 1))\n    return mean, mode, variance\n\nPer esempio\n\nalpha = 7\nbeta = 3\nmean, mode, variance = beta_mean_mode_variance(alpha, beta)\nprint(f\"Mean: {mean}, Mode: {mode}, Variance: {variance}\")\n\nMean: 0.7, Mode: 0.75, Variance: 0.019090909090909092\n\n\n\n\n36.8.7 Distribuzione a priori coniugata\nLa distribuzione Beta rappresenta una prior coniugata ottimale per una gamma di distribuzioni legate a eventi di successo e fallimento, quali le distribuzioni Bernoulli, Binomiale, Binomiale Negativa e Geometrica, nell’ambito dell’inferenza Bayesiana. Questa caratteristica di prior coniugata rende il calcolo della distribuzione a posteriori particolarmente efficiente, poiché permette di bypassare onerose computazioni numeriche tipicamente associate all’inferenza Bayesiana.\nPrendiamo, ad esempio, il caso in cui la distribuzione Beta, espressa come Beta(α, β), venga adottata come prior nel contesto di una distribuzione Binomiale. Questa scelta metodologica ci assicura che la distribuzione a posteriori manterrà la forma funzionale della distribuzione Beta. Ciò significa che, una volta raccolti i dati, l’aggiornamento a posteriori può essere eseguito semplicemente aggiungendo il numero di successi osservati (x) e il numero di fallimenti (n-x) ai parametri α e β del prior, rispettivamente. In tal modo, si ottiene una distribuzione a posteriori Beta con parametri aggiornati (α+x, β+n-x), senza la necessità di compiere la moltiplicazione tra la funzione di verosimiglianza e il prior.\n\n\n\n\n\n\nÈ importante prestare attenzione all’uso del termine “Beta” in questo contesto, poiché assume significati differenti a seconda del riferimento: - La distribuzione Beta, che descrive una distribuzione di probabilità continua. - La funzione Beta, una funzione matematica speciale. - Il parametro β, che insieme ad α, definisce i parametri specifici della distribuzione Beta.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.9 Distribuzione di Cauchy",
    "text": "36.9 Distribuzione di Cauchy\nLa distribuzione di Cauchy è un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libertà. È definita da una densità di probabilità che corrisponde alla seguente funzione, dipendente da due parametri \\(\\alpha\\) e \\(\\beta\\),\n\\[\nf(x \\mid \\alpha, \\beta) = \\frac{1}{\\pi \\beta \\left[1 + \\left( \\frac{x - \\alpha}{\\beta} \\right)^2\\right]}.\n\\tag{36.5}\\]\nIl grafico mostra alcune distribuzioni di Cauchy con \\(\\alpha\\) = 0., 0., 0., -2.0 e \\(\\beta\\) = .5, 1., 2., 1.0.\n\nx = np.linspace(-5, 5, 500)\nalphas = [0.0, 0.0, 0.0, -2.0]\nbetas = [0.5, 1.0, 2.0, 1.0]\n\nplt.figure()\nfor a, b in zip(alphas, betas):\n    pdf = stats.cauchy.pdf(x, loc=a, scale=b)\n    plt.plot(x, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(a, b))\nplt.xlabel(\"x\", fontsize=12)\nplt.ylabel(\"f(x)\", fontsize=12)\nplt.legend(loc=1);",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-gamma",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.10 Distribuzione Gamma",
    "text": "36.10 Distribuzione Gamma\nLa distribuzione Gamma è ampiamente utilizzata nella statistica bayesiana come distribuzione a priori per parametri che sono strettamente positivi, come tassi o varianze. È particolarmente utile nella modellazione di variabili che rappresentano tempi di attesa o qualsiasi altra quantità che può assumere solo valori positivi. La densità di probabilità Gamma gioca un ruolo fondamentale nella modellazione del tempo di attesa per l’occorrenza di un certo numero di eventi indipendenti e rari, rendendola adatta per processi di Poisson generalizzati.\nLa distribuzione Gamma può essere vista come una generalizzazione della distribuzione esponenziale. Più precisamente, la distribuzione esponenziale è un caso speciale della distribuzione Gamma. Se sommiamo \\(n\\) variabili casuali indipendenti, ciascuna delle quali segue una distribuzione esponenziale con parametro \\(\\lambda\\), il risultato segue una distribuzione Gamma con parametri \\(n\\) (numero di variabili sommate) e \\(\\lambda\\) (tasso esponenziale). Questo si formalizza come:\n\\[\n\\text{Gamma}(n, \\lambda) = \\sum_{i=1}^n \\text{Esponenziale}(\\lambda).\n\\]\nIn particolare, la distribuzione Gamma con parametro di forma 1, ovvero \\(\\text{Gamma}(1, \\lambda)\\), corrisponde esattamente a una distribuzione esponenziale con parametro \\(\\lambda\\), cioè:\n\\[\n\\text{Gamma}(1, \\lambda) = \\text{Esponenziale}(\\lambda).\n\\]\nLa distribuzione Gamma è anche legata alla distribuzione normale in alcuni contesti. Sebbene non vi sia una relazione diretta e semplice tra una distribuzione Gamma e una normale, un caso specifico è quando il parametro di forma \\(n\\) è molto grande (cioè \\(n \\to \\infty\\)). In questo caso, la distribuzione Gamma può essere approssimata da una distribuzione normale tramite il teorema del limite centrale. Più precisamente, quando \\(n\\) è grande, una Gamma di parametri \\(n\\) e \\(\\lambda\\) converge approssimativamente a una normale con media \\(n/\\lambda\\) e varianza \\(n/\\lambda^2\\).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "href": "chapters/probability/12_cont_rv_distr.html#parametrizzazione",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.11 Parametrizzazione",
    "text": "36.11 Parametrizzazione\nLa distribuzione Gamma è caratterizzata da due parametri principali: \\(\\alpha\\) e \\(\\beta\\), noti rispettivamente come parametro di forma e parametro di tasso (o, alternativamente, si può usare \\(\\theta = \\frac{1}{\\beta}\\), il parametro di scala).\n\n36.11.1 Parametro di forma (\\(\\alpha\\))\nIl parametro di forma, \\(\\alpha\\), determina la forma generale della curva della distribuzione:\n\nSe \\(\\alpha = 1\\), la distribuzione Gamma si riduce a una distribuzione esponenziale, con la funzione di densità \\(f(x) = \\beta e^{-\\beta x}\\).\nSe \\(\\alpha &gt; 1\\), la distribuzione presenta un picco (modalità) attorno a \\((\\alpha - 1) \\cdot \\theta\\), indicando una distribuzione più concentrata attorno a un valore medio.\nSe \\(\\alpha &lt; 1\\), la distribuzione è inclinata verso destra, con una coda lunga che si estende verso valori più bassi, mostrando una maggiore probabilità di valori piccoli di \\(x\\).\n\nIl parametro \\(\\alpha\\) può essere interpretato come il numero di “eventi” che ci si aspetta si verifichino prima di raggiungere un certo tempo di attesa, in contesti di modelli di Poisson generalizzati. Ad esempio, se la distribuzione Gamma modella il tempo di attesa per l’arrivo di un certo numero di eventi, \\(\\alpha\\) indica il numero di eventi attesi.\nMan mano che \\(\\alpha\\) aumenta, la distribuzione si sposta verso destra e diventa più simmetrica. Per valori alti di \\(\\alpha\\), la distribuzione Gamma si avvicina a una distribuzione normale.\n\n\n36.11.2 Parametro di scala (\\(\\theta\\)) o tasso (\\(\\beta\\))\nIl parametro \\(\\theta\\) (o, alternativamente, \\(\\beta\\)) controlla la scala temporale o la larghezza della distribuzione:\n\nIl parametro di scala \\(\\theta\\) è inversamente proporzionale al parametro di tasso \\(\\beta\\). Un valore più grande di \\(\\theta\\) (o un valore più piccolo di \\(\\beta\\)) produce una curva più piatta, indicando una maggiore variabilità (dispersione) nel tempo di attesa.\nUn valore più piccolo di \\(\\theta\\) (o più grande di \\(\\beta\\)) rende la curva più appuntita, indicando una minore variabilità.\n\nNel contesto del tempo di attesa, \\(\\theta\\) agisce come un fattore di scala: un valore grande di \\(\\theta\\) indica un periodo di tempo più lungo tra gli eventi, mentre un valore piccolo di \\(\\theta\\) indica un periodo di tempo più breve.\n\n\n36.11.3 Formula della funzione di densità di probabilità\nLa funzione di densità di probabilità (PDF) della distribuzione Gamma è data da:\n\\[\nf(x \\mid \\alpha, \\theta) = \\frac{x^{\\alpha-1} e^{-\\frac{x}{\\theta}}}{\\theta^\\alpha \\Gamma(\\alpha)},\n\\]\ndove:\n\n\\(x\\) è la variabile casuale continua, con \\(x &gt; 0\\),\n\\(\\alpha\\) è il parametro di forma,\n\\(\\theta\\) è il parametro di scala (alternativamente si può usare \\(\\beta = \\frac{1}{\\theta}\\), il parametro di tasso),\n\\(\\Gamma(\\alpha)\\) è la funzione Gamma di Eulero, che generalizza il fattoriale per numeri reali e complessi. Per numeri interi \\(n\\), si ha \\(\\Gamma(n) = (n-1)!\\), ma per argomenti generali \\(\\alpha\\), la funzione Gamma è definita come:\n\n\\[\n\\Gamma(\\alpha) = \\int_0^\\infty x^{\\alpha-1} e^{-x} dx.\n\\]\n\n\n36.11.4 Media e varianza della distribuzione Gamma\nLe espressioni per la media e la varianza della distribuzione Gamma in funzione di \\(\\alpha\\) e \\(\\theta\\) (o \\(\\beta\\)) sono:\n\nMedia (\\(\\mu\\)):\n\n\\[\n\\mu = \\alpha \\cdot \\theta = \\frac{\\alpha}{\\beta}.\n\\]\n\nVarianza (\\(\\sigma^2\\)): \\[\n\\sigma^2 = \\alpha \\cdot \\theta^2 = \\frac{\\alpha}{\\beta^2}.\n\\]\n\nIn sintesi, il parametro di forma \\(\\alpha\\) controlla la forma generale della distribuzione, mentre il parametro di scala \\(\\theta\\) (o tasso \\(\\beta\\)) regola la dispersione o variabilità. Questa parametrizzazione è largamente utilizzata, in particolare nella statistica bayesiana, dove la distribuzione Gamma può servire da distribuzione a priori per parametri positivi, come varianze o tassi di processi stocastici.\nPer esempio, qui è riportata la distribuzione Gamma di parametri \\(\\alpha\\) = 3 e \\(\\beta\\) = 5/3.\n\nalpha = 3\nbeta = 5/3\n\nmean = alpha / beta\nprint(mean)\n\n1.7999999999999998\n\n\n\n# Standard deviation = sqrt(alpha / beta^2)\n\nsigma = np.sqrt(alpha / beta**2)\nprint(sigma)\n\n1.0392304845413263\n\n\n\n# Generazione di dati dalla distribuzione Gamma\ndata = rng.gamma(shape=alpha, scale=1/beta, size=100000)\n\n# Plot dell'istogramma dei dati generati\nplt.hist(data, bins=30, density=True, alpha=0.6, color='g')\n\n# Plot della PDF (Probability Density Function) della distribuzione Gamma\nx = np.linspace(0, 10, 1000)\nplt.plot(x, stats.gamma.pdf(x, a=alpha, scale=1/beta), 'r-', lw=2, label='PDF')\n\nplt.xlabel('Valore')\nplt.ylabel('Densità di probabilità')\nplt.title('Distribuzione Gamma con alpha=3 e beta=5/3')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "href": "chapters/probability/12_cont_rv_distr.html#distribuzione-esponenziale-1",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.12 Distribuzione Esponenziale",
    "text": "36.12 Distribuzione Esponenziale\nLa distribuzione esponenziale è una distribuzione di probabilità continua che descrive la “durata di vita” di un fenomeno che non invecchia (ossia la distribuzione esponenziale è priva di memoria).\nLa distribuzione esponenziale (o di Laplace) può anche essere ricavata come la distribuzione di probabilità di una variabile aleatoria definita come somma dei quadrati di due variabili aleatorie normali standardizzate (ossia con valore atteso zero e varianza unitaria); dunque è riconducibile a un caso particolare di distribuzione del chi-quadro, essendo, quest’ultima, la distribuzione di probabilità della variabile aleatoria costruita come la somma dei quadrati di \\(n\\) variabili aleatorie indipendenti normali e standardizzate.\nLa distribuzione esponenziale con parametro \\({\\displaystyle \\lambda &gt;0}\\), ha funzione di densità di probabilità:\n\\[\n{\\displaystyle f(x;\\lambda )={\\begin{cases}\\lambda e^{-\\lambda x}&x&gt;0,\\\\0&x\\leq 0.\\end{cases}}}.\n\\]\nUna variabile aleatoria con distribuzione esponenziale di parametro \\({\\displaystyle \\lambda }\\) ha\n\nvalore atteso \\({\\displaystyle E[X]=1/\\lambda }\\),\nvarianza \\({\\displaystyle {\\text{Var}}(X)=1/\\lambda ^{2}}.\\)\n\nPer fare un esempio, consideriamo il punteggio totale della scala psicologica di Kessler (K6), una misura standardizzata utilizzata dal NHIS per lo screening del disagio psicologico. La K6 include sei item relativi alla sintomatologia depressiva e ansiosa e valuta il disagio psicologico aspecifico degli ultimi 30 giorni. Gli item sono valutati su una scala Likert a 5 punti, che va da “mai” (=0) a “sempre” (=4). I punteggi totali variano da 0 a 24. Secondo Tomitaka et al. (2019), il punteggio totale della K6 segue una distribuzione esponenziale, con punteggi di cut-off per disagio psicologico moderato e grave corrispondenti a punteggi di 5 e 13, rispettivamente. Dallo studio emerge che il punteggio medio del totale della K6 nella popolazione americana è di 2.5. La corrispondente distribuzione esponenziale è rappresentata di seguito.\n\nmean = 2.5\nx = np.linspace(0.001, 22, 100)\nplt.figure()\npdf = stats.expon.pdf(x, scale=mean)\nplt.plot(x, pdf, label=r\"$\\lambda$ = {}\".format(lam))\nplt.xlabel(\"x\")\nplt.ylabel(\"f(x)\")\nplt.show()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/12_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.13 Commenti e considerazioni finali",
    "text": "36.13 Commenti e considerazioni finali\nLa statistica bayesiana impiega le distribuzioni di probabilità come motore inferenziale per la stima dei parametri e dell’incertezza. Immaginiamo che le distribuzioni di probabilità siano piccoli pezzi di “Lego” con cui possiamo costruire qualsiasi cosa desideriamo. Questo principio si applica analogamente ai modelli statistici bayesiani. Possiamo costruire modelli che vanno dai più semplici ai più complessi, utilizzando le distribuzioni di probabilità e le loro interrelazioni.\nPython, oltre al modulo stats, offre la capacità di generare campioni casuali da varie distribuzioni di probabilità attraverso il generatore di numeri casuali disponibile in NumPy. Dopo aver importato NumPy con il comando:\nimport numpy as np\nè possibile inizializzare il generatore di numeri casuali (rng) con un valore di seme (seed) specifico, garantendo così la riproducibilità degli esperimenti:\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\nA questo punto, si possono generare campioni da diverse distribuzioni di probabilità. Ad esempio, per generare un campione dalla distribuzione normale (gaussiana), si può procedere nel seguente modo:\nmedia, deviazione_standard = 0, 1  # Valori per media e deviazione standard\ncampione_normale = rng.normal(media, deviazione_standard, size=100)\nIn questo esempio, size=100 indica che vogliamo generare un campione di 100 valori dalla distribuzione. Analogamente, si possono generare campioni da altre distribuzioni di probabilità specificando i relativi parametri:\nDistribuzione Uniforme: Per generare valori da una distribuzione uniforme, definita in un intervallo da a a b, si può usare:\na, b = 0, 10  # Estremi dell'intervallo\ncampione_uniforme = rng.uniform(a, b, size=100)  # Aggiunta del parametro 'size'\nDistribuzione t di Student: Per ottenere valori dalla distribuzione t di Student, con un dato numero di gradi di libertà:\ngradi_libertà = 10  # Gradi di libertà\ncampione_t = rng.standard_t(gradi_libertà, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Beta: Per la distribuzione Beta, specificando i parametri alpha e beta:\nalpha, beta = 2, 5  # Parametri alpha e beta\ncampione_beta = rng.beta(alpha, beta, size=100)  # Aggiunta del parametro 'size'\nDistribuzione Gamma: Infine, per generare un campione dalla distribuzione Gamma, con i parametri di forma e scala:\nforma, scala = 2, 1  # Parametri di forma e scala\ncampione_gamma = rng.gamma(forma, scala, size=100)  # Aggiunta del parametro 'size'\nIn tutti i casi, l’aggiunta del parametro size consente di specificare la dimensione del campione desiderato.\nPer analizzare le proprietà statistiche di diverse distribuzioni di probabilità, oltre alla generazione di campioni casuali, si utilizzano le funzioni di densità di probabilità (PDF), le funzioni di ripartizione cumulativa (CDF) e le funzioni quantili. Queste operazioni possono essere effettuate efficacemente utilizzando la libreria SciPy in Python.\nPer determinare la funzione densità di probabilità (PDF), la quale rappresenta la probabilità relativa di osservare un valore all’interno di un intervallo continuo, il procedimento è il seguente. Per la distribuzione normale, ad esempio:\nimport numpy as np\nfrom scipy.stats import norm, uniform, t, beta, gamma\n\nmedia, deviazione_standard = 0, 1\nx = np.linspace(media - 4*deviazione_standard, media + 4*deviazione_standard, 100)\npdf_normale = norm.pdf(x, loc=media, scale=deviazione_standard)\nSimili operazioni possono essere effettuate per altre distribuzioni, come mostrato di seguito:\nDistribuzione Uniforme:\na, b = 0, 10\nx = np.linspace(a, b, 100)\npdf_uniforme = uniform.pdf(x, loc=a, scale=b-a)\nDistribuzione t di Student:\ngradi_libertà = 10\nx = np.linspace(-5, 5, 100)\npdf_t = t.pdf(x, df=gradi_libertà)\nDistribuzione Beta:\nalpha, beta_param = 2, 5\nx = np.linspace(0, 1, 100)\npdf_beta = beta.pdf(x, alpha, beta_param)\nDistribuzione Gamma:\nforma, scala = 2, 1\nx = np.linspace(0, 10, 100)\npdf_gamma = gamma.pdf(x, a=forma, scale=scala)\nPer determinare i quantili, ovvero i valori corrispondenti a specifiche probabilità cumulate nella funzione di distribuzione, si utilizza la funzione ppf (Percent Point Function). Ad esempio, per la distribuzione normale:\nprobabilità = 0.5\nquantile_normale = norm.ppf(probabilità, loc=media, scale=deviazione_standard)\nE per le altre distribuzioni:\nDistribuzione Uniforme:\nquantile_uniforme = uniform.ppf(probabilità, loc=a, scale=b-a)\nDistribuzione t di Student:\nquantile_t = t.ppf(probabilità, df=gradi_libertà)\nDistribuzione Beta:\nquantile_beta = beta.ppf(probabilità, alpha, beta_param)\nDistribuzione Gamma:\nquantile_gamma = gamma.ppf(probabilità, a=forma, scale=scala)\nInfine, per calcolare la probabilità cumulativa associata a un dato quantile (ovvero la probabilità che una variabile casuale sia minore o uguale a quel quantile), si utilizza la funzione cdf (Cumulative Distribution Function). Questo permette di determinare la probabilità che si verifichi un evento entro un certo intervallo di valori per la distribuzione considerata. Ad esempio, per la distribuzione normale:\nquantile = 0\nprobabilità_normale = norm.cdf(quantile, loc=media, scale=deviazione_standard)\nE analogamente per le altre distribuzioni:\nDistribuzione Uniforme:\nprobabilità_uniforme = uniform.cdf(quantile, loc=a, scale=b-a)\nDistribuzione t di Student:\nprobabilità_t = t.cdf(quantile, df=gradi_libertà)\nDistribuzione Beta:\nprobabilità_beta = beta.cdf(quantile, alpha, beta_param)\nDistribuzione Gamma:\nprobabilità_gamma = gamma.cdf(quantile, a=forma, scale=scala)",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "href": "chapters/probability/12_cont_rv_distr.html#esercizi",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "36.14 Esercizi",
    "text": "36.14 Esercizi\n\nEsercizio 36.1 Per ciascuna delle distribuzioni di massa di probabilità discusse, utilizza Python per:\n\ncreare un grafico della funzione, scegliendo opportunamente i parametri;\nestrarre un campione di 1000 valori casuali dalla distribuzione e visualizzarlo con un istogramma;\ncalcolare la media e la deviazione standard dei campioni e confrontarle con i valori teorici attesi;\nstimare l’intervallo centrale del 94% utilizzando i campioni simulati;\ndeterminare i quantili della distribuzione per gli ordini 0.05, 0.25, 0.75 e 0.95;\nscegliendo un valore della distribuzione pari alla media più una deviazione standard, calcolare la probabilità che la variabile aleatoria assuma un valore minore o uguale a questo valore.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/12_cont_rv_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "36  Distribuzioni di v.c. continue",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 21 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\npandas    : 2.2.1\nnumpy     : 1.26.4\narviz     : 0.17.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nTomitaka, S., Kawasaki, Y., Ide, K., Akutagawa, M., Ono, Y., & Furukawa, T. A. (2019). Distribution of psychological distress is stable in recent decades and follows an exponential pattern in the US population. Scientific reports, 9(1), 11982.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Distribuzioni di v.c. continue</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html",
    "href": "chapters/probability/13_qq_plot.html",
    "title": "37  Diagramma quantile-quantile",
    "section": "",
    "text": "Introduzione\nL’obiettivo di questo breve capitolo è spiegare il diagramma quantile-quantile (QQ-plot) e illustrarne l’utilità come strumento per analizzare visivamente la conformità di un dataset a una distribuzione teorica, in particolare alla distribuzione normale. Il QQ-plot è una tecnica essenziale per chi lavora con dati che si presume seguano una distribuzione specifica, e rappresenta un passaggio cruciale in molte analisi statistiche, soprattutto per verificare l’assunto di normalità.\nNelle analisi statistiche, si parte spesso dall’assunzione che i dati seguano una distribuzione specifica, come la distribuzione normale. Tuttavia, questa ipotesi deve essere verificata. Un QQ-plot permette di:\nIl QQ-plot è costruito tracciando i quantili del campione contro i quantili teorici di una distribuzione di riferimento. L’interpretazione è piuttosto semplice:\nIl QQ-plot è particolarmente utile nelle seguenti situazioni:\nNel capitolo che segue, costruiremo e analizzeremo QQ-plot per tre casi tipici:\nSimuleremo i dati, li ordineremo, calcoleremo manualmente i quantili teorici e infine utilizzeremo librerie specializzate per replicare e confrontare i risultati. Questo approccio pratico ci permetterà di comprendere a fondo l’utilità e il funzionamento del QQ-plot.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html#introduzione",
    "href": "chapters/probability/13_qq_plot.html#introduzione",
    "title": "37  Diagramma quantile-quantile",
    "section": "",
    "text": "Valutare graficamente la normalità dei dati: Se i punti nel diagramma seguono approssimativamente una linea retta, i dati possono essere considerati normalmente distribuiti. In caso contrario, il QQ-plot rivela deviazioni dalla normalità, come code pesanti o asimmetrie.\nIdentificare outlier: Gli outlier nei dati saranno visibili come punti che si discostano significativamente dalla linea retta del QQ-plot.\nConfrontare distribuzioni: Il QQ-plot non si limita solo alla distribuzione normale, ma può essere utilizzato per confrontare la distribuzione del campione con qualsiasi distribuzione teorica, facilitando l’analisi di dati con forme di distribuzione complesse.\n\n\n\nSe il campione segue la distribuzione teorica, i punti nel QQ-plot si allineano lungo una linea retta di pendenza 1 (e intercetta 0 nel caso di distribuzione normale standardizzata).\nLa deviazione dalla linea retta indica differenze nella distribuzione del campione rispetto alla distribuzione teorica:\n\nIntercetta diversa da 0: indica che la media del campione differisce dalla media della distribuzione teorica.\nPendenza diversa da 1: indica una differenza nella varianza tra il campione e la distribuzione teorica.\nCurve: indicano deviazioni sistematiche, come code pesanti o distribuzioni asimmetriche.\n\n\n\n\nPre-analisi statistica: Prima di applicare tecniche come la regressione lineare, dove l’assunzione di normalità è cruciale, un QQ-plot permette di diagnosticare la normalità dei residui.\nVerifica della bontà del fit: Quando si utilizza un modello per stimare la distribuzione di un dataset, il QQ-plot permette di confrontare visivamente quanto il modello si adatti bene ai dati osservati.\nIdentificazione di dati anomali: Un QQ-plot può evidenziare valori atipici, che potrebbero influenzare negativamente i risultati dell’analisi, permettendo di valutare la necessità di una trasformazione dei dati o di un trattamento degli outlier.\n\n\n\nCampione con stessa media e varianza della distribuzione teorica.\nCampione con media diversa ma stessa varianza.\nCampione con media e varianza diverse.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html#comprendere-e-costruire-un-qq-plot-distribuzione-normale",
    "href": "chapters/probability/13_qq_plot.html#comprendere-e-costruire-un-qq-plot-distribuzione-normale",
    "title": "37  Diagramma quantile-quantile",
    "section": "37.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)",
    "text": "37.1 Comprendere e Costruire un QQ-Plot (Distribuzione Normale)\nUn QQ-plot (Quantile-Quantile plot) è uno strumento grafico utilizzato per confrontare la distribuzione di un campione con una distribuzione teorica, spesso la distribuzione normale. Il QQ-plot aiuta a visualizzare se un dataset segue una distribuzione specifica, tracciando i quantili del campione contro i quantili della distribuzione teorica.\n\n37.1.1 Passi per Costruire un QQ-Plot\n\nOrdinare i Dati: Disporre i dati del campione in ordine crescente.\nDeterminare i Quantili Teorici: Per una distribuzione normale, i quantili corrispondono all’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale.\nConfrontare i Quantili: Tracciare i quantili del campione rispetto ai quantili della distribuzione teorica. Se il campione proviene dalla distribuzione teorica, i punti dovrebbero trovarsi approssimativamente su una linea retta.\n\n\n\n37.1.2 Caso 1: Campione con Stessa Media e Varianza della Distribuzione Normale\nSupponiamo che il campione provenga da una distribuzione normale ( N(= 0, ^2 = 1) ), esattamente come la distribuzione teorica.\n\n\n37.1.3 Simulazione dei Dati\nIniziamo simulando un piccolo dataset da ( N(0, 1) ):\n\n# Generiamo 20 punti dati da N(0, 1)\ndati_campione = np.random.normal(0, 1, 20)\n\n# Ordiniamo i dati del campione\ncampione_ordinato = np.sort(dati_campione)\n\n# Calcoliamo i quantili teorici da N(0, 1)\nquantili_teorici = stats.norm.ppf((np.arange(1, 21) - 0.5) / 20)\n\n# Tracciamo il QQ-plot\nplt.scatter(quantili_teorici, campione_ordinato)\nplt.plot(quantili_teorici, quantili_teorici, color=\"red\", label=\"y=x\")\nplt.xlabel(\"Quantili Teorici\")\nplt.ylabel(\"Quantili del Campione\")\nplt.title(\"QQ-Plot: Stessa Media e Varianza\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn questo caso, poiché i dati del campione provengono da ( N(0, 1) ), ci aspettiamo che i punti si allineino con la linea rossa, indicando che la distribuzione del campione corrisponde a quella teorica.\n\n\n37.1.4 Caso 2: Campione con Media Diversa (Intercetta ≠ 0)\nAdesso, simuliamo un campione da ( N(2, 1) ), ovvero il campione ha una media diversa ma la stessa varianza:\n\n# Generiamo 20 punti dati da N(2, 1)\ndati_campione_media_spostata = np.random.normal(2, 1, 20)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_media_spostata = np.sort(dati_campione_media_spostata)\n\n# Tracciamo il QQ-plot\nplt.scatter(quantili_teorici, campione_ordinato_media_spostata)\nplt.plot(quantili_teorici, quantili_teorici, color=\"red\", label=\"y=x\")\nplt.xlabel(\"Quantili Teorici\")\nplt.ylabel(\"Quantili del Campione\")\nplt.title(\"QQ-Plot: Media Diversa (Intercetta ≠ 0)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn questo caso, i punti dovrebbero seguire una linea retta ma essere spostati verticalmente, indicando un’intercetta diversa (media).\n\n\n37.1.5 Caso 3: Campione con Media e Varianza Diverse (Pendenza ≠ 1)\nInfine, simuliamo un campione da ( N(2, 2^2) ), ovvero il campione ha una media e una varianza diverse:\n\n# Generiamo 20 punti dati da N(2, 2)\ndati_campione_varianza_spostata = np.random.normal(2, 2, 20)\n\n# Ordiniamo i dati del campione\ncampione_ordinato_varianza_spostata = np.sort(dati_campione_varianza_spostata)\n\n# Tracciamo il QQ-plot\nplt.scatter(quantili_teorici, campione_ordinato_varianza_spostata)\nplt.plot(quantili_teorici, quantili_teorici, color=\"red\", label=\"y=x\")\nplt.xlabel(\"Quantili Teorici\")\nplt.ylabel(\"Quantili del Campione\")\nplt.title(\"QQ-Plot: Media e Varianza Diverse (Pendenza ≠ 1)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn questo caso, i punti si discosteranno sia verticalmente (per la media diversa) sia rispetto alla pendenza della linea (per la varianza diversa). La maggiore varianza farà sì che i punti siano più dispersi rispetto alla linea teorica.\n\n\n37.1.6 Calcolo Manuale del QQ-Plot\nPer ciascun caso sopra, abbiamo eseguito i seguenti passaggi manualmente:\n\nOrdinato i dati del campione: Questo ci dà i quantili del campione.\nCalcolato i quantili teorici: Utilizzando la funzione percentuale inversa (ppf) per la distribuzione normale.\n\nPossiamo calcolare i quantili teorici senza usare librerie specializzate:\n\n# Calcolo manuale dei quantili utilizzando l'inversa della CDF per una distribuzione normale\ndef quantili_teorici_manuali(n):\n    return [stats.norm.ppf((i - 0.5) / n) for i in range(1, n + 1)]\n\n\nn = len(dati_campione)\nquantili_teorici_manuali = quantili_teorici_manuali(n)\n\n\n\n37.1.7 Utilizzo di Funzioni Specializzate per Replicare i Risultati\nPossiamo replicare i QQ-plot sopra utilizzando la funzione probplot di scipy.stats:\n\n# Generazione del QQ-plot utilizzando probplot\nstats.probplot(dati_campione, dist=\"norm\", plot=plt)\nplt.title(\"QQ-Plot: Stessa Media e Varianza (Usando probplot)\")\nplt.show()\n\n\n\n\n\n\n\n\nAllo stesso modo, possiamo ripetere per i casi di media e varianza spostate.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html#conclusione",
    "href": "chapters/probability/13_qq_plot.html#conclusione",
    "title": "37  Diagramma quantile-quantile",
    "section": "37.2 Conclusione",
    "text": "37.2 Conclusione\nQuesto tutorial mostra come costruire manualmente un QQ-plot e interpretarlo in diversi casi che coinvolgono variazioni nella media e nella varianza del campione.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/13_qq_plot.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/13_qq_plot.html#informazioni-sullambiente-di-sviluppo",
    "title": "37  Diagramma quantile-quantile",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Sep 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Diagramma quantile-quantile</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html",
    "href": "chapters/probability/14_likelihood.html",
    "title": "38  La verosimiglianza",
    "section": "",
    "text": "Introduzione\nI ricercatori sviluppano modelli con forme funzionali diverse, espressi in termini di parametri, per fare previsioni su come si comporteranno i dati. Il confronto tra i dati osservati e queste previsioni è fondamentale per scegliere tra modelli alternativi. Si seleziona il modello che produce previsioni più vicine ai dati osservati, dimostrandosi il più adatto a descrivere il fenomeno in esame. La funzione di verosimiglianza gioca un ruolo centrale in questo processo, poiché quantifica la probabilità che i dati osservati siano compatibili con un modello e i suoi parametri.\nLa verosimiglianza rappresenta il processo generativo dei dati: stabilisce una relazione tra i parametri del modello e le osservazioni empiriche, descrivendo come i dati potrebbero essere generati se il modello fosse corretto. Tuttavia, la verosimiglianza da sola non è sufficiente a rappresentare un modello scientifico completo. Un modello aggiunge ulteriore struttura e assunzioni che non sono contenute solo nella verosimiglianza.\nAd esempio, in un approccio bayesiano, il modello scientifico include anche i priori, ossia le ipotesi iniziali che formuliamo sui parametri del modello prima di osservare i dati. I priori rappresentano la nostra conoscenza o incertezza preesistente sui parametri e si combinano con la verosimiglianza per generare la distribuzione a posteriori, che descrive i parametri alla luce dei dati osservati. Questo passaggio è fondamentale nel confronto tra modelli perché i priori possono influenzare le conclusioni finali.\nInoltre, un modello scientifico potrebbe includere altri aspetti, come l’errore di misurazione, che tiene conto del fatto che i dati osservati spesso non riflettono esattamente il processo reale, ma sono affetti da rumore o errori. La modellazione dell’errore di misurazione è un altro elemento cruciale che differenzia un modello scientifico completo dalla sola verosimiglianza, poiché consente di catturare le imperfezioni nei dati.\nIn sintesi, la verosimiglianza descrive come i dati potrebbero essere generati da un modello dato un insieme di parametri, ma un modello scientifico aggiunge ulteriori componenti, come i priori (in un approccio bayesiano) o l’errore di misurazione, che aiutano a rendere la rappresentazione più accurata e realistica. Il confronto tra i modelli, quindi, si basa non solo sulla verosimiglianza, ma sull’intera struttura del modello, che include le ipotesi sui parametri e l’incertezza che li circonda.\nLo scopo di questo capitolo è di approfondire il concetto di verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "href": "chapters/probability/14_likelihood.html#il-principio-della-verosimiglianza-e-la-sua-formalizzazione",
    "title": "38  La verosimiglianza",
    "section": "38.1 Il Principio della Verosimiglianza e la sua Formalizzazione",
    "text": "38.1 Il Principio della Verosimiglianza e la sua Formalizzazione\nLa funzione di verosimiglianza e la funzione di densità (o massa) di probabilità sono concetti fondamentali in statistica. Sebbene condividano la stessa espressione matematica, essi hanno interpretazioni e ruoli distinti a seconda del contesto. La chiave per distinguerli sta nel modo in cui vengono trattati i dati e i parametri del modello.\nNella funzione di densità (o massa) di probabilità, i parametri del modello sono fissati, mentre i dati sono considerati variabili. L’obiettivo è calcolare la probabilità di osservare un determinato insieme di dati, dati i parametri noti. Ad esempio, se stiamo lanciando una moneta più volte, potremmo utilizzare la distribuzione binomiale per calcolare la probabilità di ottenere un certo numero di teste, assumendo che la probabilità di ottenere testa in ogni lancio sia un valore fisso e conosciuto.\nLa funzione di verosimiglianza, invece, inverte questa prospettiva: i dati osservati sono considerati fissi, mentre i parametri del modello sono variabili. Lo scopo è valutare quanto bene diversi valori dei parametri si adattino ai dati osservati. In questo contesto, la funzione di verosimiglianza permette di esplorare la plausibilità di differenti set di parametri, dati i dati raccolti, e di identificare il set che meglio spiega le osservazioni.\nFormalmente, la relazione tra la funzione di verosimiglianza e la funzione di densità di probabilità è espressa come:\n\\[\nL(\\theta \\mid y) \\propto p(y \\mid \\theta),\n\\]\ndove \\(L(\\theta \\mid y)\\) rappresenta la funzione di verosimiglianza per i parametri \\(\\theta\\) dato l’insieme di osservazioni \\(y\\), e \\(p(y \\mid \\theta)\\) è la probabilità (o densità) di osservare i dati \\(y\\) dato un certo set di parametri \\(\\theta\\).\nConsideriamo l’esempio del lancio di una moneta. Se osserviamo 7 teste su 10 lanci, la funzione di massa di probabilità della distribuzione binomiale ci permette di calcolare la probabilità di ottenere esattamente questo risultato, dato un valore fissato di \\(p\\) (la probabilità di ottenere testa in un singolo lancio). In questo caso, \\(p\\) è un parametro fisso, mentre i dati (7 teste su 10 lanci) sono le variabili.\nInvece, nella funzione di verosimiglianza, manteniamo fissi i dati (7 teste su 10 lanci) e variamo \\(p\\) per valutare quanto ciascun valore di \\(p\\) si adatti a questo risultato osservato. La funzione di verosimiglianza, dunque, ci dice quali valori di \\(p\\) sono più plausibili alla luce dei dati osservati.\nSebbene le due funzioni condividano la stessa forma matematica, il loro utilizzo è profondamente diverso. La funzione di densità di probabilità si concentra sulla probabilità di osservare certi esiti dato un set di parametri fissi, mentre la funzione di verosimiglianza ci permette di valutare la plausibilità dei parametri dati i risultati osservati. Questa distinzione è cruciale per l’inferenza statistica, poiché ci consente di stimare i parametri del modello che meglio si adattano ai dati e di approfondire la comprensione del fenomeno sotto studio.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#verosimiglianza-binomiale",
    "href": "chapters/probability/14_likelihood.html#verosimiglianza-binomiale",
    "title": "38  La verosimiglianza",
    "section": "38.2 Verosimiglianza Binomiale",
    "text": "38.2 Verosimiglianza Binomiale\nRiprendendo l’esempio della distribuzione binomiale, possiamo approfondire il ruolo della funzione di verosimiglianza nell’analisi statistica con uno scenario pratico. Immaginiamo di condurre un esperimento con un numero definito di prove \\(n\\), dove ogni prova può concludersi con un successo o un fallimento, come nel caso dei lanci di una moneta. Se registriamo \\(y\\) successi e \\(n - y\\) fallimenti, la probabilità di osservare esattamente \\(y\\) successi è descritta dalla funzione di massa di probabilità (FMP) binomiale, espressa come:\n\\[\nP(Y = y) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\theta\\) rappresenta la probabilità di successo in una singola prova di Bernoulli.\nQuando utilizziamo la funzione di verosimiglianza, ci concentriamo su come differenti valori di \\(\\theta\\) spieghino i dati osservati \\(y\\). La funzione di verosimiglianza è espressa come:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^y (1 - \\theta)^{n - y},\n\\]\nin quanto il coefficiente binomiale \\(\\binom{n}{y}\\), non dipendendo da \\(\\theta\\), può essere omesso per semplificare la formulazione.\n\nEsempio 38.1 Per illustrare meglio questo concetto, consideriamo uno studio che indaga sulle aspettative negative tra individui clinicamente depressi. Supponiamo di esaminare un gruppo di 30 pazienti, di cui 23 esprimono un atteggiamento negativo verso il futuro (Zetsche et al., 2019). In questo caso, i dati osservati sono \\(y = 23\\) e \\(n = 30\\), e la funzione di verosimiglianza per \\(\\theta\\), la probabilità sconosciuta di avere aspettative negative, diventa:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\theta^{23} (1 - \\theta)^7.\n\\]\nNotiamo che il coefficiente binomiale è stato omesso poiché non influisce sulla stima di \\(\\theta\\).\nValutando questa funzione per una serie di valori di \\(\\theta\\), possiamo determinare quale valore di \\(\\theta\\) rende i dati osservati più verosimili. Un approccio comune è quello di simulare 100 valori equidistanti di \\(\\theta\\) nell’intervallo \\([0, 1]\\) e calcolare la verosimiglianza per ciascuno di essi. In questo modo, possiamo individuare il valore di \\(\\theta\\) che massimizza la verosimiglianza, ovvero il valore che meglio spiega i dati osservati.\n\nn = 30\ny = 23\n\nCreiamo i possibili valori del parametro \\(\\theta\\) per i quali calcoleremo la verosimiglianza.\n\ntheta = np.linspace(0.0, 1.0, num=100)\nprint(theta)\n\n[0.         0.01010101 0.02020202 0.03030303 0.04040404 0.05050505\n 0.06060606 0.07070707 0.08080808 0.09090909 0.1010101  0.11111111\n 0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717\n 0.18181818 0.19191919 0.2020202  0.21212121 0.22222222 0.23232323\n 0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929\n 0.3030303  0.31313131 0.32323232 0.33333333 0.34343434 0.35353535\n 0.36363636 0.37373737 0.38383838 0.39393939 0.4040404  0.41414141\n 0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747\n 0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354\n 0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.5959596\n 0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566\n 0.66666667 0.67676768 0.68686869 0.6969697  0.70707071 0.71717172\n 0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778\n 0.78787879 0.7979798  0.80808081 0.81818182 0.82828283 0.83838384\n 0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.8989899\n 0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596\n 0.96969697 0.97979798 0.98989899 1.        ]\n\n\nPer esempio, ponendo \\(\\theta = 0.1\\) otteniamo il seguente valore dell’ordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.1)\n\n9.737168290200003e-18\n\n\nPonendo \\(\\theta = 0.2\\) otteniamo il seguente valore dell’ordinata della funzione di verosimiglianza:\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7.\n\\]\n\nstats.binom.pmf(y, n, 0.2)\n\n3.581417234922211e-11\n\n\nSe ripetiamo questo processo 100 volte, una volta per ciascuno dei valori \\(\\theta\\) che abbiamo elencato sopra, otteniamo 100 coppie di punti \\(\\theta\\) e \\(f(\\theta)\\). A tale fine, definiamo la seguente funzione.\n\ndef like(r, n, theta):\n    return math.comb(n, r) * theta**r * (1 - theta)**(n - r)\n\nLa curva che interpola i punti ottenuti è la funzione di verosimiglianza, come indicato dalla figura seguente.\n\nplt.figure()\nplt.plot(theta, like(r=y, n=n, theta=theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\");\n\n\n\n\n\n\n\n\nÈ importante notare che, invece di utilizzare la funzione like() che abbiamo definito precedentemente per motivi didattici, è possibile ottenere lo stesso risultato utilizzando in modo equivalente la funzione binom.pmf().\n\nplt.figure()\nplt.plot(theta, stats.binom.pmf(y, n, theta), \"-\")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Verosimiglianza\")\n\nText(0, 0.5, 'Verosimiglianza')\n\n\n\n\n\n\n\n\n\n\n\n38.2.1 Interpretazione della Funzione di Verosimiglianza\nLa funzione di verosimiglianza ci permette di valutare quanto bene i diversi valori di \\(\\theta\\) si adattano ai dati osservati. Il valore che massimizza la funzione di verosimiglianza rappresenta la stima più plausibile di \\(\\theta\\) dato l’insieme di dati. Ad esempio, se il valore che massimizza la verosimiglianza è \\(\\theta = 0.767\\), ciò suggerisce che la probabilità più plausibile di successo (o, nel nostro caso, di atteggiamento negativo) nella popolazione studiata è del 76.7%.\nLa determinazione numerica di questo valore ottimale può essere effettuata mediante tecniche di ottimizzazione. Metodi computazionali, come quelli disponibili in linguaggi di programmazione come Python, permettono di identificare il punto in cui la funzione di verosimiglianza raggiunge il massimo. L’uso di librerie statistiche e matematiche, come NumPy o SciPy, consente di calcolare la stima di \\(\\theta\\) in modo preciso ed efficiente, fornendo un parametro che meglio si adatta ai dati osservati.\nQuesta metodologia, centrata sull’uso della funzione di verosimiglianza, è fondamentale nell’inferenza statistica. Essa consente ai ricercatori di stimare i parametri di un modello basandosi sui dati empirici, e di valutare l’adeguatezza del modello rispetto ai dati reali.\nIn pratica, per identificare numericamente il valore ottimale di \\(\\theta\\), si può utilizzare un approccio computazionale che identifica il massimo della verosimiglianza. Ad esempio, la funzione argmax di NumPy può essere impiegata per localizzare l’indice del vettore dei valori di verosimiglianza in cui si raggiunge il picco. Una volta identificato questo indice, si risale al corrispondente valore di \\(\\theta\\), ottenendo così la stima del parametro che rende i dati osservati più plausibili.\n\nl = stats.binom.pmf(y, n, theta)\nl.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#massima-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#massima-verosimiglianza",
    "title": "38  La verosimiglianza",
    "section": "38.3 Massima Verosimiglianza",
    "text": "38.3 Massima Verosimiglianza\nQuando cerchiamo di stimare i parametri di un modello, come \\(\\theta\\), il nostro obiettivo è trovare il valore che massimizza la probabilità dei dati osservati, ovvero quello che corrisponde al massimo della funzione di verosimiglianza.\nIn termini di ottimizzazione, possiamo parlare di “minimizzazione” o “massimizzazione” a seconda della funzione. La minimizzazione consiste nel trovare il punto più basso di una “valle”, mentre la massimizzazione implica trovare il punto più alto su una “collina”. Nel caso della funzione di verosimiglianza, vogliamo trovare il punto in cui questa funzione raggiunge il suo valore massimo. Tuttavia, poiché molti algoritmi sono progettati per minimizzare le funzioni, possiamo convertire il problema cercando di minimizzare il negativo della funzione di verosimiglianza, il cui minimo corrisponderà al massimo della funzione originale.\n\n38.3.1 La Strategia di Base\nL’ottimizzazione segue alcune fasi generali:\n\nPunto di Partenza: L’algoritmo inizia da un punto iniziale, scelto casualmente o basato su un’ipotesi ragionevole.\nEsplorazione: L’algoritmo “esplora” la superficie della funzione, spostandosi nelle direzioni che sembrano portare verso il minimo (o massimo, se stiamo massimizzando). È simile a sentirsi il terreno intorno a noi e camminare nella direzione della discesa.\nAggiustamento: Durante l’esplorazione, l’algoritmo regola la traiettoria in base a ciò che rileva. Se trova una discesa, continua in quella direzione; se incontra una salita, prova a cambiare rotta.\nConvergenza: L’algoritmo procede fino a quando non trova un punto in cui non ci sono più discese significative, suggerendo di aver raggiunto il minimo (o massimo) raggiungibile con quel percorso.\n\n\n\n38.3.2 Metodi di Ottimizzazione\nEsistono diversi metodi che l’algoritmo può utilizzare per determinare come muoversi:\n\nDiscesa del Gradiente (Gradient Descent): Utilizza il gradiente della funzione, che indica la direzione e la pendenza, per decidere in che direzione spostarsi.\nMetodo di Newton-Raphson: Impiega sia il gradiente che la curvatura della funzione (ossia la derivata seconda) per compiere passi più informati verso il minimo.\nAlgoritmi Genetici: Ispirati alla selezione naturale, questi algoritmi generano soluzioni “evolutive” attraverso iterazioni che simulano l’evoluzione biologica.\n\n\n\n38.3.3 Interpretazione Intuitiva\nL’ottimizzazione può essere vista come un processo di esplorazione metodica, in cui l’algoritmo riceve continuamente feedback dalla funzione che sta cercando di ottimizzare. Questo feedback guida il percorso verso il punto ottimale, che può essere il massimo o il minimo della funzione, a seconda del problema.\n\n\n38.3.4 Ottimizzazione della Verosimiglianza\nPer trovare il massimo della funzione di verosimiglianza, possiamo quindi definire e minimizzare il negativo della funzione stessa. Questo ci permette di utilizzare algoritmi di minimizzazione per raggiungere il massimo, ottenendo così la stima del parametro \\(\\theta\\) che meglio si adatta ai dati osservati.\n\ndef negative_likelihood(theta, n, y):\n    # Calcolo del negativo della funzione di verosimiglianza\n    return -stats.binom.pmf(y, n, theta)\n\nUtilizziamo ora scipy.optimize.minimize per trovare il valore di theta che massimizza la verosimiglianza. Bisogna specificare un valore iniziale per theta, qui assumiamo 0.5 come punto di partenza. I vincoli su theta sono che deve essere compreso tra 0 e 1.\n\nresult = minimize(negative_likelihood, x0=0.5, args=(n, y), bounds=[(0, 1)])\nresult.x\n\narray([0.76666666])",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#la-funzione-di-log-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#la-funzione-di-log-verosimiglianza",
    "title": "38  La verosimiglianza",
    "section": "38.4 La Funzione di Log-Verosimiglianza",
    "text": "38.4 La Funzione di Log-Verosimiglianza\nProseguendo con l’analisi della funzione di verosimiglianza, ci avviciniamo a una sua trasformazione matematica frequentemente utilizzata dagli statistici: la funzione di log-verosimiglianza. Questa è definita come il logaritmo naturale della funzione di verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta \\mid y),\n\\]\nLa log-verosimiglianza non altera la posizione del massimo della funzione di verosimiglianza, grazie alla proprietà di monotonicità del logaritmo. In termini pratici, il valore di \\(\\theta\\) che massimizza la log-verosimiglianza, denotato come \\(\\hat{\\theta}\\), è lo stesso che massimizza la verosimiglianza originale:\n\\[\n\\hat{\\theta} = \\arg \\max_{\\theta \\in \\Theta} \\ell(\\theta) = \\arg \\max_{\\theta \\in \\Theta} \\mathcal{L}(\\theta).\n\\]\nL’uso della log-verosimiglianza semplifica il processo di ottimizzazione, specialmente quando si lavora con numeri molto piccoli o con dataset di grandi dimensioni. La log-verosimiglianza trasforma infatti il prodotto delle probabilità in una somma di logaritmi, facilitando i calcoli e migliorando la stabilità numerica. Questo è particolarmente utile nei casi in cui si gestiscono molte osservazioni, evitando problemi di underflow (quando i numeri diventano troppo piccoli per essere rappresentati accuratamente).\nAd esempio, per un modello binomiale, la log-verosimiglianza è data da:\n\\[\n\\ell(\\theta \\mid y) = \\log(\\theta^y (1 - \\theta)^{n - y}) = y \\log(\\theta) + (n - y) \\log(1 - \\theta).\n\\]\nQuesta trasformazione rende i calcoli più semplici perché converte il prodotto di probabilità in una somma, semplificando l’ottimizzazione, soprattutto in presenza di osservazioni indipendenti. Inoltre, la funzione logaritmica consente un’esecuzione più efficiente delle operazioni numeriche, rendendo l’analisi più stabile.\n\n38.4.1 Esempio: Applicazione della Log-Verosimiglianza\nRiprendendo l’esempio della distribuzione binomiale, possiamo applicare la funzione di log-verosimiglianza per stimare il parametro \\(\\theta\\) che meglio si adatta ai dati osservati. Metodi computazionali, come l’uso di librerie statistiche in Python, ad esempio tramite binom.logpmf(), permettono di calcolare direttamente la log-verosimiglianza per un insieme di osservazioni e diversi valori di \\(\\theta\\). In questo modo, è possibile identificare il valore di \\(\\theta\\) che massimizza la log-verosimiglianza e ottenere una stima accurata e computazionalmente efficiente del parametro.\n\n\n38.4.2 Vantaggi della Log-Verosimiglianza\nL’adozione della funzione di log-verosimiglianza non solo risolve problemi pratici legati alla manipolazione di probabilità molto piccole, ma offre anche una struttura concettuale più chiara per interpretare la plausibilità dei parametri del modello dati gli osservati. Questa trasformazione è fondamentale nell’analisi inferenziale, poiché migliora la precisione delle stime e la robustezza numerica durante il processo di ottimizzazione.\n\n\n38.4.3 Rappresentazione Grafica\nInfine, una rappresentazione grafica della funzione di log-verosimiglianza fornisce ulteriori intuizioni sul comportamento della funzione stessa e aiuta a visualizzare chiaramente il punto in cui viene massimizzata, facilitando l’interpretazione delle stime dei parametri.\n\nn = 30\nr = 23\nplt.figure()\nplt.plot(theta, stats.binom.logpmf(y, n, theta), \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale theta [0, 1]\")\nplt.ylabel(\"Log-verosimiglianza\");\n\n\n\n\n\n\n\n\nIl risultato replica quello trovato in precedenza con la funzione di verosimiglianza.\n\nll = stats.binom.logpmf(y, n, theta)\nll.argmax()\n\n76\n\n\n\ntheta[76]\n\n0.7676767676767677\n\n\nDefinizione della funzione del negativo della log-verosimiglianza con correzioni per evitare errori di dominio:\n\ndef corrected_negative_log_likelihood(theta, n, y):\n    # Assicurarsi che theta sia all'interno di un intervallo valido per evitare errori di logaritmo\n    theta = np.clip(theta, 1e-10, 1-1e-10)\n    return - (y * np.log(theta) + (n - y) * np.log(1 - theta))\n\nUtilizzo di scipy.optimize.minimize per trovare il valore di theta che massimizza la log-verosimiglianza:\n\nresult_log_likelihood_corrected = minimize(\n    corrected_negative_log_likelihood, x0=[0.5], args=(n, y), bounds=[(0, 1)]\n)\n\n\n# Il risultato ottimizzato per theta utilizzando la log-verosimiglianza corretta\noptimized_theta = result_log_likelihood_corrected.x\noptimized_theta\n\narray([0.76666666])",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#verosimiglianza-congiunta",
    "href": "chapters/probability/14_likelihood.html#verosimiglianza-congiunta",
    "title": "38  La verosimiglianza",
    "section": "38.5 Verosimiglianza Congiunta",
    "text": "38.5 Verosimiglianza Congiunta\nProseguendo nell’esplorazione dell’inferenza statistica basata sulla verosimiglianza, ci soffermiamo ora sul caso in cui disponiamo di più osservazioni indipendenti, tutte provenienti dalla stessa distribuzione binomiale. Questo scenario è comune nelle applicazioni pratiche, dove raccogliamo un insieme di \\(n\\) osservazioni \\(Y = [y_1, y_2, \\ldots, y_n]\\), ciascuna ottenuta nelle stesse condizioni sperimentali e indipendentemente dalle altre (condizione di indipendenza e identica distribuzione, IID).\nPer analizzare queste osservazioni congiuntamente, dobbiamo calcolare la probabilità congiunta di osservare \\(y_1, y_2, \\ldots, y_n\\), data una comune probabilità di successo \\(\\theta\\) per tutte le prove. L’indipendenza delle osservazioni ci permette di esprimere questa probabilità congiunta come il prodotto delle probabilità individuali di ciascuna osservazione:\n\\[\np(y_1, y_2, \\ldots, y_n \\mid \\theta) = \\prod_{i=1}^{n} p(y_i \\mid \\theta) = \\prod_{i=1}^{n} \\text{Binomiale}(y_i \\mid \\theta).\n\\]\nIn questo contesto, la verosimiglianza congiunta rappresenta la plausibilità complessiva di \\(\\theta\\), dati tutti i dati osservati \\(Y\\). È semplicemente il prodotto delle verosimiglianze individuali di ciascuna osservazione \\(y_i\\) rispetto a \\(\\theta\\):\n\\[\n\\mathcal{L}(\\theta \\mid Y) = \\prod_{i=1}^{n} \\mathcal{L}(\\theta \\mid y_i) = \\prod_{i=1}^{n} p(y_i \\mid \\theta).\n\\]\nQuesta formulazione della verosimiglianza congiunta evidenzia quanto bene il parametro \\(\\theta\\) si adatta all’intero insieme di dati \\(Y\\), offrendo un quadro coerente per l’inferenza statistica. Il parametro \\(\\theta\\) che massimizza la verosimiglianza congiunta è chiamato stimatore di massima verosimiglianza (MLE). Questo stimatore rappresenta il valore di \\(\\theta\\) che rende l’intero set di dati \\(Y\\) il più plausibile possibile, secondo il modello scelto.\nL’approccio basato sulla verosimiglianza congiunta è potente, poiché ci permette di considerare tutte le osservazioni contemporaneamente, sfruttando l’informazione fornita da ciascun dato per ottenere una stima più precisa e affidabile del parametro \\(\\theta\\).\nFacciamo un esempio concreto. Quando disponiamo di più gruppi di osservazioni Bernoulliane indipendenti e identicamente distribuite (iid), la funzione di log-verosimiglianza congiunta per tutti i gruppi può essere espressa come la somma delle log-verosimiglianze di ciascun gruppo. Questo deriva dalla proprietà secondo cui il logaritmo di un prodotto è uguale alla somma dei logaritmi.\nSupponiamo di avere i seguenti dati per quattro gruppi di osservazioni:\n\nGruppo 1: 30 prove con 23 successi\nGruppo 2: 28 prove con 21 successi\nGruppo 3: 40 prove con 31 successi\nGruppo 4: 36 prove con 29 successi\n\nLa funzione di log-verosimiglianza congiunta per questi dati, assumendo una singola probabilità di successo \\(\\theta\\) comune a tutti i gruppi, è data dalla seguente espressione:\n\\[\n\\log L(\\theta) = \\sum_{i=1}^{4} \\left[ y_i \\log(\\theta) + (n_i - y_i) \\log(1 - \\theta) \\right],\n\\]\ndove \\(n_i\\) e \\(y_i\\) rappresentano rispettivamente il numero di prove e il numero di successi nel gruppo \\(i\\)-esimo.\nPer trovare il valore di \\(\\theta\\) che massimizza questa funzione di log-verosimiglianza, possiamo utilizzare metodi di ottimizzazione numerica come scipy.optimize.minimize in Python. Questo metodo ci permette di minimizzare il negativo della funzione di log-verosimiglianza, il che equivale a massimizzarla. Inoltre, per evitare problemi numerici (ad esempio, logaritmi di zero), possiamo utilizzare np.clip per limitare i valori di \\(\\theta\\) all’interno di un intervallo ragionevole (ad esempio, tra \\(10^{-10}\\) e \\(1 - 10^{-10}\\)).\n\ndef log_verosimiglianza_congiunta(theta, dati):\n    theta = np.clip(theta, 1e-10, 1-1e-10)  # Evita valori esattamente 0 o 1\n    log_likelihood = 0\n    for n, y in dati:\n        log_likelihood += y * np.log(theta) + (n - y) * np.log(1 - theta)\n    return -log_likelihood  # Restituisce il negativo per l'ottimizzazione\n\n\n# Dati dei gruppi: (prove, successi)\ndati_gruppi = [(30, 23), (28, 20), (40, 29), (36, 29)]\nprint(dati_gruppi)\n\n[(30, 23), (28, 20), (40, 29), (36, 29)]\n\n\nOttimizzazione con la funzione log_verosimiglianza_congiunta\n\nresult = minimize(\n    log_verosimiglianza_congiunta, x0=[0.5], args=(dati_gruppi,), bounds=[(0, 1)]\n)\n\n# Il risultato ottimizzato per theta con la funzione corretta\nresult.x\n\narray([0.75373134])\n\n\n\n# Intervallo di valori di theta da esplorare\ntheta_values = np.linspace(0.01, 0.99, 100)\n\n# Calcolo dei valori di log-verosimiglianza per ogni theta\nlog_likelihood_values = [log_verosimiglianza_congiunta(theta, dati_gruppi) for theta in theta_values]\n\n# Creazione del grafico\nplt.figure(figsize=(10, 6))\nplt.plot(theta_values, log_likelihood_values, label='Log-verosimiglianza')\nplt.xlabel('Theta')\nplt.ylabel('Log-verosimiglianza negativa')\nplt.title('Funzione di Log-verosimiglianza')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIn questo esempio, utilizziamo minimize per ottimizzare la funzione di log-verosimiglianza congiunta e ottenere una stima di \\(\\theta\\). Il valore risultante di \\(\\theta\\) rappresenta la stima di massima verosimiglianza (MLE) basata sui dati forniti.\nIn conclusione, questo esempio illustra come sia possibile stimare il parametro \\(\\theta\\) utilizzando la log-verosimiglianza congiunta in presenza di più gruppi di dati. La combinazione della funzione di log-verosimiglianza con tecniche di ottimizzazione numerica rende possibile risolvere problemi di inferenza anche con dataset più complessi o con più gruppi di osservazioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#la-verosimiglianza-marginale",
    "href": "chapters/probability/14_likelihood.html#la-verosimiglianza-marginale",
    "title": "38  La verosimiglianza",
    "section": "38.6 La Verosimiglianza Marginale",
    "text": "38.6 La Verosimiglianza Marginale\nProseguendo con la nostra discussione sulla verosimiglianza, approfondiamo un concetto chiave nell’inferenza bayesiana: la verosimiglianza marginale. Questo concetto è cruciale quando il parametro di interesse, \\(\\theta\\), non è un valore fisso, ma è descritto da una distribuzione di probabilità che riflette la nostra incertezza o variabilità.\nIn molte applicazioni pratiche, \\(\\theta\\) può assumere una gamma di valori possibili, ciascuno con una certa probabilità associata, anziché essere un valore deterministico. La verosimiglianza marginale ci consente di calcolare la probabilità complessiva di osservare un determinato risultato tenendo conto di tutti i possibili valori di \\(\\theta\\), integrando o sommando le probabilità associate a ciascun valore di \\(\\theta\\).\n\n38.6.1 Esempio con Parametri Discreti\nConsideriamo una sequenza di prove binomiali, in cui stiamo osservando un risultato specifico, come \\(k = 7\\) successi su \\(n = 10\\) prove. Se \\(\\theta\\) rappresenta la probabilità di successo in ciascuna prova e può assumere un insieme discreto di valori (ad esempio, 0.1, 0.5 e 0.9), ciascuno con probabilità uguale, la verosimiglianza marginale può essere calcolata come:\n\\[\np(k = 7, n = 10) = \\sum_{\\theta \\in \\{0.1, 0.5, 0.9\\}} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta),\n\\]\ndove \\(p(\\theta)\\) è la probabilità associata a ciascun valore di \\(\\theta\\). In questo caso, poiché \\(\\theta\\) assume valori discreti, la somma calcola la verosimiglianza complessiva pesando i diversi valori di \\(\\theta\\) in base alla loro probabilità.\n\n\n38.6.2 Esempio con Parametri Continui\nNella maggior parte delle applicazioni reali, \\(\\theta\\) può variare continuamente all’interno di un intervallo, ad esempio tra 0 e 1 in una distribuzione binomiale. In questi casi, la verosimiglianza marginale richiede l’integrazione su tutto lo spazio dei valori di \\(\\theta\\), per tener conto della gamma continua di possibili probabilità di successo. La formula si estende a:\n\\[\np(k = 7, n = 10) = \\int_{0}^{1} \\binom{10}{7} \\theta^7 (1 - \\theta)^3 p(\\theta) \\, d\\theta,\n\\]\ndove \\(p(\\theta) \\, d\\theta\\) rappresenta la densità di probabilità di \\(\\theta\\) in un intervallo infinitesimale, e l’integrale copre tutti i possibili valori di \\(\\theta\\) nell’intervallo da 0 a 1.\n\n\n38.6.3 Calcolo della Verosimiglianza Marginale\nPer calcolare la verosimiglianza marginale in presenza di una distribuzione continua di \\(\\theta\\), possiamo utilizzare tecniche di integrazione numerica. In Python, la libreria scipy offre strumenti efficienti per eseguire questo tipo di calcoli. Ad esempio, possiamo utilizzare la funzione quad di scipy.integrate per integrare la funzione su uno spazio continuo:\n\n# Definire la funzione di verosimiglianza\ndef likelihood(theta):\n    return stats.binom.pmf(k=7, n=10, p=theta)\n\n# Calcolare la verosimiglianza marginale integrando su θ\nmarginal_likelihood, _ = quad(lambda theta: likelihood(theta), 0, 1)\n\nprint(\"La verosimiglianza marginale è:\", marginal_likelihood)\n\nLa verosimiglianza marginale è: 0.09090909090909094\n\n\nIn conclusione, l’esempio presentato illustra come integrare la probabilità su un insieme continuo di valori di \\(\\theta\\) per ottenere la probabilità complessiva di osservare un determinato risultato. Il codice precedente esegue l’integrazione della funzione di verosimiglianza binomiale su tutti i possibili valori di \\(\\theta\\) (da 0 a 1), fornendo così la verosimiglianza marginale per il nostro esempio. Questo approccio consente di tenere conto dell’incertezza su \\(\\theta\\), offrendo una visione più completa della verosimiglianza dell’evento osservato senza fissare \\(\\theta\\) a un singolo valore.\nDal punto di vista numerico, nel caso della verosimiglianza basata su una distribuzione binomiale, la verosimiglianza marginale può essere interpretata come l’area sottesa dalla funzione di verosimiglianza, calcolata integrandola su tutto l’intervallo dei possibili valori di \\(\\theta\\) (da 0 a 1). Questa integrazione fornisce un valore che quantifica quanto bene il modello complessivo, considerando tutti i possibili valori di \\(\\theta\\), spiega i dati osservati. È importante notare che questo valore non rappresenta la probabilità dei dati dati i parametri, poiché la verosimiglianza non è una densità di probabilità sui parametri. Piuttosto, esso misura la capacità complessiva del modello di spiegare i dati, tenendo conto dell’incertezza sui parametri.\nLa vera rilevanza della verosimiglianza marginale emerge nel contesto dell’inferenza bayesiana: essa funge da fattore di normalizzazione nella formula di Bayes. Più precisamente, la verosimiglianza marginale normalizza il prodotto tra la verosimiglianza e la distribuzione a priori dei parametri (il numeratore nella formula di Bayes), garantendo che il risultato sia una distribuzione di probabilità valida sui parametri. In altre parole, la verosimiglianza marginale assicura che l’area sotto la curva della distribuzione posteriore sia pari a 1, rendendola una vera distribuzione di probabilità.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "href": "chapters/probability/14_likelihood.html#modello-gaussiano-e-verosimiglianza",
    "title": "38  La verosimiglianza",
    "section": "38.7 Modello Gaussiano e Verosimiglianza",
    "text": "38.7 Modello Gaussiano e Verosimiglianza\nAmpliamo ora la nostra analisi al caso della distribuzione gaussiana. Inizieremo con la verosimiglianza associata a una singola osservazione $ Y $, per poi estendere la discussione a un insieme di osservazioni gaussiane indipendenti e identicamente distribuite (IID).\n\n38.7.1 Caso di una Singola Osservazione\nIniziamo esaminiamo il caso di una singola osservazione. Quale esempio, prendiamo in considerazione la situazione in cui una variabile casuale rappresenta il Quoziente d’Intelligenza (QI) di un individuo. Se consideriamo la distribuzione del QI come gaussiana, possiamo esprimere la funzione di verosimiglianza per un singolo valore osservato di QI tramite la formula della distribuzione gaussiana, che misura la probabilità di osservare quel particolare valore di QI dato un insieme di parametri specifici, \\(\\mu\\) (la media) e \\(\\sigma\\) (la deviazione standard). La verosimiglianza offre quindi un modo per quantificare quanto bene i parametri \\(\\mu\\) e \\(\\sigma\\) si accordano con il valore osservato di QI.\nSupponiamo che il QI osservato sia 114 e, per semplicità, assumiamo che la deviazione standard \\(\\sigma\\) sia conosciuta e pari a 15. Vogliamo esaminare un’ampia gamma di possibili valori per la media \\(\\mu\\), diciamo tra 70 e 160, e valutare quale di questi valori rende più plausibile l’osservazione fatta Definiamo quindi un insieme di 1000 valori per \\(\\mu\\) da esplorare:\n\nmu = np.linspace(70.0, 160.0, num=1000)\ny = 114\n\nLa nostra analisi consiste nell’applicare la funzione di densità di probabilità gaussiana a ciascuno di questi 1000 valori di \\(\\mu\\), mantenendo fisso il valore osservato di QI, \\(y=114\\), e la deviazione standard, \\(\\sigma=15\\). In questo modo, possiamo costruire la funzione di verosimiglianza che esprime la plausibilità di ciascun valore di \\(\\mu\\) alla luce del QI osservato.\nIl calcolo specifico della densità di probabilità per ogni valore di \\(\\mu\\) può essere eseguito con la funzione norm.pdf di scipy.stats, che accetta il valore osservato \\(y\\), un array di medie (i nostri valori di \\(\\mu\\)) e la deviazione standard \\(\\sigma\\). Per un singolo valore mu = 70, otteniamo\n\nstats.norm.pdf(y, loc=70, scale=15)\n\n0.00036007041207962535\n\n\nPer il valore mu = 70.05 otteniamo\n\nstats.norm.pdf(y, loc=70.05, scale=15)\n\n0.00036360634900376967\n\n\ne così via. Se usiamo utti i 1000 valori possibili di mu, otteniamo un vettore di 1000 risultati:\n\nf_mu = stats.norm.pdf(y, loc=mu, scale=15)\n\nQuesto passaggio ci fornisce un array di valori che rappresentano la verosimiglianza di ciascun valore di \\(\\mu\\) data l’osservazione \\(y\\). Tracciando questi valori f_mu in funzione di \\(\\mu\\), otteniamo una curva di verosimiglianza che illustra visivamente quanto bene ciascun valore di \\(\\mu\\) si adatta al dato osservato y = 114:\n\nplt.figure()\nplt.plot(mu, f_mu, \"-\")\nplt.title(\"Funzione di verosimiglianza per QI = 114\")\nplt.xlabel(\"Valore di mu [70, 160]\")\nplt.ylabel(\"Verosimiglianza\")\nplt.xlim([70, 160])\nplt.show()\n\n\n\n\n\n\n\n\nAbbiamo dunque proceduto come nel caso della distribuzione binomiale esaminata in precedenza. Abbiamo utilizzato la formula\n\\[\nf(x | \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right),\n\\]\ntenendo costante il valore \\(x\\) = 114 e considerando noto \\(\\sigma\\) = 15, e abbiamo applicato la formula 1000 volte facendo variare mu ogni volta utilizziando ciascuno dei valori definiti con np.linspace(70.0, 160.0, num=1000).\nLa moda della distribuzione, si trova con\n\noptimal_mu = mu[f_mu.argmax()]\nprint(optimal_mu)\n\n113.96396396396396\n\n\nIn questo esempio, otteniamo il valore \\(\\mu\\) = 113.96 che massimizza la verosimiglianza.\nPer calcolare il massimo della log-verosimiglianza per una distribuzione Gaussiana usando la funzione optimize() di SciPy, possiamo seguire questi passi. Partiamo dalla formula della densità di probabilità della distribuzione gaussiana per una singola osservazione \\(y\\), con media \\(\\mu\\) e deviazione standard \\(\\sigma\\). La formula è:\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\n\\]\nPoiché abbiamo una singola osservazione \\(y\\), la funzione di verosimiglianza coincide con la funzione di densità di probabilità. Quindi, prendiamo il logaritmo naturale di entrambi i lati della equazione della densità di probabilità gaussiana per ottenere la log-verosimiglianza:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log \\left( \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right) \\right)\n\\]\nApplichiamo le proprietà dei logaritmi. Ricordiamo che:\n\n\\(\\log(ab) = \\log(a) + \\log(b)\\)\n\\(\\log\\left(\\frac{1}{a}\\right) = -\\log(a)\\)\n\\(\\log(e^x) = x\\)\n\nQuindi, possiamo scrivere:\n\\[\n\\log f(y \\mid \\mu, \\sigma) = \\log\\left(\\frac{1}{\\sigma \\sqrt{2\\pi}}\\right) + \\log\\left(\\exp \\left( -\\frac{(y - \\mu)^2}{2\\sigma^2} \\right)\\right)\n\\]\n\\[\n= -\\log(\\sigma \\sqrt{2\\pi}) -\\frac{(y - \\mu)^2}{2\\sigma^2}.\n\\]\nRicordando che \\(\\log(ab) = \\log(a) + \\log(b)\\), possiamo scrivere \\(\\log(\\sigma \\sqrt{2\\pi})\\) come la somma di due logaritmi:\n\\[\n-\\log(\\sigma \\sqrt{2\\pi}) = -\\log(\\sigma) - \\log(\\sqrt{2\\pi}).\n\\]\nE dato che \\(\\log(\\sqrt{2\\pi}) = \\frac{1}{2}\\log(2\\pi)\\), possiamo sostituire per ottenere:\n\\[\n-\\log(\\sigma) - \\frac{1}{2}\\log(2\\pi).\n\\]\nCombinando tutto, otteniamo:\n\\[\n\\log L(\\mu; y, \\sigma) = -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y - \\mu)^2}{2 \\sigma^2}.\n\\]\nQuesta è la trasformata logaritmica della funzione di densità di probabilità gaussiana per una singola osservazione, che rappresenta la log-verosimiglianza di osservare \\(y\\) dato \\(\\mu\\) e \\(\\sigma\\).\nVogliamo trovare il valore di \\(\\mu\\) che massimizza questa funzione di log-verosimiglianza. Siccome optimize() di SciPy minimizza una funzione, possiamo passare il negativo della log-verosimiglianza per trovare il massimo.\n\n# Dati osservati\ny_obs = 114\nsigma = 15\n\n# Definizione della funzione negativa della log-verosimiglianza\ndef negative_log_likelihood(mu, y, sigma):\n    return 0.5 * np.log(2 * np.pi) + np.log(sigma) + ((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza\nresult = minimize(negative_log_likelihood, x0=0, args=(y_obs, sigma))\n\n# Il risultato ottimizzato per mu\nresult.x\n\narray([113.99997648])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per una distribuzione Gaussiana con \\(y = 114\\) e \\(\\sigma = 15\\) è circa \\(114\\). Questo risultato dimostra che, nel caso di una distribuzione Gaussiana con una singola osservazione e deviazione standard nota, il massimo della log-verosimiglianza si ottiene quando la media stimata \\(\\mu\\) è molto vicina al valore osservato \\(y\\).\n\n\n38.7.2 Campione indipendente di osservazioni da una distribuzione gaussiana\nPassiamo ora all’esame di un contesto più complesso: quello di un campione composto da \\(n\\) osservazioni indipendenti, tutte provenienti da una distribuzione gaussiana. Consideriamo questo insieme di osservazioni come realizzazioni indipendenti ed identicamente distribuite (i.i.d.) di una variabile casuale \\(X\\), che segue una distribuzione normale con media $ $ e deviazione standard \\(\\sigma\\), entrambi parametri sconosciuti. Denotiamo questa situazione con la notazione \\(X \\sim N(\\mu, \\sigma^2)\\).\nIn presenza di osservazioni i.i.d., la densità di probabilità congiunta del campione è il prodotto delle funzioni di densità per ogni singola osservazione. Matematicamente, ciò si esprime attraverso l’equazione:\n\\[ p(y_1, y_2, \\ldots, y_n | \\mu, \\sigma) = \\prod_{i=1}^{n} p(y_i | \\mu, \\sigma), \\]\ndove \\(p(y_i | \\mu, \\sigma)\\) indica la funzione di densità gaussiana per l’osservazione \\(y_i\\), parametrizzata da \\(\\mu\\) e \\(\\sigma\\).\nSe manteniamo i dati osservati come costanti, ciò che cambia in questa equazione quando variamo $ $ e \\(\\sigma\\) sono le probabilità associate ad ogni configurazione dei parametri, portandoci così alla funzione di verosimiglianza congiunta per il campione.\n\nEsempio 38.2 Consideriamo, per illustrare questa dinamica, il caso di uno studio clinico che misura i punteggi del Beck Depression Inventory II (BDI-II) su trenta partecipanti. Supponiamo che questi punteggi seguano una distribuzione normale. Dati i punteggi BDI-II per i trenta partecipanti, il nostro obiettivo è costruire una funzione di verosimiglianza per questi dati, assumendo che la deviazione standard \\(\\sigma\\) sia nota e pari alla deviazione standard campionaria di 6.50.\nPer la totalità del campione, la densità di probabilità congiunta diventa quindi il prodotto delle densità per ogni osservazione. Di conseguenza, la funzione di verosimiglianza per il campione intero è rappresentata dal prodotto delle densità di probabilità di tutte le osservazioni.\nIn questo contesto, ogni possibile valore di \\(\\mu\\) viene valutato in termini di verosimiglianza. Per esemplificare, consideriamo un range di 1000 valori per \\(\\mu\\) e calcoliamo la funzione di verosimiglianza per ognuno di questi. Per rendere più gestibili i calcoli, utilizziamo il logaritmo della funzione di verosimiglianza.\nDefinendo una funzione log_likelihood in Python che accetta i punteggi BDI-II \\(y\\), un valore medio \\(\\mu\\), e imposta \\(\\sigma\\) al valore noto, possiamo calcolare la log-verosimiglianza per un’ampia gamma di valori di \\(\\mu\\) entro un intervallo specifico. Ciò ci permette di visualizzare la credibilità relativa di ciascun valore di \\(\\mu\\) alla luce dei dati osservati.\nInfine, il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza corrisponde alla stima di massima verosimiglianza di \\(\\mu\\) data la distribuzione dei punteggi BDI-II nel campione. Questo valore, nel nostro esempio, coincide con la media campionaria dei punteggi BDI-II, offrendo una stima concorde con l’intuizione che la media del campione sia un buon rappresentante del parametro \\(\\mu\\) in una distribuzione normale.\nI dati sono:\n\ny = [\n    26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25,\n    28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n]\n\nIl nostro scopo è sviluppare una funzione di verosimiglianza utilizzando le 30 osservazioni indicate sopra. Basandoci su studi precedenti, ipotizziamo che questi punteggi seguano una distribuzione normale. Assumiamo inoltre che la deviazione standard \\(\\sigma\\) sia nota e corrisponda a quella osservata nel campione, ossia 6.50.\nPer la prima osservazione del campione, dove \\(y_1 = 26\\), la funzione di densità di probabilità si esprime come:\n\\[\nf(26 \\,|\\, \\mu, \\sigma = 6.50) = \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(26 - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\]\nEstendendo questo calcolo all’intero campione, la funzione di densità di probabilità congiunta si ottiene come il prodotto delle densità di tutte le osservazioni individuali:\n\\[\nf(y \\,|\\, \\mu, \\sigma = 6.50) = \\prod_{i=1}^{n} f(y_i \\,|\\, \\mu, \\sigma = 6.50).\n\\]\nDi conseguenza, la funzione di verosimiglianza, indicata con \\(\\mathcal{L}(\\mu, \\sigma = 6.50 \\,|\\, y)\\), si determina moltiplicando insieme le densità di probabilità di tutte le osservazioni nel campione:\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\mu, \\sigma=6.50 \\,|\\, y) &= \\prod_{i=1}^{30} \\frac{1}{6.50\\sqrt{2\\pi}} \\exp \\left( -\\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right) \\\\\n&= \\left( \\frac{1}{6.50\\sqrt{2\\pi}} \\right)^{30} \\exp\\left( -\\sum_{i=1}^{30} \\frac{(y_i - \\mu)^2}{2 \\cdot 6.50^2} \\right).\n\\end{aligned}\n\\]\nIn questa formula, \\(\\mu\\) rappresenta il parametro di interesse, la media della distribuzione, la cui stima massimizza la funzione di verosimiglianza. Se si considerano 1000 valori differenti per \\(\\mu\\), dovremmo calcolare la funzione di verosimiglianza per ciascuno di questi valori.\nPer rendere i calcoli più gestibili, è consigliabile utilizzare il logaritmo della funzione di verosimiglianza. In Python, possiamo definire una funzione log_likelihood() che accetta come argomenti y, mu e sigma = true_sigma. Per semplificare, impostiamo true_sigma uguale alla deviazione standard osservata nel campione.\n\ntrue_sigma = np.std(y)\nprint(true_sigma)\n\n6.495810615739622\n\n\n\ndef log_likelihood(y, mu, sigma=true_sigma):\n    return np.sum(stats.norm.logpdf(y, loc=mu, scale=true_sigma))\n\nConsideriamo, ad esempio, il valore \\(\\mu_0 = \\bar{y}\\), ovvero\n\nbar_y = np.mean(y)\nprint(bar_y)\n\n30.933333333333334\n\n\nL’ordinata della funzione di log-verosimiglianza in corrispondenza di \\(\\mu = 30.93\\) è\n\nlog_likelihood(y, 30.93, sigma=true_sigma)\n\n-98.70288339960591\n\n\nTroviamo ora i valori della log-verosimiglianza per ciascuno dei 1000 valori \\(\\mu\\) nell’intervallo \\([\\bar{y} - 2 \\sigma, \\bar{y} + 2 \\sigma]\\). Iniziamo a definire il vettore mu.\n\nmu = np.linspace(np.mean(y) - 2 * np.std(y), np.mean(y) + 2 * np.std(y), num=1000)\n\nTroviamo il valore dell’ordinata della funzione di log-verosimiglianza in corrispondenza di ciascuno dei 1000 valori mu che abbiamo definito.\n\nll = [log_likelihood(y, mu_val, true_sigma) for mu_val in mu]\n\nNel caso di un solo parametro sconosciuto (nel caso presente, \\(\\mu\\)) è possibile rappresentare la log-verosimiglianza con una curva che interpola i punti (mu, ll). Tale funzione descrive la credibilità relativa che può essere attribuita ai valori del parametro \\(\\mu\\) alla luce dei dati osservati.\n\nplt.figure()\nplt.plot(mu, ll, \"-\")\nplt.title(\"Funzione di log-verosimiglianza\")\nplt.xlabel(\"Valore della variabile casuale mu\")\nplt.ylabel(\"Log-verosimiglianza\")\nplt.axvline(x=np.mean(y), alpha=0.4, ls=\"--\");\n\n\n\n\n\n\n\n\nIl valore \\(\\mu\\) più credibile corrisponde al massimo della funzione di log-verosimiglinza e viene detto stima di massima verosimiglianza.\nIl massimo della funzione di log-verosimiglianza, ovvero 30.93 per l’esempio in discussione, è identico alla media dei dati campionari.\nPer applicare lo stesso approccio usato precedentemente con optimize ad un campione di dati, anziché a una singola osservazione, possiamo modificare la funzione di log-verosimiglianza per prendere in considerazione tutte le osservazioni nel campione. La log-verosimiglianza per un campione da una distribuzione Gaussiana, dove ogni osservazione \\(y_i\\) ha la stessa media \\(\\mu\\) e deviazione standard \\(\\sigma\\), è la somma delle log-verosimiglianze di ogni osservazione individuale.\nLa formula modificata per il campione sarà:\n\\[\n\\log L(\\mu; y, \\sigma) = \\sum_{i=1}^{n} \\left[ -\\frac{1}{2} \\log(2 \\pi) - \\log(\\sigma) - \\frac{(y_i - \\mu)^2}{2 \\sigma^2} \\right],\n\\]\ndove \\(y\\) è l’array delle osservazioni e \\(n\\) è il numero di osservazioni nel campione.\nPoiché, per semplicità, assumiamo \\(\\sigma\\) come la deviazione standard del campione, prima calcoleremo \\(\\sigma\\) dal campione fornito e poi useremo quel valore per l’ottimizzazione della log-verosimiglianza, cercando il valore di \\(\\mu\\) che la massimizza.\n\n# Calcolo della deviazione standard del campione\nsigma_sample = np.std(y, ddof=1)\n\n# Definizione della funzione negativa della log-verosimiglianza per il campione\ndef negative_log_likelihood_sample(mu, y, sigma):\n    n = len(y)\n    return n * 0.5 * np.log(2 * np.pi) + n * np.log(sigma) + np.sum((y - mu)**2) / (2 * sigma**2)\n\n# Ottimizzazione per trovare il valore di mu che massimizza la log-verosimiglianza per il campione\nresult_sample = minimize(negative_log_likelihood_sample, x0=np.mean(y), args=(y, sigma_sample))\n\n# Il risultato ottimizzato per mu\nresult_sample.x\n\narray([30.93333333])\n\n\nIl valore di \\(\\mu\\) che massimizza la log-verosimiglianza per il campione di dati fornito, assumendo noto il valore di \\(\\sigma\\) (la deviazione standard del campione), è circa \\(30.93\\). Questo rappresenta la stima ottimale per la media della distribuzione Gaussiana che meglio si adatta al campione di dati dato.\n\n\n\n38.7.3 La Stima di Massima Verosimiglianza per \\(\\mu\\)\nPer determinare il valore di \\(\\mu\\) che massimizza la funzione di log-verosimiglianza, procediamo calcolando la sua derivata parziale rispetto a \\(\\mu\\) e impostando il risultato uguale a zero:\n\nPartiamo dalla funzione di log-verosimiglianza, che è data da:\n\\[\n\\ell = -\\frac{n}{2} \\log(2\\pi) - \\frac{n}{2} \\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2.\n\\]\nCalcoliamo la derivata parziale di $ $ rispetto a $ $:\n\\[\n\\frac{\\partial \\ell}{\\partial \\mu} = \\sum_{i=1}^n \\frac{(y_i - \\mu)}{\\sigma^2}.\n\\]\nImpostiamo la derivata uguale a zero per trovare il punto di massimo:\n\\[\n\\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\mu) = 0.\n\\]\n\nRisolvendo questa equazione per $ $, otteniamo la stima di massima verosimiglianza:\n\\[\n\\hat{\\mu}_{MLE} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\bar{y}.\n\\]\nQuesta formula ci mostra che la stima di massima verosimiglianza per \\(\\mu\\) corrisponde semplicemente alla media aritmetica delle osservazioni.\nQuesto processo può essere analogamente applicato per stimare \\(\\sigma^2\\), la varianza, e si trova che la stima di massima verosimiglianza per \\(\\sigma^2\\) è pari alla varianza campionaria.\nIn conclusione, all’interno di una distribuzione gaussiana, le stime di massima verosimiglianza per \\(\\mu\\) (la media) e \\(\\sigma^2\\) (la varianza) coincidono con la media campionaria e la varianza campionaria, rispettivamente.\n\nEsempio 38.3 Consideriamo un esempio relativo all’apprendimento per rinforzo. Lo scopo degli studi sull’apprendimento per rinforzo è quello di comprendere come le persone imparano a massimizzare le loro ricompense in situazioni in cui la scelta migliore è inizialmente sconosciuta. In modo più specifico, consideriamo il seguente problema di apprendimento. Un partecipante deve effettuare ripetutamente delle scelte tra diverse opzioni o azioni, e dopo ogni scelta riceve una ricompensa numerica estratta da una distribuzione di probabilità che dipende dall’azione selezionata. L’obiettivo del partecipante è massimizzare la ricompensa totale attesa durante un certo periodo di tempo, ad esempio, durante 100 scelte. Per descrivere questa situazione, viene spesso utilizzata la metafora di un giocatore che deve fare una serie di \\(T\\) scelte tra \\(K\\) slot machine (conosciute anche come “multi-armed bandits”) al fine di massimizzare le sue vincite. Se nella scelta \\(t\\) viene selezionata la slot machine \\(k\\), viene ottenuta una ricompensa \\(r_t\\) che ha valore 1 con una probabilità di successo \\(\\mu^k_t\\), altrimenti ha valore 0. Le probabilità di successo sono diverse per ogni slot machine e inizialmente sono sconosciute al partecipante. Nella versione più semplice di questo compito, le probabilità di successo rimangono costanti nel tempo.\nIl modello di Rescorla-Wagner è un modello di apprendimento associativo che descrive come gli animali o gli umani aggiornano le loro aspettative di rinforzo in risposta a stimoli. Il modello può essere descritto con la seguente formula di aggiornamento:\n\\[ V_{t+1} = V_t + \\alpha (\\lambda - V_t), \\]\ndove:\n\n\\(V_t\\) è il valore predetto del rinforzo al tempo \\(t\\),\n\\(\\alpha\\) è il tasso di apprendimento, un parametro che vogliamo stimare,\n\\(\\lambda\\) è l’intensità del rinforzo,\n\\(V_{t+1}\\) è il valore aggiornato dopo aver sperimentato il rinforzo.\n\nPer semplificare, consideriamo un caso in cui gli stimoli si presentano in maniera binaria (rinforzo presente o assente), e \\(\\lambda\\) è noto. L’obiettivo è stimare il valore di \\(\\alpha\\) che massimizza la verosimiglianza dei dati osservati sotto il modello.\nLa funzione di verosimiglianza per questo modello dipende dalla differenza tra i valori predetti e gli effettivi rinforzi ricevuti. Tuttavia, la formulazione esatta della funzione di verosimiglianza può variare a seconda della specifica formulazione del problema e dei dati disponibili. Per mantenere le cose semplici, consideriamo una versione semplificata in cui la “verosimiglianza” è basata sulla somma dei quadrati degli errori (SSE) tra i rinforzi previsti e quelli osservati (anche se tecnicamente questo non è un approccio basato sulla verosimiglianza nel senso statistico classico).\nPer questo esempio, assumiamo di avere un semplice set di dati di rinforzi osservati e vogliamo trovare il valore di \\(\\alpha\\) che minimizza l’SSE:\n\\[ SSE = \\sum_{t=1}^{n} (\\lambda - V_t)^2. \\]\nEcco un esempio di implementazione in Python che utilizza scipy.optimize.minimize per stimare \\(\\alpha\\):\n\n# Dati di esempio: rinforzi osservati (lambda)\n# In questo esempio, assumiamo lambda = 1 per rinforzo presente e lambda = 0 per rinforzo assente\n# per semplicità. In pratica, lambda potrebbe essere diverso a seconda degli esperimenti.\nrinforzi_osservati = [1, 0, 1, 1, 0, 1]  # Esempio di sequenza di rinforzi\n\n\n# Funzione che calcola l'SSE per un dato valore di alpha\ndef sse(alpha, rinforzi, V0=0):\n    V = V0\n    sse = 0\n    for lambda_ in rinforzi:\n        sse += (lambda_ - V)**2\n        V += alpha * (lambda_ - V)  # Aggiornamento del valore secondo il modello Rescorla-Wagner\n    return sse\n\n# Ottimizzazione per trovare il valore di alpha che minimizza l'SSE\nresult_alpha = minimize(sse, x0=0.5, args=(rinforzi_osservati,))\n\n# Il risultato ottimizzato per alpha\nresult_alpha.x\n\narray([0.29739989])\n\n\nIl valore di \\(\\alpha\\) (tasso di apprendimento) che minimizza la somma dei quadrati degli errori (SSE) per il modello di Rescorla-Wagner, dato il campione di rinforzi osservati, è circa \\(0.297\\). Questo suggerisce che il tasso di apprendimento ottimale per adattare il modello ai dati osservati in questo esempio semplificato è di circa 0.297, secondo l’approccio di minimizzazione dell’errore utilizzato qui.\n\n\nEsempio 38.4 Consideriamo ora un esempio relativo alla distribuzione esponenziale. Supponiamo che i seguenti siano i tempi di attesa per un certo evento:\n\ndata = np.array([27, 64, 3, 18, 8])\n\nDefiniamo la funzione di log-verosimiglianza negativa. Per iniziare, ricordiamo che la funzione di densità di probabilità (PDF) per una distribuzione esponenziale, dato un tasso \\(\\lambda\\), è definita come:\n\\[\nf(x; \\lambda) = \\lambda e^{-\\lambda x} \\quad \\text{per } x \\geq 0.\n\\]\nLa verosimiglianza (\\(L\\)) di osservare un insieme di dati \\(\\{x_1, x_2, ..., x_n\\}\\) dato un parametro \\(\\lambda\\) è il prodotto delle funzioni di densità di probabilità per ogni punto dati, assumendo che ciascun dato sia indipendente dagli altri. Quindi, per \\(n\\) dati osservati, la funzione di verosimiglianza è:\n\\[\nL(\\lambda) = \\prod_{i=1}^{n} f(x_i; \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\n\\]\nLa log-verosimiglianza (\\(\\log(L(\\lambda))\\)) è il logaritmo naturale di \\(L(\\lambda)\\). Utilizziamo il logaritmo per semplificare la moltiplicazione in una somma, il che rende più semplici sia il calcolo che la differenziazione. Pertanto, la log-verosimiglianza diventa:\n\\[\n\\log(L(\\lambda)) = \\log\\left(\\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i}\\right) = \\sum_{i=1}^{n} \\log(\\lambda e^{-\\lambda x_i}) = \\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nIl motivo per utilizzare il negativo della log-verosimiglianza, cioè \\(-\\log(L(\\lambda))\\), nelle tecniche di ottimizzazione, è perché molte librerie e funzioni di ottimizzazione sono progettate per minimizzare una funzione obiettivo piuttosto che massimizzarla. Dato che vogliamo trovare il valore di \\(\\lambda\\) che massimizza la log-verosimiglianza (e quindi la verosimiglianza), possiamo invece minimizzare il suo negativo. Di conseguenza, la funzione obiettivo che passiamo all’algoritmo di minimizzazione è:\n\\[\n-\\log(L(\\lambda)) = -\\sum_{i=1}^{n} (\\log(\\lambda) - \\lambda x_i)\n\\]\nScriviamo la funzione in Python:\n\ndef neg_log_likelihood(lambda_, data, eps=1e-8):\n    lambda_ = np.clip(lambda_, eps, None)  # Assicura che lambda_ sia almeno eps\n    return -np.sum(np.log(lambda_) - lambda_ * data)\n\nMinimizzaziamo la funzione di log-verosimiglianza negativa:\n\nresult = minimize(neg_log_likelihood, x0=0.1, args=(data,), bounds=[(0, None)])\nprint(f\"Il valore di lambda che massimizza la log-verosimiglianza è: {result.x[0]}\")\n\nIl valore di lambda che massimizza la log-verosimiglianza è: 0.04166666292998713\n\n\nAvendo trovato il tasso \\(\\lambda\\), la stima di massima verosimiglianza del tempo di attesa medio diventa:\n\n1 / result.x\n\narray([24.00000215])\n\n\nVisualizzazione.\n\nlambda_opt = result.x[0]\nlambda_array = np.geomspace(0.01, 0.1, 100)\nLL = [-neg_log_likelihood(L, data) for L in lambda_array]\n\nplt.plot(lambda_array, LL, label='Log-likelihood')\nplt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\nplt.xlabel('$\\lambda$')\nplt.ylabel('Log-likelihood')\nplt.title('Log-likelihood over a range of $\\lambda$ values')\nplt.legend()\nplt.show()\n\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:6: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\l'\n&lt;&gt;:9: SyntaxWarning: invalid escape sequence '\\l'\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:6: SyntaxWarning: invalid escape sequence '\\l'\n  plt.axvline(lambda_opt, color='r', linestyle='--', label=f'Optimal $\\lambda$ = {lambda_opt:.4f}')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:7: SyntaxWarning: invalid escape sequence '\\l'\n  plt.xlabel('$\\lambda$')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_53240/73438383.py:9: SyntaxWarning: invalid escape sequence '\\l'\n  plt.title('Log-likelihood over a range of $\\lambda$ values')",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#conclusione-e-riflessioni-finali",
    "href": "chapters/probability/14_likelihood.html#conclusione-e-riflessioni-finali",
    "title": "38  La verosimiglianza",
    "section": "38.8 Conclusione e Riflessioni Finali",
    "text": "38.8 Conclusione e Riflessioni Finali\nLa funzione di verosimiglianza rappresenta un elemento cruciale che collega i dati osservati ai parametri di un modello statistico. Essa fornisce una misura della plausibilità dei dati in relazione a diversi valori possibili dei parametri del modello. La strutturazione di una funzione di verosimiglianza richiede la considerazione di tre componenti fondamentali: il modello statistico che si presume abbia generato i dati, l’insieme di valori possibili per i parametri di tale modello e le osservazioni empiriche che effettivamente abbiamo a disposizione.\nLa funzione di verosimiglianza è centrale nella pratica dell’inferenza statistica. Essa ci permette di quantificare quanto bene differenti set di parametri potrebbero aver generato i dati osservati. Questo è fondamentale sia per la selezione del modello che per la stima dei parametri, e pertanto è indispensabile per un’analisi dati rigorosa e per un’interpretazione accurata dei risultati.\nUn’applicazione pratica e illustrativa dei principi esposti in questo capitolo è fornita nella sezione sul modello Rescorla-Wagner, che è un esempio di come la teoria della verosimiglianza possa essere applicata per affrontare questioni empiriche in psicologia.\nIn sintesi, la comprensione e l’applicazione appropriata della funzione di verosimiglianza sono passaggi essenziali nel processo di analisi dati. Essa costituisce uno strumento indispensabile per chi è impegnato nella ricerca empirica e nell’interpretazione di dati complessi.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#esercizi",
    "href": "chapters/probability/14_likelihood.html#esercizi",
    "title": "38  La verosimiglianza",
    "section": "38.9 Esercizi",
    "text": "38.9 Esercizi\n\nEsercizio 38.1 Spiega ciascuno dei concetti seguenti con una frase:\n\nprobabilità.\nfunzione di massa di probabilità.\nfunzione di densità di probabilità.\ndistribuzione di probabilità.\ndistribuzione di probabilità discreta.\ndistribuzione di probabilità continua.\nfunzione di distribuzione cumulativa (cdf).\nverosimiglianza\n\n\n\n\n\n\n\n\nAll’esame ti verrà chiesto di:\n\nCalcolare la funzione di verosimiglianza binomiale e riportare il valore della funzione in corrispondenza di specifici valori \\(\\theta\\).\nCalcolare la funzione di verosimiglianza del modello gaussiano, per \\(\\sigma\\) noto, e riportare il valore della funzione in corrispondenza di specifici valori \\(\\mu\\).\nCalcolare la stima di massima verosimiglianza.\nRispondere a domande che implicano una adeguata comprensione del concetto di funzione di verosimiglianza.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/14_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/14_likelihood.html#informazioni-sullambiente-di-sviluppo",
    "title": "38  La verosimiglianza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Oct 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nscipy     : 1.14.0\narviz     : 0.18.0\nmatplotlib: 3.9.1\npandas    : 2.2.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>La verosimiglianza</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html",
    "href": "chapters/probability/15_simulation.html",
    "title": "39  Simulazioni",
    "section": "",
    "text": "39.1 Introduzione\nIn questo capitolo discuteremo alcuni degli esercizi di simulazione presentati da Gelman et al. (2021) nel quinto capitolo del loro libro. Gli autori introducono la pratica della simulazione affermando che simulare variabili casuali è fondamentale nelle statistiche applicate per vari motivi.\nIn primo luogo, utilizziamo modelli di probabilità per imitare la variazione nel mondo reale, e gli strumenti di simulazione ci aiutano a comprendere meglio come questa variazione si manifesti. I modelli di casualità spesso contraddicono il pensiero umano comune: i nostri cervelli faticano a comprendere che le oscillazioni casuali sono presenti nel breve termine ma si livellano nel lungo termine. In molti casi, la simulazione è di grande aiuto per allenare le nostre intuizioni riguardo agli andamenti medi e alla variazione.\nIn secondo luogo, possiamo utilizzare la simulazione per approssimare la distribuzione campionaria dei dati e trasferire questa approssimazione alla distribuzione campionaria delle stime e delle procedure statistiche.\nInfine, i modelli di regressione non sono deterministici, ma producono previsioni probabilistiche. La simulazione è il metodo più conveniente e generale per rappresentare le incertezze nelle previsioni.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#simulazione-di-modelli-di-probabilità-discreti",
    "href": "chapters/probability/15_simulation.html#simulazione-di-modelli-di-probabilità-discreti",
    "title": "39  Simulazioni",
    "section": "39.2 Simulazione di Modelli di Probabilità Discreti",
    "text": "39.2 Simulazione di Modelli di Probabilità Discreti\nIl primo esercizio discusso da Gelman et al. (2021) cerca di rispondere alla seguente domanda: Quante bambine su 400 nascite?\nLa probabilità che un neonato sia una bambina o un bambino è approssimativamente del 48.8% o 51.2%, rispettivamente, e queste percentuali non variano molto in tutto il mondo. Supponiamo che in un anno nascano 400 bambini in un ospedale. Quante saranno bambine?\nGelman et al. (2021) mostrano come possiamo rispondere a questa domanda simulando le 400 nascite utilizzando la distribuzione binomiale e ripetendo la simulazione 10,000 volte.\n\n# Numero di simulazioni\nn_sims = 10_000\n\n# Probabilità di avere una bambina\np_girl = 0.488\n\n# Simulazione delle nascite\nn_girls = np.random.binomial(n=400, p=p_girl, size=n_sims)\n\n# Visualizzazione dell'istogramma\nplt.hist(n_girls, bins=30, edgecolor=\"black\", alpha=0.5)\nplt.title('Distribuzione del Numero di Bambine su 400 Nascite')\nplt.xlabel('Numero di Bambine')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nPossiamo complicare il modello in diversi modi. Ad esempio, c’è una probabilità di 1 su 125 che un evento di nascita risulti in gemelli dizigoti, ciascuno dei quali ha una probabilità approssimativa del 49.5% di essere una bambina, e una probabilità di 1 su 300 di gemelli monozigoti, che hanno una probabilità approssimativa del 49.5% di essere entrambe bambine. Possiamo simulare 400 eventi di nascita nel modo seguente:\n\n# Probabilità per i tipi di nascita\nprobabilities = [1/125, 1/300, 1 - 1/125 - 1/300]\n\n# Tipi di nascita\nbirth_types = [\"fraternal twin\", \"identical twin\", \"single birth\"]\n\n# Simulazione dei tipi di nascita per 400 eventi\nbirth_type = np.random.choice(birth_types, size=400, p=probabilities)\n\n# Array per memorizzare il numero di bambine\ngirls = np.empty(400)\n\n# Ciclo per determinare il numero di bambine in base al tipo di nascita\nfor i in range(400):\n    if birth_type[i] == \"single birth\":\n        girls[i] = np.random.binomial(1, 0.488)\n    elif birth_type[i] == \"identical twin\":\n        girls[i] = 2 * np.random.binomial(1, 0.495)\n    elif birth_type[i] == \"fraternal twin\":\n        girls[i] = np.random.binomial(2, 0.495)\n\n# Somma totale delle bambine\nn_girls = np.sum(girls)\n\nprint(n_girls)\n\n194.0\n\n\nNel codice, identifichiamo tre categorie di nascita: gemelli dizigoti, gemelli monozigoti e nascite singole, e assegnamo le probabilità specificate dal problema a ciascun tipo di nascita. Campioniamo in maniera casuale da tale distribuzione di probabilità discreta ottenendo il vettore birth_type di 400 elementi. Nel ciclo for, esaminiamo ciascuno dei 400 elementi di birth_type. Se il tipo di nascita è single birth, generiamo un valore casuale dalla distribuzione binomiale con probabilità di successo \\(p\\) pari a 0,488. Se il tipo di nascita è identical twin, generiamo un valore casuale dalla distribuzione binomiale con \\(p\\) pari a 0,495 e moltiplichiamo per 2 per rappresentare entrambe le gemelle. Se il tipo di nascita è fraternal twin, generiamo un valore casuale dalla distribuzione binomiale con \\(p\\) pari a 0,495 per due nascite.\nUsciti dal ciclo, sommiamo il numero di 1 nel vettore girls per ottenere una stima del numero di bambine nate.\nInvece di utilizzare un ciclo for per 400 iterazioni, è possibile generare 400 eventi dalla distribuzione binomiale con una singola istruzione, come mostrato nel codice seguente.\n\n# Determinazione del numero di bambine per ogni tipo di nascita\ngirls = np.where(birth_type == \"single birth\", \n                 np.random.binomial(1, 0.488, 400),\n                 np.where(birth_type == \"identical twin\", \n                          2 * np.random.binomial(1, 0.495, 400),\n                          np.random.binomial(2, 0.495, 400)))\n\n# Somma totale delle bambine\nn_girls = np.sum(girls)\n\nprint(n_girls)\n\n199\n\n\nAnche in questo secondo caso otteniamo un risultato simile al precedente. Poiché si tratta di una simulazione basata su numeri casuali, il risultato numerico esatto varia ad ogni esecuzione della simulazione. Per comprendere l’incertezza associata alla simulazione, possiamo ripetere l’intero processo un gran numero di volte (in questo caso, 10,000 volte).\n\nn_sims = 10_000\n\n# Array per memorizzare il numero di bambine per ogni simulazione\nn_girls = np.zeros(n_sims)\n\n# Eseguiamo 10.000 simulazioni\nfor s in range(n_sims):\n    # Simulazione dei tipi di nascita per 400 eventi\n    birth_type = np.random.choice(birth_types, size=400, p=probabilities)\n\n    # Array per memorizzare il numero di bambine per ogni evento di nascita\n    girls = np.zeros(400)\n\n    # Determiniamo il numero di bambine in base al tipo di nascita\n    for i in range(400):\n        if birth_type[i] == \"single birth\":\n            girls[i] = np.random.binomial(1, 0.488)\n        elif birth_type[i] == \"identical twin\":\n            girls[i] = 2 * np.random.binomial(1, 0.495)\n        elif birth_type[i] == \"fraternal twin\":\n            girls[i] = np.random.binomial(2, 0.495)\n\n    # Sommiamo il numero di bambine per questa simulazione\n    n_girls[s] = np.sum(girls)\n\n# Visualizzazione dell'istogramma\nplt.hist(n_girls, bins=30, edgecolor=\"black\", alpha=0.5)\nplt.title(\"Distribuzione del Numero di Bambine su 400 Nascite\")\nplt.xlabel(\"Numero di Bambine\")\nplt.ylabel(\"Frequenza\")\nplt.show()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#simulazione-di-probabilità-continue",
    "href": "chapters/probability/15_simulation.html#simulazione-di-probabilità-continue",
    "title": "39  Simulazioni",
    "section": "39.3 Simulazione di probabilità continue",
    "text": "39.3 Simulazione di probabilità continue\nGelman et al. (2021) dimostrano come sia possibile incorporare anche distribuzioni di probabilità continue nei tipi di simulazioni discusse nella sezione precedente. Forniscono il seguente esempio di un modello misto discreto/continuo: il 52% degli adulti negli Stati Uniti sono donne e il 48% sono uomini. L’altezza degli uomini segue approssimativamente una distribuzione normale con una media di 69.1 pollici e una deviazione standard di 2.9 pollici; per le donne, la media è 63.7 pollici e la deviazione standard è 2.7 pollici. Ecco il codice per generare l’altezza di un adulto scelto casualmente:\n\n# Funzione per simulare l'altezza media\ndef height_sim(N):\n    male = np.random.binomial(1, 0.48, N)\n    height = np.where(male == 1, np.random.normal(69.1, 2.9, N), np.random.normal(63.7, 2.7, N))\n    return np.mean(height)\n\nSupponiamo di selezionare 10 adulti a caso. Cosa possiamo dire della loro altezza media?\n\n# Numero di simulazioni\nn_sims = 10_000\n\n# Array per memorizzare le altezze medie\navg_height = np.empty(n_sims)\nmax_height = np.empty(n_sims)\n\n# Eseguiamo 10000 simulazioni\nfor s in range(n_sims):\n    N = 10\n    male = np.random.binomial(1, 0.48, N)\n    height = np.where(male == 1, np.random.normal(69.1, 2.9, N), np.random.normal(63.7, 2.7, N))\n    avg_height[s] = np.mean(height)\n    max_height[s] = np.max(height)\n\n# Istogramma delle altezze medie\nplt.hist(avg_height, bins=30, edgecolor='black', alpha=0.5)\nplt.title('Distribuzione dell\\'altezza media di 10 adulti')\nplt.xlabel('Altezza media')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nCosa possiamo dire dell’altezza massima delle 10 persone?\n\n# Istogramma delle altezze massime\nplt.hist(max_height, bins=30, edgecolor='black', alpha=0.5)\nplt.title('Distribuzione dell\\'altezza massima di 10 adulti')\nplt.xlabel('Altezza massima')\nplt.ylabel('Frequenza')\nplt.show()",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "href": "chapters/probability/15_simulation.html#sommario-di-una-simulazione-con-media-e-mediana",
    "title": "39  Simulazioni",
    "section": "39.4 Sommario di una simulazione con media e mediana",
    "text": "39.4 Sommario di una simulazione con media e mediana\nQuando le nostre distribuzioni sono costruite come simulazioni al computer, può essere conveniente riassumerle in qualche modo. Tipicamente, riassumiamo la posizione di una distribuzione con la sua media o mediana, che possiamo calcolare direttamente in Python utilizzando numpy.\nLa variazione nella distribuzione è tipicamente riassunta dalla deviazione standard (in Python, calcolata utilizzando numpy.std), ma spesso preferiamo usare la deviazione mediana assoluta. Se la mediana di un insieme di simulazioni \\(z_1, \\ldots, z_n\\) è \\(M\\), allora la deviazione mediana assoluta è:\n\\[ \\text{mad} = \\text{mediana}_{n} |z_i - M| \\]\nTuttavia, poiché siamo abituati a lavorare con le deviazioni standard, quando calcoliamo la deviazione mediana assoluta, la riscaliamo moltiplicandola per 1.483, il che riproduce la deviazione standard nel caso speciale della distribuzione normale. Chiamiamo questa la “mad sd” e può essere calcolata in Python come:\n\\[ 1.483 * \\text{median}(|y - \\text{median}(z)|) \\]\nPreferiamo tipicamente i riassunti basati sulla mediana perché sono più stabili computazionalmente, e riscaliamo il riassunto basato sulla mediana della variazione come descritto sopra in modo da essere comparabile alla deviazione standard, che sappiamo già interpretare nella pratica statistica usuale.\n\n39.4.1 Codice in Python\nEcco come implementare quanto sopra in Python per i dati relativi all’altezza media di 10 adulti.\n\n# Funzione per calcolare la media e la mediana\ndef summarize_location(data):\n    mean_value = np.mean(data)\n    median_value = np.median(data)\n    return mean_value, median_value\n\n# Funzione per calcolare la deviazione standard\ndef calculate_sd(data):\n    return np.std(data, ddof=1)\n\n# Funzione per calcolare la deviazione mediana assoluta (mad)\ndef calculate_mad(data):\n    median_value = np.median(data)\n    mad = np.median(np.abs(data - median_value))\n    mad_sd = 1.483 * mad\n    return mad, mad_sd\n\n# Esempio di utilizzo\ndata = avg_height\n\n# Calcolo della media e della mediana\nmean_value, median_value = summarize_location(data)\nprint(\"Mean:\", mean_value)\nprint(\"Median:\", median_value)\n\n# Calcolo della deviazione standard\nsd_value = calculate_sd(data)\nprint(\"Standard Deviation:\", sd_value)\n\n# Calcolo della deviazione mediana assoluta e mad sd\nmad_value, mad_sd_value = calculate_mad(data)\nprint(\"MAD:\", mad_value)\nprint(\"MAD SD:\", mad_sd_value)\n\nMean: 66.26638365143874\nMedian: 66.26529661442922\nStandard Deviation: 1.2304485051822338\nMAD: 0.835064693740172\nMAD SD: 1.2384009408166752\n\n\nInfine, possiamo riassumere qualsiasi distribuzione tramite intervalli di incertezza; ad esempio, quantile(z, 0.25, 0.75) restituisce un intervallo centrale del 50% e quantile(z, 0.025, 0.975) restituisce un intervallo centrale del 95%.\nIn Python, possiamo usare numpy per calcolare i quantili e quindi ottenere gli intervalli di incertezza desiderati. Ecco come fare:\n\n# Funzione per calcolare gli intervalli di incertezza\ndef uncertainty_intervals(data, lower_quantile, upper_quantile):\n    lower = np.quantile(data, lower_quantile)\n    upper = np.quantile(data, upper_quantile)\n    return lower, upper\n\n# Esempio di utilizzo\ndata = avg_height\n\n# Calcolo dell'intervallo centrale del 50%\nlower_50, upper_50 = uncertainty_intervals(data, 0.25, 0.75)\nprint(\"Central 50% interval:\", lower_50, \"-\", upper_50)\n\n# Calcolo dell'intervallo centrale del 95%\nlower_95, upper_95 = uncertainty_intervals(data, 0.025, 0.975)\nprint(\"Central 95% interval:\", lower_95, \"-\", upper_95)\n\nCentral 50% interval: 65.42660984223639 - 67.0950850704999\nCentral 95% interval: 63.88592362666574 - 68.7170467946227",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#commenti-e-considerazioni-finali",
    "href": "chapters/probability/15_simulation.html#commenti-e-considerazioni-finali",
    "title": "39  Simulazioni",
    "section": "39.5 Commenti e Considerazioni Finali",
    "text": "39.5 Commenti e Considerazioni Finali\nLo scopo della simulazione di dati fittizi non è fornire intuizioni sui dati o sul problema reale in esame, ma piuttosto valutare le proprietà dei metodi statistici utilizzati, partendo da un modello generativo ipotizzato. Le simulazioni sono cruciali nella pratica della ricerca. Molti autori suggeriscono che dovrebbero essere eseguite prima di raccogliere i dati di uno studio, per valutare, tra le altre cose, se la dimensione campionaria prevista fornisce un potere statistico sufficiente per rispondere alla domanda della ricerca (Gelman & Brown, 2024).",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#esercizi",
    "href": "chapters/probability/15_simulation.html#esercizi",
    "title": "39  Simulazioni",
    "section": "39.6 Esercizi",
    "text": "39.6 Esercizi\n\nEsercizio 39.1 Immagina il caso di 220 studenti che devono sostenere tre prove in itinere in un corso. Il voto finale è la media dei voti ottenuti in queste tre prove. Le distribuzioni dei voti per le prove sono descritte come segue:\n\nPrima prova: I voti sono distribuiti secondo una gaussiana con media 24. Il 15% degli studenti ottiene un voto inferiore a 18.\nSeconda prova: I voti sono distribuiti secondo una gaussiana con media 25. Il 10% degli studenti ottiene un voto inferiore a 18.\nTerza prova: I voti sono distribuiti secondo una gaussiana con media 26. Solo il 5% degli studenti ottiene un voto inferiore a 18.\n\nDei 220 studenti iniziali:\n\nIl 10% non partecipa alla prima prova.\nUn ulteriore 5% non partecipa alla seconda prova.\n\nPer ottenere il voto finale, uno studente deve partecipare a tutte e tre le prove.\nUtilizzando una simulazione, trova la media finale dei voti e calcola l’intervallo di incertezza al 90% per la stima della media.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/probability/15_simulation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/probability/15_simulation.html#informazioni-sullambiente-di-sviluppo",
    "title": "39  Simulazioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Aug 08 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Probabilità",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Simulazioni</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "href": "chapters/bayesian_inference/introduction_bayes_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esamineremo l’inferenza bayesiana applicata a modelli statistici in cui si stima un unico parametro scalare, cioè quando l’estimando \\(\\theta\\) è unidimensionale. In questo capitolo, consideriamo quattro modelli unidimensionali fondamentali e ampiamente utilizzati: il modello binomiale, il modello normale, il modello di Poisson e il modello esponenziale. Approfondiremo il processo di aggiornamento bayesiano, analizzando due metodi principali per derivare la distribuzione a posteriori: l’approssimazione numerica attraverso il metodo basato su griglia e l’utilizzo delle distribuzioni coniugate, in cui una specifica combinazione di distribuzione a priori e verosimiglianza consente una derivazione analitica della distribuzione a posteriori. Inoltre, considereremo l’influenza della scelta della distribuzione a priori sulla distribuzione a posteriori e discuteremo le tecniche utili per sintetizzare e interpretare quest’ultima in modo efficace.",
    "crumbs": [
      "Inferenza",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html",
    "href": "chapters/bayesian_inference/01_intro_bayes.html",
    "title": "40  La quantificazione dell’incertezza",
    "section": "",
    "text": "40.1 Introduzione\nL’approccio bayesiano alla statistica non si limita all’applicazione del Teorema di Bayes, ma si caratterizza per una gestione rigorosa dell’incertezza e per la rappresentazione delle soluzioni attraverso distribuzioni di probabilità. Il processo di modellazione bayesiana, noto come workflow bayesiano (Baribault & Collins, 2023), si articola in più fasi: dalla costruzione del modello, all’applicazione del Teorema di Bayes, fino all’analisi critica dei risultati. Questo ciclo iterativo permette un apprendimento continuo, migliorando progressivamente le stime e adattandole alle nuove evidenze che emergono.\nL’obiettivo dell’approccio bayesiano non è quello di raggiungere una verità assoluta, ma di aggiornare razionalmente le credenze su una determinata ipotesi, integrando progressivamente nuove informazioni. Questo approccio è particolarmente utile in psicologia, dove i fenomeni analizzati sono complessi e le misurazioni soggette a molte fonti di incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#introduzione",
    "title": "40  La quantificazione dell’incertezza",
    "section": "",
    "text": "“Quindi non avete una sola risposta alle vostre domande?”\n“Adson, se l’avessi insegnerei teologia a Parigi.”\n“A Parigi hanno sempre la risposta vera?”\n“Mai,” disse Guglielmo, “ma sono molto sicuri dei loro errori.”\n(Umberto Eco: Il Nome della Rosa)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-valore-dellincertezza",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.2 Il Valore dell’Incertezza",
    "text": "40.2 Il Valore dell’Incertezza\nIn psicologia e in altre scienze sociali, l’informazione è spesso incompleta, e le variabili di interesse sono latenti o difficili da osservare direttamente. L’inferenza bayesiana offre un quadro metodologico per rappresentare e affrontare questa incertezza, permettendo di modellare ciò che non si conosce come una variabile aleatoria che può essere aggiornata man mano che si acquisiscono nuovi dati (Jaynes, 2003).\nDiversamente dai modelli deterministici, che assumono la possibilità di prevedere i risultati con certezza date tutte le informazioni, i modelli bayesiani accolgono e gestiscono l’incertezza, caratteristica fondamentale in psicologia. Molti fenomeni psicologici coinvolgono variabili latenti – come l’ansia, la motivazione o l’autostima – che non possono essere osservate direttamente. L’approccio bayesiano consente di rappresentare tali variabili in modo flessibile, integrando evidenze precedenti con i dati attuali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-frequentista-vs.-bayesiana-dellincertezza",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza",
    "text": "40.3 Interpretazione Frequentista vs. Bayesiana dell’Incertezza\n\nInterpretazione Frequentista: Immaginiamo di misurare la frequenza di un evento psicologico, come un livello di ansia oltre una certa soglia, in un grande campione di individui simili. Secondo i frequentisti, si potrebbe interpretare l’incertezza come la frequenza relativa dell’evento in situazioni simili nel lungo periodo. Tuttavia, questa interpretazione presenta due problemi principali: non è possibile osservare un evento infinite volte in condizioni identiche, e il “gruppo di riferimento” (o reference class) – cioè, le condizioni simili rilevanti – può essere difficile da definire precisamente.\nInterpretazione Bayesiana: Un’interpretazione bayesiana dell’incertezza riguarda invece il grado di credenza soggettiva. Supponiamo che uno psicologo creda con il 10% di fiducia che un individuo avrà un punteggio d’ansia superiore a una certa soglia. Questo grado di fiducia può essere aggiornato man mano che si raccolgono nuove informazioni, utilizzando il Teorema di Bayes per calcolare probabilità a posteriori. A differenza dell’approccio frequentista, l’incertezza bayesiana descrive una credenza soggettiva che può essere costantemente aggiornata.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#esempi-psicologici-dellinferenza-bayesiana",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.4 Esempi Psicologici dell’Inferenza Bayesiana",
    "text": "40.4 Esempi Psicologici dell’Inferenza Bayesiana\nEsempio 1: Misurare l’Ansia con Questionari\nQuando si misura l’ansia tramite un questionario, la stima è soggetta a incertezza per vari motivi: 1. Risposte Soggettive: L’interpretazione delle domande può variare tra individui e può essere influenzata dallo stato d’animo. 2. Misurazioni Incomplete: Un questionario può non cogliere tutte le sfumature dell’ansia. 3. Rumore nei Dati: Errori minori, come distrazioni durante la compilazione, possono influire sulla precisione dei risultati.\nCon l’approccio bayesiano, è possibile combinare credenze a priori basate su ricerche precedenti con i dati raccolti per ottenere una stima aggiornata. Ad esempio, se si dispone di una distribuzione di probabilità iniziale sull’ansia, questa distribuzione può essere aggiornata man mano che si raccolgono più dati, permettendo una stima più accurata del livello di ansia effettivo.\nEsempio 2: Effetto del Rinforzo Negativo sulla Motivazione\nConsideriamo uno studio sull’effetto del rinforzo negativo sulla motivazione in un compito. La “motivazione interna” è una variabile latente, non osservabile direttamente. Possiamo inferirla, però, tramite misure indirette, come il tempo trascorso sul compito o la velocità di risposta. Un modello bayesiano consente di collegare queste variabili osservabili alla motivazione latente, rappresentando l’incertezza sia nella variabilità individuale sia nell’effetto del rinforzo negativo. Man mano che vengono raccolti nuovi dati, il modello bayesiano aggiorna le stime di motivazione e permette di esprimere in modo rigoroso la probabilità che un cambiamento osservato sia effettivamente dovuto al rinforzo negativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#inferenza-bayesiana-e-incertezza-nelle-stime",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.5 Inferenza Bayesiana e Incertezza nelle Stime",
    "text": "40.5 Inferenza Bayesiana e Incertezza nelle Stime\nL’inferenza bayesiana utilizza le probabilità per aggiornare le credenze sui parametri di un modello basandosi sui dati osservati. Queste credenze sono rappresentate da distribuzioni di probabilità, e l’ampiezza di queste distribuzioni riflette l’incertezza associata alle stime. In psicologia, dove spesso si lavora con campioni limitati e misurazioni indirette di variabili latenti, questa gestione dell’incertezza è fondamentale per interpretare i risultati in modo robusto e realistico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-modello-bayesiano",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.6 Il Modello Bayesiano",
    "text": "40.6 Il Modello Bayesiano\nUn modello statistico combina una distribuzione probabilistica con ipotesi sui parametri per descrivere un fenomeno osservato. Ad esempio, possiamo modellare il lancio di una moneta equa con un modello binomiale, in cui la probabilità \\(\\theta\\) è fissata a 0.5, oppure modellare l’altezza degli uomini italiani con un modello normale, in cui \\(\\mu\\) è 183 cm e \\(\\sigma\\) è 5 cm. In termini bayesiani, il modello statistico include tre componenti principali:\n\nDistribuzione a Priori (Prior): Rappresenta le credenze iniziali sui valori dei parametri del modello, informate da ricerche precedenti o da assunzioni neutre.\nVerosimiglianza (Likelihood): Descrive la probabilità di osservare i dati dati i parametri del modello, riflettendo il processo che genera i dati.\nDistribuzione a Posteriori (Posterior): È la distribuzione aggiornata dei parametri dopo aver osservato i dati, ottenuta combinando la prior e la verosimiglianza mediante il teorema di Bayes. La posterior rappresenta la conoscenza aggiornata dopo aver integrato le informazioni fornite dai dati.\n\nLa modellazione bayesiana descrive il processo generativo che ha prodotto i dati osservati, incorporando l’incertezza nei parametri e aggiornando continuamente le stime man mano che emergono nuovi dati. Questo approccio è particolarmente utile in contesti come la psicologia, dove i fenomeni complessi e le variabili latenti rendono necessario modellare l’incertezza in modo esplicito.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#componenti-chiave-della-modellazione-probabilistica",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.7 Componenti Chiave della Modellazione Probabilistica",
    "text": "40.7 Componenti Chiave della Modellazione Probabilistica\n\nVariabili Aleatorie: Quantità incerte che assumono diversi valori secondo una distribuzione di probabilità. Ad esempio, il livello di depressione di un paziente può essere trattato come una variabile aleatoria.\nDistribuzioni di Probabilità: Descrivono come i valori di una variabile aleatoria sono distribuiti. Ad esempio, una distribuzione normale può essere utilizzata per modellare la variabilità dell’ansia in una popolazione.\nInferenza Bayesiana: Aggiorna la distribuzione di probabilità delle variabili di interesse sulla base dei nuovi dati, migliorando progressivamente le stime.\n\nEsempio: Inferenza sul Livello di Depressione\nIn uno studio clinico sulla depressione, possiamo utilizzare l’inferenza bayesiana per stimare il livello di depressione di un paziente partendo da una distribuzione a priori informata da studi precedenti. Ogni nuovo dato raccolto (come punteggi a questionari o osservazioni) permette di aggiornare questa stima, affinando progressivamente la comprensione del fenomeno.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-potere-dellaggiornamento-bayesiano",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.8 Il Potere dell’Aggiornamento Bayesiano",
    "text": "40.8 Il Potere dell’Aggiornamento Bayesiano\nIl vero punto di forza della modellazione bayesiana risiede nella sua capacità di aggiornare continuamente le credenze sui parametri del modello man mano che si raccolgono nuovi dati. Questo processo iterativo, basato sul teorema di Bayes, consente di integrare sia le credenze iniziali (a priori) sia le evidenze empiriche (verosimiglianza) per ottenere stime sempre più precise.\nEsempio Intuitivo: Il Globo Terrestre\nUn esempio intuitivo per spiegare l’aggiornamento bayesiano è quello proposto da McElreath (2020). Supponiamo di voler stimare la proporzione della superficie terrestre coperta d’acqua. L’esperimento consiste nel lanciare un globo terrestre in aria, afferrarlo e osservare se la superficie sotto il dito è acqua o terra. Dopo ogni osservazione, possiamo aggiornare le nostre credenze sulla proporzione d’acqua (p).\nIniziamo con una distribuzione a priori che assegna la stessa probabilità a tutti i valori possibili di \\(p\\) (proporzione d’acqua). Dopo il primo lancio, in cui osserviamo acqua (“W”), la probabilità che \\(p\\) sia zero diminuisce, mentre quella che \\(p\\) sia maggiore aumenta. Man mano che raccogliamo più dati, la distribuzione si aggiorna, riducendo l’incertezza e convergendo verso una stima più precisa di \\(p\\).\nCon l’aumento dei dati osservati, la distribuzione a posteriori si concentra sempre di più attorno ai valori di \\(p\\) che meglio spiegano i dati. Questo processo rappresenta il continuo affinamento delle stime bayesiane, che diventano più accurate man mano che le evidenze si accumulano.\nIn sintesi, l’aggiornamento bayesiano fornisce un quadro flessibile e sistematico per trattare l’incertezza e integrare nuove informazioni. È particolarmente utile nelle scienze psicologiche e sociali, dove la complessità e la variabilità dei fenomeni rendono difficile ottenere stime precise. Questo approccio consente di migliorare costantemente la comprensione dei fenomeni, adattando le credenze man mano che emergono nuovi dati.\n\n\n\n\n\n\n\n\n\nIl grafico precedente illustra un processo di aggiornamento bayesiano, in cui vengono progressivamente aggiornate le credenze sulla proporzione di superficie coperta d’acqua (\\(p\\)) del globo terrestre, man mano che vengono raccolti nuovi dati.\nL’esperimento prevede il lancio di un globo terrestre per osservare se la superficie sotto il dito è acqua (“W”) o terra (“L”). Dopo ogni lancio, le probabilità sui possibili valori di \\(p\\) vengono aggiornate sulla base delle osservazioni, utilizzando il teorema di Bayes. Il processo è visualizzato attraverso una serie di grafici, organizzati in una griglia 3x3, con ogni pannello che rappresenta un’osservazione aggiuntiva.\n\nLinee tratteggiate: Ogni curva tratteggiata in un pannello rappresenta la distribuzione di probabilità a posteriori (posterior) derivata dal pannello precedente. In altre parole, questa è la distribuzione che incorpora tutte le osservazioni fino a quel momento.\nLinee continue: Ogni curva continua rappresenta la nuova distribuzione a posteriori, aggiornata dopo aver aggiunto una nuova osservazione. Questa curva combina la distribuzione a priori (che coincide con la curva tratteggiata dal pannello precedente) e la nuova evidenza.\n\n\nPrimo Pannello (Osservazione: W)\n\nLa prima osservazione è “acqua” (W). La distribuzione a priori è uniforme, poiché non ci sono informazioni iniziali. Dopo aver osservato acqua, la distribuzione a posteriori si aggiorna: la probabilità che \\(p = 0\\) (nessuna acqua) è ora zero, e la curva si sposta verso destra, indicando che è più probabile che \\(p\\) sia maggiore di 0.\n\nSecondo Pannello (Osservazione: L)\n\nLa seconda osservazione è “terra” (L). La curva si sposta leggermente verso sinistra, poiché è ora meno probabile che \\(p\\) sia molto alto (vicino a 1). La probabilità che \\(p\\) sia 0.5 diventa massima, in quanto abbiamo osservato una volta acqua e una volta terra.\n\nTerzo Pannello (Osservazione: W)\n\nIl terzo lancio produce di nuovo acqua. La curva si sposta nuovamente verso destra, con un picco vicino a \\(p = 0.75\\), riflettendo che abbiamo osservato acqua due volte su tre. La distribuzione si aggiorna in base alla nuova evidenza.\n\nPannelli Successivi\n\nOgni nuovo pannello segue lo stesso schema: la distribuzione a priori (linea tratteggiata) viene aggiornata con la nuova osservazione (linea continua). Se viene osservata acqua (W), il picco della distribuzione si sposta a destra; se viene osservata terra (L), il picco si sposta a sinistra. In ogni caso, la curva diventa progressivamente più “appuntita”, indicando che l’incertezza sulla vera proporzione di acqua diminuisce con l’aumentare del numero di osservazioni.\n\n\nL’aspetto fondamentale dell’approccio bayesiano è che ogni distribuzione a posteriori aggiornata (linea continua) diventa la nuova distribuzione a priori per la successiva osservazione. Questo processo iterativo permette di apprendere progressivamente dai dati, integrando ogni nuova informazione per affinare la stima di \\(p\\). Alla fine, la distribuzione diventa sempre più concentrata intorno al valore più probabile di \\(p\\), man mano che raccogliamo più dati.\nIn conclusione, l’esempio illustra come l’aggiornamento bayesiano modifichi le nostre credenze sulla proporzione d’acqua (\\(p\\)) sulla superficie del globo, basandosi sulle osservazioni raccolte. Ogni curva rappresenta la sintesi delle conoscenze attuali, combinando le osservazioni precedenti con l’ultima evidenza raccolta. Il grafico dimostra visivamente come l’approccio bayesiano consenta di trattare l’incertezza e aggiornare le stime in modo coerente e progressivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#il-processo-generatore-dei-dati",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.9 Il Processo Generatore dei Dati",
    "text": "40.9 Il Processo Generatore dei Dati\nNel contesto dell’aggiornamento bayesiano, è fondamentale fare un’assunzione su quale modello statistico descriva il processo generatore dei dati, ossia il meccanismo che collega i parametri sconosciuti ai dati osservati. Questo modello è rappresentato dalla funzione di verosimiglianza, che descrive la probabilità di osservare i dati per ogni possibile valore del parametro incognito. Ad esempio, nel caso di esperimenti bernoulliani come quello dei lanci del globo, ogni prova può risultare in un successo (acqua) o in un fallimento (terra), e l’obiettivo è stimare la probabilità di successo, \\(\\theta\\).\nIl processo generatore dei dati per questo tipo di esperimento è ben descritto da una distribuzione binomiale, che modella il numero di successi osservati in una serie di prove indipendenti, ciascuna caratterizzata dalla stessa probabilità \\(\\theta\\). In questo contesto, \\(\\theta\\) rappresenta la proporzione di superficie coperta d’acqua sul globo, e l’assunzione chiave è che essa rimanga costante durante l’intero esperimento.\n\n\n\n\n\n\nFigura 40.1: Gli stessi dati possono essere coerenti con diverse ipotesi riguardanti il processo che li ha generati(Figura tratta da Freiesleben & Molnar, 2024).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#aggiornamento-bayesiano-e-processo-generatore",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.10 Aggiornamento Bayesiano e Processo Generatore",
    "text": "40.10 Aggiornamento Bayesiano e Processo Generatore\nL’aggiornamento bayesiano permette di modificare le nostre credenze riguardo al valore del parametro \\(\\theta\\) man mano che osserviamo nuovi dati. Il punto di partenza è una distribuzione a priori su \\(\\theta\\), che può riflettere la nostra ignoranza (ad esempio, una distribuzione uniforme, che assegna uguale probabilità a tutti i valori di \\(\\theta\\) tra 0 e 1) o conoscenze preesistenti. Nel nostro esempio con il globo, possiamo iniziare con una distribuzione a priori uniforme, che indica che ogni proporzione di acqua è inizialmente considerata ugualmente probabile.\nMan mano che raccogliamo dati (ad esempio, 6 successi su 9 lanci), applichiamo il Teorema di Bayes per combinare la distribuzione a priori con la verosimiglianza dei dati osservati, ottenendo una distribuzione a posteriori che rappresenta le nostre credenze aggiornate su \\(\\theta\\). La distribuzione a posteriori riflette le informazioni aggiunte dai dati e fornisce una stima aggiornata e più precisa di \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#interpretazione-della-distribuzione-a-posteriori",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.11 Interpretazione della Distribuzione a Posteriori",
    "text": "40.11 Interpretazione della Distribuzione a Posteriori\nLa distribuzione a posteriori ci permette di fare inferenze più solide su \\(\\theta\\). In particolare, possiamo calcolare:\n\nModa: Il valore di \\(\\theta\\) con la massima probabilità, che indica la stima più plausibile.\nMedia o Mediana: Altre misure riassuntive della distribuzione a posteriori, che possono fornire ulteriori informazioni sull’intervallo di valori probabili per \\(\\theta\\).\n\nL’incertezza sulla stima è rappresentata dall’ampiezza della distribuzione a posteriori. Se la distribuzione è stretta, significa che l’incertezza è bassa, mentre una distribuzione più ampia indica una maggiore incertezza. Con l’aumento dei dati osservati, la distribuzione tende a concentrarsi intorno a un intervallo ristretto, riducendo l’incertezza e migliorando la precisione della stima.\nNel caso del globo, ad esempio, se osserviamo che la distribuzione a posteriori ha un picco vicino a \\(\\theta = 0.67\\), possiamo concludere che la probabilità più plausibile per la proporzione di acqua sul globo è circa 67%. Inoltre, se la distribuzione a posteriori è stretta, possiamo essere più sicuri di questa stima, mentre se è più ampia, la nostra incertezza sarà maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#influenza-delle-distribuzioni-a-priori",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.12 Influenza delle Distribuzioni a Priori",
    "text": "40.12 Influenza delle Distribuzioni a Priori\nIn questo esempio, abbiamo utilizzato una distribuzione a priori uniforme, che esprime una totale mancanza di conoscenza iniziale su \\(\\theta\\). Tuttavia, in contesti in cui abbiamo informazioni preesistenti, è possibile utilizzare distribuzioni a priori più informative. Ad esempio, se sappiamo da studi precedenti che circa il 70% della superficie terrestre è coperta d’acqua, possiamo utilizzare una distribuzione a priori che rifletta questa conoscenza. Questo tipo di distribuzione a priori informativa può rendere l’aggiornamento bayesiano più efficiente, portando a stime più precise con meno dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#vantaggi-dellaggiornamento-bayesiano",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.13 Vantaggi dell’Aggiornamento Bayesiano",
    "text": "40.13 Vantaggi dell’Aggiornamento Bayesiano\nUno dei principali vantaggi dell’approccio bayesiano è che ogni nuova osservazione aggiorna automaticamente le credenze preesistenti, integrando le informazioni precedenti con i nuovi dati. Questo processo consente un apprendimento iterativo e progressivo, che diventa più efficiente man mano che si accumulano dati. Inoltre, la flessibilità nella scelta della distribuzione a priori consente al ricercatore di adattare l’inferenza bayesiana al contesto specifico, migliorando ulteriormente la precisione delle stime.\nIn sintesi, il processo generatore dei dati, modellato tramite la verosimiglianza, gioca un ruolo centrale nell’aggiornamento bayesiano. Nel caso del globo, abbiamo modellato il fenomeno utilizzando una distribuzione binomiale e, attraverso l’applicazione del Teorema di Bayes, abbiamo aggiornato progressivamente le nostre credenze sulla proporzione di acqua osservata. Il risultato è una stima sempre più precisa di \\(\\theta\\), con una distribuzione a posteriori che riflette sia le osservazioni passate sia le nuove evidenze, riducendo progressivamente l’incertezza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#riflessioni-conclusive",
    "title": "40  La quantificazione dell’incertezza",
    "section": "40.14 Riflessioni Conclusive",
    "text": "40.14 Riflessioni Conclusive\nNegli ultimi anni, i metodi bayesiani stanno acquisendo sempre più importanza nel campo dell’inferenza statistica, anche in discipline come la psicologia. Questa diffusione è favorita dall’accesso a risorse educative e a testi fondamentali, come quelli di Albert & Hu (2019), Johnson et al. (2022), McElreath (2020) e Kruschke (2014), che hanno reso la modellizzazione bayesiana più accessibile, chiarendo i concetti centrali in modo pratico e comprensibile.\nL’approccio bayesiano si distingue dalla metodologia frequentista tradizionale per la sua capacità di trattare i parametri di interesse come quantità probabilistiche. Invece di considerare i parametri come valori fissi e sconosciuti (come avviene nel paradigma frequentista), il bayesianesimo assegna ai parametri una distribuzione a priori, che rappresenta le credenze iniziali del ricercatore. Man mano che nuovi dati vengono raccolti, queste credenze vengono aggiornate tramite il teorema di Bayes, portando a una distribuzione a posteriori che riflette sia le informazioni pregresse sia l’evidenza empirica. Questa distribuzione aggiornata consente di esprimere l’incertezza sui parametri in modo più completo e informato.\nUno dei principali vantaggi dell’approccio bayesiano è la sua capacità di combinare conoscenze pregresse con nuove osservazioni in modo fluido e sistematico. Ogni nuova informazione arricchisce e raffina le stime, rendendole più accurate e interpretabili nel contesto del problema specifico. Questo non solo migliora la precisione delle inferenze, ma permette anche una migliore comprensione dell’incertezza che circonda i parametri studiati.\nIn definitiva, l’inferenza bayesiana non è solo uno strumento analitico, ma un approccio dinamico che incoraggia un’interazione continua tra teoria ed evidenza. Offrendo una flessibilità unica e una gestione esplicita dell’incertezza, il bayesianesimo si rivela un metodo potente per supportare il processo decisionale in contesti complessi, rendendo le sue applicazioni particolarmente rilevanti in campi come la psicologia, dove l’incertezza è una componente inevitabile dell’analisi dei dati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/01_intro_bayes.html#informazioni-sullambiente-di-sviluppo",
    "title": "40  La quantificazione dell’incertezza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Sat Oct 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.14.0\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nBaribault, B., & Collins, A. G. (2023). Troubleshooting Bayesian cognitive models. Psychological Methods.\n\n\nFreiesleben, T., & Molnar, C. (2024). Supervised Machine Learning for Science: How to stop worrying and love your black box. https://ml-science-book.com/\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>La quantificazione dell'incertezza</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html",
    "title": "41  Inferenza bayesiana",
    "section": "",
    "text": "Introduzione\nQuesto capitolo approfondisce i concetti introdotti nel capitolo precedente, presentando l’aggiornamento bayesiano in modo più formale e dettagliato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#paradigma-bayesiano",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#paradigma-bayesiano",
    "title": "41  Inferenza bayesiana",
    "section": "41.1 Paradigma Bayesiano",
    "text": "41.1 Paradigma Bayesiano\nL’approccio bayesiano alla statistica si fonda sull’idea di rappresentare la conoscenza a priori sui parametri che governano un fenomeno attraverso distribuzioni di probabilità. Queste distribuzioni a priori riflettono le credenze iniziali del ricercatore riguardo ai parametri, prima di osservare i dati. Quando nuovi dati vengono raccolti, l’informazione fornita da tali dati viene integrata nel modello tramite la funzione di verosimiglianza, che rappresenta la probabilità di osservare quei dati dati i parametri ipotizzati.\nAttraverso l’applicazione del Teorema di Bayes, le credenze a priori vengono aggiornate combinando la distribuzione a priori con la verosimiglianza dei dati. Questo processo produce la distribuzione a posteriori, che rappresenta una nuova e più informata stima dei parametri, tenendo conto sia delle credenze iniziali sia dei dati osservati.\nL’approccio bayesiano richiede un cambiamento di prospettiva rispetto ai metodi classici di stima dei parametri. Non ci si limita più a trovare un singolo valore “ottimale” per i parametri del modello. Invece, l’obiettivo è determinare l’intera distribuzione a posteriori dei parametri, che descrive in modo completo lo stato di conoscenza attuale. Solo questa distribuzione fornisce una rappresentazione adeguata dell’incertezza associata ai parametri, permettendo di quantificare non solo quali valori sono più probabili, ma anche l’ampiezza dell’incertezza su tali stime.\n\n41.1.1 Vantaggi dell’Approccio Bayesiano\nUn aspetto distintivo dell’inferenza bayesiana è la sua capacità di gestire l’incertezza in modo esplicito. Invece di limitarsi a una singola stima puntuale, l’approccio bayesiano considera l’intero spettro di valori possibili per i parametri e le loro rispettive probabilità. Questo consente una rappresentazione più ricca delle informazioni disponibili e una valutazione più robusta delle ipotesi.\nInoltre, l’approccio bayesiano è altamente flessibile, permettendo di incorporare informazioni precedenti sotto forma di distribuzioni a priori. In contesti in cui si dispone di conoscenze pregresse, come dati di studi precedenti o teorie consolidate, questa caratteristica offre un vantaggio notevole rispetto agli approcci frequentisti, che non integrano facilmente tali informazioni.\nIn conclusione, il paradigma bayesiano offre una visione più ampia e completa dell’incertezza e della variabilità dei parametri rispetto ai metodi tradizionali, rappresentando un quadro teorico e pratico fondamentale per l’inferenza statistica e la modellazione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#densità-di-probabilità",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#densità-di-probabilità",
    "title": "41  Inferenza bayesiana",
    "section": "41.2 Densità di Probabilità",
    "text": "41.2 Densità di Probabilità\nNei capitoli precedenti abbiamo esaminato alcuni esempi di funzioni di densità di probabilità (PDF). Ma quali sono le caratteristiche generali di una PDF?\nSe \\(X\\) è una variabile casuale con una funzione di densità di probabilità \\(p(x)\\), la probabilità che \\(X\\) assuma un valore nell’intervallo \\((a, b)\\) può essere calcolata come:\n\\[\np(X \\in (a,b)) = \\int_a^b p(x)dx.\n\\]\nPer variabili discrete, l’integrazione si trasforma in una somma.\n\n41.2.1 Le Regole di Somma e Prodotto\nDate due variabili casuali continue \\(x\\) e \\(y\\), le regole di somma e prodotto per le densità di probabilità si esprimono come:\n\\[\n\\begin{align*}\np(y) = \\int p(x,y)dx \\quad &\\text{- regola della somma},\\\\\np(x,y) = p(y|x) p(x) = p(x|y) p(y) \\quad &\\text{- regola del prodotto}.\n\\end{align*}\n\\]\nLa probabilità \\(p(y)\\) è chiamata probabilità marginale.\nLa regola del prodotto specifica che la distribuzione congiunta di due variabili può essere espressa come il prodotto di una distribuzione condizionata \\(p(y \\mid x)\\) e una distribuzione marginale \\(p(x)\\), o viceversa.\n\n\n41.2.2 La Distribuzione Marginale\nLa distribuzione marginale si riferisce alla distribuzione di probabilità di una variabile quando si tiene conto di tutte le possibili variazioni dell’altra variabile in una distribuzione congiunta. In altre parole, essa descrive la probabilità di una variabile indipendentemente dall’altra.\nConsideriamo due variabili correlate, \\(x\\) e \\(y\\). Possiamo esprimere la relazione tra di esse con la regola del prodotto:\n\\[\np(x, y) = p(y \\mid x)p(x),\n\\]\ndove \\(p(y \\mid x)\\) è la probabilità di \\(y\\) dato un certo valore di \\(x\\), e \\(p(x)\\) è la distribuzione di probabilità di \\(x\\).\nPer ottenere la distribuzione marginale di \\(y\\), dobbiamo sommare o integrare \\(p(y \\mid x)\\) su tutti i possibili valori di \\(x\\):\n\\[\np(y) = \\int p(y \\mid x)p(x)dx.\n\\]\nIn questo modo, la distribuzione marginale di \\(y\\) rappresenta la probabilità di \\(y\\), tenendo conto di tutte le possibili variazioni di \\(x\\).\n\n\n41.2.3 Il Teorema di Bayes\nDalla regola di prodotto, e sfruttando la proprietà di simmetria \\(p(x \\mid y)p(y) = p(y \\mid x)p(x)\\), deriviamo immediatamente la regola di Bayes:\n\\[\np(y \\mid x) = \\frac{p(x \\mid y)p(y)}{p(x)} = \\frac{p(x \\mid y)p(y)}{\\int p(x \\mid y)p(y)dy}.\n\\]\nQuesta formula è l’elemento chiave nell’inferenza bayesiana, poiché definisce la densità a posteriori di \\(y\\), \\(p(y \\mid x)\\), dopo aver incorporato l’informazione \\(x\\) attraverso il modello di probabilità condizionata \\(p(x \\mid y)\\). La probabilità marginale di \\(x\\), \\(p(x)\\), funge da costante di normalizzazione, garantendo che \\(p(y \\mid x)\\) sia una corretta funzione di densità di probabilità.\n\n\n41.2.4 Modellizzazione e Inferenza Bayesiana\nLa modellizzazione bayesiana consiste nel descrivere matematicamente tutti i dati osservabili \\(y\\) e i parametri non osservabili, detti anche parametri “latenti” \\(\\theta\\), definendo la distribuzione congiunta di dati e parametri \\(p(y, \\theta)\\).\nSi costruiscono modelli probabilistici per le quantità osservate condizionate ai parametri \\(p(y \\mid \\theta)\\) e per le quantità non osservate, rappresentate dalla distribuzione a priori \\(p(\\theta)\\), che rappresenta le nostre conoscenze precedenti sui parametri. Questi due elementi vengono combinati, seguendo la regola del prodotto, per formare una distribuzione congiunta:\n\\[\np(y, \\theta) = p(y \\mid \\theta)p(\\theta).\n\\]\n\n\n41.2.5 Il Modello Osservazionale\nLa funzione\n\\[\np(y \\mid \\theta)\n\\]\nè un modello probabilistico dei dati osservati che mette in relazione \\(y\\) con i parametri sconosciuti \\(\\theta\\) che vogliamo stimare. Questo modello rappresenta l’evidenza fornita dai dati e costituisce la principale fonte di informazione. In questo contesto, viene chiamato funzione di verosimiglianza (likelihood). È importante notare che la funzione di verosimiglianza nel contesto bayesiano non è diversa da quella utilizzata nell’approccio frequentista: in entrambi i casi collega i dati osservati ai parametri sconosciuti.\n\n\n41.2.6 La Distribuzione a Priori\nLa distribuzione\n\\[\np(\\theta)\n\\]\nrappresenta la distribuzione a priori dei parametri, che codifica le conoscenze preesistenti sui parametri stessi. Questa distribuzione a priori può essere informativa o non informativa, a seconda della quantità di informazioni affidabili che si possiedono sui parametri. Uno degli aspetti principali che differenziano l’approccio bayesiano da quello frequentista è l’uso delle distribuzioni di probabilità per i parametri sconosciuti. Queste distribuzioni vengono poi combinate con la funzione di verosimiglianza per ottenere una distribuzione a posteriori, che incorpora sia le informazioni precedenti che le evidenze fornite dai nuovi dati.\n\n\n41.2.7 Inferenza sui Parametri\nOttenere la distribuzione a posteriori dei parametri sconosciuti è l’elemento centrale dell’approccio bayesiano. Riformulando la regola di Bayes in termini di \\(y\\) e \\(\\theta\\), otteniamo una formula che ci mostra come calcolare la distribuzione a posteriori:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)} = \\frac{p(y \\mid \\theta)p(\\theta)}{\\int p(y \\mid \\theta)p(\\theta) d\\theta}.\n\\]\nIl denominatore della regola di Bayes,\n\\[\np(y) = \\int p(y \\mid \\theta)p(\\theta) d \\theta,\n\\]\nè chiamato verosimiglianza marginale, poiché integra la verosimiglianza rispetto all’informazione a priori sui parametri. Questa quantità è anche nota come evidenza del modello e serve a normalizzare la distribuzione a posteriori, rendendola una vera distribuzione di probabilità. L’inferenza finale sarà un compromesso tra l’evidenza fornita dai dati e l’informazione a priori disponibile.\n\n\n41.2.8 Inferenza bayesiana in sintesi: verosimiglianza, prior, posteriore\nPer riassumere, ecco tutti i componenti fondamentali dell’inferenza bayesiana.\nIl teorema di Bayes, espresso in termini di dati \\(y\\) e parametri del modello \\(\\theta\\), è\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)},\n\\]\ndove:\n\nIl denominatore \\(p(y)\\) è la costante di normalizzazione o evidenza.\n\\(p(\\theta)\\) rappresenta il prior, ovvero le credenze iniziali sui parametri.\n\\(p(y \\mid \\theta)\\) è la verosimiglianza, che collega i dati osservati ai parametri del modello.\n\\(p(\\theta \\mid y)\\) è la distribuzione a posteriori, che rappresenta le credenze aggiornate sui parametri dopo aver osservato i dati.\n\nLa distribuzione a posteriori riassume il nostro stato di credenza sui possibili valori di \\(\\theta\\), aggiornato sulla base delle evidenze fornite dai dati.\nSi noti che \\(p(y)\\) non dipende dai parametri \\(\\theta\\). Pertanto, in molte situazioni pratiche, è sufficiente calcolare la distribuzione a posteriori fino a una costante. Per questo motivo, spesso la regola di Bayes viene riassunta come:\n\\[p(\\theta \\mid y) \\propto p(y \\mid \\theta)p(\\theta).\\]\nIn questa forma, si ignora il denominatore poiché è una costante (indipendente da \\(\\theta\\)).\n\n\n41.2.9 Il Ruolo dei Priors\nUna delle caratteristiche distintive dell’approccio bayesiano è l’incorporazione delle conoscenze a priori riguardo ai parametri del modello. Dichiarare questi priors ci obbliga a esplicitare tutte le assunzioni che facciamo sulla struttura del modello e sui suoi parametri. Allo stesso tempo, i priors sono spesso oggetto di critica nell’inferenza bayesiana a causa della soggettività che possono introdurre.\nTuttavia, l’inferenza bayesiana offre alcuni vantaggi meno evidenti a prima vista, tra cui:\n\nla capacità di lavorare efficacemente con piccoli set di dati,\nla capacità di eseguire la regolarizzazione del modello.\n\nQuesti aspetti rendono l’approccio bayesiano particolarmente utile in situazioni in cui i dati sono scarsi o le assunzioni esplicite sul modello possono contribuire a migliorare le previsioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#inferenza-predittiva",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#inferenza-predittiva",
    "title": "41  Inferenza bayesiana",
    "section": "41.3 Inferenza Predittiva",
    "text": "41.3 Inferenza Predittiva\nLa distribuzione a posteriori dei parametri può essere utilizzata per modellare l’incertezza nelle previsioni \\(\\tilde{y}\\) relative a nuove osservazioni. La distribuzione predittiva a posteriori di \\(\\tilde{y}\\) si ottiene marginalizzando la distribuzione congiunta delle previsioni \\(\\tilde{y}\\) e dei parametri \\(\\theta\\) rispetto ai parametri del modello:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y}, \\theta \\mid y)d \\theta = \\int p(\\tilde{y} \\mid \\theta, y)p(\\theta|y)d\\theta.\n\\]\nIn questo modo, la distribuzione predittiva può essere vista come una media delle previsioni del modello \\(p(\\tilde{y} \\mid \\theta, y)\\) ponderata sulla distribuzione a posteriori dei parametri del modello \\(p(\\theta \\mid y)\\). Questo consente di incorporare l’incertezza sui parametri nel processo di previsione, rendendo le stime più robuste.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#come-possiamo-eseguire-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#come-possiamo-eseguire-linferenza-bayesiana",
    "title": "41  Inferenza bayesiana",
    "section": "41.4 Come possiamo eseguire l’inferenza bayesiana?",
    "text": "41.4 Come possiamo eseguire l’inferenza bayesiana?\nEsistono due approcci principali per determinare la distribuzione posteriore:\n\nApproccio Analitico (o Coniugato): Questo metodo è applicabile quando la distribuzione a priori scelta e la funzione di verosimiglianza appartengono alla stessa famiglia di distribuzioni, definite coniugate. In questi casi, la distribuzione posteriore può essere calcolata analiticamente, ovvero attraverso formule matematiche esatte. L’approccio coniugato è computazionalmente efficiente ma presenta una limitazione significativa: è applicabile solo in situazioni in cui si può assumere una coniugazione tra la distribuzione a priori e la verosimiglianza. Di conseguenza, trova un impiego limitato nelle analisi di dati reali, dove spesso le assunzioni di coniugazione risultano troppo restrittive.\nApproccio Numerico: Quando non è possibile ottenere una forma analitica chiusa per la distribuzione posteriore, a causa della complessità del modello o della mancanza di coniugazione tra la distribuzione a priori e la verosimiglianza, si ricorre a metodi numerici. Questi algoritmi consentono di ottenere una stima approssimata, ma spesso accurata, della distribuzione posteriore.\n\n\n41.4.1 Metodi Numerici\nLe catene di Markov Monte Carlo (MCMC) sono una classe di algoritmi ampiamente utilizzati in questo contesto. Essi costruiscono una catena di Markov che converge alla distribuzione posteriore desiderata. Tra i metodi MCMC più comuni troviamo:\n\nMetropolis-Hastings: Un algoritmo generale che consente di campionare da una vasta gamma di distribuzioni posteriori.\nGibbs Sampling: Un caso particolare di Metropolis-Hastings, particolarmente efficiente quando la distribuzione congiunta è difficile da campionare direttamente, ma le distribuzioni condizionali sono note.\n\nOltre alle MCMC, esistono altre tecniche numeriche:\n\nVariational Bayes: Questo approccio consiste nel trovare la distribuzione \\(q(z)\\) che meglio approssima la distribuzione posteriore \\(p(z \\mid x)\\), secondo un criterio di divergenza (ad esempio, la divergenza di Kullback-Leibler). L’obiettivo è trasformare il problema di inferenza esatta in un problema di ottimizzazione. Variational Bayes offre spesso una soluzione più veloce rispetto alle MCMC, ma l’approssimazione può essere meno accurata in alcuni casi.\nLaplace approximation: Questa tecnica consiste nell’approssimare la distribuzione posteriore con una distribuzione normale centrata sul massimo a posteriori (MAP) e con matrice di covarianza pari all’inverso della matrice di Hessiano negativa calcolata nel MAP. L’approssimazione di Laplace è computazionalmente efficiente, ma è valida solo localmente attorno al MAP e può portare a stime inaccurate della varianza posteriore.\n\nVantaggi:\n\nVersatilità: L’approccio numerico è applicabile a una vasta gamma di modelli e distribuzioni.\nFlessibilità: Consente di incorporare facilmente informazioni a priori complesse.\n\nSvantaggi:\n\nCosto computazionale: Può richiedere un tempo di calcolo considerevole, soprattutto per modelli complessi o grandi dataset.\nTuning: La scelta dei parametri degli algoritmi MCMC (ad esempio, la proposta iniziale) può influenzare la convergenza e l’efficienza del campionamento.\n\nIn sintesi, l’approccio numerico offre una soluzione generale e flessibile per l’inferenza bayesiana, ma richiede una maggiore attenzione alla scelta degli algoritmi e alla valutazione della convergenza delle catene.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#programmazione-probabilistica",
    "title": "41  Inferenza bayesiana",
    "section": "41.5 Programmazione Probabilistica",
    "text": "41.5 Programmazione Probabilistica\nI linguaggi di programmazione probabilistica (PPL) rappresentano un’importante innovazione nella modellazione bayesiana, facilitando l’uso di tecniche di approssimazione numerica per stimare le distribuzioni posteriori. Grazie ai PPL, la modellizzazione probabilistica diventa più accessibile, riducendo le barriere tecniche e computazionali. Questi strumenti consentono di definire modelli in modo dichiarativo, descrivendo le relazioni tra le variabili in termini probabilistici senza doversi occupare dei dettagli algoritmici sottostanti. In altre parole, i PPL permettono ai ricercatori di concentrarsi sull’espressione del modello, lasciando ai linguaggi il compito di gestire l’implementazione computazionale.\nTra i PPL più utilizzati troviamo:\n\nStan: Uno dei linguaggi più popolari, noto per la sua efficienza e flessibilità.\nPyMC: Molto utilizzato nell’ecosistema Python, offre un’interfaccia user-friendly per la modellazione bayesiana.\nTensorFlow: Un framework che combina un approccio probabilistico con le reti neurali.\n\n\n41.5.1 Vantaggi della Programmazione Probabilistica in Psicologia\nLa programmazione probabilistica offre numerosi vantaggi per la ricerca psicologica, in particolare per l’analisi di processi complessi come l’apprendimento, le emozioni e il comportamento. Alcuni dei principali vantaggi includono:\n\nFlessibilità: I PPL, come Stan, Pyro, Numpyro, PyMC e Turing.jl, offrono un quadro flessibile per la definizione e la personalizzazione dei modelli probabilistici. In psicologia, questa flessibilità è cruciale, poiché i modelli devono adattarsi a una vasta gamma di processi mentali e comportamentali che variano tra individui e contesti.\nQuantificazione dell’Incertezza: La programmazione probabilistica permette di rappresentare esplicitamente e quantificare l’incertezza, un aspetto fondamentale in psicologia, dove molte variabili di interesse, come stati emotivi o atteggiamenti, sono latenti e soggette a incertezza. Incorporare questa incertezza nei modelli consente di ottenere stime più realistiche e affidabili.\nValidazione del Modello: I PPL facilitano la validazione dei modelli psicologici, consentendo ai ricercatori di confrontare le previsioni dei modelli con i dati osservati. Tecniche come i posterior predictive checks permettono di valutare la qualità e l’affidabilità del modello, contribuendo a una maggiore solidità delle conclusioni.\nModellazione Gerarchica: Molti studi psicologici raccolgono dati a più livelli (ad esempio, misurazioni ripetute per individuo, sessioni sperimentali, contesti diversi). I PPL semplificano la costruzione e l’analisi di modelli gerarchici, catturando la variabilità sia intra- che inter-individuale.\nSelezione e Confronto dei Modelli: In psicologia è spesso necessario confrontare modelli con strutture diverse o ipotesi alternative. I PPL permettono di confrontare le capacità predittive dei modelli in modo sistematico e rigoroso, supportando la scelta del modello più adatto basandosi sull’accuratezza predittiva e non solo sulla complessità.\nComunicazione Trasparente: La programmazione probabilistica favorisce la trasparenza nella modellizzazione. I ricercatori possono specificare chiaramente le assunzioni del modello, i prior e le funzioni di verosimiglianza, rendendo più facile la comunicazione e la collaborazione con altri esperti.\nLibrerie Estensibili: I PPL offrono librerie estese e strumenti avanzati per lo sviluppo di modelli, l’inferenza e la visualizzazione. Questo riduce il carico computazionale e di implementazione, rendendo più agevole l’analisi di dati complessi tipici della psicologia sperimentale e clinica.\n\n\n\n41.5.2 Come Funzionano i PPL?\nI linguaggi di programmazione probabilistica richiedono semplicemente la descrizione del modello probabilistico. Successivamente, utilizzano algoritmi di inferenza, come le catene di Markov Monte Carlo (MCMC) o l’inferenza variazionale, per stimare la distribuzione posteriore delle variabili di interesse. Ciò consente ai ricercatori di ottenere stime delle variabili sconosciute e di valutare l’incertezza associata.\nIn conclusione, i linguaggi di programmazione probabilistica hanno trasformato il modo in cui affrontiamo l’inferenza bayesiana, rendendola più accessibile e potente. Grazie alla loro semplicità d’uso e alla potenza computazionale, i PPL hanno reso l’inferenza bayesiana uno strumento sempre più diffuso in molte discipline, inclusa la psicologia. Questo approccio facilita la modellazione di fenomeni complessi e l’analisi rigorosa di dati, offrendo un metodo efficace per rispondere a domande di ricerca psicologica in modo trasparente e accurato.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#notazione",
    "title": "41  Inferenza bayesiana",
    "section": "41.6 Notazione",
    "text": "41.6 Notazione\nIn seguito, utilizzeremo \\(y\\) per rappresentare i dati osservati e \\(\\theta\\) per indicare i parametri sconosciuti di un modello statistico. Entrambi, \\(y\\) e \\(\\theta\\), saranno trattati come variabili casuali. Utilizzeremo \\(x\\) per denotare le quantità note, come i predittori di un modello lineare.\nÈ comune scrivere modelli statistici utilizzando la seguente notazione:\n\\[\n\\begin{aligned}\ny & \\sim \\mathrm{normal}(\\mu, \\sigma) \\\\\n\\mu & \\sim \\mathrm{normal}(0, 10) \\\\\n\\sigma & \\sim \\mathrm{normal}^+(\\sigma \\mid  0, 1),\n\\end{aligned}\n\\]\ndove il simbolo \\(\\sim\\) è chiamato tilde (\\sim in LaTeX).\nIn generale, possiamo leggere \\(\\sim\\) come “è distribuito come”, e questa notazione è usata come una scorciatoia per definire distribuzioni. L’esempio sopra può essere scritto anche come:\n\\[\n\\begin{aligned}\n   p(y \\mid \\mu, \\sigma) & = \\mathrm{normal}(y \\mid  \\mu, \\sigma)\\\\\n   p(\\mu) & = \\mathrm{normal}(\\mu \\mid 0, 10)\\\\\n   p(\\sigma) & = \\mathrm{normal}^+(\\sigma \\mid  0, 1).\n\\end{aligned}\n\\]",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#addendum-la-verosimiglianza-marginale",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#addendum-la-verosimiglianza-marginale",
    "title": "41  Inferenza bayesiana",
    "section": "41.7 Addendum: La Verosimiglianza Marginale",
    "text": "41.7 Addendum: La Verosimiglianza Marginale\nNella discussione precedente, abbiamo introdotto la verosimiglianza marginale \\(p(y)\\) come una costante di normalizzazione. Ma perché è così importante normalizzare la distribuzione posteriore? La verosimiglianza marginale rappresenta la probabilità dei dati osservati, integrata su tutti i possibili valori del parametro \\(\\theta\\). In altre parole, esprime la probabilità di osservare i dati senza fare riferimento a un particolare valore del parametro.\nPer comprendere intuitivamente, immagina di voler stimare la temperatura media di una stanza. Usando un termometro, ottieni una misurazione, ma sei consapevole che variabili come la posizione del termometro o l’ora del giorno potrebbero influenzare la lettura. La verosimiglianza marginale è equivalente a considerare la probabilità di ottenere una certa misurazione, prendendo in considerazione tutte queste possibili variabili.\nSenza la normalizzazione, la somma delle probabilità assegnate ai diversi valori del parametro non sarebbe uguale a 1, il che significherebbe che non avremmo una distribuzione di probabilità valida. Questo renderebbe difficile interpretare correttamente i risultati. La verosimiglianza marginale agisce come una costante di normalizzazione, garantendo che l’area sotto la curva della distribuzione posteriore sia esattamente pari a 1, come richiesto da una distribuzione di probabilità.\nLa verosimiglianza marginale si calcola integrando (o sommando, nel caso di parametri discreti) la funzione di verosimiglianza rispetto a tutti i possibili valori del parametro, pesando ciascun valore con la sua probabilità a priori.\nConsideriamo un esempio con una variabile casuale binomiale \\(Y\\), la cui funzione di massa di probabilità (PMF) \\(p(Y)\\) dipende dal parametro \\(\\theta\\). Supponiamo che \\(\\theta\\) possa assumere uno tra tre valori specifici: 0.1, 0.5 o 0.9, ciascuno con una probabilità a priori di \\(\\frac{1}{3}\\).\nSe i dati indicano \\(n = 10\\) prove e \\(k = 7\\) successi, la funzione di verosimiglianza è data da:\n\\[\np(k = 7, n = 10 \\mid \\theta) = \\binom{10}{7} \\theta^7 (1 - \\theta)^3.\n\\]\nPer calcolare la verosimiglianza marginale \\(p(k = 7, n = 10)\\), marginalizziamo su \\(\\theta\\), valutando la verosimiglianza per ciascun valore di \\(\\theta\\), moltiplicando per la probabilità a priori di ciascun \\(\\theta\\), e sommando i risultati:\n\\[\np(k = 7, n = 10) = \\sum_{i=1}^{3} p(k = 7, n = 10 \\mid \\theta_i) \\cdot p(\\theta_i).\n\\]\nSostituendo i valori di \\(\\theta\\) e le probabilità corrispondenti:\n\\[\np(k = 7, n = 10) = \\frac{1}{3} \\binom{10}{7} 0.1^7 (1 - 0.1)^3 + \\frac{1}{3} \\binom{10}{7} 0.5^7 (1 - 0.5)^3 + \\frac{1}{3} \\binom{10}{7} 0.9^7 (1 - 0.9)^3.\n\\]\nQuesto calcolo dimostra come la marginalizzazione su \\(\\theta\\) incorpori tutte le sue possibili variazioni, ottenendo una stima complessiva che tiene conto dell’incertezza su \\(\\theta\\).\n\n41.7.1 Implementazione in Python\nPer implementare questo calcolo in Python, possiamo definire una funzione per calcolare la verosimiglianza per i valori discreti di \\(\\theta\\) e poi sommare i risultati. Se invece i parametri sono continui, possiamo usare la libreria scipy per eseguire l’integrazione numerica.\nEcco un esempio di codice Python per il calcolo della verosimiglianza marginale nel caso discreto:\n\ndef likelihood_binomial(theta, k, n):\n    return sp.comb(n, k) * (theta**k) * ((1 - theta) ** (n - k))\n\n\n# Valori di theta e probabilità a priori\ntheta_values = [0.1, 0.5, 0.9]\nprior = 1 / 3  # Probabilità a priori per ciascun theta\nk = 7\nn = 10\n\n# Calcolo della verosimiglianza marginale\nmarginal_likelihood_discrete = sum(\n    prior * likelihood_binomial(theta, k, n) for theta in theta_values\n)\n\nprint(f\"Likelihood Marginale (discreta): {marginal_likelihood_discrete}\")\n\nLikelihood Marginale (discreta): 0.05819729199999999\n\n\nPer l’integrazione continua, si può utilizzare scipy.integrate.quad:\n\n# Likelihood marginale su un intervallo continuo [0, 1]\nmarginal_likelihood_continuous, _ = quad(\n    lambda theta: likelihood_binomial(theta, k, n), 0, 1\n)\n\nprint(f\"Likelihood Marginale (continua): {marginal_likelihood_continuous}\")\n\nLikelihood Marginale (continua): 0.09090909090909091\n\n\nNel codice precedente, utilizzando l’integrazione continua con quad, si calcola la verosimiglianza marginale integrando la funzione di verosimiglianza \\(p(k \\mid \\theta)\\) rispetto a \\(\\theta\\) su quell’intervallo. In questo modo, implicitamente, si sta usando una distribuzione a priori uniforme su \\([0, 1]\\). Questo perché la verosimiglianza non è stata moltiplicata per una funzione di densità a priori, quindi il peso che si assegna a ciascun valore di \\(\\theta\\) è lo stesso in tutto l’intervallo. La distribuzione uniforme assegna uguale probabilità a tutti i valori di \\(\\theta\\) tra 0 e 1, quindi si sta trattando \\(\\theta\\) come se provenisse da una distribuzione uniforme \\(\\theta \\sim \\text{Uniform}(0, 1)\\).\nSe si desidera utilizzare una distribuzione a priori diversa (ad esempio, una Beta), è necessario moltiplicare la verosimiglianza per la densità di probabilità della distribuzione a priori prima di integrare. Ecco un esempio con una distribuzione Beta come prior:\n\n# Definisci la distribuzione a priori come Beta(alpha, beta)\nalpha_prior = 2\nbeta_prior = 2\n\n# Likelihood marginale con prior Beta\nmarginal_likelihood_continuous_beta, _ = quad(\n    lambda theta: likelihood_binomial(theta, k, n)\n    * beta.pdf(theta, alpha_prior, beta_prior),\n    0,\n    1,\n)\n\nprint(f\"Likelihood Marginale con prior Beta: {marginal_likelihood_continuous_beta}\")\n\nLikelihood Marginale con prior Beta: 0.1118881118881119\n\n\nIn questo caso, il prior è una Beta(2,2), che dà più peso ai valori di \\(\\theta\\) vicini a 0.5, riflettendo una distribuzione a priori che preferisce valori intermedi di \\(\\theta\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#riflessioni-conclusive",
    "title": "41  Inferenza bayesiana",
    "section": "41.8 Riflessioni Conclusive",
    "text": "41.8 Riflessioni Conclusive\nAl cuore della ricerca scientifica c’è una domanda del tipo: “dimmi qualcosa sulla variabile \\(\\theta\\) dato che ho osservato i dati \\(D\\) e ho una certa conoscenza del meccanismo sottostante che genera i dati”. La regola di Bayes fornisce la seguente risposta:\n\\[\np(\\theta \\mid D) = \\frac{p(D \\mid\\theta) p(\\theta)}{p(D)} = \\frac{p(D \\mid \\theta) p(\\theta)}{\\int_\\theta p(D \\mid\\theta) p(\\theta) d\\theta}.\n\\]\nQuesta equazione mostra come, partendo da un modello generativo \\(p(D \\mid\\theta)\\) dei dati osservati e abbinato a una credenza a priori \\(p(\\theta)\\) su quali valori della variabile \\(\\theta\\) siano plausibili, possiamo inferire la distribuzione a posteriori \\(p(\\theta \\mid D)\\) della variabile alla luce dei dati osservati.\nLa stima MAP (Massimo A Posteriori), che corrisponde al valore di \\(\\theta\\) che massimizza la distribuzione a posteriori, rappresenta una stima puntuale del parametro:\n\\[\n\\theta^* = \\arg \\max_\\theta p(\\theta \\mid D).\n\\]\nNel caso di un prior non informativo (piatto), la stima MAP coincide con la stima di massima verosimiglianza, ovvero il valore di \\(\\theta\\) che massimizza la probabilità che il modello generi i dati osservati.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/02_bayesian_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "41  Inferenza bayesiana",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Sat Oct 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.14.0\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html",
    "href": "chapters/bayesian_inference/03_subj_prop.html",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Introduzione\nL’inferenza bayesiana è un metodo di inferenza statistica che utilizza la probabilità per aggiornare le credenze sui parametri di un modello, sulla base di nuove evidenze o dati osservati. Essa fornisce un quadro concettuale per stimare variabili sconosciute, tenendo conto dell’incertezza. Attraverso un modello che descrive le dipendenze tra variabili aleatorie, la teoria della probabilità può essere impiegata per inferire tutte le quantità sconosciute. In questo approccio, tutte le incertezze, sia nelle osservazioni che nei parametri del modello, sono trattate come distribuzioni di probabilità.\nIn sintesi, l’inferenza bayesiana è il processo di deduzione delle proprietà di una distribuzione di probabilità a partire dai dati, utilizzando il teorema di Bayes. Questo processo incorpora l’idea che la probabilità rappresenti una misura della fiducia su una previsione o un risultato.\nQuesto capitolo ha lo scopo di esplorare in dettaglio il concetto di aggiornamento bayesiano, illustrandolo con un esempio concreto in un contesto semplificato. L’obiettivo è dimostrare come le credenze preesistenti sulla probabilità di un parametro \\(\\theta\\) possano essere aggiornate attraverso l’osservazione di nuovi dati.\nIl primo passo nell’inferenza bayesiana consiste nel rappresentare le credenze iniziali, formulate prima di raccogliere i dati, tramite una distribuzione a priori. La distribuzione a priori riflette le nostre conoscenze o ipotesi preesistenti su \\(\\theta\\) e può variare in base al contesto o alle informazioni pregresse disponibili.\nUna volta ottenuti nuovi dati, il passaggio successivo è l’aggiornamento delle credenze tramite la distribuzione a posteriori. Questo aggiornamento si ottiene moltiplicando la distribuzione a priori per la verosimiglianza dei dati osservati, il che riflette quanto i dati supportino un determinato valore di \\(\\theta\\). Il prodotto di questi due termini fornisce una misura delle credenze aggiornate, che viene successivamente normalizzata per garantire che il risultato sia una distribuzione di probabilità valida (ovvero, che l’area sotto la curva sia pari a 1).\nIl capitolo si concentra sul modello binomiale. Questo modello è utilizzato per stimare una proporzione sconosciuta basata su una serie di dati binari \\(y_1, \\ldots, y_n\\), ciascuno dei quali può assumere valore 0 o 1.\nInizieremo esplorando un esempio in cui la distribuzione a priori di \\(\\theta\\) è discreta, un caso in cui i valori possibili di \\(\\theta\\) sono limitati a un insieme finito di opzioni. Successivamente, discuteremo scenari in cui la distribuzione a priori è continua, ampliando il modello per affrontare casi più complessi e realistici. Questo approccio progressivo consente di acquisire una comprensione graduale dei concetti centrali dell’inferenza bayesiana e del loro utilizzo pratico nel contesto di problemi statistici reali.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "href": "chapters/bayesian_inference/03_subj_prop.html#introduzione",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "L’unica cosa rilevante è l’incertezza – il grado della nostra conoscenza e ignoranza. Il fatto che gli eventi considerati siano in qualche modo determinati, o conosciuti da altre persone, non ha alcuna importanza.\n(Bruno deFinetti)",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#verosimiglianza-binomiale",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.1 Verosimiglianza Binomiale",
    "text": "42.1 Verosimiglianza Binomiale\nLa distribuzione binomiale offre un modello naturale per dati che derivano da una sequenza di \\(n\\) prove indipendenti e identicamente distribuite, dove ciascuna prova dà origine a uno dei due possibili esiti, convenzionalmente etichettati come ‘successo’ e ‘fallimento’. Grazie al fatto che le prove sono iid, i dati possono essere riassunti dal numero totale di successi nelle \\(n\\) prove, che denotiamo con \\(y\\). Il parametro \\(\\theta\\) rappresenta la proporzione di successi nella popolazione o, equivalentemente, la probabilità di successo in ciascuna prova. Il modello di campionamento binomiale è:\n\\[ p(y|\\theta) = \\text{Bin}(y|n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n-y}, \\]\ndove nella parte sinistra dell’equazione non si indica la dipendenza da \\(n\\) perché viene considerato parte del disegno sperimentale e fissato; tutte le probabilità discusse per questo problema sono considerate condizionate su \\(n\\), cioè assumono che il numero totale di prove sia fissato e noto.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "href": "chapters/bayesian_inference/03_subj_prop.html#applicazione-specifica-del-modello-binomiale",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.2 Applicazione Specifica del Modello Binomiale",
    "text": "42.2 Applicazione Specifica del Modello Binomiale\nIn questo capitolo, esaminiamo un’applicazione specifica del modello binomiale per valutare la prestazione di un partecipante in un classico esperimento di psicologia, noto come Go/No-Go task (Shiffrin & Schneider, 1977). In questo tipo di compito, ai partecipanti viene richiesto di rispondere a determinati stimoli (prove Go) e di trattenere la risposta ad altri stimoli (prove No-Go). Ad esempio, i partecipanti possono vedere una serie di lettere presentate su uno schermo e devono premere un pulsante quando vedono qualsiasi lettera tranne una specifica lettera bersaglio (ad esempio, la lettera “X”). In questo esperimento, ogni prova rappresenta un evento di tipo bernoulliano con due possibili esiti: o il partecipante risponde correttamente o commette un errore. I ricercatori analizzano la percentuale di risposte corrette e di inibizioni, concentrandosi in particolare sulla capacità del partecipante di controllare l’impulso di rispondere durante le prove No-Go.\nConsideriamo un piccolo numero di prove No-Go di un partecipante, dove i risultati sono: 1, 0, 1, 1, 1, 0, 1, 0, 1. Qui, il valore “1” indica che il partecipante è stato in grado di inibire la risposta, mentre “0” indica che non è riuscito a farlo. L’obiettivo dell’analisi è quantificare l’incertezza nella stima di \\(\\theta\\), che rappresenta la proporzione di risposte corrette nel compito No-Go, ovvero la capacità inibitoria del partecipante.\nConsideriamo questi dati come una sequenza di 9 prove bernoulliane indipendenti. Utilizzando il modello binomiale, stimiamo la probabilità \\(\\theta\\) che il partecipante riesca a controllare il proprio impulso di rispondere durante le prove No-Go e quantifichiamo l’incertezza associata a questa stima.\n\n42.2.1 Processo di Lavoro\nMcElreath (2020) descrive il flusso lavoro bayesiano nel modo seguente.\n\nDefinire un Modello Generativo per i Dati: Un modello generativo descrive il processo attraverso il quale i dati vengono prodotti. Nel contesto del compito No-Go, consideriamo ogni prova come un processo di Bernoulli con due possibili esiti: una prestazione corretta, ovvero l’inibizione della risposta (rappresentata da 1), oppure una prestazione errata, ovvero la mancata inibizione della risposta (rappresentata da 0). Definiamo \\(\\theta\\) come la probabilità di ottenere una prestazione corretta nel compito No-Go. Il modello generativo per questi dati può essere formalizzato come:\n\\[\nX_i \\sim \\text{Bernoulli}(\\theta),\n\\]\ndove \\(i = 1, 2, \\dots, 9\\) e \\(X_i\\) assume il valore 1 in caso di prestazione corretta e 0 in caso di prestazione errata nel compito No-Go.\nDefinire uno Stimatore per il Parametro di Interesse: Uno stimatore è una regola o una formula che utilizza i dati campionari per fornire una stima del parametro di interesse. Nel nostro caso, lo stimatore di interesse è la probabilità \\(\\theta\\) di inibire correttamente la risposta durante le prove No-Go. L’obiettivo è non solo calcolare questa probabilità, ma anche quantificare l’incertezza associata alla stima di \\(\\theta\\), basandoci sui dati raccolti.\nSviluppare un Metodo Statistico per la Stima del Parametro di Interesse: Per stimare \\(\\theta\\), utilizziamo l’approccio bayesiano. In statistica bayesiana, si parte da una distribuzione a priori che rappresenta le nostre convinzioni iniziali su \\(\\theta\\), e poi si aggiorna questa distribuzione alla luce dei dati osservati per ottenere una distribuzione a posteriori. Nel contesto di un modello Bernoulli/Binomiale, una scelta comune per la distribuzione a priori è la distribuzione Beta. In questo caso, iniziamo con una distribuzione a priori non informativa, \\(\\text{Beta}(1, 1)\\), che corrisponde a una distribuzione uniforme su \\(\\theta\\).\nLa verosimiglianza dei nostri dati (6 “successi”, 3 “insuccessi”) è data dalla distribuzione binomiale:\n\\[\nL(p) = {9 \\choose 6} \\theta^{6} (1-\\theta)^{3}.\n\\]\nUtilizziamo il teorema di Bayes per combinare priori e verosimiglianza e ottenere la distribuzione a posteriori:\n\\[\n\\text{Posteriore} \\propto \\text{Verosimiglianza} \\times \\text{Priori}\n\\]\nValidazione del Modello tramite Simulazioni:\nPrima di analizzare i dati reali, eseguiamo una simulazione predittiva a priori per verificare se il modello è in grado di generare dati plausibili. Successivamente, dopo aver adattato il modello ai dati osservati, conduciamo una simulazione predittiva a posteriori per valutare la capacità del modello di riprodurre dati simili a quelli effettivamente osservati.\nAnalisi e Sintesi dei Risultati:\nInfine, analizziamo i dati reali calcolando la distribuzione a posteriori, tipicamente tramite metodi computazionali come il Monte Carlo a catene di Markov (MCMC). Riassumiamo questa distribuzione per fare inferenze su \\(\\theta\\), utilizzando statistiche descrittive come la media, la mediana e gli intervalli di credibilità.\n\nNel corso di questo capitolo, illustreremo come generare numericamente la distribuzione a posteriori, mentre nei capitoli successivi approfondiremo ulteriormente le varie fasi del flusso di lavoro proposto da McElreath (2020).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia-nellaggiornamento-bayesiano",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.3 Metodo Basato su Griglia nell’Aggiornamento Bayesiano",
    "text": "42.3 Metodo Basato su Griglia nell’Aggiornamento Bayesiano\nDopo aver discusso l’aggiornamento bayesiano e come permette di raffinare le nostre convinzioni preesistenti alla luce di nuove evidenze, esploreremo ora una tecnica specifica per realizzare questo aggiornamento: il metodo basato su griglia.\nIl metodo basato su griglia è un approccio semplice e intuitivo per stimare la distribuzione a posteriori, particolarmente utile quando non sono disponibili soluzioni analitiche esatte o si desidera evitare l’uso di algoritmi computazionali complessi. La procedura si articola nei seguenti passi:\n\nSelezione di un intervallo per il parametro: Basandosi sulle convinzioni a priori, si definisce un intervallo ragionevole per il parametro di interesse.\nCreazione di una griglia di punti: Su questo intervallo, si distribuiscono una serie di punti, di solito equidistanti tra loro.\nCalcolo della posteriori per ogni punto: Per ogni punto della griglia, si moltiplica la verosimiglianza per il prior corrispondente.\nNormalizzazione dei risultati: Per garantire che la somma delle probabilità sia pari a 1, si normalizzano i valori ottenuti dividendo ciascun punto per l’area totale sottesa dalla curva della distribuzione a posteriori.\n\nAttraverso questo metodo, si ottiene una rappresentazione approssimativa ma illustrativa della distribuzione a posteriori. Questo approccio offre un modo accessibile per visualizzare e comprendere il processo di aggiornamento bayesiano.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-discreta",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta",
    "text": "42.4 Aggiornamento Bayesiano con una Distribuzione a Priori Discreta\n\n42.4.1 Distribuzione a priori\nQuando non disponiamo di informazioni specifiche preliminari su \\(\\theta\\), potremmo inizialmente assegnare un valore di 0.5, suggerendo una probabilità a priori uniforme tra le due alternative (la capacità di inibire la risposta e la mancanza di questa capacità in una prova del compito Go/No-Go). Tuttavia, questo valore non rappresenta adeguatamente l’intero spettro della nostra incertezza iniziale.\nPer riflettere meglio questa incertezza, utilizziamo una distribuzione a priori discreta, che assegna una probabilità distinta a ciascun valore plausibile di \\(\\theta\\). Questo approccio ci permette di quantificare le nostre convinzioni preliminari sulla distribuzione di questi valori.\nSupponiamo di considerare undici possibili valori per \\(\\theta\\), che variano da 0 a 1 con incrementi di 0.1. Possiamo attribuire a ciascun valore una probabilità a priori uguale, creando così una distribuzione uniforme, oppure scegliere una distribuzione non uniforme che meglio rifletta le nostre aspettative sui valori di \\(\\theta\\) più probabili.\nDopo aver osservato i dati — nel nostro caso, 6 successi in 9 prove — applichiamo il teorema di Bayes per trasformare la distribuzione a priori in una distribuzione a posteriori. Questo processo consiste nel combinare la probabilità a priori di \\(\\theta\\) con la verosimiglianza dei dati per produrre una probabilità a posteriori aggiornata per \\(\\theta\\).\nLa distribuzione a posteriori integra quindi le nostre conoscenze pregresse con le nuove informazioni ottenute dalle osservazioni, offrendoci una visione aggiornata e quantitativamente informata del parametro \\(\\theta\\). Attraverso questo esempio, possiamo osservare un approccio sistematico ed efficace per affinare le nostre credenze alla luce di nuove prove.\n\ntheta = np.linspace(0, 1, 11)\nprint(theta)\n\n[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n\n\nNel caso in cui non vi siano motivi fondati per assegnare probabilità diverse ai vari valori di \\(\\theta\\), è possibile attribuire la stessa probabilità a ciascun valore, creando così una distribuzione uniforme. È importante prestare attenzione alla seconda riga di codice, che esegue una standardizzazione. Poiché unif_discr_pdf è un vettore composto da un numero finito di elementi, questi elementi devono essere considerati come probabilità, e tali probabilità devono obbligatoriamente sommarsi a uno.\n\nunif_prior = stats.uniform.pdf(theta) \nunif_prior = unif_prior / np.sum(unif_prior)\nprint(unif_prior)\n\n[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n\n\n\nnp.sum(unif_prior)\n\n1.0\n\n\nUna rappresentazione visiva di questa distribuzione di massa di probabilità si ottiene nel modo seguente.\n\nplt.stem(theta, unif_prior, markerfmt=\" \")\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilità\");\n\n\n\n\n\n\n\n\nSe, al contrario, riteniamo che i valori centrali nella distribuzione di \\(\\theta\\) siano più credibili rispetto a quelli situati agli estremi, potremmo esprimere questa opinione soggettiva mediante la seguente distribuzione di massa di probabilità.\n\nnot_unif_prior = [0, 0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05]\nplt.stem(theta, not_unif_prior, markerfmt=\" \")\nplt.title(\"Distribuzione a priori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"Probabilità\");\n\n\n\n\n\n\n\n\nLa prima distribuzione di probabilità è una distribuzione discreta uniforme, in quanto assegna la stessa probabilità a ciascun elemento dell’insieme discreto su cui è definita, ossia i valori \\(\\{0, 0.1, 0.2, \\dots, 1.0\\}\\). La seconda distribuzione di probabilità, pur essendo discreta, segue un andamento non uniforme: si presume che \\(\\theta\\) abbia una probabilità maggiore di assumere un valore nell’insieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) rispetto all’insieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\).\nLe credenze iniziali riguardo ai possibili valori di \\(\\theta\\) costituiscono la “distribuzione a priori”. L’inferenza bayesiana aggiorna queste credenze iniziali utilizzando le informazioni ottenute dai dati. Queste informazioni vengono combinate con le credenze iniziali su \\(\\theta\\) attraverso l’applicazione del teorema di Bayes, allo scopo di ottenere la “distribuzione a posteriori”. Quest’ultima rappresenta le nostre credenze aggiornate sui possibili valori di \\(\\theta\\) dopo l’osservazione dei dati.\nAbbiamo osservato 6 successi in 9 prove. Per calcolare la distribuzione a posteriori, utilizzeremo la seconda delle due distribuzioni a priori precedentemente descritte. In base al teorema di Bayes, la distribuzione a posteriori si ottiene moltiplicando la verosimiglianza per la distribuzione a priori e quindi dividendo per una costante di normalizzazione (la verosimiglianza marginale):\n\\[ p(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}. \\]\n\n\n42.4.2 Verosimiglianza\nPer calcolare la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), è essenziale comprendere il processo attraverso il quale i dati sono stati generati. Nel nostro caso, i dati rappresentano i risultati di 9 ripetizioni di un esperimento casuale, in cui ciascuna prova può avere solo due esiti possibili: risposta corretta (inibizione della risposta nelle prove No-Go) o risposta scorretta (mancata inibizione della risposta nelle prove No-Go). Inoltre, assumiamo che le 9 prove siano indipendenti tra loro, cioè che la prestazione in una prova non influenzi quella nelle prove successive. Date queste condizioni, possiamo modellare il processo generativo dei dati utilizzando un modello binomiale con una probabilità sconosciuta \\(\\theta\\).\nUtilizzando Python, è possibile calcolare la funzione di verosimiglianza tramite la funzione binom.pmf().\n\nlike = stats.binom.pmf(6, 9, theta)\nlike = like / np.sum(like)\nlike\n\narray([0.00000000e+00, 6.11961968e-05, 2.75072287e-03, 2.09902955e-02,\n       7.42695176e-02, 1.63955860e-01, 2.50659622e-01, 2.66654495e-01,\n       1.76046264e-01, 4.46120274e-02, 0.00000000e+00])\n\n\nPer i 10 valori \\(\\theta\\) considerati, la funzione di verosimiglianza (normalizzata) assume la forma indicata dalla figura seguente.\n\nplt.stem(theta, like, markerfmt=\" \")\nplt.title(\"Funzione di verosimiglianza\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(\"$L(\\\\theta)$\");\n\n\n\n\n\n\n\n\nPer calcolare la distribuzione a posteriori, eseguiamo una moltiplicazione elemento per elemento tra il vettore contenente i valori della distribuzione a priori e il vettore contenente i valori della funzione di verosimiglianza. Usando Python, il risultato si trova nel modo seguente.\n\nnot_unif_prior * like\n\narray([0.00000000e+00, 3.05980984e-06, 1.37536144e-04, 1.04951477e-03,\n       1.29971656e-02, 2.86922755e-02, 4.38654338e-02, 4.66645366e-02,\n       8.80231320e-03, 2.23060137e-03, 0.00000000e+00])\n\n\nPer illustrare con un esempio, il valore dell’ottavo elemento della distribuzione a posteriori si calcola come segue (tenendo presente che in Python gli indici partono da 0):\n\nnot_unif_prior[7] * like[7]\n\n0.04666453655213576\n\n\nDopo questa moltiplicazione, otteniamo una distribuzione che rappresenta le probabilità condizionate dei possibili valori di \\(\\theta\\) alla luce dei dati osservati. Tuttavia, questa distribuzione potrebbe non è normalizzata, il che significa che la somma di tutte le probabilità condizionate non è uguale a 1.\nPer ottenere una distribuzione di probabilità correttamente normalizzata, dobbiamo dividere ciascun valore ottenuto precedentemente per la probabilità marginale dei dati \\(y\\). La probabilità marginale dei dati \\(y\\) è una costante di normalizzazione e può essere calcolata utilizzando la legge della probabilità totale (si veda l’eq. {eq}eq-prob-tot).\nPer chiarire, ricordiamo che, nel capitolo {ref}cond-prob-notebook abbiamo considerato il caso di una partizione dello spazio campione in due eventi mutualmente esclusivi ed esaustivi, \\(H_1\\) e \\(H_2\\). All’interno dello spazio campione abbiamo definito un evento \\(E\\) non nullo e abbiamo visto che \\(P(E) = P(E \\cap H_1) + P(E \\cap H_2)\\), ovvero \\(P(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2)\\). Usando la terminologia che stiamo usando qui, \\(P(E \\mid H_i)\\) corrisponde alla funzione di verosimiglianza e \\(P(H_i)\\) corrisponde alla funzione a priori. Nel caso discreto, come quello che stiamo considerando ora, il teorema della probabilità totale ci dice dunque che dobbiamo fare la somma dei prodotti tra i valori della funzione di verosimiglianza e i corrispondenti valori della distribuzione a priori.\n\nnp.sum(not_unif_prior * like)\n\n0.14444243675028887\n\n\nOtteniamo dunque il seguente risultato.\n\npost = (not_unif_prior * like) / np.sum(not_unif_prior * like)\nprint(post)\n\n[0.00000000e+00 2.11835933e-05 9.52186538e-04 7.26597251e-03\n 8.99816278e-02 1.98641591e-01 3.03687994e-01 3.23066667e-01\n 6.09399384e-02 1.54428395e-02 0.00000000e+00]\n\n\nVerifichiamo di avere ottenuto una distribuzione di massa di probabilità:\n\nnp.sum(post)\n\n0.9999999999999999\n\n\nEsaminiamo la distribuzione a posteriori di \\(\\theta\\) con un grafico.\n\nplt.stem(theta, post, markerfmt=\" \")\nplt.title(\"Distribuzione a posteriori\")\nplt.xlabel(\"$\\\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\");\n\n\n\n\n\n\n\n\nUna volta trovata la distribuzione a posteriori di \\(\\theta\\), possiamo calcolare altre quantità di interesse. Ad esempio, la moda a posteriori di \\(\\theta\\) può essere individuata direttamente dal grafico precedente e risulta pari a 0.5. Per calcolare invece la media a posteriori, ci avvaliamo della formula del valore atteso delle variabili casuali.\n\nnp.sum(theta * post)\n\n0.6086957633539818\n\n\nLa varianza della distribuzione a posteriori è\n\nnp.sum(theta**2 * post) - (np.sum(theta * post)) ** 2\n\n0.013379767754025107\n\n\nCon questo metodo, possiamo calcolare la distribuzione a posteriori di \\(\\theta\\) per qualsiasi distribuzione a priori discreta.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "href": "chapters/bayesian_inference/03_subj_prop.html#aggiornamento-bayesiano-con-una-distribuzione-a-priori-continua",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.5 Aggiornamento bayesiano con una distribuzione a priori continua",
    "text": "42.5 Aggiornamento bayesiano con una distribuzione a priori continua\nA fini didattici, abbiamo esaminato il caso di una distribuzione a priori discreta. Tuttavia, è importante notare che l’impiego di una distribuzione a priori continua, come la distribuzione Beta, risulta più appropriato in quanto permette di rappresentare un’ampia gamma di possibili valori per il parametro non noto \\(\\theta\\), senza essere vincolati a un insieme discreto di valori. Inoltre, la distribuzione Beta presenta l’ulteriore vantaggio di avere un dominio definito nell’intervallo [0, 1], che corrisponde alla gamma dei possibili valori per la proporzione \\(\\theta\\).\nPer esempio, consideriamo la distribuzione Beta(2, 2), caratterizzata da una simmetria nella sua forma. Per valutare la distribuzione Beta in corrispondenza di punti specifici, come ad esempio 0.5, 0.8 e 1.2, possiamo fare affidamento sulla funzione beta.pdf. A titolo illustrativo, la densità di probabilità della distribuzione Beta(2, 2) nel caso del valore 0.5 risulta essere 1.5, suggerendo che i valori di \\(\\theta\\) vicini a 0.5 appaiono più plausibili rispetto a quelli intorno a 0.8, dove la funzione assume un valore di 0.96. È importante sottolineare che la densità di probabilità della distribuzione Beta(2, 2) relativa al valore 1.2 è pari a 0, poiché tale valore esula dall’intervallo di definizione della distribuzione (0 e 1). La distribuzione Beta(2, 2) è illustrata nella figura qui di seguito.\n\nalpha = 2\nbeta = 2\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nSupponiamo – solo allo scopo di illustrare la procedura – che le nostre credenze a priori siano rappresentate da una Beta(2, 5).\n\nalpha = 2\nbeta = 5\n\nx = np.linspace(0, 1, 1000)\npdf = stats.beta.pdf(x, alpha, beta)\n\nplt.plot(x, pdf)\nplt.xlabel('x')\nplt.ylabel('Probability Density')\n_ = plt.title('Probability Density Function of Beta Distribution')\n\n\n\n\n\n\n\n\nNel seguente esempio, useremo la funzione beta.pdf() per generare una distribuzione a priori discretizzata.\n\nprint(stats.beta.pdf(theta, 2, 5))\n\n[0.     1.9683 2.4576 2.1609 1.5552 0.9375 0.4608 0.1701 0.0384 0.0027\n 0.    ]\n\n\n\n_ = plt.plot(theta, stats.beta.pdf(theta, 2, 5))\n\n\n\n\n\n\n\n\nOra però usiamo un numero maggiore di valori \\(\\theta\\).\n\ntheta = np.linspace(0, 1, 1001)\nprint(theta)\n\n[0.    0.001 0.002 ... 0.998 0.999 1.   ]\n\n\nCalcoliamo la distribuzione a priori normalizzata.\n\nprior = stats.beta.pdf(theta, 2, 5) \nprior = prior / np.sum(prior)\nprint(prior)\n\n[0.00000000e+00 2.98802546e-05 5.95215869e-05 ... 4.79041198e-13\n 2.99700749e-14 0.00000000e+00]\n\n\n\nsum(prior)\n\n1.0000000000000002\n\n\nPer calcolare la verosimiglianza, seguiamo la medesima procedura illustrata nel capitolo {ref}cap-likelihood. In aggiunta, effettuiamo la normalizzazione dei valori discretizzati della verosimiglianza, come precedentemente descritto.\n\nlike = stats.binom.pmf(6, 9, theta)\nlike = like / np.sum(like)\nprint(like)\n\n[0.00000000e+00 8.37482519e-19 5.34380847e-17 ... 6.63976213e-09\n 8.34972583e-10 0.00000000e+00]\n\n\nInfine, otteniamo la distribuzione a posteriori moltiplicando la distribuzione a priori per la verosimiglianza e dividendo per la costante di normalizzazione.\n\npost = (prior * like) / np.sum(prior * like)\n\n\nnp.sum(post)\n\n1.0\n\n\n\nplt.plot(theta, prior, linestyle=\"solid\", color=\"C0\", label=\"Prior\")\nplt.plot(theta, like, linestyle=\"solid\", color=\"C1\", label=\"Likelihood\")\nplt.plot(theta, post, linestyle=\"solid\", color=\"C4\", label=\"Posterior\")\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(r\"$f(\\theta)$\")\n_ = plt.legend()\n\n\n\n\n\n\n\n\nPossiamo calcolare la media e la deviazione standard della distribuzione a posteriori come abbiamo fatto in precedenza.\n\n# media\nnp.sum(theta * post)\n\n0.5000000000000001\n\n\n\n# deviazione standard\nnp.sqrt(np.sum(theta**2 * post) - (np.sum(theta * post)) ** 2)\n\n0.12126781251816628",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "href": "chapters/bayesian_inference/03_subj_prop.html#sintesi-ed-elaborazioni-inferenziali-sulla-distribuzione-a-posteriori",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori",
    "text": "42.6 Sintesi ed elaborazioni inferenziali sulla distribuzione a posteriori\nUna volta ottenuta la distribuzione a posteriori, è possibile generare un campione casuale da questa distribuzione. A titolo di esempio, possiamo estrarre un campione di 10000 punti dalla distribuzione a posteriori di \\(\\theta\\) che abbiamo calcolato.\n\nsamples = np.random.choice(theta, p=post, size=int(1e4), replace=True)\n\nL’istruzione precedente genera un array denominato samples contenente 10000 punti campionati dalla distribuzione a posteriori calcolata. La funzione np.random.choice viene impiegata per selezionare casualmente i valori theta basandosi sulle probabilità definite da post.\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n# Primo subplot: Scatter plot\naxs[0].plot(samples, \"o\", alpha=0.2, color=\"rebeccapurple\")\naxs[0].set_xlabel(\"Numero di campione\")\naxs[0].set_ylabel(r\"$\\theta$\")\naxs[0].set_title(\"Scatter Plot dei Campioni\")\n\n# Secondo subplot: KDE plot\naz.plot_kde(samples, ax=axs[1], plot_kwargs={\"color\": \"rebeccapurple\"})\naxs[1].set_xlabel(r\"$\\theta$\")\naxs[1].set_ylabel(\"Densità\")\naxs[1].set_title(\"KDE Plot dei Campioni\")\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_59892/1469964889.py:15: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nSfruttando il campione estratto dalla distribuzione a posteriori, è possibile calcolare diverse quantità di interesse. Ad esempio, la stima della media a posteriori di \\(\\theta\\) si ottiene semplicemente calcolando la media dei valori così ottenuti.\n\nnp.mean(samples)\n\n0.49900239999999996\n\n\nIn maniera analoga possiamo calcolare la deviazione standard della distribuzione a posteriori di \\(\\theta\\).\n\nnp.std(samples)\n\n0.120342000956607\n\n\nLa moda a posteriori si può calcolare nel modo seguente.\n\nprint(theta[post == max(post)])\n\n[0.5]\n\n\nOppure, usando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo\n\nstats.mode(samples)[0]\n\n0.481\n\n\nUsando il campione estratto dalla distribuzione a posteriori, è immediato trovare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(samples)\n\n0.497\n\n\nPossiamo calcolare la probabilità di varie ipotesi relative a \\(\\theta\\) nella distribuzione a posteriori. Per esempio, calcoliamo la probabilità \\(P(\\theta &lt; 0.5)\\).\n\nsum(post[theta &lt; 0.5])\n\n0.49842895507812507\n\n\nAlternativamente, utilizzando il campione estratto dalla distribuzione a posteriori di \\(\\theta\\), otteniamo un risultato analogo, sebbene soggetto a variazioni dovute all’approssimazione numerica.\n\nsum(samples &lt; 0.5) / 1e4\n\n0.5078\n\n\nPossiamo trovare la probabilità a posteriori che \\(\\theta\\) sia compresa in un dato intervallo. Per esempio, troviamo \\(P(0.5 &lt; \\theta &lt; 0.75)\\).\n\nsum((samples &gt; 0.6) & (samples &lt; 0.8)) / 1e4\n\n0.2056\n\n\nUtilizzando il campionamento effettuato dalla distribuzione a posteriori di \\(\\theta\\), è possibile risolvere il problema inverso, ovvero determinare l’intervallo che contiene \\(\\theta\\) con una specifica probabilità. Ad esempio, si può calcolare l’intervallo che ha una probabilità pari a 0.94 di contenere \\(\\theta\\), basandosi sulla distribuzione a posteriori campionata.\n\nnp.percentile(samples, [2, 98])\n\narray([0.25798, 0.744  ])\n\n\nL’intervallo specificato è noto come intervallo di credibilità e rappresenta una quantificazione statistica dell’incertezza associata alla stima del parametro \\(\\theta\\). In termini probabilistici, si può affermare con il 94% di credibilità che il valore “vero” di \\(\\theta\\) è contenuto nell’intervallo [0.26, 0.74].\nSe vogliamo trovare l’intervallo di credibilità a più alta densità a posteriori (HPD), usiamo la funzione ArviZ hdi() (si veda il capitolo {ref}sintesi-distr-post-notebook).\n\naz.hdi(samples, hdi_prob=0.94)\n\narray([0.276, 0.722])\n\n\nNel contesto attuale, la distribuzione a posteriori è simmetrica. Di conseguenza, l’intervallo di credibilità calcolato attraverso i quantili e l’intervallo di credibilità a più alta densità a posteriori (HPDI) sono molto simili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#qual-è-il-modo-migliore-per-stimare-il-parametro-theta",
    "href": "chapters/bayesian_inference/03_subj_prop.html#qual-è-il-modo-migliore-per-stimare-il-parametro-theta",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.7 Qual è il modo migliore per stimare il parametro \\(\\theta\\)?",
    "text": "42.7 Qual è il modo migliore per stimare il parametro \\(\\theta\\)?\nNonostante abbiamo discusso in precedenza dei diversi metodi di stima puntuale e intervallare per riassumere la distribuzione a posteriori di \\(\\theta\\), la migliore stima del parametro che stiamo cercando di inferire è rappresentata dall’intera distribuzione a posteriori. Per citare le parole di McElreath (2020):\n\nThat an arbitrary interval contains an arbitrary value is not meaningful. Use the whole distribution.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/03_subj_prop.html#metodo-basato-su-griglia",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.8 Metodo basato su griglia",
    "text": "42.8 Metodo basato su griglia\nIl metodo utilizzato in questo capitolo per generare la distribuzione a posteriori è noto come metodo basato su griglia. Questo metodo numerico esatto si basa sul calcolo della distribuzione a posteriori mediante una griglia di punti uniformemente spaziati. Nonostante la maggior parte dei parametri sia continua, l’approssimazione della distribuzione a posteriori può essere ottenuta considerando soltanto una griglia finita di valori dei parametri. Il metodo segue quattro fasi:\n\nFissare una griglia discreta di possibili valori dei parametri.\nValutare la distribuzione a priori e la funzione di verosimiglianza per ciascun valore della griglia.\nCalcolare l’approssimazione della densità a posteriori, ottenuta moltiplicando la distribuzione a priori per la funzione di verosimiglianza per ciascun valore della griglia e normalizzando i prodotti in modo che la loro somma sia uguale a 1.\nSelezionare \\(n\\) valori casuali dalla griglia per ottenere un campione casuale della densità a posteriori normalizzata.\n\nQuesto metodo può essere potenziato aumentando il numero di punti nella griglia, ma il limite principale risiede nel fatto che all’aumentare della dimensionalità dello spazio dei parametri, il numero di punti necessari per una stima accurata cresce in modo esponenziale, rendendo il metodo impraticabile per problemi complessi.\nIn sintesi, l’approccio basato sulla griglia è intuitivo e non richiede competenze di programmazione avanzate per l’implementazione. Inoltre, fornisce un risultato che può essere considerato, per tutti gli scopi pratici, come un campione casuale estratto dalla distribuzione di probabilità a posteriori condizionata ai dati. Tuttavia, questo metodo è limitato a causa della maledizione della dimensionalità1, il che significa che può essere applicato soltanto a modelli statistici semplici con non più di due parametri. Di conseguenza, in pratica, è spesso sostituito da altre tecniche più efficienti, poiché i modelli impiegati in psicologia richiedono frequentemente la stima di centinaia o anche migliaia di parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/03_subj_prop.html#riflessioni-conclusive",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.9 Riflessioni Conclusive",
    "text": "42.9 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato l’aggiornamento bayesiano utilizzando una distribuzione a priori discreta, accennando brevemente al caso delle distribuzioni a priori continue. Quando si affrontano scenari con distribuzioni a priori continue, l’elaborazione della distribuzione a posteriori generalmente richiede la risoluzione di un integrale che, nella maggior parte dei casi, non ammette una soluzione analitica. Tuttavia, ci sono eccezioni notevoli, come nell’inferenza relativa alle proporzioni, dove la distribuzione a priori è modellata come una distribuzione Beta e la funzione di verosimiglianza segue una distribuzione binomiale. In queste circostanze particolari, è possibile derivare analiticamente la distribuzione a posteriori. L’analisi dettagliata di questo caso sarà trattata nel capitolo successivo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "href": "chapters/bayesian_inference/03_subj_prop.html#esercizi",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "42.10 Esercizi",
    "text": "42.10 Esercizi\n\nEsercizio 42.1 Viene chieso di calcolare la distribuzione a posteriori della probabilità che uno studio condivida i materiali di ricerca utilizzando il metodo basato su griglia. Si utilizzeranno dati reali per motivare e costruire una distribuzione a priori discretizzata.\nIn uno studio sull’analisi delle pratiche di trasparenza e riproducibilità nella ricerca in psicologia, Hardwicke et al. (2022) hanno riportato che la condivisione dei materiali di ricerca è stata rilevata nel 14% dei casi (26 su 183 studi), con un intervallo di confidenza al 95% pari a [10%, 19%]. Questo suggerisce che la condivisione di materiali è rara.\nIspirandoti ai risultati di questo studio, costruisci una distribuzione a priori per la probabilità \\(\\theta\\) che uno studio condivida i materiali di ricerca. Per semplicità, discretizza \\(\\theta\\) in 10 livelli equispaziati: \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\).\nAttribuisci le seguenti probabilità a priori ai 10 livelli, basandoti sull’informazione che la condivisione dei materiali è un evento raro ma non trascurabile: \\(0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02\\).\nSupponiamo che siano stati osservati 20 studi su 100 che hanno condiviso i materiali di ricerca. Calcola la distribuzione a posteriori utilizzando il metodo basato su griglia. Calcola la media della distribuzione a posteriori e l’intervallo di credibilità al 89%.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/03_subj_prop.html#informazioni-sullambiente-di-sviluppo",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and Bayesian Modeling. CRC Press.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D., Kidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence of transparency and reproducibility-related research practices in psychology (2014–2017). Perspectives on Psychological Science, 17(1), 239–251.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nShiffrin, R. M., & Schneider, W. (1977). Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory. Psychological Review, 84(2), 127–190.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "href": "chapters/bayesian_inference/03_subj_prop.html#footnotes",
    "title": "42  Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Per comprendere la maledizione della dimensionalità, possiamo considerare l’esempio di una griglia di 100 punti equispaziati. Nel caso di un solo parametro, sarebbe necessario calcolare solo 100 valori. Tuttavia, se abbiamo due parametri, il numero di valori da calcolare diventa \\(100^2\\). Se invece abbiamo 10 parametri, il numero di valori da calcolare sarebbe di \\(10^{10}\\). È evidente che la quantità di calcoli richiesta diventa troppo grande persino per un computer molto potente. Pertanto, per modelli che richiedono la stima di un numero significativo di parametri, è necessario utilizzare un approccio diverso.↩︎",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Pensare ad una proporzione in termini soggettivi</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html",
    "href": "chapters/bayesian_inference/04_grid_gauss.html",
    "title": "43  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, estenderemo la discussione precedente sul calcolo della distribuzione a posteriori utilizzando il metodo basato su griglia, applicandolo questa volta a un caso con verosimiglianza gaussiana. In particolare, ci concentreremo su come costruire un modello gaussiano per descrivere l’intelligenza.\nImmaginiamo di condurre uno studio sulla plusdotazione, considerando l’approccio psicometrico. Secondo questo approccio, una persona è considerata plusdotata se ha un QI (Quoziente Intellettivo) di 130 o superiore (Robinson, Zigler, & Gallagher, 2000). Anche se l’uso di un QI di 130 come soglia è il criterio più comune, non è universalmente accettato. L’intelligenza nei bambini plusdotati non è solo superiore rispetto a quella dei loro pari, ma è qualitativamente diversa (Lubart & Zenasni, 2010). I bambini plusdotati tendono a mostrare caratteristiche come un vocabolario ampio, un linguaggio molto sviluppato, processi di ragionamento avanzati, eccellente memoria, vasti interessi, forte curiosità, empatia, capacità di leadership, abilità visive elevate, impegno in situazioni sfidanti e un forte senso di giustizia (Song & Porath, 2005).\nNella simulazione che seguirà, assumeremo che i dati provengano da una distribuzione normale. Per semplicità, considereremo che la deviazione standard sia nota e pari a 5. Il parametro della media sarà l’oggetto della nostra inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#dati",
    "title": "43  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "43.1 Dati",
    "text": "43.1 Dati\nSupponiamo di avere un campione di 10 osservazioni. I dati saranno generati casualmente da una distribuzione normale con media 130 e deviazione standard 5. Utilizziamo il seguente codice Python per generare questi dati:\n\nnp.random.seed(RANDOM_SEED)  # Per la riproducibilità\nvera_media = 130  # Media vera\nsigma_conosciuta = 5  # Deviazione standard conosciuta\ndimensione_campione = 10  # Dimensione del campione\n\n# Generare un campione\ncampione = np.random.normal(loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione).round()\nprint(campione)\n\n[129. 124. 135. 141. 128. 123. 141. 119. 132. 131.]",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#griglia",
    "title": "43  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "43.2 Griglia",
    "text": "43.2 Griglia\nCreiamo ora una griglia di 100 valori compresi tra 110 e 150. Questa griglia ci servirà per calcolare la verosimiglianza.\n\nmu_griglia = np.linspace(start=110, stop=150, num=100)  # 100 punti tra 110 e 150\nprint(mu_griglia)\n\n[110.         110.4040404  110.80808081 111.21212121 111.61616162\n 112.02020202 112.42424242 112.82828283 113.23232323 113.63636364\n 114.04040404 114.44444444 114.84848485 115.25252525 115.65656566\n 116.06060606 116.46464646 116.86868687 117.27272727 117.67676768\n 118.08080808 118.48484848 118.88888889 119.29292929 119.6969697\n 120.1010101  120.50505051 120.90909091 121.31313131 121.71717172\n 122.12121212 122.52525253 122.92929293 123.33333333 123.73737374\n 124.14141414 124.54545455 124.94949495 125.35353535 125.75757576\n 126.16161616 126.56565657 126.96969697 127.37373737 127.77777778\n 128.18181818 128.58585859 128.98989899 129.39393939 129.7979798\n 130.2020202  130.60606061 131.01010101 131.41414141 131.81818182\n 132.22222222 132.62626263 133.03030303 133.43434343 133.83838384\n 134.24242424 134.64646465 135.05050505 135.45454545 135.85858586\n 136.26262626 136.66666667 137.07070707 137.47474747 137.87878788\n 138.28282828 138.68686869 139.09090909 139.49494949 139.8989899\n 140.3030303  140.70707071 141.11111111 141.51515152 141.91919192\n 142.32323232 142.72727273 143.13131313 143.53535354 143.93939394\n 144.34343434 144.74747475 145.15151515 145.55555556 145.95959596\n 146.36363636 146.76767677 147.17171717 147.57575758 147.97979798\n 148.38383838 148.78787879 149.19191919 149.5959596  150.        ]\n\n\n\n43.2.1 Calcolo della Verosimiglianza\nPer ogni valore di media nella griglia, calcoleremo la verosimiglianza, che rappresenta la probabilità di osservare il nostro campione dati quei valori di media. Poiché le osservazioni nel campione sono indipendenti, la verosimiglianza complessiva è il prodotto delle densità di probabilità di ciascuna osservazione:\n\nlikelihood = np.array(\n    [np.prod(stats.norm.pdf(campione, loc=mu, scale=sigma_conosciuta)) for mu in mu_griglia]\n)\nlikelihood\n\narray([1.09207034e-51, 2.81130431e-50, 6.77962875e-49, 1.53159793e-47,\n       3.24133885e-46, 6.42606189e-45, 1.19345536e-43, 2.07638679e-42,\n       3.38416198e-41, 5.16695682e-40, 7.39025335e-39, 9.90203887e-38,\n       1.24288439e-36, 1.46142874e-35, 1.60977567e-34, 1.66109274e-33,\n       1.60569555e-32, 1.45402990e-31, 1.23345773e-30, 9.80202970e-30,\n       7.29707081e-29, 5.08887652e-28, 3.32457450e-27, 2.03465618e-26,\n       1.16650552e-25, 6.26503313e-25, 3.15210554e-24, 1.48565830e-23,\n       6.55960851e-23, 2.71317442e-22, 1.05127978e-21, 3.81592400e-21,\n       1.29754350e-20, 4.13318590e-20, 1.23335687e-19, 3.44773107e-19,\n       9.02856674e-19, 2.21485371e-18, 5.08993326e-18, 1.09577133e-17,\n       2.20987945e-17, 4.17501498e-17, 7.38904479e-17, 1.22506566e-16,\n       1.90270402e-16, 2.76836859e-16, 3.77326575e-16, 4.81783232e-16,\n       5.76271010e-16, 6.45717667e-16, 6.77796577e-16, 6.66494974e-16,\n       6.13953092e-16, 5.29802873e-16, 4.28286349e-16, 3.24335853e-16,\n       2.30089337e-16, 1.52911036e-16, 9.51967178e-17, 5.55195483e-17,\n       3.03326726e-17, 1.55244505e-17, 7.44324992e-18, 3.34310310e-18,\n       1.40662310e-18, 5.54429749e-19, 2.04718038e-19, 7.08119413e-20,\n       2.29455090e-20, 6.96513754e-21, 1.98062612e-21, 5.27613760e-22,\n       1.31665056e-22, 3.07797970e-23, 6.74065000e-24, 1.38286126e-24,\n       2.65764058e-25, 4.78469973e-26, 8.06963581e-27, 1.27495245e-27,\n       1.88701280e-28, 2.61635402e-29, 3.39827856e-30, 4.13487371e-31,\n       4.71309645e-32, 5.03258607e-33, 5.03404275e-34, 4.71719026e-35,\n       4.14086138e-36, 3.40516999e-37, 2.62317767e-38, 1.89302967e-39,\n       1.27975826e-40, 8.10474333e-42, 4.80829822e-43, 2.67229458e-44,\n       1.39129131e-45, 6.78566815e-47, 3.10033032e-48, 1.32697923e-49])\n\n\nQuesto codice svolge le seguenti operazioni:\n\nCalcolo della PDF: Per ogni valore di media nella griglia, stats.norm.pdf(campione, loc=mu, scale=sigma_conosciuta) calcola la densità di probabilità (PDF) per ogni osservazione del campione. Questo ci indica quanto sia probabile osservare quel campione, dato un certo valore di media.\nMoltiplicazione delle Probabilità: np.prod() moltiplica tutte queste densità di probabilità, ottenendo così la verosimiglianza complessiva per quel particolare valore della media. Questo passo è essenziale perché stiamo assumendo che le osservazioni siano indipendenti.\nIterazione su Tutti i Valori della Griglia: Il calcolo viene ripetuto per ciascun valore della media nella griglia, restituendo un array (likelihood) che contiene la verosimiglianza per ogni valore di media.\n\nAd esempio, per il primo valore della griglia, 110, il codice calcola quanto sia probabile osservare il campione, assumendo che la media sia effettivamente 110.\n\n\n43.2.2 Calcolo della Distribuzione a Posteriori\nDopo aver calcolato la verosimiglianza per ciascun valore della media, possiamo costruire la distribuzione a posteriori, che combina le informazioni provenienti dai dati con la conoscenza a priori.\n\nImpostazione della Prior: In questo esempio, usiamo una prior uniforme, cioè assumiamo che tutti i valori di media siano inizialmente equiprobabili.\nCalcolo della Posteriori Non Normalizzata: Moltiplichiamo la verosimiglianza per la prior per ottenere la distribuzione a posteriori non normalizzata.\nNormalizzazione della Posteriori: Normalizziamo la distribuzione a posteriori dividendo ciascun valore per la somma totale degli elementi, ottenendo una distribuzione di probabilità valida.\n\nEcco come appare il codice:\n\nprior = np.ones(len(mu_griglia))  # Una prior uniforme\nposterior_non_norm = likelihood * prior  # Calcoliamo la posterior non normalizzata moltiplicando per la prior\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizziamo la posterior\n\nQuesto processo di normalizzazione garantisce che la distribuzione a posteriori sia una distribuzione di probabilità valida, con una somma totale pari a 1.\n\n\n43.2.3 Rappresentazione Grafica della Posterior\nPossiamo ora visualizzare la distribuzione a posteriori con un semplice grafico:\n\nplt.plot(mu_griglia, posterior)\nplt.title('Distribuzione a Posteriori della Media')\nplt.xlabel('Media')\nplt.ylabel('Probabilità')\nplt.show()\n\n\n\n\n\n\n\n\nPer esplorare ulteriormente, consideriamo una prior non uniforme, come una distribuzione gaussiana con media 140 e deviazione standard 3:\n\n# Calcolo della prior gaussiana per ogni valore della griglia della media\nprior = stats.norm.pdf(mu_griglia, loc=140, scale=3)\n\n# Calcolo della likelihood (rimane invariato)\nlikelihood = np.array([np.prod(stats.norm.pdf(campione, loc=mu, scale=sigma_conosciuta)) for mu in mu_griglia])\n\n# Calcolo della distribuzione a posteriori (aggiornamento con la nuova prior)\nposterior_non_norm = likelihood * prior  # Moltiplicazione element-wise\nposterior = posterior_non_norm / np.sum(posterior_non_norm)  # Normalizzazione\n\nPossiamo confrontare la nuova distribuzione a posteriori con la prior originale:\n\nplt.plot(mu_griglia, posterior, label='Posterior')\nplt.plot(mu_griglia, prior / np.sum(prior), label='Prior', linestyle='--')\nplt.title('Distribuzione a Posteriori e Prior della Media')\nplt.xlabel('Media')\nplt.ylabel('Densità')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSi osserva che, con un campione di piccole dimensioni, l’utilizzo di una prior informativa ha influenzato considerevolmente la distribuzione a posteriori, spostandola verso la prior. Questo effetto è evidente se confrontiamo la posterior ottenuta con la prior informativa rispetto a quella ottenuta con una prior uniforme.\n\n\n43.2.4 Campionamento dalla Posterior\nPer ottenere un campione dalla distribuzione a posteriori, possiamo utilizzare il campionamento ponderato:\n\n# Selezione casuale di un indice dalla griglia secondo le probabilità a posteriori\nindice_campionato = np.random.choice(a=len(mu_griglia), size=1000, p=posterior)\n\n# Estrazione del valore della media corrispondente all'indice campionato\nmedia_campionata = mu_griglia[indice_campionato]\nmedia_campionata.shape\n\n(1000,)\n\n\nIl metodo np.random.choice permette di selezionare un indice dalla griglia con probabilità proporzionale ai valori della distribuzione a posteriori. In questo modo, i valori della media con probabilità a posteriori più alta saranno selezionati più frequentemente, riflettendo la loro maggiore plausibilità data la combinazione dei dati osservati e della prior.\nQuesto campione dalla distribuzione a posteriori rappresenta quindi una possibile stima della media della popolazione, tenendo conto sia dei dati osservati (attraverso la likelihood) sia delle nostre conoscenze o supposizioni precedenti (attraverso la prior).\nQuesto campionamento riflette la plausibilità di ciascun valore della media, basandosi sui dati e sulla prior. L’istogramma risultante mostra la distribuzione dei campioni:\n\n_ = sns.histplot(media_campionata, alpha=0.5)\n\n\n\n\n\n\n\n\nCalcoliamo ora la media a posteriori:\n\nnp.mean(media_campionata)\n\n132.4363636363636\n\n\nPer calcolare l’intervallo di credibilità al 94%, possiamo fare così:\n\n# Calcolo del 3° e 97° percentile dei campioni per ottenere l'intervallo di credibilità al 95%\nlimite_inferiore = np.percentile(media_campionata, 3)\nlimite_superiore = np.percentile(media_campionata, 97)\n\nprint(f\"Intervallo di credibilità al 94% per la media: [{limite_inferiore}, {limite_superiore}]\")\n\nIntervallo di credibilità al 94% per la media: [129.7979797979798, 135.05050505050505]\n\n\nL’intervallo di credibilità offre una stima probabilistica di dove si trova il vero valore della media, riflettendo l’incertezza della nostra stima basata sui dati e sulle conoscenze precedenti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#la-log-verosimiglianza",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#la-log-verosimiglianza",
    "title": "43  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "43.3 La Log-Verosimiglianza",
    "text": "43.3 La Log-Verosimiglianza\nNel calcolo della verosimiglianza, abbiamo visto che lavorare con la somma delle probabilità può causare problemi (ovvero, produrre valori numerici estremamente piccoli). Per risolvere questi problemi, è meglio usare i logaritmi.\n\nStabilità Numerica: Quando moltiplichiamo molte probabilità piccole, il risultato può essere così piccolo che il computer lo arrotonda a zero, causando errori. Usare i logaritmi trasforma le moltiplicazioni in somme, riducendo questo rischio.\nSemplificazione dei Calcoli: Il logaritmo di un prodotto è uguale alla somma dei logaritmi (log(ab) = log(a) + log(b)). Questo ci permette di trasformare un prodotto complesso in una somma, rendendo i calcoli più semplici e veloci.\nMiglioramento della Precisione: I calcolatori sono generalmente più precisi nel sommare numeri che nel moltiplicarli, specialmente quando si tratta di numeri molto grandi o molto piccoli. Usare i logaritmi aiuta quindi a mantenere una maggiore precisione nei nostri calcoli.\nFacilità di Ottimizzazione: Molti algoritmi di ottimizzazione funzionano meglio con somme piuttosto che con prodotti. Questo è particolarmente utile quando dobbiamo stimare parametri, come la media, in modo più efficiente.\nGestione di Valori Estremi: I logaritmi aiutano a gestire meglio un’ampia gamma di valori, riducendo l’impatto di numeri estremamente grandi o piccoli che potrebbero influenzare negativamente i risultati.\n\nIn conclusione, usare i logaritmi nei calcoli probabilistici è vantaggioso perché migliora la stabilità, la precisione e l’efficienza, rendendolo un metodo preferibile in molte situazioni.\nEsempio con Log-Verosimiglianza\nPer applicare questo concetto, riprendiamo l’esempio precedente e rifacciamo i calcoli usando i logaritmi. Questo ci aiuterà a evitare problemi di precisione e a semplificare i calcoli. Seguiamo i passaggi uno per uno:\n\nGenerazione del Campione: Generiamo un campione di dati da una distribuzione normale.\nDefinizione della Griglia: Creiamo una serie di possibili valori per la media.\nCalcolo della Log-Verosimiglianza: Calcoliamo la log-verosimiglianza per ciascun valore della media.\nCalcolo della Log-Posterior: Combiniamo la log-verosimiglianza con la log-prior (se applicabile) e normalizziamo i risultati per ottenere la distribuzione a posteriori.\nVisualizzazione: Mostriamo graficamente la distribuzione a posteriori.\n\nEcco come fare in Python:\n\n# Per la riproducibilità dei risultati\nnp.random.seed(RANDOM_SEED)\n\n# Parametri veri e conosciuti\nvera_media = 130\nsigma_conosciuta = 5\ndimensione_campione = 10\n\n# Generazione di un campione casuale dalla distribuzione normale\ncampione = np.random.normal(\n    loc=vera_media, scale=sigma_conosciuta, size=dimensione_campione\n)\n\n# Definizione della griglia per la media\nmu_griglia = np.linspace(start=110, stop=150, num=100)\n\n# Calcolo della log-verosimiglianza per ciascun valore nella griglia\nlog_likelihood = np.array(\n    [\n        np.sum(stats.norm.logpdf(campione, loc=mu, scale=sigma_conosciuta))\n        for mu in mu_griglia\n    ]\n)\n\n# Calcolo della log-prior gaussiana centrata su 140 con deviazione standard 3\nlog_prior = stats.norm.logpdf(mu_griglia, loc=140, scale=3)\n\n# Calcolo della log-posterior non normalizzata\nlog_posterior_non_norm = log_likelihood + log_prior\n\n# Normalizzazione della log-posterior (conversione alla scala lineare)\nlog_posterior = log_posterior_non_norm - np.log(\n    np.sum(np.exp(log_posterior_non_norm - np.max(log_posterior_non_norm)))\n)\nposterior = np.exp(log_posterior)\n\n# Visualizzazione della distribuzione a posteriori\nplt.plot(mu_griglia, posterior)\nplt.title(\"Distribuzione a Posteriori della Media (Log-verosimiglianza)\")\nplt.xlabel(\"Media\")\nplt.ylabel(\"Probabilità\")\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice ci permette di calcolare e visualizzare la distribuzione a posteriori in modo più sicuro ed efficiente, utilizzando i logaritmi per gestire meglio i calcoli complessi.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#deviazione-standard-ignota",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#deviazione-standard-ignota",
    "title": "43  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "43.4 Deviazione Standard Ignota",
    "text": "43.4 Deviazione Standard Ignota\nEstendere l’approccio usato sopra al caso in cui la deviazione standard (\\(\\sigma\\)) della popolazione non è conosciuta introduce una complessità maggiore nell’inferenza bayesiana, poiché ora dobbiamo stimare due parametri (la media e la deviazione standard) invece di uno solo. In questo contesto, la distribuzione a posteriori diventa una funzione delle due dimensioni (media e \\(\\sigma\\)), e la sua esplorazione richiede metodi più sofisticati per navigare efficacemente lo spazio dei parametri. Vediamo come affrontare questo problema:\n\n43.4.1 1. Definizione dello Spazio dei Parametri\nDobbiamo definire una griglia bidimensionale che copra le possibili combinazioni di valori per la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)). Questo approccio, sebbene computazionalmente intensivo, è fattibile per problemi di dimensioni moderate.\n\nmu_griglia = np.linspace(start=110, stop=150, num=100)\nsigma_griglia = np.linspace(start=1, stop=10, num=50)\n\n\n\n43.4.2 2. Calcolo della Log-Likelihood Bidimensionale\nPer ogni coppia di valori (\\(\\mu\\), \\(\\sigma\\)) nella griglia, calcoliamo la log-likelihood del campione. Questo richiede un’iterazione su entrambe le dimensioni della griglia.\n\nlog_likelihood_2d = np.array([[np.sum(stats.norm.logpdf(campione, loc=mu, scale=sigma))\n                                for sigma in sigma_griglia] for mu in mu_griglia])\n\n\n\n43.4.3 3. Applicazione delle Priors\nLe priors per \\(\\mu\\) e \\(\\sigma\\) possono essere definite in modo indipendente e poi combinate, o si può definire una prior congiunta che rifletta la conoscenza o le assunzioni sui parametri. Le log-priors per \\(\\mu\\) e \\(\\sigma\\) sono calcolate su ogni griglia rispettivamente e poi sommate per ottenere una log-prior congiunta.\n\nlog_prior_mu = stats.norm.logpdf(mu_griglia, loc=140, scale=5)\nlog_prior_sigma = stats.norm.logpdf(sigma_griglia, loc=5, scale=2)\nlog_prior_2d = log_prior_mu[:, np.newaxis] + log_prior_sigma\n\n\n\n43.4.4 4. Calcolo della Distribuzione a Posterior Bidimensionale\nSommando la log-likelihood con la log-prior congiunta e normalizzando, otteniamo la distribuzione a posteriori bidimensionale.\n\nlog_posterior_2d = log_likelihood_2d + log_prior_2d\nlog_posterior_2d -= np.max(log_posterior_2d)  # Stabilizzazione\nposterior_2d = np.exp(log_posterior_2d)\nposterior_2d /= np.sum(posterior_2d)\n\n\n\n43.4.5 5. Visualizzazione\nLa visualizzazione di distribuzioni bidimensionali può essere effettuata tramite contour plot o heatmaps.\n\nplt.contourf(mu_griglia, sigma_griglia, posterior_2d.T)\nplt.xlabel('Media ($\\mu$)')\nplt.ylabel('Deviazione Standard ($\\sigma$)')\nplt.colorbar(label='Densità Posterior')\nplt.title('Distribuzione a Posteriori Bidimensionale')\nplt.show()\n\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:3: SyntaxWarning: invalid escape sequence '\\s'\n&lt;&gt;:2: SyntaxWarning: invalid escape sequence '\\m'\n&lt;&gt;:3: SyntaxWarning: invalid escape sequence '\\s'\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63985/4162669767.py:2: SyntaxWarning: invalid escape sequence '\\m'\n  plt.xlabel('Media ($\\mu$)')\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63985/4162669767.py:3: SyntaxWarning: invalid escape sequence '\\s'\n  plt.ylabel('Deviazione Standard ($\\sigma$)')",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#riflessioni-conclusive",
    "title": "43  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "43.5 Riflessioni Conclusive",
    "text": "43.5 Riflessioni Conclusive\nQuando si passa alla stima simultanea di più parametri, come la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), l’analisi diventa notevolmente più complessa. Questo perché occorre considerare un numero molto maggiore di combinazioni di parametri rispetto alla stima di un solo parametro, aumentando così il carico computazionale. Inoltre, la scelta delle priors per ciascun parametro richiede particolare attenzione, poiché queste influenzeranno in modo diretto le stime a posteriori.\nIn scenari dove lo spazio dei parametri è multidimensionale o quando l’esplorazione della griglia diventa impraticabile, l’uso di metodi avanzati come il campionamento di Markov Chain Monte Carlo (MCMC) diventa indispensabile. Questi metodi permettono di campionare in modo efficiente dalla distribuzione a posteriori, senza la necessità di esplorare esplicitamente ogni combinazione possibile di parametri, rendendo l’analisi più gestibile anche in contesti complessi.\nIn conclusione, l’estensione dell’approccio bayesiano a problemi con più parametri sconosciuti richiede un’attenzione ancora maggiore nella definizione dello spazio dei parametri, nella selezione delle priors appropriate e nel calcolo delle distribuzioni a posteriori. L’adozione di tecniche come l’MCMC può facilitare questo processo, permettendo di affrontare in modo efficiente problemi che altrimenti sarebbero proibitivi dal punto di vista computazionale.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/04_grid_gauss.html#informazioni-sullambiente-di-sviluppo",
    "title": "43  Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Mar 20 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.1\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\nmatplotlib: 3.8.3\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Calcolo della Distribuzione a Posteriori Gaussiana tramite Metodo a Griglia</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploriamo il concetto di distribuzioni a priori coniugate e il loro ruolo nell’inferenza bayesiana. Utilizzando il modello beta-binomiale come esempio paradigmatico, dimostreremo come queste distribuzioni semplifichino l’analisi attraverso calcoli analitici diretti. L’uso di una distribuzione a priori coniugata non solo rende l’inferenza più agevole, ma fornisce anche una chiara visione del modo in cui le credenze a priori influenzano le conclusioni.\nPer favorire la comprensione, procederemo in tre fasi principali:",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#introduzione",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "",
    "text": "Introduzione del modello beta-binomiale.\nAnalisi della distribuzione Beta e del suo ruolo come distribuzione a priori.\nDescrizione del processo di aggiornamento bayesiano e dei vantaggi derivanti dall’uso di distribuzioni coniugate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#il-modello-beta-binomiale",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "44.1 Il Modello Beta-Binomiale",
    "text": "44.1 Il Modello Beta-Binomiale\nIl modello beta-binomiale è un esempio classico per analizzare una proporzione \\(\\theta\\), ossia la probabilità di successo in una sequenza di prove binarie (ad esempio, successo/fallimento). Supponiamo di osservare \\(y\\) successi su \\(n\\) prove, dove ogni prova è indipendente e con la stessa probabilità di successo \\(\\theta\\), che appartiene all’intervallo \\([0,1]\\).\nLa funzione di verosimiglianza, basata sulla distribuzione binomiale, è espressa come:\n\\[\n\\text{Bin}(y \\mid n, \\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y},\n\\]\ndove \\(\\binom{n}{y}\\) è il coefficiente binomiale che conta il numero di modi in cui \\(y\\) successi possono verificarsi in \\(n\\) prove.\nPer modellare la nostra conoscenza preliminare su \\(\\theta\\), scegliamo una distribuzione a priori Beta, che rappresenta un’ampia gamma di credenze iniziali con parametri flessibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#la-distribuzione-beta-un-prior-flessibile",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "44.2 La Distribuzione Beta: Un Prior Flessibile",
    "text": "44.2 La Distribuzione Beta: Un Prior Flessibile\nLa distribuzione Beta è definita come:\n\\[\n\\text{Beta}(\\theta \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\theta^{\\alpha - 1} (1 - \\theta)^{\\beta - 1}, \\quad \\text{con } \\theta \\in (0, 1),\n\\]\ndove:\n\n\\(\\alpha &gt; 0\\) e \\(\\beta &gt; 0\\) sono i iperparametri, che determinano la forma della distribuzione.\n\\(B(\\alpha, \\beta)\\) è la funzione Beta di Eulero, calcolata come:\n\\[\n  B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)},\n  \\]\ndove \\(\\Gamma(x)\\) è la funzione Gamma, una generalizzazione del fattoriale.\n\n\n44.2.1 Interpretazione Intuitiva di \\(\\alpha\\) e \\(\\beta\\)\nNel contesto bayesiano:\n\n\\(\\alpha -1\\) rappresenta il numero ipotetico di “successi” a priori.\n\\(\\beta -1\\) rappresenta il numero ipotetico di “fallimenti” a priori.\n\nAd esempio:\n\nUna distribuzione Beta(1, 1) è uniforme (0 successi a priori e 0 fallimenti), indicando totale incertezza iniziale (assenza di credenze informate).\nUna distribuzione Beta(10, 20) rappresenta una conoscenza a priori basata su 9 successi e 19 fallimenti ipotizzati, indicando una convinzione iniziale relativamente solida, poiché deriva da un totale di 28 osservazioni virtuali che riflettono le credenze precedenti.\n\nQuesta interpretazione consente di calibrare le credenze a priori in base all’evidenza disponibile o alla fiducia nella stima.\n\n\n44.2.2 Flessibilità della Distribuzione Beta\nLa distribuzione Beta è estremamente versatile:\n\nForma: Valori diversi di \\(\\alpha\\) e \\(\\beta\\) producono distribuzioni simmetriche, asimmetriche o uniformi.\nForza del prior: Valori elevati di \\(\\alpha\\) e \\(\\beta\\) riducono la varianza, riflettendo credenze più forti.\n\nQuesta flessibilità rende la distribuzione Beta una scelta ideale per rappresentare credenze iniziali su proporzioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#aggiornamento-bayesiano",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "44.3 Aggiornamento Bayesiano",
    "text": "44.3 Aggiornamento Bayesiano\nL’aggiornamento bayesiano combina le informazioni iniziali (priori) con i dati osservati (verosimiglianza) per produrre una nuova distribuzione delle credenze (posteriori). Nel caso del modello beta-binomiale, questo processo è particolarmente semplice grazie alla “coniugazione”: il prior Beta e la verosimiglianza Binomiale producono una distribuzione a posteriori che appartiene ancora alla famiglia Beta.\n\n44.3.1 Problema\nSe osserviamo \\(y\\) successi su \\(n\\) prove, vogliamo aggiornare il nostro prior Beta con i dati osservati per ottenere una distribuzione a posteriori Beta. I parametri aggiornati della distribuzione a posteriori sono:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\nVediamo in dettaglio come si arriva a questo risultato.\n\n\n44.3.2 Passaggi dell’Aggiornamento Bayesiano\n1. Formula di Bayes\nLa regola di Bayes afferma che:\n\\[\n\\text{Posterior} \\propto \\text{Prior} \\times \\text{Verosimiglianza},\n\\]\ndove \\(\\propto\\) indica “proporzionale a”. Qui ci concentriamo sui termini che dipendono dal parametro di interesse, \\(\\theta\\), la probabilità di successo.\n2. Espressione del Prior\nIl prior è una distribuzione Beta, definita come:\n\\[\n\\text{Prior} = \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1},\n\\]\ndove:\n\n\\(\\theta\\) rappresenta la probabilità di successo,\n\\(\\alpha\\) e \\(\\beta\\) sono parametri che descrivono le nostre convinzioni iniziali:\n\n\\(\\alpha\\): il numero di successi attesi prima di osservare i dati,\n\\(\\beta\\): il numero di insuccessi attesi prima di osservare i dati.\n\n\n3. Espressione della Verosimiglianza\nLa verosimiglianza è data dalla distribuzione Binomiale, che rappresenta la probabilità di osservare \\(y\\) successi su \\(n\\) prove:\n\\[\n\\text{Verosimiglianza} = \\theta^y (1-\\theta)^{n-y},\n\\]\ndove:\n\n\\(y\\) è il numero di successi osservati,\n\\(n\\) è il numero totale di prove,\n\\(\\theta\\) è la probabilità di successo (il parametro che stiamo aggiornando).\n\n4. Moltiplicazione di Prior e Verosimiglianza\nCombinando prior e verosimiglianza, otteniamo:\n\\[\n\\text{Posterior} \\propto \\underbrace{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}_{\\text{Prior}} \\times \\underbrace{\\theta^y (1-\\theta)^{n-y}}_{\\text{Verosimiglianza}}.\n\\]\n5. Raggruppamento dei termini\nMoltiplicando i termini simili, raggruppiamo gli esponenti di \\(\\theta\\) e \\(1-\\theta\\):\n\\[\n\\text{Posterior} \\propto \\theta^{(\\alpha-1) + y} (1-\\theta)^{(\\beta-1) + (n-y)}.\n\\]\n6. Forma finale\nSemplificando gli esponenti:\n\\[\n\\text{Posterior} \\propto \\theta^{\\alpha + y - 1} (1-\\theta)^{\\beta + n - y - 1}.\n\\]\nQuesta è la forma di una distribuzione Beta con nuovi parametri:\n\\[\n\\alpha' = \\alpha + y, \\quad \\beta' = \\beta + n - y.\n\\]\n7. Normalizzazione\nPer trasformare questa espressione in una distribuzione di probabilità vera e propria, dobbiamo dividere per una costante di normalizzazione. La funzione Beta, \\(B(\\alpha', \\beta')\\), normalizza la distribuzione:\n\\[\np(\\theta | y, n) = \\frac{\\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1}}{B(\\alpha', \\beta')},\n\\]\ndove \\(B(\\alpha', \\beta')\\) è definita come:\n\\[\nB(\\alpha', \\beta') = \\int_0^1 \\theta^{\\alpha' - 1} (1-\\theta)^{\\beta' - 1} \\, d\\theta.\n\\]\nTuttavia, non dobbiamo calcolarla esplicitamente poiché sappiamo già che il risultato è una distribuzione Beta.\n8. Parametri aggiornati\nIn conclusione, i parametri aggiornati sono:\n\nNuovo \\(\\alpha'\\): \\(\\alpha + y\\), che somma al vecchio \\(\\alpha\\) il numero di successi osservati (\\(y\\)).\nNuovo \\(\\beta'\\): \\(\\beta + n - y\\), che somma al vecchio \\(\\beta\\) il numero di insuccessi osservati (\\(n-y\\)).\n\n\n\n44.3.3 Vantaggi del Modello Beta-Binomiale\nIl modello beta-binomiale presenta diversi vantaggi:\n\nSemplicità analitica: La distribuzione a posteriori appartiene alla stessa famiglia della distribuzione a priori, evitando calcoli complessi.\nInterpretazione trasparente: L’aggiornamento dei parametri \\(\\alpha\\) e \\(\\beta\\) mostra chiaramente come i dati influenzino le credenze.\n\nNonostante la semplicità, le distribuzioni a priori coniugate non sempre rappresentano credenze realistiche. Tecniche moderne come il campionamento Monte Carlo consentono di usare distribuzioni a priori più complesse, ma il modello beta-binomiale rimane un esempio didattico fondamentale per comprendere l’inferenza bayesiana.\nIn conclusione, il modello beta-binomiale illustra chiaramente come le distribuzioni a priori coniugate possano semplificare l’inferenza bayesiana e fornire una comprensione intuitiva dell’interazione tra prior e dati. Questo modello rappresenta un punto di partenza ideale per approfondire l’approccio bayesiano e prepararsi a concetti più avanzati.\n\nEsempio 44.1 In un esempio ispirato da McElreath (2020) nel suo libro “Statistical Rethinking”, consideriamo un esperimento dove otteniamo 6 successi (indicati come “acqua”) su un totale di 9 prove (immaginate come lanci di un mappamondo). La verosimiglianza binomiale per questo esperimento è data da:\n\\[\n\\theta^y (1-\\theta)^{n-y},\n\\]\ndove \\(y = 6\\) è il numero di successi e \\(n = 9\\) è il numero totale di prove.\nSe scegliamo una distribuzione a priori Beta con parametri \\(\\alpha = 2\\) e \\(\\beta = 2\\), possiamo utilizzare l’aggiornamento bayesiano per calcolare i parametri della distribuzione a posteriori, dato l’esito delle nostre prove. L’applicazione del teorema di Bayes porta a una distribuzione a posteriori Beta con i parametri aggiornati \\(\\alpha' = \\alpha + y = 8\\) e \\(\\beta' = \\beta + n - y = 5\\).\nOra, vediamo come visualizzare le tre distribuzioni di interesse: la distribuzione a priori Beta(\\(2, 2\\)), la verosimiglianza binomiale per \\(y=6\\) e \\(n=9\\), e la distribuzione a posteriori Beta(\\(8, 5\\)).\n\n# Definiamo i parametri\nalpha_prior, beta_prior = 2, 2\ny, n = 6, 9\nalpha_post, beta_post = alpha_prior + y, beta_prior + n - y\n\n# Creiamo un array di valori theta\ntheta = np.linspace(0, 1, 1000)  # Aumentiamo la risoluzione per un calcolo più preciso\n\n# Calcoliamo le PDF\nprior_pdf = stats.beta.pdf(theta, alpha_prior, beta_prior)\nlikelihood = theta**y * (1-theta)**(n-y)\n\n# Normalizziamo la verosimiglianza\nlikelihood_integral = trapezoid(likelihood, theta)\nnormalized_likelihood = likelihood / likelihood_integral\n\nposterior_pdf = stats.beta.pdf(theta, alpha_post, beta_post)\n\n# Disegnamo le distribuzioni\nplt.plot(theta, prior_pdf, label=f'Prior Beta({alpha_prior}, {beta_prior})', color='blue')\nplt.plot(theta, normalized_likelihood, label='Likelihood (normalizzata)', linestyle='--', color='green')\nplt.plot(theta, posterior_pdf, label=f'Posterior Beta({alpha_post}, {beta_post})', color='red')\n\nplt.xlabel('$\\\\theta$')\nplt.ylabel('Density')\nplt.title('Distribuzioni Prior, Likelihood e Posterior')\n_ = plt.legend()\n\n\n\n\n\n\n\n\nIn questo codice, la funzione trapezoid viene usata per calcolare l’integrale della funzione di verosimiglianza non normalizzata su θ, fornendo il fattore di normalizzazione. Dividendo la funzione di verosimiglianza per questo fattore, otteniamo una funzione di verosimiglianza normalizzata, il cui integrale su [0, 1] è uguale a 1. La normalizzazione della verosimiglianza è eseguita solo a scopo di visualizzazione, per facilitare il confronto tra le curve.\n\n\nEsempio 44.2 Esaminiamo ora un esempio discuso da Johnson et al. (2022). In uno studio molto famoso, Stanley Milgram ha studiato la propensione delle persone a obbedire agli ordini delle figure di autorità, anche quando tali ordini potrebbero danneggiare altre persone (Milgram 1963). Nell’articolo, Milgram descrive lo studio come\n\nconsistente nell’ordinare a un soggetto ingenuo di somministrare una scossa elettrica a una vittima. Viene utilizzato un generatore di scosse simulato, con 30 livelli di tensione chiaramente contrassegnati che vanno da IS a 450 volt. Lo strumento porta delle designazioni verbali che vanno da Scossa Lieve a Pericolo: Scossa Grave. Le risposte della vittima, che è un complice addestrato dell’esperimentatore, sono standardizzate. Gli ordini di somministrare scosse vengono dati al soggetto ingenuo nel contesto di un ‘esperimento di apprendimento’ apparentemente organizzato per studiare gli effetti della punizione sulla memoria. Man mano che l’esperimento procede, al soggetto ingenuo viene ordinato di somministrare scosse sempre più intense alla vittima, fino al punto di raggiungere il livello contrassegnato Pericolo: Scossa Grave.\n\nIn altre parole, ai partecipanti allo studio veniva dato il compito di testare un altro partecipante (che in realtà era un attore addestrato) sulla loro capacità di memorizzare una serie di item. Se l’attore non ricordava un item, al partecipante veniva ordinato di somministrare una scossa all’attore e di aumentare il livello della scossa con ogni fallimento successivo. I partecipanti non erano consapevoli del fatto che le scosse fossero finte e che l’attore stesse solo fingendo di provare dolore dalla scossa.\nNello studio di Milgram, 26 partecipanti su 40 hanno somministrato scosse al livello “Pericolo: Scossa Grave”. Il problema richiede di costruire la distribuzione a posteriori della probabilità \\(\\theta\\) di infliggere una scossa a l livello “Pericolo: Scossa Grave”, ipotizzando che uno studio precedente aveva stabilito che \\(\\theta\\) segue una distribuzione Beta(1, 10).\nIniziamo a fornire una rappresentazione grafica della distribuzione a priori.\n\n# Impostazione dei parametri della distribuzione Beta\nalpha = 1\nbeta_val = 10\n\n# Creazione di valori x per il plot\nx_values = np.linspace(0, 1, 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf = stats.beta.pdf(x_values, alpha, beta_val)\n\n# Plot della densità di probabilità\ncolor_fill = \"#b97c7c\"\nplt.plot(x_values, beta_pdf, label='Beta(1, 10)', color=color_fill)\nplt.title('Distribuzione Beta(1, 10)')\nplt.xlabel('x')\nplt.ylabel('Densità di probabilità')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori è una Beta di parametri aggiornati\n\ny = 26\nn = 40\n\nalpha_prior = 1\nbeta_prior = 10\n\nalpha_post = alpha_prior + y\nbeta_post = beta_prior + n - y\n\nalpha_post, beta_post\n\n(27, 24)\n\n\n\n# Creazione di valori x per il plot\nx_values = np.linspace(0, 1, 1000)\n\n# Calcolo della densità di probabilità per ogni valore di x\nbeta_pdf = stats.beta.pdf(x_values, alpha_post, beta_post)\n\n# Plot della densità di probabilità\nplt.plot(x_values, beta_pdf, label='Beta(27, 24)', color=color_fill)\nplt.title('Distribuzione Beta(1, 10)')\nplt.xlabel('theta')\nplt.ylabel('Densità di probabilità')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo la media a posteriori di \\(\\theta\\):\n\nalpha_post / (alpha_post + beta_post)\n\n0.5294117647058824\n\n\nCalcoliamo la moda a posteriori:\n\n(alpha_post - 1) / (alpha_post + beta_post - 2)\n\n0.5306122448979592\n\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\)\n\nstats.beta.sf(0.6, alpha_post, beta_post)\n\n0.15616833089995472\n\n\novvero\n\n1 - stats.beta.cdf(0.6, alpha_post, beta_post)\n\n0.15616833089995474\n\n\nSvolgiamo ora il problema usando il metodo basato su griglia. Definiamo la griglia di interesse:\n\ntheta = np.linspace(0, 1, 100)\n\n\nalpha_prior = 1  \nbeta_prior = 10   \n\n# Calcolo della PDF della distribuzione Beta per i valori x\nprior = stats.beta.pdf(theta, alpha_prior, beta_prior)\n\nplt.vlines(theta, 0, prior / np.sum(prior), color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilità')\nplt.title('Distribuzione a priori')\n\nplt.show()\n\n\n\n\n\n\n\n\nCreiamo la verosimiglianza.\n\nlk = stats.binom.pmf(y, n, theta)\n\nplt.vlines(theta, 0, lk / np.sum(lk), color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilità')\nplt.title('Verosimiglianza')\n\nplt.show()\n\n\n\n\n\n\n\n\n\npost = (prior * lk) / np.sum(prior * lk)\n\nplt.vlines(theta, 0, post, color=color_fill, linestyle='-')\nplt.xlabel('theta')\nplt.ylabel('Probabilità')\nplt.title('Distribuzione a posteriori')\n\nplt.show()\n\n\n\n\n\n\n\n\nEstraiamo un campione dalla distribuzione a posteriori.\n\nsamples = np.random.choice(theta, p=post, size=int(1e6), replace=True)\n\nTroviamo la media a posteriori.\n\nnp.mean(samples)\n\n0.5294427575757579\n\n\nCalcoliamo la probabilità che \\(\\theta &gt; 0.6\\).\n\nnp.mean(samples &gt; 0.6)\n\n0.15274",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#principali-distribuzioni-coniugate",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "44.4 Principali distribuzioni coniugate",
    "text": "44.4 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori che producono una distribuzione a posteriori con la stessa forma della distribuzione a priori. Ecco alcune delle più note coniugazioni tra modelli statistici e distribuzioni a priori:\n\nNel modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribuzione a priori è \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione a posteriori è \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nNel modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nNel modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribuzione a priori è \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione a posteriori è \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nNel modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribuzione a priori è \\(\\text{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione a posteriori è \\(\\text{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#riflessioni-conclusive",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "44.5 Riflessioni Conclusive",
    "text": "44.5 Riflessioni Conclusive\nIn conclusione, l’utilizzo di priori coniugati presenta vantaggi e svantaggi. Cominciamo con i vantaggi principali. Il principale vantaggio dell’adozione di distribuzioni a priori coniugate risiede nella loro capacità di rendere l’analisi della distribuzione a posteriori trattabile da un punto di vista analitico. Ad esempio, nel corso di questo capitolo abbiamo esaminato come sia possibile formulare la distribuzione a posteriori in seguito a un esperimento composto da una serie di prove di Bernoulli (con una verosimiglianza binomiale), utilizzando una distribuzione Beta sia per la prior che per il posteriore.\nTuttavia, è cruciale riconoscere che i modelli basati sul concetto di famiglie coniugate presentano delle limitazioni intrinseche. Le distribuzioni coniugate a priori sono disponibili solamente per distribuzioni di verosimiglianza di base e relativamente semplici. Per modelli complessi e più realistici, la ricerca di priori coniugati diventa spesso un compito estremamente arduo, limitando quindi la loro utilità. Inoltre, anche quando le distribuzioni a priori coniugate sono disponibili, un modello che ne fa uso potrebbe non essere sufficientemente flessibile per adattarsi alle nostre credenze iniziali. Ad esempio, un modello basato su una distribuzione normale è sempre unimodale e simmetrico rispetto alla media \\(\\mu\\). Tuttavia, se le nostre conoscenze iniziali non sono simmetriche o non seguono una distribuzione unimodale, la scelta di una distribuzione a priori normale potrebbe non risultare la più adeguata (Johnson et al., 2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#esercizi",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "44.6 Esercizi",
    "text": "44.6 Esercizi\n\nEsercizio 44.1 Si consideri lo studio “An excess of positive results: Comparing the standard psychology literature with registered reports” di Scheel et al. (2021). In questo lavoro, gli autori confrontano il tasso di risultati positivi \\(\\theta\\) ottenuti in studi psicologici pubblicati senza preregistrazione con quelli pubblicati con preregistrazione. Si utilizzi il tasso di successo riportato negli studi preregistrati per costruire una distribuzione a priori per il parametro \\(\\theta\\).\nSecondo i risultati degli studi preregistrati, gli autori riscontrano un tasso di successo del 43.66%, con un intervallo di confidenza al 95% [CI] = [31.91, 55.95]. Sulla base di questi dati, si costruisca una distribuzione beta come distribuzione a priori per \\(\\theta\\), seguendo il metodo illustrato da Johnson et al. (2022).\nSuccessivamente, utilizzando questa distribuzione beta come distribuzione a priori, si determini la distribuzione a posteriori utilizzando il metodo delle famiglie coniugate per due scenari distinti, basati su 152 studi osservati: (a) Un tasso di successo del 60% (b) Un tasso di successo del 96% (come riportato per gli studi non preregistrati da Scheel et al. (2021)).\nInfine, si commentino i risultati derivanti dall’analisi delle distribuzioni a posteriori ottenute per entrambi gli scenari.\n\n\nEsercizio 44.2 Tra i fattori che possono influenzare il rapporto tra i sessi alla nascita c’è la condizione materna di placenta previa, una condizione insolita della gravidanza in cui la placenta è impiantata in basso nell’utero, impedendo un normale parto vaginale del feto. Uno studio condotto in Germania ha esaminato il sesso dei neonati in casi di placenta previa e ha riscontrato che, su un totale di 980 nascite, 437 erano femmine.\nQuanta evidenza fornisce questo studio a supporto dell’ipotesi che la proporzione di nascite femminili nella popolazione di placenta previa sia inferiore a 0.485, che rappresenta la proporzione di nascite femminili nella popolazione generale? (Esercizio tratto da Gelman et al. (1995))\n\n\nEsercizio 44.3 Per valutare la sensibilità della soluzione precedente alla scelta della distribuzione a priori, ripetere l’esercizio utilizzando come distribuzione a priori per la proporzione di nascite femminili una distribuzione Beta(48.5, 51.5). Questa distribuzione è centrata su 0.485 e concentra la maggior parte della sua massa nell’intervallo [0.385, 0.585]. Interpretare i risultati ottenuti.\n\n\nEsercizio 44.4 In uno studio recente, Gori et al. (2024) hanno esaminato un campione di 202 adulti italiani e hanno riscontrato una prevalenza di mancini del 6.4%. Una meta-analisi di Papadatou-Pastou et al. (2020), condotta su un totale di 2,396,170 soggetti, riporta che la proporzione di mancini varia tra il 9.3% e il 18.1%, a seconda di come viene misurata la lateralità manuale. Inoltre, Papadatou-Pastou et al. (2020) mostrano che la prevalenza della lateralità manuale varia tra i paesi e nel tempo. Considerata questa incertezza, si determini la distribuzione a posteriori che combina i dati dello studio di Gori et al. (2024) con le informazioni pregresse fornite da Papadatou-Pastou et al. (2020). Le informazioni di Papadatou-Pastou et al. (2020) possono essere espresse in termini di una distribuzione Beta(8, 60).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/05_conjugate_families_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "44  Distribuzioni coniugate (1)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Distribuzioni coniugate (1)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html",
    "title": "45  Distribuzioni coniugate (2)",
    "section": "",
    "text": "Introduzione\nLa statistica bayesiana ci permette di aggiornare le nostre credenze iniziali o conoscenze a priori sulla distribuzione di un parametro (in questo caso, la media della popolazione) in base ai dati osservati. Questo processo di aggiornamento ci porta a ottenere una distribuzione a posteriori che riflette una nuova comprensione del parametro, integrata con le informazioni fornite dal campione.\nIl concetto fondamentale è che, attraverso l’aggiornamento bayesiano, l’incertezza sulla stima del parametro si riduce. Questo è dovuto al fatto che l’informazione aggiuntiva fornita dai dati osservati consente di “restringere” la distribuzione a posteriori rispetto alla distribuzione a priori, riducendo così la varianza (o deviazione standard) della distribuzione del parametro di interesse.\nIn questo capitolo, approfondiremo il tema delle {ref}distr-coniugate-1-notebook, focalizzandoci sul modello normale-normale. Una caratteristica distintiva di questo modello è la sua capacità di auto-coniugazione rispetto a una funzione di verosimiglianza gaussiana. In termini più semplici, se la funzione di verosimiglianza segue una distribuzione gaussiana, l’adozione di una distribuzione a priori gaussiana per la media garantisce che anche la distribuzione a posteriori mantenga la sua forma gaussiana.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#perché-usare-la-distribuzione-normale",
    "title": "45  Distribuzioni coniugate (2)",
    "section": "45.1 Perché Usare la Distribuzione Normale?",
    "text": "45.1 Perché Usare la Distribuzione Normale?\nSpesso, quando la distribuzione a posteriori è nota per essere unimodale e simmetrica, possiamo modellarla efficacemente con una distribuzione normale, anche se sappiamo che la sua forma è solo approssimativamente normale. Nei casi in cui il ricercatore abbia un’idea approssimativa di dove sia centrato un parametro sconosciuto, la distribuzione normale fornisce un metodo utile per modellare questa stima, permettendo di descrivere il livello di incertezza tramite il termine di varianza della distribuzione normale. Questa convenienza può offrire buone approssimazioni alla densità a posteriori desiderata, con la consapevolezza che, con l’aumentare dei dati osservati, tali assunzioni perdono di importanza.\nCome dimostrato di seguito, il modello normale bayesiano possiede proprietà frequentiste desiderabili. Sebbene l’enfasi nell’analisi bayesiana non sia sulle stime puntuali, si può dimostrare che, con campioni sempre più grandi, la media della distribuzione a posteriori bayesiana si avvicina alla stima di massima verosimiglianza. Questa proprietà esiste perché la distribuzione a posteriori è un compromesso ponderato tra la distribuzione a priori specificata dall’utente, che in questo capitolo è normale, e la funzione di verosimiglianza derivata dai dati, anch’essa normale in questo capitolo. Con l’aumentare delle dimensioni del campione, la verosimiglianza diventa sempre più dominante in questa ponderazione.\nNel caso di una media normale, illustrato qui, la varianza della distribuzione di campionamento frequentista diminuisce con l’aumento della dimensione del campione. Nel contesto bayesiano, la riduzione della varianza media dalla funzione di verosimiglianza alla fine prevale anche su una varianza a priori deliberatamente grande. Pertanto, se si prevede che la dimensione del dataset sia grande, i ricercatori possono permettersi di essere liberali nella specificazione della varianza a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#distribuzione-a-posteriori-in-un-contesto-normale-con-varianza-nota",
    "title": "45  Distribuzioni coniugate (2)",
    "section": "45.2 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota",
    "text": "45.2 Distribuzione a Posteriori in un Contesto Normale con Varianza Nota\nConsideriamo un insieme di dati \\(y = [y_1, y_2, \\ldots, y_n]\\), composto da \\(n\\) osservazioni indipendenti e identicamente distribuite (i.i.d.) secondo una distribuzione normale \\(\\mathcal{N}(\\mu, \\sigma^2)\\). In questo scenario, il nostro obiettivo è stimare il valore del parametro \\(\\mu\\), che rappresenta la media della popolazione da cui provengono i dati.\n\n45.2.1 Distribuzione a Priori\nNell’approccio bayesiano, assumiamo una conoscenza iniziale sul parametro \\(\\mu\\) mediante una distribuzione a priori. In questo caso, utilizziamo una distribuzione normale coniugata, ovvero una distribuzione normale con media \\(\\mu_0\\) e varianza \\(\\sigma_0^2\\). Questa scelta riflette la nostra incertezza iniziale su \\(\\mu\\).\n\n\n45.2.2 Funzione di Verosimiglianza\nLa funzione di verosimiglianza, denotata da \\(p(y | \\mu, \\sigma)\\), rappresenta la probabilità di osservare i dati \\(y\\) dato il valore del parametro \\(\\mu\\) e la varianza nota \\(\\sigma^2\\). Per una distribuzione normale i.i.d., la funzione di verosimiglianza è data da:\n\\[\np(y | \\mu, \\sigma) = \\prod_{i=1}^n \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2\\sigma^2}\\right).\n\\]\n\n\n45.2.3 Teorema di Bayes e Distribuzione a Posteriori\nIl teorema di Bayes combina la distribuzione a priori con la funzione di verosimiglianza per ottenere la distribuzione a posteriori del parametro \\(\\mu\\), data l’evidenza osservata \\(y\\):\n\\[\np(\\mu | y) = \\frac{ p(y | \\mu) p(\\mu) }{ p(y) }.\n\\]\nPoiché la distribuzione a priori e la funzione di verosimiglianza sono entrambe distribuzioni normali, la distribuzione a posteriori risulterà anch’essa una distribuzione normale con media a posteriori \\(\\mu_p\\) e varianza a posteriori \\(\\sigma_p^2\\).\n\n\n45.2.4 Formula per la Media a Posteriori (\\(\\mu_p\\))\nLa media a posteriori \\(\\mu_p\\) rappresenta la stima aggiornata del parametro \\(\\mu\\) alla luce delle informazioni contenute nei dati osservati. La sua formula è:\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2} \\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}},\n\\]\ndove \\(\\bar{y}\\) rappresenta la media campionaria:\n\\[\n\\bar{y} = \\frac{\\sum_{i=1}^n y_i}{n}.\n\\]\nOsserviamo che \\(\\mu_p\\) è una combinazione ponderata tra la media a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\). Il peso di \\(\\bar{y}\\) aumenta con il numero di osservazioni \\(n\\), mentre il peso di \\(\\mu_0\\) diminuisce. Questo riflette il fatto che con più dati, la nostra fiducia nella media campionaria cresce, mentre l’incertezza a priori diminuisce.\n\n\n45.2.5 Formula per la Varianza a Posteriori (\\(\\sigma_p^2\\))\nLa varianza a posteriori \\(\\sigma_p^2\\) rappresenta l’incertezza residua sulla stima del parametro \\(\\mu\\) dopo aver incorporato le informazioni dai dati. La sua formula è:\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac{1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}.\n\\]\nRispetto alla varianza a priori \\(\\sigma_0^2\\), la varianza a posteriori \\(\\sigma_p^2\\) è sempre inferiore o uguale. In altre parole, l’incertezza sulla stima di \\(\\mu\\) si riduce con l’aumentare del numero di osservazioni. La varianza a posteriori rappresenta un bilanciamento tra l’incertezza a priori (\\(\\sigma_0^2\\)) e l’informazione derivata dai dati (\\(\\sigma^2/n\\)).\nIn sintesi, nel caso normale-normale con varianza nota, la distribuzione a posteriori risulta essere una distribuzione normale con una media e una varianza che riflettono un’integrazione bilanciata tra l’informazione a priori e quella ottenuta dai dati osservati. Questo approccio garantisce una stima aggiornata e affinata del parametro \\(\\mu\\) che migliora con l’aumento del numero di osservazioni.\n\nEsempio 45.1 I test standard di QI sono progettati per misurare l’intelligenza con una media di 100 e una deviazione standard di 15. Tuttavia, si dice anche che questi test presentino bias culturali che favoriscono alcuni gruppi rispetto ad altri. Un’ulteriore complicazione si verifica quando i punteggi di QI vengono aggregati a livello nazionale, poiché le caratteristiche interne ai paesi vengono mascherate. Questo esempio analizza i dati di QI raccolti a livello internazionale (Lynn e Vanhanen, 2001) per 80 paesi da fonti nazionali pubblicate e discussi da Gill (2015). L’idea chiave nella descrizione della distribuzione a posteriori è se le differenze tra le nazioni alterano la parametrizzazione prevista.\nI dati di Lynn e Vanhanen (2001) sono forniti di seguito:\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\nPaese\nIQ\n\n\n\n\nArgentina\n96\nAustralia\n98\nAustria\n102\nBarbados\n78\n\n\nBelgium\n100\nBrazil\n87\nBulgaria\n93\nCanada\n97\n\n\nChina\n100\nCongo (Br.)\n73\nCongo (Zr.)\n65\nCroatia\n90\n\n\nCuba\n85\nCzech Repub.\n97\nDenmark\n98\nEcuador\n80\n\n\nEgypt\n83\nEq. Guinea\n59\nEthiopia\n63\nFiji\n84\n\n\nFinland\n97\nFrance\n98\nGermany\n102\nGhana\n71\n\n\nGreece\n92\nGuatemala\n79\nGuinea\n66\nHong Kong\n107\n\n\nHungary\n99\nIndia\n81\nIndonesia\n89\nIran\n84\n\n\nIraq\n87\nIreland\n93\nIsrael\n94\nItaly\n102\n\n\nJamaica\n72\nJapan\n105\nKenya\n72\nKorea (S.)\n106\n\n\nLebanon\n86\nMalaysia\n92\nMarshall I.\n84\nMexico\n87\n\n\nMorocco\n85\nNepal\n78\nNetherlands\n102\nNew Zealand\n100\n\n\nNigeria\n67\nNorway\n98\nPeru\n90\nPhilippines\n86\n\n\nPoland\n99\nPortugal\n95\nPuerto Rico\n84\nQatar\n78\n\n\nRomania\n94\nRussia\n96\nSamoa\n87\nSierra Leone\n64\n\n\nSingapore\n103\nSlovakia\n96\nSlovenia\n95\nSouth Africa\n72\n\n\nSpain\n97\nSudan\n72\nSuriname\n89\nSweden\n101\n\n\nSwitzerland\n101\nTaiwan\n104\nTanzania\n72\nThailand\n91\n\n\nTonga\n87\nTurkey\n90\nUganda\n73\nU.K.\n100\n\n\nU.S.\n98\nUruguay\n96\nZambia\n77\nZimbabwe\n66\n\n\n\nImplementiamo le informazioni necessarie in Python.\n\n# Dati IQ delle 80 nazioni\niq = np.array(\n    [\n        96,\n        100,\n        100,\n        85,\n        83,\n        97,\n        92,\n        99,\n        87,\n        72,\n        86,\n        85,\n        67,\n        99,\n        94,\n        103,\n        97,\n        101,\n        87,\n        98,\n        87,\n        73,\n        97,\n        59,\n        98,\n        79,\n        81,\n        93,\n        105,\n        92,\n        78,\n        98,\n        95,\n        96,\n        72,\n        104,\n        90,\n        96,\n        98,\n        102,\n        78,\n        90,\n        63,\n        84,\n        84,\n        107,\n        86,\n        102,\n        106,\n        94,\n        102,\n        72,\n        101,\n        89,\n        72,\n        101,\n        91,\n        100,\n        100,\n        66,\n        107,\n        86,\n        78,\n        84,\n        78,\n        64,\n        72,\n        101,\n        91,\n        100,\n        67,\n        86,\n    ]\n)\n\n\n# Numero di osservazioni\nn = len(iq)\n\n# Media campionaria\ny_bar = np.mean(iq)\n\n# Deviazione standard nota\nsigma = 15\n\n# Parametri a priori\nmu_0 = 100\nsigma_0 = 15\n\nCalcoliamo la media a posteriori con la formula discussa in precedenza\n\\[\n\\mu_p = \\frac{\\frac{1}{\\sigma_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\sigma_0^2} + \\frac{n}{\\sigma^2}}\n\\]\ndove:\n\n\\(\\mu_0\\) è la media a priori\n\\(\\sigma_0\\) è la deviazione standard a priori\n\\(n\\) è il numero di osservazioni\n\\(\\sigma\\) è la deviazione standard delle osservazioni (nota)\n\\(\\bar{y}\\) è la media campionaria\n\n\nmu_p = ((1 / sigma_0**2) * mu_0 + (n / sigma**2) * y_bar) / (\n    (1 / sigma_0**2) + (n / sigma**2)\n)\nprint(f\"Media a posteriori (mu_p): {mu_p}\")\n\nMedia a posteriori (mu_p): 89.35616438356165\n\n\nCalcoliamo la varianza a posteriori\n\\[\n\\sigma_p^2 = \\frac{1}{\\frac {1}{\\sigma_0^2}+ \\frac{n}{\\sigma^2}}\n\\]\n\nsigma_p_sq = 1 / ((1 / sigma_0**2) + (n / sigma**2))\nprint(f\"Varianza a posteriori (sigma_p_sq): {sigma_p_sq}\")\n\nVarianza a posteriori (sigma_p_sq): 3.082191780821918\n\n\nGeneriamo una rappresentazione grafica della distribuzione a posteriori della media del IQ sulla base dei dati osservati, avendo assunto mu_0 = 100 e sigma_0 = 15 per la distribuzione a priori.\n\nsigma_p = np.sqrt(sigma_p_sq)\n\n# Definizione dei valori sull'asse x\nx = np.linspace(mu_p - 4 * sigma_p, mu_p + 4 * sigma_p, 1000)\n\n# Calcolo della densità di probabilità\npdf = stats.norm.pdf(x, mu_p, sigma_p)\n\n# Creazione del grafico\nplt.plot(x, pdf, label=f\"N({mu_p:.2f}, {sigma_p:.2f})\", color=\"blue\")\nplt.fill_between(x, pdf, color=\"blue\", alpha=0.2)\nplt.title(\"Distribuzione a Posteriori\")\nplt.xlabel(\"Media del Quoziente di Intelligenza\")\nplt.ylabel(\"Densità di probabilità\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nL’analisi condotta mediante un modello bayesiano basato sulla distribuzione normale ha prodotto un risultato interessante: la media stimata della distribuzione a posteriori del QI si attesta a 89.36, un valore sensibilmente inferiore ai 100 punti previsti come media standard.\nTuttavia, per un’interpretazione completa di questo dato, è fondamentale adottare un approccio critico che consideri alcuni aspetti cruciali:\n\nLa media a posteriori è ottenuta aggregando i dati QI di 80 nazioni diverse. Questo processo può innescare un effetto di aggregazione, dove la media “smussata” risultante non rispecchia accuratamente la distribuzione del QI a livello individuale in ogni singola nazione. Di conseguenza, le differenze tra le nazioni in termini di QI medio e variabilità potrebbero essere mascherate da questa media aggregata.\nÈ importante sottolineare che la media a posteriori viene calcolata utilizzando dati non ponderati per ogni nazione. Ciò significa che nazioni con popolazioni più piccole, anche se con punteggi QI mediamente più alti o più bassi, hanno lo stesso impatto sulla media aggregata rispetto a nazioni con popolazioni più grandi. Questo aspetto potrebbe ulteriormente distorcere la rappresentazione della vera distribuzione globale del QI.\nLa deviazione osservata dalla media standard di 100 potrebbe non riflettere esclusivamente differenze nell’intelligenza media tra le nazioni, ma anche differenze nei contesti sanitari, sociologici e politici in cui i test sono stati somministrati. Fattori quali l’accesso all’istruzione, la qualità della nutrizione e l’esposizione a stimoli cognitivi possono influenzare i punteggi QI ottenuti e contribuire alla variabilità osservata tra le nazioni.\nInoltre, è fondamentale considerare la possibilità di un bias culturale intrinseco allo strumento stesso. I test del QI sono stati originariamente progettati per un contesto specifico (paese industrializzato di lingua inglese) e potrebbero non essere adatti o culturalmente sensibili a contesti differenti. Questo potrebbe portare a una sottostima dei punteggi QI in alcune nazioni e influenzare la media a posteriori aggregata.\n\nQuesti risultati evidenziano l’importanza di un’attenta considerazione dei fattori metodologici quando si interpretano dati di test del QI a livello trans-culturale. L’effetto di aggregazione, l’utilizzo di medie non ponderate, le differenze nei contesti e il potenziale bias culturale richiedono un’analisi più approfondita che consideri questi fattori e utilizzi metodi statistici più sofisticati per ottenere una comprensione più completa delle differenze nel QI tra le nazioni.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#riflessioni-conclusive",
    "title": "45  Distribuzioni coniugate (2)",
    "section": "45.3 Riflessioni Conclusive",
    "text": "45.3 Riflessioni Conclusive\nIn questa sezione, abbiamo approfondito il meccanismo dell’aggiornamento bayesiano attraverso l’implementazione del modello normale-normale.\nIl processo inizia definendo una distribuzione a priori per \\(\\mu\\), specificata da una media \\(\\mu_0\\) e una varianza \\(\\sigma_0^2\\). Dopo l’acquisizione di nuovi dati, ipotizzando che seguano una distribuzione Normale con media campionaria \\(\\bar{y}\\) e varianza nota \\(\\sigma^2\\), implementiamo il teorema normale-normale per derivare la distribuzione a posteriori del parametro.\nLa media della distribuzione a posteriori, denotata come \\(\\mu_{\\text{post}}\\), si configura come una media ponderata tra la media a priori $ _0 $ e la media campionaria \\(\\bar{y}\\), dove il peso assegnato a ciascuna media è determinato dalle rispettive varianze \\(\\sigma_0^2\\) e \\(\\sigma^2\\) della distribuzione a priori e dei dati osservati. Analogamente, la varianza a posteriori \\(\\sigma_{\\text{post}}^2\\) è determinata utilizzando un’espressione che incorpora entrambe le varianze.\nIn sintesi, l’adozione del modello normale-normale in un contesto bayesiano facilita il calcolo delle distribuzioni a posteriori, grazie alla scelta di una distribuzione a priori Normale che mantiene la proprietà di coniugatezza, semplificando così l’intero processo analitico.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/06_conjugate_families_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "45  Distribuzioni coniugate (2)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.8.4\nscipy     : 1.13.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences approach (3rd Edition). Chapman; Hall/CRC.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Distribuzioni coniugate (2)</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html",
    "href": "chapters/bayesian_inference/07_summary_posterior.html",
    "title": "46  Sintesi a posteriori",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, concentriamo la nostra attenzione sulla sintesi dell’informazione racchiusa nella distribuzione a posteriori, la quale rappresenta il nostro livello di incertezza riguardo al parametro o ai parametri incogniti oggetto dell’inferenza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riepilogo-numerico",
    "title": "46  Sintesi a posteriori",
    "section": "46.1 Riepilogo numerico",
    "text": "46.1 Riepilogo numerico\nLa distribuzione a posteriori contiene in sé tutte le informazioni disponibili sui potenziali valori del parametro. Nel caso di un parametro unidimensionale o bidimensionale, possiamo rappresentare la distribuzione a posteriori mediante un grafico \\(p(\\theta \\mid y)\\).\nTuttavia, quando ci troviamo di fronte a vettori di parametri con più di due dimensioni, risulta vantaggioso eseguire una sintesi numerica della distribuzione a posteriori. Possiamo distinguere due forme di sintesi numerica della distribuzione a posteriori:\n\nStima puntuale;\nIntervallo di credibilità.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#stima-puntuale",
    "title": "46  Sintesi a posteriori",
    "section": "46.2 Stima puntuale",
    "text": "46.2 Stima puntuale\nNel contesto dell’inferenza bayesiana, il processo di stima del valore più credibile del parametro \\(\\theta\\) tramite la distribuzione a posteriori si avvale di tre statistiche: la moda, la mediana e la media, la cui scelta è guidata dalla forma della distribuzione a posteriori. Queste statistiche sono utilizzate per ottenere una stima puntuale della tendenza centrale della distribuzione a posteriori, che a sua volta fornisce il “valore più credibile” del parametro. Questo valore rappresenta la stima a cui attribuiamo il massimo grado di fiducia soggettiva, basandoci sui dati osservati e sulle nostre credenze a priori.\n\nModa (Massimo a posteriori, MAP): La moda rappresenta il valore più probabile di un parametro, ovvero quello che massimizza la distribuzione a posteriori. Questo valore è noto come “massimo a posteriori” (MAP). La stima MAP prende origine dalla stima di massima verosimiglianza (MLE), che cerca il valore di \\(\\theta\\), denotato come \\(\\hat{\\theta}_{ML}\\), che massimizza la funzione di verosimiglianza \\(L(\\theta \\mid y)\\):\n\\[ \\hat{\\theta}_{ML} = \\arg \\max_\\theta L(\\theta \\mid y). \\]\nNell’inferenza bayesiana, \\(\\theta\\) è considerato una variabile casuale, e si specifica una distribuzione a priori su \\(\\theta\\) per riflettere l’incertezza sul suo valore. Integrando l’informazione a priori nella funzione di verosimiglianza, si ottiene la formula per la stima MAP:\n\\[ \\hat{\\theta}_{MAP} = \\arg \\max_\\theta L(\\theta \\mid y)p(\\theta). \\]\nQuesta formula evidenzia che la stima MAP corrisponde al valore che massimizza la densità a posteriori di \\(\\theta\\) dati i dati osservati \\(y\\), ovvero il valore che rappresenta la moda della distribuzione a posteriori.\nSebbene il concetto di MAP sia intuitivo, presenta diversi problemi che ne limitano l’uso nella pratica.\nLa prima difficoltà è di tipo computazionale: con i metodi MCMC comunemente utilizzati per stimare le distribuzioni a posteriori, è molto difficile individuare con precisione la posizione esatta del MAP nello spazio delle distribuzioni posteriori.\nIl secondo problema è legato all’uso dell’inferenza bayesiana in modelli complessi e in situazioni non asintotiche. In questi casi, la verosimiglianza o la distribuzione a posteriori possono avere forme irregolari o non normali. Se la distribuzione a posteriori è molto asimmetrica, il MAP potrebbe non rappresentare adeguatamente dove si concentra la maggior parte della probabilità. Di conseguenza, il MAP non sempre fornisce un’idea accurata del comportamento complessivo della distribuzione a posteriori.\nMedia a posteriori: La media a posteriori è il valore atteso del parametro \\(\\theta\\), calcolato sulla base della distribuzione a posteriori. In termini matematici, nel caso continuo, è espressa dalla formula:\n\\[ E(\\theta \\mid y) = \\int_{-\\infty}^{\\infty} \\theta \\, p(\\theta \\mid y) \\, d\\theta. \\]\nMediana: La mediana è il valore del parametro per cui il 50% della massa di probabilità a posteriori si distribuisce equamente a sinistra e a destra. È una misura robusta della tendenza centrale, particolarmente utile in presenza di distribuzioni asimmetriche o multimodali, dove la moda potrebbe non fornire una stima accurata del valore più probabile del parametro.\n\nPer valutare l’incertezza associata al parametro \\(\\theta\\), è utile calcolare la varianza a posteriori. Questa varianza è basata sulla tendenza centrale definita dalla media a posteriori, e la sua radice quadrata fornisce la deviazione standard a posteriori, che misura l’incertezza a posteriori relativa a \\(\\theta\\), espressa nelle stesse unità di misura dei dati. La formula per la varianza a posteriori è data da:\n\\[\nV(\\theta|y) = E[((\\theta - E[(\\theta|y)])^2 |y) = \\int_{-\\infty}^{\\infty} (\\theta - E[\\theta | y])^2 p(\\theta | y) d\\theta = E[\\theta^2 |y] - E[\\theta|y]^2.\n\\]\nIn sintesi, la media, la moda e la mediana a posteriori, insieme alla varianza a posteriori, forniscono una descrizione comprensiva del comportamento della distribuzione a posteriori di \\(\\theta\\), permettendoci di derivare stime puntuali e misurare l’incertezza associata a \\(\\theta\\) in modo informativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilità",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#intervallo-di-credibilità",
    "title": "46  Sintesi a posteriori",
    "section": "46.3 Intervallo di credibilità",
    "text": "46.3 Intervallo di credibilità\nNell’inferenza bayesiana, l’intervallo di credibilità è uno strumento utilizzato per definire un intervallo che contiene una determinata percentuale della massa della distribuzione a posteriori del parametro \\(\\theta\\). Questo intervallo riflette l’incertezza associata alla stima del parametro: un intervallo più ampio suggerisce una maggiore incertezza. Lo scopo principale dell’intervallo di credibilità è fornire una misura quantitativa dell’incertezza riguardante \\(\\theta\\).\nA differenza degli intervalli di confidenza frequentisti, non esiste un unico intervallo di credibilità per un dato livello di confidenza \\((1 - \\alpha) \\cdot 100\\%\\). In effetti, è possibile costruire un numero infinito di tali intervalli. Per questo motivo, è necessario stabilire criteri aggiuntivi per selezionare l’intervallo di credibilità più appropriato. Tra le opzioni più comuni ci sono l’intervallo di credibilità simmetrico e l’intervallo di massima densità posteriore (HPD).\n\nIntervallo di Credibilità Simmetrico: Questo tipo di intervallo è centrato rispetto al punto di stima puntuale. Se \\(\\hat{\\theta}\\) rappresenta la stima del parametro, l’intervallo simmetrico avrà la forma \\((\\hat{\\theta} - a, \\hat{\\theta} + a)\\), dove \\(a\\) è un valore positivo scelto in modo tale che la massa totale inclusa sia pari a \\((1 - \\alpha)\\). Più formalmente, un intervallo di credibilità simmetrico al livello \\(\\alpha\\) può essere espresso come:\n\\[ I_{\\alpha} = [q_{\\alpha/2}, q_{1 - \\alpha/2}], \\]\ndove \\(q_z\\) rappresenta il quantile \\(z\\) della distribuzione a posteriori. Ad esempio, un intervallo di credibilità simmetrico al 94% sarà:\n\\[ I_{0.06} = [q_{0.03}, q_{0.97}], \\]\ndove il 3% della massa a posteriori si trova in ciascuna delle due code della distribuzione.\nIntervallo di Credibilità Più Stretto (Intervallo di Massima Densità Posteriore, HPD): L’intervallo di massima densità posteriore (HPD) è l’intervallo più stretto possibile che contiene il \\((1 - \\alpha) \\cdot 100\\%\\) della massa a posteriori. A differenza dell’intervallo simmetrico, l’HPD include tutti i valori di \\(\\theta\\) che hanno la maggiore densità a posteriori. Per costruirlo, si disegna una linea orizzontale sulla distribuzione a posteriori e si regola l’altezza della linea in modo che l’area sotto la curva corrisponda a \\((1 - \\alpha)\\). L’HPD risulta essere il più stretto tra tutti gli intervalli possibili per lo stesso livello di confidenza. Nel caso di una distribuzione a posteriori unimodale e simmetrica, l’HPD coincide con l’intervallo di credibilità simmetrico.\n\n\n46.3.1 Interpretazione\nIl calcolo degli intervalli di credibilità, in particolare dell’intervallo di massima densità posteriore (HPD), richiede spesso l’uso di software statistici avanzati. Questo perché determinare manualmente tali intervalli può essere complicato, soprattutto nei modelli bayesiani con distribuzioni posteriori complesse o quando sono necessarie simulazioni numeriche per stimare la distribuzione a posteriori.\nUn aspetto cruciale dell’inferenza bayesiana riguarda l’interpretazione dell’incertezza. Nel contesto frequentista, si considera il parametro, come ad esempio la media della popolazione \\(\\mu\\), come un valore fisso ma sconosciuto. L’inferenza frequentista si basa sull’immaginare un numero infinito di campioni ripetuti dalla popolazione. Per ogni campione, si può calcolare una media campionaria \\(\\bar{x}\\) e formare un intervallo di confidenza al \\(100(1-\\alpha)\\%\\). L’interpretazione corretta in termini frequentisti è che, nel lungo periodo, il \\(100(1-\\alpha)\\%\\) degli intervalli di confidenza costruiti con questo metodo conterrà il vero valore del parametro \\(\\mu\\). Tuttavia, per un singolo intervallo calcolato, la probabilità che contenga effettivamente \\(\\mu\\) è o 0 o 1, poiché \\(\\mu\\) è considerato un valore fisso.\nNel framework bayesiano, invece, il parametro è trattato come una variabile aleatoria con una distribuzione di probabilità. Campionando dalla distribuzione a posteriori dei parametri, possiamo ottenere quantili che ci permettono di calcolare direttamente la probabilità che un parametro rientri in un determinato intervallo. Ad esempio, un intervallo di credibilità al 95% indica che c’è una probabilità del 95% che il parametro sia contenuto all’interno di quell’intervallo, data l’evidenza osservata. Questa interpretazione differisce profondamente da quella frequentista e risulta più intuitiva, poiché riflette direttamente il grado di incertezza che abbiamo riguardo al parametro.\nIn sintesi, mentre l’intervallo di confidenza frequentista riguarda la ripetizione ipotetica del campionamento, l’intervallo di credibilità bayesiano fornisce una misura diretta dell’incertezza attuale sul valore di un parametro, basata sui dati osservati e sulle informazioni a priori. Questo approccio è spesso considerato più vicino al senso comune quando si tratta di interpretare la probabilità associata ai parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "46  Sintesi a posteriori",
    "section": "46.4 Verifica di ipotesi bayesiana",
    "text": "46.4 Verifica di ipotesi bayesiana\nL’inferenza bayesiana può essere applicata anche nel contesto della verifica di ipotesi, in un approccio noto come verifica di ipotesi bayesiana. In questo tipo di inferenza, l’obiettivo è valutare la plausibilità che un parametro \\(\\theta\\) assuma valori all’interno di un determinato intervallo. Ad esempio, possiamo voler sapere quanto è probabile che \\(\\theta\\) sia maggiore di 0.5 o che rientri in un intervallo specifico, come [0.5, 1.0].\nIn questo approccio, si calcola la probabilità a posteriori che \\(\\theta\\) si trovi all’interno dell’intervallo di interesse. Questa probabilità viene ottenuta integrando la distribuzione a posteriori su tale intervallo. Quindi, invece di rifiutare o accettare un’ipotesi come nel test di ipotesi frequentista, la verifica di ipotesi bayesiana fornisce una misura diretta della probabilità che un parametro rientri in un intervallo specifico, dato l’evidenza osservata e le informazioni a priori.\nIn altre parole, questo approccio consente di quantificare la nostra incertezza rispetto all’affermazione che \\(\\theta\\) rientri in un certo intervallo, fornendo una probabilità che rappresenta direttamente la plausibilità di quell’ipotesi.\n\nEsempio 46.1 Per comprendere meglio attraverso un esempio pratico, esaminiamo i dati relativi ai punteggi del BDI-II (Beck Depression Inventory - Second Edition) di 30 soggetti clinici, come riportato nello studio condotto da Zetsche et al. (2019). Il BDI-II è un questionario utilizzato per valutare la gravità dei sintomi depressivi.\n\nbdi = np.array([\n    26,\n    35,\n    30,\n    25,\n    44,\n    30,\n    33,\n    43,\n    22,\n    43,\n    24,\n    19,\n    39,\n    31,\n    25,\n    28,\n    35,\n    30,\n    26,\n    31,\n    41,\n    36,\n    26,\n    35,\n    33,\n    28,\n    27,\n    34,\n    27,\n    22,\n])\nprint(*bdi)\n\n26 35 30 25 44 30 33 43 22 43 24 19 39 31 25 28 35 30 26 31 41 36 26 35 33 28 27 34 27 22\n\n\nUn valore BDI-II \\(\\geq 30\\) indica la presenza di un livello grave di depressione. Nel campione clinico di {cite:t}zetsche_2019future, 17 pazienti su 30 manifestano un livello grave di depressione.\n\nnp.sum(bdi &gt;= 30)\n\n17\n\n\nSupponiamo di volere stimare la distribuzione a posteriori della probabilità \\(\\theta\\) di depressione grave nei pazienti clinici, così come viene misurata dal test BDI-II, imponendo su \\(\\theta\\) una distribuzione a priori \\(Beta(8, 2)\\).\nPoiché i dati possono essere concepiti come una sequenza di prove Bernoulliane indipendenti, laddove la presenza di depressione grave viene concepita come un “successo”, la verosimiglianza sarà Binomiale con paramentri \\(n\\) = 30 e \\(y\\) = 17.\nAvendo scelto, quale distribuzione a priori, una \\(Beta(8, 2)\\), la distribuzione a posteriori di \\(\\theta\\) sarà una \\(Beta(8 + 17, 2 + 30 - 17)\\):\n\\[\nf(\\theta \\mid y = 17) = \\frac{\\Gamma(25 + 15)}{\\Gamma(25)\\Gamma(15)}\\theta^{25-1} (1-\\theta)^{15-1} \\;\\; \\text{ for } \\theta \\in [0,1] \\; .\n\\] (eq-post-beta-25-15)\n\ntheta = np.linspace(0, 1, 200)\nalpha = 25\nbeta = 15\npdf = stats.beta.pdf(theta, alpha, beta)\nplt.plot(theta, pdf, label=r\"$\\alpha$ = {}, $\\beta$ = {}\".format(alpha, beta))\nplt.xlabel(r\"$\\theta$\", fontsize=14)\nplt.ylabel(\"Densità di probabilità\", fontsize=14)\nplt.legend(loc=1)\nplt.show()\n\n\n\n\n\n\n\n\nVediamo ora come ottenere delle stime puntuali da tale distribuzione a posteriori.\nper il presente esempio, la media della distribuzione a posteriori di \\(\\theta\\) è\n\\[\n\\mathbb{E}(\\pi \\mid y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25+15} = 0.625.\n\\]\nUna stima del massimo della probabilità a posteriori, o brevemente massimo a posteriori, MAP (da maximum a posteriori probability), è la moda della distribuzione a posteriori. Nel caso presente, abbiamo\n\\[\nMo(\\pi \\mid y = 17) = \\frac{\\alpha-1}{\\alpha + \\beta-2} = \\frac{25-1}{25+15-2} = 0.6316.\n\\]\nLa mediana si ottiene con la funzione beta.ppf():\n\nstats.beta.ppf(0.5, alpha, beta)\n\n0.6271031100419254\n\n\nL’intervallo di credibilità simmetrico al 94% è dato dalla chiamata a beta.ppf().\n\n[stats.beta.ppf(0.03, alpha, beta), stats.beta.ppf(0.97, alpha, beta)]\n\n[0.4781025861696672, 0.7612890799836668]\n\n\nIl calcolo precedente evidenzia l’interpretazione intuitiva dell’intervallo di credibilità. Tale intervallo, infatti, può essere interpretato nel modo seguente: possiamo attribuire una certezza soggettiva del 94% all’evento che \\(\\theta\\) assuma un valore compreso tra 0.478 e 0.761. Il valore di 0.94 corrisponde infatti all’area sottesa dalla distribuzione a posteriori nell’intervallo \\[0.478, 0.761\\].\n\\[\nP(\\theta \\in (0.478, 0.761) \\mid Y = 17) = \\int_{0.478}^{0.761} f(\\theta \\mid y=17) d\\theta = 0.94.\n\\]\n\nbetacdf = stats.beta(alpha, beta).cdf\nbetacdf(0.7612890799836668) - betacdf(0.4781025861696672)\n\n0.9400000000000001\n\n\nPossiamo costruire vari intervalli di credibilità simmetrici. Ad esempio, l’intervallo di credibilità compreso tra il 25-esimo e il 75-esimo percentile:\n\n[stats.beta.ppf(0.25, alpha, beta), stats.beta.ppf(0.75, alpha, beta)]\n\n[0.5743877928498646, 0.6778673380880944]\n\n\nIn questo secondo caso, possiamo affermare con una certezza soggettiva del 50% che la probabilità di depressione grave tra i pazienti clinici si situa tra 0.57 e 0.68.\nNon esiste un livello “giusto” di credibilità soggettiva. I ricercatori adottano livelli differenti, come il 50%, l’80% o il 94%, a seconda del contesto dell’analisi statistica. Ogni intervallo offre una prospettiva unica sulla nostra comprensione della distribuzione a posteriori del parametro d’interesse.\nNon sempre è appropriato presentare un intervallo di credibilità con le stesse code. Quando la distribuzione a posteriori è marcatamente asimmetrica, risulta più adeguato fornire l’intervallo di credibilità più stretto (o Intervallo di Massima Densità Posteriore, HPD). L’intervallo HPD è più facilmente calcolabile quando si approssima la distribuzione a posteriori con il metodo MCMC.\nPassiamo ora alla verifica di ipotesi bayesiana. Supponiamo che la nostra ipotesi sia: \\(\\theta &gt;\\) 0.5. La credibilità soggettiva dell’evento \\(\\theta &gt; 0.5\\) può essere ottenuta calcolando il seguente integrale:\n\\[\nf(\\theta &gt; 0.5 \\; \\mid \\; y = 17) = \\int_{0.5}^{1}f(\\theta \\mid y=17)d\\theta \\;,\n\\]\ndove \\(f(\\cdot)\\) è la distribuzione Beta(25, 15).\nÈ facile trovare questo valore con Python.\n\n# Parametri della distribuzione Beta\nalpha = 25\nbeta = 15\n\n# Calcoliamo la probabilità P(theta &lt; 0.5) utilizzando la funzione cdf \nprobability = stats.beta.cdf(0.5, alpha, beta)\n\n# La probabilità P(theta &lt; 0.5) è data da 1 - P(theta &gt; 0.5)\nprobability_less_than_0_5 = 1 - probability\n\nprint(f\"La probabilità P(theta &lt; 0.5) per una Beta(25, 15) è: {probability_less_than_0_5:.4f}\")\n\nLa probabilità P(theta &lt; 0.5) per una Beta(25, 15) è: 0.9459",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#sintesi-della-distribuzione-a-posteriori-questioni-multivariate",
    "title": "46  Sintesi a posteriori",
    "section": "46.5 Sintesi della distribuzione a posteriori: questioni multivariate",
    "text": "46.5 Sintesi della distribuzione a posteriori: questioni multivariate\nQuando si affronta un’analisi bayesiana con più parametri, la complessità aumenta. Le principali difficoltà riguardano le interazioni tra i parametri e il modo in cui queste influenzano le distribuzioni marginali. Questi fattori possono complicare notevolmente la sintesi della distribuzione a posteriori e, se non considerati attentamente, possono portare a interpretazioni errate.\n\n46.5.1 Correlazioni nascoste e distribuzioni marginali\nUn problema comune nelle analisi con più parametri è rappresentato dalle correlazioni tra i parametri. Le distribuzioni marginali a posteriori, spesso riportate nei riassunti statistici, possono essere molto fuorvianti se considerate isolatamente. Quando i parametri sono fortemente correlati, le distribuzioni marginali possono apparire piatte o poco informative, inducendo a pensare che non ci sia molta informazione nella verosimiglianza.\nTuttavia, le correlazioni tra parametri possono restringere notevolmente lo spazio delle combinazioni plausibili, escludendo vaste aree dello spazio dei parametri. Questo significa che, nonostante le marginali possano sembrare non informative, l’analisi congiunta dei parametri può rivelare una struttura sottostante che riduce l’incertezza su specifiche combinazioni. Pertanto, è essenziale esaminare le correlazioni congiunte tra i parametri per ottenere una visione più completa dell’incertezza.\nCon un numero maggiore di parametri, anche i grafici di correlazione bidimensionali possono diventare limitati, poiché potrebbero esistere correlazioni di ordine superiore che non emergono in rappresentazioni a due dimensioni.\n\n\n46.5.2 Correlazioni non lineari\nUn’altra difficoltà significativa riguarda le correlazioni non lineari tra i parametri. Quando queste correlazioni sono presenti, il massimo delle distribuzioni marginali non coincide necessariamente con il massimo della distribuzione congiunta. Per esempio, se due parametri presentano una correlazione complessa, come una forma a “banana”, il massimo delle distribuzioni marginali potrebbe trovarsi in una posizione diversa rispetto al massimo globale della distribuzione congiunta.\nQuesto fenomeno rende più difficile sintetizzare correttamente la distribuzione a posteriori. In tali casi, la stima del massimo a posteriori (MAP) o altri riassunti, come gli intervalli di credibilità (CI) o gli intervalli di massima densità a posteriori (HPD), calcolati sulle marginali, potrebbero essere fuorvianti. Quando la distribuzione a posteriori è asimmetrica nello spazio multivariato, le distribuzioni marginali non catturano adeguatamente le relazioni tra i parametri. Questa è una fonte comune di confusione, poiché si tende a sottovalutare l’importanza della struttura multivariata nella distribuzione a posteriori.\n\n\n46.5.3 Strategie per affrontare queste sfide\n\nConfronto tra distribuzioni predittive:\n\nConfrontare la distribuzione predittiva a priori con quella a posteriori offre una visione più completa della riduzione dell’incertezza.\nQuesto approccio è particolarmente utile in presenza di parametri multipli e correlazioni complesse, poiché la distribuzione predittiva a posteriori incorpora le interazioni tra i parametri, fornendo una rappresentazione più accurata della plausibilità dei diversi valori parametrici.\n\nAnalisi congiunta:\n\nEsaminare le distribuzioni congiunte dei parametri, oltre alle distribuzioni marginali.\nUtilizzare grafici di dispersione bivariati o multivariati per visualizzare le relazioni tra i parametri.\nTecniche avanzate di visualizzazione, come i pair plots o le heatmap, possono essere utili per esplorare relazioni in spazi ad alta dimensionalità.\n\nMisure di dipendenza:\n\nUtilizzare misure di dipendenza non lineare, come la correlazione di Spearman o l’informazione mutua, che possono catturare relazioni complesse che le misure lineari tradizionali potrebbero non rilevare.\n\nAnalisi di sensibilità:\n\nCondurre un’analisi di sensibilità per valutare come i cambiamenti in un parametro influenzano gli altri parametri e le previsioni del modello. Questo permette di capire meglio le relazioni tra i parametri e il loro impatto sulle inferenze.\n\nTecniche di riduzione della dimensionalità:\n\nQuando ci sono molti parametri, l’uso di metodi come l’analisi delle componenti principali (PCA) o il t-SNE può aiutare a identificare strutture latenti e ridurre la complessità del problema, facilitando l’interpretazione dei risultati.\n\n\nIn sintesi, l’analisi multivariata in un contesto bayesiano richiede particolare attenzione nella sintesi delle distribuzioni a posteriori. Le distribuzioni marginali possono fornire informazioni utili, ma spesso nascondono importanti correlazioni e strutture di dipendenza tra i parametri. Un’analisi completa dovrebbe combinare l’esame delle marginali con una valutazione attenta delle relazioni congiunte tra i parametri, utilizzando tecniche di visualizzazione e misure di dipendenza adeguate. Questo approccio integrato permette di comprendere più a fondo la distribuzione a posteriori e di trarre inferenze più robuste e accurate.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#riflessioni-conclusive",
    "title": "46  Sintesi a posteriori",
    "section": "46.6 Riflessioni Conclusive",
    "text": "46.6 Riflessioni Conclusive\nIn conclusione, la distribuzione a posteriori rappresenta la nostra conoscenza aggiornata sui parametri sconosciuti. L’impiego delle statistiche descrittive e l’analisi degli intervalli di credibilità contribuiscono a tracciare un quadro completo della distribuzione a posteriori e delle nostre inferenze riguardo al parametro di interesse.\nLe stime puntuali, ottenute attraverso statistiche descrittive come media, mediana o moda a posteriori, offrono una singola valutazione numerica del parametro ignoto. Gli intervalli di credibilità forniscono un intervallo di valori all’interno del quale si ritiene, con un certo grado di probabilità soggettiva, che il parametro incognito possa rientrare. Questi intervalli quantificano l’incertezza associata al parametro e consentono di esprimere il livello di fiducia soggettiva riguardo ai possibili valori del parametro dopo l’analisi dei dati. Abbiamo inoltre esaminato il concetto di test di ipotesi bayesiano, il quale può essere condotto agevolmente calcolando l’area appropriata sotto la distribuzione a posteriori, in accordo con l’ipotesi in questione.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/07_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/07_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "46  Sintesi a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Mar 28 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.12.0\nnumpy     : 1.26.4\narviz     : 0.17.1\nsys       : 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:51:20) [Clang 16.0.6 ]\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: biased or realistic? Journal of Abnormal Psychology, 128(7), 678.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Sintesi a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Introduzione\nConsideriamo un semplice scenario medico: un paziente si presenta dal dottore con un mal di testa. Il medico, per formulare una diagnosi accurata, dovrà considerare diversi fattori. Possiamo immaginare due medici con approcci leggermente differenti:\nQuale dei due medici è in grado di fornire una diagnosi più precisa? La risposta risiede nel concetto di probabilità a priori (o semplicemente prior), ovvero le credenze che un individuo ha su un evento prima di osservare nuovi dati.\nNel contesto medico, la storia clinica del paziente rappresenta una preziosa fonte di informazioni a priori. Conoscere gli antecedenti sanitari di un individuo permette al medico di formulare ipotesi più plausibili sulla causa del mal di testa. In termini bayesiani, i priori agiscono come una sorta di “lente” attraverso cui vengono interpretati i nuovi dati (in questo caso, i risultati dei test).\nQuando prendiamo decisioni nella vita quotidiana, utilizziamo costantemente le nostre conoscenze pregresse per interpretare nuove informazioni. Ad esempio, se vediamo una persona che indossa un camice bianco in un ospedale, inferiamo che si tratti di un medico, basandoci sulla nostra esperienza e sulle associazioni mentali che abbiamo costruito nel tempo. Questo processo di inferenza è molto simile a quello che avviene nell’aggiornamento bayesiano.\nLa scelta dei priori ha un impatto fondamentale sulla qualità delle inferenze che possiamo trarre dai dati. Questo capitolo si focalizza sull’importanza e sulle implicazioni che derivano dalla scelta dei priori sul processo di aggiornamento bayesiano. Per illustrare questi concetti, esamineremo alcuni esempi discussi da Johnson et al. (2022).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#introduzione",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "",
    "text": "Medico 1: Si basa principalmente sui risultati di test specifici, senza considerare una storia clinica pregressa del paziente.\nMedico 2: Oltre ai test, tiene conto della storia clinica del paziente, cercando di individuare eventuali fattori di rischio o condizioni preesistenti che potrebbero essere correlate al mal di testa.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#la-distribuzione-a-priori",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.1 La Distribuzione a Priori",
    "text": "47.1 La Distribuzione a Priori\nLa distribuzione a priori gioca un ruolo centrale nell’approccio bayesiano, poiché rappresenta le nostre conoscenze pregresse o le ipotesi sui parametri del modello prima di osservare i dati. Questo concetto è fondamentale perché permette di integrare le informazioni disponibili in precedenza con i dati osservati, fornendo così una stima più precisa e robusta dei parametri. Le distribuzioni a priori possono variare a seconda del grado di certezza che si attribuisce ai valori dei parametri.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#tipologie-di-distribuzioni-a-priori",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.2 Tipologie di Distribuzioni a Priori",
    "text": "47.2 Tipologie di Distribuzioni a Priori\nLa scelta della distribuzione a priori (nota come elicitazione della prior) è uno dei passaggi cruciali nell’analisi bayesiana ed è spesso vista come la fase più controversa, poiché è considerata “soggettiva”. Tuttavia, è importante sottolineare che la scelta della prior non è necessariamente soggettiva. A differenza dell’approccio frequentista, l’approccio bayesiano incoraggia la raccolta e l’integrazione di tutte le informazioni conosciute sul parametro in anticipo. Questo può essere fatto in modo oggettivo, basandosi su evidenze pregresse o raccomandazioni consolidate.\nEsistono tre principali categorie di distribuzioni a priori.\n\nDistribuzioni a Priori Non Informative. Le distribuzioni a priori non informative sono caratterizzate da una totale mancanza di conoscenza pregressa e assegnano la stessa credibilità a tutti i valori dei parametri. Un esempio comune di distribuzione a priori non informativa è la distribuzione uniforme, basata sul “Principio della Ragione Insufficiente” formulato da Laplace. Secondo questo principio, in assenza di evidenze rilevanti pregresse, tutte le possibili configurazioni dei parametri sono considerate equiprobabili.\nDistribuzioni a Priori Debolmente Informative. Le distribuzioni a priori debolmente informative consentendo di integrare una quantità limitata di informazioni pregresse nei modelli statistici. Queste distribuzioni sono progettate per riflettere le nostre assunzioni su quali possono essere i valori “ragionevoli” dei parametri del modello, tenendo conto delle incertezze presenti nell’analisi. L’uso di informazioni a priori debolmente informative può contribuire a migliorare la stabilità dell’analisi senza influenzare in modo significativo le conclusioni derivate da essa.\nLe distribuzioni a priori debolmente informative hanno la caratteristica di non “spostare” in modo significativo la distribuzione a posteriori in una direzione specifica. In altre parole, sono centrate su valori “neutri” dei parametri. Ad esempio, quando si trattano parametri che possono assumere valori positivi o negativi, la distribuzione a priori debolmente informativa potrebbe essere centrata sullo zero. Nel caso di parametri che rappresentano proporzioni, essa potrebbe essere centrata su 0.5.\nTuttavia, ciò che rende queste distribuzioni debolmente informative è la specifica definizione di un intervallo “plausibile” di valori dei parametri. Questo intervallo indica quali valori dei parametri sono considerati plausibili e quali sono invece considerati implausibili. Ad esempio, una distribuzione a priori debolmente informativa potrebbe suggerire che valori estremamente grandi o estremamente bassi dei parametri sono poco plausibili, concentrandosi su un intervallo più stretto di valori considerati ragionevoli.\nIn sintesi, le distribuzioni a priori debolmente informative sono utilizzate per incorporare informazioni pregresse limitate nei modelli bayesiani, contribuendo a stabilizzare le stime dei parametri senza influenzare in modo significativo le conclusioni derivate dai dati. Queste distribuzioni definiscono un intervallo plausibile di valori dei parametri, aiutando a guidare l’analisi verso soluzioni più verosimili senza imporre vincoli eccessivi sui risultati.\nDistribuzioni a Priori Informativa. Le conoscenze pregresse, acquisite attraverso ricerche precedenti, pareri esperti o una combinazione di entrambi, possono essere meticolosamente integrate nel processo di analisi mediante l’incorporazione nelle distribuzioni a priori. Queste distribuzioni sono comunemente conosciute come distribuzioni a priori informative. Esse rappresentano un mezzo per codificare in modo sistematico informazioni concrete e rilevanti che possono avere un notevole impatto sull’analisi statistica, fornendo una solida base di conoscenza su cui fondare l’inferenza bayesiana.\nLe distribuzioni a priori informative possono derivare da una vasta gamma di fonti, comprese ricerche pregresse, pareri di esperti nel campo e altre fonti affidabili. Questo approccio offre un metodo strutturato per integrare in modo coerente le conoscenze pregresse nel processo di analisi statistica. L’incorporazione di queste informazioni aggiuntive contribuisce notevolmente a migliorare la robustezza e l’accuratezza delle conclusioni derivate dai dati, fornendo una solida base empirica su cui basare le stime dei parametri del modello e le decisioni basate sull’analisi bayesiana.\nNell’ambito della ricerca psicologica, l’utilizzo di distribuzioni a priori informative è attualmente poco diffuso, tuttavia emergono segnali che all’interno della comunità statistica sta crescendo l’interesse per questa pratica, considerandola come un avanzamento promettente nel campo della data science.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#limportanza-della-prior-in-base-ai-dati",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.3 L’importanza della Prior in base ai Dati",
    "text": "47.3 L’importanza della Prior in base ai Dati\nUn aspetto cruciale da considerare è che l’influenza della prior diminuisce all’aumentare del numero di dati osservati. In altre parole, con un numero infinito di dati, la verosimiglianza diventa estremamente precisa (o “affilata”), rendendo la scelta della prior irrilevante, a patto che la prior non assegni probabilità zero a regioni dello spazio parametri dove la verosimiglianza è positiva.\nTuttavia, la prior assume un’importanza fondamentale quando si lavora con dataset di piccole dimensioni. In questi casi, la distribuzione a priori può avere un’influenza significativa sulle stime, poiché i dati da soli non sono sufficienti per ottenere stime precise.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#effetti-del-cambiamento-di-scala-dei-parametri",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.4 Effetti del Cambiamento di Scala dei Parametri",
    "text": "47.4 Effetti del Cambiamento di Scala dei Parametri\nUn altro aspetto da tenere a mente è che le priors possono cambiare quando si modificano le scale dei parametri. Se un parametro viene riscalato, ad esempio passando da metri a chilometri, anche la prior deve essere riscalata di conseguenza per mantenere la coerenza dell’inferenza.\n\n47.4.1 Scala e invariabilità della scelta delle distribuzioni a priori\nLa scelta delle distribuzioni a priori non informative non è sempre banale e non può sempre essere rappresentata da una prior piatta. Per capire questo concetto, è fondamentale comprendere il ruolo della scala. Vediamo un esempio per chiarire meglio questo aspetto.\nImmaginiamo di avere un dataset che contiene la media dei diametri di alcuni alberi, e vogliamo stimare la media di questi diametri utilizzando un metodo bayesiano. Prima di osservare i dati, dobbiamo specificare la nostra distribuzione a priori, poiché non vogliamo che i dati influenzino la nostra scelta. Supponiamo di scegliere una distribuzione a priori piatta tra 1 cm e 10 cm, per evitare di introdurre bias:\nimport numpy as np\n\nvalori = np.arange(1, 6)  # Crea un array NumPy da 1 a 5\npesoPrior = np.full(5, 1/5)  # Crea un array NumPy di 5 elementi, tutti uguali a 1/5\nIn questo caso, stiamo assegnando la stessa probabilità a ciascun diametro compreso tra 1 e 10 cm, senza dare più peso a un valore rispetto a un altro. Questa sembra una scelta ragionevole e “non informativa”, poiché non stiamo preferendo nessun diametro in particolare.\nOra, supponiamo di voler modificare leggermente la nostra analisi e di misurare la grandezza degli alberi in termini di area basale (cioè la sezione trasversale dell’albero alla base), che è proporzionale al quadrato del diametro (cioè \\(x^2\\)). Poiché abbiamo già specificato la nostra distribuzione a priori in termini di diametro, dovremmo trasformare questa distribuzione in modo coerente con la nuova scala (area basale).\nIl problema che emerge è il seguente: quando riscaliamo l’asse \\(x\\) per riflettere l’area basale (cioè, passiamo da cm a cm²), i valori più grandi diventano più ampi (poiché l’area cresce con il quadrato del diametro), mentre i valori più piccoli diventano più stretti. Se vogliamo mantenere la stessa distribuzione a priori in termini di probabilità, dobbiamo modificare il peso di ciascun valore.\nDi conseguenza, una distribuzione a priori che inizialmente era piatta (uguale per tutti i valori di diametro) non rimane piatta dopo la trasformazione in area basale. I valori più grandi ora hanno un peso minore, mentre i valori più piccoli hanno un peso maggiore. Questo dimostra che una distribuzione a priori non può essere piatta per tutte le possibili trasformazioni dei parametri.\n\n\n47.4.2 Il concetto di invariabilità della scala\nUna delle chiavi per definire correttamente le distribuzioni a priori non informative è l’invariabilità rispetto alle trasformazioni dei parametri. Se possiamo scegliere liberamente come rappresentare i parametri (ad esempio, in termini di diametro o area basale), la nostra distribuzione a priori dovrebbe essere definita in modo che sia coerente indipendentemente dalla scala scelta.\n\n\n47.4.3 Attenzione alle trasformazioni dei parametri\nUn secondo messaggio importante riguarda la cautela nelle trasformazioni dei parametri nell’analisi bayesiana. Quando cambiamo i parametri del nostro modello, non stiamo semplicemente osservando un singolo valore, ma una distribuzione intera. La forma di questa distribuzione può cambiare notevolmente con la trasformazione dei parametri.\nAd esempio, se si sta conducendo uno studio psicologico e si vuole misurare un parametro legato alla gravità di un disturbo (ad esempio, la gravità della depressione su una scala numerica), e poi si decide di trasformare la scala in un’unità diversa (ad esempio, un punteggio quadratico per evidenziare differenze estreme), la distribuzione a priori che sembrava ragionevole prima della trasformazione potrebbe non esserlo più dopo. Questo significa che bisogna prestare attenzione a come si scelgono le priors e come queste si comportano sotto diverse rappresentazioni del problema.\nIn conclusione, la scelta delle distribuzioni a priori non può essere fatta superficialmente. Deve essere considerata con attenzione, tenendo conto delle possibili trasformazioni dei parametri e assicurandosi che le priors siano coerenti rispetto alla scala scelta. Questo rende evidente che le priors non informative non sono sempre piatte, e la loro scelta deve tenere conto della struttura del problema e delle variabili coinvolte.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#scelte-predefinite-per-le-distribuzioni-a-priori-non-informative",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.5 Scelte predefinite per le distribuzioni a priori non informative",
    "text": "47.5 Scelte predefinite per le distribuzioni a priori non informative\nUna delle domande più ricorrenti nell’inferenza bayesiana riguarda la scelta delle distribuzioni a priori non informative. La risposta, però, è piuttosto complessa: non esiste una soluzione generalmente accettata. Questo è particolarmente importante perché, mentre le priors informative possono essere basate su conoscenze pregresse, una prior non informativa deve essere scelta con cura per evitare di influenzare eccessivamente i risultati.\nUna delle proposte più famose, che soddisfa molte delle proprietà desiderabili, è la prior di Jeffreys, definita come:\n\\[\np(\\phi) \\propto \\sqrt{ \\det (F(\\phi)) },\n\\]\ndove \\(F(\\phi)\\) è la matrice di informazione di Fisher, che misura quanto la verosimiglianza cambia quando variano i parametri. La prior di Jeffreys ha due caratteristiche fondamentali:\n\nInvarianza rispetto alla riscalatura dei parametri: Ciò significa che se trasformiamo la scala del parametro, la prior si adatta automaticamente, rimanendo coerente con il problema.\nProporzionalità all’influenza dei parametri sulla verosimiglianza: Parametri che influenzano maggiormente la verosimiglianza hanno una prior più informativa.\n\nQuesti aspetti sembrano coprire molti dei criteri comunemente accettati per la scelta delle distribuzioni a priori non informative. Tuttavia, la prior di Jeffreys presenta alcuni problemi nei modelli multivariati e gerarchici, il che limita la sua applicabilità come soluzione universale.\n\n47.5.1 Scelte predefinite comuni per le priors non informative\nNonostante le difficoltà legate alla prior di Jeffreys, sono emerse alcune scelte predefinite comuni per le priors non informative, basate su intuizioni derivanti proprio da questa distribuzione. Di seguito sono elencate alcune di queste scelte:\n\nParametri di scala (es. coefficiente angolare o intercetta in una regressione):\n\nPer i parametri di scala, che influenzano l’output in modo lineare, si utilizzano comunemente priors piatte o quasi piatte. Queste possono essere distribuzioni uniformi con limiti fissati o, più comunemente, una distribuzione normale ampia.\nUn esempio di prior modificata è l’uso di una normalità centrata su un valore neutro, come 0, per ottenere l’analogo bayesiano della regressione Lasso o Ridge, che introduce una penalizzazione sui parametri (Park & Casella, 2008; Kyung et al., 2010).\n\nSe questa penalizzazione è lieve, si parla di priors debolmente regolarizzanti.\nSe è forte, si parla di priors di riduzione (shrinkage), che possono essere fisse o adattative:\n\nShrinkage fisso: la forza della riduzione (ad es. controllata dalla deviazione standard nella prior normale) rimane costante.\nShrinkage adattativo: la prior di riduzione si adatta tramite un iperparametro (hyperprior), il che consente al modello di decidere autonomamente la forza della riduzione.\n\n\n\nParametri di varianza (es. la deviazione standard in una regressione lineare):\n\nPer i parametri di varianza, si utilizzano spesso priors che decrescono all’aumentare del valore. Un esempio classico è la prior di Jeffrey’s, che per la varianza assume la forma \\(1/x\\), oppure la distribuzione inversa-gamma, molto comune per via della sua proprietà di coniugazione, che semplifica il calcolo bayesiano.\n\nIperparametri di varianza nei modelli gerarchici:\n\nNei modelli gerarchici, gli iperparametri di varianza vengono trattati con priors decrescenti come l’inversa-gamma o la distribuzione half-t (Gelman, 2006). Queste priors sono progettate per gestire la varianza tra gruppi in modo efficace.\n\nDistribuzioni binomiali:\n\nPer una distribuzione binomiale, la prior di Jeffreys corrisponde a una distribuzione Beta(1/2, 1/2), che è considerata una buona scelta predefinita non informativa. Questo tipo di prior assegna un peso equo alle possibili probabilità di successo, riflettendo una distribuzione equilibrata senza favorire un particolare risultato.\n\n\n\n\n47.5.2 Attenzione alle trasformazioni dei parametri\nUn aspetto importante da considerare nell’uso delle priors non informative è che la loro forma può cambiare significativamente in seguito a trasformazioni dei parametri. Per esempio, passando dalla scala lineare alla scala quadratica di un parametro, la prior può assumere una forma diversa e introdurre involontariamente un bias. Pertanto, è essenziale prestare attenzione a come i parametri sono scalati e trasformati nel modello.\n\n\n47.5.3 Analisi di sensibilità\nInfine, quando si è incerti sulla scelta della prior, un buon approccio consiste nel condurre un’analisi di sensibilità. Questa tecnica prevede di variare la prior e osservare come ciò influenzi i risultati. Se i risultati sono robusti rispetto a diverse scelte di prior, ciò suggerisce che la prior scelta non sta influenzando in modo eccessivo l’inferenza finale. Questo è particolarmente utile nei casi in cui si dispone di pochi dati, situazione in cui la prior può avere un impatto maggiore.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#priori-coniugate",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.6 Priori coniugate",
    "text": "47.6 Priori coniugate\nUna distribuzione a priori è detta coniugata rispetto a una funzione di verosimiglianza se la distribuzione a posteriori risultante ha la stessa forma funzionale della distribuzione a priori. In altre parole, la distribuzione a priori e quella a posteriori appartengono alla stessa famiglia di distribuzioni. Questo è particolarmente utile perché, quando si usano priori coniugate, si ottiene una distribuzione a posteriori che può essere espressa in forma chiusa, rendendo possibile risolverla analiticamente.\nUn esempio tipico è quello delle funzioni di verosimiglianza appartenenti alla famiglia esponenziale, per le quali esiste sempre una distribuzione a priori coniugata. Questo è uno dei motivi per cui le distribuzioni della famiglia esponenziale sono così rilevanti: in modelli semplici, l’uso di una prior coniugata consente di ottenere una soluzione analitica per la distribuzione a posteriori, noto come modello coniugato-esponenziale.\nTradizionalmente, si preferiva specificare priori coniugate quando possibile, proprio per la semplicità analitica che garantivano. Tuttavia, l’importanza delle priors coniugate è diminuita con l’evoluzione dei metodi di campionamento. Oggi, la maggior parte dei campionatori moderni (come i metodi MCMC) non richiede più la coniugazione per funzionare in modo efficiente, e l’uso di priors non coniugate è diventato comune senza compromettere la qualità delle stime.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#simulazioni",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.7 Simulazioni",
    "text": "47.7 Simulazioni\nIn questa sezione, esploriamo come le distribuzioni a priori influenzano la distribuzione a posteriori attraverso una serie di simulazioni. La formula di Bayes, \\(p(\\theta \\mid y) \\propto p(\\theta) \\times p(y \\mid \\theta)\\), evidenzia come la distribuzione a posteriori sia il risultato della combinazione tra la distribuzione a priori e la funzione di verosimiglianza basata sui dati osservati. Se abbiamo le valutazioni puntuali della verosimiglianza e della distribuzione a priori, possiamo moltiplicarle punto per punto per ottenere la distribuzione a posteriori.\nConsideriamo il caso in cui la verosimiglianza sia binomiale. Iniziamo con un caso non coniugato, utilizzando distribuzioni a priori arbitrarie. Supponiamo che i dati consistano in 6 successi su 9 prove di tipo bernoulliano. Confronteremo l’effetto di tre diverse distribuzioni a priori sulla distribuzione a posteriori, analizzando come ciascuna influisce sull’inferenza finale.\n\nsuccess = 6\ntosses = 9\n\n# define grid\ngrid_points = 100\n\n# define grid\np_grid = np.linspace(0, 1, grid_points)\n\n# compute likelihood at each point in the grid\nlikelihood = stats.binom.pmf(success, tosses, p_grid)\n\n\ndef computePosterior(likelihood, prior):\n\n    # compute product of likelihood and prior\n    unstd_posterior = likelihood * prior\n\n    # standardize posterior\n    posterior = unstd_posterior / unstd_posterior.sum()\n\n    plt.figure(figsize=(17, 3))\n    ax1 = plt.subplot(131)\n    ax1.set_title(\"Prior\")\n    plt.plot(p_grid, prior)\n\n    ax2 = plt.subplot(132)\n    ax2.set_title(\"Likelihood\")\n    plt.plot(p_grid, likelihood)\n\n    ax3 = plt.subplot(133)\n    ax3.set_title(\"Posterior\")\n    plt.plot(p_grid, posterior)\n    plt.show()\n\n    return\n\nIl nostro primo priore sarà una distribuzione uniforme: \\(p(\\theta) = 1\\). Questa scelta riflette una completa mancanza di informazioni a priori sulla probabilità di successo \\(\\theta\\). In altre parole, consideriamo tutti i valori possibili tra 0 e 1 come equiprobabili.\n\nprior1 = np.repeat(1, grid_points)\nposterior1 = computePosterior(likelihood, prior1)\n\n\n\n\n\n\n\n\nCome previsto, in questo caso la distribuzione a posteriori sarà uguale alla distribuzione di verosimiglianza (a parte un fattore di scala), poiché non abbiamo fornito alcuna informazione aggiuntiva. Tuttavia, è interessante notare che la distribuzione uniforme è un caso particolare della distribuzione beta, con parametri \\(\\alpha = 1\\) e \\(\\beta = 1\\). Questo significa che la distribuzione uniforme è coniugata alla distribuzione binomiale.\nIl secondo priore proposto è una funzione a gradino (step function). Questa distribuzione a priori rappresenta la convinzione che l’esito “testa” sia più probabile dell’esito “croce”, ovvero che la moneta sia truccata in favore della testa, ma senza specificare di quanto. Per esprimere questa credenza, possiamo definire una funzione a gradino in cui la probabilità è 0 al di sotto di un certo valore e uniforme al di sopra.\nLa distribuzione a priori può essere definita come segue:\n\\[\np(\\theta) = \\begin{cases}\n0, & \\text{se } \\theta &lt; \\theta_0 \\\\\nc, & \\text{se } \\theta \\geq \\theta_0\n\\end{cases}\n\\]\ndove:\n\n\\(\\theta\\) rappresenta la probabilità di ottenere “testa”.\n\\(\\theta_0\\) è il valore di soglia al di sotto del quale la probabilità è 0.\n\\(c\\) è una costante di normalizzazione per garantire che l’integrale della distribuzione sia uguale a 1.\n\nQuesta distribuzione a priori esprime la convinzione che la probabilità di ottenere “testa” sia maggiore di \\(\\theta_0\\) (nel caso presente, \\(\\theta_0 = 0.5\\)). Tuttavia, non fornisce informazioni specifiche sulla distribuzione di probabilità al di sopra di \\(\\theta_0\\), assumendo semplicemente una distribuzione uniforme.\n\nprior2 = (p_grid &gt;= 0.5).astype(int)\nposterior2 = computePosterior(likelihood, prior2)\n\n\n\n\n\n\n\n\nLa scelta di questo priore ha l’effetto di escludere completamente dalla distribuzione a posteriori tutti i valori di \\(\\theta\\) inferiori a \\(\\theta_0\\), assegnando loro una probabilità nulla. In pratica, questa scelta significa che siamo assolutamente certi che la probabilità di ottenere ‘testa’ sia superiore a \\(\\theta_0\\), escludendo completamente la possibilità di valori inferiori.\nIl terzo prior che consideriamo è una distribuzione centrata su 0.5, con un rapido decadimento esponenziale su entrambi i lati. Anche questo caso rappresenta un prior coniugato, modellato da una distribuzione Beta con parametri \\(\\alpha\\) e \\(\\beta\\) uguali. Il carattere esponenziale della distribuzione esprime una riduzione relativamente veloce della densità di probabilità man mano che ci si allontana da 0.5. Ci possiamo aspettare che la scelta di questo priore abbia l’effetto di ‘attrarre’ la distribuzione a posteriori verso 0.5, a meno che i dati non forniscano evidenze contrarie molto forti.\n\nprior3 = np.exp(-5 * abs(p_grid - 0.5))\nposterior3 = computePosterior(likelihood, prior3)\n\n\n\n\n\n\n\n\nLa distribuzione a posteriori conferma quanto previsto.\nIn una seconda serie di simulazioni, per illustrare l’importanza del priore, utilizzeremo le funzioni plot_beta_binomial e summarize_beta_binomial ispirate da Johnson et al. (2022). Ci concentreremo sul modello coniugato beta-binomiale.\n\ndef plot_beta_binomial(alpha, beta, y=None, n=None, prior=True, likelihood=True, posterior=True) -&gt; None:\n    \"\"\"Plot a Beta-Binomial Bayesian Model\n    \n    Parameters:\n    - alpha, beta: positive shape parameters of the prior Beta distribution\n    - y: observed number of successes\n    - n: observed number of trials\n    - prior: indicates whether the prior distribution should be plotted\n    - likelihood: indicates whether the scaled likelihood should be plotted\n    - posterior: indicates whether the posterior distribution should be plotted\n    \"\"\"\n    \n    θ = np.linspace(0, 1, 100)  # Range of possible values for θ\n    \n    if prior:\n        p_theta = stats.beta.pdf(θ, alpha, beta)\n        plt.fill_between(θ, p_theta, step='mid', alpha=0.2, color='blue', label='Prior')\n    \n    if y is not None and n is not None:\n        if likelihood:\n            likelihood_values = stats.binom.pmf(y, n, θ)\n            scale_factor = integrate.simpson(y=likelihood_values, x=θ)  # Corrected to use keyword arguments\n            plt.plot(θ, likelihood_values / scale_factor, color='orange', label='Likelihood (scaled)', lw=2)\n        \n        if posterior:\n            alpha_post = alpha + y\n            beta_post = beta + n - y\n            p_theta_post = stats.beta.pdf(θ, alpha_post, beta_post)\n            plt.fill_between(θ, p_theta_post, step='mid', alpha=0.4, color='green', label='Posterior')\n    \n    plt.xlabel(r'$\\theta$')\n    plt.ylabel('Density')\n    plt.legend(loc='upper left')\n    plt.title('Beta-Binomial Model')\n    plt.show()\n\n\ndef summarize_beta_binomial(alpha, beta, y=None, n=None):\n    \"\"\"Summarize a Beta-Binomial Bayesian model\n\n    @param alpha,beta positive shape parameters of the prior Beta model\n    @param y number of successes\n    @param n number of trials\n\n    Return: Pandas dataframe summarizing beta binomial\n    \"\"\"\n\n    def beta_mean(a, b):\n        return a / (a + b)\n\n    def beta_mode(a, b):\n        if a &lt; 1 and b &lt; 1:\n            return \"0 and 1\"\n        elif a &lt;= 1 and b &gt; 1:\n            return 0\n        elif a &gt; 1 and b &lt; 1:\n            return 1\n        else:\n            return (a - 1) / (a + b - 2)\n\n    def beta_var(a, b):\n        return a * b / ((a + b) ** 2 * (a + b + 1))\n\n    prior_mean = beta_mean(alpha, beta)\n    prior_mode = beta_mode(alpha, beta)\n    prior_var = beta_var(alpha, beta)\n    prior_sd = np.sqrt(prior_var)\n    if y is None and n is None:\n        summary = pd.DataFrame(\n            {\n                \"alpha\": alpha,\n                \"beta\": beta,\n                \"mean\": prior_mean,\n                \"mode\": prior_mode,\n                \"var\": prior_var,\n                \"sd\": prior_sd,\n            },\n            index=[\"prior\"],\n        )\n    else:\n        post_alpha = y + alpha\n        post_beta = n - y + beta\n        post_mean = beta_mean(post_alpha, post_beta)\n        post_mode = beta_mode(post_alpha, post_beta)\n        post_var = beta_var(post_alpha, post_beta)\n        post_sd = np.sqrt(post_var)\n        summary = pd.DataFrame(\n            {\n                \"alpha\": [alpha, post_alpha],\n                \"beta\": [beta, post_beta],\n                \"mean\": [prior_mean, post_mean],\n                \"mode\": [prior_mode, post_mode],\n                \"var\": [prior_var, post_var],\n                \"sd\": [prior_sd, post_sd],\n            },\n            index=[\"prior\", \"posterior\"],\n        )\n    return summary\n\nNel caso in cui disponiamo di un campione di dati di dimensioni molto ridotte, come ad esempio 15 successi su 20 tentativi in una distribuzione beta-binomiale, la distribuzione a priori può esercitare un notevole impatto sulla distribuzione a posteriori. In contrasto, se consideriamo una distribuzione a priori uniforme, la distribuzione a posteriori assomiglierà alla funzione di verosimiglianza, con l’eccezione dell’area sotto le due curve. In parole più semplici, quando la distribuzione a priori è uniforme, la distribuzione a posteriori presenterà un picco nella stima di massima verosimiglianza. Tuttavia, quando adottiamo diverse distribuzioni a priori, la distribuzione a posteriori potrebbe notevolmente discostarsi.\nCominciamo esaminando il caso in cui viene adottata una distribuzione a priori uniforme.\n\nplot_beta_binomial(alpha=1, beta=1, y=15, n=20)\n\n\n\n\n\n\n\n\nEsaminiamo ora l’effetto di una distribuzione a priori poco informativa, come ad esempio una Beta(2, 2). In questa situazione, l’impatto di tale scelta sulla distribuzione a posteriori è di modesta entità, ma comunque presente. Questo fenomeno può essere interpretato come un effetto di “regolarizzazione”, il quale influisce sulla nostra stima in modo più cauto rispetto a quanto ottenuto tramite il principio di massima verosimiglianza. In altre parole, la stima risultante risulta essere più “bilanciata” verso il valore intermedio di 0.5.\n\nplot_beta_binomial(alpha=2, beta=2, y=15, n=20)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=2, y=15, n=20)\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n2\n0.500000\n0.500000\n0.050000\n0.223607\n\n\nposterior\n17\n7\n0.708333\n0.727273\n0.008264\n0.090906\n\n\n\n\n\n\n\nSe il campione è di dimensioni maggiori, l’adozione di una distribuzione a priori Beta(2, 2) ha un effetto trascurabile: infatti, il valore massimo della distribuzione a posteriori risulta essere quasi identico alla stima di massima verosimiglianza.\n\nplot_beta_binomial(alpha=2, beta=2, y=150, n=200)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=2, y=150, n=200)\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n2\n0.500000\n0.500000\n0.050000\n0.223607\n\n\nposterior\n152\n52\n0.745098\n0.747525\n0.000926\n0.030438\n\n\n\n\n\n\n\nSe optiamo per una distribuzione a priori informativa, questa avrà un notevole impatto sulla distribuzione a posteriori quando ci si trova di fronte a un campione di dimensioni ridotte.\n\nplot_beta_binomial(alpha=2, beta=5, y=15, n=20)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=15, n=20)\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.20\n0.025510\n0.159719\n\n\nposterior\n17\n10\n0.629630\n0.64\n0.008328\n0.091260\n\n\n\n\n\n\n\nAl contrario, la medesima distribuzione a priori ha un effetto insignificante sulla distribuzione a posteriori quando il campione è di dimensioni considerevoli.\n\nplot_beta_binomial(alpha=2, beta=5, y=150, n=200)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=150, n=200)\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.200000\n0.025510\n0.159719\n\n\nposterior\n152\n55\n0.734300\n0.736585\n0.000938\n0.030627\n\n\n\n\n\n\n\n\nplot_beta_binomial(alpha=2, beta=5, y=1500, n=2000)\n\n\n\n\n\n\n\n\n\nsummarize_beta_binomial(alpha=2, beta=5, y=1500, n=2000)\n\n\n\n\n\n\n\n\nalpha\nbeta\nmean\nmode\nvar\nsd\n\n\n\n\nprior\n2\n5\n0.285714\n0.200000\n0.025510\n0.159719\n\n\nposterior\n1502\n505\n0.748381\n0.748628\n0.000094\n0.009684",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#connessione-tra-intuizioni-e-teoria",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.8 Connessione tra intuizioni e teoria",
    "text": "47.8 Connessione tra intuizioni e teoria\nL’equilibrio tra la distribuzione a priori e le evidenze provenienti dai dati, come dimostrato negli esempi precedenti, non solo rispecchia le nostre intuizioni, ma rappresenta anche una necessità matematica. Questo concetto diventa chiaro esaminando la formula del valore atteso della distribuzione a posteriori nel contesto del caso beta-binomiale, che può essere riscritta come segue:\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta + n} \\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\]\nL’equazione precedente rivela che il valore atteso a posteriori si ottiene come una media ponderata tra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata dei successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono dati da \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Pertanto, quando il numero di osservazioni \\(n\\) è significativo rispetto alla somma dei parametri \\(\\alpha + \\beta\\), la distribuzione a posteriori sarà principalmente influenzata dai dati osservati e in minor misura dalle credenze a priori. Al contrario, se \\(n\\) è piccolo rispetto a \\(\\alpha + \\beta\\), i dati avranno un peso inferiore rispetto alle credenze a priori.\nQueste considerazioni indicano come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se desideriamo rappresentare una totale ignoranza sul fenomeno, una scelta coerente è \\(\\alpha = \\beta = 1\\) (attribuiamo uguale credibilità a ogni valore di \\(\\theta\\)). Se, invece, possediamo forti credenze a priori, possiamo selezionare \\(\\alpha\\) in modo da eguagliare il valore atteso a priori, mentre \\(\\alpha + \\beta\\) rifletterà l’importanza attribuita all’informazione a priori: maggiore è il valore di \\(\\alpha + \\beta\\), maggiore sarà il numero di dati necessari per influenzare significativamente la distribuzione a posteriori rispetto a quella a priori. In situazioni in cui \\(n\\) è considerevolmente grande, la distribuzione a posteriori avrà un impatto ridotto sulla distribuzione a priori, a meno che non si facciano scelte estreme per i parametri a priori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#conflitto-tra-prior-e-verosimiglianza",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.9 Conflitto tra Prior e Verosimiglianza",
    "text": "47.9 Conflitto tra Prior e Verosimiglianza\nEsaminiamo ora un altro esempio proposto da McElreath:\n\nLesson: Don’t trust intuition, for even simple prior+likelihood scenarios defy it. Four examples below, each producing radically different posteriors. Can you guess what each does?\n\n\nNella figura successiva vediamo la risposta alla domanda precedente.\n\nMcElreath descrive le caratteristiche di quattro diversi modelli in cui si combinano distribuzioni normali (Gaussiane) e Student-t (con 2 gradi di libertà) per il prior e la likelihood. La distribuzione gaussiana ha code molto sottili, mentre quella di Student-t ha code più spesse.\n\nIn Alto a Sinistra: Prior Normale, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Normal(10,1)\n\nIn questo scenario classico di aggiornamento bayesiano, il posterior risulta essere un compromesso tra il prior e la likelihood. La distribuzione normale, con le sue code sottili, contribuisce a un aggiornamento più “prevedibile” e concentrato attorno al valore medio.\nIn Alto a Destra: Prior Student, Likelihood Student (df=2)\n\ny ~ Student(2,mu,1)\nmu ~ Student(2,10,1)\n\nIn questo caso, entrambe le distribuzioni hanno code più spesse. La presenza di “extra massa” nelle code significa che ciascuna distribuzione trova il modo dell’altra più plausibile, portando a una media che non rappresenta il miglior “compromesso”. Questo scenario risulta in una maggiore incertezza e un posterior meno definito.\nIn Basso a Sinistra: Prior Student, Likelihood Normale\n\ny ~ Normal(mu,1)\nmu ~ Student(2,10,1)\n\nQui, la likelihood normale, con le sue code sottili, tende a dominare. Essa è molto scettica nei confronti del prior con code spesse, ma il prior di Student-t non è sorpreso dalla likelihood. Questo porta a un posterior che è più influenzato dalla likelihood normale.\nIn Basso a Destra: Prior Normale, Likelihood Student\n\ny ~ Student(2,mu,1)\nmu ~ Normal(10,1)\n\nIn questo ultimo scenario, è il prior normale a dominare. Il ragionamento è simile a quello del caso precedente, ma in senso inverso. Il prior normale, con le sue code sottili, impone una maggiore influenza sul posterior, rendendolo meno influenzato dalle code più spesse della likelihood di Student-t.\n\nIn sintesi, la combinazione di queste due distribuzioni in diversi modi porta a risultati di aggiornamento bayesiano molto differenti, a seconda di quale tra prior e likelihood abbia le code più spesse e quindi eserciti una maggiore influenza sul posterior.\nDi seguito è riportato il codice per riprodurre i risultati delle figure precedenti.\n\n# Observed data\nyobs = 0\n\n# Number of samples\nn_samples = 2000\n\n# Model with normal prior and normal likelihood\nwith pm.Model() as mnn:\n    mu = pm.Normal('mu', mu=10, sigma=1)\n    y = pm.Normal('y', mu=mu, sigma=1, observed=yobs)\n    trace_mnn = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with t prior and t likelihood\nwith pm.Model() as mtt:\n    mu = pm.StudentT('mu', nu=2, mu=10, sigma=1)\n    y = pm.StudentT('y', nu=2, mu=mu, sigma=1, observed=yobs)\n    trace_mtt = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with t prior and normal likelihood\nwith pm.Model() as mnt:\n    mu = pm.StudentT('mu', nu=2, mu=10, sigma=1)\n    y = pm.Normal('y', mu=mu, sigma=1, observed=yobs)\n    trace_mnt = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n# Model with normal prior and t likelihood\nwith pm.Model() as mtn:\n    mu = pm.Normal('mu', mu=10, sigma=1)\n    y = pm.StudentT('y', nu=2, mu=mu, sigma=1, observed=yobs)\n    trace_mtn = pm.sampling_jax.sample_numpyro_nuts(n_samples, chains=4)\n\n\n# Function to plot the results\ndef plot_posterior(trace, model_name):\n    mu_samples = trace.posterior['mu'].values.flatten()  # Extracting 'mu' samples\n    plt.hist(mu_samples, density=True, bins=30, alpha=0.7, label=f'{model_name} Posterior')\n    plt.xlabel('mu')\n    plt.ylabel('Density')\n    plt.legend()\n\n# Plotting the results\nplt.figure(figsize=(9, 7))\n\nplt.subplot(2, 2, 1)\nplot_posterior(trace_mnn, 'Normal Prior, Normal Likelihood')\n\nplt.subplot(2, 2, 2)\nplot_posterior(trace_mtt, 't Prior, t Likelihood')\n\nplt.subplot(2, 2, 3)\nplot_posterior(trace_mnt, 't Prior, Normal Likelihood')\n\nplt.subplot(2, 2, 4)\nplot_posterior(trace_mtn, 'Normal Prior, t Likelihood')\nplt.tight_layout()\nplt.show()\n\n/var/folders/hl/dt523djx7_q7xjrthzjpdvc40000gn/T/ipykernel_61930/765634110.py:23: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nIn conclusione, questo esercizio mostra come, ad eccezione del caso gaussiano, i risultati non sono affatto intuitivi. Pertanto, in contesti come questi, affidarsi esclusivamente alle proprie intuizioni non è una scelta consigliabile. È invece fondamentale procedere con l’esecuzione dei calcoli.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#riflessioni-conclusive",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "47.10 Riflessioni Conclusive",
    "text": "47.10 Riflessioni Conclusive\nLa scelta della distribuzione a priori è uno degli aspetti più cruciali nell’inferenza bayesiana. Da un lato, le priors non informative possono essere utilizzate per minimizzare l’influenza delle conoscenze pregresse, permettendo ai dati osservati di guidare l’inferenza. Dall’altro, le priors informative sono estremamente utili quando si dispone di informazioni affidabili sui parametri, consentendo una stima più precisa. È importante ricordare che, con un gran numero di dati, l’influenza della prior tende a ridursi, mentre nei contesti con pochi dati la scelta della prior può avere un impatto significativo.\nUn aspetto essenziale dell’approccio bayesiano, come evidenziato nell’esempio di Johnson (2022), è che il processo di aggiornamento bayesiano riflette il modo in cui le persone ragionano intuitivamente: di fronte a evidenze deboli, le credenze rimangono stabili, mentre nuove informazioni robuste portano a un aggiornamento significativo delle credenze. Questo meccanismo formalizza in modo quantitativo e rigoroso le intuizioni che utilizziamo quotidianamente. Al contrario, l’approccio frequentista ignora le conoscenze pregresse, il che può portare a cambiamenti nelle inferenze senza tener conto delle credenze già esistenti.\nTuttavia, come evidenziato dagli esempi di McElreath, la situazione può essere più complessa nei modelli non coniugati, dove l’intuizione può fallire nel prevedere correttamente la distribuzione a posteriori. Questo ci ricorda che il contesto e la struttura del modello giocano un ruolo determinante nell’inferenza bayesiana.\n\n47.10.1 Il Ruolo della Prior nella Regolarizzazione\nNel contesto bayesiano, le distribuzioni a priori debolmente informative fungono da meccanismo di regolarizzazione, limitando l’influenza delle osservazioni estreme e garantendo inferenze più stabili. Questo approccio è ormai ampiamente accettato nella comunità statistica, poiché permette di ottenere risultati più prudenti senza introdurre un forte bias.\n\n\n47.10.2 L’Importanza dei Prior Informativi\nNegli ultimi anni, l’uso di priori informativi ha guadagnato maggiore attenzione, soprattutto grazie all’integrazione delle conoscenze esperte nel processo inferenziale. Questa pratica, nota come elicitazione della conoscenza esperta, richiede un rigoroso approccio metodologico per evitare bias cognitivi e assicurare che le informazioni pregresse siano incorporate in modo accurato. Questo è particolarmente rilevante in campi come la psicologia, dove spesso la base teorica è incerta, e l’elicitazione esperta può contribuire a migliorare la solidità delle analisi bayesiane (O’Hagan, 2019).\n\n\n47.10.3 Conclusioni Finali\nIn conclusione, la scelta delle prior deve essere ponderata attentamente in base alla disponibilità di dati e al contesto dell’analisi. Sebbene l’uso di priors non informative possa sembrare una scelta “neutra”, è spesso sub-ottimale. Le priors debolmente informative rappresentano lo standard attuale, poiché favoriscono un’inferenza più robusta grazie alla loro capacità di regolarizzare l’influenza dei dati. Infine, l’uso di priori informativi, sviluppati attraverso protocolli rigorosi di elicitazione esperta, è una frontiera in crescita nell’analisi bayesiana, poiché consente di sfruttare al meglio le conoscenze pregresse per migliorare la qualità delle inferenze e ridurre l’incertezza.\nQuesto approccio, che bilancia conoscenza pregressa e nuovi dati, permette di sviluppare modelli bayesiani più solidi e informati, riflettendo accuratamente sia l’incertezza sia la competenza specifica del dominio di studio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/08_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/08_balance_prior_post.html#informazioni-sullambiente-di-sviluppo",
    "title": "47  L’influenza della distribuzione a priori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p jax\n\nLast updated: Tue Apr 09 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\njax: 0.4.25\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.17.0\nrequests  : 2.31.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nscipy     : 1.12.0\npandas    : 2.2.1\npymc      : 5.10.4\nmatplotlib: 3.8.3\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, A. (2006). Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper). Bayesian Analysis, 1(3), 515–534. https://doi.org/10.1214/06-BA117A\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nO’Hagan, A. (2019). Expert knowledge elicitation: subjective but scientific. The American Statistician, 73(sup1), 69–81.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>L'influenza della distribuzione a priori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html",
    "title": "48  Modello coniugato Gamma-Poisson",
    "section": "",
    "text": "48.1 Introduzione\nIn psicologia, le variabili di conteggio (\\(y\\)), che indicano il numero di occorrenze di un evento, trovano ampio impiego in diversi ambiti. Ad esempio, sono usate per quantificare la frequenza dei sintomi di un disturbo o per analizzare le frequenze delle parole negli studi di psicolinguistica. Queste variabili, assumendo valori discreti, richiedono modelli statistici specifici.\nQuesto capitolo si focalizza sulla stima del tasso medio di incidenza (\\(\\lambda_i\\)) di tali eventi, ovvero sul numero medio di occorrenze per unità di misura. Adotteremo un approccio bayesiano, utilizzando il modello di Poisson per descrivere la distribuzione di probabilità delle variabili di conteggio. In particolare, esploreremo la derivazione analitica della distribuzione a posteriori del parametro \\(\\lambda_i\\), considerando una distribuzione a priori Gamma. Successivamente, verificheremo la validità dei risultati analitici mediante simulazioni Monte Carlo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-di-poisson",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#distribuzione-di-poisson",
    "title": "48  Modello coniugato Gamma-Poisson",
    "section": "48.2 Distribuzione di Poisson",
    "text": "48.2 Distribuzione di Poisson\nLa distribuzione di Poisson è un modello probabilistico utilizzato per descrivere il numero di eventi che si verificano in un intervallo di tempo o spazio fisso, partendo dall’assunto che tali eventi si verifichino con una frequenza media costante e in modo indipendente rispetto al tempo trascorso dall’ultimo evento. Se un dato \\(y\\) segue una distribuzione di Poisson con parametro \\(\\lambda\\), allora la probabilità di osservare un singolo valore \\(y_i\\) è data da:\n\\[\nf(y_i \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!},\n\\]\ndove \\(\\lambda &gt; 0\\) rappresenta la frequenza media di occorrenza degli eventi e \\(y_i\\) è il numero di eventi osservati. La distribuzione di Poisson ha la caratteristica che sia il valore atteso che la varianza di una variabile casuale \\(Y\\) che segue questa distribuzione sono pari a \\(\\lambda\\), cioè \\(E(Y) = \\lambda\\) e \\(\\text{Var}(Y) = \\lambda\\).\n\n48.2.1 Simulazione\nPer capire meglio come funziona la distribuzione di Poisson, immaginiamo un paziente con un disturbo ossessivo-compulsivo. Supponiamo che in media questo paziente ripeta un’azione compulsiva 2 volte ogni ora. In questo caso, il parametro della distribuzione di Poisson è λ = 2.\nLa probabilità di osservare esattamente \\(k\\) eventi in un’ora è calcolata dalla formula:\n\\[\nf(k | \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!}.\n\\]\nNel caso specifico con \\(\\lambda = 2\\), le probabilità per i primi valori di \\(k\\) sono:\n\nLa probabilità di osservare 0 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^0}{0!} = e^{-2} \\approx 0{.}1353\\).\nLa probabilità di osservare 1 evento in un’ora è \\(\\frac{e^{-2} \\cdot 2^1}{1!} = 2e^{-2} \\approx 0{.}2707\\).\nLa probabilità di osservare 2 eventi in un’ora è \\(\\frac{e^{-2} \\cdot 2^2}{2!} = 2e^{-2} \\approx 0{.}2707\\).\nE così via per \\(k = 3\\), \\(k = 4\\), \\(\\dots\\)\n\nQuesto esempio illustra come la distribuzione di Poisson possa essere utilizzata per modellare il numero di eventi rari che si verificano in un intervallo temporale fisso, con una frequenza media nota.\nSvolgiamo ora i calcoli usando la funzione poisson del modulo scipy.stats:\n\nlam_true = 2\n# Creazione di un array di valori da 0 a 9\nk_values = np.arange(0, 10)  \n\n# Calcolo delle probabilità per ogni valore in k_values\nprobabilities = stats.poisson.pmf(k_values, lam_true)\n\nfor k, prob in zip(k_values, probabilities):\n    print(f\"Probabilità di {k} eventi: {prob:.4f}\")\n\nProbabilità di 0 eventi: 0.1353\nProbabilità di 1 eventi: 0.2707\nProbabilità di 2 eventi: 0.2707\nProbabilità di 3 eventi: 0.1804\nProbabilità di 4 eventi: 0.0902\nProbabilità di 5 eventi: 0.0361\nProbabilità di 6 eventi: 0.0120\nProbabilità di 7 eventi: 0.0034\nProbabilità di 8 eventi: 0.0009\nProbabilità di 9 eventi: 0.0002\n\n\nIl seguente codice Python genera il grafico della funzione di massa di probabilità (PMF) di una distribuzione di Poisson con parametro \\(\\lambda\\) = 2.\n\n# Definiamo il parametro lambda\nlambd = 2\n\n# Generiamo i valori sull'asse x (numero di eventi)\nx = np.arange(0, 10)  # Possiamo aumentare o diminuire il range a seconda delle esigenze\n\n# Calcoliamo le probabilità corrispondenti utilizzando la funzione pmf di scipy.stats.poisson\ny = stats.poisson.pmf(x, lambd)\n\n# Creiamo il grafico a barre\nplt.bar(x, y, alpha=0.5)\n\n# Aggiungiamo le etichette agli assi\nplt.xlabel('Numero di eventi')\nplt.ylabel('Probabilità')\nplt.title('Distribuzione di Poisson (λ = 2)')\nplt.show()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni-poisson",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#verosimiglianza-per-un-campione-di-osservazioni-poisson",
    "title": "48  Modello coniugato Gamma-Poisson",
    "section": "48.3 Verosimiglianza per un Campione di Osservazioni Poisson",
    "text": "48.3 Verosimiglianza per un Campione di Osservazioni Poisson\nConsideriamo un campione di \\(n\\) osservazioni indipendenti e identicamente distribuite, \\(y_1, y_2, ..., y_n\\), provenienti da una distribuzione di Poisson con parametro \\(\\lambda\\). La funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità congiunta di osservare esattamente questi valori dato un particolare valore di \\(\\lambda\\).\nMatematicamente, la verosimiglianza si esprime come:\n\\[\nf(y \\mid \\lambda)=\\prod_{i=1}^{n} \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!}\n=\\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^{n}y_i!}.\n\\]\nLa verosimiglianza ci fornisce una misura della probabilità di osservare l’intero campione di dati, dato un valore specifico di \\(\\lambda\\). Più alta è la verosimiglianza, più compatibili sono i dati con il valore di \\(\\lambda\\) considerato.\nInterpretazione intuitiva\nConsideriamo un campione di dati \\(y_1, y_2, ..., y_n\\) e un parametro incognito \\(\\lambda\\). La funzione di verosimiglianza, associata a questo modello statistico, esprime la probabilità di osservare esattamente i dati campionati in funzione dei diversi valori possibili di \\(\\lambda\\). In altre parole, per ogni valore di \\(\\lambda\\), la funzione di verosimiglianza fornisce una misura di quanto quel valore sia plausibile alla luce dei dati osservati.\nSpesso, per semplificare i calcoli e evitare problemi di overflow numerico, si lavora con il logaritmo naturale della funzione di verosimiglianza, chiamato log-verosimiglianza.\n\n48.3.1 Distribuzione Gamma\nLa distribuzione Gamma è fondamentale per il modello coniugato gamma-poisson, dove serve come distribuzione a priori per il parametro di tasso \\(\\lambda\\) di una distribuzione di Poisson. La sua scelta è motivata dalla sua coniugatezza con la Poisson, che semplifica i calcoli inferenziali.\nLa funzione di densità di probabilità della distribuzione Gamma è definita come:\n\\[ f(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x}, \\]\ndove \\(\\alpha\\) controlla la forma della distribuzione (più alto è \\(\\alpha\\), più simmetrica è la distribuzione) e \\(\\beta\\) controlla la scala (più alto è \\(\\beta\\), più concentrata è la massa di probabilità vicino all’origine). Ad esempio, una distribuzione Gamma con \\(\\alpha = 2\\) e \\(\\beta = 3\\) rappresenta un processo in cui eventi relativamente rari si verificano occasionalmente, mentre una distribuzione con \\(\\alpha = 10\\) e \\(\\beta = 1\\) indica un processo più regolare con eventi frequenti.\n\n\n\n\n\n\nIn Scipy, la parametrizzazione è leggermente diversa. Il parametro di scala in Scipy è l’inverso del parametro \\(\\beta\\) nella formula sopra.\n\n\n\nPer calcolare la densità di probabilità in scipy.stats, si utilizza:\nstats.gamma.pdf(x, a=alpha, scale=1/beta)\nConsideriamo il seguente esempio.\n\nalpha = 2\nbeta = 3\nx = np.linspace(0, 3, 500)\npdf = stats.gamma.pdf(x, a=alpha, scale=1/beta)\n# Create plot\nplt.plot(x, pdf)\nplt.xlabel(\"x\")\nplt.ylabel(\"Probability Density\")\nplt.title(\"Gamma Distribution (α=2, β=3)\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIl codice precedente calcola la densità di probabilità per una gamma con parametri \\(\\alpha = 2\\) e \\(\\beta = 3\\) su un intervallo da 0 a 3.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#metodo-basato-su-griglia",
    "title": "48  Modello coniugato Gamma-Poisson",
    "section": "48.4 Metodo Basato su Griglia",
    "text": "48.4 Metodo Basato su Griglia\nPoniamoci ora il problema di determinare la distribuzione a posteriori del parametro \\(\\lambda\\) di un modello di Poisson, adottando una distribuzione a priori Gamma. In questo primo esempio utilizzeremo un approccio numerico basato sulla discretizzazione dello spazio dei parametri (metodo della griglia). Supponiamo di avere osservato i seguenti dati.\n\ny = np.array([2, 1, 3, 2, 2, 1, 1, 1])\n\nQuale distribuzione a priori per il parametro \\(\\lambda\\) della distribuzione di Poisson, scegliamo una distribuzione Gamma con i seguenti parametri.\n\nalpha_prior = 9\nbeta_prior = 2\n\nx = np.linspace(start=0, stop=10, num=300)\n\nplt.plot(x, stats.gamma.pdf(x, a=alpha_prior, scale=1 / beta_prior))\nplt.axvline(x=alpha_prior / beta_prior, linestyle=\"--\", label=\"gamma mean\")\nplt.axvline(x=y.mean(), linestyle=\"--\", color=\"C2\", label=\"sample mean\")\nplt.legend()\nplt.title(f\"Gamma Density Function for a={9} and b={2}\")\nplt.show()\n\n\n\n\n\n\n\n\nDefiniamo una griglia di valori per il parametro \\(\\lambda\\) nell’intervallo [0.01, 10].\n\n# Omettiamo lo zero per evitare divisione per zero\nlambda_grid = np.linspace(0.01, 10, 1000)\n  \nlen(lambda_grid)\n\n1000\n\n\nDefiniamo la nostra credenza iniziale sulla distribuzione del parametro \\(\\lambda\\) tramite una distribuzione Gamma. Assegniamo a ciascun possibile valore di \\(\\lambda\\) nella griglia un peso iniziale (la densità a priori) secondo una distribuzione Gamma con parametri alpha_prior e beta_prior. Questi pesi sono memorizzati nel vettore prior.\n\nprior = stats.gamma.pdf(lambda_grid, a=alpha_prior, scale=1/beta_prior)\nlen(prior)\n\n1000\n\n\nInizializziamo un vettore verosimiglianza con tutti gli elementi uguali a 1, della stessa lunghezza della griglia dei valori di \\(\\lambda\\). Successivamente, per ogni osservazione \\(y_i\\) nei dati, calcoliamo la probabilità di massa di Poisson per ogni valore di \\(\\lambda\\) nella griglia e moltiplichiamo la verosimiglianza corrente per questo valore. Alla fine del ciclo, il vettore verosimiglianza conterrà la verosimiglianza totale per ogni valore di \\(\\lambda\\), dati i dati osservati.\n\nlikelihood = np.ones_like(lambda_grid)\n\nfor yi in y:\n    likelihood *= stats.poisson.pmf(yi, lambda_grid)\n    \nlen(likelihood)\n\n1000\n\n\nLa verosimiglianza misura quanto bene un modello (in questo caso, una distribuzione di Poisson con un particolare valore di \\(\\lambda\\)) spiega i dati osservati. Valori più alti della verosimiglianza indicano un migliore adattamento del modello ai dati. Utilizziamo il prodotto perché assumiamo che le osservazioni siano indipendenti. La probabilità congiunta di osservare tutti i dati è il prodotto delle probabilità individuali.\nSecondo il teorema di Bayes, la distribuzione a posteriori è proporzionale al prodotto della verosimiglianza e della distribuzione a priori. Pertanto, calcoliamo la distribuzione a posteriori non normalizzata moltiplicando elemento per elemento la verosimiglianza per la distribuzione a priori.\n\nposterior_unnormalized = likelihood * prior\n\nLa moltiplicazione della verosimiglianza per la distribuzione a priori ha l’effetto di “pesare” i valori di \\(\\lambda\\) in base a quanto bene spiegano i dati e a quanto erano considerati plausibili a priori.\nCalcoliamo il fattore di normalizzazione sommando i valori della distribuzione a posteriori non normalizzata, moltiplicati per la larghezza dell’intervallo della griglia (che rappresenta approssimativamente l’area di ciascun rettangolo nella stima dell’integrale). Dividendo la distribuzione non normalizzata per questo fattore, otteniamo una distribuzione di probabilità valida, ovvero una distribuzione che si integra a 1.\n\nposterior = posterior_unnormalized / np.sum(\n    posterior_unnormalized * (lambda_grid[1] - lambda_grid[0])\n)\n\nlen(posterior)\n\n1000\n\n\nIl codice Python sotto riportato crea un grafico che visualizza sia la distribuzione a priori che quella a posteriori del parametro \\(\\lambda\\).\n\nplt.plot(lambda_grid, posterior, label=\"Distribuzione a Posteriori\")\nplt.plot(lambda_grid, prior, \"--\", label=\"Distribuzione a Priori\")\nplt.xlabel(r\"$\\lambda$\")\nplt.ylabel(\"Densità di probabilità\")\nplt.legend()\nplt.title(\"Distribuzione a Posteriori di $\\lambda$\")\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico mostra come la nostra conoscenza sulla distribuzione del parametro \\(\\lambda\\) si evolve da una distribuzione a priori (prima di osservare i dati) a una distribuzione a posteriori (dopo aver osservato i dati). L’area sotto la curva rappresenta la probabilità. Confrontare le due distribuzioni permette di valutare l’impatto dei dati sulla nostra inferenza.\nNel caso presente\n\nla distribuzione a posteriori è spostata a sinistra rispetto alla distribuzione a priori, indicando che i dati hanno fornito nuove informazioni sul valore più probabile di \\(\\lambda\\);\nla distribuzione a posteriori è più stretta rispetto alla distribuzione a priori, indicando che i dati hanno ridotto l’incertezza sul valore di \\(\\lambda\\).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#modello-coniugato-gamma-poission",
    "title": "48  Modello coniugato Gamma-Poisson",
    "section": "48.5 Modello Coniugato Gamma-Poission",
    "text": "48.5 Modello Coniugato Gamma-Poission\nPer calcolare analiticamente la distribuzione a posteriori nel contesto di un modello gamma-Poisson possiamo seguire un processo diretto. Il modello Gamma-Poisson è coniugato, il che significa che la distribuzione a posteriori sarà ancora una distribuzione Gamma.\nSeguendo il teorema di Bayes, possiamo scrivere la distribuzione a posteriori come:\n\\(f(\\lambda \\mid y) \\propto f(y \\mid \\lambda) \\cdot f(\\lambda) ,\\)\ndove \\(f(\\lambda \\mid y)\\) è la distribuzione a posteriori, \\(f(y \\mid \\lambda)\\) è la verosimiglianza e \\(f(\\lambda)\\) è la distribuzione a priori.\nDefiniamo la verosimiglianza (distribuzione di Poisson):\n\\(f(y \\mid \\lambda) = \\prod_{i=1}^n \\frac{e^{-\\lambda}\\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!}.\\)\nDefiniamo la distribuzione a priori (distribuzione Gamma):\n\\(f(\\lambda) = \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nOra, moltiplichiamo la verosimiglianza per la distribuzione a priori:\n\\(f(\\lambda|y) \\propto \\frac{e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i}}{\\prod_{i=1}^n y_i!} \\cdot \\frac{b^a}{\\Gamma(a)}\\lambda^{a-1}e^{-b\\lambda}.\\)\nSemplifichiamo, eliminando i termini costanti (che non dipendono da \\(\\lambda\\)):\n\\(f(\\lambda \\mid y) \\propto e^{-n\\lambda}\\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1}e^{-b\\lambda}.\\)\nRaggruppiamo i termini:\n\\(f(\\lambda|y) \\propto \\lambda^{\\sum_{i=1}^n y_i} \\cdot \\lambda^{a-1} \\cdot e^{-n\\lambda} \\cdot e^{-b\\lambda}.\\)\nSemplifichiamo ulteriormente:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{\\sum_{i=1}^n y_i + a - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nRiconosciamo che questa è la forma di una distribuzione Gamma con nuovi parametri:\n\\(f(\\lambda \\mid y) \\propto \\lambda^{(\\sum_{i=1}^n y_i + a) - 1} \\cdot e^{-(n+b)\\lambda}.\\)\nQuindi, la distribuzione a posteriori è una Gamma con parametri:\n\n\\(\\alpha_{post} = a + \\sum_{i=1}^n y_i\\),\n\\(\\beta_{post} = b + n\\),\n\ndove:\n\n\\(a\\) e \\(b\\) sono i parametri della distribuzione Gamma a priori,\n\\(\\sum_{i=1}^n y_i\\) è la somma di tutte le osservazioni,\n\\(n\\) è il numero di osservazioni.\n\nQuesta derivazione mostra come la distribuzione a posteriori mantiene la forma di una Gamma, ma con parametri aggiornati che incorporano l’informazione dai dati osservati.\nConsideriamo nuovamente l’esempio precedente. Utilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori.\n\n# Aggiornamento dei parametri per la distribuzione a posteriori\nalpha_post = alpha_prior + np.sum(y)\nbeta_post = beta_prior + len(y)\n\n# Calcolo della distribuzione a posteriori analitica sulla griglia\nposterior_analytic = stats.gamma.pdf(lambda_grid, a=alpha_post, scale=1 / beta_post)\n\n# Plot della distribuzione a posteriori analitica\nplt.plot(lambda_grid, posterior_analytic)\nplt.title(\"Distribuzione a Posteriori Gamma-Poisson Analitica\")\nplt.xlabel(\"$\\lambda$\")\nplt.ylabel(\"Densità di probabilità\")\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico mostra la distribuzione a posteriori analitica del parametro di tasso \\(\\lambda\\) di un modello di Poisson, ottenuta utilizzando una distribuzione a priori Gamma e aggiornando i parametri alla luce dei dati osservati. La distribuzione a posteriori è calcolata come una Gamma aggiornata con i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\), e rappresenta la nostra conoscenza aggiornata dopo aver visto i dati. I risultati analitici concordano con quelli ottenuti tramite simulazione.\nProcediamo ora con il calcolo della soluzione analitica per la media della distribuzione a posteriori del parametro \\(\\lambda\\).\n\n# Posterior gamma parameters.\nshape = alpha_prior + y.sum()\nrate = beta_prior + y.size\n\n# Posterior mean.\nprint(f\"Posterior Mean = {shape / rate: 0.3f}\")\n\nPosterior Mean =  2.200\n\n\nSapendo che la distribuzione a posteriori è una Gamma di parametri\n\nprint(f\"shape = {shape: 0.1f}\")\nprint(f\"rate = {rate: 0.1f}\")\n\nshape =  22.0\nrate =  10.0\n\n\npossiamo calcolare la probabilità di qualsiasi evento di interesse. Per esempio, ci possiamo chiedere quale sia la probabilità di osservare più di 3 compulsioni per ora:\n\n# Calcolo della probabilità che y &gt; 3\nprob_y_greater_than_3 = 1 - stats.gamma.cdf(3, a=shape, scale=1/rate)\n\nprint(\n    f\"La probabilità di osservare più di 3 compulsioni per ora è {prob_y_greater_than_3: 0.3f}\"\n)\n\nLa probabilità di osservare più di 3 compulsioni per ora è  0.054",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#riflessioni-conclusive",
    "title": "48  Modello coniugato Gamma-Poisson",
    "section": "48.6 Riflessioni Conclusive",
    "text": "48.6 Riflessioni Conclusive\nIl modello Gamma-Poisson offre un framework robusto per l’inferenza bayesiana su dati di conteggio in psicologia. Partendo da una distribuzione a priori Gamma, che rappresenta la nostra conoscenza iniziale sul tasso medio, siamo in grado di aggiornare questa conoscenza alla luce dei dati osservati, ottenendo una distribuzione a posteriori che riflette in modo più preciso la realtà sottostante. Questo approccio permette di quantificare l’incertezza associata alle nostre stime e di prendere decisioni informate sulla base dei dati disponibili.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#esercizi",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#esercizi",
    "title": "48  Modello coniugato Gamma-Poisson",
    "section": "48.7 Esercizi",
    "text": "48.7 Esercizi\n\nEsercizio 48.1 Consideriamo uno studio longitudinale su coppie, dove i partecipanti registrano quotidianamente la frequenza con cui nascondono il loro comportamento di fumo al partner. Basandoci sui dati di Scholz et al. (2021), assumiamo che il tasso medio di nascondere il fumo sia di 1.52 volte al giorno. Supponiamo di avere i seguenti dati giornalieri per un partecipante:\n\nGiorno 1: 2 volte.\nGiorno 2: 0 volte.\nGiorno 3: 1 volta.\nGiorno 4: 3 volte.\n\nUtilizzare un modello Gamma-Poisson per stimare la distribuzione a posteriori del tasso individuale di nascondere il fumo per un partecipante specifico, dato il suo insieme di osservazioni giornaliere.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/09_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/09_gamma_poisson_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "48  Modello coniugato Gamma-Poisson",
    "section": "48.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "48.8 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue Nov 19 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.1.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\npandas    : 2.2.2\nseaborn   : 0.13.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021). How do people experience and respond to social control from their partner? Three daily diary studies. Frontiers in Psychology, 11, 613546.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Modello coniugato Gamma-Poisson</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html",
    "title": "49  Modello gamma-esponenziale",
    "section": "",
    "text": "49.1 Introduzione\nNell’inferenza bayesiana, il modello coniugato Gamma-Esponenziale rappresenta un approccio analitico efficace per l’analisi di dati che seguono una distribuzione esponenziale. Questa distribuzione è comunemente utilizzata per modellare i tempi di attesa tra eventi in processi di Poisson, come ad esempio gli intervalli tra arrivi in un sistema a coda o la durata di eventi psicologici.\nConsideriamo, ad esempio, un esperimento in psicologia in cui si misurano i tempi di insorgenza di episodi di ansia in seguito a un evento stressante. In questo caso, si può ipotizzare che i tempi di insorgenza siano distribuiti esponenzialmente. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio con cui si verificano gli episodi di ansia.\nIl modello coniugato Gamma-Esponenziale consente di stimare il parametro \\(\\lambda\\) utilizzando i dati osservati. La distribuzione a priori Gamma viene utilizzata per rappresentare l’incertezza iniziale su \\(\\lambda\\), mentre la distribuzione esponenziale modella i dati osservati. Grazie a questa coniugazione, l’aggiornamento delle credenze sul parametro \\(\\lambda\\) avviene in modo semplice e analitico, permettendo di ottenere una stima bayesiana del tasso medio di occorrenza degli episodi di ansia, fornendo così una descrizione probabilistica accurata del fenomeno in esame.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#introduzione",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#introduzione",
    "title": "49  Modello gamma-esponenziale",
    "section": "",
    "text": "49.1.1 Il Modello Matematico\nCaso singolo. Supponiamo di osservare un singolo tempo di attesa \\(y_1\\) prima che si verifichi un evento, come un episodio di disagio psicologico. Assumiamo che questo tempo di attesa segua una distribuzione esponenziale con parametro \\(\\lambda\\). La funzione di densità di probabilità (pdf) della distribuzione esponenziale è data da:\n\\[\nf(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1},\n\\]\ndove:\n\n\\(y_1\\) rappresenta il tempo di attesa,\n\\(\\lambda\\) è il parametro della distribuzione, che rappresenta il tasso medio con cui gli eventi si verificano per unità di tempo.\n\nIn questa distribuzione, \\(\\lambda\\) è il tasso di occorrenza o tasso di decadimento, ed è l’inverso del tempo medio di attesa. Più precisamente:\n\nIl tempo medio di attesa è il valore medio del tempo che trascorre prima che l’evento si verifichi (ad esempio, quanto tempo ci si aspetta in media prima che arrivi un autobus).\nIl parametro \\(\\lambda\\) rappresenta la frequenza con cui l’evento si verifica per unità di tempo, e quindi \\(\\lambda = \\frac{1}{\\text{tempo medio}}\\).\n\nPertanto, nella funzione esponenziale \\(f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}\\), il parametro \\(\\lambda\\) è inversamente proporzionale al tempo medio di attesa: più grande è \\(\\lambda\\), più breve è il tempo medio di attesa tra gli eventi.\nQuesta funzione descrive la probabilità di osservare un tempo di attesa esattamente uguale a \\(y_1\\), dato un valore specifico di \\(\\lambda\\). Per la distribuzione esponenziale, la media è \\(\\frac{1}{\\lambda}\\) e la varianza è \\(\\frac{1}{\\lambda^2}\\), il che riflette l’influenza del tasso \\(\\lambda\\) sulla dispersione dei tempi di attesa.\nPer fare un esempio, supponiamo che il tempo medio di attesa sia 2 ore. In tali circostanze, il parametro \\(\\lambda\\) (l’inverso del tempo medio di attesa) è \\(\\frac{1}{2}\\).\n\n# Parametro lambda (l'inverso del tempo medio di attesa)\nlambda_value = 1 / 2\n\nDisegniamo la funzione esponenziale per tempi di attesa compresi tra 0 e 10 ore.\n\n# Creazione dei valori di y1 su cui valutare la funzione\ny1_values = np.linspace(0, 10, 500)  # Intervallo da 0 a 10 ore\n\n# Definizione della funzione di densità esponenziale\ndef exponential_density(y1, lambda_value):\n    return lambda_value * np.exp(-lambda_value * y1)\n\n# Calcolo dei valori di f(y1 | lambda)\nf_values = exponential_density(y1_values, lambda_value)\n\n# Creazione del grafico\nplt.plot(y1_values, f_values, label=r'$f(y_1 \\mid \\lambda) = \\lambda e^{-\\lambda y_1}$')\nplt.title('Funzione di Densità Esponenziale con $\\lambda = 1/2$')\nplt.xlabel('Tempo di attesa (ore)')\nplt.ylabel('Densità')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIl caso di \\(n\\) osservazioni indipendenti. Consideriamo ora un campione di \\(n\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_n\\). L’indipendenza tra le osservazioni implica che il tempo di attesa osservato per un evento non influisce sulla probabilità di osservare altri tempi di attesa.\nPoiché le osservazioni sono indipendenti, la probabilità congiunta di osservare tutti i tempi di attesa nel campione è il prodotto delle probabilità individuali. Di conseguenza, la funzione di verosimiglianza per l’intero campione è data da:\n\\[\nf(y_1, y_2, \\dots, y_n \\mid \\lambda) = f(y_1 \\mid \\lambda) \\cdot f(y_2 \\mid \\lambda) \\cdot \\dots \\cdot f(y_n \\mid \\lambda).\n\\]\nSostituendo la funzione di densità della distribuzione esponenziale per ciascuna osservazione, otteniamo:\n\\[\nf(y \\mid \\lambda) = \\lambda e^{-\\lambda y_1} \\cdot \\lambda e^{-\\lambda y_2} \\cdot \\dots \\cdot \\lambda e^{-\\lambda y_n}.\n\\]\nRaccogliendo i termini comuni, possiamo riscrivere la funzione di verosimiglianza come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda (y_1 + y_2 + \\dots + y_n)}.\n\\]\nUtilizzando la notazione di sommatoria, possiamo esprimere la funzione di verosimiglianza in modo compatto come:\n\\[\nf(y \\mid \\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} y_i}.\n\\]\nLa funzione di verosimiglianza \\(f(y \\mid \\lambda)\\) rappresenta la probabilità di osservare il campione \\(y_1, y_2, \\dots, y_n\\) dato un particolare valore del parametro \\(\\lambda\\). Un valore più alto della verosimiglianza indica una maggiore plausibilità del valore di \\(\\lambda\\), dato il campione osservato.\nSpesso è più conveniente lavorare con il logaritmo della funzione di verosimiglianza, poiché il logaritmo trasforma i prodotti in somme, semplificando i calcoli. Il logaritmo della funzione di verosimiglianza è:\n\\[\n\\log L(\\lambda \\mid y_1, y_2, \\dots, y_n) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} y_i.\n\\]\nQuesta forma semplificata della log-verosimiglianza è utile per stimare il parametro \\(\\lambda\\) tramite tecniche come la massimizzazione della verosimiglianza.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#aggiornare-le-nostre-credenze-con-linferenza-bayesiana",
    "title": "49  Modello gamma-esponenziale",
    "section": "49.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana",
    "text": "49.2 Aggiornare le Nostre Credenze con l’Inferenza Bayesiana\nNell’approccio bayesiano, non consideriamo solo i dati, ma anche le nostre conoscenze a priori sul parametro \\(\\lambda\\). Assegniamo a \\(\\lambda\\) una distribuzione a priori, tipicamente una distribuzione Gamma. Combinando la verosimiglianza con la distribuzione a priori, otteniamo la distribuzione a posteriori di \\(\\lambda\\), che rappresenta la nostra conoscenza aggiornata alla luce dei dati. La proprietà della coniugazione assicura che la distribuzione a posteriori sia anch’essa una Gamma, facilitando i calcoli.\nPer fare un esempio concreto, simuleremo un campione di dati. Immaginiamo di raccogliere dati che rappresentano il tempo, misurato in ore, che intercorre tra episodi di ansia in individui con disturbi d’ansia. La distribuzione esponenziale può essere utilizzata per modellare questo tempo di attesa tra un episodio di ansia e il successivo. Ad esempio, possiamo ipotizzare che, una volta concluso un episodio, l’insorgenza del prossimo segua un processo stocastico con un tasso costante, indipendentemente dal tempo trascorso dall’episodio precedente. In questo contesto, il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso medio di occorrenza degli episodi di ansia, ossia quanti episodi ci si aspetta in media in una certa unità di tempo (ad esempio, in un giorno).\nIn pratica, se \\(\\lambda\\) è elevato, ciò indica che gli episodi di ansia sono più frequenti, con tempi di attesa più brevi tra un episodio e l’altro.\n\n# Imposta il seed per rendere i risultati riproducibili\nnp.random.seed(42)\n\n# Parametro lambda per la distribuzione esponenziale\nmean = 3.0\nlambda_param = 1 / mean\n\n# Numero di osservazioni nel campione\nn = 15\n\n# Generazione del campione casuale\n\ny = np.random.exponential(scale=mean, size=n).round()\nprint(y)\n\n[ 1.  9.  4.  3.  1.  1.  0.  6.  3.  4.  0. 11.  5.  1.  1.]\n[ 1.  9.  4.  3.  1.  1.  0.  6.  3.  4.  0. 11.  5.  1.  1.]\n\n\nImmaginiamo che questi dati corrispondano al tempo di attesa in ore tra episodi di ansia in 14 individui con disturbi d’ansia. Il tempo di attesa medio è\n\nnp.mean(y)\n\n3.3333333333333335\n\n\ne quindi il tasso di occorrenza, \\(\\lambda\\), è\n\n1 / np.mean(y)\n\n0.3\n\n\nPoniamoci il problema di trovare la distribuzione a posteriori per il tasso di occorrenza \\(\\lambda\\).\n\n49.2.1 Passi per definire un prior debolmente informativo\nIl primo passo consiste nel definire una distribuzione a priori per \\(\\lambda\\), il tasso di occorrenza degli episodi di ansia in individui con disturbi d’ansia. Se disponiamo di poche informazioni a priori riguardo al valore di \\(\\lambda\\), possiamo adottare una distribuzione a priori debolmente informativa. Un prior debolmente informativo ha lo scopo di esercitare una minima influenza sull’inferenza, consentendo ai dati osservati di guidare principalmente la stima del parametro.\nLa distribuzione a priori coniugata per la distribuzione esponenziale è la distribuzione Gamma. Un prior debolmente informativo per \\(\\lambda\\) potrebbe essere impostato in modo tale da riflettere una conoscenza vaga, con una media che rappresenta un tempo di attesa ragionevole (basato su qualche informazione preliminare o ipotesi generale), ma con una varianza ampia, in modo da non vincolare eccessivamente l’inferenza.\nSupponiamo, ad esempio, di voler impostare il prior con una media pari a 3.33 ore e una deviazione standard ampia, come 5. Tuttavia, vogliamo una distribuzione a priori per λ, che rappresenta il tasso di occorrenza (cioè l’inverso del tempo medio di attesa). Dobbiamo dunque applicare la distribuzione Gamma ai valori di λ, non direttamente ai tempi di attesa. In tali circostanze, i parametri \\(\\alpha\\) (forma) e \\(\\theta\\) (scala) sono dati da:\n\n\\(\\alpha_{\\text{prior}} = 0.45\\),\n\\(\\beta_{\\text{prior}} = 1.5\\).\n\n\n# Parametri della distribuzione Gamma\nalpha_prior = 0.45  # Forma\nbeta_prior = 1.5   # Tasso (inverso della scala)\n\n# Creazione dei valori x per il grafico\nx = np.linspace(0, 2, 500)\n\n# Funzione di densità della distribuzione Gamma con i parametri dati\ngamma_pdf = stats.gamma.pdf(x, a=alpha_prior, scale=1/beta_prior)\n\n# Creazione del grafico\nplt.figure(figsize=(8, 6))\nplt.plot(x, gamma_pdf, label=f'Gamma PDF ($\\\\alpha$={alpha}, $\\\\beta$={beta})')\nplt.xlabel('x')\nplt.ylabel('Densità di probabilità')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nVerifichiamo:\n\n# Calcoliamo la media e la varianza della distribuzione Gamma per il tasso di occorrenza (lambda)\nmean_lambda = alpha / beta\nvariance_lambda = alpha / (beta**2)\n\n# Ora trasformiamo questi valori per ottenere la media e la varianza dei tempi di attesa, non del tasso\nmean_waiting_time = 1 / mean_lambda\nvariance_waiting_time = variance_lambda / (mean_lambda**4)  # Trasformazione della varianza per il tempo di attesa\n\nmean_waiting_time, variance_waiting_time\n\n(3.3333333333333335, 24.69135802469136)\n\n\nLa media e la varianza della distribuzione Gamma per il tasso di occorrenza (λ) sono state calcolate come segue:\n\nLa media del tempo di attesa (trasformata dalla media del tasso) è 3.33 ore.\nLa varianza del tempo di attesa è 24.59 ore.\n\nQuesti valori riflettono il tempo di attesa medio e la variabilità nei tempi di attesa degli episodi di ansia, non più il reciproco del tempo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#metodo-basato-su-griglia",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#metodo-basato-su-griglia",
    "title": "49  Modello gamma-esponenziale",
    "section": "49.3 Metodo Basato su Griglia",
    "text": "49.3 Metodo Basato su Griglia\nPoniamoci l’obiettivo di usare il metodo basato su griglia per derivare la distribuzione a posteriori per il parametro \\(\\lambda\\) della distribuzione esponenziale. Iniziamo con la creazione della griglia per \\(\\lambda\\) nell’intervallo [0.01, 10].\n\n# Evita zero per evitare divisione per zero\nlambda_grid = np.linspace(0.01, 2, 1000)\n\nCalcoliamo la distribuzione a priori.\n\nprior = stats.gamma.pdf(lambda_grid, a=alpha_prior, scale=1 / beta_prior)\n\nCalcoliamo la verosimiglianza per ciascun valore di lambda.\n\nlikelihood = np.ones_like(lambda_grid)\nfor yi in y:\n    likelihood *= stats.expon.pdf(yi, scale=1 / lambda_grid)\n\nCalcoliamo la distribuzione a posteriori non normalizzata.\n\nposterior_unnormalized = likelihood * prior\n\nNormalizziamo la distribuzione a posteriori.\n\nposterior = posterior_unnormalized / np.sum(\n    posterior_unnormalized * (lambda_grid[1] - lambda_grid[0])\n)\n\nVisualizzazione dei risultati.\n\nplt.plot(lambda_grid, posterior, label=\"Distribuzione a Posteriori\")\nplt.plot(lambda_grid, prior, \"--\", label=\"Distribuzione a Priori\")\nplt.xlabel(r\"$\\lambda$\")\nplt.ylabel(\"Densità di probabilità\")\nplt.legend()\nplt.title(\"Distribuzione a Posteriori di $\\lambda$\")\nplt.show()",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#modello-coniugato-gamma-esponenziale",
    "title": "49  Modello gamma-esponenziale",
    "section": "49.4 Modello Coniugato Gamma-Esponenziale",
    "text": "49.4 Modello Coniugato Gamma-Esponenziale\nQuando utilizziamo una distribuzione \\(\\text{Gamma}(\\alpha, \\beta)\\) come distribuzione coniugata a priori, la distribuzione a posteriori risulta anch’essa essere una distribuzione Gamma, con parametri aggiornati \\(\\alpha + n\\) e \\(\\beta + \\sum_{i=1}^{n} x_{i}\\).\nIn altre parole, se il parametro \\(\\lambda\\) della distribuzione esponenziale segue una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\), allora, dopo aver osservato un campione di \\(n\\) osservazioni \\(x_1, x_2, \\dots, x_n\\), la distribuzione a posteriori di \\(\\lambda\\) sarà ancora una distribuzione Gamma, ma con i parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_{i}).\n\\]\nQuesto aggiornamento dei parametri è una conseguenza della proprietà coniugata della distribuzione Gamma rispetto alla distribuzione esponenziale.\n\n49.4.1 Dimostrazione del Modello Coniugato Gamma-Esponenziale\nPer dimostrare questo risultato, partiamo dal teorema di Bayes:\n\\[\nf(\\lambda \\mid x) \\propto f(x \\mid \\lambda) \\cdot f(\\lambda),\n\\]\ndove \\(f(\\lambda \\mid x)\\) è la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\), \\(f(x \\mid \\lambda)\\) è la verosimiglianza basata sul campione \\(x\\), e \\(f(\\lambda)\\) è la distribuzione a priori di \\(\\lambda\\).\nLa funzione di verosimiglianza per un campione di \\(n\\) osservazioni indipendenti \\(x_1, x_2, \\dots, x_n\\), che seguono una distribuzione esponenziale con parametro \\(\\lambda\\), è data da:\n\\[\nf(x \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i}.\n\\]\nSupponiamo che il parametro \\(\\lambda\\) segua una distribuzione a priori Gamma con parametri \\(\\alpha\\) e \\(\\beta\\):\n\\[\nf(\\lambda) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nMoltiplicando la verosimiglianza per la distribuzione a priori, otteniamo la distribuzione a posteriori:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} x_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n\\]\nSemplificando, si ottiene:\n\\[\nf(\\lambda \\mid x) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left(\\beta + \\sum_{i=1}^{n} x_i\\right)}.\n\\]\nQuesta espressione corrisponde alla forma di una distribuzione Gamma con parametri aggiornati:\n\nparametro della forma (alpha): \\(\\alpha_{\\text{post}} = \\alpha + n\\);\nparametro della scala (beta): \\(\\beta_{\\text{post}} = \\beta + \\sum_{i=1}^{n} x_i\\).\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) dato il campione \\(x\\) segue una distribuzione Gamma con parametri aggiornati:\n\\[\n\\lambda \\mid x \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum_{i=1}^{n} x_i).\n\\]\nQuesta derivazione mostra come l’informazione contenuta nei dati osservati venga incorporata nei parametri della distribuzione a posteriori, mantenendo la forma della distribuzione a priori grazie alla proprietà coniugata.\nPer il caso dell’esempio in discussione,\n\nil numero di osservazioni nel campione \\(n\\) è 15;\nla somma delle osservazioni del campione è:\n\n\\[\n\\sum_{i=1}^{n} y_i = 1 + 9 + 4 + 3 + 1 + 1 + 0 + 6 + 3 + 4 + 0 + 11 + 5 + 1 + 1 = 50\n\\]\nI parametri aggiornati della distribuzione a posteriori sono:\n\\[\n\\alpha_{\\text{post}} = 15 + 0.009 = 15.009.\n\\]\n\\[\n\\beta_{\\text{post}} = 50 + 0.03 = 50.03.\n\\]\nUtilizzando i parametri aggiornati, rappresentiamo graficamente la distribuzione a posteriori.\n\n# Aggiornamento dei parametri per la distribuzione a posteriori\nalpha_post = alpha_prior + len(y)\nbeta_post = beta_prior + np.sum(y)\n\nprint(f\"alpha_post = {alpha_post}; beta_post = {beta_post:.4f}\")\n\nalpha_post = 15.45; beta_post = 51.5000\nalpha_post = 15.45; beta_post = 51.5000\n\n\nQuindi, la distribuzione a posteriori di \\(\\lambda\\) è:\n\\[\np(\\lambda \\mid y) \\sim \\text{Gamma}(15.009, 50.03).\n\\]\n\n# Parametri della distribuzione Gamma a posteriori\nalpha_post = 15.009\nbeta_post = 50.03\n\n# Griglia di valori di lambda per il plot\nlambda_grid = np.linspace(0, 2, 1000)\n\n# Calcolo della distribuzione Gamma a posteriori\nposterior_pdf = stats.gamma.pdf(lambda_grid, a=alpha_post, scale=1 / beta_post)\n\n# Plot della distribuzione a posteriori\nplt.plot(\n    lambda_grid,\n    posterior_pdf,\n    label=r\"$\\Gamma(\\alpha_{\\text{post}}=15.009, \\beta_{\\text{post}} = 50.03)$\",\n)\nplt.xlabel(r\"$\\lambda$\")\nplt.ylabel(\"Densità di probabilità\")\nplt.title(\"Distribuzione Gamma a Posteriori\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesta distribuzione Gamma a posteriori riflette l’informazione combinata proveniente sia dal prior che dai dati osservati. Con i parametri \\(\\alpha_{\\text{posteriori}} = 15.009\\) e \\(\\beta_{\\text{posteriori}} = 50.03\\), la distribuzione a posteriori di \\(\\lambda\\) (il tasso di occorrenza degli episodi di ansia) sarà centrata attorno alla media:\n\\[\n\\text{E}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{posteriori}}}{\\beta_{\\text{posteriori}}} \\approx \\frac{15.009}{50.03} \\approx 0.3,\n\\]\ncon una varianza:\n\\[\n\\text{Var}[\\lambda \\mid y] = \\frac{\\alpha_{\\text{posteriori}}}{\\beta_{\\text{posteriori}}^2} \\approx \\frac{15.009}{50.03^2} \\approx 0.006.\n\\]\nQuesti valori si riferiscono alla distribuzione del tasso di occorrenza \\(\\lambda\\), che rappresenta il reciproco del tempo medio di attesa tra episodi di ansia.\n\n\n49.4.2 Trasformazione della media e della varianza\nPer interpretare questi risultati in termini di tempi di attesa, dobbiamo trasformare i valori sulla scala inversa, cioè passare dal tasso \\(\\lambda\\) ai tempi di attesa \\(T = \\frac{1}{\\lambda}\\).\nLa media del tempo di attesa \\(T\\) è l’inverso della media del tasso di occorrenza \\(\\lambda\\). Pertanto, la media dei tempi di attesa sarà:\n\\[\n\\text{E}[T \\mid y] = \\frac{1}{\\text{E}[\\lambda \\mid y]} = \\frac{1}{0.3} \\approx 3.33 \\, \\text{ore}.\n\\]\nPer la varianza del tempo di attesa, dobbiamo applicare una trasformazione più complessa. La varianza del tempo di attesa \\(T\\) è legata alla varianza di \\(\\lambda\\) da:\n\\[\n\\text{Var}(T) = \\frac{\\text{Var}[\\lambda \\mid y]}{(\\text{E}[\\lambda \\mid y])^4}.\n\\]\nSostituendo i valori calcolati per la varianza e la media di \\(\\lambda\\), otteniamo:\n\\[\n\\text{Var}(T) \\approx \\frac{0.006}{(0.3)^4} \\approx 24.59 \\, \\text{ore}.\n\\]\nIn conclusione,\n\nla media del tempo di attesa a posteriori è di circa 3.33 ore;\nla varianza del tempo di attesa a posteriori è di circa 24.59 ore, che indica una certa dispersione dei tempi di attesa, con alcuni episodi che possono verificarsi molto più rapidamente o più lentamente rispetto alla media. Si noti che la distribuzione a posteriori è più concentrata rispetto al prior, poiché incorpora l’informazione aggiuntiva proveniente dai dati osservati.\n\nQuesta trasformazione ci permette di interpretare i risultati sulla scala dei tempi di attesa, che è più intuitiva per descrivere fenomeni psicologici come l’insorgenza di episodi di ansia.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#applicazioni",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#applicazioni",
    "title": "49  Modello gamma-esponenziale",
    "section": "49.5 Applicazioni",
    "text": "49.5 Applicazioni\nUna volta ottenuta la distribuzione a posteriori per λ, possiamo utilizzarla per rispondere a domande probabilistiche relative ai tempi di attesa tra episodi di ansia. Questo approccio ci consente di calcolare probabilità aggiornate alla luce dei dati osservati, rispecchiando meglio l’incertezza e le informazioni disponibili. Ad esempio, possiamo stimare la probabilità di osservare tempi di attesa compresi tra 2 e 5 ore.\nPer risolvere questo problema possiamo usare il metodo Monte Carlo:\n\nGeneriamo un gran numero di campioni dalla distribuzione Gamma a posteriori di \\(\\lambda\\), usando i parametri \\(\\alpha_{\\text{posteriori}}\\) e \\(\\beta_{\\text{posteriori}}\\).\nConvertiamo ciascun \\(\\lambda\\) campionato in un tempo di attesa \\(T = \\frac{1}{\\lambda}\\).\nCalcoliamo le probabilità richieste (ad esempio, \\(P(T &gt; 2)\\) e \\(P(T &lt; 5)\\)) semplicemente contando le proporzioni di campioni che soddisfano tali condizioni.\n\nProcediamo con l’implementazione in Python.\n\n# Parametri posteriori per la distribuzione Gamma\nalpha_post = 15.009\nbeta_post = 50.03\n\n# Numero di campioni da generare\nn_samples = 100000\n\n# Simuliamo i campioni dalla distribuzione a posteriori di lambda (Gamma)\nlambda_samples = np.random.gamma(alpha_post, 1/beta_post, n_samples)\n\n# Convertiamo i campioni di lambda nei tempi di attesa T = 1/lambda\nwaiting_time_samples = 1 / lambda_samples\n\n# Calcoliamo la probabilità che il tempo di attesa sia compreso tra 2 e 5 ore\nprob_between_2_and_5_mc = np.mean((waiting_time_samples &gt;= 2) & (waiting_time_samples &lt;= 5))\n\nprob_between_2_and_5_mc\n\n0.90603\n\n\nLa probabilità che il tempo di attesa tra due episodi di ansia sia compreso tra 2 e 5 ore è di circa 0.9029, ovvero circa il 90.3%.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#riflessioni-conclusive",
    "title": "49  Modello gamma-esponenziale",
    "section": "49.6 Riflessioni Conclusive",
    "text": "49.6 Riflessioni Conclusive\nIl modello esponenziale si rivela uno strumento utile e versatile nella ricerca psicologica, in particolare per la modellazione di fenomeni caratterizzati da tempi di attesa o durate di eventi. È applicabile in vari contesti, tra cui l’analisi dei tempi di reazione, lo studio degli intervalli tra episodi di ansia o depressione e, più in generale, in tutti quei processi psicologici che possono essere descritti come il tempo trascorso fino al verificarsi di un evento.\nUn aspetto particolarmente vantaggioso dell’uso di modelli basati sulla distribuzione esponenziale nell’inferenza bayesiana è la possibilità di utilizzare le famiglie coniugate. Nella famiglia coniugata Gamma-Esponenziale, la distribuzione a priori Gamma per il tasso \\(\\lambda\\) si aggiorna in modo analitico quando si osservano nuovi dati esponenziali. Questo rende i calcoli bayesiani particolarmente efficienti e semplici da implementare, poiché la distribuzione a posteriori rimane della stessa forma della distribuzione a priori (ossia, una Gamma). Tale proprietà coniugata consente di ottenere una stima aggiornata del tasso \\(\\lambda\\) e di fare inferenze accurate sui tempi di attesa futuri.\nLa combinazione tra la distribuzione esponenziale e il prior Gamma non solo semplifica l’inferenza, ma fornisce anche una struttura interpretativa chiara. Ad esempio, il parametro \\(\\lambda\\), che rappresenta il tasso di occorrenza di un fenomeno, viene aggiornato sulla base dell’evidenza osservata, consentendo una stima dinamica della frequenza con cui gli episodi si verificano. Questo approccio bayesiano offre un’interpretazione probabilistica naturale dei tempi di attesa futuri, rispecchiando l’incertezza presente nei dati.\nInoltre, grazie alla flessibilità del metodo Monte Carlo, è possibile simulare campioni dalla distribuzione a posteriori di \\(\\lambda\\) e ottenere stime precise per una vasta gamma di probabilità, come la probabilità che il tempo di attesa sia compreso tra intervalli specifici. Questo approccio simulativo permette di rispondere a domande specifiche relative ai processi psicologici, ad esempio la probabilità che un episodio di ansia duri più di un certo numero di ore.\nIn conclusione, il modello esponenziale, integrato in un framework bayesiano con famiglie coniugate, rappresenta un utile strumento per la ricerca psicologica. Offre un modo rigoroso per modellare e analizzare dati su tempi di attesa e durate, fornendo al contempo una base solida per l’inferenza e la previsione dei processi psicologici.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/10_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/10_gamma_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "49  Modello gamma-esponenziale",
    "section": "49.7 Informazioni sull’Ambiente di Sviluppo",
    "text": "49.7 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Sep 11 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\nLast updated: Wed Sep 11 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Modello gamma-esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html",
    "title": "50  Distribuzione predittiva a posteriori",
    "section": "",
    "text": "50.1 Introduzione\nIn questo capitolo esploreremo il concetto di distribuzione predittiva a posteriori, concentrandoci sul caso discreto. Per illustrare questo concetto in modo chiaro e intuitivo, utilizzeremo il problema del “bag of coins” come esempio esplicativo.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#previsioni-su-eventi-futuri",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#previsioni-su-eventi-futuri",
    "title": "50  Distribuzione predittiva a posteriori",
    "section": "50.2 Previsioni su Eventi Futuri",
    "text": "50.2 Previsioni su Eventi Futuri\nLa distribuzione predittiva a posteriori è un concetto chiave nell’inferenza bayesiana. In parole semplici, rappresenta le probabilità degli eventi futuri basate su ciò che abbiamo già osservato. In altre parole, è come fare previsioni su quello che potrebbe succedere, utilizzando le informazioni raccolte fino a quel momento e le nostre convinzioni aggiornate (a posteriori).",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#definizione",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#definizione",
    "title": "50  Distribuzione predittiva a posteriori",
    "section": "50.3 Definizione",
    "text": "50.3 Definizione\nImmagina di avere un insieme di dati che hai già osservato, chiamato \\(y = \\{y_1, y_2, \\ldots, y_n\\}\\). Supponiamo che questi dati siano stati generati da un modello con un parametro sconosciuto \\(\\theta\\), e che tu abbia una qualche idea iniziale (detta a priori) su quale possa essere il valore di \\(\\theta\\), rappresentata dalla distribuzione \\(p(\\theta)\\).\nDopo aver osservato i dati, possiamo aggiornare la nostra idea iniziale per ottenere una nuova distribuzione per \\(\\theta\\), chiamata distribuzione a posteriori, indicata come \\(p(\\theta | y)\\). Questa distribuzione riflette quello che abbiamo imparato sui parametri del modello dopo aver visto i dati.\nLa formula per la distribuzione a posteriori è:\n\\[\np(\\theta | y) = \\frac{p(y | \\theta) p(\\theta)}{p(y)},\n\\]\ndove:\n\n\\(p(\\theta | y)\\) è la distribuzione a posteriori del parametro \\(\\theta\\);\n\\(p(y | \\theta)\\) è la probabilità di osservare i dati dati i parametri, chiamata verosimiglianza;\n\\(p(\\theta)\\) è la distribuzione a priori del parametro \\(\\theta\\);\n\\(p(y)\\) è la probabilità di osservare quei dati, chiamata anche evidenza.\n\nPer fare previsioni su un nuovo dato \\(\\tilde{y}\\), usiamo la distribuzione predittiva a posteriori. Questa si ottiene combinando tutte le possibili ipotesi sui parametri del modello, pesandole per quanto le riteniamo probabili in base ai dati osservati:\n\\[\np(\\tilde{y} | y) = \\int p(\\tilde{y} | \\theta) p(\\theta | y) \\, d\\theta.\n\\]\nSe il parametro \\(\\theta\\) può assumere solo alcuni valori discreti, invece di un integrale si usa una somma:\n\\[\np(\\tilde{y} | y) = \\sum_{\\theta} p(\\tilde{y} | \\theta) p(\\theta | y).\n\\]\nQuesta distribuzione combina la nostra convinzione aggiornata sui parametri \\(\\theta\\) con la probabilità di osservare un nuovo dato \\(\\tilde{y}\\), dato un certo valore di \\(\\theta\\). In questo modo, possiamo fare previsioni considerando tutte le incertezze che abbiamo sui parametri del modello.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#il-sacchetto-di-monete",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#il-sacchetto-di-monete",
    "title": "50  Distribuzione predittiva a posteriori",
    "section": "50.4 Il Sacchetto di Monete",
    "text": "50.4 Il Sacchetto di Monete\nIn questo esempio discutiamo un problema che consente di presentare il concetto di distribuzione predittiva a posteriori in un modo intuivito. Immaginiamo di avere un sacchetto contenente tre tipi diversi di monete. Questi tre tipi di monete hanno caratteristiche uniche riguardo la probabilità di ottenere “testa” o “croce” quando vengono lanciate:\n\nMoneta di Tipo 0: Questa moneta dà sempre “croce”. La probabilità di ottenere “testa” è 0.\nMoneta di Tipo 1: Questa è una moneta equa. La probabilità di ottenere “testa” è 0.5, e quindi anche la probabilità di ottenere “croce” è 0.5.\nMoneta di Tipo 2: Questa moneta dà sempre “testa”. La probabilità di ottenere “testa” è 1.\n\nSupponiamo di scegliere una moneta a caso dal sacchetto e di lanciarla quattro volte. In tutte e quattro le volte otteniamo “croce”. Ora vogliamo calcolare la probabilità di ottenere “croce” al quinto lancio.\n\n50.4.1 Passo 1: Probabilità Iniziali\nPrima di lanciare la moneta, non sappiamo quale tipo di moneta abbiamo estratto dal sacchetto. Poiché ogni moneta ha la stessa probabilità di essere scelta, attribuiamo una probabilità iniziale (prior) uguale a ciascun tipo di moneta:\n\nProbabilità di avere la Moneta di Tipo 0: \\(\\frac{1}{3}\\).\nProbabilità di avere la Moneta di Tipo 1: \\(\\frac{1}{3}\\).\nProbabilità di avere la Moneta di Tipo 2: \\(\\frac{1}{3}\\).\n\n\n\n50.4.2 Passo 2: Osservare i Risultati e Aggiornare le Probabilità\nDopo aver osservato quattro lanci che hanno dato tutti “croce”, possiamo aggiornare le nostre probabilità di avere un certo tipo di moneta utilizzando queste informazioni.\n\nMoneta di Tipo 0: Se avessimo questa moneta, ottenere “croce” in tutti i lanci è ciò che ci aspetteremmo, dato che dà sempre “croce”.\nMoneta di Tipo 1: Con questa moneta, ottenere quattro “croce” di fila è possibile ma piuttosto improbabile, dato che la probabilità di “croce” in ciascun lancio è solo 0.5.\nMoneta di Tipo 2: Con questa moneta, ottenere “croce” è impossibile perché dà sempre “testa”.\n\nBasandoci su queste osservazioni, è molto più probabile che la moneta scelta sia di Tipo 0. La probabilità di avere la Moneta di Tipo 1 è bassa, mentre la probabilità di avere la Moneta di Tipo 2 è zero.\n\n\n50.4.3 Passo 3: Calcolare le Probabilità Posteriori\nPer calcolare le nuove probabilità (posteriori) per ogni tipo di moneta dopo aver visto quattro “croce”, utilizziamo la formula di Bayes. Supponiamo che \\(D\\) rappresenti il dato “croce, croce, croce, croce”. Dopo i calcoli (che qui non dettagliamo, ma che presenteremo in seguito), otteniamo le seguenti probabilità posteriori:\n\nProbabilità a posteriori di avere la Moneta di Tipo 0: circa 0.941.\nProbabilità a posteriori di avere la Moneta di Tipo 1: circa 0.059.\nProbabilità a posteriori di avere la Moneta di Tipo 2: 0.\n\n\n\n50.4.4 Passo 4: Predire il Risultato del Quinto Lancio\nPer prevedere la probabilità di ottenere “croce” al quinto lancio, combiniamo le probabilità posteriori di ogni tipo di moneta con la probabilità di ottenere “croce” specifica a ciascun tipo:\n\nMoneta di Tipo 0: Probabilità di “croce” = 1.\nMoneta di Tipo 1: Probabilità di “croce” = 0.5.\nMoneta di Tipo 2: Probabilità di “croce” = 0.\n\nCalcoliamo ora la probabilità totale di ottenere “croce” al quinto lancio:\n\nContributo della Moneta di Tipo 0: \\(0.941 \\times 1 = 0.941\\).\nContributo della Moneta di Tipo 1: \\(0.059 \\times 0.5 = 0.0295\\).\nContributo della Moneta di Tipo 2: \\(0 \\times 0 = 0\\).\n\nSommando queste probabilità:\n\\[\n0.941 + 0.0295 + 0 = 0.9705.\n\\]\nNel seguito considereremo come svolgere tutti i calcoli.\n\nEsempio 50.1 Iniziamo con una distribuzione a priori uniforme per ciascun tipo di moneta, poiché inizialmente non sappiamo quale sia stata scelta:\n\\[\nP(X = 0) = P(X = 1) = P(X = 2) = \\frac{1}{3}.\n\\]\nDopo aver osservato una sequenza di lanci, ad esempio quattro “croce” (0, 0, 0, 0), possiamo aggiornare le nostre credenze sulla base dei dati.\nCalcoliamo la distribuzione a posteriori per ciascun tipo di moneta dopo aver osservato i risultati dei lanci.\nVerosimiglianza per ciascun tipo di moneta:\n\nMoneta tipo 0: Poiché dà sempre “croce”, la verosimiglianza di osservare quattro “croce” è \\(P(D | X = 0) = 1\\).\nMoneta tipo 1: Poiché è equa, la verosimiglianza di osservare quattro “croce” è \\(P(D | X = 1) = (0.5)^4 = 0.0625\\).\nMoneta tipo 2: Poiché dà sempre “testa”, la verosimiglianza di osservare quattro “croce” è \\(P(D | X = 2) = 0\\).\n\nCalcolo della distribuzione a posteriori per ciascun tipo di moneta:\n\\[\nP(X = 0 | D) = \\frac{P(D | X = 0)P(X = 0)}{P(D)},\n\\]\n\\[\nP(X = 1 | D) = \\frac{P(D | X = 1)P(X = 1)}{P(D)},\n\\]\n\\[\nP(X = 2 | D) = \\frac{P(D | X = 2)P(X = 2)}{P(D)},\n\\]\ndove \\(P(D) = P(D | X = 0)P(X = 0) + P(D | X = 1)P(X = 1) + P(D | X = 2)P(X = 2)\\).\nSostituendo i valori:\n\\[\nP(D) = \\frac{1}{3} \\times 1 + \\frac{1}{3} \\times 0.0625 + \\frac{1}{3} \\times 0 = \\frac{1 + 0.0625}{3} = \\frac{1.0625}{3}.\n\\]\nQuindi, le distribuzioni a posteriori diventano:\n\\[\nP(X = 0 | D) = \\frac{\\frac{1}{3}}{\\frac{1.0625}{3}} = \\frac{1}{1.0625} \\approx 0.941,\n\\]\n\\[\nP(X = 1 | D) = \\frac{\\frac{1}{3} \\times 0.0625}{\\frac{1.0625}{3}} = \\frac{0.0625}{1.0625} \\approx 0.059,\n\\]\n\\[\nP(X = 2 | D) = 0.\n\\]\nOra possiamo calcolare la distribuzione predittiva a posteriori per il prossimo lancio di moneta.\nLa probabilità che il prossimo lancio sia “croce” è data dalla somma delle probabilità ponderate da ciascun tipo di moneta, basate sulle distribuzioni a posteriori:\n\\[\nP(\\text{croce nel prossimo lancio} | D) = P(X = 0 | D) \\times 1 + P(X = 1 | D) \\times 0.5 + P(X = 2 | D) \\times 0.\n\\]\nInserendo i valori calcolati:\n\\[\nP(\\text{croce nel prossimo lancio} | D) = 0.941 \\times 1 + 0.059 \\times 0.5 + 0 \\times 0 = 0.9705.\n\\]\nQuindi, la distribuzione predittiva a posteriori ci dice che, dato che abbiamo osservato quattro “croce”, la probabilità che il prossimo lancio sia “croce” è circa \\(0.9705\\).\n\n\n\n50.4.5 Interpretazione\nIn questo esempio, abbiamo utilizzato la distribuzione predittiva a posteriori per fare una stima sulla probabilità di ottenere “croce” al quinto lancio. La distribuzione predittiva a posteriori rappresenta una combinazione delle nostre credenze aggiornate (probabilità posteriori) riguardo a quale moneta abbiamo selezionato, basate sui dati osservati (i primi quattro lanci), e le probabilità di ottenere “croce” associate a ciascun tipo di moneta. In altre parole, ci dice qual è la probabilità di un nuovo dato (il quinto lancio che dia “croce”) tenendo conto delle evidenze raccolte fino a quel punto.\nNel contesto dell’esempio, la distribuzione predittiva a posteriori è data dalla combinazione delle probabilità posteriori di avere ciascun tipo di moneta con le probabilità di ottenere “croce” con quella moneta. Questa distribuzione ci permette di fare previsioni future (come il risultato del quinto lancio) basandoci sulle informazioni aggiornate dalle osservazioni precedenti. Il risultato finale di 0.9705 rappresenta la probabilità di ottenere “croce” al prossimo lancio, tenendo conto delle evidenze osservate.\nLa distribuzione predittiva a posteriori è fondamentale nell’inferenza bayesiana perché permette di fare previsioni che considerano tutte le incertezze riguardo ai parametri del modello. Non ci basiamo solo sul valore stimato dei parametri, ma teniamo conto anche della nostra incertezza su questi valori.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#riflessioni-conclusive",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#riflessioni-conclusive",
    "title": "50  Distribuzione predittiva a posteriori",
    "section": "50.5 Riflessioni Conclusive",
    "text": "50.5 Riflessioni Conclusive\nUtilizzando il modello “bag of coins”, possiamo vedere come le osservazioni passate influenzano le previsioni future attraverso la distribuzione predittiva a posteriori. Questo esempio mostra come, anche con una conoscenza iniziale limitata, possiamo aggiornare le nostre credenze in modo sistematico e fare previsioni ragionevoli basate sui dati raccolti.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#esercizi",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#esercizi",
    "title": "50  Distribuzione predittiva a posteriori",
    "section": "50.6 Esercizi",
    "text": "50.6 Esercizi\n\nEsercizio 50.1 Utilizzando un set di dati diverso, ovvero tre “testa” seguite da una “croce”, calcola la distribuzione predittiva a posteriori per il prossimo lancio.\n\n\nEsercizio 50.2 Consideriamo un modello in cui ci sono tre tipi di monete, ognuna con una probabilità diversa di dare “testa” o “croce”:\n\nMoneta di Tipo 0: Questa moneta dà sempre “croce”. La probabilità di ottenere “testa” è 0.\nMoneta di Tipo 1: Questa moneta ha una probabilità di 0.7 di ottenere “testa” e 0.3 di ottenere “croce”.\nMoneta di Tipo 2: Questa moneta dà sempre “testa”. La probabilità di ottenere “testa” è 1.\n\nNel sacchetto ci sono: 2 monete di tipo 0, 1 moneta di tipo 1 e 1 moneta di tipo 2. Supponiamo di osservare la sequenza croce, testa, croce. Vogliamo calcolare la probabilità di ottenere “croce” al quarto lancio.",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/bayesian_inference/11_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/bayesian_inference/11_post_pred_distr.html#informazioni-sullambiente-di-sviluppo",
    "title": "50  Distribuzione predittiva a posteriori",
    "section": "50.7 Informazioni sull’Ambiente di Sviluppo",
    "text": "50.7 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Jun 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.24.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npymc      : 5.15.0\nscipy     : 1.13.0\narviz     : 0.18.0\nmatplotlib: 3.8.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Inferenza",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Distribuzione predittiva a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/introduction_mcmc.html",
    "href": "chapters/mcmc/introduction_mcmc.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, ci concentreremo sulle procedure Monte Carlo a catena di Markov, con particolare attenzione all’algoritmo di Metropolis, che consente di approssimare la distribuzione a posteriori quando non è possibile ottenere una soluzione analitica. Esploreremo il concetto di predizione bayesiana, fondamentale per la costruzione della distribuzione predittiva a posteriori, e discuteremo anche la distribuzione predittiva a priori. Applicheremo l’inferenza bayesiana a diversi contesti, tra cui la stima di una proporzione, il confronto tra due proporzioni, la stima di una media da una distribuzione normale e il confronto tra due medie. Esamineremo inoltre il modello bayesiano di Poisson per l’analisi delle frequenze. Infine, introdurremo il modello gerarchico bayesiano, uno strumento potente per affrontare situazioni in cui le osservazioni sono strutturate su diversi livelli di incertezza.",
    "crumbs": [
      "MCMC",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html",
    "href": "chapters/mcmc/01_metropolis.html",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "",
    "text": "Introduzione\nIn precedenza, abbiamo esplorato diversi esempi di inferenza bayesiana riguardanti la distribuzione a posteriori di un singolo parametro, come nel caso del modello bernoulliano. Abbiamo anche trattato metodi come l’approssimazione tramite griglia e l’utilizzo dei priori coniugati per ottenere o approssimare la distribuzione a posteriori. In questo capitolo, ci concentreremo sul metodo di simulazione Monte Carlo a Catena di Markov (MCMC).\nIl metodo MCMC è una tecnica computazionale utilizzata per approssimare distribuzioni di probabilità complesse, generando una sequenza di campioni (correlati) attraverso una catena di Markov, in cui ogni campione viene ottenuto tramite una transizione iterativa con probabilità attentamente progettate.\nIl metodo MCMC rappresenta l’approccio moderno per approssimare distribuzioni a posteriori complesse. L’idea di base è simile al concetto di considerare la distribuzione a posteriori come una popolazione da cui estraiamo campioni ripetutamente. Con un numero sufficientemente grande di campioni (ad esempio 1000), la distribuzione del campione si avvicina molto alla distribuzione della popolazione, consentendo stime affidabili dei parametri incogniti.\nUna differenza rispetto all’analogia precedente è che i campioni generati con MCMC sono correlati: se il primo campione ha un valore alto, anche il successivo ha maggiori probabilità di essere alto. Questo accade perché non abbiamo un modo diretto per estrarre campioni dalla distribuzione a posteriori, che spesso ha una forma molto complessa; utilizziamo invece algoritmi che ci permettono di arrivarci indirettamente. La correlazione tra i campioni non rappresenta un problema rilevante, ma rende necessario estrarre un numero maggiore di campioni per compensare questa correlazione e ottenere stime accurate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "href": "chapters/mcmc/01_metropolis.html#il-denominatore-bayesiano",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.1 Il denominatore bayesiano",
    "text": "51.1 Il denominatore bayesiano\nNell’approccio bayesiano, l’obiettivo principale è determinare la distribuzione a posteriori \\(p(\\theta \\mid y)\\) di un parametro \\(\\theta\\), utilizzando i dati osservati \\(y\\) e la distribuzione a priori \\(p(\\theta)\\). Questo si ottiene attraverso il teorema di Bayes:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) d\\theta}.\n\\]\nIl denominatore \\(\\int p(y \\mid \\theta) p(\\theta) d\\theta\\) rappresenta la probabilità marginale di \\(y\\), chiamata evidenza. Tale integrale garantisce che \\(p(\\theta \\mid y)\\) sia una distribuzione di probabilità valida. Tuttavia, il calcolo di questo integrale è spesso complesso, soprattutto in modelli articolati o ad alta dimensionalità, rendendo difficile ottenere una rappresentazione esplicita della distribuzione a posteriori.\nUna possibile semplificazione analitica è l’uso di distribuzioni a priori coniugate, che offrono una soluzione esatta per la distribuzione a posteriori. Tuttavia, questo approccio è limitato a casi specifici e impone forti vincoli sulla scelta delle distribuzioni a priori e delle verosimiglianze.\nUn approccio più generale è ricorrere a soluzioni numeriche. In precedenza abbiamo discusso il metodo di campionamento a griglia. Tuttavia, i metodi di campionamento a griglia, sebbene efficaci per modelli con pochi parametri, diventano impraticabili man mano che il numero di parametri aumenta, poiché richiedono una copertura densa dell’intero spazio parametrico. Di conseguenza, per modelli più complessi e con più parametri, si rende necessario un metodo che possa esplorare lo spazio dei parametri in maniera più efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "href": "chapters/mcmc/01_metropolis.html#il-metodo-monte-carlo-e-le-sue-limitazioni",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.2 Il metodo Monte Carlo e le sue limitazioni",
    "text": "51.2 Il metodo Monte Carlo e le sue limitazioni\nIl metodo Monte Carlo fornisce una soluzione a questo problema generando campioni casuali dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). L’idea centrale è semplice: se possiamo generare un numero sufficiente di campioni casuali dalla distribuzione a posteriori, possiamo usare questi campioni per stimare le proprietà d’interesse, come la media o la varianza del parametro \\(\\theta\\). Questa procedura ci permette di evitare il calcolo diretto dell’integrale complicato nel denominatore del teorema di Bayes.\nPer esempio, se fossimo in grado di generare una serie di campioni \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) dalla distribuzione a posteriori, potremmo approssimare il valore atteso di \\(\\theta\\) con la media campionaria:\n\\[\n\\mathbb{E}[\\theta] \\approx \\frac{1}{T} \\sum_{t=1}^T \\theta^{(t)}.\n\\]\nTuttavia, un problema significativo nei metodi Monte Carlo tradizionali è che generare campioni indipendenti dalla distribuzione a posteriori non è semplice, soprattutto quando questa distribuzione ha una forma complessa, è multimodale o definita su spazi di alta dimensionalità. Le regioni di alta densità, che contribuiscono maggiormente al valore dell’integrale, possono essere difficili da individuare e campionare adeguatamente. Per ottenere una buona copertura dello spazio dei parametri, sarebbe necessario generare un numero enorme di campioni, rendendo il metodo Monte Carlo inefficiente e computazionalmente oneroso.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#perché-i-metodi-mcmc-sono-necessari",
    "href": "chapters/mcmc/01_metropolis.html#perché-i-metodi-mcmc-sono-necessari",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.3 Perché i metodi MCMC sono necessari",
    "text": "51.3 Perché i metodi MCMC sono necessari\nÈ qui che entrano in gioco i Metodi Monte Carlo a Catena di Markov (MCMC). Questi metodi risolvono il problema generando campioni dipendenti dalla distribuzione a posteriori, sfruttando la struttura di una catena di Markov. A differenza dei campioni indipendenti utilizzati nei metodi Monte Carlo tradizionali, i metodi MCMC costruiscono una sequenza di campioni, in cui ciascun campione dipende dal precedente. Questa dipendenza permette di esplorare in modo più efficiente le regioni di alta densità della distribuzione a posteriori, riducendo il numero di campioni necessari per ottenere stime accurate.\nIn pratica, MCMC consente di evitare di campionare inutilmente da regioni di bassa densità, concentrandosi invece sulle aree più rilevanti della distribuzione. Questo approccio è particolarmente potente nei contesti ad alta dimensionalità o in presenza di distribuzioni multimodali, dove i metodi Monte Carlo tradizionali risulterebbero inefficaci o richiederebbero un numero sproporzionato di campioni.\nIn sintesi, i metodi Monte Carlo classici sono limitati quando si tratta di campionare da distribuzioni complesse e multidimensionali. I metodi MCMC, invece, offrono una soluzione efficiente e flessibile, permettendo di esplorare le distribuzioni a posteriori anche in contesti complessi, senza la necessità di campionare indipendentemente ogni punto. Nel prossimo paragrafo introdurremo i concetti fondamentali delle catene di Markov e vedremo come queste vengono utilizzate nei metodi MCMC per campionare efficacemente da distribuzioni a posteriori difficili da trattare analiticamente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "href": "chapters/mcmc/01_metropolis.html#le-catene-di-markov",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.4 Le Catene di Markov",
    "text": "51.4 Le Catene di Markov\nLe catene di Markov, introdotte da Andrey Markov nel 1906, rappresentano un’estensione della legge dei grandi numeri per descrivere sequenze di variabili casuali non indipendenti (per maggiori dettagli, si veda l’Appendice Q). Nella statistica tradizionale, si lavora spesso con sequenze di variabili casuali indipendenti e identicamente distribuite (i.i.d.), come \\(X_0, X_1, \\ldots, X_n, \\ldots\\), dove ogni variabile è indipendente dalle altre e segue la stessa distribuzione. Tuttavia, nei modelli più realistici che descrivono fenomeni complessi, l’indipendenza tra variabili è un’assunzione troppo rigida e spesso irrealistica.\nLe catene di Markov superano questo limite introducendo una dipendenza locale, detta dipendenza a un passo, formalizzata nella cosiddetta proprietà di Markov. Secondo questa proprietà, il valore futuro di una variabile casuale \\(X_{n+1}\\) dipende unicamente dal valore attuale \\(X_n\\), ignorando tutta la storia precedente della catena. Questo permette di semplificare notevolmente i calcoli relativi alle probabilità condizionali. La proprietà di Markov è formalmente espressa come:\n\\[\nP(X_{n+1} = j | X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j | X_n = i).\n\\]\nIn altre parole, la previsione di un evento futuro dipende soltanto dallo stato attuale e non da tutti gli eventi precedenti, semplificando così il processo di modellazione. Questa caratteristica rende le catene di Markov particolarmente utili per descrivere sistemi dinamici in cui gli eventi successivi sono influenzati solo dallo stato immediatamente precedente.\n\n51.4.1 Catene di Markov e Metodi MCMC\nLe catene di Markov sono fondamentali nei metodi Monte Carlo a Catena di Markov (MCMC) perché forniscono un modo efficiente per generare sequenze di campioni che approssimano distribuzioni di probabilità complesse. Mentre i metodi Monte Carlo classici generano campioni indipendenti, i metodi MCMC costruiscono una sequenza di campioni dipendenti attraverso una catena di Markov, in cui ciascun campione è ottenuto in base al campione precedente. Questo approccio consente di concentrarsi sulle regioni di alta probabilità della distribuzione, migliorando l’efficienza del campionamento.\nPer esempio, consideriamo una distribuzione di probabilità \\(P(x_1, x_2, ..., x_n)\\) definita su un insieme di variabili \\(x_1, x_2, ..., x_n\\). Nei metodi MCMC, si genera una sequenza di configurazioni \\(\\{x(0)\\}, \\{x(1)\\}, \\{x(2)\\}, \\dots\\), tale che la frequenza con cui ogni configurazione \\(\\{x\\}\\) viene visitata è proporzionale alla sua probabilità \\(P(x)\\). In questo modo, le configurazioni più probabili vengono visitate più spesso, garantendo che l’algoritmo converga alla distribuzione di interesse.\n\n\n51.4.2 Condizioni fondamentali per le Catene di Markov\nAffinché un algoritmo MCMC funzioni correttamente e converga alla distribuzione desiderata, la catena di Markov deve soddisfare alcune condizioni fondamentali:\n\nProprietà di Markov: La prossima configurazione dipende solo dalla configurazione attuale, non dalla storia passata. Questo garantisce che l’evoluzione della catena sia “locale” e non influenzata dagli stati remoti.\nIrriducibilità: Ogni configurazione della catena può essere raggiunta da qualsiasi altra in un numero finito di passi. Ciò assicura che l’intero spazio dei parametri possa essere esplorato.\nAperiodicità: La catena non segue cicli fissi e non ritorna sistematicamente allo stesso stato dopo un certo numero di passi. Questo garantisce che la catena possa esplorare lo spazio dei parametri in modo casuale.\nCondizione di bilanciamento dettagliato: La probabilità di passare da uno stato a un altro deve essere bilanciata dalla probabilità di tornare allo stato iniziale, assicurando così che la distribuzione di equilibrio della catena sia proprio la distribuzione a posteriori desiderata.\n\n\n\n51.4.3 Algoritmi MCMC\nEsistono diversi algoritmi basati su MCMC, ognuno con caratteristiche specifiche:\n\nMetropolis-Hastings: Questo è uno degli algoritmi più noti. Si basa sulla generazione di una configurazione proposta che viene accettata o rifiutata in base a un criterio di probabilità. Se la configurazione proposta ha una probabilità più alta, viene accettata; se ha una probabilità più bassa, può essere accettata con una certa probabilità, che dipende dal rapporto tra le probabilità delle due configurazioni.\nGibbs Sampling: In questo algoritmo, le variabili vengono aggiornate una alla volta, campionando ogni variabile dalla sua distribuzione condizionale data la configurazione corrente delle altre variabili. È particolarmente utile quando le distribuzioni condizionali sono note o facili da campionare.\nHamiltonian Monte Carlo (HMC): Utilizza principi della meccanica hamiltoniana per esplorare lo spazio dei parametri in modo più efficiente, considerando non solo le probabilità, ma anche le “forze” che muovono i campioni attraverso lo spazio dei parametri. Questo approccio è particolarmente vantaggioso per modelli complessi e ad alta dimensionalità, poiché consente di generare campioni lontani dallo stato corrente senza ricorrere a piccoli passi.\n\n\n\n51.4.4 Conclusione\nLe catene di Markov forniscono il fondamento teorico e pratico per i metodi MCMC, offrendo un modo efficiente per esplorare lo spazio dei parametri nei modelli complessi. Grazie alle proprietà specifiche delle catene di Markov, i metodi MCMC permettono di affrontare problemi di inferenza bayesiana che sarebbero intrattabili con approcci analitici o con i metodi Monte Carlo classici. Essendo flessibili e potenti, le catene di Markov continueranno a essere uno strumento fondamentale nella statistica e nella scienza dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "href": "chapters/mcmc/01_metropolis.html#estrazione-di-campioni-dalla-distribuzione-a-posteriori",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.5 Estrazione di campioni dalla distribuzione a posteriori",
    "text": "51.5 Estrazione di campioni dalla distribuzione a posteriori\nIn questo capitolo presenteremo l’algoritmo di Metropolis, che è uno dei più semplici e potenti metodi MCMC. Sfruttando la struttura delle catene di Markov, esplora in modo efficiente lo spazio dei parametri, permettendo di ottenere campioni dalla distribuzione a posteriori anche in casi complessi, dove i metodi analitici falliscono. In sostanza, il MCMC genera un gran numero di valori per il parametro \\(\\theta\\) che, nel loro insieme, approssimano la distribuzione di interesse \\(p(\\theta \\mid y)\\). A questo fine, il capitolo è strutturato in varie sezioni che facilitano la comprensione progressiva del tema.\n\nInizieremo discutendo di come la distribuzione a posteriori possa essere approssimata mediante tecniche di simulazione convenzionali. Questa prima parte presuppone che la distribuzione target, o “a posteriori,” sia già conosciuta o disponibile per l’analisi.\nIn seguito, passeremo a illustrare come l’algoritmo di Metropolis possa essere utilizzato per affrontare situazioni in cui la distribuzione a posteriori non è direttamente nota. In questi casi, spesso abbiamo a disposizione informazioni riguardanti la distribuzione a priori e la funzione di verosimiglianza, che possono essere utilizzate per ottenere un’approssimazione efficace della distribuzione a posteriori.\n\nA titolo esemplificativo, utilizzeremo il dataset moma_sample.csv, il quale costituisce un campione casuale di 100 artisti provenienti dal Museo di Arte Moderna di New York (MoMA) e contiene diverse informazioni relative a ciascun artista.\nIl nostro interesse è focalizzato sulla determinazione della probabilità che un artista presente nel MoMA appartenga alla generazione X o a una generazione successiva (nati dopo il 1965). Questa probabilità sarà indicata come \\(\\pi\\). Iniziamo importando i dati.\n\nfile_path = os.path.join(project_directory, \"data\", \"moma_sample.csv\")\nmoma_sample = pd.read_csv(file_path)\n\nEsaminiamo le prime cinque righe del DataFrame.\n\nmoma_sample.head()\n\n\n\n\n\n\n\n\nartist\ncountry\nbirth\ndeath\nalive\ngenx\ngender\ncount\nyear_acquired_min\nyear_acquired_max\n\n\n\n\n0\nAd Gerritsen\ndutch\n1940\n2015.0\nFalse\nFalse\nmale\n1\n1981\n1981\n\n\n1\nKirstine Roepstorff\ndanish\n1972\nNaN\nTrue\nTrue\nfemale\n3\n2005\n2005\n\n\n2\nLisa Baumgardner\namerican\n1958\n2015.0\nFalse\nFalse\nfemale\n2\n2016\n2016\n\n\n3\nDavid Bates\namerican\n1952\nNaN\nTrue\nFalse\nmale\n1\n2001\n2001\n\n\n4\nSimon Levy\namerican\n1946\nNaN\nTrue\nFalse\nmale\n1\n2012\n2012\n\n\n\n\n\n\n\nDai dati osserviamo che solo 14 artisti su 100 appartengono alla generazione X o a una generazione successiva.\n\nresult = moma_sample[\"genx\"].value_counts()\nprint(result)\n\ngenx\nFalse    86\nTrue     14\nName: count, dtype: int64\n\n\nIl valore campionato \\(y = 14\\) riflette le caratteristiche del campione che è stato osservato. Tuttavia, poiché il MOMA contiene opere di migliaia di artisti, sorge una domanda riguardante il vero valore di \\(\\theta\\) (la probabilità di appartenere alla generazione X o a una generazione successiva) all’interno di questa popolazione.\nPossiamo interpretare i dati \\(y = 14\\) come l’esito di una variabile casuale Binomiale con parametri \\(N = 100\\) e \\(\\theta\\) sconosciuto.\nSupponiamo che le nostre credenze pregresse riguardo a \\(\\theta\\) possano essere modellate attraverso una distribuzione Beta(4, 6).\nSfruttando le proprietà delle distribuzioni coniugate, possiamo calcolare la distribuzione a posteriori esatta:\nY ~ Binomiale(100, π)\nθ = Beta(4, 6)\nθ | (Y = 14) ~ Beta(4 + 14, 6 + 100 - 14) → Beta(18, 92)\nNella figura successiva è rappresentata la distribuzione a posteriori del parametro \\(\\theta\\), insieme alla distribuzione a priori scelta.\n\nx = np.linspace(0, 1, 1000)\n\nprior_density = stats.beta.pdf(x, 4, 6)\nposterior_density = stats.beta.pdf(x, 18, 92)\n\nplt.fill_between(x, prior_density, alpha=0.5, label=\"Prior: Beta(4, 6)\")\nplt.fill_between(x, posterior_density, alpha=0.5, label=\"Posterior: Beta(18, 92)\")\nplt.xlabel(\"Parameter Value\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.title(\"Prior and Posterior Densities\")\nplt.show()\n\n\n\n\n\n\n\n\nSe vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto è\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{18}{18 + 92} \\approx 0.1636.\n\\]\n\n51.5.1 Simulazione con distribuzione target nota\nUsiamo ora una simulazione numerica per stimare la media a posteriori di \\(\\theta\\). Conoscendo la forma della distribuzione a posteriori \\(Beta(18, 92)\\), possiamo generare un campione di osservazioni casuali da questa distribuzione. Successivamente, calcoliamo la media delle osservazioni ottenute per ottenere un’approssimazione della media a posteriori.\nSe vogliamo ottenere un risultato approssimato con poche osservazioni (ad esempio, 10), possiamo procedere con la seguente simulazione:\n\ny = stats.beta(18, 92).rvs(10)\nprint(y)\n\n[0.12971627 0.15527801 0.14714901 0.20647646 0.1897427  0.16158686\n 0.17558128 0.20738074 0.23121331 0.1330954 ]\n\n\n\nnp.mean(y)\n\n0.17372200509655458\n\n\nTuttavia, con solo 10 campioni l’approssimazione potrebbe non essere molto accurata. Più aumentiamo il numero di campioni (cioè il numero di osservazioni casuali generate), più precisa sarà l’approssimazione. Aumentando il numero di campioni, ad esempio a 10000, otteniamo un risultato più preciso:\n\nstats.beta(18, 92).rvs(10000).mean()\n\n0.1635283857789979\n\n\nQuando il numero di campioni a posteriori diventa molto grande, la distribuzione campionaria converge alla densità della popolazione. Questo concetto si applica non solo alla media, ma anche ad altre statistiche descrittive, come la moda e la varianza.\nÈ importante sottolineare che l’applicazione della simulazione di Monte Carlo è efficace per calcolare distribuzioni a posteriori solo quando conosciamo la distribuzione stessa e possiamo utilizzare funzioni Python per estrarre campioni casuali da tale distribuzione. Ciò è stato possibile nel caso della distribuzione a posteriori \\(Beta(18, 92)\\).\nTuttavia, questa situazione ideale non si verifica sempre nella pratica, poiché le distribuzioni a priori coniugate alla verosimiglianza sono spesso rare. Per esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori gaussiana, l’espressione\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}\n\\]\nrende impossibile calcolare analiticamente la distribuzione a posteriori di \\(\\theta\\), precludendo quindi l’utilizzo diretto di Python per generare campioni casuali.\nIn queste circostanze, però, è possibile ottenere campioni casuali dalla distribuzione a posteriori mediante l’uso di metodi Monte Carlo basati su Catena di Markov (MCMC). Gli algoritmi MCMC, come ad esempio l’algoritmo Metropolis, costituiscono una classe di metodi che consentono di estrarre campioni casuali dalla distribuzione a posteriori senza richiedere la conoscenza della sua rappresentazione analitica. Le tecniche MCMC sono ampiamente adottate per risolvere problemi di inferenza bayesiana e rappresentano il principale strumento computazionale per ottenere stime approssimate di distribuzioni a posteriori in situazioni complesse e non analiticamente trattabili.\n\n\n51.5.2 Algoritmo di Metropolis\nL’algoritmo di Metropolis appartiene alla famiglia dei metodi Monte Carlo basati su catene di Markov (MCMC), sfruttando le proprietà di queste catene per generare campioni da una distribuzione target. Il suo obiettivo principale è di esplorare lo spazio dei parametri in modo efficiente, producendo campioni che approssimano la distribuzione a posteriori di interesse.\n\n\n51.5.3 Principio di Funzionamento\nL’algoritmo inizia da un valore iniziale per i parametri e, in ogni iterazione, genera un nuovo campione tramite una distribuzione di proposta (solitamente una distribuzione normale centrata sul valore corrente). Successivamente, decide se accettare il nuovo campione in base al confronto tra le densità posteriori del nuovo campione e di quello precedente. Questa accettazione avviene in modo probabilistico, favorendo campioni con una densità più alta ma consentendo anche l’accettazione di campioni peggiori per evitare che la catena rimanga bloccata in minimi locali.\n\n\n51.5.4 Burn-in e Convergenza\nPoiché i primi campioni potrebbero non rappresentare bene la distribuzione target, si esclude spesso una porzione iniziale della catena (fase di burn-in). Con il progredire delle iterazioni, i campioni si distribuiscono in accordo con la distribuzione stazionaria desiderata, indipendentemente dallo stato iniziale scelto. Questo processo permette di esplorare lo spazio dei parametri in modo efficiente.\n\n\n51.5.5 Meccanismo di Accettazione e Rifiuto\nL’algoritmo di Metropolis bilancia due esigenze opposte:\n\nEsplorazione di nuove aree dello spazio dei parametri.\nSfruttamento delle informazioni già acquisite dai campioni precedenti.\n\nUtilizzando una regola probabilistica per accettare campioni peggiori (con minore densità a posteriori), l’algoritmo evita di restare intrappolato in minimi locali, esplorando così in modo più completo l’intera distribuzione.\n\n\n51.5.6 Passaggi Fondamentali dell’Algoritmo di Metropolis\n\nScelta di uno stato iniziale \\(\\theta_1\\) e impostazione del contatore \\(t = 1\\).\n\nQuesto è il punto di partenza della catena, dove \\(\\theta_1\\) rappresenta il primo campione.\n\nProposta di un nuovo campione \\(\\theta_p\\).\n\nUn nuovo valore \\(\\theta_p\\) viene generato da una distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\), solitamente una distribuzione normale centrata sul campione corrente \\(\\theta_t\\) con una deviazione standard \\(\\tau\\) che controlla l’ampiezza dei passi.\n\nVerifica dei vincoli del campione proposto.\n\nSe il nuovo campione deve rispettare dei vincoli (ad esempio, essere compreso tra 0 e 1 per probabilità), campioni non validi vengono automaticamente rifiutati.\n\nCalcolo del rapporto di accettazione \\(\\alpha\\).\n\nSi calcola \\(\\alpha = \\frac{p(\\theta_p \\mid y)}{p(\\theta_t \\mid y)}\\), che rappresenta il rapporto tra le densità a posteriori del nuovo campione \\(\\theta_p\\) e del campione corrente \\(\\theta_t\\). Questo valore guida la decisione di accettazione.\n\nDecisione di accettazione.\n\nSe \\(\\alpha \\geq 1\\), il nuovo campione \\(\\theta_p\\) viene accettato incondizionatamente.\nSe \\(\\alpha &lt; 1\\), il campione \\(\\theta_p\\) viene accettato con probabilità \\(\\alpha\\). In caso di rifiuto, si mantiene il campione corrente \\(\\theta_t\\) per la prossima iterazione.\n\nRipetizione del processo.\n\nSi ripetono i passaggi dal 2 al 5 fino a ottenere il numero desiderato di campioni.\n\n\n\n\n51.5.7 Dettagli Aggiuntivi\n\nDistribuzione di proposta: La distribuzione di proposta \\(g(\\theta_p \\mid \\theta_t)\\) genera nuovi campioni attorno a \\(\\theta_t\\). Tipicamente si usa una normale \\(N(\\theta_t, \\tau)\\), dove \\(\\tau\\) controlla quanto il nuovo campione si discosta da quello corrente. Scegliere un \\(\\tau\\) troppo piccolo può rendere l’esplorazione lenta, mentre un \\(\\tau\\) troppo grande può far rifiutare troppi campioni, riducendo l’efficienza.\nRapporto di accettazione \\(\\alpha\\): Se il nuovo campione ha una densità a posteriori maggiore del campione corrente, viene sempre accettato. Se ha una densità inferiore, viene accettato con probabilità \\(\\alpha\\), il che consente di esplorare anche regioni meno probabili della distribuzione.\nAccettazione probabilistica: Accettare campioni peggiori occasionalmente aiuta l’algoritmo a evitare di bloccarsi in minimi locali. Questo è uno dei punti di forza dell’algoritmo di Metropolis, che garantisce una buona esplorazione dello spazio dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "href": "chapters/mcmc/01_metropolis.html#esempio-di-implementazione",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.6 Esempio di Implementazione",
    "text": "51.6 Esempio di Implementazione\nPer la presente simulazione, ci serviremo dell’implementazione in Python proposta da Elizaveta Semenova, che offre una presentazione particolarmente concisa ed efficace della logica sottostante l’algoritmo. Iniziamo a definire alcune funzioni.\nDefiniamo una funzione prior che accetta come argomento il valore di \\(\\theta\\) e restituisce la densità della distribuzione Beta(4, 6).\n\n# Define prior distribution (Beta(4,6))\ndef prior(p):\n    alpha = 4\n    beta = 6\n    return stats.beta.pdf(p, alpha, beta)\n\nDefiniamo la funzione likelihood, che accetta come argomento il valore di \\(\\theta\\) e restituisce la densità della funzione di verosimiglianza binomiale per il caso di 14 successi su 100 prove.\n\n# Define likelihood function (Binomial with y = 14 successes out of n = 100 trials)\ndef likelihood(p):\n    y = 14\n    n = 100\n    return stats.binom.pmf(y, n, p)\n\nInfine, definiamo la funzione posterior, che accetta come argomento il valore di \\(\\theta\\) e restituisce la densità della distribuzione a posteriori non normalizzata, calcolata come il prodotto della distribuzione a priori e della verosimiglianza.\n\n# Define posterior as the product of prior and likelihood\ndef posterior(p):\n    return likelihood(p) * prior(p)\n\nDefiniamo la distribuzione proposta come una distribuzione gaussiana centrata sullo stato corrente con deviazione standard definita a priori.\n\n# Proposal distribution (normal distribution around current state)\ndef proposal_distribution(current_state, proposal_sigma):\n    return np.random.normal(current_state, proposal_sigma)\n\nDefiniamo la distribuzione target che corrispone dalla distribuzione a posteriori.\n\n# Target distribution is the posterior we are sampling from\ndef target_distribution(p):\n    return posterior(p)\n\nProcediamo ora con un’implementazione dell’algoritmo di Metropolis, considerando i dati relativi agli artisti della Generazione X presenti al MoMA. In questa simulazione, come indicato in precedenza, adottiamo una distribuzione a priori per \\(\\theta\\) (la probabilità di appartenere alla Generazione X) modellata secondo una (arbitraria) distribuzione Beta(4, 6).\n\n# Metropolis-Hastings algorithm\ndef metropolis_hastings(num_samples, initial_state, proposal_sigma):\n    # Start with the initial state and prepare to store samples\n    samples = [initial_state]\n    current_state = initial_state\n\n    for _ in range(num_samples):\n        # Propose a new state from a normal distribution around the current state\n        proposed_state = proposal_distribution(current_state, proposal_sigma)\n\n        # Ensure the proposed state is within valid bounds (between 0 and 1 for probabilities)\n        if 0 &lt;= proposed_state &lt;= 1:\n            # Calculate acceptance ratio\n            acceptance_ratio = min(\n                1,\n                target_distribution(proposed_state)\n                / target_distribution(current_state),\n            )\n\n            # Accept or reject the proposed state\n            if np.random.uniform(0, 1) &lt; acceptance_ratio:\n                current_state = proposed_state\n\n        # Append the current state (accepted or rejected) to the samples\n        samples.append(current_state)\n\n    return samples\n\nNell’implementazione dell’algoritmo di Metropolis proposta ci sono diversi punti cruciali da considerare, che contribuiscono al funzionamento e alla correttezza dell’algoritmo.\n\n51.6.1 Simmetria della Distribuzione Proposta\nL’algoritmo di Metropolis richiede che la distribuzione di proposta sia simmetrica. Questo significa che la probabilità di proporre uno stato \\(\\theta_p\\) partendo da \\(\\theta_t\\) deve essere uguale alla probabilità di proporre \\(\\theta_t\\) partendo da \\(\\theta_p\\). Nel tuo caso, la distribuzione normale utilizzata (\\(N(\\theta_t, \\sigma)\\)) soddisfa questa condizione, poiché è simmetrica attorno al valore corrente \\(\\theta_t\\). È importante notare che questa condizione è necessaria per l’algoritmo di Metropolis, ma non per l’algoritmo di Metropolis-Hastings, che permette distribuzioni proposte asimmetriche.\n\n\n51.6.2 Scelta del Valore Iniziale\nIl valore iniziale initial_state dovrebbe essere scelto con attenzione. Idealmente, questo valore dovrebbe trovarsi in una regione con alta densità della distribuzione a priori, in modo da facilitare la convergenza dell’algoritmo verso la distribuzione target. In alcuni casi, una scelta di partenza lontana dalla distribuzione a posteriori potrebbe richiedere un periodo di burn-in più lungo, poiché l’algoritmo impiega più tempo a esplorare lo spazio dei parametri e a stabilizzarsi.\n\n\n51.6.3 Gestione della Probabilità Zero\nUn altro aspetto fondamentale è garantire che il nuovo campione proposto, proposed_state, rientri nei limiti del supporto della verosimiglianza e del prior. Nel tuo esempio, proposed_state è limitato all’intervallo [0, 1], come appropriato per i problemi di probabilità. Se il campione proposto cadesse al di fuori di questo intervallo, la densità a posteriori risulterebbe zero, causando un’accettazione impossibile o un rapporto indefinito.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#meccanismo-di-accettazione",
    "href": "chapters/mcmc/01_metropolis.html#meccanismo-di-accettazione",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.7 Meccanismo di Accettazione",
    "text": "51.7 Meccanismo di Accettazione\nNel processo successivo alla generazione di un nuovo stato proposto, l’algoritmo deve decidere se accettare o meno questo stato in base alla sua densità a posteriori, calcolata come il prodotto tra la verosimiglianza e il prior. Questo confronto avviene nel seguente modo:\n\n51.7.1 Generazione del Nuovo Stato\nIl nuovo stato proposed_state viene generato da una distribuzione di proposta centrata sullo stato corrente current_state. La deviazione standard della distribuzione, definita dal parametro proposal_sigma, determina quanto il nuovo stato può distanziarsi dallo stato attuale. In pratica, un valore di proposal_sigma troppo piccolo potrebbe rallentare l’esplorazione dello spazio dei parametri, mentre un valore troppo grande potrebbe portare a un tasso di rifiuto elevato.\n\n\n51.7.2 Confronto tra Stati\nIl cuore dell’algoritmo è il confronto tra la densità a posteriori del nuovo stato (proposed_state) e quella dello stato corrente (current_state). Se il nuovo stato ha una densità a posteriori maggiore o uguale rispetto al vecchio stato, viene sempre accettato. Altrimenti, viene accettato con una probabilità data dal rapporto di accettazione.\n\n\n51.7.3 Calcolo del Rapporto di Accettazione\nIl rapporto di accettazione \\(\\alpha\\) viene calcolato come:\n\\[\n\\alpha = \\min\\left(1, \\frac{p(\\text{proposed state})}{p(\\text{current state})}\\right),\n\\]\ndove \\(p(\\text{proposed state})\\) è la densità a posteriori del nuovo stato e \\(p(\\text{current state})\\) è quella dello stato attuale. Se il nuovo stato ha una probabilità maggiore, sarà accettato. Se invece la sua probabilità è minore, verrà accettato con una probabilità pari a \\(\\alpha\\). In questo modo, lo schema probabilistico permette all’algoritmo di esplorare anche aree con minore densità, evitando di restare bloccato in minimi locali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#tasso-di-accettazione-e-efficienza",
    "href": "chapters/mcmc/01_metropolis.html#tasso-di-accettazione-e-efficienza",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.8 Tasso di Accettazione e Efficienza",
    "text": "51.8 Tasso di Accettazione e Efficienza\nUno degli aspetti cruciali nell’uso dell’algoritmo è il tasso di accettazione, ovvero il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso di accettazione troppo basso indica che l’algoritmo sta rifiutando troppi campioni e quindi l’esplorazione dello spazio dei parametri è inefficiente. Viceversa, un tasso di accettazione troppo alto potrebbe indicare che la distribuzione proposta non si sta spostando abbastanza tra le iterazioni, con il rischio di una convergenza lenta.\nIn generale, un tasso di accettazione compreso tra il 20% e il 40% è spesso considerato ottimale per garantire un buon bilanciamento tra esplorazione e efficienza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#esecuzione-del-campionamento",
    "href": "chapters/mcmc/01_metropolis.html#esecuzione-del-campionamento",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.9 Esecuzione del Campionamento",
    "text": "51.9 Esecuzione del Campionamento\nProcediamo con l’esecuzione del campionamento, implementando l’algoritmo di Metropolis come precedentemente illustrato\n\ninitial_state = 0.5  # Starting at the midpoint of the probability range\nproposal_sigma = 0.1  # Standard deviation for the proposal distribution\nnum_samples = 10000  # Number of samples to generate\n\nsamples = metropolis_hastings(num_samples, initial_state, proposal_sigma)\n\nLa funzione metropolis_hastings() accetta come input il numero num_samples di passi da simulare, il punto di partenza e la deviazione standard della distribuzione proposta gaussiana. Come output, restituisce una catena di valori del parametro, specificamente la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\ldots, \\theta^{\\text{nsamp}}\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#aspetti-computazionali",
    "href": "chapters/mcmc/01_metropolis.html#aspetti-computazionali",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.10 Aspetti computazionali",
    "text": "51.10 Aspetti computazionali\n\n51.10.1 Warm-up/Burn-in\nUno degli aspetti cruciali per la riuscita dell’algoritmo è il raggiungimento della stazionarietà da parte della catena. In genere, i primi 1000-5000 valori vengono scartati in quanto rappresentano il periodo di “burn-in” della catena. Dopo un determinato numero di passi \\(k\\), la catena converge e i valori diventano campioni effettivi dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\n\n51.10.2 Sintesi della distribuzione a posteriori\nL’array samples contiene 10000 valori di una catena di Markov. Escludiamo i primi 5000 valori considerati come burn-in e consideriamo i restanti 5000 valori come un campione casuale estratto dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\nMediante i valori della catena così ottenuta è facile trovare una stima a posteriori del parametro \\(\\theta\\). Per esempio, possiamo trovare la stima della media a posteriori.\n\nburnin = int(num_samples * 0.5)\nburnin\n\n5000\n\n\n\nnp.mean(samples[burnin:])\n\n0.16389183286201028\n\n\nOppure possiamo stimare la deviazione standard della distribuzione a posteriori.\n\nnp.std(samples[burnin:])\n\n0.0353754937892814\n\n\nIl trace plot indica che la catena inizia con un valore casuale per poi spostarsi rapidamente nell’area intorno a 0.16, che è l’area con alta densità a posteriori. Successivamente, oscilla intorno a quel valore per le iterazioni successive. Visualizziamo un trace plot dei primi 200 valori della catena di Markov.\n\nplt.plot(samples[0:200])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nVisualizziamo un trace plot dei valori della catena di Markov dopo il periodo di burn-in.\n\nplt.plot(samples[burnin:])\nplt.xlabel(\"sample\")\nplt.ylabel(\"theta\")\nplt.show()\n\n\n\n\n\n\n\n\nL’istogramma mostrato di seguito, sul quale è stata sovrapposta la distribuzione a posteriori derivata analiticamente – specificamente una \\(\\text{Beta}(25, 17)\\) – dimostra che la catena converge effettivamente alla distribuzione a posteriori desiderata.\n\nplt.hist(samples[burnin:], bins=20, alpha=0.4, label=\"MCMC distribution\", density=True)\n# plot the true function\nx = np.linspace(0, 1, 1000)\nplt.plot(x, stats.beta.pdf(x, 18, 92), \"C0\", label=\"True distribution\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nCome previsto, la distribuzione a posteriori calcolata con l’algorimo di Metropolis converge verso la soluzione analitica.\nÈ possibile usare la funzione summary del pacchetto ArviZ per calolare l’intervallo di credibilità, ovvero l’intervallo che contiene la proporzione indicata dei valori estratti a caso dalla distribuzione a posteriori.\n\nsamples_array = np.array(samples) # per potere usare ArViZ\naz.summary(samples_array[burnin:], kind=\"stats\", hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\nx\n0.16\n0.03\n0.11\n0.23\n\n\n\n\n\n\n\nUn KDE plot corrispondente all’istogramma precedente si può generare usando az.plot_posterior(). La curva rappresenta l’intera distribuzione a posteriori e viene calcolata utilizzando la stima della densità del kernel (KDE) che serve a “lisciare” l’istogramma.\n\naz.plot_posterior(samples_array[burnin:])\nplt.show()\n\n\n\n\n\n\n\n\nL’HDI è una scelta comune nelle statistiche bayesiane e valori arrotondati come 50% o 95% sono molto popolari. Ma ArviZ utilizza il 94% come valore predefinito. La ragione di questa scelta è che il 94% è vicino al valore ampiamente utilizzato del 95%, ma è anche diverso da questo, così da servire da “amichevole promemoria” che non c’è niente di speciale nella soglia del 5%. Idealmente sarebbe opportuno scegliere un valore che si adatti alle specifiche esigenze dell’analisi statistica che si sta svolgendo, o almeno riconoscere che si sta usando un valore arbitrario.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "href": "chapters/mcmc/01_metropolis.html#catene-di-markov-e-convergenza",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.11 Catene di Markov e Convergenza",
    "text": "51.11 Catene di Markov e Convergenza\nNell’ambito delle simulazioni Monte Carlo, una catena rappresenta una sequenza di valori campionati dall’algoritmo durante le sue iterazioni. Ogni valore nella catena corrisponde a un possibile stato del sistema che stiamo modellando. In altre parole, una catena traccia il percorso che l’algoritmo segue nello spazio dei parametri, esplorando le diverse configurazioni possibili.\nPer verificare se l’algoritmo ha raggiunto la convergenza e se i campioni generati rappresentano effettivamente la distribuzione di interesse, è utile eseguire multiple catene. Ogni catena parte da un punto iniziale diverso nello spazio dei parametri.\nI vantaggi delle multiple catene:\n\nDiagnostica della convergenza: Confrontando le diverse catene, possiamo valutare se si stabilizzano verso la stessa distribuzione. Se le catene si mescolano bene, ovvero si intersecano frequentemente nel grafico dei valori campionati (trace plot), è un forte indicatore di convergenza.\nRobustezza: L’utilizzo di multiple catene rende l’analisi meno sensibile alla scelta del punto di partenza. Se una singola catena potesse rimanere “intrappolata” in una regione dello spazio dei parametri, multiple catene aumentano la probabilità di esplorare lo spazio in modo più completo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "href": "chapters/mcmc/01_metropolis.html#diagnostiche-della-soluzione-mcmc",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.12 Diagnostiche della soluzione MCMC",
    "text": "51.12 Diagnostiche della soluzione MCMC\n\n51.12.1 Stazionarietà e Convergenza\nUn aspetto cruciale nell’analisi delle catene di Markov MCMC è la convergenza alla distribuzione stazionaria. Intuitivamente, la catena converge quando i campioni generati rappresentano fedelmente la distribuzione di interesse, indipendentemente dal punto di partenza. Questo fenomeno è spesso indicato come “mixing”.\n\n51.12.1.1 Valutazione Visuale: Trace Plots e Grafici di Densità\n\nTrace Plots: Questi grafici visualizzano l’evoluzione dei parametri nel tempo. Una catena convergente mostra tracce stabili e senza trend evidenti. Tracce irregolari o con andamenti sistematici suggeriscono problemi di convergenza.\nGrafici di Densità: Confrontando i grafici di densità dei campioni con la distribuzione teorica, è possibile valutare visivamente se la catena sta esplorando adeguatamente lo spazio dei parametri. Una buona convergenza si manifesta con una sovrapposizione significativa tra i due grafici.\n\nSegni di Convergenza:\n\nStabilità: I valori campionati oscillano attorno a un valore medio costante, senza trend marcati.\nOmogeneità: La variabilità dei campioni rimane relativamente uniforme nel tempo.\nAssenza di Periodicità: Non si osservano pattern ciclici o ripetitivi.\n\nIn sintesi, i trace plots e i grafici di densità offrono strumenti visivi rapidi per valutare la convergenza di una catena di Markov MCMC. Una convergenza soddisfacente è fondamentale per garantire la validità delle inferenze statistiche basate sui campioni generati.\n\n\n\n51.12.2 Autocorrelazione nelle catene di Markov MCMC\nA differenza dei generatori di numeri casuali indipendenti, gli algoritmi MCMC producono una sequenza di campioni correlati. Ogni valore campionato dipende da quello precedente, formando una catena di Markov. Questa interdipendenza è un aspetto fondamentale dell’MCMC.\nL’autocorrelazione quantifica il grado di dipendenza tra valori distanti di una certa quantità (detta lag) nella catena. Un’alta autocorrelazione a lag bassi indica una forte dipendenza tra campioni successivi. Al contrario, una rapida diminuzione dell’autocorrelazione al crescere del lag suggerisce che la catena “miscela” bene, ovvero esplora lo spazio dei parametri in modo efficiente.\n\nLag 1: Misura la correlazione tra valori consecutivi nella catena.\nLag 2: Misura la correlazione tra valori separati da un passo intermedio.\nLag k: Generalizza il concetto ai valori separati da k passi.\n\nUn correlogramma è un grafico che mostra l’autocorrelazione in funzione del lag. Un decadimento rapido dell’autocorrelazione verso zero indica una buona convergenza della catena.\nL’autocorrelazione di ordine \\(k\\) è data da \\(\\rho_k\\) e può essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{Cov(\\theta_m, \\theta_{m+k})}{Var(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\tag{51.1}\\]\nPer fare un esempio pratico, simuliamo dei dati autocorrelati.\n\nx = pd.array([22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51])\nprint(x)\n\n&lt;IntegerArray&gt;\n[22, 24, 25, 25, 28, 29, 34, 37, 40, 44, 51, 48, 47, 50, 51]\nLength: 15, dtype: Int64\n\n\nL’autocorrelazione di ordine 1 è semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza.\n\nsm.tsa.acf(x)\n\narray([ 1.        ,  0.83174224,  0.65632458,  0.49105012,  0.27863962,\n        0.03102625, -0.16527446, -0.30369928, -0.40095465, -0.45823389,\n       -0.45047733, -0.36933174])\n\n\nNell’esempio, il vettore x è una sequenza temporale di 15 elementi. Il vettore \\(x'\\) include gli elementi con gli indici da 0 a 13 nella sequenza originaria, mentre il vettore \\(x''\\) include gli elementi 1:14. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((0, 1)\\), \\((1, 2), (2, 3), \\dots (13, 14)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori \\(x'\\) e \\(x''\\) corrisponde all’autocorrelazione di ordine 1 della serie temporale.\nNell’output precedente\n\n0.83174224 è l’autocorrelazione di ordine 1 (lag = 1),\n0.65632458 è l’autocorrelazione di ordine 2 (lag = 2),\n0.49105012 è l’autocorrelazione di ordine 3 (lag = 3),\necc.\n\nÈ possibile specificare il numero di ritardi (lag) da utilizzare con l’argomento nlags:\n\nsm.tsa.acf(x, nlags=4)\n\narray([1.        , 0.83174224, 0.65632458, 0.49105012, 0.27863962])\n\n\nIn Python possiamo creare un grafico della funzione di autocorrelazione (correlogramma) per una serie temporale usando la funzione tsaplots.plot_acf() dalla libreria statsmodels.\n\ntsaplots.plot_acf(x, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nPer i dati dell’esempio in discussione otteniamo la situazione seguente.\n\ntsaplots.plot_acf(samps[burnin:], lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nIn situazioni ottimali l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per piccoli lag. Ciò indica che i valori della catena di Markov che si trovano a più di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del “mixing” della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l’autocorrelazione è quella di assottigliare l’output immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di thinning.\nNel seguente correlogramma, analizziamo la medesima catena di Markov. Tuttavia, in questa occasione applichiamo un “thinning” (sottocampionamento) con un fattore di 5.\n\nthin = 5\nsampsthin = samps[burnin::thin]\ntsaplots.plot_acf(sampsthin, lags=9)\nplt.show()\n\n\n\n\n\n\n\n\nSi può notare come l’autocorrelazione diminuisce molto più rapidamente.\n\n51.12.2.1 Tasso di accettazione\nQuando si utilizza l’algoritmo Metropolis, è importante monitorare il tasso di accettazione e assicurarsi che sia nell’intervallo ottimale. Se si accetta quasi sempre il candidato proposto, probabilmente significa che, in ogni iterazione, la catena salta solo di un piccolo passo (in modo che il rapporto di accettazione sia vicino a 1 ogni volta). Di conseguenza, la catena impiegherà molte iterazioni per raggiungere altre regioni della distribuzione stazionaria e i campioni consecutivi saranno molto fortemente correlati. D’altra parte, se il tasso di accettazione è molto basso, la catena rimarrà bloccata nella stessa posizione per molte iterazioni prima di spostarsi verso uno stato diverso. Per l’algoritmo Metropolis base con un singolo parametro con una distribuzione proposta Gaussiana normale, un tasso di accettazione ottimale è compreso tra il 40% e il 50%.\n\n\n\n51.12.3 Test Statistici per la Convergenza\nOltre agli approcci grafici, esistono test statistici specifici che possono aiutare a determinare se la catena ha raggiunto uno stato stazionario.\n\n51.12.3.1 Test di Geweke\nIl test di Geweke è una procedura che confronta le medie di due segmenti della catena di campionamento, tipicamente il primo 10% e l’ultimo 50% dei campioni, dopo aver escluso un iniziale periodo di “burn-in” (una fase iniziale durante la quale la catena potrebbe non essere ancora convergente). La premessa di base è che, se la catena è in uno stato stazionario, le medie di questi due segmenti dovrebbero essere sostanzialmente uguali. Differenze significative tra queste medie possono indicare che la catena non ha ancora raggiunto la convergenza.\n\n\n51.12.3.2 Geweke Z-score\nUna variante del test di Geweke è lo z-score di Geweke, che offre un modo quantitativo per valutare le differenze tra i segmenti della catena. Questo test calcola uno z-score che confronta le medie dei due segmenti tenendo conto della varianza. Un valore di z-score:\n\nAl di sotto di 2 (in valore assoluto) suggerisce che non ci sono differenze significative tra i segmenti, indicando che la catena potrebbe essere in stato stazionario.\nSuperiore a 2 (in valore assoluto) indica che esiste una differenza significativa tra i segmenti, suggerendo che la catena non ha raggiunto la convergenza e potrebbe essere necessario un periodo di burn-in più esteso.\n\nEntrambi i metodi forniscono strumenti utili per valutare la convergenza delle catene MCMC. È importante notare che nessun test può garantire con certezza la convergenza, ma l’utilizzo congiunto di approcci grafici e test statistici può offrire una buona indicazione dello stato della catena.\n\n\n\n51.12.4 Dimensione del campione effettiva (ESS)\nLa correlazione tra campioni consecutivi in una catena MCMC riduce l’informazione effettiva contenuta in ogni iterazione. La dimensione del campione effettiva (ESS) quantifica questa perdita di informazione dovuta alla dipendenza tra i campioni, stimando il numero equivalente di campioni indipendenti. Un valore basso di ESS indica una forte correlazione tra i campioni e una convergenza più lenta della catena.\nL’ESS descrive l’efficacia del campionamento dipendente in termini di campioni indipendenti estratti dalla stessa distribuzione. Rappresenta un indicatore dell’efficienza del campionamento e dell’autocorrelazione della catena.\nLa formula per stimare la dimensione del campione effettiva (ESS) di una catena di Markov è:\n\\[\n\\text{ESS} = \\frac{N}{1 + 2 \\sum_{t=1}^{T} \\rho_t},\n\\]\ndove:\n\n\\(N\\) è il numero totale di campioni nella catena,\n\\(T\\) è il lag, ovvero il numero massimo di termini di autocorrelazione considerati,\n\\(\\rho_t\\) è l’autocorrelazione al lag \\(t\\), ossia la correlazione tra due campioni consecutivi separati da \\(t\\) iterazioni.\n\nIn pratica, \\(T\\) viene scelto in modo tale che \\(\\rho_T\\) sia sufficientemente piccolo, indicando che l’autocorrelazione è quasi svanita. La somma \\(\\sum_{t=1}^T \\rho_t\\) viene quindi troncata approssimativamente a \\(T\\), poiché i contributi delle autocorrelazioni successive diventano trascurabili.\n\n\n51.12.5 Calcolo della Statistica di Gelman-Rubin (\\(\\hat{R}\\))\nPer calcolare la statistica di Gelman-Rubin (spesso indicata come \\(\\hat{R}\\)), è necessario eseguire più catene e confrontare la variabilità all’interno di ciascuna catena con la variabilità tra le catene. Ecco i passaggi per calcolare \\(\\hat{R}\\):\n\nEsegui \\(m\\) catene di Markov di lunghezza \\(n\\), dove \\(m\\) è solitamente maggiore di 1.\nPer ciascun parametro scalare \\(\\theta\\), calcola la varianza all’interno delle catene (\\(W\\)) e la varianza tra le catene (\\(B\\)).\nCalcola la varianza combinata \\(\\hat{V}\\) come media ponderata delle varianze all’interno delle catene.\nCalcola il fattore di riduzione della scala potenziale \\(\\hat{R}\\) come la radice quadrata del rapporto tra la varianza combinata \\(\\hat{V}\\) e la varianza all’interno delle catene \\(W\\):\n\\[\n\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}.\n\\]\nSe \\(\\hat{R}\\) è vicino a 1, ciò indica che le catene sono in convergenza.\n\nLa statistica di Gelman-Rubin \\(\\hat{R}\\) è una misura di convergenza per le catene di Markov. Essa quantifica il grado di accordo tra più catene, fornendo uno strumento diagnostico per valutare la convergenza nelle simulazioni MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "href": "chapters/mcmc/01_metropolis.html#vantaggi-del-campionamento-mcmc-rispetto-alle-soluzioni-analitiche",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.13 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche",
    "text": "51.13 Vantaggi del Campionamento MCMC rispetto alle Soluzioni Analitiche\nIl campionamento MCMC offre notevoli vantaggi pratici rispetto alle soluzioni analitiche nella statistica bayesiana, in particolare quando si tratta di manipolare distribuzioni a posteriori. Sebbene l’impossibilità di calcolare analiticamente la distribuzione a posteriori sia spesso la motivazione principale per l’uso di MCMC, i benefici di questo approccio si estendono ben oltre questa necessità (Bürkner, 2024).\n\n51.13.1 Facilità di Manipolazione e Flessibilità\nIl vantaggio chiave del campionamento MCMC risiede nella semplicità con cui si possono manipolare i campioni ottenuti. Mentre le densità calcolate analiticamente possono richiedere trasformazioni matematiche complesse, i campioni MCMC possono essere facilmente trasformati con operazioni dirette. Questa flessibilità si manifesta in diversi aspetti:\n\nTrasformazioni di Variabili: Consideriamo un caso in cui siamo interessati alla varianza residua (\\(\\sigma^2\\)) in un modello, ma abbiamo campioni solo della deviazione standard residua (\\(\\sigma\\)). Con il campionamento MCMC, la trasformazione è immediata:\n\\[\n(\\sigma^{(s)})^2 = \\sigma^{2(s)},\n\\]\ndove \\(s\\) indica il singolo campione. Questa operazione si traduce semplicemente nell’elevare al quadrato ogni campione di \\(\\sigma\\), ottenendo direttamente campioni validi di \\(\\sigma^2\\). In contrasto, con una densità analitica di \\(\\sigma\\), la trasformazione richiederebbe l’applicazione dell’aggiustamento del Jacobiano, un processo matematicamente più complesso.\nCombinazione di Parametri: Il MCMC semplifica notevolmente la combinazione di parametri in modelli statistici. Per una quantità \\(\\theta\\) che dipende da parametri \\(\\beta_1\\) e \\(\\beta_2\\) attraverso una funzione \\(f\\), possiamo calcolare:\n\\[\\theta^{(s)} = f(\\beta_1^{(s)}, \\beta_2^{(s)}).\\]\nQuesta operazione si estende facilmente a combinazioni complesse e funzioni non lineari, contrastando nettamente con la complessità di derivare analiticamente la distribuzione di \\(\\theta\\).\n\nIn conclusione, il campionamento MCMC non è solo una necessità quando le soluzioni analitiche sono introvabili, ma offre vantaggi in termini di facilità di manipolazione, flessibilità computazionale e applicabilità pratica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#caso-normale-normale",
    "href": "chapters/mcmc/01_metropolis.html#caso-normale-normale",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.14 Caso Normale-Normale",
    "text": "51.14 Caso Normale-Normale\nPer fare un altro esempio, consideriamo ora il caso Normale-Normale di cui è possibile trovare una soluzione analitica. Supponiamo, come prior, una \\(\\mathcal{N}(30, 5\\).\n\ndef prior(mu):\n    return stats.norm.pdf(mu, 30, 5)\n\nPer la verosimiglianza del parametro \\(\\mu\\), supponiamo \\(\\sigma\\) nota e uguale alla deviazione standard del campione.\n\ndef likelihood(mu, data):\n    std_data = np.std(data)  # Calcola la deviazione standard dei dati\n    return np.prod(stats.norm.pdf(data, mu, std_data))\n\nDefiniamo il posterior non normalizzato:\n\ndef posterior(mu, data):\n    return likelihood(mu, data) * prior(mu)\n\nModifichiamo ora l’algoritmo di Metropolis descritto sopra per adattarlo al caso presente.\n\n# Algoritmo di Metropolis per il caso normale-normale\ndef metropolis_for_normal(nsamp, xinit, data):\n    samples = np.empty(nsamp)\n    x_prev = xinit\n\n    for i in range(nsamp):\n        x_star = np.random.normal(x_prev, 0.5)  # Genera un nuovo punto dalla proposta\n\n        # Calcola il rapporto di accettazione e accetta il nuovo punto con una certa probabilità\n        if posterior(x_star, data) / posterior(x_prev, data) &gt; np.random.uniform():\n            x_prev = x_star\n\n        samples[i] = x_prev\n\n    return samples\n\nVediamo cosa fa la presente versione dell’algoritmo di Metropolis passo dopo passo:\n\nCiclo sui Campioni: for i in range(nsamp): inizia un ciclo che si ripeterà nsamp volte, dove nsamp è il numero totale di campioni che vogliamo generare. Ogni iterazione di questo ciclo produrrà un campione dalla distribuzione di interesse.\nGenerazione di un Nuovo Punto: x_star = np.random.normal(x_prev, 0.5) genera un nuovo punto (x_star) come proposta per il prossimo passo del campionamento. Questo è fatto campionando da una distribuzione normale con media uguale all’ultimo punto accettato (x_prev) e una deviazione standard di 0.5. Questa distribuzione è detta distribuzione di proposta e serve a esplorare lo spazio dei parametri.\nCalcolo del Rapporto di Accettazione:\n\nIl rapporto di accettazione è calcolato come posterior(x_star, data) / posterior(x_prev, data), che è il rapporto tra la probabilità del posterior del nuovo punto proposto (x_star) e la probabilità del posterior dell’ultimo punto accettato (x_prev).\nQuesto rapporto indica quanto sia preferibile il nuovo punto rispetto al precedente, basandosi sulla funzione posterior, che calcola la probabilità a posteriori del modello dato il parametro e i dati osservati.\n\nDecisione di Accettazione del Nuovo Punto:\n\nLa decisione se accettare o meno il nuovo punto (x_star) si basa su un confronto del rapporto di accettazione con un numero casuale uniformemente distribuito tra 0 e 1 (np.random.uniform()).\nSe il rapporto di accettazione è maggiore di questo numero casuale, il nuovo punto è accettato come il prossimo punto nella catena (x_prev = x_star). Ciò significa che il nuovo punto ha una probabilità a posteriori più alta rispetto al punto precedente, o è stato “fortunato” nel processo di selezione casuale, consentendo all’algoritmo di esplorare lo spazio dei parametri anche in zone di minore probabilità.\nSe il nuovo punto non viene accettato, la catena rimane nel punto precedente (x_prev), e questo punto viene nuovamente aggiunto all’array dei campioni.\n\nSalvataggio del Campione: samples[i] = x_prev salva il punto corrente (che può essere il nuovo punto accettato o il punto precedente se il nuovo punto è stato rifiutato) nell’array samples. Questo processo si ripete fino a quando non si raggiunge il numero desiderato di campioni.\n\nCome dati, usiamo il campione di 30 valori BDI-II ottenuti dai soggetti clinici esaminati da {cite}zetsche_2019future.\n\ny = np.array([\n    26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31,\n    41, 36, 26, 35, 33, 28, 27, 34, 27, 22,\n])\n\nProcediamo con l’esecuzione dell’algoritmo di Metropolis.\n\nsamples = metropolis_for_normal(100_000, np.mean(y), y)\nsamples.shape\n\n(100000,)\n\n\n\n51.14.1 Calcolo dei Parametri del Posterior Analitico\nNel caso normale-normale, possiamo derivare analiticamente la distribuzione posteriore quando sia il prior che la likelihood sono distribuzioni normali. La bellezza di questo approccio sta nella forma chiusa del posterior, che è anch’esso una distribuzione normale con parametri specifici facilmente calcolabili. Ecco come si fa:\n\nMedia Posteriore (\\(\\mu_{post}\\)): La media del posterior è un peso tra la media del campione e la media del prior, dove i pesi sono determinati dalle varianze del prior e dei dati.\n\\[\n\\mu_{post} = \\frac{\\frac{\\mu_{prior}}{\\sigma_{prior}^2} + \\frac{\\sum y_i}{\\sigma_{data}^2}}{\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}}\n\\]\nVarianza Posteriore (\\(\\sigma_{post}^2\\)): La varianza del posterior è determinata dalle varianze del prior e dei dati.\n\\[\n\\sigma_{post}^2 = \\left(\\frac{1}{\\sigma_{prior}^2} + \\frac{n}{\\sigma_{data}^2}\\right)^{-1}\n\\]\n\nDove: - \\(\\mu_{prior}\\) è la media del prior (in questo caso, 30), - \\(\\sigma_{prior}^2\\) è la varianza del prior (\\(5^2\\) in questo caso), - \\(\\sigma_{data}^2\\) è la varianza dei dati (calcolata dai dati), - \\(n\\) è il numero di osservazioni, - \\(\\sum y_i\\) è la somma delle osservazioni.\n\n\n51.14.2 Codice per il Grafico\nPer produrre il grafico con l’istogramma dei campioni dal posterior (usando l’algoritmo di Metropolis) e la curva della distribuzione posteriore analitica, usiamo i parametri calcolati:\n\n# Parametri del prior\nmu_prior = 30\nstd_prior = 5\nvar_prior = std_prior ** 2\n\n# Dati osservati\nn = len(y)\nsum_y = np.sum(y)\nvar_data = np.var(y, ddof=1)  # ddof=1 for sample variance\n\n# Calcolo dei parametri posterior\nmu_post = (mu_prior / var_prior + sum_y / var_data) / (1 / var_prior + n / var_data)\nvar_post = 1 / (1 / var_prior + n / var_data)\nstd_post = np.sqrt(var_post)\n\n# Generazione dei punti x per il grafico\nx = np.linspace(mu_post - 4 * std_post, mu_post + 4 * std_post, 1000)\n\n# Istogramma dei campioni dal posterior\nplt.hist(samples[burnin:], bins=30, alpha=0.4, density=True, label=\"MCMC Samples Distribution\")\n\n# Curva della distribuzione posteriore analitica\nplt.plot(x, stats.norm.pdf(x, mu_post, std_post), \"C1\", label=\"Analytical Posterior Distribution\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice mostra come integrare l’analisi MCMC con l’approccio analitico per il caso normale-normale, offrendo sia una visualizzazione dei risultati del sampling che la conferma attraverso la soluzione analitica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/01_metropolis.html#commenti-e-considerazioni-finali",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "51.15 Commenti e Considerazioni Finali",
    "text": "51.15 Commenti e Considerazioni Finali\nIn molti casi, la distribuzione a posteriori dei parametri di un modello statistico non ha una forma analitica risolvibile. Per affrontare questa limitazione, si utilizzano metodi Monte Carlo basati su catene di Markov (MCMC). Questi algoritmi permettono di campionare efficacemente dalla distribuzione a posteriori, anche per modelli complessi, generando una sequenza di valori che approssima la distribuzione desiderata. L’algoritmo di Metropolis-Hastings (Hastings, 1970), un’estensione dell’algoritmo di Metropolis originale (Metropolis et al., 1953), è uno dei metodi MCMC più ampiamente utilizzati.\nIn sintesi, l’algoritmo segue questi passaggi principali:\n\nGenerazione del nuovo stato proposto: Si crea un nuovo stato vicino a quello corrente utilizzando una distribuzione di proposta.\nConfronto tra densità posteriori: Si confrontano le densità a posteriori del nuovo stato proposto e dello stato corrente.\nAccettazione probabilistica: Il nuovo stato viene sempre accettato se ha una densità posteriore maggiore, oppure accettato con una certa probabilità se ha una densità minore.\nBurn-in e tasso di accettazione: I primi campioni vengono scartati (fase di burn-in) per garantire che la catena abbia raggiunto la distribuzione stazionaria, e si monitora il tasso di accettazione per ottimizzare l’efficienza del campionamento.\n\nQuesto approccio consente di ottenere campioni che approssimano la distribuzione a posteriori, ma l’algoritmo di Metropolis può presentare limiti di efficienza, soprattutto per problemi ad alta dimensionalità o distribuzioni con geometrie complesse. Un aspetto cruciale è il tasso di accettazione, che rappresenta il rapporto tra il numero di proposte accettate e il numero totale di proposte. Un tasso troppo basso può indicare che la catena esplora lo spazio dei parametri in modo inefficiente, mentre un tasso troppo alto può segnalare che i passi effettuati sono troppo piccoli per consentire una buona esplorazione.\nRispetto alle varianti più moderne, l’algoritmo di Metropolis tende a essere meno efficiente. Metodi come il No-U-Turn Sampler (NUTS) e l’Hamiltonian Monte Carlo (HMC) offrono miglioramenti significativi, specialmente in spazi di parametri di grandi dimensioni. NUTS, ad esempio, viene utilizzato in strumenti avanzati come Stan e PyMC (Hoffman et al., 2014), permettendo un’esplorazione più rapida e accurata della distribuzione a posteriori.\nTra gli altri algoritmi MCMC degni di nota troviamo il campionatore di Gibbs (Geman & Geman, 1984) e l’Hamiltonian Monte Carlo (Duane et al., 1987). Questi metodi, insieme a Metropolis-Hastings, formano la base di numerose tecniche moderne per il campionamento da distribuzioni complesse. Per un approfondimento dettagliato sulle tecniche MCMC, si consiglia di consultare Hanada & Matsuura (2022).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/01_metropolis.html#informazioni-sullambiente-di-sviluppo",
    "title": "51  Monte Carlo a Catena di Markov",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jun 15 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nsys        : 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:35:20) [Clang 16.0.6 ]\nmatplotlib : 3.8.4\narviz      : 0.18.0\nstatsmodels: 0.14.2\nscipy      : 1.13.1\nnumpy      : 1.26.4\nseaborn    : 0.13.2\npymc       : 5.15.1\npandas     : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBürkner, P.-C. (2024). The brms Book: Applied Bayesian Regression Modelling Using R and Stan (Early Draft). https://paulbuerkner.com/software/brms-book\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987). Hybrid monte carlo. Physics letters B, 195(2), 216–222.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on pattern analysis and machine intelligence, 6, 721–741.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from Scratch. Springer.\n\n\nHastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97–109.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research, 15(1), 1593–1623.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087–1092.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Monte Carlo a Catena di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html",
    "href": "chapters/mcmc/02_ppl.html",
    "title": "52  Linguaggi di programmazione probabilistici",
    "section": "",
    "text": "52.1 Cos’è la programmazione probabilistica\nLa programmazione probabilistica è un paradigma della programmazione informatica che consente di creare modelli e algoritmi capaci di gestire l’incertezza e la casualità. Combina i principi della teoria delle probabilità con la programmazione, permettendo di costruire sistemi in grado di ragionare su dati incerti e di prendere decisioni informate. Questo approccio consente di esprimere modelli complessi in modo naturale e intuitivo, facilitando il processo di inferenza bayesiana.\nLa programmazione probabilistica si colloca all’intersezione tra algoritmi di machine learning, statistica e linguaggi di programmazione. I suoi obiettivi principali sono semplificare il processo di inferenza e automatizzarlo.\nLa gerarchia logica generale della programmazione probabilistica può essere vista così:\nInferenza → Sistema di programmazione probabilistica → Linguaggio di programmazione probabilistica → Modelli → Applicazioni",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "href": "chapters/mcmc/02_ppl.html#perché-abbiamo-bisogno-della-programmazione-probabilistica",
    "title": "52  Linguaggi di programmazione probabilistici",
    "section": "52.2 Perché abbiamo bisogno della programmazione probabilistica?",
    "text": "52.2 Perché abbiamo bisogno della programmazione probabilistica?\nScrivere un proprio campionatore per l’inferenza bayesiana è un compito estremamente difficile. Richiede competenze matematiche avanzate e una profonda conoscenza degli algoritmi di campionamento (sia MCMC che approssimati). Inoltre, ci sono numerosi problemi potenziali legati alla stabilità numerica e ai costi computazionali. Questo significa che per riuscirci bisogna essere allo stesso tempo degli ottimi sviluppatori e degli esperti statistici.\nÈ però possibile delegare tutti questi compiti a un sistema che li automatizzi, permettendoci di concentrarci sulla risoluzione dei problemi scientifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "href": "chapters/mcmc/02_ppl.html#linguaggi-di-programmazione-probabilistica-ppls",
    "title": "52  Linguaggi di programmazione probabilistici",
    "section": "52.3 Linguaggi di programmazione probabilistica (PPLs)",
    "text": "52.3 Linguaggi di programmazione probabilistica (PPLs)\nIn questa sezione esamineremo il panorama moderno dei linguaggi di programmazione probabilistica (PPLs) e, nella sezione successiva, esploreremo le funzionalità di uno di questi, Stan.\nUn PPL ci consente di formalizzare un modello bayesiano e di eseguire l’inferenza grazie a potenti algoritmi. L’utente deve solo definire il modello, scegliere un campionatore (se necessario) e “premere il pulsante dell’inferenza”.\nIn generale, ciò che si richiede da un linguaggio di programmazione probabilistica è la capacità di: - estrarre valori casuali da distribuzioni; - condizionare i valori delle variabili su osservazioni (dati).\nAlcuni dei primi linguaggi e strumenti di programmazione probabilistica, come BUGS e WinBUGS, hanno aperto la strada, offrendo tre capacità chiave:\n\nrandom: per creare variabili casuali,\nconstraint: per vincolare variabili ai dati osservati,\ninfer: per restituire la distribuzione di una variabile.\n\nL’elenco dei linguaggi di programmazione probabilistica attualmente esistenti è molto lungo e in continua crescita. Ecco alcuni esempi:\n\nBUGS, WinBUGS, JAGS,\nStan,\nPyMC3, PyMC4, PyMC,\nNimble,\nPyro, NumPyro,\nEdward, TensorFlow Probability, Edward 2,\nGen,\nTuring,\nStheno,\nSOSS,\nOmega,\nInfer.NET.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "href": "chapters/mcmc/02_ppl.html#come-scegliere-un-ppl",
    "title": "52  Linguaggi di programmazione probabilistici",
    "section": "52.4 Come scegliere un PPL?",
    "text": "52.4 Come scegliere un PPL?\nDal punto di vista pratico, come si può decidere quale linguaggio di programmazione probabilistica scegliere? Ecco alcuni fattori chiave da considerare:\n\nFunzionalità: valuta il linguaggio in base alla disponibilità di un ampio range di distribuzioni probabilistiche e campionatori.\nPersonalizzazione: verifica se il PPL permette di definire distribuzioni e campionatori personalizzati.\nPerformance: alcuni PPL offrono ottimizzazioni o capacità di elaborazione parallela per migliorare le prestazioni.\nDocumentazione: la disponibilità di risorse ben documentate, come guide, tutorial e documentazione ufficiale, può avere un grande impatto sulla tua curva di apprendimento e produttività.\nSupporto della comunità: una comunità attiva e di supporto può essere una risorsa preziosa quando incontri difficoltà o hai domande. Forum, gruppi di discussione e contenuti condivisi dagli utenti possono offrire soluzioni e suggerimenti.\nIntegrazione: valuta se il PPL si integra facilmente con altri strumenti e framework che potresti utilizzare nel tuo progetto. La compatibilità con librerie per la manipolazione dei dati, la visualizzazione o il machine learning può semplificare il flusso di lavoro.\n\nQuesti criteri ci aiutano a scegliere il PPL più adatto alle nostre esigenze.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Linguaggi di programmazione probabilistici</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html",
    "href": "chapters/mcmc/03_stan_language.html",
    "title": "53  Linguaggio Stan",
    "section": "",
    "text": "53.1 Introduzione\nStan implementa una versione più efficiente dell’algoritmo di Metropolis (Capitolo 51) chiamata Hamiltonian Monte Carlo (HMC), che viene ulteriormente ottimizzata in Stan attraverso l’algoritmo NUTS (No-U-Turn Sampler). Sebbene l’algoritmo di Metropolis e NUTS producano la stessa soluzione finale, l’algoritmo di Metropolis richiede un numero molto maggiore di iterazioni per raggiungere una condizione di equilibrio, dove i valori prodotti possono essere considerati equivalenti a un campione casuale estratto dalla distribuzione a posteriori desiderata. Questo aspetto diventa particolarmente critico nei modelli complessi, dove la convergenza può richiedere un grande numero di iterazioni, comportando tempi di calcolo molto lunghi. Di conseguenza, l’efficienza del campionamento diventa essenziale. Dal punto di vista concettuale, dunque, ciò che l’algoritmo di Metropolis e NUTS producono è sostanzialmente lo stesso: una catena di campioni che riflette la distribuzione a posteriori target. La differenza principale risiede nella velocità con cui NUTS raggiunge questo obiettivo, rendendolo una scelta preferibile per modelli complessi.\nIn questo capitolo, introdurremo un linguaggio di programmazione probabilistica (PPL) chiamato Stan. Stan ci permette di campionare da distribuzioni di probabilità costruendo una catena di Markov, la cui distribuzione di equilibrio (o stazionaria) coincide con la distribuzione desiderata. Il nome del linguaggio onora Stanislaw Ulam, uno dei pionieri del metodo Monte Carlo. Per maggiori informazioni, si veda l’Appendice P.\nStan è un linguaggio altamente versatile, compatibile con diverse piattaforme e linguaggi di programmazione, tra cui R, Python e Julia. In questo corso, ci concentreremo su CmdStanPy, un’interfaccia Python che semplifica l’utilizzo di Stan. CmdStanPy agisce come un ponte tra Python e CmdStan, l’interfaccia a riga di comando di Stan implementata in C++. Le istruzioni per installare CmdStanPy e i componenti necessari di CmdStan dal repository conda-forge sono disponibili nell’Appendice E. Oltre a CmdStanPy, esistono altre interfacce come cmdstanr per R, Stan.jl per Julia e MatlabStan per Matlab, offrendo una vasta gamma di opzioni per integrare Stan nel proprio flusso di lavoro.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#stan-e-la-programmazione-probabilistica",
    "href": "chapters/mcmc/03_stan_language.html#stan-e-la-programmazione-probabilistica",
    "title": "53  Linguaggio Stan",
    "section": "53.2 Stan e la Programmazione Probabilistica",
    "text": "53.2 Stan e la Programmazione Probabilistica\nLa programmazione probabilistica rappresenta un innovativo paradigma nel campo dell’informatica, che fonde i principi della teoria della probabilità con quelli della programmazione. Questo approccio consente di sviluppare modelli e algoritmi capaci di gestire l’incertezza e la casualità in modo efficace e intuitivo.\nAl cuore di questo paradigma si trova la capacità di costruire sistemi che ragionano su dati incerti e prendono decisioni informate. La programmazione probabilistica si colloca all’intersezione tra machine learning, statistica e linguaggi di programmazione, con l’obiettivo primario di semplificare e automatizzare il processo di inferenza bayesiana.\nI Linguaggi di Programmazione Probabilistica (PPL) offrono un framework potente per formalizzare modelli bayesiani ed eseguire inferenze complesse. L’utente è chiamato principalmente a formulare il modello e, eventualmente, a selezionare un metodo di campionamento appropriato. Dopodiché, il processo di inferenza può essere avviato con relativa semplicità, quasi come se si trattasse di premere un “pulsante di inferenza”.\nIn essenza, un programma probabilistico deve possedere due capacità fondamentali:\n\nL’abilità di estrarre valori casuali da distribuzioni di probabilità.\nLa capacità di condizionare i valori delle variabili nel programma sulla base di osservazioni.\n\nTra i vari PPL disponibili, in questo insegnamento utilizzeremo Stan. Stan offre un ambiente robusto e flessibile per la modellazione bayesiana, combinando potenza computazionale e facilità d’uso, rendendolo ideale sia per scopi didattici che per applicazioni pratiche avanzate.\n\n53.2.1 Struttura di un Programma Stan\nUn programma Stan richiede la specificazione di variabili e parametri, definendo le distribuzioni a priori per i parametri del modello statistico e la funzione di verosimiglianza. In sostanza, un programma Stan descrive la relazione tra i dati e i parametri, oltre alle distribuzioni probabilistiche che governano questi parametri. Questo permette di effettuare inferenze sulle distribuzioni a posteriori dei parametri del modello, dedotte sia dai dati osservati che dalle distribuzioni a priori definite dall’utente.\n\n\n53.2.2 Esecuzione di un Programma Stan\nStan utilizza metodi come il Monte Carlo a catena di Markov (MCMC) per generare campioni dalle distribuzioni a posteriori. Oltre all’MCMC, Stan supporta anche metodi approssimativi, come l’inferenza variazionale, che forniscono stime più rapide delle distribuzioni a posteriori, pur sacrificando parte della precisione.\nStan può anche generare dati simulati attraverso procedure pseudo-casuali in due contesti principali:\n\nSimulazione in avanti: dove i dati vengono generati a partire da parametri di modello noti.\nInferenza inversa: dove, partendo dai dati osservati e dalle distribuzioni a priori, si stima la distribuzione a posteriori dei parametri del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#simulazione-in-avanti",
    "href": "chapters/mcmc/03_stan_language.html#simulazione-in-avanti",
    "title": "53  Linguaggio Stan",
    "section": "53.3 Simulazione in Avanti",
    "text": "53.3 Simulazione in Avanti\nLa simulazione in avanti consiste nella generazione di dati simulati a partire da un insieme di parametri noti del modello probabilistico. In altre parole, dato un insieme di ipotesi sui parametri del modello, la simulazione in avanti permette di prevedere i possibili risultati che ci aspetteremmo osservare.\nAd esempio, consideriamo uno studio clinico con \\(N\\) soggetti e una probabilità \\(\\theta\\) di esito positivo per ciascun soggetto. Sapendo il valore di \\(\\theta\\) e il numero di soggetti \\(N\\), possiamo utilizzare una distribuzione binomiale per simulare il numero di pazienti che avranno un esito positivo. Questo processo ci consente di generare dati che riflettono le nostre ipotesi sui parametri del modello.\nIn notazione statistica, questo scenario si esprime come segue:\n\\[\nY \\sim \\text{Binomiale}(N, \\theta)\n\\]\ndove \\(Y\\) rappresenta il numero di esiti positivi su \\(N\\) pazienti, con probabilità \\(\\theta\\) di esito positivo per ciascun paziente.\nSupponiamo di avere \\(N = 100\\) soggetti in uno studio clinico e un tasso di successo \\(\\theta = 0.3\\). Possiamo simulare il risultato \\(Y\\), generando casualmente il numero di soggetti con esito positivo. Utilizzando la distribuzione binomiale, possiamo calcolare la probabilità di ottenere esattamente \\(y\\) esiti positivi su \\(N\\) tentativi con la seguente formula:\n\\[\np(Y = y \\mid N, \\theta) = \\binom{N}{y} \\cdot \\theta^y \\cdot (1 - \\theta)^{N - y}\n\\]\nQuesta espressione ci consente di calcolare la probabilità di osservare un certo numero di successi, dato il numero totale di soggetti e la probabilità di successo per ciascuno di essi.\nIn altre parole, possiamo utilizzare Stan per generare campioni casuali da una distribuzione binomiale, proprio come potremmo fare in Python utilizzando librerie come numpy. Ad esempio, in Python, possiamo generare valori casuali da una distribuzione binomiale nel seguente modo:\n\n# Genera 20 valori casuali da una distribuzione binomiale con n=100 e p=0.3\nrandom_values = np.random.binomial(n=100, p=0.3, size=20)\nprint(random_values)\n\n[27 29 27 31 30 21 30 34 31 26 35 18 29 30 34 36 29 25 26 36]\n\n\nAnalogamente, possiamo fare lo stesso in Stan per eseguire simulazioni in avanti e studiare i risultati previsti sulla base dei nostri parametri assunti.\n\n53.3.1 Un Primo Programma in Stan: Generazione di Dati Casuali\nSupponiamo di voler generare valori casuali \\(Y\\) da una distribuzione binomiale con parametri \\(N = 100\\) e \\(\\theta = 0.3\\). Questo può essere realizzato utilizzando il seguente programma Stan:\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0, upper=1&gt; theta;\n}\n\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y;\n  y = binomial_rng(N, theta);\n}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#organizzazione-di-un-programma-stan",
    "href": "chapters/mcmc/03_stan_language.html#organizzazione-di-un-programma-stan",
    "title": "53  Linguaggio Stan",
    "section": "53.4 Organizzazione di un Programma Stan",
    "text": "53.4 Organizzazione di un Programma Stan\nLa prima cosa da notare è che un programma Stan è strutturato in blocchi. In questo esempio, abbiamo due blocchi principali: il blocco dei dati (data), che contiene le dichiarazioni delle variabili da fornire come input, e il blocco delle quantità generate (generated quantities), che non solo dichiara le variabili, ma assegna anche dei valori. In questo programma Stan, la variabile y viene assegnata come risultato di una singola estrazione da una distribuzione \\(\\textrm{binomiale}(N, \\theta)\\), utilizzando la funzione binomial_rng fornita da Stan.\n\n53.4.1 Tipi di Variabili in Stan\nLa seconda cosa da notare è che in un programma Stan tutte le variabili devono essere dichiarate con tipi specifici. Stan utilizza la tipizzazione statica, il che significa che, a differenza di linguaggi come Python o R, il tipo di una variabile deve essere dichiarato esplicitamente nel programma prima che venga utilizzata, e non viene determinato dinamicamente durante l’esecuzione in base al valore assegnato. Una volta dichiarato, il tipo di una variabile rimane invariato.\nNel programma in esame, vengono dichiarate tre variabili: N e y, entrambe di tipo int (intero), e theta, di tipo real (numero reale).\n\n\n53.4.2 Vincoli sui Tipi\nLe variabili in Stan possono avere dei vincoli specifici. Ad esempio, poiché N rappresenta un conteggio, deve essere maggiore o uguale a zero; questo è indicato con il vincolo lower=0. Allo stesso modo, la variabile y, che rappresenta il numero di successi su N tentativi, deve essere compresa tra 0 e N (inclusi), e questo è specificato con il vincolo lower=0, upper=N. Infine, la variabile theta, essendo una probabilità, deve essere compresa tra 0 e 1, il che viene espresso con il vincolo lower=0, upper=1. Sebbene tecnicamente i limiti per i numeri reali siano aperti, in pratica è possibile ottenere valori di 0 o 1 a causa di errori di arrotondamento nei calcoli.\n\n\n53.4.3 Esecuzione del Programma Stan\nPer eseguire un programma Stan, il primo passo è compilare il codice Stan. Questo può essere fatto utilizzando la funzione cmdstan_model(). Tale funzione crea un oggetto CmdStanModel a partire da un file contenente il codice Stan. In background, CmdStan traduce il programma Stan in codice C++ e genera un eseguibile compilato, che potrà poi essere utilizzato per eseguire il modello.\nPer fare un esempio, consideriamo il codice Stan che definisce soltanto i vincoli della variabile y. La variabile y ha valore minimo uguale a 0 e valore massimo 100. Se non specifichiamo nient’altro, Stan genererà un campione casuale di valori y con queste caratteristiche.\n\n# Define the Stan model code\nmodel_code_1 = \"\"\"\nparameters{\n    real&lt;lower=0, upper=100&gt; y;\n}\n\"\"\"\n\n# Create a temporary file for the Stan model\nwith tempfile.NamedTemporaryFile(suffix=\".stan\", mode=\"w\", delete=False) as f:\n    f.write(model_code_1)\n    stan_file = f.name\n\nCompiliamo il modello salvato nel file temporaneo model_code_1.stan:\n\nmodel_1 = CmdStanModel(stan_file=stan_file)\n\nEseguiamo il campionamento MCMC:\n\nsamples_1 = model_1.sample(\n    data={},\n    seed=123,\n    chains=4,\n    parallel_chains=4, # No data needed for this model\n    show_progress=False, \n    show_console=False\n)\n\n\n# Print summary of the samples\nprint(samples_1.summary())\n\n          Mean      MCSE     StdDev       5%       50%      95%    N_Eff  \\\nlp__   2.62356  0.023407   0.813402  1.01076   2.93862   3.2163  1207.62   \ny     51.68350  0.742127  28.626100  6.02640  51.84290  94.9665  1487.88   \n\n      N_Eff/s    R_hat  \nlp__  21956.8  1.00196  \ny     27052.3  1.00070  \n\n\n\n# Convert to a NumPy array for plotting\nposterior_draws = samples_1.draws_pd()  # Get samples as pandas DataFrame\ny_samples = posterior_draws[\"y\"]\n\n\n# Plot the posterior samples\nplt.plot(y_samples, label=\"duration\")\nplt.xlabel(\"sample\")\nplt.ylabel(\"duration\")\nplt.title(\"Posterior Samples of Duration\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Plot the density of the posterior samples\nplt.hist(y_samples, bins=30, density=True, alpha=0.75)\nplt.xlabel(\"y\")\nplt.title(\"Density of Posterior Samples\")\nplt.show()\n\n\n\n\n\n\n\n\nIn questo modo abbiamo generato un campione casuale di valori dalla distribuzione uniforme nell’intervallo [0, 100]. Tuttavia, il nostro obiettivo è ottenere 20 valori y estratti casualmente da una distribuzione binomiale \\(\\text{Binomial}(N, \\theta)\\). Per farlo, modifichiamo il programma Stan come segue.\n\nstan_file = os.path.join(project_directory, \"stan\", \"binomial-rng.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0, upper=1&gt; theta;\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y = binomial_rng(N, theta);\n}\n\n\n\nNel blocco data, specifichiamo due parametri: N (il numero di prove Bernoulliane indipendenti) e theta (la probabilità di successo per ciascuna prova). A questi dati vengono applicati vincoli che ne garantiscono la validità: N deve essere un numero intero positivo, mentre theta deve essere un valore compreso tra 0 e 1.\nIl secondo blocco, generated quantities, utilizza la funzione binomial_rng(), che genera valori casuali da una distribuzione binomiale, usando i parametri specificati (N e theta).\nDurante l’esecuzione, il modello Stan richiede come input i valori di N e theta. A ogni iterazione, il programma campiona un valore di y utilizzando il suo generatore di numeri pseudocasuali integrato. Per eseguire il modello, i valori di N e theta devono essere forniti in un dizionario Python, che verrà passato come input al programma.\n\nN = 100\ntheta = 0.3\ndata = {\n    'N': N, \n    'theta': theta\n}\n\nInfine campioniamo dal modello utilizzando il metodo sample di CmdStanModel.\n\ntrace = model.sample(\n    data=data, \n    seed=123, \n    chains=1,\n    iter_sampling=20, \n    iter_warmup=1,\n    show_progress=False, \n    show_console=False\n)\n\nNell’interfaccia Python, il metodo sample() accetta i seguenti argomenti:\n\ndata: i dati letti nel blocco dati del programma Stan,\nseed: generatore di numeri pseudocasuali per la riproducibilità,\nchains: il numero di simulazioni da eseguire (parallel_chains indica quante eseguire in parallelo),\niter_sampling: numero di estrazioni (cioè, dimensione del campione) da restituire,\niter_warmup: numero di iterazioni di riscaldamento per tarare i parametri dell’algoritmo di campionamento (non necessari qui, quindi impostato a 0),\nshow_progress: se True, stampa aggiornamenti di progresso,\nshow_console: apre un monitor di progresso GUI.\n\nIl risultato della chiamata a sample() sull’istanza del modello viene assegnato alla variabile trace e contiene le 20 estrazioni richieste con l’argomento iter_sampling = 20.\nQuando si chiama model.sample(...), CmdStan esegue Stan come programma C++ autonomo in un processo in background. Questo programma inizia copiando i dati forniti nell’argomento data di Python in un file, quindi legge quel file di dati per costruire un oggetto C++ che rappresenta il modello statistico. Poiché il nostro programma Stan ha solo un blocco di quantità generate, l’unico compito rimanente della classe C++ è generare il numero richiesto di estrazioni. Per ciascuna delle estrazioni specificate da iter_sampling, Stan utilizza un generatore di numeri pseudocasuali per ottenere un valore dalla distribuzione binomiale specificata.\nLa generazione di numeri casuali è determinata dal valore seed specificato nella chiamata.\n\n\n53.4.4 Estrazione dei Risultati\nUna volta completato il campionamento, possiamo estrarre il campione di 20 valori per la variabile scalare y sotto forma di array e quindi stampare i loro valori insieme ai valori delle variabili di input.\n\ny = trace.stan_variable('y')\nprint(\"N =\", N, \";  theta =\", theta, \";  y =\", *y.astype(int))\n\nN = 100 ;  theta = 0.3 ;  y = 28 34 31 29 26 25 31 28 30 36 29 36 37 27 29 23 29 34 30 42\n\n\nQuesto è un esempio di simulazione “forward”, ossia la generazione di dati simulati a partire da un modello probabilistico con parametri noti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#il-problema-inverso",
    "href": "chapters/mcmc/03_stan_language.html#il-problema-inverso",
    "title": "53  Linguaggio Stan",
    "section": "53.5 Il Problema Inverso",
    "text": "53.5 Il Problema Inverso\nIl problema inverso riguarda la stima dei parametri di un modello (come la probabilità di successo \\(\\theta\\) nell’esempio precedente) a partire da un campione di dati osservati.\nPer illustrare come affrontare il problema inverso utilizzando Stan, consideriamo un esperimento Go-No Go in cui sono stati osservati 6 successi su 9 prove. La verosimiglianza di questi dati segue una distribuzione binomiale con parametro di successo \\(\\theta\\) sconosciuto. Come in precedenza, imponiamo una distribuzione uniforme come prior per \\(\\theta\\). L’obiettivo è stimare la distribuzione a posteriori di \\(\\theta\\), ovvero la probabilità di successo.\nÈ noto che la distribuzione a posteriori di \\(\\theta\\), dato un risultato osservato \\(y\\) e un prior Beta, segue anch’essa una distribuzione Beta, con parametri aggiornati che si ottengono sommando \\(y\\) a \\(\\alpha\\) e \\(N-y\\) a \\(\\beta\\). In altre parole, la distribuzione a posteriori è:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(\\alpha + y, \\beta + N - y).\n\\]\nSe scegliamo un prior non informativo con \\(\\alpha = 1\\) e \\(\\beta = 1\\), otteniamo:\n\\[\n\\theta \\mid y \\sim \\text{Beta}(1 + 6, 1 + 9 - 6) = \\text{Beta}(7, 4).\n\\]\nIn questo caso, la distribuzione a posteriori di \\(\\theta\\) è una \\(\\text{Beta}(7, 4)\\), che riflette l’informazione aggiornata dal campione di dati osservati.\nUtilizzando Stan, possiamo campionare da questa distribuzione a posteriori per calcolare statistiche riassuntive e fare previsioni.\nIn sintesi, la simulazione forward e il problema inverso sono due approcci complementari: la simulazione forward genera dati simulati a partire da parametri noti, mentre il problema inverso consente di stimare i parametri del modello utilizzando dati osservati.\nEcco come possiamo specificare il modello Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"go_nogo_model.stan\")\nmodel_go_nogo = CmdStanModel(stan_file=stan_file)\nprint(model_go_nogo.code())\n\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=0&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  y ~ binomial(N, p); // Likelihood\n  p ~ beta(1, 1); // Prior\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; p_gt_chance = p &gt; 0.5;\n}\n\n\n\nIn questo programma Stan, vediamo che il numero totale di prove (n) e il numero di successi (y) vengono forniti come dati. Successivamente, sono presenti due blocchi aggiuntivi: un blocco dei parametri, utilizzato per dichiarare i valori sconosciuti (in questo caso, la probabilità di rispondere correttamente, p), e un blocco del modello, dove vengono specificate la distribuzione a priori e la verosimiglianza. Stan calcola la distribuzione a posteriori combinando queste due componenti. Inoltre, è presente un blocco delle quantità generate in cui viene calcolata una variabile booleana che indica se la probabilità di risposta corretta è maggiore di 0.5.\nIl modello bayesiano e la sua implementazione in Stan ci permettono di affrontare il problema inverso: inferire la probabilità di una risposta corretta (inibizione nelle prove No-Go) a partire dai dati osservati. Utilizzando Stan, possiamo stimare non solo la probabilità di rispondere correttamente nelle prove No-Go, ma anche la probabilità che tale probabilità sia superiore al valore atteso per caso (p_gt_chance).\n\n53.5.1 Campionare dalla Distribuzione a Posteriori\nQuando eseguiamo un programma Stan, vengono generati campioni casuali che approssimano la distribuzione a posteriori. Con l’aumentare del numero di campioni, questi si avvicinano sempre più a veri campioni della distribuzione a posteriori.\nStan utilizza un algoritmo Markov Chain Monte Carlo (MCMC), che può introdurre autocorrelazione tra i campioni, cioè i campioni successivi sono correlati tra loro. Sebbene l’autocorrelazione non crei bias, può aumentare la varianza delle stime, rendendo meno precise le stime nei modelli più complessi.\nPer migliorare l’efficienza del campionamento, specialmente nei modelli ad alta dimensionalità, Stan utilizza un algoritmo chiamato No-U-Turn Sampler (NUTS), che è una versione avanzata dell’Hamiltonian Monte Carlo (HMC). NUTS può generare campioni anti-correlati, riducendo la varianza e migliorando la precisione delle stime rispetto ai campioni indipendenti.\n\n\n53.5.2 Compilazione del Codice Stan\nPer utilizzare Stan, dobbiamo compilare il codice del modello. Questo crea un file eseguibile che, nel nostro caso, abbiamo chiamato model_go_nogo:\nmodel_go_nogo = CmdStanModel(stan_file=stan_file)\nInseriamo i dati richiesti in un dizionario.\n\nstan_data = {\"N\": 9, \"y\": 6}\nprint(stan_data)\n\n{'N': 9, 'y': 6}\n\n\nEseguiamo il campionamento con la seguente chiamata:\n\nfit = model_go_nogo.sample(\n    data=stan_data,\n    iter_warmup=2000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nIl metodo .sample() viene applicato al file eseguibile del modello Stan che abbiamo compilato e nominato model_go_nogo.\nAssumendo una distribuzione a priori per il parametro p, l’algoritmo procede iterativamente, aggiornando la distribuzione a priori di p condizionandola ai valori già generati. Dopo un certo numero di iterazioni, l’algoritmo raggiunge la convergenza, e i valori estratti possono essere considerati campioni dalla distribuzione a posteriori di p.\nAll’inizio del campionamento, la distribuzione dei campioni può essere significativamente diversa dalla distribuzione stazionaria. Questo periodo iniziale è chiamato “burn-in”. Durante il burn-in, i campioni possono non rappresentare accuratamente la distribuzione a posteriori e vengono tipicamente scartati. Con l’aumentare del numero di iterazioni, la distribuzione dei campioni si avvicina sempre più alla distribuzione target.\nUna volta eseguito il modello in Stan, otteniamo una serie di campioni di p dalla distribuzione a posteriori \\(p(p \\mid N, y)\\). Ogni campione rappresenta un possibile valore di p compatibile con i dati osservati y. Procediamo quindi a estrarre i campioni a posteriori per le variabili p e p_gt_chance.\n\np_draws = fit.stan_variable(\"p\")\np_gt_chance_draws = fit.stan_variable(\"p_gt_chance\")\n\nTracciando un istogramma di questi campioni, possiamo visualizzare dove i valori di p sono più probabili e comprendere meglio la forma della distribuzione a posteriori. L’istogramma ci fornisce diverse informazioni:\n\nValore più probabile di p: Questo è il valore intorno al quale i campioni sono più concentrati, noto come la moda della distribuzione.\nDistribuzione dei possibili valori di p: Questo ci dà un’idea dell’incertezza nella stima di p.\n\nSe l’istogramma è stretto e concentrato attorno a un valore specifico, significa che c’è poca incertezza nella stima di p. In altre parole, possiamo essere abbastanza sicuri che il valore vero di p sia vicino a questo valore. Se l’istogramma è largo e distribuito, significa che c’è maggiore incertezza nella stima di p. Questo indica che i dati osservati non forniscono una stima precisa e che il valore di p potrebbe variare notevolmente.\n\nplt.hist(\n    p_draws,\n    bins=30,\n    alpha=0.5,\n    density=True,\n)\nplt.title(\"Istogramma della distribizione a posteriori di p\")\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\nCon un numero così piccolo di prove la nostra incertezza relativamente al valore vero di \\(p\\) è enorme. Si noti la corrispondenza tra questo istogramma e quello calcolato “manualmente” nella ?sec-metropolis-1.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#prior-debolmente-informativi",
    "href": "chapters/mcmc/03_stan_language.html#prior-debolmente-informativi",
    "title": "53  Linguaggio Stan",
    "section": "53.6 Prior Debolmente Informativi",
    "text": "53.6 Prior Debolmente Informativi\nConsideriamo ora una seconda versione del modello Stan precedente, con l’unica differenza che questa volta utilizzeremo una distribuzione a priori debolmente informativa. Torniamo ai dati sulla proporzione di artisti della Generazione X presenti al MoMA. In precedenza, abbiamo osservato che 14 artisti su un campione di 100 appartenevano alla Generazione X. Per costruire un esempio in cui la distribuzione a posteriori differisce significativamente dalla verosimiglianza, impostiamo una distribuzione a priori Beta(4, 6) per \\(\\theta\\), la probabilità che un artista appartenga alla Generazione X. Il codice Stan aggiornato è quindi il seguente.\n\nstan_file = os.path.join(project_directory, \"stan\", \"moma_model.stan\")\nmodel_moma = CmdStanModel(stan_file=stan_file)\nprint(model_moma.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0, upper=N&gt; y;\n  int&lt;lower=0&gt; alpha_prior;\n  int&lt;lower=0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y_rep;\n  int&lt;lower=0, upper=1&gt; theta_gt_025 = theta &gt; 0.25;\n  \n  y_rep = binomial_rng(N, theta);\n}\n\n\n\nCreiamo un dizionario con i dati.\n\ndata_moma = {\n    \"N\": 100,\n    \"y\": 14,\n    \"alpha_prior\": 4,\n    \"beta_prior\": 6\n}\nprint(stan_data)\n\n{'N': 9, 'y': 6}\n\n\nEseguiamo il campionamento.\n\nfit_moma = model_moma.sample(\n    data=data_moma,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro \\(\\theta\\).\n\n_ = az.plot_trace(fit_moma, var_names=(\"theta\"))\n\n\n\n\n\n\n\n\n\naz.summary(fit_moma, var_names=(\"theta\"), kind=\"stats\", hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\ntheta\n0.16\n0.03\n0.1\n0.23\n\n\n\n\n\n\n\nSi noti come la stima putuale a posteriori e l’intervallo di credibilità riproducono i valori ottenuti utilizzando l’algoritmo di Metropolis nella Sezione 51.10.2.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#utilizzo-di-dati-simulati-per-comprendere-il-modello",
    "href": "chapters/mcmc/03_stan_language.html#utilizzo-di-dati-simulati-per-comprendere-il-modello",
    "title": "53  Linguaggio Stan",
    "section": "53.7 Utilizzo di Dati Simulati per Comprendere il Modello",
    "text": "53.7 Utilizzo di Dati Simulati per Comprendere il Modello\nNella sezione precedente abbiamo adattato un modello a un set di dati reale. Tuttavia, nella pratica è essenziale procedere con maggiore cautela ed esaminare attentamente il comportamento del nostro modello e dell’algoritmo di inferenza. Un metodo utile a tal fine è lavorare con dati simulati.\n\n53.7.1 Verifica dei Priors\nPossiamo verificare se i nostri priors sono adeguati calcolando la probabilità a priori dei parametri di interesse. Ad esempio, nel nostro campione, sappiamo che la proporzione di artisti appartenenti alla Generazione X è 0.14. È importante che i priors consentano configurazioni ragionevoli dei dati ma escludano scenari chiaramente assurdi, basandosi sulla nostra esperienza del dominio. Per verificare se i nostri priors soddisfano questo requisito, possiamo effettuare un prior predictive check.\nPer condurre un prior predictive check, utilizziamo lo stesso modello usato in precedenza, inseriamo i parametri di interesse nel blocco generated_quantities e rimuoviamo il termine relativo alla distribuzione di campionamento (ossia la verosimiglianza) dal modello. Senza la verosimiglianza, i parametri non vengono adattati ai dati e vengono quindi campionati dalla loro distribuzione a priori. Il codice Stan rimane identico a quello finale, ma senza la riga y ~ binomial(N, theta);. Un trucco utile per semplificare i prior predictive check è aggiungere uno switch compute_likelihood ai dati, come mostrato di seguito:\nif (compute_likelihood == 1)\n  y ~ binomial(N, theta);\nQuesto ci consente di utilizzare lo stesso file Stan per eseguire sia i prior predictive check che l’inferenza, semplicemente modificando il valore di compute_likelihood.\nDefiniamo innanzitutto il dizionario dei dati:\n\n# Definiamo i dati\ndata_moma = {\n    \"N\": 100,  # Number of trials\n    \"y\": 0,  # Placeholder, not used during prior predictive checks\n    \"alpha_prior\": 4,  # Values for Beta prior parameters\n    \"beta_prior\": 6,\n    \"compute_likelihood\": 0,  # Set to 0 to disable likelihood for prior predictive check\n}\n\nCompiliamo il modello Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"moma_model_prior.stan\")\nmodel_moma_prior = CmdStanModel(stan_file=stan_file)\n\nIl codice Stan associato è il seguente:\n\nprint(model_moma_prior.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  int&lt;lower=0, upper=N&gt; y;\n  int&lt;lower=0&gt; alpha_prior;\n  int&lt;lower=0&gt; beta_prior;\n  int&lt;lower=0, upper=1&gt; compute_likelihood; // Flag to control likelihood inclusion\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior); // Prior for theta\n  \n  if (compute_likelihood == 1) {\n    y ~ binomial(N, theta); // Likelihood is only included if compute_likelihood == 1\n  }\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y_rep;\n  int&lt;lower=0, upper=1&gt; theta_gt_025 = theta &gt; 0.25; // Indicator if theta &gt; 0.25\n  y_rep = binomial_rng(N, theta); // Simulated data for posterior predictive check\n}\n\n\n\nEseguiamo il campionamento utilizzando solo la distribuzione a priori:\n\n# Campionamento dalla distribuzione a priori (compute_likelihood settato a 0)\nfit_prior = model_moma_prior.sample(\n    data=data_moma,\n    chains=4,\n    iter_warmup=500,\n    iter_sampling=1000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEstraiamo i campioni a priori per il parametro \\(\\theta\\):\n\ntheta_samples = fit_prior.stan_variable(\"theta\")\n\nInfine, creiamo un istogramma per visualizzare la distribuzione a priori di \\(\\theta\\):\n\nplt.hist(theta_samples, bins=30, density=True, alpha=0.5, color=\"blue\")\nplt.axvline(0.14, color=\"red\", linestyle=\"--\")  # Mark theta = 0.14 as in your example\nplt.title(\"Prior Predictive Distribution of Theta\")\nplt.xlabel(\"Theta\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\nIn conclusione, osserviamo che la distribuzione a priori per \\(\\theta\\) include la proporzione campionaria, ma la maggior parte della massa di probabilità si concentra su valori più elevati. Questo suggerisce che la scelta della distribuzione Beta come prior potrebbe non essere completamente ottimale per rappresentare il parametro in questione. Sarà necessario valutare se un prior diverso potrebbe migliorare l’inferenza, garantendo una rappresentazione più accurata delle conoscenze a priori e dei dati osservati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#stime-puntuali-bayesiane",
    "href": "chapters/mcmc/03_stan_language.html#stime-puntuali-bayesiane",
    "title": "53  Linguaggio Stan",
    "section": "53.8 Stime Puntuali Bayesiane",
    "text": "53.8 Stime Puntuali Bayesiane\nIn termini bayesiani, una stima puntuale per un parametro \\(\\Theta\\) condizionato sui dati osservati \\(Y = y\\) è un singolo valore \\(\\hat{\\theta} \\in \\mathbb{R}^D\\) che riassume la distribuzione a posteriori \\(p(\\theta \\mid y)\\). La notazione \\(\\hat{\\theta}\\) è convenzionale nella statistica per indicare una stima di un parametro \\(\\theta\\). In questa sezione definiamo tre stimatori e discutiamo come i due stimatori bayesiani minimizzino una funzione di perdita tra il valore vero e la stima. Torneremo alla funzione di perdita e alle proprietà degli stimatori dopo averli definiti.\n\n53.8.1 Stimatore della Media Posteriori\nLa stima puntuale bayesiana più comune per un parametro è la media posteriori,\n\\[\n\\begin{align}\n\\widehat{\\theta}\n&= \\mathbb{E}[\\Theta \\mid Y = y] \\\\\n&= \\int_{\\Theta} \\theta \\cdot p(\\theta \\mid y) \\, \\textrm{d}\\theta \\\\\n&= \\lim_{M \\rightarrow \\infty} \\, \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)} \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)},\n\\end{align}\n\\]\ndove nelle ultime due righe, ogni estrazione è distribuita approssimativamente secondo la distribuzione a posteriori,\n\\[\n\\theta^{(m)} \\sim p(\\theta \\mid y).\n\\]\nAbbiamo introdotto la notazione di aspettativa condizionale nella prima riga di questa definizione. Le aspettative sono semplicemente medie ponderate, con i pesi dati da una densità di probabilità. L’inferenza bayesiana coinvolge aspettative sulla distribuzione a posteriori, la cui notazione concisa è quella dell’aspettativa condizionale,\n\\[\n\\mathbb{E}\\!\n\\left[ f(\\Theta) \\mid Y = y \\right]\n= \\int_{\\mathbb{R^N}} f(\\theta) \\cdot p_{\\Theta \\mid Y}(\\theta \\mid y) \\, \\textrm{d}\\theta,\n\\]\ndove \\(\\Theta\\) e \\(Y\\) sono variabili casuali, mentre \\(\\theta\\) e \\(y\\) sono variabili vincolate ordinarie.\nPer il modello precedente, la stima per il tasso di artisti della Generazione X rappresentato al MoMA, ovvero \\(\\theta\\), condizionata sui dati osservati \\(y\\), è calcolata come la media campionaria delle estrazioni per theta.\n\ntheta = fit_moma.stan_variable(\"theta\")\ntheta_hat = np.mean(theta)\nprint(f\"estimated theta = {theta_hat:.3f}\")\n\nestimated theta = 0.164\n\n\n\n\n53.8.2 Stimatore della Mediana Posteriori, Quantili e Intervalli\nUn’alternativa popolare alla stima puntuale bayesiana è la mediana posteriori, \\(\\theta^+\\). La mediana è il valore tale che, per ogni dimensione \\(d \\in 1{:}D\\),\n\\[\n\\Pr[\\Theta_d \\leq \\theta^+_d] = \\frac{1}{2}.\n\\]\nIn altre parole, la mediana è il valore che divide la distribuzione a posteriori in due parti uguali: il 50% dei campioni è al di sotto della mediana e il 50% è al di sopra. La mediana posteriori può essere calcolata prendendo la mediana dei campioni dalla distribuzione a posteriori.\nEcco come calcolare la mediana posteriori utilizzando Python:\n\ntheta_plus = np.median(theta)\nprint(f\"estimated (median) theta = {theta_plus:.3f}\")\n\nestimated (median) theta = 0.162\n\n\nPoiché la distribuzione a posteriori per i dati relativi agli artisti della Generazione X è quasi simmetrica, la media posteriori e la mediana posteriori sono molto simili.\n\n\n53.8.3 Quantili e Intervalli di Credibilità\nOltre alla mediana, possiamo anche calcolare i quantili e gli intervalli di credibilità per fornire ulteriori informazioni sulla distribuzione a posteriori. I quantili sono valori che dividono la distribuzione in intervalli con una probabilità specificata. Gli intervalli di credibilità indicano l’intervallo entro il quale cade una certa percentuale della distribuzione a posteriori.\n\n53.8.3.1 Quantili\nAd esempio, se vogliamo calcolare il quantile al 95% della distribuzione a posteriori, possiamo semplicemente prendere il valore che si trova al 95° percentile nella sequenza ordinata dei campioni. Di seguito sono riportati i quantili al 5% e al 95% della distribuzione a posteriori per gli artisti della Generazione X, calcolati utilizzando i quantili empirici.\n\nquantile_05 = np.quantile(theta, 0.05)\nquantile_95 = np.quantile(theta, 0.95)\nprint(f\"\"\"0.05 quantile = {quantile_05:.3f};\n0.95 quantile = {quantile_95:.3f}\"\"\")\n\n0.05 quantile = 0.111;\n0.95 quantile = 0.224\n\n\n\n\n53.8.3.2 Intervalli Posteriori\nInsieme, il quantile al 5% e al 95% ci forniscono i limiti del nostro intervallo di probabilità centrale al 90%. Questo intervallo è definito come l’intervallo che contiene il 90% della massa di probabilità a posteriori, con il 5% della massa rimanente al di sotto dell’intervallo e il 5% al di sopra.\n\n\n\n53.8.4 Errore di Stima e Bias\nL’errore di una stima è la differenza tra la stima stessa e il valore vero del parametro,\n\\[\n\\textrm{err} = \\hat{\\theta} - \\theta.\n\\]\nLa nostra stima \\(\\hat{\\theta}\\) è implicitamente una funzione dei dati \\(y\\), quindi anche l’errore dipende dai dati. Possiamo rendere esplicita questa dipendenza scrivendo\n\\[\n\\text{err}(y) = \\hat{\\theta}(y) - \\theta.\n\\]\nIl bias di uno stimatore è definito come l’errore atteso, cioè la media dell’errore rispetto alla distribuzione dei dati per la variabile casuale \\(Y\\),\n\\[\n\\begin{align}\n\\text{bias}\n&= \\mathbb{E}[\\text{err}(Y)] \\\\\n&= \\mathbb{E}[\\hat{\\theta}(Y) - \\theta] \\\\\n&= \\int_Y (\\hat{\\theta}(y) - \\theta) \\, \\text{d}y.\n\\end{align}\n\\]\nIn altre parole, il bias misura quanto, in media, la stima \\(\\hat{\\theta}\\) si discosta dal valore vero \\(\\theta\\) considerando tutte le possibili realizzazioni dei dati \\(Y\\). Un bias nullo indica che lo stimatore è corretto in media, cioè non tende a sovrastimare o sottostimare il valore vero del parametro.\n\n\n53.8.5 Stimatore della Moda Posteriori\nUno stimatore popolare, sebbene non strettamente bayesiano, è la moda a posteriori, che rappresenta il valore del parametro \\(\\theta\\) per cui la densità a posteriori è massima. Formalmente, è definita come:\n\\[\n\\theta^* = \\text{arg max}_\\theta \\ p(\\theta \\mid y).\n\\]\nLa stima \\(\\theta^*\\) è spesso chiamata stima MAP (Maximum A Posteriori). La moda a posteriori non è considerata un vero stimatore bayesiano perché non tiene conto dell’incertezza nella stessa misura in cui lo fanno altri metodi bayesiani. In altre parole, non minimizza una funzione di perdita basata sui valori veri dei parametri, ma cerca semplicemente il valore più probabile dato i dati osservati.\n\n\n53.8.6 Caratteristiche della Moda Posteriori\n\nNon considera l’incertezza: La stima MAP si focalizza solo sul valore più probabile della distribuzione a posteriori, senza tenere conto della variabilità dei dati.\nMassimo della densità a posteriori: La moda a posteriori rappresenta il punto in cui la densità a posteriori raggiunge il suo massimo.\nPossibili limitazioni: La stima MAP potrebbe non esistere in alcuni casi, come nei modelli in cui la densità cresce senza limiti. Questo può accadere, ad esempio, nei modelli bayesiani gerarchici o in distribuzioni semplici come la distribuzione esponenziale con parametro 1 (\\(\\textrm{esponenziale}(1)\\)).\n\n\n\n53.8.7 Funzioni di Perdita e Proprietà degli Stimatori\nLa media a posteriori è uno stimatore bayesiano popolare per due ragioni principali. Primo, è uno stimatore non distorto, il che significa che ha un bias nullo. Secondo, ha l’errore quadratico medio atteso minimo tra tutti gli stimatori non distorti. L’errore quadratico di una stima è definito come:\n\\[\n\\text{err}^2(y) = \\left(\\hat{\\theta}(y) - \\theta\\right)^2.\n\\]\nQuesta è una funzione di perdita, che misura la differenza tra una stima \\(\\hat{\\theta}\\) e il valore vero \\(\\theta\\). Tuttavia, la media a posteriori potrebbe non esistere se la distribuzione a posteriori ha code molto ampie, come accade nella distribuzione di Cauchy standard.\n\n\n53.8.8 Proprietà della Mediana Posteriori\nLa mediana a posteriori \\(\\theta^+\\) ha tre proprietà interessanti:\n\nSempre ben definita: La mediana a posteriori è sempre ben definita, anche per densità con poli o code molto ampie.\nMinimizzazione dell’errore assoluto atteso: La mediana minimizza l’errore assoluto atteso, il che la rende robusta.\nRobustezza ai valori anomali: La mediana è meno sensibile ai valori anomali rispetto alla media, perché minimizza l’errore assoluto anziché l’errore quadrato.\n\n\n\n53.8.9 Concentrazione sulle Medie a Posteriori\nIn questa introduzione a Stan, ci concentreremo principalmente sulle medie a posteriori. La media a posteriori non solo fornisce una stima non distorta, ma minimizza anche l’errore quadratico medio atteso, rendendola uno strumento potente per l’inferenza bayesiana. Tuttavia, è importante essere consapevoli delle sue limitazioni, specialmente in presenza di distribuzioni a posteriori con code molto ampie.\n\n\n53.8.10 Errore (Markov Chain) Monte Carlo e Dimensione del Campione Effettivo\nQuando utilizziamo un campionatore di catene di Markov per stimare parametri, otteniamo una sequenza di campioni casuali. Questa sequenza è essa stessa una variabile casuale, perché è composta da molte variabili casuali. A causa di questa natura casuale, ogni esecuzione del campionatore può produrre risultati leggermente diversi, introducendo quello che è noto come errore Monte Carlo.\nL’errore Monte Carlo è l’errore introdotto dal fatto che utilizziamo solo un numero finito di campioni ($ M $) per stimare i parametri. Questo tipo di errore si verifica perché, con un numero limitato di campioni, non possiamo catturare perfettamente l’intera distribuzione a posteriori.\n\n53.8.10.1 Errore Standard di Monte Carlo (MCMC)\nStan riporta l’errore standard di Monte Carlo (MCMC) insieme alle stime della media. L’errore standard MCMC per un parametro scalare $ _d $ è definito come:\n\\[\n\\text{mcmc-se} = \\frac{\\textrm{sd}[\\Theta_d \\mid Y = y]}{\\sqrt{N^{\\text{eff}}}},\n\\]\ndove: - \\(\\text{sd}[\\Theta_d \\mid Y = y]\\) è la deviazione standard del parametro $ _d $ nella distribuzione a posteriori. - \\(N^{\\text{eff}}\\) è la dimensione del campione effettivo, che riflette il numero di campioni indipendenti equivalenti ottenuti dal campionatore.\n\n\n53.8.10.2 Dimensione del Campione Effettivo\nNel classico teorema del limite centrale, la dimensione del campione (numero di estrazioni indipendenti) appare al posto di \\(N^{\\text{eff}}\\). Tuttavia, nel contesto delle catene di Markov, i campioni successivi sono correlati tra loro. La dimensione del campione effettivo (\\(N^{\\text{eff}}\\)) tiene conto di questa correlazione e rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle nostre estrazioni correlate.\nLa dimensione del campione effettivo per un campione di dimensione $ M $ è definita come:\n\\[\nN^{\\text{eff}} = \\frac{M}{\\text{IAT}},\n\\]\ndove \\(\\text{IAT}\\) è il tempo di autocorrelazione integrata. Sebbene non sia definito formalmente qui, può essere considerato come l’intervallo tra estrazioni effettivamente indipendenti nella nostra catena di Markov. Se l’autocorrelazione è bassa, \\(\\text{IAT}\\) sarà vicino a 1; se l’autocorrelazione è alta, \\(\\text{IAT}\\) sarà molto più alto.\nIn sintesi, \\(N^{\\text{eff}}\\) rappresenta il numero di estrazioni indipendenti che porterebbero allo stesso errore delle estrazioni correlate della nostra catena di Markov.\nIn conclusione, l’errore standard di Monte Carlo (MCMC) fornisce una misura di quanto varierebbero le nostre stime se ripetessimo il processo di campionamento più volte. È un indicatore dell’affidabilità delle nostre stime, tenendo conto della casualità introdotta dall’utilizzo di un numero finito di campioni. Conoscere questo errore ci aiuta a valutare la precisione delle nostre stime e a comprendere meglio l’incertezza associata ai risultati ottenuti tramite il campionamento di catene di Markov.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#stima-delle-probabilità-di-evento",
    "href": "chapters/mcmc/03_stan_language.html#stima-delle-probabilità-di-evento",
    "title": "53  Linguaggio Stan",
    "section": "53.9 Stima delle Probabilità di Evento",
    "text": "53.9 Stima delle Probabilità di Evento\nLaplace non cercava semplicemente un valore specifico per \\(\\theta\\). Voleva sapere qual era la probabilità che \\(\\theta\\) fosse maggiore di \\(\\frac{1}{2}\\) dopo aver osservato \\(y\\) nascite maschili su un totale di \\(N\\) nascite. In termini di teoria della probabilità, voleva stimare la probabilità di un evento.\nUn sottoinsieme di parametri è noto come evento. Possiamo convertire le condizioni sui parametri in eventi. Ad esempio, la condizione \\(\\theta &gt; \\frac{1}{2}\\) può essere espressa come l’evento:\n\\[ A = \\left\\{ \\theta \\in \\Theta : \\theta &gt; \\frac{1}{2} \\right\\}. \\]\nData una misura di probabilità, la probabilità dell’evento \\(A\\), ossia che il tasso di nascite maschili sia superiore a quello delle nascite femminili, sarà ben definita. Poiché possiamo convertire le condizioni in eventi, possiamo trattarle come tali. Questo ci permette di scrivere \\(\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\, \\big| \\, N, y\\right]\\) per indicare la probabilità dell’evento \\(\\Theta &gt; \\frac{1}{2}\\).\n\n53.9.1 Probabilità di Evento tramite Indicatori\nLa funzione indicatrice \\(\\textrm{I}\\) assegna il valore 1 alle proposizioni vere e 0 a quelle false. Ad esempio, \\(\\textrm{I}(\\theta &gt; \\frac{1}{2}) = 1\\) se la proposizione \\(\\theta &gt; \\frac{1}{2}\\) è vera, cioè quando \\(\\theta\\) è maggiore di un mezzo.\nLe probabilità di evento sono definite come aspettative condizionali posteriori delle funzioni indicatrici per eventi:\n\\[\n\\begin{align}\n\\Pr[\\Theta &gt; 0.5 \\mid N, y]\n&= \\mathbb{E}\\!\\left[\\textrm{I}[\\Theta &gt; 0.5] \\mid N, y\\right] \\\\\n&= \\int_{\\Theta} \\textrm{I}(\\theta &gt; 0.5) \\cdot p(\\theta \\mid N, y) \\, \\textrm{d}\\theta \\\\\n&\\approx \\frac{1}{M} \\sum_{m=1}^M \\textrm{I}(\\theta^{(m)} &gt; 0.5),\n\\end{align}\n\\]\ndove \\(\\theta^{(m)}\\) rappresenta i campioni dalla distribuzione a posteriori \\(p(\\theta \\mid N, y)\\) per \\(m = 1, 2, \\ldots, M\\).\n\n\n53.9.2 Eventi come Indicatori in Stan\nIn Stan, possiamo codificare direttamente il valore della funzione indicatrice e assegnarlo a una variabile nel blocco delle quantità generate.\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; theta_gt_025 = theta &gt; 0.25; // Indicator if theta &gt; 0.25\n}\nLe espressioni condizionali come theta &gt; 0.25 assumono il valore 1 se sono vere e 0 se sono false. In notazione matematica, scriveremmo \\(\\textrm{I}(\\theta &gt; 0.25)\\), che assume valore 1 se \\(\\theta &gt; 0.25\\) e 0 altrimenti. In Stan, come in C++, trattiamo &gt; come un operatore binario che restituisce 0 o 1, quindi scriviamo semplicemente theta &gt; 0.25.\nLa media a posteriori della variabile theta_gt_025 è quindi la nostra stima per \\(\\Pr[\\theta &gt; 0.25 \\mid N, y]\\). È essenzialmente 1. Stampando a 15 cifre decimali, vediamo\n\ntheta_gt_025_samples = fit_moma.stan_variable(\"theta_gt_025\")\n\nPr_theta_gt_025 = np.mean(theta_gt_025_samples)\nprint(f\"estimated Pr[theta &gt; 0.25] = {Pr_theta_gt_025:.15f}\")\n\nestimated Pr[theta &gt; 0.25] = 0.011875000000000\n\n\nAbbiamo dunque una probabilità molto piccola che almeno un quarto degli artisti rappresentati al MoMA appartenga alla Generazione X o successive.\n\n\n53.9.3 Statistiche di riepilogo MCMC da Stan\nCon Stan, possiamo ottenere un riepilogo completo della variabile \\(\\theta\\) nella distribuzione a posteriori. Per fare ciò, basta chiamare la funzione .summary() sul campione. Questo riepilogo include tutte le statistiche rilevanti.\n\nfit_moma.summary(sig_figs = 3)\n\n\n\n\n\n\n\n\nMean\nMCSE\nStdDev\n5%\n50%\n95%\nN_Eff\nN_Eff/s\nR_hat\n\n\n\n\nlp__\n-49.5000\n0.011900\n0.7010\n-50.900\n-49.200\n-49.000\n3470.0\n51800.0\n1.0\n\n\ntheta\n0.1640\n0.000638\n0.0348\n0.111\n0.162\n0.224\n2970.0\n44300.0\n1.0\n\n\ny_rep\n16.4000\n0.075900\n5.1300\n9.000\n16.000\n25.000\n4560.0\n68100.0\n1.0\n\n\ntheta_gt_025\n0.0119\n0.001510\n0.1080\n0.000\n0.000\n0.000\n5140.0\n76700.0\n1.0\n\n\n\n\n\n\n\nL’istruzione print(sample.diagnose()) in Stan viene utilizzata per eseguire una diagnosi completa del campionamento MCMC. Questa funzione fornisce una serie di statistiche diagnostiche che aiutano a valutare la qualità e la convergenza del campionamento.\nQuesti sono alcuni degli aspetti che possono essere diagnosticati:\n\nConvergenza: La diagnosi verifica se le catene di Markov sono convergenti, ad esempio controllando il valore di \\(\\hat{R}\\). Un valore di \\(\\hat{R}\\) vicino a 1 indica che le catene sono ben mescolate e convergenti.\nAutocorrelazione: Fornisce informazioni sull’autocorrelazione delle catene, che può influire sull’efficienza del campionamento. Bassa autocorrelazione è desiderabile per ottenere campioni indipendenti.\nEfficienza del campionamento: Viene calcolata la dimensione del campione effettivo (\\(N_{\\text{eff}}\\)), che indica quanti campioni indipendenti equivarrebbero ai campioni correlati ottenuti.\nVarianza e Deviazione Standard: Viene riportata la varianza e la deviazione standard dei campioni, aiutando a comprendere la distribuzione a posteriori del parametro.\n\n\nprint(fit_moma.diagnose())\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpcud9f7dn/moma_model3tkl6v79/moma_model-20241014090410_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpcud9f7dn/moma_model3tkl6v79/moma_model-20241014090410_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpcud9f7dn/moma_model3tkl6v79/moma_model-20241014090410_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpcud9f7dn/moma_model3tkl6v79/moma_model-20241014090410_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nUn grafico con le tracce si ottiene nel modo seguente:\n\n_ = az.plot_trace(fit_moma, var_names=(\"theta\"), combined=False)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#riscaldamento",
    "href": "chapters/mcmc/03_stan_language.html#riscaldamento",
    "title": "53  Linguaggio Stan",
    "section": "54.1 Riscaldamento",
    "text": "54.1 Riscaldamento\nDurante le fasi iniziali di riscaldamento, Stan cerca di trovare la regione di alta probabilità da cui campionare, adattare una buona dimensione del passo e stimare la varianza a posteriori. La varianza stimata viene utilizzata per migliorare l’efficienza del campionatore, un processo chiamato “precondizionamento”. Precondizionare significa ridimensionare i parametri per rendere il campionamento più efficiente.\nStan può anche stimare una matrice di covarianza completa, che rappresenta le relazioni tra tutti i parametri. Utilizzando questa matrice, Stan può effettuare rotazioni e ridimensionamenti dei parametri per campionare in modo più efficace. In questo contesto, “rotazione e scalatura” si riferiscono alla trasformazione dei parametri in una nuova base (rotazione) e alla regolazione delle loro scale (scalatura) per facilitare il campionamento, rendendolo più rapido e affidabile. Per ulteriori dettagli su questi processi, si può fare riferimento a Neal (2011).\nIl riscaldamento converge quando la dimensione del passo e le stime della covarianza a posteriori diventano stabili. Con più catene, è possibile verificare che tutte convergano verso una dimensione del passo e una stima della covarianza simili. A meno che non ci siano problemi, generalmente non misuriamo la convergenza dell’adattamento, ma piuttosto se otteniamo campioni a posteriori ragionevoli dopo il riscaldamento.\nDurante la fase di riscaldamento, Stan non produce una catena di Markov coerente perché utilizza la memoria per adattarsi alle condizioni del modello. Questo adattamento serve a trovare i migliori parametri di campionamento. Tuttavia, una volta terminato il riscaldamento e iniziata la fase di campionamento, Stan inizia a produrre una vera e propria catena di Markov.\nLe nostre analisi a posteriori si baseranno esclusivamente sui campioni generati durante questa fase di campionamento, non sui campioni raccolti durante il riscaldamento. È comunque possibile salvare ed esaminare i campioni del riscaldamento per comprendere meglio come il processo di adattamento è avvenuto e se ci sono stati problemi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#riduzione-potenziale-della-scala-e-widehatr",
    "href": "chapters/mcmc/03_stan_language.html#riduzione-potenziale-della-scala-e-widehatr",
    "title": "53  Linguaggio Stan",
    "section": "54.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)",
    "text": "54.2 Riduzione potenziale della scala e \\(\\widehat{R}\\)\nStan utilizza la statistica di riduzione potenziale della scala \\(\\widehat{R}\\) (pronunciata “R hat”). Dato un insieme di catene di Markov, Stan divide ciascuna di esse a metà per assicurarsi che la prima metà e la seconda metà della catena concordino, quindi calcola le varianze all’interno di ciascuna catena e tra tutte le catene e le confronta. La statistica \\(\\widehat{R}\\) converge a 1 quando le catene di Markov convergono alla stessa distribuzione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#quante-catene-per-quanto-tempo",
    "href": "chapters/mcmc/03_stan_language.html#quante-catene-per-quanto-tempo",
    "title": "53  Linguaggio Stan",
    "section": "54.3 Quante catene per quanto tempo?",
    "text": "54.3 Quante catene per quanto tempo?\nUna semplice regola empirica consiste nell’eseguire quattro catene finché \\(\\widehat{R} \\leq 1.01\\) e la dimensione campionaria effettiva (ESS) è superiore a 100. La raccomandazione di avere una dimensione campionaria effettiva di “soli” 100 è dovuta al fatto che questo valore implica un errore standard pari a \\(\\frac{1}{10}\\) della deviazione standard. Poiché la deviazione standard a posteriori rappresenta l’incertezza residua, calcolare le medie con una precisione maggiore è raramente utile.\nIl modo più semplice per ottenere \\(\\widehat{R} \\leq 1.01\\) e \\(N_{\\text{eff}} &gt; 100\\) è iniziare con 100 iterazioni di riscaldamento e 100 iterazioni di campionamento. Se i valori di \\(\\widehat{R}\\) sono troppo alti o se la dimensione campionaria effettiva è troppo bassa, raddoppiare il numero di iterazioni di riscaldamento e di campionamento e riprovare. Eseguire più iterazioni di riscaldamento è importante perché il campionamento non sarà efficiente se il riscaldamento non è convergente. Utilizzare lo stesso numero di iterazioni di riscaldamento e di campionamento può comportare un costo massimo doppio rispetto alle impostazioni ottimali, che non sono note in anticipo.\nAnche se si utilizzano più di quattro catene, è necessario assicurarsi che la dimensione campionaria effettiva sia almeno 25 per catena. Non è tanto per l’inferenza, quanto per garantire la fiducia nello stimatore della dimensione campionaria effettiva, che non è affidabile se è molto inferiore. Un modo per verificare l’adeguatezza dello stimatore ESS è raddoppiare il numero di campioni e assicurarsi che anche l’ESS raddoppi. Se ciò non accade, significa che la prima stima dell’ESS non è affidabile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#esecuzione-delle-catene-contemporaneamente",
    "href": "chapters/mcmc/03_stan_language.html#esecuzione-delle-catene-contemporaneamente",
    "title": "53  Linguaggio Stan",
    "section": "54.4 Esecuzione delle catene contemporaneamente",
    "text": "54.4 Esecuzione delle catene contemporaneamente\nÈ possibile impostare il numero di catene da eseguire utilizzando l’argomento chains del metodo sample(). Inoltre, è possibile controllare quante catene possono essere eseguite contemporaneamente con l’argomento parallel_cores (che per default è impostato su 1, ovvero esecuzione sequenziale).\nSe il numero massimo di catene parallele è impostato troppo basso, le risorse della CPU potrebbero non essere sfruttate appieno. Al contrario, se è impostato troppo alto, la CPU o la memoria potrebbero diventare il collo di bottiglia, rallentando le prestazioni complessive rispetto all’esecuzione con un numero inferiore di catene parallele.\nIn progetti personali sul nostro hardware, l’obiettivo è solitamente ottenere la massima dimensione campionaria effettiva nel minor tempo possibile. Tuttavia, a volte è necessario lasciare abbastanza potenza di elaborazione per continuare a lavorare su altre attività come documenti, email, ecc.\n\n54.4.1 Matrici, Vettori o Array in Stan\nStan offre vari tipi di dati per gestire operazioni di algebra lineare e per definire strutture di dati più generali come gli array. Capire le differenze tra questi tipi è fondamentale per sapere cosa possiamo fare con essi e per ottimizzare la velocità di esecuzione del nostro modello.\n\nTipi di base per l’algebra lineare:\n\nvector: un vettore colonna di dimensione N.\nrow_vector: un vettore riga di dimensione N.\nmatrix: una matrice di dimensioni N1 × N2.\n\nArray:\n\nGli array possono essere creati con qualsiasi tipo di elemento e possono avere più dimensioni. Ad esempio:\n\narray[N] real a; definisce un array unidimensionale di numeri reali.\narray[N1, N2] real m; definisce un array bidimensionale di numeri reali.\n\n\nIntercambiabilità e limitazioni:\n\nAnche se possiamo usare sia vector che array per contenitori unidimensionali, l’algebra matriciale (come la moltiplicazione) è definita solo per vettori e matrici, non per array.\nAlcune funzioni, come normal_lpdf, accettano sia vettori che array.\n\nEsempi pratici:\n\nQuando definiamo una media (mu) come somma di un parametro (alpha) e il prodotto di un vettore di carichi (c_load) con un coefficiente (beta), dobbiamo usare i vettori:\nvector[N] mu = alpha + c_load * beta;\nPer utilizzare un generatore di numeri casuali (_rng) in modo vettoriale, dobbiamo usare un array:\narray[N] real p_size_pred = normal_rng(alpha + c_load * beta, sigma);\n\n\nIn sintesi, la scelta tra vector, row_vector, matrix e array dipende dalle operazioni che si desidera eseguire e dalle specifiche esigenze del modello. Scegliere il tipo di dato appropriato permette di sfruttare appieno le funzionalità di Stan e ottimizzare le prestazioni del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#modello-di-esecuzione-di-stan",
    "href": "chapters/mcmc/03_stan_language.html#modello-di-esecuzione-di-stan",
    "title": "53  Linguaggio Stan",
    "section": "54.5 Modello di esecuzione di Stan",
    "text": "54.5 Modello di esecuzione di Stan\nI programmi Stan sono composti da diversi blocchi. Ecco una panoramica di ciascun blocco, di quando viene eseguito e di cosa fa. Nessuno di questi blocchi è obbligatorio, ma se presenti, devono seguire quest’ordine.\n\n\n\n\n\n\n\n\nBlocco\nQuando viene eseguito\nCosa fa\n\n\n\n\nfunctions\nsecondo necessità\nDefinizione delle funzioni create dall’utente\n\n\ndata\nuna volta\nLettura dei dati per costruire il modello\n\n\ntransformed data\nuna volta\nDefinizione dei dati trasformati\n\n\nparameters\nuna volta / densità logaritmica\nDefinizione dei parametri con i relativi vincoli\n\n\ntransformed parameters\nuna volta / densità logaritmica\nDefinizione dei parametri trasformati\n\n\nmodel\nuna volta / densità logaritmica\nValutazione della densità logaritmica del modello\n\n\ngenerated quantities\nuna volta / per estrazione\nDefinizione delle quantità generate\n\n\n\n\n54.5.1 Dati e dati trasformati\nIl blocco data contiene solo le dichiarazioni delle variabili. Queste variabili vengono lette una volta durante il caricamento dei dati.\nIl blocco transformed data contiene sia dichiarazioni che definizioni delle variabili. Questo blocco serve per calcolare nuove variabili a partire dai dati originali, come predittori standardizzati o costanti per i priori. Può anche includere la generazione pseudocasuale di numeri. Viene eseguito una volta, dopo la lettura dei dati, per definire le nuove variabili trasformate.\nIn ogni blocco, tutte le variabili devono avere il loro tipo e dimensione dichiarati (che possono dipendere dai dati). Le variabili locali all’interno dei blocchi, invece, sono dichiarate senza specificare la dimensione.\nI vincoli sulle variabili nel blocco data vengono controllati mentre i dati vengono letti, mentre quelli nel blocco transformed data vengono verificati alla fine dell’esecuzione del blocco. Se ci sono violazioni dei vincoli nei dati o nei dati trasformati, si genera un’eccezione che interrompe l’esecuzione del programma.\nLe variabili definite nel blocco transformed data possono essere assegnate una volta, ma non possono essere riassegnate dopo l’esecuzione del blocco.\n\n\n54.5.2 Parametri e Parametri Trasformati\nIl blocco parameters serve a dichiarare le variabili su cui è basato il modello. In pratica, si tratta di elencare i parametri che il modello utilizzerà, specificandone le dimensioni. Quando il blocco viene eseguito, vengono forniti i valori concreti di questi parametri.\nI vincoli sui parametri sono utilizzati per trasformare le variabili vincolate in variabili non vincolate. Ad esempio, se una variabile ha un vincolo lower=0 (cioè deve essere maggiore o uguale a zero), questa variabile viene trasformata usando il logaritmo per renderla non vincolata. È essenziale dichiarare tutti i vincoli necessari sui parametri affinché il modello funzioni correttamente su tutto lo spazio dei parametri.\nIl blocco transformed parameters permette di definire nuove variabili che sono funzioni dei parametri originali e dei dati. Gli utenti possono creare le loro trasformazioni dei parametri in questo blocco. I vincoli su queste nuove variabili vengono verificati alla fine dell’esecuzione del blocco. Se questi vincoli non sono rispettati, viene generata un’eccezione che di solito porta al rifiuto della proposta corrente.\nLe variabili dichiarate nel blocco parameters sono simili agli argomenti di una funzione: la funzione di densità logaritmica del programma Stan prende questi parametri come input. Quindi, i valori dei parametri vengono sempre forniti dall’esterno del programma Stan.\nDopo l’esecuzione del blocco transformed parameters, le variabili dichiarate in esso non possono essere modificate ulteriormente.\nLa differenza principale tra le variabili dichiarate come locali nel blocco model e quelle nel blocco transformed parameters è che le variabili trasformate vengono stampate e sono disponibili anche nel blocco generated quantities.\n\n\n54.5.3 Modello\nLo scopo del blocco model è definire la funzione che calcola la densità logaritmica del modello. Una volta caricati i dati, il compito principale di un programma Stan è fornire questa funzione di densità logaritmica non normalizzata sui parametri non vincolati. Algoritmi esterni, come ottimizzatori, campionatori o metodi di inferenza variazionale, forniranno i valori dei parametri non vincolati per la valutazione.\nIl valore della densità logaritmica non normalizzata calcolato dal modello viene conservato in una variabile chiamata target. Le densità posteriori (che ci interessano) sono calcolate moltiplicando i fattori delle funzioni di densità o massa di probabilità. In termini logaritmici, questo equivale ad aggiungere i termini delle funzioni di densità o massa non normalizzate alla target.\nL’accumulatore target parte da zero e viene incrementato durante l’esecuzione del programma Stan. Come accennato prima, la prima cosa che questa funzione di densità logaritmica non normalizzata fa è trasformare i parametri vincolati in non vincolati e aggiungere un aggiustamento logaritmico per il cambio di variabili alla target. Questo processo è automatico e fornisce i valori dei parametri trasformati al codice che verrà eseguito successivamente nel blocco model.\nLa densità logaritmica accumulata in target può essere incrementata direttamente, come mostrato nell’esempio seguente:\ntarget += -0.5 * x^2;\nAnche se non è possibile usare direttamente target come variabile, il suo valore attuale può essere recuperato tramite la funzione target(), utile per il debugging.\nLe istruzioni di campionamento sono una scorciatoia per incrementare target. Ad esempio, l’istruzione\nx ~ normal(0, 1);\nè equivalente a\ntarget += normal_lupdf(x | 0, 1);\nQui, _lupdf indica che si tratta di una funzione di densità di probabilità logaritmica non normalizzata.\nLa barra verticale | è utilizzata per separare le variabili osservate dai parametri. La notazione lpdf denota una funzione di densità di probabilità logaritmica, mentre lpmf indica una funzione di massa di probabilità logaritmica. Le varianti lupdf e lupmf sono le loro controparti non normalizzate, che possono omettere le costanti di normalizzazione che non dipendono dai parametri. A meno che non siano necessarie, ad esempio in un componente di un modello di mescolanza, è più efficiente usare le forme lupdf e lupmf incrementando direttamente target o tramite istruzioni di campionamento.\n\n\n54.5.4 Quantità generate\nIl blocco generated quantities viene eseguito una volta per ogni campione generato, anziché ogni volta che viene calcolata la densità logaritmica. Con algoritmi come il campionamento Monte Carlo Hamiltoniano, ogni campione può richiedere diverse valutazioni della densità logaritmica.\nUn vantaggio delle quantità generate è che vengono calcolate utilizzando numeri in virgola mobile a doppia precisione, il che le rende molto efficienti. Questo blocco può anche utilizzare numeri pseudocasuali. I vincoli sui dati generati vengono verificati alla fine del blocco, ma eventuali errori non causano il rigetto del campione, solo possibili avvertimenti o valori non definiti (NaN).\nLe quantità generate non influenzano il calcolo della densità logaritmica, ma sono comunque una parte importante del modello statistico. Sono utilizzate principalmente per fare previsioni su nuovi dati, basandosi sui parametri stimati dal modello. Questo processo è noto come inferenza predittiva posteriore. In altre parole, ci permette di fare previsioni su nuovi dati utilizzando i valori dei parametri generati dal modello.\nEsempi di utilizzo delle quantità generate includono la previsione di nuovi valori o il calcolo di statistiche derivate dai parametri stimati. Le quantità generate offrono un modo per esplorare ulteriormente il comportamento del modello e fare inferenze utili dai dati simulati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#considerazioni-conclusive",
    "href": "chapters/mcmc/03_stan_language.html#considerazioni-conclusive",
    "title": "53  Linguaggio Stan",
    "section": "54.6 Considerazioni Conclusive",
    "text": "54.6 Considerazioni Conclusive\nL’inferenza bayesiana ha subito una trasformazione significativa grazie all’introduzione dei metodi MCMC, che permettono di esplorare distribuzioni complesse anche in assenza di soluzioni analitiche o campionamenti indipendenti. Tra questi metodi, l’Hamiltonian Monte Carlo (HMC) si distingue per la sua efficienza e capacità di scalare su modelli ad alta dimensione. Stan, con la sua implementazione di HMC, ha reso accessibile l’analisi di modelli bayesiani complessi, consentendo di ottenere risultati in tempi ragionevoli anche per problemi computazionalmente impegnativi. L’introduzione a Stan mostra come questo strumento non solo amplia la gamma di modelli che possiamo affrontare, ma lo fa in modo rigoroso e altamente efficiente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#esercizi",
    "href": "chapters/mcmc/03_stan_language.html#esercizi",
    "title": "53  Linguaggio Stan",
    "section": "54.7 Esercizi",
    "text": "54.7 Esercizi\n\nEsercizio 54.1 Un decennio dopo la pubblicazione della regola di Bayes, Laplace utilizzò la funzione beta di Eulero per derivare formalmente la distribuzione a posteriori. Laplace raccolse dati sul sesso dei bambini nati vivi a Parigi tra il 1745 e il 1770:\n\n\n\nSesso\nNascite vive\n\n\n\n\nFemmina\n105.287\n\n\nMaschio\n110.312\n\n\n\nLaplace si chiese se, sulla base di questi dati, la probabilità di nascita dei maschi fosse superiore a quella delle femmine.\nAnalizzare il problema di Laplace utilizzando Stan.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/03_stan_language.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/03_stan_language.html#informazioni-sullambiente-di-sviluppo",
    "title": "53  Linguaggio Stan",
    "section": "54.8 Informazioni sull’Ambiente di Sviluppo",
    "text": "54.8 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Mon Oct 14 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nlogging   : 0.5.1.2\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html",
    "href": "chapters/mcmc/04_stan_summary_posterior.html",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "",
    "text": "Introduzione\nL’obiettivo di questo capitolo è quello di descrivere i metodi di sintesi della distribuzione a posteriori mediante l’utilizzo della tecnica MCMC.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#sintesi-della-distribuzione-a-posteriori",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.1 Sintesi della Distribuzione a Posteriori",
    "text": "54.1 Sintesi della Distribuzione a Posteriori\nIl risultato di un’analisi bayesiana è una distribuzione a posteriori, contenente tutte le informazioni sui parametri dati un modello e un insieme di dati. Pertanto, riassumere la distribuzione a posteriori significa sintetizzare le conseguenze logiche del modello e dei dati analizzati. È prassi comune riportare, per ciascun parametro, una misura di posizione centrale (come la media, la moda o la mediana) per fornire un’idea della localizzazione della distribuzione, accompagnata da una misura di dispersione, quale la deviazione standard, per quantificare l’incertezza delle stime. La deviazione standard è adeguata per distribuzioni simili alla normale, ma può risultare fuorviante per distribuzioni di altra natura, come quelle asimmetriche.\nPer riassumere la dispersione di una distribuzione a posteriori, si utilizza spesso l’Intervallo di Densità Più Alta (HDI, Highest-Density Interval). L’HDI è l’intervallo più breve che contiene una data porzione della densità di probabilità. Ad esempio, se diciamo che l’HDI al 95% per un’analisi è [2, 5], intendiamo che, secondo i nostri dati e modello, il parametro in questione si trova tra 2 e 5 con una probabilità di 0.95. Non vi è nulla di particolare nella scelta del 95%, del 50% o di qualsiasi altro valore; siamo liberi di scegliere, ad esempio, l’intervallo HDI all’89% o al 94% secondo le nostre preferenze. Idealmente, le giustificazioni per queste scelte dovrebbero dipendere dal contesto e non essere automatiche, ma è accettabile stabilire un valore comune come il 95%. Per ricordarci della natura arbitraria di questa scelta, il valore predefinito in ArviZ è del 94%.\nArviZ è un pacchetto Python per l’analisi esplorativa di modelli bayesiani e offre numerose funzioni utili per riassumere la distribuzione a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#campionamento-con-stan",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.2 Campionamento con Stan",
    "text": "54.2 Campionamento con Stan\nA scopo illustrativo, utilizziamo ancora una volta i dati relativi agli artisti della Generazione X presenti al MOMA. I dati consistono in 14 casi di successo, ovvero artisti della Generazione X, su un totale di 100 opere selezionate casualmente dal MOMA. Come fatto in precedenza, impostiamo il parametro \\(\\theta\\), che rappresenta la probabilità di appartenere alla Generazione X o alle successive, seguendo una distribuzione Beta(4, 6).\nPer iniziare, eseguiamo il processo di campionamento MCMC usando Stan.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'moma.stan')\n\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=N&gt; y_rep;\n  y_rep = binomial_rng(N, theta);\n}\n\n\n\nCompiliamo il modello:\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nDefiniamo il dizionario con i dati:\n\nN = 100\ny = 14\n\ndata = {\n    'N': N, \n    'y': y,\n    \"alpha_prior\" : 4,\n    \"beta_prior\" : 6\n    }\n\nprint(data)\n\n{'N': 100, 'y': 14, 'alpha_prior': 4, 'beta_prior': 6}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=data,\n    iter_warmup = 1000,\n    iter_sampling = 4_000,\n    chains = 4,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#analisi-della-distribuzione-a-posteriori",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.3 Analisi della distribuzione a posteriori",
    "text": "54.3 Analisi della distribuzione a posteriori\nLa distribuzione a posteriori rappresenta la nostra conoscenza aggiornata riguardo al valore del parametro \\(\\theta\\) dopo aver osservato i dati. Combina le nostre credenze a priori riguardo al parametro (la distribuzione a priori) con le nuove evidenze fornite dai dati osservati (la funzione di verosimiglianza) per ottenere una nuova distribuzione che riflette la nostra comprensione aggiornata del parametro, ovvero la distribuzione a posteriori.\nLa distribuzione a posteriori ci dice quanto sia probabile ogni possibile valore del parametro alla luce dei dati osservati. Un picco stretto indica che i dati sono molto informativi rispetto al parametro, portando a una maggiore certezza nella sua stima. Un picco largo, invece, indica maggiore incertezza.\nLa distribuzione a posteriori rappresenta un aggiornamento delle nostre credenze a priori in base ai dati osservati.\nIn genere, il primo passo da fare dopo il campionamento è quello di verificare l’aspetto dei risultati.\n\ntrace.draws().shape\n\n(4000, 4, 9)\n\n\nLe dimensioni (4000, 4, 9) restituite dall’istruzione trace.draws().shape in CmdStanPy si riferiscono alla struttura dei dati campionati ottenuti dall’esecuzione del modello Stan. Vediamo cosa rappresenta ciascuna dimensione:\n\n4000: Questo rappresenta il numero di iterazioni di campionamento per catena. Qui, abbiamo specificato iter_sampling = 4000, quindi ci sono 4000 campioni per ciascuna catena.\n4: Questo è il numero di catene. Abbiamo specificato chains = 4, quindi ci sono 4 catene di campionamento eseguite in parallelo.\n9: Questo rappresenta il numero di parametri o quantità di interesse (inclusi parametri trasformati e quantità generate) che sono stati campionati. Include tutte le variabili definite nei blocchi parameters, transformed parameters e generated quantities del modello Stan.\n\nPossiamo recuperare i nomi delle variabili dall’oggetto trace e il numero di campioni a posteriori per ciascuna variabile nel modo seguente:\n\nvars = trace.stan_variables()\nfor (k,v) in vars.items():\n    print(k, v.shape)\n\ntheta (16000,)\ny_rep (16000,)\n\n\nRecuperiamo i campioni posteriori per theta:\n\ntheta_samples = trace.stan_variable('theta')\ntheta_samples.shape\n\n(16000,)\n\n\nGeneriamo un istogramma della distribuzione a posteriori di theta:\n\nplt.hist(theta_samples, bins=30, density=True, alpha=0.5, color='blue')\nplt.xlabel('Valori di $\\\\theta$')\nplt.ylabel('Frequenza')\nplt.title('Istogramma della Distribuzione a Posteriori di $\\\\theta$')\nplt.show()\n\n\n\n\n\n\n\n\nIn alternativa, possiamo passare l’oggetto trace alle funzioni di ArviZ. La funzione plot_trace di ArviZ è particolarmente adatta a questo scopo:\n\n_ = az.plot_trace(trace, var_names=['theta'])\n\n\n\n\n\n\n\n\nLa figura illustra il risultato predefinito ottenuto chiamando az.plot_trace; vengono generati due subplot per ogni variabile non osservata. Nella configurazione del nostro modello, l’unica variabile non osservata è θ. A sinistra, viene visualizzato un grafico di stima della densità del kernel (KDE), che rappresenta una versione liscia dell’istogramma. È auspicabile che tutte le catene abbiano un KDE molto simile ad una gaussiana, come mostrato nella figura. A destra, vengono mostrati i valori individuali ad ogni passo di campionamento, con tante linee quanti sono i percorsi delle catene. L’ideale è che questa rappresentazione appaia rumorosa, senza un pattern chiaro, rendendo difficile l’identificazione di una catena rispetto alle altre. Il concetto chiave è che, eseguendo molte catene, ci aspettiamo che risultino praticamente indistinguibili l’una dall’altra. Nel caso presente, il campionatore ha svolto un buon lavoro e possiamo fiduciosi nei risultati ottenuti.\nConfrontiamo la distribuzione a posteriori con la distribuzione a priori di \\(\\theta\\).\n\n# Parametri della distribuzione Beta\nalpha, beta_param = 4, 6\n\n# Creazione di un range di valori\nx = np.linspace(0, 1, 1000)\n\n# Calcolo della PDF\npdf = stats.beta.pdf(x, alpha, beta_param)\n\n# Visualizzazione della PDF\n_ = plt.plot(x, pdf, lw=2)\n\n\n\n\n\n\n\n\nNel caso presente, la distribuzione a posteriori differisce in maniera importante dalla distribuzione a priori. Ciò indica che i dati hanno avuto un forte impatto sulle nostre credenze riguardo al valore del parametro.\n\n54.3.1 Intervallo di credibilità\nLa funzione az.plot_posterior ci consente di generare un grafico della distribuzione a posteriori che include la media e l’intervallo di credibilità HDI al 94%. Questo tipo di grafico è stato presentato da John K. Kruschke nel suo libro “Doing Bayesian Data Analysis” (doingbayesian?).\n\n_ = az.plot_posterior(trace, var_names=['theta'])\n\n\n\n\n\n\n\n\nL’intervallo di credibilità fornisce una stima dell’intervallo entro cui il parametro si trova con una certa probabilità. Nel caso presente, l’intervallo di credibilità del 94% ci dice che, data la nostra comprensione a posteriori del parametro, c’è il 94% di probabilità che il vero valore del parametro si trovi all’interno dell’intervallo [0.1, 0.23].\nA differenza dell’intervallo di confidenza frequentista, che è interpretato in termini di lungo termine su ripetuti campionamenti, l’intervallo di credibilità bayesiano è direttamente interpretato come la probabilità che il parametro si trovi all’interno di un certo intervallo dato il set di dati specifico.\nUn sommario numerico della distribuzione a posteriori si ottiene con la funzione az.summary, la quale ritorna una Pandas Data Frame:\n\naz.summary(trace, var_names=['theta'], kind=\"stats\").round(2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\n\n\n\n\ntheta\n0.16\n0.04\n0.1\n0.23\n\n\n\n\n\n\n\nNella prima colonna abbiamo il nome della variabile, nella seconda colonna troviamo la media del posteriore, nella terza colonna la deviazione standard del posteriore, e nelle ultime due colonne troviamo i limiti inferiore e superiore dell’intervallo di densità più alta al 94%. Di conseguenza, secondo il nostro modello e i dati a disposizione, riteniamo che il valore di θ sia probabilmente 0.16, con una probabilità del 94% che si trovi effettivamente tra 0.1 e 0.23. Possiamo riportare un riassunto simile utilizzando la deviazione standard. Il vantaggio della deviazione standard rispetto all’HDI è che è una statistica più conosciuta. Come svantaggio, dobbiamo essere più attenti nell’interpretarla; altrimenti, potrebbe portare a risultati privi di significato. Nel caso presente, se calcoliamo la media ± 2 deviazioni standard, otterremo gli intervalli (0.08, 0.24) che sono simili ai limiti dell’intervallo HDI riportato sopra.\n\n[0.16 + i*0.04 for i in (-2, 2)]\n\n[0.08, 0.24]\n\n\nTuttavia, in alcuni casi, questa procedura potrebbe generare un limite inferiore o superiore al di fuori dell’intervallo consentito per i valori di θ, il quale è compreso tra 0 e 1.\n\n\n54.3.2 Test di Ipotesi Bayesiane\nIn alcune situazioni, la mera descrizione della distribuzione a posteriori non basta. Spesso ci troviamo di fronte alla necessità di fare scelte basate sulle nostre inferenze, traducendo stime continue in decisioni binarie: ad esempio, affermare se un individuo è sano o malato, se un intervento ha avuto successo o meno, e così via.\nPrendiamo come esempio la questione se, nel Museum of Modern Art (MoMA), gli artisti appartenenti alla generazione X rappresentino il 50% dell’intero corpus. Avvalendoci di un campione casuale di 100 opere, unitamente alle nostre convinzioni pregresse (prior), abbiamo determinato un Intervallo di Massima Densità (HDI) che va da 0.1 a 0.23. La nostra ipotesi prevede che θ (la proporzione degli artisti della generazione X) sia 0.5. Confrontando questo valore con l’HDI ottenuto, osserviamo che 0.5 non rientra nell’intervallo [0.1, 0.23]. Questo risultato può essere interpretato come un’indicazione che il MoMA manifesti una preferenza per artisti nati prima del periodo 1965-1980. Tuttavia, non possiamo escludere del tutto la possibilità che la generazione X contribuisca per metà alle opere presenti nel museo. Per arrivare a una conclusione più definita, sarebbe necessario raccogliere ulteriori dati per ridurre la variabilità della distribuzione a posteriori, o considerare l’adozione di un prior più informativo per affinare la nostra analisi.\nOppure possiamo chiederci quale sia la probabilità che il valore a posteriori \\(\\theta\\) assuma un valore minore di 0.5. La funzione az.plot_posterior(idata, ref_val=0.5) ci dice che questa probabilità è uguale a 1. Ovvero, possiamo essere del tutto certi che la proporzione di opere d’arte della generazione X rappresentate al MoMA sia minore del 50% del totale.\n\n_ = az.plot_posterior(trace, var_names=['theta'], ref_val=0.5)\n\n\n\n\n\n\n\n\nPossiamo usare qualsiasi valore di riferimento. Per esempio\n\n_ = az.plot_posterior(trace, var_names=['theta'], ref_val=0.20)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#la-regione-di-equivalenza-pratica-rope",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#la-regione-di-equivalenza-pratica-rope",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.4 La Regione di Equivalenza Pratica (ROPE)",
    "text": "54.4 La Regione di Equivalenza Pratica (ROPE)\nLa Regione di Equivalenza Pratica (ROPE) costituisce un elemento chiave nei test di equivalenza, mirando a stabilire la rilevanza pratica di un parametro. Questa regione si allinea a un’ipotesi nulla predefinita, permettendo di valutare se un parametro può essere considerato equivalente rispetto a tale ipotesi.\nÈ fondamentale comprendere che, data l’infinita precisione teorica nella misurazione dei parametri, la probabilità di identificare un valore esatto di un parametro è sempre uguale a zero. Pertanto, l’analisi si concentra non sull’ottenimento di valori precisi, ma piuttosto su valori che rientrano in un intervallo di accettabilità prefissato.\nIl metodo decisionale “HDI+ROPE” (Kruschke, 2014; Kruschke & Liddell, 2018) viene frequentemente utilizzato per determinare se i valori di un parametro debbano essere considerati accettabili o meno in relazione all’ipotesi nulla delineata dalla ROPE. Questo metodo esamina la percentuale dell’Intervallo Credibile (CI) che si trova all’interno della ROPE, considerata come regione corrispondente all’ipotesi nulla. Se questa percentuale è notevolmente bassa, l’ipotesi nulla viene scartata; viceversa, se è elevata, l’ipotesi viene accettata.\nPer illustrare, consideriamo l’esempio di una moneta teoricamente equilibrata, la cui probabilità di ottenere “testa” si vuole sia vicina al valore teorico di 0.5. Al posto di focalizzarsi esclusivamente sul valore esatto di 0.5, possiamo definire una ROPE, ad esempio tra [0.45, 0.55]. Tale intervallo viene considerato praticamente equivalente a 0.5 ai fini della nostra analisi, consentendo di valutare l’equità della moneta tenendo conto delle naturali fluttuazioni nelle misurazioni.\nDopo aver definito la ROPE, confrontiamo il nostro risultato con l’intervallo di densità più alta (HDI). Da questo confronto emergono tre possibili scenari:\n\nAssenza di sovrapposizione tra ROPE e HDI: Indica che i risultati ottenuti sono sufficientemente distanti dall’intervallo di equivalenza pratica, portando al rifiuto dell’ipotesi di equivalenza. Questo scenario suggerisce che il parametro analizzato ha un impatto pratico che va oltre l’ipotesi di nullità considerata dalla ROPE.\nLa ROPE include completamente l’HDI: Questo scenario si verifica quando l’intero intervallo di densità più alta cade all’interno della ROPE, indicando che i risultati sono pienamente compatibili con l’ipotesi di nullità. In questo caso, possiamo accettare l’ipotesi che il parametro sia praticamente equivalente all’ipotesi nulla, suggerendo una mancanza di significatività pratica del parametro in esame.\nSovrapposizione parziale tra ROPE e HDI: In questo caso, una porzione dell’HDI si sovrappone con la ROPE, ma non completamente. Questo risultato implica che non possiamo trarre conclusioni definitive riguardo all’equivalenza pratica del parametro rispetto all’ipotesi nulla. Si rende necessaria un’ulteriore analisi o l’impiego di altri criteri decisionali per determinare la rilevanza pratica del parametro.\n\nConsiderando un esempio relativo all’analisi dei dati della Generazione X, con una ROPE definita come [0.25, 0.35].\n\n_ = az.plot_posterior(trace, var_names=['theta'], rope=[0.25, .35])\n\n\n\n\n\n\n\n\nLa ROPE così definita corrisponde all’ipotesi del parametro \\(\\theta\\) = 0.3 e considerando equivalenti i valori osservati nell’intervallo [0.25, 0.35].\nL’analisi mostra che l’HDI non si sovrappone alla ROPE. Inoltre, solo l’1.3% della distribuzione a posteriori è contenuta nella ROPE. Possiamo dunque rifiutare l’ipotesi specificata dalla ROPE.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#estrazione-degli-attributi-da-inferencedata",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#estrazione-degli-attributi-da-inferencedata",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.5 Estrazione degli attributi da InferenceData",
    "text": "54.5 Estrazione degli attributi da InferenceData\nVediamo ora nei dettagli come sia possibile effettuare le varie operazioni sulla distribuzione a posteriori, ovvero la stima puntuale, gli intervalli di credibilità e i test di ipotesi, mediante la manipolazione dell’oggetto theta_draws ottenuto dalla funzione sample.stan_variable().",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#stima-puntuale",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#stima-puntuale",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.6 Stima puntuale",
    "text": "54.6 Stima puntuale\nPossiamo recuperare la traccia di campionamento dalla variabile latente theta nel modo seguente:\n\ntheta_draws = trace.stan_variable('theta')\ntheta_draws.shape\n\n(16000,)\n\n\nIn cmdstanpy, quando si utilizza il metodo stan_variable per estrarre i campioni di un parametro specifico dai campioni posteriori, questo restituisce un array numpy contenente i campioni.\nIl metodo stan_variable('theta') estrae tutti i campioni per il parametro theta dalla distribuzione posteriore. Questo include i campioni da tutte le catene e tutte le iterazioni dopo il warmup. Il risultato, theta_draws, è un array numpy in cui i campioni di tutte le catene sono concatenati insieme. La forma di theta_draws è tipicamente (num_samples * num_chains, ) se theta è un parametro scalare, o (num_samples * num_chains, dim1, dim2, ...) se theta è un vettore o una matrice. I campioni delle 4 catene sono concatenati. Questo significa che i campioni di ciascuna catena sono aggiunti uno dopo l’altro in un singolo array. Non sono mescolati insieme in modo casuale; piuttosto, sono semplicemente posizionati in sequenza.\nPer visualizzare il primi 30 valori di theta_draws, ad esempio, usiamo:\n\ntheta_draws[0:30]\n\narray([0.152399, 0.164544, 0.185841, 0.210788, 0.210788, 0.158488,\n       0.152418, 0.117835, 0.161514, 0.168753, 0.137032, 0.162867,\n       0.168521, 0.182565, 0.123249, 0.114717, 0.123867, 0.128263,\n       0.171871, 0.142336, 0.204677, 0.221803, 0.171478, 0.121296,\n       0.108108, 0.199047, 0.133709, 0.138647, 0.144356, 0.174385])\n\n\nDi conseguenza, possiamo calcolare su theta_draws tutte le misure statistiche descrittive che si possono ottenere da un vettore di dati. Per esempio, possiamo calcolare la media a posteriori.\n\nnp.mean(theta_draws)\n\n0.16424613186875\n\n\nPossiamo calcolare la mediana a posteriori di \\(\\theta\\).\n\nnp.median(theta_draws)\n\n0.16208250000000002\n\n\nOppure la deviazione standard della stima a posteriori di \\(\\theta\\).\n\nnp.std(theta_draws)\n\n0.03521655992174475",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità-1",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#intervallo-di-credibilità-1",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.7 Intervallo di credibilità",
    "text": "54.7 Intervallo di credibilità\nL’inferenza bayesiana tramite l’intervallo di credibilità riguarda invece la stima dell’intervallo che contiene il parametro \\(\\theta\\) ad un dato livello di probabilità soggettiva.\nUsando l’oggetto sample, possiamo ottenere un sommario della distribuzione a posteriori con il metodo az.summary().\n\naz.summary(trace, var_names=['theta'], hdi_prob=0.94, round_to=3)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta\n0.164\n0.035\n0.1\n0.231\n0.0\n0.0\n5412.045\n7678.797\n1.0\n\n\n\n\n\n\n\nSi ottiene così l’intervallo di credibilità a più alta densità a posteriori (HPD) al 94%. Questo intervallo ci informa sul fatto che, a posteriori, possiamo essere certi al 94%, che il vero valore del parametro \\(\\theta\\) sia contenuto nell’intervallo [0.103, 0.23].\nDato che, nel caso presente, conosciamo la soluziona analitica, possiamo verificare il risultato precedente calcolando i quantili della distribuzione a posteriori Beta(18, 92) di ordine 0.03 e 0.97.\n\nll = stats.beta.ppf(0.03, 18, 92)\nul = stats.beta.ppf(0.97, 18, 92)\nlist([ll, ul])\n\n[0.10303527075398665, 0.23457657606771784]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#verifica-di-ipotesi-bayesiana",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.8 Verifica di ipotesi bayesiana",
    "text": "54.8 Verifica di ipotesi bayesiana\nUn secondo tipo di inferenza bayesiana riguarda problemi in cui siamo interessati a valutare la plausibilità che il parametro \\(\\theta\\) assuma valori contenuti in un dato intervallo di valori. Per esempio, ci potrebbe interessare l’ipotesi \\(\\theta &gt; 0.5\\). In questo caso, possiamo calcolare la probabilità a posteriori che \\(\\theta\\) cada nell’intervallo di interesse, integrando la distribuzione a posteriori Beta su tale intervallo.\nNel caso dell’esempio degli artisti della Generazione X, supponiamo di essere interessati alle due seguenti ipotesi:\n\\[\n\\begin{split}\nH_0: & \\; \\; \\pi \\ge 0.2 \\\\\nH_a: & \\; \\; \\pi &lt; 0.2\n\\end{split}\n\\]\nLa nostra domanda è la seguente: Date le nostre credenze iniziali e i dati disponibili, quale importanza relativa possiamo attribuire a queste due ipotesi?\nPer affrontare questa questione, iniziamo a calcolare la probabilità \\(P(\\theta &lt; 0.2)\\).\n\nprint(np.mean(theta_draws &lt; 0.2))\n\n0.846125\n\n\nPassiamo ora a calcolare gli odds a posteriori:\n\npost_odds = (np.mean(theta_draws &lt; 0.2)) / (1 - np.mean(theta_draws &lt; 0.2))\nprint(post_odds)\n\n5.498781478472787\n\n\nCiò implica che la probabilità che \\(\\pi\\) sia inferiore al 20% è circa 6 volte superiore rispetto alla probabilità che sia al di sopra del 20%.\nQuesto risultato si basa solo sulle informazioni relative alla distribuzione a posteriori. Prima di avere osservato i dati del campione, avevamo una distribuzione a priori \\(\\operatorname{Beta}(6, 4)\\), e in quel contesto avevamo una probabilità del 9% che \\(H_a\\) fosse vera e una probabilità del 91% che fosse falsa.\n\nthreshold = 0.2\nprior_prob = stats.beta.cdf(threshold, a=4, b=6)\n\n\nprior_odds = prior_prob / (1 - prior_prob)\nprint(prior_odds)\n\n0.09366320688790145\n\n\nOra possiamo combinare le informazioni degli odds a posteriori e degli odds a priori in una quantità chiamata Bayes Factor, che è semplicemente il rapporto tra le due:\n\nBF = post_odds / prior_odds\nprint(BF)\n\n58.70802058970575\n\n\nIn conclusione, dopo aver appreso informazioni riguardo a 14 artisti appartenenti alla generazione X, le probabilità posteriori della nostra ipotesi \\(H_a: \\; \\pi &lt; 0.2\\) sono circa 60 volte superiori rispetto alle probabilità a priori.\nQuesto è un esempio di test di ipotesi bayesiano.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#commenti-e-considerazioni-finali",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "54.9 Commenti e considerazioni finali",
    "text": "54.9 Commenti e considerazioni finali\nLa crescente popolarità dei metodi bayesiani in psicologia e nelle scienze sociali è stata fortemente influenzata dalla (ri)scoperta di algoritmi numerici capaci di stimare le distribuzioni a posteriori dei parametri del modello a partire dai dati osservati. Prima di questi sviluppi, ottenere misure riassuntive delle distribuzioni a posteriori, soprattutto per modelli complessi con molti parametri, era praticamente impossibile.\nQuesto capitolo fornisce un’introduzione a cmdstanpy, un’implementazione in Python di cmdstan, che permette di compilare ed eseguire modelli probabilistici espressi in linguaggio Stan. Grazie a questa tecnologia, è possibile generare una stima della distribuzione a posteriori attraverso il campionamento Markov Chain Monte Carlo (MCMC), rivoluzionando la capacità di effettuare inferenze bayesiane e rendendo l’analisi di modelli complessi più accessibile e gestibile.\nInoltre, nel capitolo sono state presentate diverse strategie per la trasformazione della distribuzione a posteriori e sono state esplorate modalità per ottenere intervalli di credibilità. Successivamente, è stata discussa l’analisi delle ipotesi a posteriori, che consente di confrontare due ipotesi contrapposte riguardanti il parametro \\(\\theta\\). In alcune situazioni, questo confronto viene tradotto in una misura denominata Fattore di Bayes.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/04_stan_summary_posterior.html#informazioni-sullambiente-di-sviluppo",
    "title": "54  Metodi di sintesi della distribuzione a posteriori",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Mon Jun 10 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.13.1\npandas    : 2.2.2\nnumpy     : 1.26.4\nlogging   : 0.5.1.2\nmatplotlib: 3.8.4\ncmdstanpy : 1.2.3\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n# Stampa la versione di CmdStan\nprint(\"CmdStan version:\", cmdstanpy.utils.cmdstan_version())\n\nCmdStan version: (2, 35)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Metodi di sintesi della distribuzione a posteriori</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html",
    "href": "chapters/mcmc/05_stan_diagnostics.html",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "",
    "text": "Introduzione\nLe catene di Markov sono utilizzate per approssimare la distribuzione a posteriori. Tuttavia, è fondamentale riconoscere che tale approssimazione è soggetta a errori e imperfezioni. Schoot et al. (2020) propongono una When-to-Worry- and-How-to-Avoid-the-Misuse-of-Bayesian-Statistics (WAMBS) checklist.\nLa diagnostica delle catene Markoviane, quindi, si configura come un insieme di pratiche e strumenti mirati a indagare vari aspetti della convergenza. Questi includono l’accuratezza dell’approssimazione della distribuzione a posteriori, l’efficienza del campionamento e l’esplorazione esaustiva dello spazio dei parametri. Tali strumenti diagnostici possono essere sia grafici che numerici e dovrebbero essere applicati in un contesto olistico per fornire una panoramica completa della qualità della catena di Markov.\nNon esiste un’unica metrica o diagnostico che possa fornire un quadro completo; piuttosto, è l’analisi combinata di più metriche e diagnostici che permette di acquisire una comprensione più profonda del comportamento della catena. Inoltre, l’esperienza del ricercatore gioca un ruolo significativo nel distinguere tra una “buona” e una “cattiva” catena di Markov e nel suggerire strategie per migliorare la qualità del campionamento.\nIn sintesi, l’analisi della convergenza e la diagnostica delle catene Markoviane sono fasi imprescindibili nel processo di inferenza bayesiana, soprattutto quando si utilizzano metodi MCMC. La loro applicazione consente di garantire che le stime a posteriori siano tanto accurate e affidabili quanto possibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#grafici-di-tracciamento",
    "href": "chapters/mcmc/05_stan_diagnostics.html#grafici-di-tracciamento",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.1 Grafici di Tracciamento",
    "text": "55.1 Grafici di Tracciamento\nUn metodo diagnostico comunemente utilizzato per valutare la convergenza nei metodi di Monte Carlo basati su catene di Markov (MCMC) è l’analisi dei grafici di tracciamento, o “trace plots”. Questi grafici rappresentano sequenzialmente le stime dei parametri posteriori ottenute ad ogni iterazione della catena. In generale, si tende a interpretare che un parametro sta convergendo quando le stime campionarie si aggregano in una banda orizzontale ristretta lungo l’asse delle iterazioni che compongono la catena. Tuttavia, considerare questa disposizione come prova conclusiva di convergenza è piuttosto grossolano, in quanto una traccia compatta non garantisce che la convergenza sia stata effettivamente raggiunta. Di fatto, questa metodologia risulta essere più un indicatore di non-convergenza. Ad esempio, se due catene per lo stesso parametro sono campionate da regioni diverse della distribuzione target e le stime rimangono separate lungo la storia della catena, ciò costituisce un’evidenza di non-convergenza. Allo stesso modo, se il grafico mostra fluttuazioni significative o salti nella catena, è probabile che la catena associata a quel parametro non abbia raggiunto la convergenza.\nUn trace plot ideale presenta una dispersione casuale dei valori attorno a un livello medio stabile, indicando una buona miscelazione delle catene e un’adeguata configurazione del processo MCMC. Questo pattern suggerisce che l’algoritmo è assestato su una distribuzione stabile e le inferenze tratte dai dati campionati sono affidabili.\nApprofondendo con l’esempio di Martin et al. (2022), è possibile osservare diversi esempi di trace plots per catene MCMC. Questi esempi illustrano sia scenari in cui il comportamento è ottimale, segnalando una convergenza adeguata, sia casi in cui le catene mostrano segni di problemi di convergenza o di miscelazione. Tali situazioni indicano la necessità di un’ulteriore affinazione dei parametri dell’algoritmo MCMC per garantire l’affidabilità delle stime statistiche ottenute.\n\ngood_chains = stats.beta.rvs(2, 5, size=(2, 2000))\nbad_chains0 = np.random.normal(\n    np.sort(good_chains, axis=None), 0.05, size=4000\n).reshape(2, -1)\n\nbad_chains1 = good_chains.copy()\nfor i in np.random.randint(1900, size=4):\n    bad_chains1[i % 2 :, i : i + 100] = np.random.beta(i, 950, size=100)\n\nchains = {\n    \"good_chains\": good_chains,\n    \"bad_chains0\": bad_chains0,\n    \"bad_chains1\": bad_chains1,\n}\n\n\naz.plot_trace(chains)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/2425599176.py:2: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nLe cattive catene non convergono né si mescolano tra loro. Uno dei motivi per l’esecuzione di più catene è che ogni singola catena potrebbe convergere verso un target, mentre un’altra catena potrebbe convergere su un target diverso, e questo sarebbe un problema. Inoltre, catene altrimenti sane possono bloccarsi occasionalmente nel corso della serie, il che suggerirebbe la necessità di modifiche al modello o alle impostazioni del campionatore. Un altro modo per valutare la convergenza dell’algoritmo è plottando la densità della distribuzione a posteriori degli effetti stimati, per assicurarsi che si avvicini ad una classica curva a campana.\nIn pratica, non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perché la diagnostica delle catene di Markov è così importante: se vediamo trace-plots come le precedenti “bad chains”, sappiamo che non abbiamo ottenuto una approssimazione adeguata della distribuzione a posteriori. In tali circostanze possiamo ricorrere ad alcuni rimedi.\n\nControllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati?\nUtilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#i-grafici-della-densità-posteriore-sono-adeguati",
    "href": "chapters/mcmc/05_stan_diagnostics.html#i-grafici-della-densità-posteriore-sono-adeguati",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.2 I Grafici della Densità Posteriore Sono Adeguati?",
    "text": "55.2 I Grafici della Densità Posteriore Sono Adeguati?\nI grafici della densità posteriore rappresentano uno degli strumenti diagnostici più efficaci per identificare eventuali anomalie nella convergenza delle catene di Markov nell’analisi bayesiana. Questi grafici mostrano la distribuzione dei valori campionati per ogni parametro del modello statistico e per ogni catena di Markov. L’importanza di questi grafici è primaria: essi sono la base da cui deriviamo le statistiche riassuntive dei parametri del modello, quali la media, la mediana, o l’intervallo di credibilità.\nPrendiamo come esempio un parametro di interesse in un modello di regressione che assume una distribuzione a priori gaussiana (normale). In un contesto ideale, senza problemi di convergenza, ci aspetteremmo che la densità posteriore del parametro sia anch’essa normalmente distribuita, centrata intorno a una media con una certa varianza. Questo andamento simmetrico e unimodale della densità posteriore è un segnale che la catena di Markov ha esplorato adeguatamente lo spazio dei parametri e che i campioni estratti possono essere considerati rappresentativi della distribuzione posteriore effettiva del parametro.\nTuttavia, se il grafico della densità posteriore mostra deviazioni significative dalla forma attesa, come ad esempio asimmetrie marcate o bimodalità, questo suggerisce che potrebbero esserci problemi nella convergenza della catena al vero valore del parametro. Una distribuzione bimodale, in particolare, può indicare che la catena è rimasta “intrappolata” in aree locali dello spazio dei parametri, senza riuscire a esplorare adeguatamente l’intero spazio e raggiungere l’equilibrio.\nPer risolvere tali problemi e ottenere una stima più accurata della distribuzione posteriore, potremmo considerare diverse strategie:\n\nAumentare il Numero di Iterazioni: Incrementare il numero delle iterazioni delle catene di Markov può permettere una migliore esplorazione dello spazio dei parametri e aiutare a superare le barriere tra i picchi di una distribuzione bimodale.\nOttimizzazione delle Distribuzioni a Priori: La scelta delle distribuzioni a priori può influenzare fortemente la convergenza della catena. Selezionare priori più informativi o più flessibili può aiutare la catena a guidare l’esplorazione dello spazio dei parametri in modo più efficace.\nAffinamento dei Parametri dell’Algoritmo MCMC: Modificare i parametri di configurazione dell’algoritmo MCMC, come il passo del campionamento o i criteri di accettazione, può migliorare la qualità del campionamento e favorire una convergenza più rapida e stabile.\n\nIn definitiva, l’analisi dei grafici della densità posteriore non solo fornisce una stima visiva dell’andamento dei parametri, ma serve anche come fondamento per decisioni metodologiche che possono migliorare la robustezza e l’affidabilità delle inferenze bayesiane.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#lautocorrelazione-nelle-catene-di-markov-monte-carlo-è-troppo-alta",
    "href": "chapters/mcmc/05_stan_diagnostics.html#lautocorrelazione-nelle-catene-di-markov-monte-carlo-è-troppo-alta",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.3 L’Autocorrelazione nelle Catene di Markov Monte Carlo È Troppo Alta?",
    "text": "55.3 L’Autocorrelazione nelle Catene di Markov Monte Carlo È Troppo Alta?\nNell’ambito dell’analisi bayesiana tramite le catene di Markov Monte Carlo (MCMC), è di fondamentale importanza valutare la rapidità con cui i campioni estratti dalla distribuzione a posteriori raggiungono l’indipendenza. Inizialmente, come è noto, i campioni della distribuzione a posteriori non sono indipendenti l’uno dall’altro, ma ci si aspetta che, nel tempo, la catena “dimentichi” il suo stato iniziale e converga verso un insieme di estrazioni indipendenti e stazionarie dalla distribuzione a posteriori.\nUna metodologia per determinare la velocità con cui la catena si allontana dallo stato iniziale è l’analisi della funzione di autocorrelazione (ACF), che si basa sull’osservazione che un campione \\(\\theta^{(s)}\\) tende a essere più simile al campione immediatamente precedente \\(\\theta^{(s-1)}\\) rispetto a quelli più distanti come \\(\\theta^{(s-2)}\\), \\(\\theta^{(s-3)}\\), e così via. La correlazione di lag-l per una catena stazionaria di Markov, dove \\(s = 1, \\ldots, S\\), può essere espressa come:\n\\[\n\\rho_l = \\text{cor}(\\theta^{(s)}, \\theta^{(s+l)}).\n\\]\nIn generale, ci aspettiamo che l’autocorrelazione a lag-1 sia vicina a 1, ma che diminuisca man mano che il lag aumenta, indicando che i componenti della catena stanno diventando indipendenti. Una riduzione rapida dell’autocorrelazione con il numero di iterazioni è preferibile, poiché una lenta diminuzione può suggerire che la catena sia “intrappolata” e non esplori completamente il supporto della distribuzione target.\nIl correlogramma, che mostra l’autocorrelazione in funzione dei ritardi fino a un certo valore (ad esempio 20), è utile per valutare questa caratteristica. Se l’autocorrelazione a lag 1 non è eccessivamente alta e diminuisce rapidamente con l’incremento dei lag, ciò indica che la catena sta fornendo una buona approssimazione di un campionamento casuale dalla distribuzione \\(p(\\theta \\mid y)\\).\nCatene che mostrano un rapido “mixing” si comportano in modo simile a un campione indipendente: i valori si concentrano nei range più plausibili della distribuzione a posteriori e l’autocorrelazione tra i campioni diminuisce rapidamente, risultando in un rapporto campionario effettivo alto. Al contrario, catene che non sono rapidamente “mixing” tendono a non concentrarsi nei valori più plausibili, presentano un’autocorrelazione che diminuisce lentamente e un rapporto campionario effettivo basso.\nIn caso di catene non rapidamente “mixing”, si possono adottare due strategie:\n\nAumento del Numero di Iterazioni: Anche una catena lenta nel “mixing” può alla fine fornire una buona approssimazione della distribuzione a posteriori se si permette un numero sufficientemente grande di iterazioni.\nThinning (Diradamento): Questo processo consiste nel selezionare solo alcuni campioni a intervalli regolari, come ogni secondo o ogni decimo valore della catena, con l’obiettivo di ridurre le autocorrelazioni presenti nei lag più brevi.\n\nUn esempio pratico è fornito da Martin et al. (2022).\n\nfig, ax = plt.subplots(3, 1)  \naz.plot_autocorr(chains, combined=True, ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/4208770402.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-dimensione-effettiva-del-campione-è-sufficiente",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-dimensione-effettiva-del-campione-è-sufficiente",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.4 La Dimensione Effettiva del Campione È Sufficiente?",
    "text": "55.4 La Dimensione Effettiva del Campione È Sufficiente?\nNell’ambito delle analisi con catene di Markov Monte Carlo (MCMC), un aspetto strettamente correlato alla diagnosi di autocorrelazione è la dimensione effettiva del campione, indicata con \\(N_{\\text{eff}}\\) nell’output del software Stan. Questa grandezza rappresenta una stima del numero di estrazioni indipendenti dalla distribuzione a posteriori. In altre parole, corrisponde al numero di campioni indipendenti che possiede lo stesso potere di stima di \\(T\\) campioni autocorrelati. Seguendo la notazione di Stan, la \\(N_{\\text{eff}}\\) è calcolata come segue:\n\\[\nN_{\\text{eff}} = \\frac{T}{1 + 2 \\sum_{s=1}^{S} \\rho_{s}},\n\\]\ndove \\(T\\) è il numero totale di campioni e \\(\\rho_{s}\\) rappresenta l’autocorrelazione a lag \\(s\\).\nPoiché i campioni della distribuzione a posteriori non sono indipendenti, ci aspettiamo che la \\(N_{\\text{eff}}\\) sia minore del numero totale di estrazioni. Se il rapporto tra la dimensione effettiva del campione e il numero totale di estrazioni è vicino a 1, ciò indica che l’algoritmo ha raggiunto un campionamento sostanzialmente indipendente. Valori molto inferiori potrebbero essere motivo di preoccupazione poiché indicano una forte dipendenza tra i campioni, ma è importante notare che questo rapporto dipende fortemente dalla scelta dell’algoritmo MCMC, dal numero di iterazioni di “warmup” (o “burn-in”), e dal numero di iterazioni successive al “warmup”.\nUn metodo per affrontare il problema dell’autocorrelazione e del conseguente abbassamento della dimensione effettiva del campione coinvolge l’uso del diradamento (thinning). Supponiamo che l’algoritmo venga impostato per effettuare 3.000 estrazioni dalla distribuzione a posteriori. Questo può essere paragonato a effettuare 30.000 estrazioni ma conservando solo ogni decima. Sebbene questo metodo sia un modo per ridurre il carico sulla memoria, il vantaggio è che tipicamente l’autocorrelazione viene ridotta, risultando in una dimensione effettiva del campione maggiore.\nPer distinguere tra buone e cattive catene MCMC, possiamo utilizzare la statistica \\(N_{\\text{eff}}\\). Un basso valore di \\(N_{\\text{eff}}\\) può indicare una catena con una mescolanza insufficiente, suggerendo la necessità di aumentare il numero di iterazioni o di implementare il diradamento. In contrasto, un valore alto di \\(N_{\\text{eff}}\\) è indice di una catena con una buona mescolanza, che assicura un campionamento efficace dalla distribuzione a posteriori. Esempi pratici di queste considerazioni sono illustrati in Martin et al. (2022), dove la statistica \\(N_{\\text{eff}}\\) è utilizzata per valutare la qualità delle catene MCMC.\n\n_, axes = plt.subplots(2, 3, sharey=True, sharex=True)\naz.plot_ess(chains, kind=\"local\", ax=axes[0])\naz.plot_ess(chains, kind=\"quantile\", ax=axes[1])\n\nfor ax_ in axes[0]:\n    ax_.set_xlabel(\"\")\nfor ax_ in axes[1]:\n    ax_.set_title(\"\")\n\nfor ax_ in axes[:, 1:].ravel():\n    ax_.set_ylabel(\"\")\nplt.ylim(-100, 5000);",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-statistica-hatr-è-prossima-a-uno",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-statistica-hatr-è-prossima-a-uno",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.5 La Statistica \\(\\hat{R}\\) È Prossima a Uno?",
    "text": "55.5 La Statistica \\(\\hat{R}\\) È Prossima a Uno?\nNell’ambito dell’analisi bayesiana, è cruciale assicurarsi che ogni catena di Markov sia stazionaria e che le diverse catene mostrino coerenza tra loro. La statistica \\(\\hat{R}\\), introdotta da Gelman e Rubin nel 1992, serve proprio a valutare il grado di convergenza tra più catene per ciascun parametro in esame. Questo indicatore si basa sul confronto tra due tipi di varianza: la varianza media all’interno di ogni singola catena (W) e la varianza tra le diverse catene (B). Questo metodo ricorda l’approccio dell’analisi della varianza unidirezionale, in cui si confrontano stime di varianza per determinare se esistono differenze significative, in questo caso tra le catene.\nLa formula per calcolare \\(\\hat{R}\\) è \\(\\hat{R} = \\frac{W + \\frac{1}{n} (B - W)}{W}\\), e tale metrica viene calcolata automaticamente dalla maggior parte dei software Bayesiani, come indicato da Gelman e collaboratori nel 2014. Nel contesto pratico, un valore di \\(\\hat{R}\\) superiore a 1.1 è generalmente considerato un segnale di convergenza inadeguata delle catene. Inoltre, è fondamentale esaminare visivamente la convergenza delle catene attraverso il confronto delle distribuzioni posteriori di ciascun parametro per ogni catena. In condizioni ideali, \\(\\hat{R}\\) dovrebbe essere pari a 1. Se \\(\\hat{R}\\) si discosta notevolmente da questo valore, ciò indica che la convergenza non è stata ancora raggiunta.\nPiù specificamente, un valore di \\(\\hat{R}\\) maggiore di 1.01, secondo Vehtari et al. (2021), segnala una mancanza di coerenza nelle approssimazioni della distribuzione a posteriori ottenute dalle diverse catene parallele. Un valore così elevato di \\(\\hat{R}\\) suggerisce una simulazione non stabile, indicando la necessità di ulteriori iterazioni o di un raffinamento del modello per garantire una convergenza affidabile. Questo aspetto è fondamentale per assicurare che le simulazioni Monte Carlo basate su catene di Markov (MCMC) forniscano risultati consistenti e attendibili per l’analisi statistica in corso.\n\naz.rhat(chains)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:      ()\nData variables:\n    bad_chains0  float64 8B 2.43\n    bad_chains1  float64 8B 1.018\n    good_chains  float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)bad_chains0()float642.43array(2.42962207)bad_chains1()float641.018array(1.01782964)good_chains()float641.001array(1.00080843)Indexes: (0)Attributes: (0)\n\n\nNell’esempio di Martin et al. (2022) vediamo come \\(\\hat{R}\\) è in grado di distinguere tra le buone e le cattive catene MCMC. Mentre bad_chains0 ha valori \\(\\hat{R}\\) totalmente inadeguati, bad_chains1 tende ad avere valori accettabili e good_chains ha un valore \\(\\hat{R}\\) praticamente uguale a 1.0.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-diagnostica-di-geweke-è-prossima-a-zero",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-diagnostica-di-geweke-è-prossima-a-zero",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.6 La Diagnostica di Geweke È Prossima a Zero?",
    "text": "55.6 La Diagnostica di Geweke È Prossima a Zero?\nLa statistica diagnostica di convergenza di Geweke è basata su un test per l’uguaglianza delle medie della prima e dell’ultima parte di una catena di Markov (di default il primo 10% e l’ultimo 50% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.\nInterpretazione: la statistica di Geweke è uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali; valori maggiori di \\(\\mid 2 \\mid\\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#lerrore-standard-di-monte-carlo-è-piccolo",
    "href": "chapters/mcmc/05_stan_diagnostics.html#lerrore-standard-di-monte-carlo-è-piccolo",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.7 L’Errore Standard di Monte Carlo È Piccolo?",
    "text": "55.7 L’Errore Standard di Monte Carlo È Piccolo?\nQuando utilizziamo i metodi MCMC introduciamo un ulteriore livello di incertezza poiché stiamo approssimando il posteriore con un numero finito di campioni. Possiamo stimare la quantità di questo tipo di errore mediante la statistica errore standard di Monte Carlo (MCSE). Il MCSE è definitp come la deviazione standard delle catene MCMC divisa per la loro numerosità campionaria effettiva (ESS). Il MCSE ci fornisce dunque un’indicazione quantitativa di quanto è grande sia il “rumore” della stima.\nPer l’esempio di Martin et al. (2022) otteniamo i valori seguenti.\n\naz.mcse(chains)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:      ()\nData variables:\n    bad_chains0  float64 8B 0.1087\n    bad_chains1  float64 8B 0.01616\n    good_chains  float64 8B 0.002583xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)bad_chains0()float640.1087array(0.10870935)bad_chains1()float640.01616array(0.01615769)good_chains()float640.002583array(0.00258312)Indexes: (0)Attributes: (0)\n\n\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 9))  \naz.plot_mcse(chains, ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/1242931680.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#i-grafici-di-rango-sono-piatti",
    "href": "chapters/mcmc/05_stan_diagnostics.html#i-grafici-di-rango-sono-piatti",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.8 I Grafici di Rango Sono Piatti?",
    "text": "55.8 I Grafici di Rango Sono Piatti?\nIn alcune situazioni, l’interpretazione dei grafici di traccia può risultare estremamente complessa. Ad esempio, quando si raccolgono un numero molto elevato di campioni, comprimere lunghe tracce in un grafico di dimensioni standard può occultare alcuni comportamenti problematici delle catene, facendo apparire erroneamente buone le tracce. Giudicare i grafici di traccia può essere difficile anche quando le distribuzioni sono fortemente asimmetriche e/o a code pesanti. Per queste ragioni, ora si raccomanda di utilizzare i grafici di rango oltre, se non al posto, dei grafici di traccia, in modo che qualsiasi differenza nei valori campionati da ogni catena possa essere riconosciuta in un modo più affidabile (Vehtari et al., 2021).\nIn statistica, il “rango” di un’osservazione è la sua posizione in un insieme di dati ordinati. Ad esempio, consideriamo il seguente insieme di dati: [5, 3, 8, 10]. Se ordiniamo questi dati in ordine crescente otterremo [3, 5, 8, 10]. In questo caso, il rango del numero 5 è 2 perché è il secondo numero nell’insieme ordinato. Allo stesso modo, il rango del numero 10 è 4 perché è il quarto numero nell’insieme ordinato.\nI grafici di rango rappresentano un nuovo strumento diagnostico che si ottiene ordinando i campioni aggregati da tutte le catene, e poi presentando un istogramma dei ranghi derivanti da ogni catena separatamente. Se tutte le catene hanno come target la stessa distribuzione, allora la distribuzione dei ranghi per ogni catena dovrebbe approssimare una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ciò indica una buon mixing delle catene. Le deviazioni dall’uniformità possono indicare una vasta gamma di problemi di convergenza. Qui sotto è riportato l’esempio fornito da Martin et al. (2022):\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 8))  \naz.plot_rank(chains, kind=\"bars\", ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_95156/2441558539.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa (con dei segmenti verticali al posto delle barre) è la seguente:\n\nfig, ax = plt.subplots(3, 1, figsize=(7, 8))  \naz.plot_rank(chains, kind=\"vlines\", ax=ax)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_24737/353816278.py:3: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#ci-sono-transizioni-divergenti",
    "href": "chapters/mcmc/05_stan_diagnostics.html#ci-sono-transizioni-divergenti",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.9 Ci Sono Transizioni Divergenti?",
    "text": "55.9 Ci Sono Transizioni Divergenti?\nQuando usiamo l’algoritmo di campionamento Hamiltonian Monte Carlo (HMC), è molto importante assicurarci che non ci siano “transizioni divergenti” riportate nei risultati. Idealmente, il numero di queste transizioni dovrebbe essere zero. Una transizione divergente è come un segnale di allarme che ci avverte di possibili problemi nella fase in cui l’algoritmo esplora i vari parametri. In pratica, indica che l’algoritmo non è riuscito a esaminare correttamente alcune aree dello spazio dei parametri.\nOgni volta che notiamo una transizione divergente, dobbiamo indagare attentamente il motivo. La presenza di queste transizioni ci dice che l’algoritmo potrebbe non avere esplorato adeguatamente certe zone, mettendo a rischio l’affidabilità delle conclusioni del nostro studio. In presenza di divergenze, i campioni risultanti non possono essere considerati affidabili e, pertanto, non dovrebbero essere impiegati per la stima dei parametri, il confronto tra modelli, o qualsiasi altra forma di inferenza statistica Gelman et al. (2020).\nPer capire e risolvere il problema delle transizioni divergenti, possiamo considerare diverse soluzioni:\n\nControllo dei dati: È utile controllare se ci sono dati anormali o estremi che potrebbero complicare il lavoro dell’algoritmo.\nValutazione delle distribuzioni a priori: Dobbiamo assicurarci che le distribuzioni a priori usate si adattino bene al modello e ai dati che stiamo analizzando. Se non sono appropriate, possono creare problemi durante l’esplorazione dello spazio dei parametri.\nRegolazione della dimensione del passo: È importante controllare e, se necessario, modificare la dimensione del passo (o step size) dell’algoritmo HMC. Un passo troppo lungo o troppo breve può causare instabilità e favorire l’occorrenza di transizioni divergenti.\n\nAffrontando questi problemi con attenzione, possiamo migliorare la performance dell’algoritmo HMC e ridurre il rischio di incontrare transizioni divergenti. Risolvere questi problemi è fondamentale per assicurare che l’algoritmo fornisca una rappresentazione precisa della distribuzione a posteriori e per garantire inferenze statistiche corrette.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-bmfi-è-sufficientemente-grande",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-bmfi-è-sufficientemente-grande",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.10 LA BMFI È Sufficientemente Grande?",
    "text": "55.10 LA BMFI È Sufficientemente Grande?\nUn altro strumento diagnostico che è stato recentemente sviluppato per il campionamento HMC/NUTS si chiama Bayesian Fraction of Missing Information (BFMI), calcolato in modo bayesiano. Questo indicatore si basa sull’analisi delle variazioni di energia durante ciascuna iterazione del campionamento nelle catene. Esso ci permette di capire con maggiore precisione quanto bene l’algoritmo HMC/NUTS sta funzionando a un livello più dettagliato rispetto ad altre tecniche di diagnostica.\nUn valore basso di BFMI in una catena specifica indica che l’algoritmo non sta esplorando efficacemente la distribuzione dei dati che stiamo analizzando, il che può portare a risultati distorti o fuorvianti. È generalmente accettato che il valore di BFMI debba essere almeno 0.2 per ogni catena. Se in una o più catene il valore scende al di sotto di 0.2, si considera che i risultati ottenuti non siano affidabili per fare inferenze corrette, poiché le stime prodotte potrebbero essere distorte (Betancourt, 2016).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#la-leave-one-out-cross-validation-fornisce-evidenze-di-buon-adattamento",
    "href": "chapters/mcmc/05_stan_diagnostics.html#la-leave-one-out-cross-validation-fornisce-evidenze-di-buon-adattamento",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.11 La Leave-One-Out Cross-Validation Fornisce Evidenze di Buon Adattamento?",
    "text": "55.11 La Leave-One-Out Cross-Validation Fornisce Evidenze di Buon Adattamento?\nLa Leave-One-Out Cross-Validation (LOO) rappresenta un metodo ampiamente impiegato nell’ambito dell’analisi bayesiana per valutare quanto adeguatamente un modello statistico si adatta ai dati osservati. Immaginiamo di avere una serie di foto e di voler valutare quanto bene un software riesce a riconoscere le persone in queste foto. La LOO ci aiuta a testare il software in un modo accurato.\nIl processo è semplice: prendiamo tutte le foto tranne una, e usiamo queste per insegnare al software come riconoscere le persone. Poi, usiamo la foto che abbiamo messo da parte per vedere se il software riesce a riconoscere la persona in quella foto. Ripetiamo questo processo per ogni singola foto, una alla volta. Ogni volta, il software apprende da tutte le foto tranne una, e quella esclusa serve per testarlo.\nQuesto metodo è molto efficace perché assicura che il software non impari solo a riconoscere le persone nelle foto specifiche che ha già visto (questo si chiama “overfitting”, ovvero sovraadattamento), ma che sia davvero capace di riconoscere persone anche in foto nuove che non ha mai analizzato. Inoltre, evita il problema opposto, chiamato “underfitting”, dove il software non impara abbastanza dai dati e quindi non riesce a fare buone previsioni.\nNel contesto dell’analisi bayesiana, dove si utilizzano modelli statistici complessi, la LOO è spesso accompagnata da calcoli come il logaritmo della verosimiglianza, che aiutano a quantificare quanto bene il modello riesce a prevedere i dati esclusi. I risultati di questi calcoli possono essere usati per calcolare un indice chiamato LOOIC (Leave-One-Out Information Criterion), che permette di confrontare diversi modelli per scegliere quello che si adatta meglio ai dati.\nIn conclusione, la LOO è uno strumento molto utile per valutare in modo imparziale e preciso quanto bene un modello statistico possa prevedere nuovi dati, garantendo che le nostre previsioni siano il più accurate possibile.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#il-parametro-k",
    "href": "chapters/mcmc/05_stan_diagnostics.html#il-parametro-k",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "55.12 Il Parametro \\(k\\)",
    "text": "55.12 Il Parametro \\(k\\)\nIl parametro \\(k\\), noto anche come parametro di coda di Pareto, riveste un ruolo importante nell’ambito del campionamento MCMC. È utilizzato per valutare l’efficienza e la convergenza delle catene di campionamento, nonché per misurare la qualità del processo di campionamento di importanza, come nel caso del Pareto Smoothed Importance Sampling (PSIS).\nImmaginiamo di essere a una festa dove stai cercando di scoprire quale gusto di gelato è il preferito tra gli invitati. Invece di chiedere a tutti, decidiamo di assaggiare solo alcuni gelati per avere un’idea generale. Questo processo di selezionare solo alcuni gelati per fare un’assunzione sul gusto preferito è simile a quello che avviene nel campionamento per l’Importance Sampling: scegliamo solo alcuni punti (o “campioni”) da un insieme molto grande per fare delle stime su tutta la popolazione.\nNel Pareto Smoothed Importance Sampling (PSIS), dopo aver scelto i campioni, cerchiamo di “lisciare” le nostre stime per renderle più precise e meno variabili. Pensalo come se stessi cercando di bilanciare le risposte per non dare troppo peso a poche opinioni estreme.\nIl parametro \\(k\\) ci dice quanto siamo vicini a raggiungere questo obiettivo di bilanciamento. Se \\(k\\) è vicino a 0, significa che abbiamo fatto un buon lavoro: le nostre stime sono affidabili e non troppo dipendenti da pochi campioni estremi. Se, invece, \\(k\\) è più alto, specialmente sopra 0.7, ci indica che ci sono problemi: forse abbiamo dato troppo peso a poche opinioni estreme, o non abbiamo un buon mix di opinioni per fare una stima affidabile. In pratica, un \\(k\\) alto è come un campanello d’allarme che ci dice che dobbiamo essere cauti con le nostre conclusioni e, possibilmente, raccogliere più dati o ripensare come li stiamo campionando.\nIn sostanza, il parametro \\(k\\) è uno strumento per aiutarci a capire quanto possiamo fidarci delle nostre stime basate su un campione limitato di dati. Un valore basso è buono, indicando che le stime sono solide e ben equilibrate, mentre un valore alto suggerisce che potremmo avere dei problemi e che dovremmo esaminare più attentamente i dati che abbiamo raccolto.\nPer calcolare il parametro \\(\\hat{\\kappa}\\), è possibile fare uso di ArviZ, uno strumento appositamente progettato per le analisi bayesiane avanzate.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/05_stan_diagnostics.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/05_stan_diagnostics.html#informazioni-sullambiente-di-sviluppo",
    "title": "55  Diagnostica delle catene markoviane",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jun 10 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.4\nlogging   : 0.5.1.2\ncmdstanpy : 1.2.3\nscipy     : 1.13.1\narviz     : 0.18.0\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBetancourt, M. (2016). Diagnosing suboptimal cotangent disintegrations in Hamiltonian Monte Carlo. arXiv preprint arXiv:1604.00695.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian Modeling and Computation in Python. CRC Press.\n\n\nSchoot, V. R. de, Veen, D., Smeets, L., & Winter, S. (2020). A tutorial on using the WAMBS checklist to avoid the misuse of Bayesian statistics (pp. 30–49). Routledge.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., & Bürkner, P.-C. (2021). Rank-normalization, folding, and localization: An improved R ̂ for assessing convergence of MCMC (with discussion). Bayesian analysis, 16(2), 667–718.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Diagnostica delle catene markoviane</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_prediction.html",
    "href": "chapters/mcmc/06_stan_prediction.html",
    "title": "56  La predizione bayesiana",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esamineremo in dettaglio le distribuzioni predittive a priori e a posteriori. La distribuzione predittiva a priori rappresenta le aspettative sui dati prima di qualsiasi osservazione reale, riflettendo le conoscenze preesistenti e le ipotesi sui parametri del modello. Essa fornisce un’indicazione delle caratteristiche che i dati potrebbero assumere in base al modello. Confrontare queste previsioni con i dati effettivamente osservati consente di valutare la validità delle ipotesi incorporate nel modello.\nLa distribuzione predittiva è spesso di maggiore interesse rispetto alla distribuzione a posteriori. Mentre la distribuzione a posteriori descrive l’incertezza sui parametri (ad esempio, la proporzione di palline rosse in un’urna), la distribuzione predittiva descrive anche l’incertezza sugli eventi futuri (ad esempio, il colore della pallina che verrà estratta in futuro). Questa differenza è cruciale, soprattutto quando si tratta di prevedere gli effetti di un intervento, come la somministrazione di un trattamento a un paziente.\nLa distribuzione predittiva a posteriori è inoltre fondamentale per valutare quanto le previsioni del modello siano coerenti con i dati osservati. Se le previsioni del modello risultano allineate con i dati raccolti, il modello può essere considerato accurato nel rappresentare il processo generativo sottostante. Questo confronto è essenziale per convalidare il modello e assicurarsi che le ipotesi riflettano adeguatamente la realtà osservata.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_prediction.html#sec-posterior-predictive-distribution",
    "href": "chapters/mcmc/06_stan_prediction.html#sec-posterior-predictive-distribution",
    "title": "56  La predizione bayesiana",
    "section": "56.1 La distribuzione predittiva a posteriori",
    "text": "56.1 La distribuzione predittiva a posteriori\nLa distribuzione predittiva a posteriori offre una valutazione critica della coerenza tra i dati reali e quelli simulati dal modello (Gelman & Shalizi, 2013). Confrontando direttamente i dati osservati con quelli generati dal modello, essa permette di identificare eventuali discrepanze che potrebbero segnalare problemi nella specificazione del modello. In pratica, la PPC (Posterior Predictive Check) funge da test diagnostico, consentendo di rilevare e correggere eventuali carenze nel modello, migliorandone così le capacità predittive.\nPer comprendere meglio il concetto, consideriamo la distribuzione predittiva a posteriori in termini di un modello coniugato normale-normale. Supponiamo di voler predire la media di una distribuzione normale futura, basandoci sui dati osservati e sulle nostre conoscenze a priori. La PPD ci offre uno strumento per calcolare queste probabilità, combinando le informazioni provenienti dai dati osservati con quelle fornite dalla distribuzione a priori.\nAd esempio, immaginiamo di aver raccolto dati sulle altezze di 100 persone, ottenendo una media campionaria di 170 cm e una deviazione standard campionaria di 10 cm. Il nostro obiettivo è stimare la media delle altezze in un futuro campione di \\(n=100\\) persone. La nostra conoscenza a priori sulla media delle altezze è rappresentata da una distribuzione normale con media 175 cm e deviazione standard di 5 cm.\nIn termini di notazione, possiamo esprimere questa distribuzione come \\(P(\\tilde{y}|\\theta=\\theta_1)\\), dove \\(\\tilde{y}\\) rappresenta un nuovo dato che è diverso dai dati attuali \\(y\\), e \\(\\theta_1\\) è la media a posteriori. Tuttavia, in statistica bayesiana, è fondamentale incorporare tutta l’incertezza nei risultati. Poiché \\(\\theta_1\\) è solo uno dei possibili valori per \\(\\theta\\), dovremmo includere ogni valore di \\(\\theta\\) per la nostra previsione. Per ottenere la migliore previsione, possiamo “mediare” le previsioni attraverso i diversi valori di \\(\\theta\\), ponderando ciascun valore secondo la sua probabilità a posteriori.\nLa distribuzione risultante è la distribuzione predittiva a posteriori, che in notazione matematica è data da:\n\\[ P(\\tilde{y}|y) = \\int_\\theta p(\\tilde{y}|\\theta, y) p(\\theta|y) d\\theta. \\]\nIn questo modo, la distribuzione predittiva a posteriori combina le informazioni dai dati osservati con la conoscenza a priori, fornendo una previsione che riflette l’incertezza associata a tutti i possibili valori dei parametri del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "href": "chapters/mcmc/06_stan_prediction.html#distribuzione-predittiva-a-posteriori-nel-modello-normale-normale",
    "title": "56  La predizione bayesiana",
    "section": "56.2 Distribuzione predittiva a posteriori nel modello normale-normale",
    "text": "56.2 Distribuzione predittiva a posteriori nel modello normale-normale\nNel modello coniugato normale-normale, se i dati osservati \\(Y = \\{y_1, y_2, ..., y_n\\}\\) sono modellati come provenienti da una distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\), e assumendo una distribuzione a priori normale per \\(\\mu\\), la distribuzione a posteriori di \\(\\mu\\) sarà anch’essa normale.\n\n56.2.1 Formule della distribuzione predittiva a posteriori\nDato che:\n\nI dati osservati \\(y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nLa prior per \\(\\mu\\) è \\(\\mu \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)\\)\n\nLa distribuzione a posteriori per \\(\\mu\\) sarà:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)\n\\]\ndove:\n\\[\n\\mu_n = \\frac{\\tau_0^2 \\bar{y} + \\sigma^2 \\mu_0}{\\tau_0^2 + \\sigma^2}\n\\]\ne\n\\[\n\\tau_n^2 = \\frac{\\tau_0^2 \\sigma^2}{\\tau_0^2 + \\sigma^2}\n\\]\nQui, \\(\\bar{y}\\) è la media campionaria dei dati osservati.\n\nEsempio 56.1 Consideriamo che:\n\n\\(\\mu_0 = 175\\) cm (media a priori)\n\\(\\tau_0 = 5\\) cm (deviazione standard a priori)\n\\(\\bar{y} = 170\\) cm (media campionaria)\n\\(\\sigma = 10\\) cm (deviazione standard campionaria)\n\\(n = 100\\) (numero di osservazioni)\n\nI parametri della distribuzione a posteriori sono:\n\\[\n\\mu_n = \\frac{(5^2 \\cdot 170) + (10^2 \\cdot 175)}{5^2 + 10^2} = \\frac{42500 + 175000}{25 + 100} = \\frac{217500}{125} = 174 \\quad \\text{cm}\n\\]\n\\[\n\\tau_n^2 = \\frac{5^2 \\cdot 10^2}{5^2 + 10^2} = \\frac{2500}{125} = 20 \\quad \\text{cm}^2 \\Rightarrow \\tau_n = \\sqrt{20} \\approx 4.47 \\quad \\text{cm}\n\\]\nPertanto, la distribuzione a posteriori per \\(\\mu\\) è:\n\\[\n\\mu \\mid Y \\sim \\mathcal{N}(174, 4.47^2)\n\\]\nPer la distribuzione predittiva a posteriori, dobbiamo considerare anche la varianza della distribuzione futura. Se stiamo predicendo per \\(n_{\\text{fut}}=100\\) nuove osservazioni, la varianza della media predittiva sarà:\n\\[\n\\sigma_{\\text{pred}}^2 = \\tau_n^2 + \\frac{\\sigma^2}{n_{\\text{fut}}}\n\\]\n\\[\n\\sigma_{\\text{pred}}^2 = 20 + \\frac{10^2}{100} = 20 + 1 = 21 \\quad \\text{cm}^2 \\Rightarrow \\sigma_{\\text{pred}} = \\sqrt{21} \\approx 4.58 \\quad \\text{cm}\n\\]\nQuindi, la distribuzione predittiva a posteriori è:\n\\[\n\\tilde{Y} \\sim \\mathcal{N}(174, 4.58^2)\n\\]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_prediction.html#implementazione-con-cmdstanpy",
    "href": "chapters/mcmc/06_stan_prediction.html#implementazione-con-cmdstanpy",
    "title": "56  La predizione bayesiana",
    "section": "56.3 Implementazione con cmdstanpy",
    "text": "56.3 Implementazione con cmdstanpy\nPer illustrare come viene generata la distribuzione predittiva a posteriori nel contesto del modello normale-normale, possiamo utilizzare cmdstanpy per eseguire l’analisi. Il codice seguente mostra come configurare il modello e generare previsioni.\n\n# Dati osservati\ny_observed = np.random.normal(170, 10, 100)\nmean_y = np.mean(y_observed)\nstd_y = np.std(y_observed)\n\n# Parametri a priori\nmu_0 = 175\ntau_0 = 5\n\n# Parametri posteriori\ntau_n_sq = (tau_0**2 * std_y**2) / (tau_0**2 + std_y**2)\ntau_n = np.sqrt(tau_n_sq)\nmu_n = (tau_0**2 * mean_y + std_y**2 * mu_0) / (tau_0**2 + std_y**2)\n\n# Parametri predittivi\nn_fut = 100\nsigma_pred_sq = tau_n_sq + (std_y**2 / n_fut)\nsigma_pred = np.sqrt(sigma_pred_sq)\nmu_pred = mu_n\n\n# Simulazioni\ny_pred_samples = np.random.normal(mu_pred, sigma_pred, 1000)\n\ncolor_fill = \"#B17F7D\"\ncolor_edge = \"#832F2B\"\n\n# Grafico\nplt.hist(y_pred_samples, bins=30, density=True, color=color_fill, alpha=0.5, label='Posterior Predictive')\nx = np.linspace(160, 190, 200)\nplt.plot(x, stats.norm.pdf(x, mu_pred, sigma_pred), 'r-', lw=2, label='Predictive Distribution')\nplt.axvline(x=mu_pred, color=color_edge, linestyle='--', label='Mean Prediction')\nplt.xlabel('Heights (cm)')\nplt.ylabel('Density')\nplt.title('Posterior Predictive Distribution for Heights')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nQuesto codice produce un grafico che illustra visivamente la distribuzione predittiva a posteriori per le altezze nel nostro campione di 100 nuove osservazioni, tenendo conto sia dei dati osservati che delle nostre aspettative iniziali.\nIn sintesi, la distribuzione predittiva a posteriori è stata generata nel modo seguente:\n\nCampioniamo un valore \\(\\mu\\) dalla distribuzione a posteriori di \\(\\mu\\).\nCampioniamo un valore \\(\\sigma\\) dalla distribuzione a posteriori di \\(\\sigma\\).\nUtilizziamo questi valori per generare un campione dalla distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nRipetiamo questo processo molte volte.\n\nLa distribuzione dei valori ottenuti da questi campionamenti costituisce la distribuzione predittiva a posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_prediction.html#metodo-mcmc",
    "href": "chapters/mcmc/06_stan_prediction.html#metodo-mcmc",
    "title": "56  La predizione bayesiana",
    "section": "56.4 Metodo MCMC",
    "text": "56.4 Metodo MCMC\nQuando usiamo un PPL come Stan, la distribuzione predittiva viene stimata mediante il campionamento da una catena di Markov, che è particolarmente utile in scenari complessi dove l’analisi analitica potrebbe essere impraticabile. Attraverso i metodi MCMC, si stimano le potenziali osservazioni future \\(p(\\tilde{y} \\mid y)\\), indicate come \\(p(y^{rep} \\mid y)\\), seguendo questi passaggi:\n\nSi campiona \\(\\theta_i \\sim p(\\theta \\mid y)\\): Viene selezionato casualmente un valore del parametro (o dei parametri) dalla distribuzione a posteriori.\nSi campiona \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\): Viene scelta casualmente un’osservazione dalla funzione di verosimiglianza, condizionata al valore del parametro (o dei parametri)ottenuto nel passo precedente.\n\nRipetendo questi due passaggi un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori.\nEsaminiamo ora come ottenere la distribuzione predittiva a posteriori con Stan per i dati dell’esempio precedente. Iniziamo creando le distribuzioni a posteriori di \\(\\mu\\) e \\(\\sigma\\).\n\nstan_ncp_file = os.path.join(\n    project_directory, 'stan', 'gaussian_model.stan')\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\nprint(model_ncp.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of observations\n  vector[N] y; // observed data\n  real mu_prior; // prior mean for mu\n  real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n  real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n  real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n}\nparameters {\n  real mu; // parameter of interest\n  real&lt;lower=0&gt; sigma; // parameter for the standard deviation\n}\nmodel {\n  mu ~ normal(mu_prior, sigma_prior); // prior for mu\n  sigma ~ normal(sigma_prior_mean, sigma_prior_sd); // prior for sigma\n  y ~ normal(mu, sigma); // likelihood\n}\ngenerated quantities {\n  array[N] real y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\n\n\nDefiniamo un dizionario che contiene i dati.\n\nstan_data = {\n    'N': len(y_observed), \n    'y': y_observed,\n    'mu_prior': 180,\n    'sigma_prior': 20,\n    'sigma_prior_mean': 10,\n    'sigma_prior_sd': 3\n}\n\nprint(stan_data)\n\n{'N': 100, 'y': array([157.2160102 , 162.69486738, 162.68308386, 164.27686592,\n       186.47491897, 161.39538834, 172.38571153, 184.63747656,\n       162.19119191, 170.19037732, 179.11386969, 164.55377485,\n       156.00523753, 172.82193962, 173.16471363, 164.63937533,\n       169.53511461, 178.1479531 , 175.49566912, 176.36456333,\n       180.81434309, 171.67280359, 159.36318605, 158.03513125,\n       151.76028503, 153.00047577, 171.88750707, 167.85311897,\n       177.083167  , 177.281136  , 180.09209358, 174.45888609,\n       168.16538298, 171.52283409, 159.34294043, 179.92208416,\n       176.76991899, 164.05355475, 167.44625251, 189.01908606,\n       169.88195177, 170.15351338, 168.4609556 , 163.39960566,\n       162.57875308, 177.18609527, 169.40757495, 170.89843378,\n       160.63985555, 167.92153439, 185.87271602, 172.97707565,\n       175.4461066 , 171.49878753, 163.44978271, 172.61501383,\n       163.13413454, 165.37487144, 165.2944901 , 151.44770452,\n       162.76871876, 174.95310706, 171.23043524, 155.42295373,\n       157.72440063, 142.88982644, 158.13376   , 181.02661795,\n       164.43996501, 171.40363966, 159.11235271, 174.07543291,\n       178.34574873, 169.37266709, 162.76188214, 176.33148411,\n       179.10232783, 168.09831272, 169.01554664, 161.3221712 ,\n       174.34823748, 166.76453274, 158.41276306, 163.48239894,\n       162.70898301, 167.53199203, 164.66658869, 161.43728297,\n       154.39015521, 168.23151416, 193.52704164, 183.39287151,\n       191.16893521, 161.0370113 , 170.22598907, 164.46860418,\n       157.79937215, 164.9038853 , 168.71477494, 170.19822606]), 'mu_prior': 180, 'sigma_prior': 20, 'sigma_prior_mean': 10, 'sigma_prior_sd': 3}\n\n\n\ny_mean = np.mean(y_observed)\ny_std = np.std(y_observed)\n\nprint(f\"Mean of y: {y_mean}\")\nprint(f\"Standard Deviation of y: {y_std}\")\n\nMean of y: 169.57193226941754\nStandard Deviation of y: 9.930634097490112\n\n\nEseguiamo il campionamento MCMC:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup = 1_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n16:57:29 - cmdstanpy - INFO - CmdStan start processing\n16:57:29 - cmdstanpy - INFO - Chain [1] start processing\n16:57:29 - cmdstanpy - INFO - Chain [2] start processing\n16:57:29 - cmdstanpy - INFO - Chain [3] start processing\n16:57:29 - cmdstanpy - INFO - Chain [4] start processing\n16:57:29 - cmdstanpy - INFO - Chain [1] done processing\n16:57:29 - cmdstanpy - INFO - Chain [2] done processing\n16:57:29 - cmdstanpy - INFO - Chain [3] done processing\n16:57:29 - cmdstanpy - INFO - Chain [4] done processing\n\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\naz.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n169.62\n1.00\n167.73\n171.43\n0.01\n0.01\n6155.68\n5203.68\n1.0\n\n\nsigma\n10.09\n0.71\n8.69\n11.35\n0.01\n0.01\n7169.12\n5070.39\n1.0\n\n\n\n\n\n\n\nConvertiamo l’oggetto sample_ncp in un oggetto di classe InferenceData:\n\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp, \n    posterior_predictive='y_rep', \n    observed_data={\"y\": y_observed}\n)\n\nLa distribuzione predittiva a posteriori è utilizzata per eseguire i controlli predittivi a posteriori (PPC), noti come Posterior Predictive Checks. I PPC consistono in un confronto grafico tra \\(p(y^{rep} \\mid y)\\), ossia la distribuzione delle osservazioni future previste, e i dati osservati \\(y\\). Questo confronto visivo permette di valutare se il modello utilizzato è adeguato per descrivere le proprietà dei dati osservati.\nOltre al confronto grafico tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\), è possibile effettuare un confronto tra le distribuzioni di varie statistiche descrittive calcolate su diversi campioni \\(y^{rep}\\) e le corrispondenti statistiche calcolate sui dati osservati. Tipicamente, vengono considerate statistiche descrittive come la media, la varianza, la deviazione standard, il minimo o il massimo, ma è possibile confrontare qualsiasi altra statistica rilevante.\nI controlli predittivi a posteriori offrono un valido strumento per un’analisi critica delle prestazioni del modello e, se necessario, per apportare eventuali modifiche o considerare modelli alternativi più adatti ai dati in esame.\nPossiamo ora usare ArviZ per generare il posterior-predictive plot:\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_prediction.html#distribuzione-predittiva-a-priori",
    "href": "chapters/mcmc/06_stan_prediction.html#distribuzione-predittiva-a-priori",
    "title": "56  La predizione bayesiana",
    "section": "56.5 Distribuzione Predittiva a Priori",
    "text": "56.5 Distribuzione Predittiva a Priori\nLe verifiche predittive a priori generano dati utilizzando unicamente le distribuzioni a priori, ignorando i dati osservati, al fine di valutare se tali distribuzioni a priori sono appropriate. La distribuzione predittiva a priori è quindi simile alla distribuzione predittiva a posteriori, ma senza dati osservati, rappresentando il caso limite di una verifica predittiva a posteriori senza dati.\nQuesto processo può essere realizzato facilmente simulando i parametri secondo le distribuzioni a priori e poi simulando i dati in base al modello dati i parametri simulati. Il risultato è una simulazione dalla distribuzione predittiva a priori.\nQuesta procedura è fondamentale per verificare se le ipotesi a priori sono realistiche e adeguate prima di raccogliere o utilizzare i dati osservati. Se i dati simulati dalla distribuzione predittiva a priori non risultano plausibili, potrebbe essere necessario rivedere le scelte delle distribuzioni a priori.\nUn prior predictive check è codificato come un posterior predictive check. Se disponiamo già del codice per un posterior predictive check ed è possibile impostare i dati come vuoti, allora non è necessario alcun codice ulteriore. I prior predictive checks possono essere codificati interamente all’interno del blocco generated quantities utilizzando la generazione di numeri casuali. I draw risultanti saranno indipendenti.\n\nEsempio 56.2 Consideriamo un primo esempio pratico utilizzando il modello beta-binomiale. Il modello iniziale, che include il blocco model, serve per stimare i parametri del modello sulla base dei dati osservati.\ndata {\n  int&lt;lower=0&gt; N;\n  array[N] int&lt;lower=0, upper=1&gt; y;\n  int&lt;lower=0&gt; alpha_prior;\n  int&lt;lower=0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ bernoulli(theta);\n}\nPer ottenere un campione dalla distribuzione a priori (cioè prima di osservare i dati), possiamo modificare il modello come segue:\ndata {\n  int&lt;lower=0&gt; N;  // Numero di osservazioni\n  int&lt;lower=0&gt; alpha_prior;  // Parametro di forma della distribuzione beta a priori\n  int&lt;lower=0&gt; beta_prior;  // Parametro di forma della distribuzione beta a priori\n}\ngenerated quantities {\n  array[N] int y_sim;  // Dati simulati\n  real&lt;lower=0, upper=1&gt; theta_prior;  // Valore di theta estratto dalla distribuzione a priori\n\n  // Estraiamo un valore per theta dalla distribuzione beta a priori\n  theta_prior = beta_rng(alpha_prior, beta_prior);\n\n  // Simuliamo N osservazioni dalla distribuzione binomiale\n  // utilizzando il valore di theta estratto e il numero totale di osservazioni N\n  for (n in 1:N)\n    y_sim[n] = binomial_rng(N, theta_prior);\n}\nIn questo secondo script abbiamo\n\neliminato il blocco model: Questo blocco serve per l’inferenza Bayesiana, ma non è necessario per generare dati a priori.\naggiunto il blocco generated quantities: In questo blocco generiamo quantità di interesse, come i dati simulati y_sim e il valore di theta estratto dalla distribuzione a priori.\nutilizzato la funzione beta_rng per estrarre un valore per theta dalla distribuzione \\(\\mathcal{Beta}\\) definita dai parametri alpha_prior e beta_prior. Questo valore rappresenta una possibile realizzazione del parametro prima di osservare i dati.\nutilizzato la funzione binomial_rng per simulare N osservazioni dalla distribuzione binomiale. Il parametro di successo theta è fissato al valore estratto theta_prior.\n\nIn sostanza, questo codice ci permette di generare un dataset simulato che potrebbe essere osservato se il processo stocastico fosse governato unicamente dai parametri specificati nella distribuzione a priori. In questo modo, possiamo valutare le proprietà del modello e la sua capacità di generare dati simili a quelli reali, prima ancora di avere a disposizione i dati osservati.\nLa distribuzione a priori rappresenta la nostra conoscenza o credenza sul valore del parametro theta prima di osservare i dati. Scegliendo diversi valori per alpha_prior e beta_prior, possiamo specificare diverse distribuzioni a priori e quindi esplorare come queste influenzano i risultati della simulazione.\n\nstan_file = os.path.join(project_directory, \"stan\", \"beta_binomial_prior.stan\")\nmodel_beta_binomial_prior = CmdStanModel(stan_file=stan_file)\nprint(model_beta_binomial_prior.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  real&lt;lower=0&gt; alpha_prior;\n  real&lt;lower=0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  // Definizione del priore Beta\n  theta ~ beta(alpha_prior, beta_prior);\n}\ngenerated quantities {\n  // Generazione della distribuzione predittiva a priori\n  array[N] int&lt;lower=0, upper=1&gt; y_sim;\n  for (n in 1 : N) {\n    y_sim[n] = bernoulli_rng(theta);\n  }\n}\n\n\n\nCreiamo il dizionario Stan per il caso dell’esempio in discussione.\n\nN = 100\ny = 14\n\n# Create an integer array of zeros\ny_vec = np.zeros(N, dtype=np.int32)\n\n# Assign 1 to the first y elements\ny_vec[:y] = 1\n\nalpha_prior = 4\nbeta_prior = 6\n\nstan_data = {\n    \"N\": N,\n    \"y\": y_vec,\n    \"alpha_prior\": alpha_prior,\n    \"beta_prior\": beta_prior,\n}\n\nEseguiamo il campionamento.\n\npp_samples = model_beta_binomial_prior.sample(\n    data=stan_data,\n    iter_sampling=1000,\n    iter_warmup=0,  # Un numero adeguato di iterazioni di warmup\n    adapt_engaged=False,  # Disabilita l'adattamento\n    chains=1,\n    show_progress=False,\n    show_console=False,\n)\n\nDall’oggetto pp_samples estraiamo y_sim.\n\ny_sim_samples = pp_samples.stan_variable(\"y_sim\")\ny_sim_flattened = y_sim_samples.flatten()\n\nCalcoliamo le statistiche descrittive per i valori y_sim che abbiamo ottenuto.\n\ny_rep_mean = np.mean(y_sim_flattened)\ny_rep_std = np.std(y_sim_flattened)\n\nprint(f\"Mean of y_rep: {y_rep_mean}\")\nprint(f\"Standard Deviation of y_rep: {y_rep_std}\")\n\nMean of y_rep: 0.40553\nStandard Deviation of y_rep: 0.49099431676955296\n\n\nGeneriamo una rappresentazione grafica della distribuzione di y_sim.\n\nplt.hist(y_sim_flattened, bins=20, density=True, alpha=0.75, color=\"blue\")\nplt.title(\"Distribuzione predittiva a priori\")\nplt.xlabel(\"Valori predetti (y_sim)\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\nEstraiamo i valori theta e generiamo un istogramma.\n\ntheta_samples = pp_samples.stan_variable(\"theta\")\nplt.hist(theta_samples, bins=20, density=True, alpha=0.75, color=\"green\")\nplt.title(\"Distribuzione del parametro theta a priori\")\nplt.xlabel(\"theta\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\nPossiamo interpretare i risulati ottenuti nel modo seguente. In questo modello, stiamo utilizzando un prior \\(\\mathcal{Beta}(4, 6)\\) per il parametro \\(\\theta\\), che rappresenta la probabilità di successo in una distribuzione Bernoulliana. Questo prior riflette una convinzione a priori secondo la quale \\(\\theta\\) ha una media di \\(\\frac{4}{4+6} = 0.4\\), con una deviazione standard piuttosto ampia. Il risultato del prior predictive check mostra che la distribuzione simulata di successi ha una media di circa 0.405, con una deviazione standard di 0.491.\nDato che nei dati reali abbiamo osservato 14 successi su 100 prove, corrispondenti a una proporzione di 0.14, il prior \\(\\mathcal{Beta}(4, 6)\\) risulta essere piuttosto largo e centrato su un valore di probabilità di successo notevolmente più alto rispetto ai dati osservati.\nIn conclusione,\n\nSe abbiamo ragioni forti per imporre il prior \\(\\mathcal{Beta}(4, 6)\\), ad esempio, una conoscenza precedente o una letteratura consolidata che suggerisce che la probabilità di successo dovrebbe aggirarsi attorno a 0.4, allora il prior predictive check conferma che il modello predittivo a priori si comporta come ci aspettiamo: il prior è informativo e impone un certo grado di convinzione sulla probabilità di successo. Questo significa che la nostra conoscenza a priori influenza fortemente il modello.\nSe invece vogliamo imporre un prior debolmente informativo, che permetta ai dati di avere un peso maggiore nell’inferenza, questo prior non è ideale. In questo caso, il prior \\(\\mathcal{Beta}(4, 6)\\) è troppo informativo, portando a una distribuzione predittiva a priori che è troppo concentrata intorno a 0.4 e non riflette adeguatamente la possibilità di avere proporzioni di successo più basse come quella osservata nei dati (0.14). Per un prior debolmente informativo, potremmo considerare un prior meno concentrato, come un \\(\\mathcal{Beta}(2, 2)\\), che lascia più spazio all’influenza dei dati osservati.\n\n\n\nEsempio 56.3 Consideriamo un secondo esempio, ovvero il caso discusso in precedenza di un campione di dati gaussiani e di un modello gaussiano in cui le distribuzioni a priori per μ e σ sono gaussiane.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'gaussian_model_prior.stan')\nmodel_gauss = CmdStanModel(stan_file=stan_file)\nprint(model_gauss.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of observations\n  real mu_prior; // prior mean for mu\n  real&lt;lower=0&gt; sigma_prior; // prior standard deviation for mu\n  real&lt;lower=0&gt; sigma_prior_mean; // prior mean for sigma\n  real&lt;lower=0&gt; sigma_prior_sd; // prior standard deviation for sigma\n}\ngenerated quantities {\n  real mu = normal_rng(mu_prior, sigma_prior); // prior draw for mu\n  real&lt;lower=0&gt; sigma = normal_rng(sigma_prior_mean, sigma_prior_sd); // prior draw for sigma\n  array[N] real y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\n\n\nIl codice precedente\nfor (n in 1:N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\nillustra come generare campioni predittivi a priori nel blocco generated quantities. In questo esempio, mu e sigma sono generati dalle loro rispettive distribuzioni a priori e usati per generare campioni di dati simulati y_rep.\nEseguiamo il campionamento MCMC.\n\nprior_predictive_samples = model_gauss.sample(\n    data=stan_data, \n    fixed_param=True, \n    iter_sampling=1000, \n    iter_warmup=1, \n    chains=1,\n    show_progress=False, \n    show_console=False\n)\n\nEstraiamo le variabili necessarie.\n\ny_rep_samples = prior_predictive_samples.stan_variable(\"y_rep\")\ny_rep_flattened = y_rep_samples.flatten()\n\nCalcoliamo le statistiche descrittive dei valori y_rep.\n\ny_rep_mean = np.mean(y_rep_flattened)\ny_rep_std = np.std(y_rep_flattened)\n\nprint(f'Mean of y_rep: {y_rep_mean}')\nprint(f'Standard Deviation of y_rep: {y_rep_std}')\n\nMean of y_rep: 179.84035606600006\nStandard Deviation of y_rep: 23.17301041707538\n\n\nCreiamo un KDE plot con la distribuzione predittiva a priori.\n\nsns.kdeplot(y_rep_flattened, fill=True, color=color_fill)\nplt.title('Prior Predictive Check')\nplt.xlabel('Height (cm)')\nplt.ylabel('Density')\nplt.axvline(x=y_rep_mean, color=color_edge, linestyle='--', label=f'Mean: {y_rep_mean:.2f}')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico della distribuzione predittiva a priori ci mostra che i prior utilizzati nel codice Stan implicano una distribuzione della variabile di interesse y che è approssimativamente normale con media di 180.25 e deviazione standard di 22.23. Questo prior predictive check garantisce che le distribuzioni a priori dei parametri mu e sigma siano realistiche e adeguate per l’analisi dei dati considerati. Questo passaggio consente di identificare e correggere eventuali ipotesi errate prima di procedere con l’analisi dei dati osservati, migliorando così la validità dei risultati ottenuti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_prediction.html#considerazioni-conclusive",
    "href": "chapters/mcmc/06_stan_prediction.html#considerazioni-conclusive",
    "title": "56  La predizione bayesiana",
    "section": "56.6 Considerazioni Conclusive",
    "text": "56.6 Considerazioni Conclusive\nLe distribuzioni predittive a priori e a posteriori, pur essendo generate in modo simile, differiscono per la fonte di informazione utilizzata nella loro costruzione.\n\nDistribuzione Predittiva a Priori: Questa distribuzione rappresenta le nostre aspettative sui dati prima che qualsiasi osservazione effettiva sia disponibile. Per costruirla, prendiamo i valori dei parametri dalla distribuzione a priori e li utilizziamo nella funzione di verosimiglianza per generare dati simulati. La distribuzione risultante di questi dati generati è la distribuzione predittiva a priori, che riflette le nostre conoscenze e incertezze iniziali, prima di osservare i dati reali.\nDistribuzione Predittiva a Posteriori: Dopo aver osservato i dati, aggiorniamo le nostre credenze sui parametri utilizzando il teorema di Bayes, ottenendo così la distribuzione a posteriori dei parametri. La distribuzione predittiva a posteriori viene quindi generata prendendo valori dei parametri dalla distribuzione a posteriori, che ora incorpora l’informazione ottenuta dai dati osservati, e utilizzandoli nella funzione di verosimiglianza per generare nuovi dati simulati. Questa distribuzione riflette le nostre previsioni sui dati futuri o non osservati, dopo aver tenuto conto dei dati già raccolti.\n\nLa differenza principale tra queste due distribuzioni predittive risiede nella distribuzione dei parametri utilizzata: nella distribuzione predittiva a priori si utilizzano i parametri estratti dal prior, mentre nella distribuzione predittiva a posteriori si utilizzano i parametri estratti dal posterior. La distribuzione predittiva a posteriori è generalmente più informativa poiché integra i dati osservati, migliorando le previsioni future.\nÈ cruciale per l’integrità del modello che la distribuzione predittiva a posteriori sia coerente con la distribuzione dei dati osservati. Per verificare questa coerenza, si utilizzano le verifiche predittive a posteriori, confrontando la distribuzione predittiva con i dati empirici tramite tecniche come le stime di densità kernel (KDE). Questo confronto permette di valutare quanto bene il modello riesca ad approssimare la struttura reale dei dati e la sua capacità di fornire previsioni affidabili.\nAd esempio, consideriamo un modello gaussiano con varianza \\(\\sigma^2\\) nota:\n\\[\n\\begin{aligned}\n  y\\sim \\mathop{\\mathrm{N}}(\\theta,\\sigma^2),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2\\) descrive l’incertezza aleatoria. Usando un prior uniforme, la distribuzione a posteriori per \\(\\theta\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\theta|y) \\sim \\mathop{\\mathrm{N}}(\\theta|\\bar{y},\\sigma^2/n),\n\\end{aligned}\n\\]\ndove \\(\\sigma^2/n\\) rappresenta l’incertezza epistemica legata a \\(\\theta\\). La distribuzione predittiva a posteriori per un nuovo valore \\(\\tilde{y}\\) sarà:\n\\[\n\\begin{aligned}\n  p(\\tilde{y}|y) \\sim \\mathop{\\mathrm{N}}(\\tilde{y}|\\bar{y},\\sigma^2+\\sigma^2/n),\n\\end{aligned}\n\\]\nIn questo caso, l’incertezza totale è data dalla somma dell’incertezza epistemica (\\(\\sigma^2/n\\)) e dell’incertezza aleatoria (\\(\\sigma^2\\)).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/06_stan_prediction.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/06_stan_prediction.html#informazioni-sullambiente-di-sviluppo",
    "title": "56  La predizione bayesiana",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Sun Aug 04 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGelman, A., & Shalizi, C. R. (2013). Philosophy and the practice of Bayesian statistics. British Journal of Mathematical and Statistical Psychology, 66(1), 8–38.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>La predizione bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html",
    "href": "chapters/mcmc/07_bayesian_workflow.html",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "",
    "text": "57.1 Introduzione\nL’applicazione dell’inferenza bayesiana nella risoluzione di problemi reali richiede un approccio strutturato e multidisciplinare, noto come workflow bayesiano. Questo processo iterativo e complesso va ben oltre la semplice applicazione della regola di Bayes, che pur costituendo il fondamento teorico dell’inferenza bayesiana, rappresenta solo il punto di partenza di un percorso analitico più articolato.\nIl workflow bayesiano richiede al ricercatore una combinazione di competenze che spaziano dalla statistica alla conoscenza approfondita del dominio applicativo, dalle abilità di programmazione alla comprensione dei processi decisionali nell’analisi dei dati. Questo approccio comprende diverse fasi interconnesse: la costruzione iterativa di modelli, la loro verifica e validazione, la risoluzione di problemi computazionali, l’interpretazione dei risultati e il confronto tra modelli alternativi.\nL’applicazione pratica del workflow bayesiano emerge, per esempio, in contesti come la valutazione dell’effetto di un intervento psicologico. In questo scenario, il ricercatore si trova di fronte a molteplici decisioni: la scelta delle covariate, la definizione di componenti gerarchiche del modello, la selezione delle distribuzioni per le osservazioni e le priori marginali. Queste scelte non sono definitive, ma parte di un processo iterativo che può richiedere revisioni e aggiustamenti in base ai risultati ottenuti.\nLa complessità del workflow bayesiano si manifesta anche nella gestione di possibili problemi computazionali, che possono compromettere la qualità dei campioni dalla distribuzione a posteriori. In questi casi, il ricercatore deve essere pronto a riformulare il modello o a modificare l’approccio computazionale. Inoltre, l’analisi non si limita alla stima dei parametri di interesse, ma include anche la valutazione delle capacità predittive del modello e il confronto con modelli alternativi.\nUn aspetto cruciale del workflow bayesiano è la necessità di bilanciare la complessità dell’analisi con la rilevanza pratica dei risultati. Mentre l’uso di un singolo modello può portare a stime distorte dell’effetto del trattamento, l’esplorazione di numerosi modelli alternativi può generare una mole di informazioni difficile da gestire e interpretare. Il ricercatore deve quindi essere in grado di identificare i modelli più rilevanti per la valutazione dell’effetto del trattamento, considerando che modelli diversi possono portare a conclusioni differenti.\nIn sintesi, il workflow bayesiano si configura come una procedura strutturata per gestire le molteplici decisioni relative alla costruzione, revisione e miglioramento dei modelli statistici. Questo approccio, pur basandosi sui principi dell’inferenza bayesiana, va oltre la semplice applicazione della regola di Bayes, offrendo un quadro metodologico completo per affrontare le sfide dell’analisi dei dati in contesti reali e complessi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "href": "chapters/mcmc/07_bayesian_workflow.html#principi-del-workflow-bayesiano",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.2 Principi del workflow bayesiano",
    "text": "57.2 Principi del workflow bayesiano\nI workflow esistono in una varietà di discipline dove definiscono cosa costituisce una “buona pratica”.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#il-ciclo-di-box",
    "href": "chapters/mcmc/07_bayesian_workflow.html#il-ciclo-di-box",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.3 Il Ciclo di Box",
    "text": "57.3 Il Ciclo di Box\nGeorge Box, figura di spicco nel campo della statistica, ha introdotto negli anni ’60 un approccio ciclico alla modellizzazione statistica, noto come Ciclo di Box. Questo paradigma ha profondamente influenzato il modo in cui i ricercatori affrontano la costruzione e la valutazione dei modelli, in particolare nell’ambito dell’inferenza bayesiana.\n\n\n\nFigura tratta da Blei (2014).\n\n\nIl Ciclo di Box si articola in una serie di fasi iterative:\n\nFormulazione del modello: Sulla base delle conoscenze a priori e dei dati disponibili, si costruisce un modello statistico che cattura le caratteristiche essenziali del fenomeno in esame.\nInferenza: Attraverso l’applicazione di tecniche inferenziali, si stimano i parametri del modello e si valutano le incertezze associate alle stime stesse.\nValutazione del modello: Il modello viene confrontato con i dati osservati al fine di verificarne l’adeguatezza e individuare eventuali discrepanze.\nRevisione del modello: In caso di inadeguatezza, il modello viene modificato e si ritorna alla fase di inferenza. Questo processo iterativo continua fino a quando il modello non fornisce una descrizione soddisfacente dei dati.\n\nIl Ciclo di Box rappresenta un approccio pragmatico alla modellizzazione statistica. Il processo di modellazione è concepito come un percorso evolutivo, in cui il modello viene continuamente raffinato alla luce delle nuove evidenze. Il paradigma bayesiano si sposa perfettamente con il Ciclo di Box. L’inferenza bayesiana permette di aggiornare le credenze a priori alla luce dei dati osservati, fornendo una base solida per la revisione iterativa dei modelli. Più recentemente, Gelman et al. (2020) hanno proposto un’estensione più dettagliata del Ciclo di Box, offrendo una guida pratica per l’implementazione di un workflow bayesiano completo.\n\n\n\nFigura tratta da Gelman et al. (2020).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "href": "chapters/mcmc/07_bayesian_workflow.html#costruzione-iterativa-del-modello",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.4 Costruzione iterativa del modello",
    "text": "57.4 Costruzione iterativa del modello\nIn pratica, un possibile ciclo del workflow bayesiano può essere descritto nei seguenti termini:\n\nComprendere il fenomeno di interesse e formulare chiaramente il problema da risolvere. Come verrà discusso in modo approfondito nelle sezioni dedicate all’inferenza causale, limitarsi a descrivere le associazioni tra variabili offre una comprensione limitata del fenomeno di interesse. È molto più utile partire da un’ipotesi sul meccanismo generatore dei dati, cioè sul funzionamento causale del fenomeno, per poi testarla attraverso la modellizzazione bayesiana.\nFormulare matematicamente il modello. La formulazione matematica del modello è facilitata dall’uso di linguaggi probabilistici (PPL), come Stan, che permettono di tradurre le ipotesi sul processo generativo dei dati in modelli probabilistici concreti.\nImplementare il modello. Il modello matematico può essere implementato utilizzando diverse interfacce per Stan, come R, Python o Julia. Queste interfacce forniscono strumenti potenti per definire e adattare modelli complessi, consentendo un’integrazione agevole con i flussi di lavoro esistenti.\nEseguire verifiche predittive a priori. Le verifiche predittive a priori consistono nel simulare dati a partire dai valori di parametri estratti dalle distribuzioni a priori. Questo processo permette di visualizzare l’intervallo di dati che il modello ritiene plausibile prima di osservare i dati effettivi, fornendo un modo intuitivo per valutare l’adeguatezza dei priori scelti. È spesso più semplice ottenere una conoscenza esperta su quantità osservabili piuttosto che su parametri astratti, per cui queste simulazioni aiutano a calibrare i modelli in base alle aspettative ragionevoli.\nAdattare il modello. Una volta definito il modello, esso viene adattato ai dati attraverso l’esecuzione del campionamento, utilizzando la sintassi specifica dell’interfaccia scelta (ad esempio, cmdstanr o cmdstanpy).\nValutare le diagnostiche di convergenza. Una volta completato il campionamento, è fondamentale verificare che la catena MCMC sia convergente e stabile. Diagnostiche come il R-hat, l’efficienza della campionatura, e il controllo della varianza tra le catene sono essenziali per confermare che il modello sia stato adattato correttamente e che le inferenze siano affidabili.\nEseguire verifiche predittive a posteriori. Le verifiche predittive a posteriori prevedono la simulazione di nuovi dati utilizzando la distribuzione predittiva posteriore. In altre parole, dopo aver stimato i parametri del modello basandoci sui dati osservati, generiamo nuovi dataset che potrebbero essere stati osservati. Il confronto tra questi dati simulati e i dati reali è cruciale per valutare la capacità del modello di riprodurre il fenomeno osservato. Se emergono discrepanze significative, potrebbe essere necessario rivedere le assunzioni del modello. Inoltre, le verifiche a posteriori forniscono un’indicazione dell’incertezza nelle previsioni, permettendoci di calcolare intervalli di credibilità per le nuove osservazioni.\nMigliorare iterativamente il modello. Il processo di costruzione del modello è spesso iterativo: si parte da modelli semplici, che vengono progressivamente raffinati e resi più complessi o efficienti dal punto di vista computazionale. Questa iterazione è guidata dalle verifiche predittive, dalle diagnostiche e dal confronto tra i dati osservati e quelli simulati, fino a raggiungere un modello che descriva adeguatamente il fenomeno di interesse e fornisca previsioni robuste.\n\nQuesto processo ciclico permette di costruire modelli sempre più accurati, rendendo il workflow bayesiano una strategia flessibile ed efficace per affrontare problemi complessi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "href": "chapters/mcmc/07_bayesian_workflow.html#analisi-multiverso",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.5 Analisi Multiverso",
    "text": "57.5 Analisi Multiverso\nIl concetto di workflow bayesiano è stato recentemente arricchito dall’introduzione della multiverse analysis, come proposto da Riha et al. (2024). Questo approccio innovativo supera la tradizionale focalizzazione su un singolo modello, abbracciando invece l’analisi simultanea di molteplici modelli plausibili. Il risultato è la creazione di un “multiverso” di modelli, dove ciascuno rappresenta una combinazione unica di scelte modellistiche, dalle covariate selezionate alle distribuzioni per osservazioni e priori.\nL’integrazione della multiverse analysis nel workflow bayesiano offre numerosi vantaggi:\n\nTrasparenza: Esplicita tutte le scelte di modellazione, chiarendo quali modelli sono stati considerati e perché.\nEsplorazione completa: Permette un’indagine parallela di diverse ipotesi, riducendo il rischio di trascurare modelli validi. Risponde a domande quali: “In che modo i risultati differiscono tra i vari modelli esplorati?”, “Quali sono le principali differenze e somiglianze?”\nValutazione comparativa: Facilita il confronto diretto tra modelli, consentendo una valutazione più robusta delle conclusioni. Risponde a domande quali: “In base a quali criteri sono stati selezionati i modelli più adatti?”, “Lo spazio dei modelli possibili è stato esplorato in modo esaustivo?”, “Sono state considerate tutte le alternative plausibili?”, “In che modo i risultati differiscono tra i vari modelli esplorati?”, “Quali sono le principali differenze e somiglianze?”\nIterazione efficiente: Consente di perfezionare simultaneamente più modelli, anziché di perfezionare sequenzialmente un singolo modello.\nReplicabilità: Fornisce informazioni dettagliate per riprodurre l’analisi e i risultati.\n\nQuesto approccio incorpora anche verifiche computazionali e analisi di sensibilità. Le prime identificano i modelli che necessitano di ulteriori verifiche per garantire l’affidabilità dei risultati, mentre le seconde esaminano la robustezza delle conclusioni rispetto alle diverse scelte di modellazione e all’influenza delle priori sulle stime posteriori.\nTuttavia, la generazione di numerosi modelli può complicare la gestione e l’interpretazione dei risultati. Per affrontare questa sfida, Riha et al. (2024) propongono un metodo di “iterative filtering” che comprende:\n\nCreazione di un multiverso iniziale di modelli.\nValutazione delle capacità predittive attraverso controlli predittivi posteriori (PPC) e calcolo dell’expected log point-wise predictive density (elpd).\nVerifica della qualità computazionale, esaminando convergenza ed efficienza del campionamento MCMC.\nFiltraggio iterativo basato su criteri di qualità predefiniti.\nPossibilità di estendere il multiverso e ripetere il processo.\n\nQuesto approccio mantiene i vantaggi della multiverse analysis riducendo al contempo la complessità attraverso un filtraggio sistematico. Il risultato è un workflow bayesiano più robusto e informativo, che bilancia la necessità di considerare molteplici ipotesi modellistiche con l’esigenza pratica di focalizzarsi sui modelli più promettenti per il problema in esame.\nUno dei casi di studio esaminati da Riha et al. (2024) riguarda l’analisi del numero di crisi epilettiche in relazione a diverse variabili (covariate) e scelte di modellazione. I dati utilizzati provengono dallo studio di Leppik et al. (1987) e sono disponibili nel pacchetto R brms.\nSono stati confrontati 24 modelli statistici, ciascuno con una specifica formulazione matematica (illustrata nella Tabella seguente). La scelta dei modelli ha riguardato diverse combinazioni di covariate e di distribuzioni di probabilità per descrivere il fenomeno in esame.\n\n\n\nTabella 1 ricavata da Riha et al. (2024).\n\n\nPer valutare la capacità predittiva dei modelli, è stato utilizzato il criterio ELPD (Expected Log-Predictive Density). I risultati sono riportati nel grafico seguente.\n\n\n\nFigura 12 ricavata da Riha et al. (2024).\n\n\nCome si può osservare, i modelli presentano performance predittive differenti.\nOltre all’ELPD, sono stati condotti controlli predittivi posteriori (PPC) per valutare la plausibilità dei modelli rispetto ai dati osservati. I risultati dei PPC sono visualizzati nella figura seguente.\n\n\n\nFigura 13 ricavata da Riha et al. (2024).\n\n\nIl modello selezionato è quello che ha mostrato il miglior valore di ELPD, evidenziando una buona capacità predittiva. Inoltre, i controlli PPC hanno confermato la plausibilità del modello rispetto ai dati osservati. Infine, il modello selezionato non ha presentato problemi computazionali durante la stima dei parametri.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/07_bayesian_workflow.html#considerazioni-conclusive",
    "href": "chapters/mcmc/07_bayesian_workflow.html#considerazioni-conclusive",
    "title": "57  Flusso di lavoro bayesiano",
    "section": "57.6 Considerazioni Conclusive",
    "text": "57.6 Considerazioni Conclusive\nL’inferenza bayesiana offre un potente framework per la modellizzazione dei dati complessi, fornendo una metodologia che non si limita alla stima dei parametri, ma permette di rappresentare e aggiornare le incertezze sulle ipotesi in modo iterativo. Come abbiamo visto, il workflow bayesiano, ispirato dal Ciclo di Box e dai contributi più recenti, si articola in una serie di fasi che vanno dalla comprensione del fenomeno alla costruzione, implementazione e verifica dei modelli. Ogni passaggio è essenziale per garantire che il modello rispecchi non solo i dati, ma anche la nostra conoscenza del processo generativo sottostante.\nL’approccio iterativo consente una continua revisione e ottimizzazione del modello, tenendo conto delle evidenze empiriche e delle nostre credenze a priori. Le verifiche predittive, sia a priori che a posteriori, sono strumenti fondamentali per valutare la qualità del modello e per affrontare le eventuali discrepanze tra i dati osservati e quelli simulati. Questo processo ciclico ci permette di costruire modelli sempre più precisi ed efficaci, rappresentando una strategia dinamica e flessibile per affrontare le sfide dell’inferenza in contesti reali. Inoltre, l’analisi multiverso permette di confrontare numerosi modelli plausibili, variando ipotesi su covariate, meccanismo generativo e prior.\nInfine, l’integrazione del workflow bayesiano con linguaggi probabilistici come Stan o PyMC facilita l’applicazione di queste metodologie, consentendo ai ricercatori di affrontare problemi complessi in modo strutturato ed efficiente.\n\n\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application, 1(1), 203–232.\n\n\nBulbulia, J. A. (2023). A workflow for causal inference in cross-cultural psychology. Religion, Brain & Behavior, 13(3), 291–306.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.\n\n\nLeppik, I., Dreifuss, F., Porter, R., Bowman, T., Santilli, N., Jacobs, M., Crosby, C., Cloyd, J., Stackman, J., Graves, N., et al. (1987). A controlled study of progabide in partial seizures: methodology and results. Neurology, 37(6), 963–963.\n\n\nRiha, A. E., Siccha, N., Oulasvirta, A., & Vehtari, A. (2024). Supporting Bayesian modelling workflows with iterative filtering for multiverse analysis. arXiv preprint arXiv:2404.01688.\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science, 11(5), 702–712.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Flusso di lavoro bayesiano</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html",
    "href": "chapters/mcmc/08_stan_odds_ratio.html",
    "title": "58  Analisi bayesiana dell’odds-ratio",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo l’applicazione degli strumenti statistici descritti nei capitoli precedenti all’analisi bayesiana di due proporzioni. Inizieremo definendo i concetti di odds, odds ratio e logit. Successivamente, mostreremo come effettuare l’analisi bayesiana per il confronto tra due proporzioni.\nUn rapporto di odds (OR) è una misura di associazione tra un’esposizione (o un certo gruppo o una certa conditione) e un risultato. L’OR rappresenta gli odds che si verifichi un risultato dato un’esposizione particolare, confrontate con gli odds del risultato che si verifica in assenza di tale esposizione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#odds",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#odds",
    "title": "58  Analisi bayesiana dell’odds-ratio",
    "section": "58.1 Odds",
    "text": "58.1 Odds\nIl termine “odds” rappresenta il rapporto tra la probabilità che un evento si verifichi e la probabilità che l’evento opposto si verifichi. Matematicamente, l’odds può essere calcolato come:\n\\[ \\text{odds} = \\frac{\\pi}{1-\\pi}, \\]\ndove \\(\\pi\\) rappresenta la probabilità dell’evento di interesse.\nMentre una probabilità \\(\\pi\\) è sempre compresa tra 0 e 1, gli odds possono variare da 0 a infinito. Per comprendere meglio gli odds lungo questo spettro, consideriamo tre diversi scenari in cui \\(\\pi\\) rappresenta la probabilità di un evento.\nSe la probabilità di un evento è \\(\\pi = \\frac{2}{3}\\), allora la probabilità che l’evento non si verifichi è \\(1 - \\pi = \\frac{1}{3}\\) e gli odds del verificarsi dell’evento sono:\n\\[ \\text{odds} = \\frac{2/3}{1-2/3} = 2. \\]\nQuesto significa che la probabilità che l’evento si verifichi è il doppio della probabilità che non si verifichi.\nSe, invece, la probabilità dell’evento è \\(\\pi = \\frac{1}{3}\\), allora gli odds che l’evento si verifichi sono la metà rispetto agli odds che non si verifichi:\n\\[ \\text{odds} = \\frac{1/3}{1-1/3} = \\frac{1}{2}. \\]\nInfine, se la probabilità dell’evento è \\(\\pi = \\frac{1}{2}\\), allora gli odds dell’evento sono pari a 1:\n\\[ \\text{odds} = \\frac{1/2}{1-1/2} = 1. \\]\n\n58.1.1 Interpretazione\nGli odds possono essere interpretati nel modo seguente. Consideriamo un evento di interesse con probabilità \\(\\pi \\in [0, 1]\\) e gli odds corrispondenti \\(\\frac{\\pi}{1-\\pi} \\in [0, \\infty)\\). Confrontando gli odds con il valore 1, possiamo ottenere una prospettiva sull’incertezza dell’evento:\n\nGli odds di un evento sono inferiori a 1 se e solo se le probabilità dell’evento sono inferiori al 50-50, cioè \\(\\pi &lt; 0.5\\).\nGli odds di un evento sono uguali a 1 se e solo se le probabilità dell’evento sono del 50-50, cioè \\(\\pi = 0.5\\).\nGli odds di un evento sono superiori a 1 se e solo se le probabilità dell’evento sono superiori al 50-50, cioè \\(\\pi &gt; 0.5\\).\n\nUno dei motivi per preferire l’uso dell’odds rispetto alla probabilità, nonostante quest’ultima sia un concetto più intuitivo, risiede nel fatto che quando le probabilità si avvicinano ai valori estremi (cioè 0 o 1), è più facile rilevare e apprezzare le differenze tra gli odds piuttosto che le differenze tra le probabilità.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#odds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#odds-ratio",
    "title": "58  Analisi bayesiana dell’odds-ratio",
    "section": "58.2 Odds Ratio",
    "text": "58.2 Odds Ratio\nQuando abbiamo una variabile di interesse espressa come proporzione, possiamo confrontare i gruppi utilizzando l’odds ratio. L’odds ratio rappresenta il rapporto tra gli odds di un evento in un gruppo e gli odds dello stesso evento in un secondo gruppo:\n\\[ OR = \\frac{odds_1}{odds_2} = \\frac{p_1/(1-p_1)}{p_2/(1-p_2)}. \\]\nInterpretazione:\n\nOR = 1: l’appartenenza al gruppo non influenza il risultato;\nOR &gt; 1: l’appartenenza al gruppo specificato al numeratore dell’OR aumenta la probabilità dell’evento rispetto al gruppo specificato al denominatore;\nOR &lt; 1: l’appartenenza al gruppo specificato al numeratore dell’OR riduce la probabilità dell’evento rispetto al gruppo specificato al denominatore.\n\nL’odds ratio è particolarmente utile quando vogliamo confrontare due gruppi e vedere come l’appartenenza a uno di essi influenza la probabilità di un certo evento. Ad esempio, consideriamo uno studio psicologico in cui stiamo valutando l’efficacia di una terapia comportamentale per ridurre l’ansia. Possiamo suddividere i partecipanti allo studio in due gruppi: quelli che sono stati sottoposti al trattamento (gruppo di trattamento) e quelli che non sono stati sottoposti al trattamento (gruppo di controllo).\nCalcolando l’odds ratio tra il gruppo di trattamento e il gruppo di controllo, possiamo capire se la terapia ha aumentato o ridotto la probabilità di riduzione dell’ansia. Se l’odds ratio è maggiore di 1, significa che la terapia ha aumentato le probabilità di riduzione dell’ansia; se è inferiore a 1, significa che il trattamento ha ridotto le probabilità di riduzione dell’ansia. L’odds ratio ci fornisce quindi una misura dell’effetto della terapia rispetto al controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#logaritmo-dellodds-ratio",
    "title": "58  Analisi bayesiana dell’odds-ratio",
    "section": "58.3 Logaritmo dell’Odds Ratio",
    "text": "58.3 Logaritmo dell’Odds Ratio\nIl logaritmo dell’odds ratio è una trasformazione matematica molto utilizzata nell’analisi statistica, specialmente nella regressione logistica. Essa permette di rendere l’odds ratio interpretabile su una scala lineare, semplificando l’analisi e l’interpretazione dei risultati.\nLa formula per calcolare il logaritmo dell’odds ratio è la seguente:\n\\[ \\text{logit}(OR) = \\log(OR) = \\log\\left(\\frac{odds_1}{odds_2}\\right). \\]\nIn altre parole, il logaritmo dell’odds ratio è il logaritmo naturale del rapporto tra gli odds di un evento nel primo gruppo e gli odds dello stesso evento nel secondo gruppo.\n\n58.3.1 Interpretazione\nL’interpretazione del logaritmo dell’odds ratio è più intuitiva rispetto all’odds ratio stesso. Una variazione di una unità nel logaritmo dell’odds ratio corrisponde a un cambiamento costante nell’odds ratio stesso.\nSe il logaritmo dell’odds ratio è positivo, significa che l’odds dell’evento nel primo gruppo è maggiore rispetto al secondo gruppo. Più il valore del logaritmo dell’odds ratio si avvicina a zero, più l’odds dell’evento nei due gruppi si avvicina a essere simile.\nSe, invece, il logaritmo dell’odds ratio è negativo, l’odds dell’evento nel primo gruppo è inferiore rispetto al secondo gruppo. Un valore di logaritmo dell’odds ratio vicino a zero indica che l’odds dell’evento è simile nei due gruppi.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-delle-proporzioni",
    "title": "58  Analisi bayesiana dell’odds-ratio",
    "section": "58.4 Analisi bayesiana delle proporzioni",
    "text": "58.4 Analisi bayesiana delle proporzioni\nUna volta compresi i concetti di odds, odds ratio e logit, possiamo procedere all’analisi bayesiana delle proporzioni. Questo approccio consente di confrontare le proporzioni di due gruppi, ottenendo stime delle probabilità a posteriori e degli intervalli di credibilità.\nL’analisi bayesiana si basa sull’applicazione del teorema di Bayes per aggiornare le conoscenze a priori con l’evidenza fornita dai dati osservati. Questo permette di ottenere una distribuzione a posteriori delle quantità di interesse, come l’odds ratio.\nIn questo capitolo, analizzeremo un set di dati fittizio ispirato a un classico esperimento di etologia descritto da Hoffmann et al. (2022). Von Frisch (1914) ha voluto verificare se le api possiedono la visione dei colori confrontando il comportamento di due gruppi di api. L’esperimento si compone di una fase di addestramento e di una fase di test.\nNella fase di addestramento, le api del gruppo sperimentale vengono esposte a un disco blu e a un disco verde. Solo il disco blu è ricoperto di una soluzione zuccherina, molto appetita dalle api. Il gruppo di controllo, invece, non riceve alcun addestramento.\nNella fase di test, la soluzione zuccherina viene rimossa dal disco blu e si osserva il comportamento di entrambi i gruppi. Se le api del gruppo sperimentale hanno appreso che solo il disco blu contiene la soluzione zuccherina e sono in grado di distinguere tra il blu e il verde, dovrebbero preferire esplorare il disco blu piuttosto che quello verde durante la fase di test.\nIl ricercatore osserva che in 130 casi su 200, le api del gruppo sperimentale continuano ad avvicinarsi al disco blu dopo la rimozione della soluzione zuccherina. Le api del gruppo di controllo, che non sono state addestrate, si avvicinano al disco blu 100 volte su 200.\nPer confrontare il comportamento delle api nelle due condizioni, useremo l’odds ratio, così da confrontare le probabilità dell’evento critico (scelta del disco blu) tra i due gruppi.\nCalcoliamo la proporzione delle api che scelgono il disco blu nella condizione sperimentale:\n\\[ p_e = \\frac{130}{200} = 0.65 \\]\nCalcoliamo gli odds nella condizione sperimentale:\n\\[ \\text{odds}_e = \\frac{p_e}{1 - p_e} \\approx 1.86 \\]\nQuesto ci indica che, nel gruppo sperimentale, ci sono circa 1.86 “successi” (ossia la scelta del disco blu) per ogni “insuccesso” (scelta del disco verde).\nProcediamo calcolando gli odds nella condizione di controllo:\n\\[ p_c = \\frac{100}{200} = 0.5 \\]\n\\[ \\text{odds}_c = \\frac{p_c}{1 - p_c} = 1.0 \\]\nQuesto ci indica che, nel gruppo di controllo, il numero di “successi” e “insuccessi” è uguale.\nInfine, confrontiamo gli odds tra la condizione sperimentale e la condizione di controllo per calcolare l’odds ratio (OR):\n\\[ \\text{OR} = \\frac{\\text{odds}_e}{\\text{odds}_c} = 1.86 \\]\nGli odds di scelta del disco blu aumentano di circa 1.86 volte nel gruppo sperimentale rispetto al gruppo di controllo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#analisi-bayesiana-dellodds-ratio",
    "title": "58  Analisi bayesiana dell’odds-ratio",
    "section": "58.5 Analisi Bayesiana dell’Odds Ratio",
    "text": "58.5 Analisi Bayesiana dell’Odds Ratio\nNella nostra analisi, ci focalizziamo sull’Odds Ratio (OR) per valutare la differenza nel comportamento di scelta delle api nelle due condizioni dell’esperimento discusso. L’OR fornisce una stima puntuale della differenza basata sul nostro campione specifico. Tuttavia, per realizzare un’inferenza statistica robusta, è essenziale considerare l’incertezza nelle nostre stime, caratterizzata attraverso la distribuzione a posteriori.\nL’analisi bayesiana si basa sull’applicazione del teorema di Bayes per aggiornare le nostre conoscenze a priori con l’evidenza fornita dai dati osservati. Questo ci permette di ottenere una distribuzione a posteriori delle quantità di interesse, come l’odds ratio.\nPer affrontare questa questione, adottiamo un approccio bayesiano, costruendo la distribuzione a posteriori dell’OR. A partire da questa distribuzione, determiniamo un intervallo di credibilità del 90%, che rappresenta l’intervallo entro il quale, con il 90% di confidenza, possiamo aspettarci che ricada il vero valore dell’OR della popolazione.\nSe questo intervallo non include il valore 1, disponiamo di una solida evidenza (con un livello di credibilità del 90%) che la differenza tra le due condizioni esaminate corrisponde a una differenza reale nella popolazione, il che suggerisce che non si tratta di un artefatto generato dalla nostra incertezza. In altre parole, possiamo affermare con ragionevole certezza che le api dispongono di una visione cromatica.\nD’altro canto, se l’intervallo di credibilità includesse il valore 1, ciò indicherebbe che la differenza osservata nel nostro campione potrebbe non riflettere una differenza significativa nella popolazione generale, suggerendo che potrebbe essere una peculiarità del nostro campione specifico.\nL’analisi bayesiana e il calcolo dell’intervallo di credibilità verranno condotti utilizzando cmdstanpy, che ci permette di implementare modelli bayesiani in modo efficiente e rigoroso. Utilizzeremo una distribuzione a priori debolmente informativa per l’OR, in modo da non influenzare eccessivamente i risultati con assunzioni preliminari.\nUna volta ottenuta la distribuzione a posteriori dell’OR, possiamo calcolare il nostro intervallo di credibilità del 90%. Questo intervallo fornirà una rappresentazione della nostra incertezza riguardo il vero valore dell’OR nella popolazione. Se il nostro intervallo di credibilità esclude il valore 1, possiamo concludere che esiste una differenza significativa tra i due gruppi, confermando che le api possono distinguere i colori e preferire il disco blu.\nIn sintesi, l’approccio bayesiano non solo ci permette di stimare l’OR, ma anche di quantificare la nostra incertezza e fare inferenze più solide e informative sulla capacità delle api di distinguere tra colori.\n\n58.5.1 Likelihood\nLa likelihood del modello descrive la probabilità di osservare i dati dati i parametri del modello. Nel nostro caso, abbiamo due gruppi con eventi binomiali.\nPer il gruppo 1:\n\\[ y_1 \\sim \\text{Binomiale}(N_1, \\theta_1) .\\]\nPer il gruppo 2:\n\\[ y_2 \\sim \\text{Binomiale}(N_2, \\theta_2) .\\]\n\n\n58.5.2 Priors\nI priors del modello descrivono le nostre convinzioni iniziali sui parametri prima di osservare i dati. Nel nostro caso, i parametri \\(\\theta_1\\) e \\(\\theta_2\\) seguono una distribuzione Beta(2, 2).\nPer \\(\\theta_1\\):\n\\[ \\theta_1 \\sim \\text{Beta}(2, 2) .\\]\nPer \\(\\theta_2\\):\n\\[ \\theta_2 \\sim \\text{Beta}(2, 2) .\\]\nCompiliamo e stampiamo il modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'odds-ratio.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n06:00:41 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio\n06:00:50 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/odds-ratio\n\n\n//  Comparison of two groups with Binomial\ndata {\n  int&lt;lower=0&gt; N1; // number of experiments in group 1\n  int&lt;lower=0&gt; y1; // number of events in group 1\n  int&lt;lower=0&gt; N2; // number of experiments in group 2\n  int&lt;lower=0&gt; y2; // number of events in group 2\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta1; // probability of event in group 1\n  real&lt;lower=0, upper=1&gt; theta2; // probability of event in group 2\n}\nmodel {\n  // model block creates the log density to be sampled\n  theta1 ~ beta(2, 2); // prior\n  theta2 ~ beta(2, 2); // prior\n  y1 ~ binomial(N1, theta1); // observation model / likelihood\n  y2 ~ binomial(N2, theta2); // observation model / likelihood\n}\ngenerated quantities {\n  real oddsratio = (theta1 / (1 - theta1)) / (theta2 / (1 - theta2));\n}\n\n\n\nNel blocco generated quantities, calcoliamo l’odds ratio:\n\\[ \\text{oddsratio} = \\frac{\\theta_1 / (1 - \\theta_1)}{\\theta_2 / (1 - \\theta_2)}. \\]\nQuesto rapporto delle odds ci dà una misura della forza dell’associazione tra l’evento e i gruppi.\nIn sintesi, il modello bayesiano utilizza i dati osservati per aggiornare le nostre convinzioni iniziali sui parametri \\(\\theta_1\\) e \\(\\theta_2\\), fornendo una distribuzione a posteriori che riflette sia le informazioni a priori sia le evidenze empiriche.\nCreiamo un dizionario che contiene i dati.\n\nn1 = 200\ny1 = 130\nn2 = 200\ny2 = 100\n\nstan_data = {\n    'N1': n1,\n    'y1': y1,\n    'N2': n2,\n    'y2': y2\n}\n\nprint(stan_data)\n\n{'N1': 200, 'y1': 130, 'N2': 200, 'y2': 100}\n\n\nEseguiamo il campionamento.\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n06:00:56 - cmdstanpy - INFO - CmdStan start processing\n06:00:56 - cmdstanpy - INFO - Chain [1] start processing\n06:00:56 - cmdstanpy - INFO - Chain [2] start processing\n06:00:56 - cmdstanpy - INFO - Chain [3] start processing\n06:00:56 - cmdstanpy - INFO - Chain [4] start processing\n06:00:56 - cmdstanpy - INFO - Chain [1] done processing\n06:00:56 - cmdstanpy - INFO - Chain [2] done processing\n06:00:56 - cmdstanpy - INFO - Chain [3] done processing\n06:00:56 - cmdstanpy - INFO - Chain [4] done processing\n\n\nEstraiamo la distribuzione a posteriori dell’odds ratio e generiamo un istogramma.\n\nor_draws = trace.stan_variable('oddsratio')\n\n\nplt.hist(\n    or_draws, bins=30, alpha=0.5, density=True\n)\nplt.title('Istogramma della distribizione a posteriori di OR')\nplt.xlabel('Valori')\nplt.ylabel('Frequenza')\nplt.show()\n\n\n\n\n\n\n\n\nLa distribuzione posteriore del rapporto degli odds è il modo più semplice e accurato per descrivere la differenza tra i due gruppi. Nel caso presente, notiamo che vi è un’elevata probabilità che la differenza tra i due gruppi sia affidabile e relativamente grande.\nUn sommario della distribuzione a posteriori dell’odds ratio si ottine nel modo seguente.\n\naz.summary(trace, var_names=['oddsratio'], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.88\n0.39\n1.2\n2.6\n0.0\n0.0\n6936.86\n5183.54\n1.0\n\n\n\n\n\n\n\nPossiamo determinare la probabilità che il rapporto di probabilità (odds ratio) superi 1. Per farlo, è sufficiente analizzare gli 8000 campioni della distribuzione posteriore dell’odds ratio\n\nlen(or_draws)\n\n8000\n\n\ne calcolare la proporzione di questi che presenta un valore maggiore di 1:\n\nnp.mean(or_draws &gt; 1.0)\n\n0.9985",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#diagnostica-delle-catene-markoviane",
    "title": "58  Analisi bayesiana dell’odds-ratio",
    "section": "58.6 Diagnostica delle catene markoviane",
    "text": "58.6 Diagnostica delle catene markoviane\nPrima di esaminare i risultati, eseguiamo la diagnostica delle catene markoviane.\n\n58.6.1 Mixing\nIl trace plot precedente dimostra un buon mixing. Questo è evidenza che il campionamento MCMC ha raggiunto uno stato stazionario.\n\n_ = az.plot_trace(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n58.6.2 Numerosità campionaria effettiva\nQuando si utilizzano metodi di campionamento MCMC, è ragionevole chiedersi se un particolare campione estratto dalla distribuzione a posteriori sia sufficientemente grande per calcolare con sicurezza le quantità di interesse, come una media o un HDI. Questo non è qualcosa che possiamo rispondere direttamente guardando solo il numero di punti della catena MCMC, e il motivo è che i campioni ottenuti dai metodi MCMC hanno un certo grado di autocorrelazione, quindi la quantità effettiva di informazioni contenute in quel campione sarà inferiore a quella che otterremmo da un campione iid della stessa dimensione. Possiamo pensare alla dimensione del campione effettivo (ESS) come a un stimatore che tiene conto dell’autocorrelazione e fornisce il numero di estrazioni che avremmo se il nostro campione fosse effettivamente iid.\nPer le catene buone, solitamente, il valore della dimensione del campione effettivo sarà inferiore al numero di campioni. Ma l’ESS può essere in realtà più grande del numero di campioni estratti. Quando si utilizza il campionatore NUTS, valori di ESS maggiori del numero totale di campioni possono verificarsi per parametri le cui distribuzioni posteriori sono vicine alla Gaussiana e che sono quasi indipendenti da altri parametri nel modello.\nNell’output di PyCM si considera ESS_BULK. Un euristica è che deve essere almeno uguale a 400. Nel caso presente questo si verifica, quindi il valore ESS_BULK non fornisce alcuna evidenza di cattivo mixing.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\noddsratio\n1.881\n0.386\n1.198\n2.597\n0.005\n0.003\n6937.0\n5184.0\n1.0\n\n\ntheta1\n0.647\n0.033\n0.585\n0.710\n0.000\n0.000\n6865.0\n5296.0\n1.0\n\n\ntheta2\n0.499\n0.035\n0.434\n0.564\n0.000\n0.000\n7465.0\n5391.0\n1.0\n\n\n\n\n\n\n\n\n\n58.6.3 R hat\nIn condizioni molto generali, i metodi di Markov chain Monte Carlo hanno garanzie teoriche che otterranno la risposta corretta indipendentemente dal punto di partenza. Sfortunatamente, tali garanzie sono valide solo per campioni infiniti. Quindi, nella pratica, abbiamo bisogno di modi per stimare la convergenza per campioni finiti. Un’idea diffusa è quella di generare più di una catena, partendo da punti molto diversi e quindi controllare le catene risultanti per vedere se sembrano simili tra loro. Questa nozione intuitiva può essere formalizzata in un indicatore numerico noto come R-hat. Esistono molte versioni di questo stimatore, poiché è stato perfezionato nel corso degli anni. In origine il R-hat veniva interpretato come la sovrastima della varianza dovuta al campionamento MCMC finito. Ciò significa che se si continua a campionare all’infinito si dovrebbe ottenere una riduzione della varianza della stima di un fattore R-hat. E quindi il nome “fattore di riduzione potenziale della scala” (potential scale reduction factor), con il valore target di 1 che significa che aumentare il numero di campioni non ridurrà ulteriormente la varianza della stima. Tuttavia, nella pratica è meglio pensarlo solo come uno strumento diagnostico senza cercare di sovra-interpretarlo.\nL’R-hat per il parametro theta viene calcolato come la deviazione standard di tutti i campioni di theta, ovvero includendo tutte le catene insieme, diviso per la radice quadratica media delle deviazioni standard separate all’interno della catena. Il calcolo effettivo è un po’ più complesso ma l’idea generale è questa. Idealmente dovremmo ottenere un valore di 1, poiché la varianza tra le catene dovrebbe essere la stessa della varianza all’interno della catena. Da un punto di vista pratico, valori di R-hat inferiori a 1.1 sono considerati sicuri.\nNel caso presente questo si verifica. Possiamo ottenere R hat con Arviz:\n\naz.rhat(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 1.0\n    theta1     float64 8B 1.001\n    theta2     float64 8B 1.001xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float641.0array(1.00038283)theta1()float641.001array(1.00052497)theta2()float641.001array(1.00059406)Indexes: (0)Attributes: (0)\n\n\nIl valore di \\(\\hat{R}\\), al massimo, raggiunge il valore di 1.001. Essendo il valore molto simile a 1 nel caso presente, possiamo dire che non ci sono evidenza di assenza di convergenza.\n\n\n58.6.4 Errore standard di Monte Carlo\nQuando si utilizzano metodi MCMC introduciamo un ulteriore livello di incertezza poiché stiamo approssimando la posteriore con un numero finito di campioni. Possiamo stimare la quantità di errore introdotta utilizzando l’errore standard di Monte Carlo (MCSE). L’MCSE tiene conto del fatto che i campioni non sono veramente indipendenti l’uno dall’altro e sono in realtà calcolati dall’ESS. Mentre i valori di ESS e R-hat sono indipendenti dalla scala dei parametri, la statistica MCSE non lo è. Se vogliamo riportare il valore di un parametro stimato al secondo decimale, dobbiamo essere sicuri che MCSE sia al di sotto del secondo decimale altrimenti, finiremo, erroneamente, per riportare una precisione superiore a quella che abbiamo realmente. Dovremmo controllare MCSE solo una volta che siamo sicuri che ESS sia abbastanza alto e R-hat sia abbastanza basso; altrimenti, MCSE non è utile.\nNel nostro caso il MCSE è sufficientemente piccolo.\n\naz.mcse(trace)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 24B\nDimensions:    ()\nData variables:\n    oddsratio  float64 8B 0.004636\n    theta1     float64 8B 0.0004029\n    theta2     float64 8B 0.0004034xarray.DatasetDimensions:Coordinates: (0)Data variables: (3)oddsratio()float640.004636array(0.00463567)theta1()float640.0004029array(0.00040294)theta2()float640.0004034array(0.00040337)Indexes: (0)Attributes: (0)\n\n\nCome per l’ESS, l’MCSE varia nello spazio dei parametri e quindi potremmo anche volerlo valutare per diverse regioni dello spazio dei parametri.\n\n_ = az.plot_mcse(trace, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nL’errore standard di Monte Carlo ci informa della precisione della stima ottenuta usando il metodo MCMC. Non possiamo riportare una precisione dei risultati maggiore di quella indicata dalla MCSE. Pertanto, per il caso presente relativo all’Odds Ratio (OR), possiamo affermare che la precisione massima raggiungibile è limitata a due decimali.\n\n\n58.6.5 Autocorrelazione\nL’autocorrelazione riduce la quantità effettiva di informazioni contenute in un campione e quindi è qualcosa che vogliamo mantenere al minimo. Possiamo ispezionare direttamente l’autocorrelazione con az.plot_autocorr.\n\n_ = az.plot_autocorr(trace, combined=True, var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\n\n\n58.6.6 Rank Plots\nI grafici dei ranghi sono un altro strumento diagnostico visivo che possiamo utilizzare per confrontare il comportamento del campionamento sia all’interno che tra le catene. I grafici dei ranghi, in parole semplici, sono istogrammi dei campioni della distribuzione a posteriori espressi in termini di ranghi. Nei grafici dei ranghi, i ranghi sono calcolati combinando prima tutte le catene ma poi rappresentando i risultati separatamente per ogni catena. Se tutte le catene stimano la stessa distribuzione, ci aspettiamo che i ranghi abbiano una distribuzione uniforme. Inoltre, se i grafici dei ranghi di tutte le catene sembrano simili, ciò indica un buon mix delle catene.\nPossiamo ottenere i grafici dei ranghi con az.plot_rank.\n\n_ = az.plot_rank(trace, kind=\"bars\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nUna rappresentazione alternativa è la seguente.\n\n_ = az.plot_rank(trace, kind=\"vlines\", var_names=[\"oddsratio\"])\n\n\n\n\n\n\n\n\nPossiamo vedere nella figura che i ranghi sono molto simili ad una distribuzione uniforme e che tutte le catene sono simili tra loro senza alcuno scostamento distintivo.\n\n\n58.6.7 Divergenza\nFinora abbiamo diagnosticato il funzionamento di un campionatore esaminando i campioni generati. Un altro modo per eseguire una diagnosi è monitorare il comportamento dei meccanismi interni del metodo di campionamento. Un esempio importante di tali diagnosi è il concetto di divergenza presente in alcuni metodi Hamiltonian Monte Carlo (HMC). Le divergenze (o transizioni divergenti) sono un modo potente e sensibile per diagnosticare i campioni e funzionano come complemento alle diagnosi che abbiamo visto nelle sezioni precedenti.\nPyMC riporta il numero di transizioni divergenti. Se non viene riportato alcun messaggio che informa della presenza di transizioni divergenti, questo vuol dire che la distribuzione a posteriori è stata stimata correttamente.\n\n\n58.6.8 BFMI\nIl BFMI (Fraction of Missing Information) serve a valutare quanto bene il processo di campionamento si allinea con la distribuzione della “energia” associata a ciascun campione. Nel contesto del campionamento Hamiltoniano, il termine “energia” si riferisce a una quantità calcolata durante il processo di campionamento che aiuta a valutare quanto è probabile un certo set di parametri alla luce dei dati osservati e del modello statistico in esame.\nIl BFMI è uno strumento che ci aiuta a valutare se il processo di campionamento sta “esplorando” adeguatamente lo spazio dei parametri possibili. In altre parole, ci dice se il nostro processo di campionamento sta dando un’immagine accurata delle regioni dello spazio dei parametri che sono realmente plausibili dati i nostri dati e il nostro modello. Un valore BFMI basso indica che il campionamento non è riuscito a esplorare adeguatamente alcune regioni dello spazio dei parametri che dovrebbero essere state esplorate, e quindi i risultati del campionamento potrebbero non essere affidabili.\nGeneralmente, un valore inferiore a 0.3 indica un campionamento insufficiente.\nNel caso presente, dal momento che i valori BFMI sono superiori a 0.3 per tutte le catene, sembra che il processo di campionamento sia riuscito a esplorare adeguatamente lo spazio dei parametri.\n\naz.bfmi(trace)\n\narray([1.14346921, 1.11602384, 1.1467078 , 1.03197001])\n\n\nLa validazione del processo di campionamento può essere efficacemente eseguita analizzando graficamente le quantità note come “energy transition” e “marginal energy”. Queste metriche sono strettamente legate alla funzione obiettivo che l’algoritmo di campionamento intende ottimizzare e giocano un ruolo cruciale nel rilevare potenziali problematiche che possono emergere durante il campionamento.\n\nEnergy transition: questa metrica illustra l’“energia” calcolata in ogni singolo passo dell’algoritmo di campionamento, offrendo una visione dettagliata delle fluttuazioni che intervengono ad ogni iterazione. Facilita l’identificazione delle aree dello spazio dei parametri dove l’algoritmo potrebbe incontrare difficoltà nel campionare in modo corretto.\nMarginal energy: fornisce un profilo dell’“energia” marginale per l’intero set di campioni, riflettendo l’“energia” media in ogni punto del campione. È una rappresentazione grafica dell’“energia” associata alla distribuzione a posteriori che si intende campionare.\n\nPer un’analisi diagnostica efficace, è auspicabile che il tracciato dell’“energy transition” coincida sostanzialmente con quello della “marginal energy”. Tale congruenza è indicativa di una esplorazione ben riuscita dello spazio dei parametri, assicurando che le regioni ad alta probabilità nella distribuzione a posteriori siano state correttamente campionate. Pertanto, una buona sovrapposizione tra i grafici delle due metriche attesterebbe un funzionamento ottimale del modello, conferendo un grado di affidabilità elevato alle stime dei parametri derivanti dal processo di campionamento.\n\n_ = az.plot_energy(trace)\n\n\n\n\n\n\n\n\n\n\n58.6.9 Conclusione\nIn questo capitolo abbiamo approfondito l’analisi bayesiana focalizzandoci sulla stima dell’odds ratio (OR). I risultati della diagnosi delle catene Markoviane non evidenziano problematiche relative alla convergenza dell’algoritmo né discrepanze nel modello statistico adottato, permettendoci di procedere con l’analisi dei risultati ottenuti.\nL’analisi ha determinato un valore a posteriori per l’OR di 1.88, accompagnato da un intervallo di credibilità del 94% compreso tra 1.20 e 2.60. Poiché questo intervallo non include il valore 1, possiamo affermare, con un grado di certezza del 94%, che il comportamento delle api differisce nelle due condizioni sperimentali. Questo fornisce evidenza a supporto dell’ipotesi che le api dispongano di una visione cromatica.\nL’approccio bayesiano adottato ci ha permesso di integrare le conoscenze a priori con i dati ottenuti dall’analisi, risultando in una stima dell’odds ratio più affidabile e accurata.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/08_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/08_stan_odds_ratio.html#informazioni-sullambiente-di-sviluppo",
    "title": "58  Analisi bayesiana dell’odds-ratio",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Sep 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\nseaborn   : 0.13.2\nscipy     : 1.14.0\npandas    : 2.2.2\n\nWatermark: 2.4.3\n\nLast updated: Sun Sep 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\nseaborn   : 0.13.2\nscipy     : 1.14.0\npandas    : 2.2.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHoffmann, T., Hofman, A., & Wagenmakers, E.-J. (2022). Bayesian tests of two proportions: A tutorial with R and JASP. Methodology, 18(4), 239–277.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>Analisi bayesiana dell'odds-ratio</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_normal_normal.html",
    "href": "chapters/mcmc/09_stan_normal_normal.html",
    "title": "59  Inferenza bayesiana su una media",
    "section": "",
    "text": "Introduzione\nL’obiettivo principale di questo capitolo è esaminare un contesto che abbiamo già preso in considerazione in precedenza: ci troviamo di fronte a un campione di dati misurati su una scala a intervalli o rapporti e desideriamo effettuare inferenze sulla media della popolazione da cui il campione è stato estratto. Tuttavia, anziché procedere con una derivazione analitica della distribuzione a posteriori della media della popolazione, in questo caso utilizzeremo i metodi MCMC con Stan.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_normal_normal.html#il-modello-normale",
    "href": "chapters/mcmc/09_stan_normal_normal.html#il-modello-normale",
    "title": "59  Inferenza bayesiana su una media",
    "section": "59.1 Il modello Normale",
    "text": "59.1 Il modello Normale\nI priori coniugati Normali di una Normale non richiedono l’approssimazione numerica ottenuta mediante metodi MCMC. In questo capitolo, tuttavia, ripetiamo l’esercizio descritto nel capitolo ?sec-distr-coniugate-2 usando Stan.\n\n59.1.1 Un esempio concreto\nPer applicare il modello Normale, utilizzeremo i dati del censimento parziale dell’area di Dobe dei !Kung San, raccolti attraverso interviste condotte da Nancy Howell alla fine degli anni ’60. I !Kung San sono una suddivisione della popolazione San, che vive nel deserto del Kalahari, tra Namibia, Botswana e Angola, e mantengono un’economia basata su caccia e raccolta. Riprodurremo l’analisi descritta da McElreath (2020), esaminando unicamente i valori dell’altezza di individui di età superiore ai 18 anni.\n\ndf = pd.read_csv('../../data/Howell_18.csv')\ndf.head()\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\n\nlen(df[\"height\"])\n\n352\n\n\n\nsns.kdeplot(df[\"height\"], bw_adjust=0.5, fill=True)  # Adjust bw_adjust for smoothing\nplt.xlabel(\"BDI-II\")\nplt.ylabel(\"Density\")\nplt.show()\n\n\n\n\n\n\n\n\nLa media dei valori dell’altezza nel campione è:\n\nnp.mean(df[\"height\"])\n\n154.5970926136364\n\n\ncon una deviazione standard pari a:\n\nnp.std(df[\"height\"], ddof=1)\n\n7.742332137351995\n\n\n\n\n59.1.2 Modello di Base\nImpostiamo una distribuzione a priori \\(\\mathcal{N}(181, 30)\\) per il parametro \\(\\mu\\) e una distribuzione a priori \\(\\mathcal{N}(0, 20)\\) per il parametro \\(\\sigma\\). Seguendo McElreath (2020), ho impostato la distribuzione a priori per \\(\\mu\\) sul valore della mia altezza, per incorporare nel modello le mie conoscenze precedenti rispetto ai valori dell’altezza.\nPertanto, il modello Normale si definisce nel modo seguente:\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(181, 30) \\notag\\\\\n\\sigma &\\sim \\mathcal{N}(0, 20) \\notag\n\\end{align}\n\\]\nCon questa specifica del modello:\n\nLa variabile casuale \\(Y_i\\) segue una distribuzione normale con parametri \\(\\mu\\) e \\(\\sigma\\).\nIl parametro \\(\\mu\\) ha una distribuzione a priori normale con media 181 e deviazione standard 30.\nIl parametro \\(\\sigma\\) ha una distribuzione a priori normale con deviazione standard 20, troncata inferiormente a 0.\n\nPer \\(\\sigma\\), la normale troncata con deviazione standard pari a 20 permette una grande variabilità, garantendo valori positivi per la deviazione standard della distribuzione normale di \\(Y_i\\). I parametri \\(\\mu\\) e \\(\\sigma\\) sono sconosciuti e rappresentano l’oggetto dell’inferenza.\n\nstan_file = os.path.join(project_directory, 'stan', 'gaussian_height.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\nparameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(mu, sigma);\n  sigma ~ normal(0, 20);\n  mu ~ normal(181, 30);\n}\n\n\n\nCreaiamo un dizionario con i dati in formato appropriato per Stan:\n\nstan_data = {\n    'N': len(df[\"height\"]), \n    'y': df[\"height\"]\n}\nprint(stan_data)\n\n{'N': 352, 'y': 0      151.765\n1      139.700\n2      136.525\n3      156.845\n4      145.415\n        ...   \n347    162.560\n348    142.875\n349    162.560\n350    156.210\n351    158.750\nName: height, Length: 352, dtype: float64}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell’inferenza insieme alle loro tracce (cioè i vettori dei campioni dei parametri \\(\\mu\\) e \\(\\sigma\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\nUna sintesi delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente.\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.60\n0.42\n153.84\n155.39\n0.0\n0.0\n7864.52\n5825.33\n1.0\n\n\nsigma\n7.77\n0.30\n7.21\n8.34\n0.0\n0.0\n6655.48\n5167.04\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_normal_normal.html#parametrizzazione-non-centrata",
    "href": "chapters/mcmc/09_stan_normal_normal.html#parametrizzazione-non-centrata",
    "title": "59  Inferenza bayesiana su una media",
    "section": "59.2 Parametrizzazione Non Centrata",
    "text": "59.2 Parametrizzazione Non Centrata\nNella versione precedente del modello Normale abbiamo specificato le distribuzioni a priori per i parametri oggetto dell’inferenza (\\(\\mu\\) e \\(\\sigma\\)) sulla scala dei dati grezzi osservati, i quali hanno una media di 154.6 e una deviazione standard di 7.7. Sul parametro \\(\\mu\\) abbiamo imposto una distribuzione a priori normale con media 181 e deviazione standard 30, e sul parametro \\(\\sigma\\) abbiamo imposto una distribuzione a priori normale con media 0 e deviazione standard 20. Queste distribuzioni a priori sono specifiche per ciascun particolare campione che possiamo osservare.\nÈ possibile usare un approccio diverso, che consente di definire delle distribuzioni a priori sui parametri che sono indipendenti dal particolare campione che osserviamo. Questa procedura è chiamata “parametrizzazione non centrata” (non-centered parametrization). In questo modello, utilizziamo variabili latenti \\(\\mu_{\\text{raw}}\\) e \\(\\sigma_{\\text{raw}}\\), che seguono una distribuzione normale standard:\n\\[\n\\begin{align}\n\\mu_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\\\\\n\\sigma_{\\text{raw}} &\\sim \\mathcal{N}(0, 1) \\notag\n\\end{align}\n\\]\nQueste variabili vengono poi trasformate per ottenere i parametri \\(\\mu\\) e \\(\\sigma\\) sulla scala originale:\n\\[\n\\begin{align}\n\\mu &= y_{\\text{mean}} + y_{\\text{sd}} \\cdot \\mu_{\\text{raw}} \\notag\\\\\n\\sigma &= y_{\\text{sd}} \\cdot \\sigma_{\\text{raw}} \\notag\n\\end{align}\n\\]\nDove: - \\(y_{\\text{mean}}\\) è la media dei dati osservati \\(y\\). - \\(y_{\\text{sd}}\\) è la deviazione standard dei dati osservati \\(y\\).\n\nstan_ncp_file = os.path.join(project_directory, 'stan', 'gaussian_ncp.stan')\nmodel_ncp = CmdStanModel(stan_file=stan_ncp_file)\n\nDi seguito è riportato il codice Stan per questo modello con la parametrizzazione non centrata:\n\nprint(model_ncp.code())\n\ndata {\n    int&lt;lower=1&gt; N;\n    vector[N] y;\n}\ntransformed data {\n    real y_mean = mean(y);\n    real y_sd = sd(y);\n}\nparameters {\n    real mu_raw;\n    real&lt;lower=0&gt; sigma_raw;\n}\ntransformed parameters {\n    real mu;\n    real&lt;lower=0&gt; sigma;\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Priors:\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    // Likelihood:\n    y ~ normal(mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\n\n\nEcco una spiegazione dettagliata del modello Stan con parametrizzazione non centrata.\n\nBlocco Dati:\n\nint&lt;lower=1&gt; N;: Il numero totale di prove o osservazioni.\nvector[N] y;: Il vettore dei punteggi osservati per ciascuna prova. Questi punteggi sono sulla loro scala originale e non standardizzati.\n\nBlocco Dati Trasformati:\n\nreal y_mean = mean(y);: La media dei dati osservati y.\nreal y_sd = sd(y);: La deviazione standard dei dati osservati y.\n\nBlocco Parametri:\n\nreal mu_raw;: Un parametro latente che segue una distribuzione normale standard.\nreal&lt;lower=0&gt; sigma_raw;: Un parametro latente che segue una distribuzione normale standard vincolata a essere positiva.\n\nBlocco Parametri Trasformati:\n\nreal mu;: La media della distribuzione normale per y sulla sua scala originale.\nreal&lt;lower=0&gt; sigma;: La deviazione standard della distribuzione normale per y sulla sua scala originale.\nQuesti parametri trasformati sono definiti come:\nmu = y_mean + y_sd * mu_raw;\nsigma = y_sd * sigma_raw;\n\n\nLa parametrizzazione non centrata comporta la riparametrizzazione del modello in termini di variabili standardizzate (mu_raw e sigma_raw) e poi la loro trasformazione di nuovo sulla scala originale dei dati. Questo approccio spesso porta a una migliore efficienza di campionamento e proprietà di convergenza, specialmente nei modelli gerarchici.\n\nParametri Latenti (mu_raw e sigma_raw):\n\nmu_raw ~ normal(0, 1);: mu_raw è una variabile normale standardizzata.\nsigma_raw ~ normal(0, 1);: sigma_raw è una variabile normale standardizzata vincolata a essere positiva.\n\nTrasformazione alla Scala Originale:\n\nmu = y_mean + y_sd * mu_raw;: Questo scala e trasla mu_raw alla posizione e scala dei dati osservati y.\nsigma = y_sd * sigma_raw;: Questo scala sigma_raw alla scala dei dati osservati y.\n\n\nLa dichiarazione della verosimiglianza y ~ normal(mu, sigma); indica che i dati osservati y seguono una distribuzione normale con media mu e deviazione standard sigma. Ecco perché ha senso anche se y è sulla sua scala originale:\n\nDati Osservati sulla Scala Originale: I dati osservati y sono sulla loro scala originale.\nParametri sulla Scala Originale: I parametri mu e sigma, dopo la trasformazione nel blocco transformed parameters, sono anch’essi sulla scala originale di y.\n\nQuindi, la dichiarazione y ~ normal(mu, sigma); specifica correttamente che i dati osservati y (sulla loro scala originale) sono modellati da una distribuzione normale con media mu e deviazione standard sigma, entrambe sulla scala originale di y.\nInfine, il blocco generated quantities viene utilizzato per i controlli predittivi posteriori generando nuovi dati (y_rep) dalla distribuzione posteriore dei parametri (mu e sigma):\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = normal_rng(mu, sigma);\n    }\n}\n\ny_rep: Questo genera punti dati replicati dalla distribuzione normale con la media posteriore mu e la deviazione standard posteriore sigma. Questo ti permette di confrontare le previsioni del modello con i dati osservati per eseguire controlli predittivi posteriori.\n\nEseguiamo il campionamento MCMC per il modello che segue una parametrizzazione non centrata:\n\ntrace_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo la distribuzioni a posteriori e le tracce dei parametri \\(\\mu\\) e \\(\\sigma\\):\n\n_ = az.plot_trace(trace_ncp, var_names=['mu', 'sigma'])\n\n\n\n\n\n\n\n\nOtteniamo una sintesi delle distribuzioni a posteriori dei parametri:\n\nsummary = az.summary(trace_ncp, var_names=['mu', 'sigma'], round_to=2)\nprint(summary)\n\n         mean    sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nmu     154.61  0.42  153.83   155.39       0.01      0.0   6329.64   5029.29   \nsigma    7.76  0.29    7.20     8.30       0.00      0.0   7836.78   5829.76   \n\n       r_hat  \nmu       1.0  \nsigma    1.0  \n\n\nI risultati sono molto simili a quelli ottenuti in precedenza.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_normal_normal.html#posterior-predictive-check",
    "href": "chapters/mcmc/09_stan_normal_normal.html#posterior-predictive-check",
    "title": "59  Inferenza bayesiana su una media",
    "section": "59.3 Posterior predictive check",
    "text": "59.3 Posterior predictive check\nUno dei vantaggi del toolkit bayesiano è che una volta ottenuta la distribuzione a posteriori congiunta dei parametri p(θ|Y) è possibile utilizzarla per generare le previsioni p(Ỹ). Matematicamente, questo può essere fatto calcolando:\n\\[\np(\\tilde{y} \\mid y) = \\int p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta distribuzione è nota come distribuzione predittiva posteriore. È predittiva perché viene utilizzata per fare previsioni e posteriore perché è calcolata utilizzando la distribuzione posteriore. Quindi possiamo pensare a questa come la distribuzione dei dati futuri dati il modello e i dati osservati.\nUtilizzando Stan è facile per ottenere campioni predittivi posteriori: non è necessario calcolare alcun integrale. Dobbiamo convertire l’oggetto creato dalla funzione sample() nel formato ArviZ InferenceData:\n\n# Convert to ArviZ InferenceData object\nidata = az.from_cmdstanpy(\n    posterior=trace_ncp,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nUn uso comune della distribuzione predittiva posteriore è quello di eseguire controlli predittivi posteriori. Questi sono un insieme di test che possono essere utilizzati per verificare se il modello è una buona rappresentazione dei dati. Possiamo utilizzare la funzione plot_ppc di ArviZ per visualizzare la distribuzione predittiva posteriore e i dati osservati. Il codice è:\n\n# Plot the posterior predictive check\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nNella figura, la linea nera rappresenta una KDE (Kernel Density Estimation) dei dati, mentre le linee blu sono KDE calcolate da ciascuno dei 500 campioni predittivi posteriori. Le linee blu riflettono l’incertezza associata alla distribuzione dei dati previsti.\nDi default, in ArviZ le KDE vengono stimati all’interno dell’intervallo effettivo dei dati e si assume che siano zero al di fuori di questo intervallo.\nDato che il tracciato del KDE plot è contenuto nell’insieme di profili dei KDE plot dei campioni predittivi a posteriori, si può concludere che il modello utilizzato offre una rappresentazione adeguata dei dati ed è utile per la maggior parte delle analisi. Tuttavia, è importante considerare che potrebbero esistere altri modelli in grado di adattarsi meglio all’intero dataset. Esploreremo ora come poter sviluppare un modello alternativo.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_normal_normal.html#modello-robusto",
    "href": "chapters/mcmc/09_stan_normal_normal.html#modello-robusto",
    "title": "59  Inferenza bayesiana su una media",
    "section": "59.4 Modello “robusto”",
    "text": "59.4 Modello “robusto”\nNon è necessario presupporre che i dati seguano una distribuzione gaussiana. Le lievi deviazioni dalla gaussianità possono essere considerate attraverso l’utilizzo della distribuzione t di Student, che è particolarmente utile quando queste deviazioni si manifestano nelle code della distribuzione, come sembra essere il caso in questa situazione. Pertanto, proponiamo di adottare un modello ‘robusto’, maggiormente adatto a gestire osservazioni che si discostano dalla normalità nelle code della distribuzione.\nLa distribuzione t di Student è caratterizzata dal parametro \\(\\nu\\), noto come ‘gradi di libertà’. Quando \\(\\nu\\) è pari o superiore a 30, la distribuzione t di Student diventa quasi indistinguibile da una distribuzione normale.\n\nnu_values = [1, 2, 10]\n\nfig, ax = plt.subplots()\n\nfor nu in nu_values:\n    x = np.linspace(-5, 5, 1000)\n    y = stats.t.pdf(x, df=nu, loc=0, scale=1)\n    ax.plot(x, y, label=f\"ν={nu}\")\n\nx = np.linspace(-5, 5, 1000)\ny = stats.t.pdf(x, df=np.inf, loc=0, scale=1)\nax.plot(x, y, linestyle=\"--\", color=\"k\", label=\"ν=∞\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nTuttavia, le code della distribuzione t di Student risultano più pesanti rispetto a quelle della normale quando \\(\\nu\\) è basso. Pertanto, proponiamo di assegnare a \\(\\nu\\) una distribuzione a priori che concentri la maggior parte della sua massa su valori bassi, come ad esempio una distribuzione esponenziale con un parametro di rate pari a 1/30.\n\n# Define the rate parameter for the exponential distribution\nrate = 1 / 30\n\n# Generate samples from the exponential distribution\nsamples = np.random.exponential(scale=1 / rate, size=10000)\n\n# Create the histogram plot of the samples\nplt.hist(samples, bins=50, density=True, alpha=0.75, label=\"Sampled Distribution\")\nplt.title(\"Exponential Distribution (λ = 1/30)\")\nplt.xlabel(\"Values\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nstan_student_file = os.path.join(project_directory, 'stan', 'student-model.stan')\nmodel_student = CmdStanModel(stan_file=stan_student_file)\nprint(model_student.code())\n\ndata {\n    int&lt;lower=1&gt; N;  // Numero totale di prove\n    vector[N] y;  // Punteggio in ciascuna prova\n}\ntransformed data {\n    real y_mean = mean(y);  // Media dei dati osservati\n    real y_sd = sd(y);  // Deviazione standard dei dati osservati\n}\nparameters {\n    real mu_raw;  // Parametro latente standardizzato per mu\n    real&lt;lower=0&gt; sigma_raw;  // Parametro latente standardizzato per sigma\n    real&lt;lower=1&gt; nu;  // Gradi di libertà per la distribuzione t di Student\n}\ntransformed parameters {\n    real mu;  // Media sulla scala originale\n    real&lt;lower=0&gt; sigma;  // Deviazione standard sulla scala originale\n    mu = y_mean + y_sd * mu_raw;\n    sigma = y_sd * sigma_raw;\n}\nmodel {\n    // Distribuzioni a priori non centrate\n    mu_raw ~ normal(0, 1);\n    sigma_raw ~ normal(0, 1);\n    nu ~ exponential(1.0 / 30.0);  // Prior esponenziale per i gradi di libertà\n    // Verosimiglianza\n    y ~ student_t(nu, mu, sigma);\n}\ngenerated quantities {\n    vector[N] y_rep;\n    for (n in 1:N) {\n        y_rep[n] = student_t_rng(nu, mu, sigma);\n    }\n}\n\n\n\n\ntrace_student = model_student.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori e le tracce dei parametri del nuovo modello.\n\n_ = az.plot_trace(trace_student, var_names=['mu', 'sigma', 'nu'])\n\n\n\n\n\n\n\n\nConvertiamo i risultati in un oggetto InferenceData di ArviZ.\n\nidata = az.from_cmdstanpy(\n    posterior=trace_student,\n    posterior_predictive='y_rep',\n    observed_data={\"y\": df[\"height\"]}\n)\n\nGeneriamo la distribuzione predittiva a posteriori.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nLa figura illustra che la situazione è analoga a quella del caso gaussiano. Questo non è sorprendente, dato che i dati relativi all’altezza si distribuiscono in maniera gaussiana nella popolazione. Pertanto, l’impiego della distribuzione t di Student o della distribuzione normale producono risultati sostanzialmente equivalenti in questo contesto.\n\naz.summary(trace_student, var_names=['mu', 'sigma', 'nu'], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n154.57\n0.42\n153.85\n155.40\n0.00\n0.00\n8798.72\n6040.50\n1.0\n\n\nsigma\n7.63\n0.30\n7.08\n8.21\n0.00\n0.00\n7145.94\n6226.65\n1.0\n\n\nnu\n62.39\n36.10\n11.40\n129.62\n0.41\n0.31\n7870.31\n5565.90\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/09_stan_normal_normal.html#commenti-e-considerazioni-finali",
    "title": "59  Inferenza bayesiana su una media",
    "section": "59.5 Commenti e considerazioni finali",
    "text": "59.5 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato il metodo per calcolare l’intervallo di credibilità per la media di una variabile casuale normale utilizzando Stan. Inoltre, abbiamo illustrato come sia possibile ampliare l’inferenza sulla media utilizzando un modello robusto basato sulla distribuzione t di Student.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_normal_normal.html#esercizi",
    "href": "chapters/mcmc/09_stan_normal_normal.html#esercizi",
    "title": "59  Inferenza bayesiana su una media",
    "section": "59.6 Esercizi",
    "text": "59.6 Esercizi\n\nEsercizio 59.1 Utilizzando i dati dell’esempio sui bambini plusdotati discusso nella Capitolo 43, impiegare Stan per replicare i risultati ottenuti con il metodo basato su griglia.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/09_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/09_stan_normal_normal.html#informazioni-sullambiente-di-sviluppo",
    "title": "59  Inferenza bayesiana su una media",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jul 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nlogging   : 0.5.1.2\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\narviz     : 0.18.0\npandas    : 2.2.2\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>Inferenza bayesiana su una media</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html",
    "href": "chapters/mcmc/10_stan_two_groups.html",
    "title": "60  Confronto tra due gruppi",
    "section": "",
    "text": "Introduzione\nL’obiettivo di questo capitolo è di ampliare la discussione del Capitolo 59, affrontando il confronto tra le medie di due gruppi indipendenti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "href": "chapters/mcmc/10_stan_two_groups.html#stima-bayesiana-e-test-dellipotesi-nulla",
    "title": "60  Confronto tra due gruppi",
    "section": "60.1 Stima bayesiana e test dell’ipotesi nulla",
    "text": "60.1 Stima bayesiana e test dell’ipotesi nulla\nSpesso, ci troviamo ad affrontare la necessità di confrontare due gruppi di dati. Potrebbe interessarci sapere se la media di un gruppo è maggiore o diversa rispetto a quella di un altro gruppo. Per effettuare tale confronto, è fondamentale utilizzare un modello statistico, poiché le vere differenze tra i gruppi sono spesso accompagnate da rumore di misurazione o fluttuazioni casuali del fenomeno in esame. Questo rende difficile trarre conclusioni basandosi unicamente sulle differenze calcolate dai dati osservati.\nIl metodo tradizionale per confrontare statisticamente due o più gruppi è quello di utilizzare un test statistico. Questo approccio prevede l’individuazione di un’ipotesi nulla, che solitamente afferma che non ci sono differenze tra i gruppi, e l’utilizzo di una statistica test per determinare se i dati osservati sono plausibili sotto questa ipotesi. L’ipotesi nulla viene rifiutata quando la statistica test calcolata supera una soglia predefinita.\nTuttavia, i test di ipotesi possono essere complessi e i risultati spesso soggetti a interpretazioni errate. La scelta delle specifiche del test statistico (ad esempio, quale test utilizzare, quale ipotesi nulla testare, quale livello di significatività adottare) è spesso arbitraria e basata su convenzioni piuttosto che sulla specificità del problema o delle decisioni da prendere (Johnson, 1999). Inoltre, i risultati forniti dai test sono spesso indiretti, incompleti e tendono a sovrastimare le evidenze contro l’ipotesi nulla (Goodman, 1999).\nUn approccio più informativo ed efficace per il confronto tra gruppi è quello basato sulla stima invece che sul test dell’ipotesi nulla, ed è guidato dalla probabilità bayesiana anziché dalla frequentista. In pratica, invece di testare se ci sono differenze tra i gruppi, si cerca di ottenere una stima di quanto siano effettivamente diversi. Questo approccio è intrinsecamente più informativo. Inoltre, viene inclusa una stima dell’incertezza associata a tale differenza, che tiene conto sia dell’incertezza dovuta alla nostra mancanza di conoscenza dei parametri del modello (incertezza epistemica) sia dell’incertezza causata dalla variabilità intrinseca del sistema (incertezza aleatoria).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#un-esempio-illustrativo",
    "href": "chapters/mcmc/10_stan_two_groups.html#un-esempio-illustrativo",
    "title": "60  Confronto tra due gruppi",
    "section": "60.2 Un esempio illustrativo",
    "text": "60.2 Un esempio illustrativo\nIn questo esempio, l’obiettivo è stimare la differenza tra le medie del quoziente di intelligenza dei bambini di due gruppi distinti in base al livello di scolarità della madre. Il primo gruppo include i bambini la cui madre non ha completato le scuole superiori, mentre il secondo gruppo comprende quelli la cui madre ha ottenuto il diploma superiore. Per questo, useremo i dati kidiq e un modello bayesiano al fine di ottenere una stima affidabile della differenza tra le medie dei due gruppi nella popolazione.\nI dati utilizzati sono forniti da Gelman e Hill (2007) e costituiscono un sottocampione estratto dal National Longitudinal Survey of Youth.\nLeggiamo i dati.\n\ndf = pd.read_stata(\"../../data/kidiq.dta\")\ndf.head()\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\nIl dataset contiene le seguenti colonne:\n\n“kid_score”: il quoziente intellettivo (QI) dei bambini. È una misura dell’intelligenza del bambino.\n“mom_hs”: una variabile binaria che indica se la madre del bambino ha completato o meno la scuola superiore. Può assumere i valori 0 o 1, dove 0 rappresenta “no” (la madre non ha completato la scuola superiore) e 1 rappresenta “sì” (la madre ha completato la scuola superiore).\n\nCi sono 93 bambini la cui madre non ha completato la scuola superiore e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\ndf.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nLe statistiche descrittive si ottengono nel modo seguente.\n\ndf[\"kid_score\"].mean()\n\n86.79723502304148\n\n\n\nsummary_stats = [np.mean, stat.stdev]\ndf.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63722/1859022749.py:2: FutureWarning: The provided callable &lt;function mean at 0x11c1f6660&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  df.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\nI bambini la cui madre ha completato le superiori tendono ad avere un QI maggiore di 11.8 punti rispetto ai bambini la cui madre non ha concluso le superiori.\n\n89.319648 - 77.548387\n\n11.771260999999996\n\n\nCreiamo due vettori che contengono il QI dei bambini dei due gruppi.\n\n# Vector of kid_score when mom_hs is 1\nkid_score_mom_hs_1 = df[df[\"mom_hs\"] == 1][\"kid_score\"]\n\n# Vector of kid_score when mom_hs is 0\nkid_score_mom_hs_0 = df[df[\"mom_hs\"] == 0][\"kid_score\"]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#dimensione-delleffetto",
    "href": "chapters/mcmc/10_stan_two_groups.html#dimensione-delleffetto",
    "title": "60  Confronto tra due gruppi",
    "section": "60.3 Dimensione dell’effetto",
    "text": "60.3 Dimensione dell’effetto\nNel caso presente, la differenza tra le medie dei due gruppi è di 11.8 punti sulla scala del QI, e potrebbe sembrare un risultato rilevante, considerando che la metrica del QI è facilmente interpretabile. Tuttavia, è importante notare che il test utilizzato in questo studio non è il WISC, che ha una distribuzione normale con media 100 e deviazione standard 15, ma il test PIAT.\nIn generale, è difficile comprendere il significato di una differenza tra le medie di due gruppi quando viene presentata solo come valore assoluto, soprattutto quando le varianze dei gruppi sono diverse. Per ottenere una misura più informativa, è necessario considerare sia la differenza tra le medie dei gruppi che l’incertezza associata a queste stime delle medie della popolazione. L’indice statistico che soddisfa questo scopo è noto come “dimensione dell’effetto” (effect size).\nLa dimensione dell’effetto è una misura della forza dell’associazione osservata, che tiene conto sia della grandezza della differenza tra i gruppi attesi che dell’incertezza sui dati. Tra gli indici più comunemente utilizzati per quantificare la dimensione dell’effetto, vi è l’indice \\(d\\) di Cohen.\nNel caso di due medie, questo indice è dato da:\n\\[\nd={\\frac {{\\bar {x}}_{1}-{\\bar {x}}_{2}}{s}},\n\\]\nladdove\n\\[\ns={\\sqrt {\\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}\n\\]\ne la varianza di ciascun gruppo è calcolata come\n\\[\ns_{1}^{2}={\\frac {1}{n_{1}-1}}\\sum _{i=1}^{n_{1}}(x_{1,i}-{\\bar {x}}_{1})^{2}.\n\\]\nSolitamente, l’indice \\(d\\) di Cohen si interpreta usando la metrica seguente:\n\n\n\nDimensione dell’effetto\n\\(d\\)\n\n\n\n\nVery small\n0.01\n\n\nSmall\n0.20\n\n\nMedim\n0.50\n\n\nLarge\n0.80\n\n\nVery large\n1.20\n\n\nHuge\n2.0\n\n\n\nPer una trattazione bayesiana della stima della dimensione dell’effetto, si veda (doingbayesian?).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#modello-bayesiano",
    "href": "chapters/mcmc/10_stan_two_groups.html#modello-bayesiano",
    "title": "60  Confronto tra due gruppi",
    "section": "60.4 Modello bayesiano",
    "text": "60.4 Modello bayesiano\nIl modello bayesiano per il confronto tra le medie di due gruppi indipendenti comprende la definizione della verosimiglianza per i dati di ciascun gruppo e la descrizione delle distribuzioni a priori dei parametri rilevanti. Inoltre, in questo caso, abbiamo incluso anche la stima della dimensione dell’effetto, che ci permette di valutare la forza dell’associazione osservata tra i gruppi, tenendo conto dell’incertezza sui dati.\nCreiamo un dizonario con i dati rilevanti.\n\nstan_data = {\n    'N1': len(kid_score_mom_hs_1), \n    'N2': len(kid_score_mom_hs_0), \n    'y1': kid_score_mom_hs_1,\n    'y2': kid_score_mom_hs_0\n}\nstan_data\n\n{'N1': 341,\n 'N2': 93,\n 'y1': 0       65\n 1       98\n 2       85\n 3       83\n 4      115\n       ... \n 425    102\n 426    104\n 430     76\n 432     88\n 433     70\n Name: kid_score, Length: 341, dtype: int32,\n 'y2': 5       98\n 14     102\n 19     101\n 24      99\n 33     106\n       ... \n 422    100\n 427     59\n 428     93\n 429     94\n 431     50\n Name: kid_score, Length: 93, dtype: int32}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#modello-stan",
    "href": "chapters/mcmc/10_stan_two_groups.html#modello-stan",
    "title": "60  Confronto tra due gruppi",
    "section": "60.5 Modello Stan",
    "text": "60.5 Modello Stan\nPer analizzare questi dati ci serviremo del seguente modello Stan.\n\nstan_file = os.path.join(project_directory, 'stan', 'kid-score.stan')\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response times (group 1)\n  vector[N2] y2;  // response times (group 2)\n}\n\nparameters {\n  real mu_1;  // mean of group 1\n  real mu_2;  // mean of group 2\n  real&lt;lower=0&gt; sigma_1;  // standard deviation of group 1\n  real&lt;lower=0&gt; sigma_2;  // standard deviation of group 2\n}\n\ntransformed parameters {\n  real delta;  // difference in means\n  real cohen_d;  // Cohen's d effect size\n  delta = mu_1 - mu_2;\n  cohen_d = delta / sqrt((sigma_1^2 + sigma_2^2) / 2);\n}\n\nmodel {\n  // Priors\n  mu_1 ~ normal(80, 20);  // Prior for mean of group 1\n  mu_2 ~ normal(80, 20);  // Prior for mean of group 2\n  sigma_1 ~ normal(0, 10);  // Prior for standard deviation of group 1\n  sigma_2 ~ normal(0, 10);  // Prior for standard deviation of group 2\n\n  // Likelihood\n  y1 ~ normal(mu_1, sigma_1);\n  y2 ~ normal(mu_2, sigma_2);\n}\n\ngenerated quantities {\n  vector[N1] y1_rep;  // replicated data for group 1\n  vector[N2] y2_rep;  // replicated data for group 2\n  for (i in 1:N1) {\n    y1_rep[i] = normal_rng(mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2_rep[i] = normal_rng(mu_2, sigma_2);\n  }\n}\n\n\n\nNel nostro modello: - N1 è il numero di osservazioni nel primo gruppo (bambini le cui madri hanno completato le superiori) - N2 è il numero di osservazioni nel secondo gruppo (bambini le cui madri non hanno completato le superiori) - y1 è un vettore contenente i valori di QI per il primo gruppo - y2 è un vettore contenente i valori di QI per il secondo gruppo\n\n60.5.1 Spiegazione del modello\n\n60.5.1.1 Parametri\n\nmu_1 e mu_2: Rappresentano le medie dei valori di QI per i due gruppi.\nsigma_1 e sigma_2: Rappresentano le deviazioni standard dei valori dei QI per i due gruppi.\n\n\n\n60.5.1.2 Parametri trasformati\n\ndelta: È la differenza tra le medie dei due gruppi (mu_1 - mu_2).\ncohen_d: È la dimensione dell’effetto di Cohen, che quantifica la differenza tra i gruppi in unità di deviazione standard.\n\n\n\n60.5.1.3 Prior\nImpostiamo delle prior per i parametri:\nmu_1 ~ normal(80, 20);\nmu_2 ~ normal(80, 20);\nsigma_1 ~ normal(0, 10);\nsigma_2 ~ normal(0, 10);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri. Per esempio, ci aspettiamo che i QI medi siano intorno a 80, ma con una certa variabilità.\n\n\n60.5.1.4 Likelihood\ny1 ~ normal(mu_1, sigma_1);\ny2 ~ normal(mu_2, sigma_2);\nQuesta parte del modello descrive come i dati osservati (y1 e y2) sono generati, date le medie e le deviazioni standard per ciascun gruppo. Assumiamo che i valori del QI seguano una distribuzione normale in ciascun gruppo.\n\n\n\n60.5.2 Quantità generate\ny1_rep[i] = normal_rng(mu_1, sigma_1);\ny2_rep[i] = normal_rng(mu_2, sigma_2);\nQueste righe generano dati “replicati” basati sul modello stimato. Questi possono essere utilizzati per il controllo del modello (posterior predictive checks).\n\n\n60.5.3 Interpretazione dei risultati\n\nmu_1 e mu_2: Ci dicono i valori QI medi stimati per ciascun gruppo.\nsigma_1 e sigma_2: Ci dicono quanto variano i valori del QI all’interno di ciascun gruppo.\ndelta: Ci dice quanto è grande la differenza nei valori dei QI medi tra i due gruppi.\ncohen_d: Ci fornisce una misura standardizzata della dimensione dell’effetto.\n\n\n\n60.5.4 Conclusione\nQuesto modello ci permette di:\n\nStimare i valori dei QI medi e la loro variabilità per ciascun gruppo.\nQuantificare la differenza tra i gruppi e la sua incertezza.\nCalcolare una misura standardizzata della dimensione dell’effetto (Cohen’s d).\nGenerare previsioni basate sul modello per future osservazioni.\n\nIl vantaggio principale di questo approccio bayesiano è che otteniamo distribuzioni di probabilità complete per tutti i parametri di interesse, permettendoci di fare affermazioni probabilistiche sulla differenza tra i gruppi e sulla dimensione dell’effetto.\nEseguiamo il campionamento MCMC:\n\nsample = model.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=1000, iter_warmup=1000,\n    show_progress=False, show_console=False\n)\n\n10:30:52 - cmdstanpy - INFO - CmdStan start processing\n10:30:52 - cmdstanpy - INFO - Chain [1] start processing\n10:30:52 - cmdstanpy - INFO - Chain [2] start processing\n10:30:52 - cmdstanpy - INFO - Chain [3] start processing\n10:30:52 - cmdstanpy - INFO - Chain [4] start processing\n10:30:52 - cmdstanpy - INFO - Chain [1] done processing\n10:30:52 - cmdstanpy - INFO - Chain [3] done processing\n10:30:52 - cmdstanpy - INFO - Chain [2] done processing\n10:30:52 - cmdstanpy - INFO - Chain [4] done processing\n10:30:52 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_lpdf: Scale parameter is 0, but must be positive! (in 'kid-score.stan', line 30, column 2 to column 29)\n    Exception: normal_lpdf: Scale parameter is 0, but must be positive! (in 'kid-score.stan', line 30, column 2 to column 29)\nConsider re-running with show_console=True if the above output is unclear!\n\n\nEsaminiamo le tracce:\n\n_ = az.plot_trace(\n    sample, \n    figsize=(9, 12), \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    divergences=\"bottom\"\n)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63722/1925110735.py:7: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\nLe distribuzioni predittive a posteriori sono adeguate, senza essere perfette.\n\nidata = az.from_cmdstanpy(\n    posterior=sample, \n    posterior_predictive=['y1_rep'], \n    observed_data={\"y1\": stan_data[\"y1\"]}\n)\n_ = az.plot_ppc(idata, data_pairs={\"y1\": \"y1_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\n\nidata = az.from_cmdstanpy(\n    posterior=sample, \n    posterior_predictive=['y2_rep'], \n    observed_data={\"y2\": stan_data[\"y2\"]}\n)\n_ = az.plot_ppc(idata, data_pairs={\"y2\": \"y2_rep\"}, num_pp_samples=500)\n\n\n\n\n\n\n\n\nUn sommario delle distribuzioni a posteriori dei parametri si ottiene nel modo seguente:\n\naz.summary(\n    sample, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.28\n1.04\n87.33\n91.18\n0.02\n0.01\n3990.38\n2947.67\n1.0\n\n\nmu_2\n77.61\n2.27\n73.61\n82.01\n0.03\n0.02\n4317.58\n2940.56\n1.0\n\n\nsigma_1\n19.03\n0.73\n17.70\n20.42\n0.01\n0.01\n4729.21\n3162.76\n1.0\n\n\nsigma_2\n22.27\n1.63\n19.35\n25.38\n0.02\n0.02\n4419.97\n2908.53\n1.0\n\n\ndelta\n11.67\n2.47\n6.89\n16.32\n0.04\n0.03\n4346.03\n2887.27\n1.0\n\n\ncohen_d\n0.56\n0.12\n0.33\n0.78\n0.00\n0.00\n4334.34\n2953.62\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#modello-robusto",
    "href": "chapters/mcmc/10_stan_two_groups.html#modello-robusto",
    "title": "60  Confronto tra due gruppi",
    "section": "60.6 Modello Robusto",
    "text": "60.6 Modello Robusto\nUn modello bayesiano robusto per il confronto tra due medie indipendenti può gestire deviazioni standard disuguali e outlier sostituendo la verosimiglianza normale con quella della distribuzione t di Student. Utilizzare una distribuzione t di Student al posto di una normale rende il modello più resistente agli outlier. La distribuzione t di Student ha code più pesanti rispetto alla normale, il che significa che è meno influenzata da valori estremi nei dati. Questo è particolarmente utile quando si sospetta la presenza di outlier nei dati o quando le deviazioni standard tra i gruppi sono disuguali. In questo modo, il modello bayesiano robusto offre stime più affidabili delle medie e delle deviazioni standard dei gruppi, nonché della differenza tra le medie e della dimensione dell’effetto.\n\nstan_file_t = os.path.join(project_directory, 'stan', 'kid-score-t.stan')\nmodel_t = CmdStanModel(stan_file=stan_file_t)\nprint(model_t.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response time (group 1)\n  vector[N2] y2;  // response time (group 2)\n}\nparameters {\n  real mu_2;  // mean of group 2\n  real delta;  // difference in means\n  real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n  real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n  real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n}\ntransformed parameters {\n  real mu_1 = mu_2 + delta; \n}\nmodel {\n  y1 ~ student_t(nu, mu_1, sigma_1);\n  y2 ~ student_t(nu, mu_2, sigma_2);\n  // priors\n  mu_2 ~ normal(80, 20);\n  delta ~ normal(0, 10);\n  sigma_1 ~ normal(0, 10);\n  sigma_2 ~ normal(0, 10);\n  nu ~ gamma(2, 0.1);\n}\ngenerated quantities {\n  vector[N1] y1rep;\n  vector[N2] y2rep;\n  real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n  real cohen_d = delta / pooled_sd;\n  \n  for (i in 1:N1) {\n    y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n  }\n}\n\n\n\n\nsample_t = model_t.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=1000, iter_warmup=1000,\n    show_progress=False, show_console=False\n)\n\n10:31:20 - cmdstanpy - INFO - CmdStan start processing\n10:31:20 - cmdstanpy - INFO - Chain [1] start processing\n10:31:20 - cmdstanpy - INFO - Chain [2] start processing\n10:31:20 - cmdstanpy - INFO - Chain [3] start processing\n10:31:20 - cmdstanpy - INFO - Chain [4] start processing\n10:31:20 - cmdstanpy - INFO - Chain [1] done processing\n10:31:20 - cmdstanpy - INFO - Chain [3] done processing\n10:31:20 - cmdstanpy - INFO - Chain [2] done processing\n10:31:20 - cmdstanpy - INFO - Chain [4] done processing\n10:31:20 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-t.stan', line 18, column 2 to column 36)\nConsider re-running with show_console=True if the above output is unclear!\n\n\nNel caso presente, usare un modello robusto non produce nessuna differenza rispetto al modello precedente in quanto non ci sono deviazoni importanti rispetto alla gaussianità e le due deviazioni standard sono simili.\n\naz.summary(\n    sample_t, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.49\n1.07\n87.43\n91.37\n0.02\n0.01\n3892.59\n3003.83\n1.0\n\n\nmu_2\n78.39\n2.29\n74.04\n82.63\n0.05\n0.03\n2486.44\n2273.07\n1.0\n\n\nsigma_1\n18.43\n0.77\n17.04\n19.94\n0.01\n0.01\n3278.45\n2545.50\n1.0\n\n\nsigma_2\n21.71\n1.62\n18.77\n24.82\n0.03\n0.02\n3175.33\n2299.83\n1.0\n\n\ndelta\n11.11\n2.50\n6.40\n15.82\n0.05\n0.04\n2487.74\n2084.50\n1.0\n\n\ncohen_d\n0.55\n0.13\n0.33\n0.81\n0.00\n0.00\n2496.90\n2123.93\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#modello-con-iper-priors",
    "href": "chapters/mcmc/10_stan_two_groups.html#modello-con-iper-priors",
    "title": "60  Confronto tra due gruppi",
    "section": "60.7 Modello con Iper-priors",
    "text": "60.7 Modello con Iper-priors\nIl seguente modello bayesiano per il confronto tra due medie indipendenti utilizza una distribuzione di Student’s t per gestire deviazioni standard disuguali e outlier. Inoltre, include iper-priors per una maggiore flessibilità nella definizione dei parametri delle distribuzioni a priori, che vengono stimate dai dati. Questo approccio permette di incorporare in modo più efficace le incertezze sui parametri dei priors stessi, migliorando la robustezza del modello.\n\nstan_file_h = os.path.join(project_directory, 'stan', 'kid-score-h.stan')\nmodel_h = CmdStanModel(stan_file=stan_file_h)\nprint(model_t.code())\n\ndata {\n  int&lt;lower=0&gt; N1;  // number of observations (group 1)\n  int&lt;lower=0&gt; N2;  // number of observations (group 2)\n  vector[N1] y1;  // response time (group 1)\n  vector[N2] y2;  // response time (group 2)\n}\nparameters {\n  real mu_2;  // mean of group 2\n  real delta;  // difference in means\n  real&lt;lower=0&gt; sigma_1;  // scale parameter for group 1\n  real&lt;lower=0&gt; sigma_2;  // scale parameter for group 2\n  real&lt;lower=1&gt; nu;  // degrees of freedom of student's t distribution\n}\ntransformed parameters {\n  real mu_1 = mu_2 + delta; \n}\nmodel {\n  y1 ~ student_t(nu, mu_1, sigma_1);\n  y2 ~ student_t(nu, mu_2, sigma_2);\n  // priors\n  mu_2 ~ normal(80, 20);\n  delta ~ normal(0, 10);\n  sigma_1 ~ normal(0, 10);\n  sigma_2 ~ normal(0, 10);\n  nu ~ gamma(2, 0.1);\n}\ngenerated quantities {\n  vector[N1] y1rep;\n  vector[N2] y2rep;\n  real pooled_sd = sqrt((sigma_1^2 + sigma_2^2) / 2);\n  real cohen_d = delta / pooled_sd;\n  \n  for (i in 1:N1) {\n    y1rep[i] = student_t_rng(nu, mu_1, sigma_1);\n  }\n  for (i in 1:N2) {\n    y2rep[i] = student_t_rng(nu, mu_2, sigma_2);\n  }\n}\n\n\n\n\nsample_h = model_h.sample(\n    data=stan_data, seed=123, chains=4,\n    iter_sampling=2_000, iter_warmup=1_000,\n    show_progress=False, show_console=False\n)\n\n10:31:27 - cmdstanpy - INFO - CmdStan start processing\n10:31:27 - cmdstanpy - INFO - Chain [1] start processing\n10:31:27 - cmdstanpy - INFO - Chain [2] start processing\n10:31:27 - cmdstanpy - INFO - Chain [3] start processing\n10:31:27 - cmdstanpy - INFO - Chain [4] start processing\n10:31:28 - cmdstanpy - INFO - Chain [1] done processing\n10:31:28 - cmdstanpy - INFO - Chain [4] done processing\n10:31:28 - cmdstanpy - INFO - Chain [2] done processing\n10:31:28 - cmdstanpy - INFO - Chain [3] done processing\n10:31:28 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is 0, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nException: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\n    Exception: student_t_lpdf: Scale parameter is inf, but must be positive finite! (in 'kid-score-h.stan', line 43, column 2 to column 36)\nConsider re-running with show_console=True if the above output is unclear!\n10:31:28 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 1 had 25 divergent transitions (1.2%)\n    Chain 2 had 8 divergent transitions (0.4%)\n    Chain 3 had 24 divergent transitions (1.2%)\n    Chain 4 had 12 divergent transitions (0.6%)\n    Use the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n\n\nAnche in questo caso, la risposta non cambia:\n\naz.summary(\n    sample_h, \n    var_names=['mu_1', 'mu_2', 'sigma_1', 'sigma_2', 'delta', 'cohen_d'], \n    round_to=2\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_1\n89.52\n1.03\n87.65\n91.54\n0.01\n0.01\n8653.78\n6400.92\n1.0\n\n\nmu_2\n78.30\n2.29\n73.95\n82.52\n0.03\n0.02\n5688.16\n5777.55\n1.0\n\n\nsigma_1\n18.43\n0.79\n16.97\n19.94\n0.01\n0.01\n7954.84\n5392.71\n1.0\n\n\nsigma_2\n21.88\n1.65\n18.88\n25.08\n0.02\n0.01\n9745.94\n5250.42\n1.0\n\n\ndelta\n11.22\n2.50\n6.51\n15.83\n0.03\n0.02\n5590.51\n6029.02\n1.0\n\n\ncohen_d\n0.56\n0.13\n0.32\n0.79\n0.00\n0.00\n5626.06\n5815.05\n1.0\n\n\n\n\n\n\n\nIl nostro obiettivo è comprendere se le medie dei due gruppi sono diverse, e l’incertezza associata alla stima a posteriori del parametro delta è fondamentale per rispondere a questa domanda. Se l’intervallo di credibilità associato a delta non include lo 0, allora possiamo concludere con un certo grado di sicurezza che le medie dei due gruppi sono diverse. In altre parole, se l’intervallo di credibilità non contiene lo 0, allora ci sono prove convincenti che le medie dei due gruppi sono diverse.\nNel caso presente, l’intervallo di credibilità al 94% non include lo 0. Pertanto, possiamo concludere, con un livello di sicurezza soggettivo del 94%, che il QI dei bambini le cui madri hanno completato le scuole superiori tende ad essere più elevato rispetto a quello dei bambini le cui madri non hanno completato le scuole superiori.\n\n_ = az.plot_posterior(sample_h, var_names=\"delta\", ref_val=0, figsize=(6, 3))\n\n\n\n\n\n\n\n\nLa figura seguente mostra la distribuzione a posteriori della grandezza dell’effetto.\n\n_ = az.plot_posterior(sample_h, var_names=\"cohen_d\", ref_val=0, figsize=(6, 3))\n\n\n\n\n\n\n\n\nPossiamo dunque concludere che, per ciò che concerne l’effetto della scolarità della madre sul quoziente di intelligenza del bambino, la dimensione dell’effetto è “media”.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#verifica-di-ipotesi-bayesiana",
    "href": "chapters/mcmc/10_stan_two_groups.html#verifica-di-ipotesi-bayesiana",
    "title": "60  Confronto tra due gruppi",
    "section": "60.8 Verifica di ipotesi bayesiana",
    "text": "60.8 Verifica di ipotesi bayesiana\nCome ulteriore approfondimento di questa analisi statistica, possiamo esaminare l’approccio bayesiano equivalente al test di ipotesi tradizionale.\nDopo aver ottenuto un campione dalla distribuzione a posteriori del parametro di interesse \\(\\mu\\) per ciascun gruppo, possiamo porci la domanda: qual è la probabilità che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell’altro gruppo? Per rispondere a questa domanda, utilizzeremo campioni casuali dalle distribuzioni a posteriori dei parametri. Confronteremo le coppie di valori campionati dalle due distribuzioni a posteriori del parametro di interesse e calcoleremo la media di tali confronti. Questo ci fornirà un’indicazione sulla probabilità che il QI di un bambino in un gruppo sia maggiore di quello di un bambino nell’altro gruppo, basandoci sulla distribuzione a posteriori dei parametri stimati dal modello.\nPer eseguire un test d’ipotesi per calcolare la probabilità che $ _1 &gt; _2 $ utilizzando il modello Stan fornito e cmdstanpy, è necessario estrarre i campioni posteriori per i parametri \\(\\mu_1\\) e \\(\\mu_2\\) dopo aver adattato il modello. Successivamente, è possibile calcolare la probabilità basandosi sui campioni posteriori. Ad esempio, ci possiamo chiedere quale sia la probabilità che un bambino la cui madre ha completato la scuola superiore abbia un QI maggiore di un bambino la cui madre non ha completato la scuola superiore.\n\n# Extract the posterior samples for mu_1 and mu_2\nposterior = sample_h.draws_pd()\nposterior['mu_1'] = posterior['mu_2'] + posterior['delta']\n\n# Compute the probability that mu_1 &gt; mu_2\nprob_mu1_greater_mu2 = np.mean(posterior['mu_1'] &gt; posterior['mu_2'])\n\nprint(f\"Probability that mu_1 &gt; mu_2: {prob_mu1_greater_mu2:.4f}\")\n\nProbability that mu_1 &gt; mu_2: 1.0000\n\n\nUna tale probabilità è effettivamente uguale a 1 il che conferma il risultato precedente, ovvero l’iportanza del livello di istruzione della madre per il QI del figlio.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#commenti-e-considerazioni-finali",
    "href": "chapters/mcmc/10_stan_two_groups.html#commenti-e-considerazioni-finali",
    "title": "60  Confronto tra due gruppi",
    "section": "60.9 Commenti e considerazioni finali",
    "text": "60.9 Commenti e considerazioni finali\nIn questo capitolo abbiamo esaminato la procedura bayesiana per calcolare la distribuzione a posteriori della differenza tra le medie di due gruppi indipendenti. Inoltre, abbiamo esplorato il calcolo della dimensione dell’effetto in termini bayesiani. Nell’esempio trattato, abbiamo considerato il caso in cui la verosimiglianza è descritta da una distribuzione Gaussiana. Tuttavia, va sottolineato che la scelta di una distribuzione specifica per la verosimiglianza non è vincolante nella statistica bayesiana. È possibile utilizzare qualsiasi distribuzione di probabilità, purché sia adeguata ai dati del campione.\nNel caso del confronto tra le medie di due gruppi indipendenti, una distribuzione molto utilizzata è la distribuzione \\(t\\) di Student. Questa distribuzione è particolarmente vantaggiosa quando si desidera condurre un’analisi statistica “robusta”, ovvero un’analisi che non sia influenzata da osservazioni anomale o outlier presenti nei dati. Per questo motivo, la distribuzione \\(t\\) di Student è spesso preferita quando si lavora con dati che potrebbero contenere valori anomali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/10_stan_two_groups.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/10_stan_two_groups.html#informazioni-sullambiente-di-sviluppo",
    "title": "60  Confronto tra due gruppi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBland, J. M., & Altman, D. G. (2011). Comparisons within randomised groups can be very misleading. Bmj, 342.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>Confronto tra due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html",
    "title": "61  Modello di Poisson (1)",
    "section": "",
    "text": "Introduction\nNel Capitolo 48, abbiamo determinato la distribuzione a posteriori sia attraverso il metodo basato su griglia, sia tramite la derivazione analitica utilizzando la famiglia coniugata gamma-poisson. In questo capitolo, affronteremo lo stesso problema utilizzando Stan.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#dati",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#dati",
    "title": "61  Modello di Poisson (1)",
    "section": "61.1 Dati",
    "text": "61.1 Dati\nRiconsideriamo lo stesso problema discusso nella sezione ?sec-poisson-model. I dati disponibili sono:\n\ny = np.array([2, 1, 3, 2, 2, 1, 1, 1])",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#modello-di-poisson-con-stan",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#modello-di-poisson-con-stan",
    "title": "61  Modello di Poisson (1)",
    "section": "61.2 Modello di Poisson con Stan",
    "text": "61.2 Modello di Poisson con Stan\nNel modello Stan utilizzeremo una verosimiglianza di Poisson e una distribuzione a priori per il parametro \\(\\lambda\\) modellata da una distribuzione Gamma con parametri \\(\\alpha_{\\text{prior}} = 9\\) e \\(\\beta_{\\text{prior}} = 2\\).\n\nstan_file = os.path.join(project_directory, \"stan\", \"gamma_poisson_mcmc.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  array[N] int&lt;lower=0&gt; y; // dati osservati\n  real&lt;lower=0&gt; alpha_prior; // parametro alpha della priori Gamma\n  real&lt;lower=0&gt; beta_prior; // parametro beta della priori Gamma\n}\nparameters {\n  real&lt;lower=0&gt; lambda; // parametro di interesse\n}\nmodel {\n  // Priori\n  lambda ~ gamma(alpha_prior, beta_prior);\n  \n  // Verosimiglianza\n  y ~ poisson(lambda);\n}\ngenerated quantities {\n  real alpha_post = alpha_prior + sum(y);\n  real beta_post = beta_prior + N;\n}\n\n\n\nSistemiamo i dati nel formato richiesto da Stan.\n\nN = len(y)\nalpha_prior = 9\nbeta_prior = 2\n\n# Preparazione dei dati per Stan\nstan_data = {\"N\": N, \"y\": y, \"alpha_prior\": alpha_prior, \"beta_prior\": beta_prior}\nprint(stan_data)\n\n{'N': 8, 'y': array([2, 1, 3, 2, 2, 1, 1, 1]), 'alpha_prior': 9, 'beta_prior': 2}\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEstraiamo un campione casuale dalla distribuzione a posteriori di lambda.\n\nlambda_samples = fit.stan_variable(\"lambda\")\n\nCalcoliamo i parametri della Gamma a posteriori teorica.\n\nalpha_post = alpha_prior + np.sum(y)\nbeta_post = beta_prior + N\n\nCreiamo un istogramma con i campioni della distribuzione a posteriori di \\(\\lambda\\) e sovrapposta la densità teorica della distribuzione a posteriori.\n\nplt.figure(figsize=(10, 6))\n\n# Istogramma normalizzato dei campioni MCMC\nplt.hist(\n    lambda_samples,\n    bins=50,\n    density=True,\n    alpha=0.7,\n    label=\"Distribuzione a posteriori empirica\",\n)\n\n# Gamma teorica\nx = np.linspace(0, max(lambda_samples), 200)\ngamma_pdf = stats.gamma.pdf(x, a=alpha_post, scale=1 / beta_post)\nplt.plot(x, gamma_pdf, \"r-\", lw=2, label=\"Distribuzione Gamma teorica\")\n\n# Personalizzazione del grafico\nplt.title(\"Distribuzione a posteriori di lambda\")\nplt.xlabel(\"lambda\")\nplt.ylabel(\"Densità\")\nplt.legend()\n\n# Aggiungiamo informazioni sui parametri\nplt.text(\n    0.95,\n    0.95,\n    f\"alpha_post = {alpha_post:.2f}\\nbeta_post = {beta_post:.2f}\",\n    transform=plt.gca().transAxes,\n    verticalalignment=\"top\",\n    horizontalalignment=\"right\",\n    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n)\n\nText(0.95, 0.95, 'alpha_post = 22.00\\nbeta_post = 10.00')\n\n\n\n\n\n\n\n\n\nUsiamo ArviZ per un sommario della distribuzione a posteriori del parametro \\(\\lambda\\).\n\naz.summary(fit, var_names=\"lambda\")\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nlambda\n2.214\n0.467\n1.395\n3.11\n0.008\n0.006\n3262.0\n4279.0\n1.0\n\n\n\n\n\n\n\nGeneriamo l’intervallo di credibilità al 94% per la distribuzione a posteriori del parametro lambda.\n\naz.plot_posterior(fit, var_names=\"lambda\")\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, analizzando i dati disponibili e utilizzando una distribuzione a priori Gamma(9, 2), possiamo affermare con un grado di certezza soggettivo del 94% che il tasso stimato di occorrenza dell’evento considerato sia di 2.2 compulsioni all’ora, con un intervallo di credibilità compreso tra 1.4 e 3.1.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/11_stan_poisson_model_1.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/11_stan_poisson_model_1.html#informazioni-sullambiente-di-sviluppo",
    "title": "61  Modello di Poisson (1)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Fri Aug 16 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\narviz     : 0.18.0\nscipy     : 1.14.0\nlogging   : 0.5.1.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\ncmdstanpy : 1.2.4",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Modello di Poisson (1)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html",
    "title": "62  Modello di Poisson (2)",
    "section": "",
    "text": "Introduction\nNel capitolo precedente abbiamo esaminato il processo di derivazione della distribuzione a posteriori per i parametri della distribuzione Gamma, la quale viene impiegata quando si adotta un prior Gamma per una verosimiglianza di Poisson. In questo capitolo, useremo tale metodo per affrontare una questione relativa all’analisi di un set di dati reali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#domanda-della-ricerca",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#domanda-della-ricerca",
    "title": "62  Modello di Poisson (2)",
    "section": "62.1 Domanda della ricerca",
    "text": "62.1 Domanda della ricerca\nCome spiegato qui, i dati che esamineremo sono raccolti dal Washington Post con lo scopo di registrare ogni sparatoria mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1° gennaio 2015. Il Washington Post ha adottato un approccio sistematico e accurato nella raccolta di queste informazioni, fornendo dati che possono essere utili per valutare i problemi legati alla violenza delle forze di polizia negli Stati Uniti.\nLo scopo della presente analisi dei dati è determinare il tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, e fornire una stima dell’incertezza associata a questo valore.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#importazione-e-pre-processing-dei-dati",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#importazione-e-pre-processing-dei-dati",
    "title": "62  Modello di Poisson (2)",
    "section": "62.2 Importazione e pre-processing dei dati",
    "text": "62.2 Importazione e pre-processing dei dati\n\nurl = \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat = pd.read_csv(url)\nfps_dat.head()\n\n\n# Convert date\nfps_dat[\"date\"] = pd.to_datetime(fps_dat[\"date\"])\n\n# Create a new column 'year' to store the year information from the 'date' column\nfps_dat[\"year\"] = fps_dat[\"date\"].dt.year\n\nfps_dat.columns\n\nIndex(['id', 'date', 'threat_type', 'flee_status', 'armed_with', 'city',\n       'county', 'state', 'latitude', 'longitude', 'location_precision',\n       'name', 'age', 'gender', 'race', 'race_source',\n       'was_mental_illness_related', 'body_camera', 'agency_ids', 'year'],\n      dtype='object')\n\n\n\n# Filter out rows with year equal to 2024\nfps = fps_dat[fps_dat[\"year\"] != 2024]\n\n# Count occurrences of each year in fps\nyear_counts = fps[\"year\"].value_counts()\nprint(year_counts)\n\nyear\n2023    1164\n2022    1095\n2021    1050\n2020    1020\n2015     995\n2019     994\n2018     991\n2017     984\n2016     959\nName: count, dtype: int64\n\n\nCreiamo un DataFrame con i dati necessari per PyMC.\n\nyear_counts.values\n\narray([1164, 1095, 1050, 1020,  995,  994,  991,  984,  959])\n\n\n\n# Convert year_counts Series to a DataFrame\ndf = year_counts.reset_index()  # This converts the index (year) to a column and resets the index of the DataFrame\ndf.columns = ['year', 'events']  # Renaming the columns to 'year' and 'events'\n\n# Now, df is the DataFrame you wanted, with 'year' and 'events' columns\nprint(df)\n\n   year  events\n0  2023    1164\n1  2022    1095\n2  2021    1050\n3  2020    1020\n4  2015     995\n5  2019     994\n6  2018     991\n7  2017     984\n8  2016     959",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#modello-di-poisson",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#modello-di-poisson",
    "title": "62  Modello di Poisson (2)",
    "section": "62.3 Modello di Poisson",
    "text": "62.3 Modello di Poisson\nIl nostro interesse riguarda il tasso di occorrenza di sparatorie fatali da parte della polizia per anno. Indicheremo questo tasso come \\(\\theta\\), e il suo intervallo di valori possibili è \\([0, \\infty)\\). Un modello di Poisson rappresenta tipicamente il punto di partenza per l’analisi di dati relativi alle frequenze assolute di un evento in un intervallo di tempo fissato. Il modello presuppone che i dati seguano una distribuzione di Poisson con un parametro di tasso \\(\\lambda\\):\n\\[\nP(Y = y \\mid \\lambda) = \\frac{\\lambda^y \\cdot e^{-\\lambda}}{y!}, \\quad \\text{per} \\quad y = 0, 1, 2, \\ldots\n\\]",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#distribuzione-a-priori",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#distribuzione-a-priori",
    "title": "62  Modello di Poisson (2)",
    "section": "62.4 Distribuzione a priori",
    "text": "62.4 Distribuzione a priori\nCome distribuzione a priori per il parametro \\(\\lambda\\) nel modello di Poisson possiamo usare la distribuzione Gamma, poiché è una scelta coniugata. Ciò significa che, quando viene combinata con la distribuzione di Poisson come verosimiglianza dei dati, la distribuzione Gamma produce una distribuzione a posteriori con una forma analitica semplice. Questa caratteristica semplifica il processo di inferenza bayesiana.\nNel nostro caso, il parametro \\(\\lambda\\) rappresenta il tasso di occorrenza di sparatorie fatali per anno negli Stati Uniti. Prima di osservare i dati effettivi riportati dal Washington Post, abbiamo una conoscenza limitata su tale fenomeno. Pertanto, dobbiamo specificare una distribuzione a priori per \\(\\lambda\\) che rifletta la nostra incertezza iniziale. As esempio, possiamo ipotizzare che ci sia, in media, una sparatoria mortale per stato al mese, quindi 12 sparatorie mortali all’anno per stato. Questo ci porta a una stima iniziale di 600 sparatorie fatali negli Stati Uniti ogni anno. Dato che non siamo molto sicuri di questa ipotesi, vogliamo specificare una distribuzione a priori con un certo grado di incertezza. Imponiamo dunque una deviazione standard pari a 200.\nPer visualizzare la distribuzione a priori per il parametro \\(\\lambda\\), creiamo un istogramma della distribuzione Gamma con i parametri specificati usando PyMC.\n\n# Parameters for the Gamma distribution\nmu = 600\nsigma = 200\n\n# Convert mu and sigma to shape (k) and scale (theta) parameters\ntheta = sigma**2 / mu\nk = mu / theta\n\n# Draw samples from the Gamma distribution\nx_draws = stats.gamma.rvs(a=k, scale=theta, size=50000, random_state=2)\n\n# Plot the histogram of the drawn samples\nsns.histplot(x_draws, kde=False)\n\n# Add labels and title\nplt.xlabel(\"Tasso di occorrenza (anno)\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione Gamma con mu = 600 e sigma = 200\")\nplt.show()",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#modello-di-poisson-con-stan",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#modello-di-poisson-con-stan",
    "title": "62  Modello di Poisson (2)",
    "section": "62.5 Modello di Poisson con Stan",
    "text": "62.5 Modello di Poisson con Stan\nFormuliamo il modello di Poisson usando questi iper-parametri per la distribuzione a priori del parametro \\(\\lambda\\) (rate) della distribuzione di Poisson.\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_model2.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y; // dati osservati  \n}\nparameters {\n  real&lt;lower=0&gt; rate; // parametro rate per la distribuzione Poisson\n}\nmodel {\n  // Priori\n  rate ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y ~ poisson(rate);\n}\n\n\n\n\n# Caricare i dati\nstan_data = {\n    \"y\": [1164, 1095, 1050, 1020, 995, 994, 991, 984, 959],\n    \"N\": 9,\n    \"mu\": 600,\n    \"sigma\": 200\n}\nprint(stan_data)\n\n{'y': [1164, 1095, 1050, 1020, 995, 994, 991, 984, 959], 'N': 9, 'mu': 600, 'sigma': 200}\n\n\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro rate.\n\naz.plot_trace(trace, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\nIl modello converge rapidamente e i grafici delle tracce sembrano ben mescolati.\nGeneriamo un sommario numerico della distribuzione a posteriori.\n\naz.summary(trace)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n1027.577\n10.825\n1007.56\n1048.1\n0.207\n0.146\n2737.0\n3896.0\n1.0\n\n\n\n\n\n\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y; // dati osservati  \n}\nparameters {\n  real&lt;lower=0&gt; rate; // parametro rate per la distribuzione Poisson\n}\nmodel {\n  // Priori\n  rate ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y ~ poisson(rate);\n}\n\n\n\nUsiamo ArviZ per generare l’intervallo di credibilità al 94% per la distribuzione a posteriori del parametro rate.\n\naz.plot_posterior(trace, var_names=\"rate\")\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, analizzando i dati compresi tra il 2015 e il 2023 e basandoci su una distribuzione a priori che presuppone una sparatoria mortale al mese per stato, possiamo concludere con un grado di certezza soggettivo del 94% che il tasso stimato di sparatorie fatali da parte della polizia negli Stati Uniti sia di 1028 casi all’anno, con un intervallo di credibilità compreso tra 1008 e 1048.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#derivazione-analitica",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#derivazione-analitica",
    "title": "62  Modello di Poisson (2)",
    "section": "62.6 Derivazione analitica",
    "text": "62.6 Derivazione analitica\nPer derivare i parametri della distribuzione Gamma (\\(\\alpha\\) e \\(\\beta\\)) conoscendo la media (\\(\\mu\\)) e la deviazione standard (\\(\\sigma\\)), possiamo utilizzare le seguenti relazioni:\n\n\\(\\alpha = (\\frac{\\mu}{\\sigma})^2\\)\n\\(\\beta = \\frac{\\mu}{\\sigma^2}\\)\n\nQueste formule si basano sul fatto che la media della distribuzione Gamma è data da \\(\\frac{\\alpha}{\\beta}\\), mentre la varianza è \\(\\frac{\\alpha}{\\beta^2}\\). Inoltre, la deviazione standard è la radice quadrata della varianza.\nLa distribuzione a posteriori per \\(\\lambda\\), data una verosimiglianza di Poisson e una distribuzione a priori gamma, è ancora una distribuzione gamma con parametri aggiornati. Possiamo calcolare i parametri della distribuzione a posteriori nel modo seguente:\n\nParametro di forma a posteriori (α_post) = α_prior + Σ(y_i), dove Σ(y_i) rappresenta la somma dei dati osservati.\nParametro di tasso a posteriori (β_post) = β_prior + n, dove n è il numero di punti dati.\n\nCon questi parametri aggiornati, possiamo poi calcolare la media a posteriori della distribuzione gamma e l’intervallo di credibilità.\n\ndata = df[\"events\"]\n\n# Prior hyperparameters\nalpha_prior = (mu / sigma)**2\nbeta_prior = mu / sigma**2\n\n# Data summary\nn = len(df[\"events\"])\nsum_y = np.sum(df[\"events\"])\n\n# Posterior hyperparameters\nalpha_post = alpha_prior + sum_y\nbeta_post = beta_prior + n\n\n# Posterior distribution (Gamma)\nposterior_gamma = stats.gamma(alpha_post, scale=1 / beta_post)\n\n# Calculate the mean and credibility interval (94%)\nposterior_mean = posterior_gamma.mean()\ncredible_interval = posterior_gamma.interval(0.94)\n\nprint(\"Estimated Rate (Posterior Mean):\", posterior_mean)\nprint(\"Credibility Interval (94%):\", credible_interval)\n\nEstimated Rate (Posterior Mean): 1027.287853577371\nCredibility Interval (94%): (1007.3046264976574, 1047.4587209661117)\n\n\nL’output delle istruzioni precedenti fornisce il tasso stimato a posteriori e l’intervallo di credibilità al 94%. A causa di approssimazioni numeriche, i valori non coincidono esattamente con i risultati ottenuti con PyMC, ma sono molto simili.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#vittime-non-armate",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#vittime-non-armate",
    "title": "62  Modello di Poisson (2)",
    "section": "62.7 Vittime non armate",
    "text": "62.7 Vittime non armate\nConsideriamo ora uno studio di Ross et al. (2021). Nell’introduzione allo studio, gli autori affermano che studi precedenti hanno dimostrato che la polizia negli Stati Uniti uccide cittadini neri rispetto a cittadini bianchi a tassi più elevati di quanto ci si potrebbe aspettare secondo un modello generativo in cui la polizia incontra e uccide cittadini neri e bianchi in proporzione alle loro dimensioni relative della popolazione (ad esempio, Gabrielson et al., 2014; The Guardian, 2016; Takagi, 1981). Tuttavia, l’utilità di questi studi nel rilevare disparità razziali ingiustificabili nel comportamento della polizia è stata messa in discussione (Cesario et al., 2019; Fryer, 2017; Selby et al., 2016; Tregle et al., 2019) perché la polizia uccide principalmente individui - neri o bianchi - che erano armati e impegnati in attività criminali al momento dell’interazione (Ross, 2015; Selby et al., 2016). Le differenze sottostanti nei tassi di attività criminale armata specifici per la razza, piuttosto che - o oltre a - pregiudizi e/o bias stereotipati non intenzionali (Payne, 2006) da parte della polizia, sono state quindi citate come possibili cause dell’aumento dei tassi di sparatorie della polizia contro gli afroamericani. Tuttavia, Ross et al. (2021) fanno notare che le disparità a discapito degli individui afro-americani nell’uso della forza da parte della polizia statunitense persistono nel caso di individui disarmati sia a livello non letale (Fryer, 2016) che letale (Ross, 2015).\nPer verificare questa affermazione di Ross et al. (2021), usiamo i dati forniti dal Washington Post. Iniziamo a considerare il numero di sparatorie fatali da parte delle polizia statunitense nei confronti di un individuo disarmato caucasico.\n\n# Filter the dataframe to include only rows where the individual was unarmed\nunarmed_events = fps[fps[\"armed_with\"] == \"unarmed\"]\n\n# Filter the dataframe to create two separate dataframes for white and non-white races\nwhite_df = unarmed_events[unarmed_events[\"race\"] == \"W\"]\nnon_white_df = unarmed_events[unarmed_events[\"race\"] != \"W\"]\n\nprint(\"\\nWhite Race DataFrame:\")\nprint(white_df.head())\n\n\nWhite Race DataFrame:\n      id       date threat_type flee_status armed_with         city  \\\n8     16 2015-01-06    accident         not    unarmed   Burlington   \n72   342 2015-01-29        move        foot    unarmed   Stillwater   \n76   114 2015-02-02        flee        foot    unarmed  Hummelstown   \n119  159 2015-02-17        flee        foot    unarmed  Springfield   \n136  371 2015-02-23        move         not    unarmed        Omaha   \n\n         county state   latitude  longitude location_precision  \\\n8    Des Moines    IA  40.809250 -91.118875      not_available   \n72        Payne    OK  36.121177 -97.050127      not_available   \n76      Dauphin    PA  40.273404 -76.712841      not_available   \n119      Greene    MO  37.225250 -93.319432      not_available   \n136     Douglas    NE  41.244051 -95.933308      not_available   \n\n                name   age  gender race    race_source  \\\n8      Autumn Steele  34.0  female    W  not_available   \n72      Ralph Willis  42.0    male    W  not_available   \n76     David Kassick  59.0    male    W  not_available   \n119  Michael Ireland  31.0    male    W  not_available   \n136     Daniel Elrod  39.0    male    W  not_available   \n\n     was_mental_illness_related  body_camera agency_ids  year  \n8                         False         True        287  2015  \n72                        False        False        164  2015  \n76                        False        False        303  2015  \n119                       False        False        350  2015  \n136                       False        False        158  2015  \n\n\n\nprint(\"\\nNon-White Race DataFrame:\")\nprint(non_white_df.head())\n\n\nNon-White Race DataFrame:\n     id       date threat_type flee_status armed_with         city    county  \\\n2     5 2015-01-03        move         not    unarmed      Wichita  Sedgwick   \n17   36 2015-01-08      attack         not    unarmed       Strong     Union   \n62  352 2015-01-26        flee         car    unarmed       Tahoka      Lynn   \n83  116 2015-02-04      attack         not    unarmed  Tallahassee      Leon   \n86  125 2015-02-04    accident         not    unarmed        Tempe  Maricopa   \n\n   state   latitude   longitude location_precision                 name   age  \\\n2     KS  37.694766  -97.280554      not_available   John Paul Quintero  23.0   \n17    AR  33.111333  -92.358981      not_available  Artago Damon Howard  36.0   \n62    TX  33.166180 -101.666311      not_available   Joshua Omar Garcia  24.0   \n83    FL  30.465764  -84.330427      not_available          Jeremy Lett  28.0   \n86    AZ  33.378178 -111.978345      not_available    Joaquin Hernandez  28.0   \n\n   gender race    race_source  was_mental_illness_related  body_camera  \\\n2    male    H  not_available                       False        False   \n17   male    B  not_available                       False        False   \n62   male    H  not_available                       False        False   \n83   male    B  not_available                       False        False   \n86   male    H  not_available                       False        False   \n\n          agency_ids  year  \n2                238  2015  \n17               249  2015  \n62               179  2015  \n83               311  2015  \n86  247;195;2267;319  2015  \n\n\nDi seguito sono riportate le frequenze assolute di vittime disarmate di razza caucasica.\n\n# Filter the dataframe to include only rows where the individual was unarmed and identified as white\nunarmed_white_events = white_df[white_df[\"armed_with\"] == \"unarmed\"]\n\n# Group the filtered dataframe by year and count the occurrences\nevents_by_year_white_race = unarmed_white_events.groupby(\"year\").size().reset_index(name=\"event_count\")\n\nprint(events_by_year_white_race)\n\n   year  event_count\n0  2015           31\n1  2016           29\n2  2017           29\n3  2018           26\n4  2019           26\n5  2020           27\n6  2021            7\n7  2022           23\n8  2023           17\n\n\nPer gli stessi anni, qui sotto sono riportate le frequenze assolute delle vittime di razza non caucasica.\n\n# Filter the dataframe to include only rows where the individual was unarmed and identified as non-white\nunarmed_non_white_events = non_white_df[non_white_df[\"armed_with\"] == \"unarmed\"]\n\n# Group the filtered dataframe by year and count the occurrences\nevents_by_year_non_white_race = unarmed_non_white_events.groupby(\"year\").size().reset_index(name=\"event_count\")\n\nprint(events_by_year_non_white_race)\n\n   year  event_count\n0  2015           63\n1  2016           35\n2  2017           40\n3  2018           33\n4  2019           28\n5  2020           34\n6  2021           26\n7  2022           28\n8  2023           34\n\n\nCome distribuzione a priori per il tasso di morti, usiamo la media dei due campioni.\n\n0.5 * (np.mean(events_by_year_non_white_race.event_count) + \nnp.mean(events_by_year_white_race.event_count))\n\n29.77777777777778\n\n\nUtilizziamo una deviazione standard piuttosto grande per esprimere la nostra incertezza.\n\n# Parameters for the Gamma distribution\nmu = 30\nsigma = 10\n\n# Convert mu and sigma to shape (k) and scale (theta) parameters\ntheta = sigma**2 / mu\nk = mu / theta\n\n# Draw samples from the Gamma distribution\nx_draws = stats.gamma.rvs(a=k, scale=theta, size=50000, random_state=2)\n\n# Plot the histogram of the drawn samples\nsns.histplot(x_draws, kde=False)\n\n# Add labels and title\nplt.xlabel(\"Tasso di occorrenza (anno)\")\nplt.ylabel(\"Frequenza\")\nplt.title(\"Distribuzione Gamma con mu = 30 e sigma = 10\")\nplt.show()\n\n\n\n\n\n\n\n\nEseguiamo il campionamento per i dati del campione caucasico.\n\n# Gruppo caucasico\nstan_data_white = {\n    \"y\": events_by_year_white_race[\"event_count\"],\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n}\n\n\ntrace_white = model.sample(\n    data=stan_data_white,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori della frequenze di vittime di razza caucasica.\n\naz.plot_trace(trace_white, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(trace_white)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n24.141\n1.583\n21.246\n27.201\n0.03\n0.021\n2864.0\n3732.0\n1.0\n\n\n\n\n\n\n\nEseguiamo il campionamento per i dati del campione caucasico.\n\n# Gruppo non caucasico\nstan_data_non_white = {\n    \"y\": events_by_year_non_white_race[\"event_count\"],\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n}\n\n\ntrace_non_white = model.sample(\n    data=stan_data_non_white,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori della frequenze di vittime di razza noln caucasica.\n\naz.plot_trace(trace_non_white, combined=True, kind=\"rank_bars\", figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(trace_non_white)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nrate\n35.585\n1.937\n32.198\n39.507\n0.035\n0.025\n2981.0\n4217.0\n1.0\n\n\n\n\n\n\n\nIl confronto tra i due intervalli di credibilità suggerisce che le frequenze attese del modello di Poisson risultano maggiori nel gruppo non caucasico rispetto al gruppo caucasico. È importante considerare anche che la popolazione caucasica negli Stati Uniti è numericamente superiore rispetto agli individui non caucasici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#modello-combinato-per-i-due-gruppi",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#modello-combinato-per-i-due-gruppi",
    "title": "62  Modello di Poisson (2)",
    "section": "62.8 Modello combinato per i due gruppi",
    "text": "62.8 Modello combinato per i due gruppi\nIn alternativa, possiamo creare un modello Stan unico che valuti direttamente la differenza a posteriori delle frequenze attese dal modello di Poisson per i due gruppi. Per fare questo, possiamo estendere il modello per includere due rate, uno per ogni gruppo, e calcolare la differenza a posteriori delle frequenze attese.\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_diff_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni per ogni gruppo\n  real&lt;lower=0&gt; mu; // parametro mu per la distribuzione Gamma\n  real&lt;lower=0&gt; sigma; // parametro sigma per la distribuzione Gamma\n  array[N] int&lt;lower=0&gt; y_white; // dati osservati per il gruppo caucasico\n  array[N] int&lt;lower=0&gt; y_non_white; // dati osservati per il gruppo non caucasico\n}\nparameters {\n  real&lt;lower=0&gt; rate_white; // parametro rate per la distribuzione Poisson per il gruppo caucasico\n  real&lt;lower=0&gt; rate_non_white; // parametro rate per la distribuzione Poisson per il gruppo non caucasico\n}\nmodel {\n  // Priori\n  rate_white ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  rate_non_white ~ gamma(mu ^ 2 / sigma ^ 2, mu / sigma ^ 2);\n  \n  // Likelihood\n  y_white ~ poisson(rate_white);\n  y_non_white ~ poisson(rate_non_white);\n}\ngenerated quantities {\n  real diff_rate = rate_non_white - rate_white; // differenza tra le frequenze attese\n}\n\n\n\nNel blocco generated quantities calcoliamo la distribuzione a posteriori della differenza tra i tassi di occorrenza stimati per i gruppi non caucasici e caucasici. Questa differenza permette di quantificare direttamente il confronto tra i tassi di incidenza dei due gruppi.\nGeneriamo il dizionario appropriato per il modello.\n\nstan_groups_data = {\n    \"N\": 9,\n    \"mu\": 30,\n    \"sigma\": 10,\n    \"y_white\": events_by_year_white_race[\"event_count\"],\n    \"y_non_white\": events_by_year_non_white_race[\"event_count\"],\n}\nprint(stan_groups_data)\n\n{'N': 9, 'mu': 30, 'sigma': 10, 'y_white': 0    31\n1    29\n2    29\n3    26\n4    26\n5    27\n6     7\n7    23\n8    17\nName: event_count, dtype: int64, 'y_non_white': 0    63\n1    35\n2    40\n3    33\n4    28\n5    34\n6    26\n7    28\n8    34\nName: event_count, dtype: int64}\n\n\nEseguiamo il campionamento.\n\ntrace_groups = model.sample(\n    data=stan_groups_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro di interesse.\n\n_ = az.plot_trace(trace_groups, combined=True, var_names=[\"diff_rate\"], figsize= (9, 3))\n\n\n\n\n\n\n\n\n\naz.summary(trace_groups)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ndiff_rate\n11.436\n2.572\n6.636\n16.211\n0.031\n0.022\n6783.0\n5100.0\n1.0\n\n\nrate_non_white\n35.498\n1.971\n31.864\n39.196\n0.024\n0.017\n6787.0\n5212.0\n1.0\n\n\nrate_white\n24.062\n1.608\n21.050\n27.032\n0.020\n0.014\n6776.0\n5147.0\n1.0\n\n\n\n\n\n\n\nSulla base dei risultati ottenuti dal modello di Poisson, possiamo trarre le seguenti conclusioni:\nIl tasso stimato di incidenza delle vittime disarmate uccise dalla polizia negli Stati Uniti è più alto per il gruppo non caucasico rispetto al gruppo caucasico. La differenza media stimata tra i due tassi di incidenza è di 11.508, con una deviazione standard di 2.586. Questo significa che, in media, il tasso per il gruppo non caucasico è di circa 11.5 punti superiore rispetto al tasso per il gruppo caucasico.\nL’intervallo di credibilità al 94% per questa differenza va da 6.792 a 16.443, indicando che è molto probabile che la vera differenza tra i tassi di incidenza dei due gruppi si trovi all’interno di questo intervallo. Questo intervallo di credibilità non include lo zero, il che fornisce ulteriore evidenza che il tasso di incidenza per il gruppo non caucasico è effettivamente più alto rispetto al gruppo caucasico.\nInoltre, i tassi di incidenza stimati per ciascun gruppo sono i seguenti:\n\nGruppo non caucasico: tasso medio di 35.577 con un intervallo di credibilità al 94% tra 31.978 e 39.260.\nGruppo caucasico: tasso medio di 24.069 con un intervallo di credibilità al 94% tra 21.098 e 27.285.\n\nQuesti risultati indicano chiaramente che il gruppo non caucasico ha un tasso di incidenza più alto di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico. L’intervallo di credibilità per ciascun tasso fornisce una stima robusta e credibile della variabilità di questi tassi.\nIn sintesi, il modello di Poisson fornisce una forte evidenza che esiste una differenza robusta tra i tassi di incidenza dei due gruppi, con il gruppo non caucasico che presenta un tasso più elevato di vittime disarmate uccise dalla polizia rispetto al gruppo caucasico.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#esercizi",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#esercizi",
    "title": "62  Modello di Poisson (2)",
    "section": "62.9 Esercizi",
    "text": "62.9 Esercizi\n\nEsercizio 62.1 Nella finale olimpica di calcio 2024, la Spagna ha sconfitto la Francia con un punteggio di 5 a 3. Supponiamo di voler calcolare la probabilità di superiorità della Spagna rispetto alla Francia utilizzando un modello coniugato gamma-poisson.\nPer fare ciò, consideriamo che il numero di gol segnati da una squadra in una partita segua una distribuzione di Poisson, con un parametro λ che rappresenta il tasso medio di gol per partita. Supponiamo di avere una distribuzione a priori gamma per λ con i parametri \\(\\alpha = 1\\) e \\(\\beta = 1\\) sia per la Spagna che per la Francia. Questi parametri rappresentano la nostra incertezza iniziale sulla capacità delle squadre di segnare gol.\n\nCalcola la distribuzione a posteriori del tasso medio di gol (λ) per entrambe le squadre dopo aver osservato il risultato della partita.\nUtilizzando queste distribuzioni a posteriori, calcola la probabilità che la Spagna sia superiore alla Francia, definita come la probabilità che \\(λ_{Spagna} &gt; λ_{Francia}\\), ovvero la probabilità che la Spagna abbia un tasso medio di gol superiore rispetto alla Francia (Esercizio ispirato da The World Cup Problem, Downey (2021)).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/12_stan_poisson_model_2.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/12_stan_poisson_model_2.html#informazioni-sullambiente-di-sviluppo",
    "title": "62  Modello di Poisson (2)",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Thu Oct 03 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy     : 1.14.0\nlogging   : 0.5.1.2\ncmdstanpy : 1.2.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\narviz     : 0.18.0\npandas    : 2.2.2\n\n\n\n\n\n\n\nDowney, A. B. (2021). Think Bayes. \" O’Reilly Media, Inc.\".\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 12(3), 323–332.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>Modello di Poisson (2)</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_exponential_model.html",
    "href": "chapters/mcmc/13_stan_exponential_model.html",
    "title": "63  Modello esponenziale",
    "section": "",
    "text": "Introduction\nNel Capitolo 49 abbiamo discusso il modello gamma-esponenziale, illustrando come i parametri possano essere stimati sia attraverso un approccio basato su una griglia di valori sia con una procedura analitica. In questo capitolo, approfondiremo l’argomento utilizzando Stan per ottenere campioni a posteriori del modello gamma-esponenziale.\nL’utilizzo di Stan offre vantaggi notevoli rispetto ai metodi precedentemente discussi. In particolare, oltre alla stima dei parametri tramite campionamento bayesiano, Stan permette di esaminare l’effetto di variabili aggiuntive, o covariate, sui parametri del modello. Questa flessibilità nell’incorporare covariate non è possibile con i metodi grid-based o analitici, rendendo Stan uno strumento potente per l’estensione e l’arricchimento dei modelli statistici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_exponential_model.html#modellare-i-tempi-di-reazione",
    "href": "chapters/mcmc/13_stan_exponential_model.html#modellare-i-tempi-di-reazione",
    "title": "63  Modello esponenziale",
    "section": "63.1 Modellare i Tempi di Reazione",
    "text": "63.1 Modellare i Tempi di Reazione\nPrendendo ispirazione dal tutorial di Michael Betancourt, affrontiamo il problema di costruire un modello bayesiano per descrivere i tempi di reazione dei soggetti nello svolgimento di un compito psicologico. Lo scopo del tutorial è mostrare come i parametri della distribuzione esponenziale stimati dal modello possano dipendere da altre variabili che influenzano le osservazioni.\nIn questo tutorial, immagineremo di avere tre informazioni per ciascun soggetto:\n\nTempo di reazione: Il tempo necessario a completare il compito.\nDifficoltà del compito: I soggetti svolgono compiti con diversi livelli di difficoltà.\nAbilità pregressa: Una misura dell’abilità dei soggetti che è stata registrata prima del compito.\n\n\n63.1.1 Obiettivo\nIl nostro obiettivo è costruire un modello che, passo dopo passo, diventi sempre più complesso. Inizieremo con un modello semplice per un singolo soggetto, senza considerare covariate. Successivamente, espanderemo il modello per includere più soggetti e infine aggiungeremo le covariate (difficoltà del compito e abilità) per studiare come queste influenzano i tempi di reazione.\n\n\n63.1.2 Struttura del Tutorial\n\nModello 1: Adattiamo un modello esponenziale semplice ai dati di un singolo soggetto con più osservazioni. In questo modello non consideriamo altre variabili.\nModello 2: Estendiamo il modello a più soggetti, con una singola osservazione per ciascun soggetto. Questo è un modello gerarchico bayesiano semplice, senza covariate.\nModello 3: Aggiungiamo le covariate (difficoltà del compito e abilità del soggetto) al modello gerarchico, modellando come queste informazioni influenzano il parametro \\(\\lambda\\) della distribuzione esponenziale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_exponential_model.html#modello-1-modello-esponenziale-per-un-singolo-soggetto",
    "href": "chapters/mcmc/13_stan_exponential_model.html#modello-1-modello-esponenziale-per-un-singolo-soggetto",
    "title": "63  Modello esponenziale",
    "section": "63.2 Modello 1: Modello Esponenziale per un Singolo Soggetto",
    "text": "63.2 Modello 1: Modello Esponenziale per un Singolo Soggetto\nNel primo modello consideriamo un singolo soggetto e modelliamo i tempi di reazione come estratti da una distribuzione esponenziale, che descrive eventi che avvengono a una certa velocità costante. Il parametro \\(\\lambda\\) della distribuzione esponenziale rappresenta il tasso con cui avvengono gli eventi (in questo caso, quanto velocemente il soggetto risponde).\n\n63.2.1 Implementazione del Modello in Stan\n\nstan_file = os.path.join(project_directory, \"stan\", \"betancourt_model_1.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Numero di osservazioni (tempi di reazione) per il soggetto\n  array[N] real&lt;lower=0&gt; reaction_times; // Tempi di reazione osservati\n}\nparameters {\n  real&lt;lower=0&gt; lambda; // Parametro lambda della distribuzione esponenziale (tasso)\n}\nmodel {\n  // Prior debolmente informativo su lambda\n  lambda ~ normal(1, 1);\n  \n  // Likelihood: distribuzione esponenziale per i tempi di reazione\n  reaction_times ~ exponential(lambda);\n}\n\n\n\n\n\n63.2.2 Spiegazione del Modello\n\nDati: Il numero di osservazioni \\(N\\) rappresenta il numero di tempi di reazione raccolti per il singolo soggetto. La variabile reaction_times è un array di dimensione \\(N\\) che contiene i tempi di reazione osservati.\nParametro: Il parametro \\(\\lambda\\) è il tasso della distribuzione esponenziale, che rappresenta quanto velocemente il soggetto risponde.\nPrior: Il prior su \\(\\lambda\\) è una distribuzione normale con media 1 e deviazione standard 1, che rappresenta una conoscenza a priori debolmente informativa su quanto ci aspettiamo che il tasso di reazione sia vicino a 1.\nLikelihood: I tempi di reazione sono modellati come estratti da una distribuzione esponenziale con parametro \\(\\lambda\\).\n\nUtilizziamo dei dati simulati.\n\nstan_data = {\n    \"N\": 10, \n    \"reaction_times\": [0.3, 0.5, 0.7, 0.4, 0.6, 0.8, 0.2, 0.9, 0.3, 0.5]\n}\nprint(stan_data)\n\n{'N': 10, 'reaction_times': [0.3, 0.5, 0.7, 0.4, 0.6, 0.8, 0.2, 0.9, 0.3, 0.5]}\n\n\nEseguiamo il campionamento.\n\nfit_1 = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro lambda.\n\naz.plot_trace(fit_1, combined=True, figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\nGeneriamo un sommario numerico della distribuzione a posteriori.\n\naz.summary(fit_1)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nlambda\n1.795\n0.46\n0.946\n2.662\n0.009\n0.006\n2573.0\n2709.0\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_exponential_model.html#modello-2-modello-gerarchico-per-più-soggetti",
    "href": "chapters/mcmc/13_stan_exponential_model.html#modello-2-modello-gerarchico-per-più-soggetti",
    "title": "63  Modello esponenziale",
    "section": "63.3 Modello 2: Modello Gerarchico per Più Soggetti",
    "text": "63.3 Modello 2: Modello Gerarchico per Più Soggetti\nNel secondo passo, estendiamo il modello a un campione di più soggetti, ciascuno con un singolo tempo di reazione osservato. Questo modello introduce la gerarchia: assumiamo che ciascun soggetto abbia un proprio parametro \\(\\lambda\\), ma che tutti i \\(\\lambda\\) individuali siano distribuiti intorno a un parametro globale \\(\\lambda_{\\text{global}}\\).\n\n63.3.1 Implementazione del Modello in Stan\n\nstan_file = os.path.join(project_directory, \"stan\", \"betancourt_model_2.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N_subjects; // Numero di soggetti\n  array[N_subjects] real&lt;lower=0&gt; reaction_times; // Tempi di reazione osservati per ciascun soggetto\n}\nparameters {\n  real&lt;lower=0&gt; lambda_global; // Parametro globale lambda\n  real&lt;lower=0&gt; sigma_lambda; // Deviazione standard delle differenze individuali\n  array[N_subjects] real&lt;lower=0&gt; lambda_individual; // Parametri lambda individuali per ciascun soggetto\n}\nmodel {\n  // Prior su lambda_global e sigma_lambda\n  lambda_global ~ normal(1, 1);\n  sigma_lambda ~ normal(0, 1);\n  \n  // I lambda individuali sono distribuiti attorno a lambda_global\n  lambda_individual ~ normal(lambda_global, sigma_lambda);\n  \n  // Likelihood: distribuzione esponenziale per i tempi di reazione\n  reaction_times ~ exponential(lambda_individual);\n}\n\n\n\n\n\n63.3.2 Spiegazione del Modello\n\nDati: Il numero di soggetti \\(N_{\\text{subjects}}\\) e i tempi di reazione per ciascun soggetto.\nParametri:\n\n\\(\\lambda_{\\text{global}}\\) rappresenta il tasso globale per il campione di soggetti.\n\\(\\sigma_{\\lambda}\\) descrive la variabilità tra i parametri \\(\\lambda\\) individuali.\nI parametri \\(\\lambda_{\\text{individual}}\\) sono i tassi individuali per ciascun soggetto.\n\nLikelihood: I tempi di reazione di ciascun soggetto sono modellati come distribuzioni esponenziali con i parametri \\(\\lambda_{\\text{individual}}\\).\n\nCreaiamo un campione di dati simulati.\n\nstan_data = {\n    \"N_subjects\": 15,\n    \"reaction_times\": [0.5, 0.6, 0.7, 1.4, 0.6, 1.8, 1.2, 0.9, 1.3, 0.5, 1.1, 0.3, 0.4, 0.1, 0.2],\n}\nprint(stan_data)\n\n{'N_subjects': 15, 'reaction_times': [0.5, 0.6, 0.7, 1.4, 0.6, 1.8, 1.2, 0.9, 1.3, 0.5, 1.1, 0.3, 0.4, 0.1, 0.2]}\n\n\nEseguiamo il campionamento.\n\nfit_2 = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori.\n\naz.plot_trace(fit_2, figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(fit_2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nlambda_global\n1.427\n0.325\n0.807\n2.025\n0.014\n0.010\n458.0\n1032.0\n1.01\n\n\nlambda_individual[0]\n1.453\n0.463\n0.605\n2.314\n0.014\n0.010\n949.0\n1881.0\n1.02\n\n\nlambda_individual[1]\n1.446\n0.462\n0.624\n2.366\n0.014\n0.010\n887.0\n1901.0\n1.02\n\n\nlambda_individual[2]\n1.435\n0.449\n0.646\n2.345\n0.015\n0.011\n718.0\n2058.0\n1.02\n\n\nlambda_individual[3]\n1.367\n0.423\n0.614\n2.204\n0.016\n0.011\n617.0\n1464.0\n1.01\n\n\nlambda_individual[4]\n1.449\n0.464\n0.656\n2.355\n0.014\n0.010\n921.0\n1954.0\n1.02\n\n\nlambda_individual[5]\n1.322\n0.414\n0.486\n2.093\n0.016\n0.012\n584.0\n1490.0\n1.01\n\n\nlambda_individual[6]\n1.386\n0.437\n0.581\n2.232\n0.015\n0.010\n769.0\n1684.0\n1.01\n\n\nlambda_individual[7]\n1.421\n0.448\n0.564\n2.265\n0.014\n0.010\n851.0\n2034.0\n1.02\n\n\nlambda_individual[8]\n1.371\n0.431\n0.559\n2.210\n0.015\n0.011\n674.0\n1685.0\n1.01\n\n\nlambda_individual[9]\n1.456\n0.469\n0.617\n2.333\n0.015\n0.011\n761.0\n1826.0\n1.03\n\n\nlambda_individual[10]\n1.393\n0.442\n0.622\n2.305\n0.016\n0.011\n598.0\n1544.0\n1.01\n\n\nlambda_individual[11]\n1.487\n0.485\n0.670\n2.422\n0.015\n0.010\n876.0\n2153.0\n1.04\n\n\nlambda_individual[12]\n1.473\n0.472\n0.606\n2.340\n0.015\n0.011\n730.0\n2199.0\n1.03\n\n\nlambda_individual[13]\n1.516\n0.498\n0.680\n2.480\n0.015\n0.011\n803.0\n2011.0\n1.04\n\n\nlambda_individual[14]\n1.495\n0.487\n0.644\n2.388\n0.015\n0.011\n824.0\n2024.0\n1.04\n\n\nsigma_lambda\n0.297\n0.241\n0.017\n0.721\n0.032\n0.023\n19.0\n13.0\n1.15",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_exponential_model.html#modello-3-modello-completo-con-difficoltà-del-compito-e-abilità",
    "href": "chapters/mcmc/13_stan_exponential_model.html#modello-3-modello-completo-con-difficoltà-del-compito-e-abilità",
    "title": "63  Modello esponenziale",
    "section": "63.4 Modello 3: Modello Completo con Difficoltà del Compito e Abilità",
    "text": "63.4 Modello 3: Modello Completo con Difficoltà del Compito e Abilità\nNel terzo passo, introduciamo le covariate: la difficoltà del compito e l’abilità del soggetto. Queste informazioni aggiuntive influenzano i tempi di reazione modellando il parametro \\(\\lambda_{\\text{individual}}\\) come una funzione della difficoltà del compito e dell’abilità del soggetto.\n\n63.4.1 Implementazione del Modello in Stan\n\nstan_file = os.path.join(project_directory, \"stan\", \"betancourt_model_3.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N_subjects;        // Numero di soggetti\n  array[N_subjects] real&lt;lower=0&gt; reaction_times; // Tempi di reazione per ciascun soggetto\n  array[N_subjects] real&lt;lower=0&gt; task_difficulty; // Difficoltà del compito per ciascun soggetto\n  array[N_subjects] real ability;                 // Abilità individuale per ciascun soggetto\n}\n\nparameters {\n  real&lt;lower=0&gt; lambda_global;    // Parametro globale lambda\n  real&lt;lower=0&gt; beta_difficulty;  // Effetto della difficoltà del compito\n}\n\ntransformed parameters {\n  array[N_subjects] real&lt;lower=0&gt; lambda_individual; // Parametri lambda individuali\n\n  // Il parametro lambda individuale dipende dalla difficoltà del compito e dall'abilità\n  for (i in 1:N_subjects) {\n    lambda_individual[i] = lambda_global + beta_difficulty * task_difficulty[i] - ability[i];\n  }\n}\n\nmodel {\n  // Priori\n  lambda_global ~ normal(1, 1);\n  beta_difficulty ~ normal(0, 1);\n\n  // Likelihood\n  reaction_times ~ exponential(lambda_individual);\n}\n\n\n\n\n\n63.4.2 Spiegazione del Modello\n\nDati: In questo modello, oltre ai tempi di reazione osservati per ciascun soggetto, includiamo due variabili aggiuntive come covariate:\n\nDifficoltà del compito: Ogni soggetto svolge un compito con un livello di difficoltà diverso, rappresentato dalla variabile task_difficulty.\nAbilità individuale: Misura delle capacità preesistenti di ciascun soggetto, rappresentata dalla variabile ability.\n\nParametri:\n\nIl parametro \\(\\lambda_{\\text{individual}}\\) rappresenta il tasso della distribuzione esponenziale per ciascun soggetto e riflette la velocità con cui il soggetto completa il compito.\nQuesto parametro dipende sia dal tasso globale \\(\\lambda_{\\text{global}}\\), che rappresenta la media del tasso di completamento dei compiti nel campione, sia dalle due covariate:\n\nDifficoltà del compito (beta_difficulty * task_difficulty): Compiti più difficili tendono a ridurre il valore di \\(\\lambda_{\\text{individual}}\\), rendendo i tempi di reazione più lunghi.\nAbilità del soggetto (\\(- \\text{ability}[i]\\)): Soggetti con maggiore abilità tendono ad avere tempi di reazione più rapidi, quindi valori più alti di abilità diminuiscono i tempi di reazione.\n\n\nLa relazione tra queste variabili è specificata nella formula:\n  for (i in 1:N_subjects) {\n      lambda_individual[i] = lambda_global + beta_difficulty * task_difficulty[i] - ability[i];\n}\nQuesto significa che per ciascun soggetto \\(i\\), il tasso esponenziale individuale \\(\\lambda_{\\text{individual}}[i]\\) è calcolato come una somma lineare di un effetto globale (\\(\\lambda_{\\text{global}}\\)), un effetto legato alla difficoltà del compito e un effetto legato all’abilità individuale.\nLikelihood: La distribuzione esponenziale viene utilizzata per modellare i tempi di reazione. La verosimiglianza è specificata come:\nreaction_times ~ exponential(lambda_individual);\nIn questa specificazione, i tempi di reazione sono modellati come variabili esponenziali con parametro \\(\\lambda_{\\text{individual}}\\). Poiché \\(\\lambda_{\\text{individual}}\\) è un vettore che varia tra i soggetti, ciascun soggetto ha il proprio valore di \\(\\lambda\\), che riflette la sua reattività in base alla difficoltà del compito e alla sua abilità.\n\nLa distribuzione esponenziale è particolarmente adatta a modellare tempi di attesa o di reazione, perché si concentra su eventi che si verificano a un tasso costante nel tempo. In questo modello, il parametro \\(\\lambda_{\\text{individual}}\\), che controlla il tasso di completamento del compito, varia per ciascun soggetto in funzione della difficoltà del compito e dell’abilità. Questo permette al modello di adattarsi in modo flessibile ai dati, considerando sia le caratteristiche del compito che le differenze individuali tra i soggetti.\nSimuliamo un campione di dati.\n\n# Parameters for data simulation\nnp.random.seed(42)\nN_subjects = 15\n\n# Global parameters\nlambda_global = np.random.normal(1, 1)\nbeta_difficulty = np.random.normal(0, 1)\n\n# Simulate task difficulty and individual ability\ntask_difficulty = np.random.uniform(0, 2, N_subjects).tolist()  # Ensuring it is a list\nability = np.random.normal(0, 1, N_subjects).tolist()  # Ensuring it is a list\n\n# Compute individual lambdas\nlambda_individual = (\n    lambda_global + beta_difficulty * np.array(task_difficulty) - np.array(ability)\n)\nlambda_individual = np.clip(lambda_individual, 0.01, None)\n\n# Simulate reaction times based on the exponential distribution\nreaction_times = np.random.exponential(\n    1 / lambda_individual\n).tolist()  # Ensuring it is a list\n\n# Organize the data into a dictionary\nsimulated_data = {\n    \"N_subjects\": N_subjects,\n    \"reaction_times\": reaction_times,\n    \"task_difficulty\": task_difficulty,  # Make sure this is a list/array, not a scalar\n    \"ability\": ability,  # Make sure this is a list/array, not a scalar\n}\n\n# Make sure that you pass the data to Stan in the correct structure\nsimulated_data\n\n{'N_subjects': 15,\n 'reaction_times': [0.026306979473107298,\n  3.0271953252826425,\n  0.9104813464865819,\n  0.04371260437678165,\n  0.358122171029951,\n  0.01750037382415924,\n  1.1802461283350816,\n  0.087038206386994,\n  0.512264739534741,\n  0.59219237344445,\n  73.41108959092286,\n  0.7580490737777282,\n  0.154346968693783,\n  1.7807423128002173,\n  0.7413644923062442],\n 'task_difficulty': [1.4639878836228102,\n  1.1973169683940732,\n  0.31203728088487304,\n  0.3119890406724053,\n  0.11616722433639892,\n  1.7323522915498704,\n  1.2022300234864176,\n  1.416145155592091,\n  0.041168988591604894,\n  1.9398197043239886,\n  1.6648852816008435,\n  0.4246782213565523,\n  0.36364993441420124,\n  0.36680901970686763,\n  0.6084844859190754],\n 'ability': [-2.6125490126936013,\n  0.9503696823969031,\n  0.8164450809513273,\n  -1.523875997615861,\n  -0.4280460641762345,\n  -0.7424068371191724,\n  -0.7033438017074073,\n  -2.1396206560762394,\n  -0.6294749609242508,\n  0.5977204669126083,\n  2.5594880310377928,\n  0.3942330218796011,\n  0.12221916522267956,\n  -0.5154356620924533,\n  -0.6002538501059117]}\n\n\nEseguiamo il campionamento.\n\nfit_3 = model.sample(\n    data={\n        \"N_subjects\": 15,\n        \"reaction_times\": reaction_times,  # List of reaction times\n        \"task_difficulty\": task_difficulty,  # List of task difficulties\n        \"ability\": ability,  # List of individual abilities\n    },\n    chains=4,\n    iter_sampling=2000,\n    iter_warmup=1000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori.\n\naz.plot_trace(fit_3, figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(fit_3)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta_difficulty\n0.753\n0.252\n0.276\n1.210\n0.017\n0.012\n241.0\n120.0\n1.01\n\n\nlambda_global\n1.333\n0.419\n0.574\n2.118\n0.028\n0.023\n241.0\n121.0\n1.01\n\n\nlambda_individual[0]\n5.048\n0.054\n4.946\n5.145\n0.003\n0.002\n275.0\n170.0\n1.01\n\n\nlambda_individual[1]\n1.284\n0.119\n1.062\n1.502\n0.008\n0.006\n248.0\n123.0\n1.01\n\n\nlambda_individual[2]\n0.751\n0.341\n0.133\n1.385\n0.023\n0.020\n241.0\n120.0\n1.01\n\n\nlambda_individual[3]\n3.092\n0.341\n2.474\n3.726\n0.023\n0.017\n241.0\n120.0\n1.01\n\n\nlambda_individual[4]\n1.849\n0.390\n1.141\n2.577\n0.026\n0.021\n241.0\n121.0\n1.01\n\n\nlambda_individual[5]\n3.380\n0.026\n3.329\n3.429\n0.001\n0.001\n383.0\n271.0\n1.01\n\n\nlambda_individual[6]\n2.941\n0.117\n2.722\n3.157\n0.008\n0.006\n248.0\n123.0\n1.01\n\n\nlambda_individual[7]\n4.539\n0.065\n4.420\n4.662\n0.004\n0.003\n263.0\n148.0\n1.01\n\n\nlambda_individual[8]\n1.994\n0.409\n1.254\n2.759\n0.027\n0.021\n241.0\n121.0\n1.01\n\n\nlambda_individual[9]\n2.196\n0.073\n2.055\n2.328\n0.005\n0.003\n255.0\n130.0\n1.01\n\n\nlambda_individual[10]\n0.027\n0.019\n0.001\n0.062\n0.000\n0.000\n2054.0\n1891.0\n1.00\n\n\nlambda_individual[11]\n1.259\n0.312\n0.691\n1.839\n0.021\n0.017\n241.0\n120.0\n1.01\n\n\nlambda_individual[12]\n1.485\n0.328\n0.890\n2.094\n0.022\n0.017\n241.0\n120.0\n1.01\n\n\nlambda_individual[13]\n2.125\n0.327\n1.532\n2.733\n0.022\n0.017\n241.0\n120.0\n1.01\n\n\nlambda_individual[14]\n2.391\n0.266\n1.906\n2.885\n0.018\n0.013\n242.0\n120.0\n1.01",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_exponential_model.html#considerazioni-conclusive",
    "href": "chapters/mcmc/13_stan_exponential_model.html#considerazioni-conclusive",
    "title": "63  Modello esponenziale",
    "section": "63.5 Considerazioni Conclusive",
    "text": "63.5 Considerazioni Conclusive\nIn questo capitolo, abbiamo dimostrato come l’utilizzo di Stan permetta non solo di stimare i parametri del modello gamma-esponenziale in modo efficiente, ma anche di estendere il modello per includere covariate che influenzano i parametri stessi. Questa capacità di esplorare relazioni più complesse tra le variabili rappresenta un significativo passo avanti rispetto ai metodi più tradizionali, come le stime analitiche o basate su griglia. L’integrazione di Stan nei processi di modellazione consente un approccio più flessibile e potente per la comprensione dei dati e delle dinamiche sottostanti.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/13_stan_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/13_stan_exponential_model.html#informazioni-sullambiente-di-sviluppo",
    "title": "63  Modello esponenziale",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Wed Sep 11 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\narviz     : 0.18.0\nlogging   : 0.5.1.2\ncmdstanpy : 1.2.4\nscipy     : 1.14.0\npandas    : 2.2.2",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>Modello esponenziale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_gaussian_mixture.html",
    "href": "chapters/mcmc/14_stan_gaussian_mixture.html",
    "title": "64  Modelli Mistura Gaussiani",
    "section": "",
    "text": "Introduzione\nLa distribuzione gaussiana è estremamente utile, non solo quando i dati seguono una distribuzione normale, ma anche in situazioni dove la distribuzione dei dati non è gaussiana. Un esempio rilevante è quello delle misture di distribuzioni. Una mistura di distribuzioni rappresenta una variabile casuale la cui funzione di probabilità (per variabili discrete) o funzione di densità di probabilità (per variabili continue) è data da una combinazione lineare ponderata di più funzioni di probabilità o densità di altre variabili casuali.\nAd esempio, la densità di probabilità di una mistura di due distribuzioni normali può essere espressa come:\n\\[\nf(x; \\pi_1, \\mu_1, \\sigma_1, \\mu_2, \\sigma_2) = \\pi_1 \\phi(x; \\mu_1, \\sigma_1) + \\pi_2 \\phi(x; \\mu_2, \\sigma_2)\n\\]\ndove:\n\\[\n\\pi_2 = 1 - \\pi_1\n\\]\ne \\(\\phi(x; \\mu, \\sigma)\\) rappresenta la funzione di densità di probabilità di una variabile casuale normale con media \\(\\mu\\) e deviazione standard \\(\\sigma\\).\nUn’applicazione comune delle misture di distribuzioni è il caso delle subpopolazioni. Quando una popolazione è composta da più sottopopolazioni, ciascuna con una propria distribuzione di valori, l’intera popolazione può essere modellata come una mistura di distribuzioni. Ad esempio, se si assume che l’altezza degli uomini e quella delle donne seguano entrambe una distribuzione normale, ma con medie diverse, l’altezza degli individui senza distinzione di sesso può essere rappresentata come una mistura di due distribuzioni normali.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_gaussian_mixture.html#simulazione-dei-dati",
    "href": "chapters/mcmc/14_stan_gaussian_mixture.html#simulazione-dei-dati",
    "title": "64  Modelli Mistura Gaussiani",
    "section": "64.1 Simulazione dei Dati",
    "text": "64.1 Simulazione dei Dati\nI dati simulati si basano su uno studio condotto da Rowland & Wenzel (2020) che ha esaminato gli effetti di un training di mindfulness ultra-breve sulla consapevolezza e l’autocontrollo percepito. Lo studio confronta i giudizi espressi da due gruppi: un gruppo sperimentale sottoposto a training di mindfulness e un gruppo di controllo che non ha ricevuto alcun training di mindfulness. I giudizi sono stati raccolti su diverse dimensioni attraverso un protocollo di valutazione ambulatoriale, iniziato il giorno successivo alla prima sessione di laboratorio e proseguito per 40 giorni consecutivi. Qui esamineremo i dati simulati ispirati dallo studio, concentrandoci sui giudizi relativi alla dimensione “sad”.\n\n# Parametri per le distribuzioni normali\n# Sad mindfulness\nmu_mindfulness = 20  # giudizi sad\nsigma_mindfulness = 10  # deviazione standard\n\n# Sad control\nmu_control = 60  # giudizi sad\nsigma_control = 10  # deviazione standard\n\n# Simulazione di 60 casi per ciascuna sottopopolazione\nnp.random.seed(42)  # per la riproducibilità\nsad_mindfulness = np.random.normal(mu_mindfulness, sigma_mindfulness, 60)\nsad_control = np.random.normal(mu_control, sigma_control, 60)\n\n# Creazione del DataFrame per visualizzare i dati\ndati_sad = pd.DataFrame(\n    {\n        \"Sad\": np.concatenate([sad_mindfulness, sad_control]),\n        \"Group\": [\"Mindfulness\"] * 60 + [\"Control\"] * 60,\n    }\n)\n\n# Mostra i parametri di ciascuna distribuzione e i primi dati simulati\nparametri_distribuzioni = pd.DataFrame(\n    {\n        \"Sottopopolazione\": [\"Mindfulness\", \"Control\"],\n        \"Media (mu)\": [mu_mindfulness, mu_control],\n        \"Deviazione Standard (sigma)\": [sigma_mindfulness, sigma_control],\n    }\n)\n\ndati_sad.head()\n\n\n\n\n\n\n\n\nSad\nGroup\n\n\n\n\n0\n24.967142\nMindfulness\n\n\n1\n18.617357\nMindfulness\n\n\n2\n26.476885\nMindfulness\n\n\n3\n35.230299\nMindfulness\n\n\n4\n17.658466\nMindfulness\n\n\n\n\n\n\n\n\ndati_sad.tail()\n\n\n\n\n\n\n\n\nSad\nGroup\n\n\n\n\n115\n63.015473\nControl\n\n\n116\n59.652882\nControl\n\n\n117\n48.313220\nControl\n\n\n118\n71.428228\nControl\n\n\n119\n67.519330\nControl\n\n\n\n\n\n\n\n\nprint(parametri_distribuzioni)\n\n  Sottopopolazione  Media (mu)  Deviazione Standard (sigma)\n0      Mindfulness          20                           10\n1          Control          60                           10\n\n\n\n# Standardizzazione dei dati\ndati_sad[\"Sad_z\"] = (\n    dati_sad[\"Sad\"] - dati_sad[\"Sad\"].mean()\n) / dati_sad[\"Sad\"].std()\n\n# Creazione dell'istogramma per i dati standardizzati\nplt.figure(figsize=(10, 6))\nplt.hist(\n    dati_sad[\"Sad_z\"], bins=20, color=\"skyblue\", edgecolor=\"black\"\n)\nplt.title(\"Istogramma dei Giudizi Sad Standardizzati\")\nplt.xlabel(\"Giudizi 'Sad' Standardizzati\")\nplt.ylabel(\"Frequenza\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIl seguente codice Stan è stato ottenuto da Identifying Bayesian Mixture Models di Michael Betancourt.\n\nstan_file = os.path.join(project_directory, \"stan\", \"bimodal_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n}\nparameters {\n  ordered[2] mu;\n  array[2] real&lt;lower=0&gt; sigma;\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  sigma ~ normal(0, 2);\n  mu ~ normal(0, 2);\n  theta ~ beta(5, 5);\n  for (n in 1 : N) \n    target += log_mix(theta, normal_lpdf(y[n] | mu[1], sigma[1]),\n                      normal_lpdf(y[n] | mu[2], sigma[2]));\n}\n\n\n\nQuesto codice Stan implementa un modello per una mistura di distribuzioni gaussiane. Ecco una spiegazione dettagliata delle varie sezioni del codice:\n\nBlocco data\n\n\nint&lt;lower=0&gt; N;: Definisce il numero di osservazioni, \\(N\\), che deve essere un intero non negativo. Questo rappresenta il numero di dati osservati.\nvector[N] y;: Definisce un vettore \\(y\\) di lunghezza \\(N\\) che contiene i dati osservati. Ogni elemento di \\(y\\) rappresenta un valore osservato.\n\n\nBlocco parameters\n\n\nordered[2] mu;: Definisce un vettore ordinato di lunghezza 2 per i parametri \\(\\mu\\), che rappresentano le medie delle due distribuzioni gaussiane nella mistura. La proprietà ordered garantisce che \\(\\mu[1] \\leq \\mu[2]\\), il che aiuta a evitare problemi di identificabilità del modello.\narray[2] real&lt;lower=0&gt; sigma;: Definisce un array di 2 elementi per i parametri \\(\\sigma\\), che rappresentano le deviazioni standard delle due distribuzioni gaussiane. Il vincolo &lt;lower=0&gt; garantisce che le deviazioni standard siano sempre positive.\nreal&lt;lower=0, upper=1&gt; theta;: Definisce il parametro \\(\\theta\\), che rappresenta la proporzione della prima distribuzione gaussiana nella mistura. Essendo vincolato tra 0 e 1, \\(\\theta\\) può essere interpretato come la probabilità che un’osservazione provenga dalla prima distribuzione.\n\n\nBlocco model\n\n\nsigma ~ normal(0, 2);: Impone una distribuzione a priori normale (\\(\\mathcal{N}(0, 2)\\)) sui parametri \\(\\sigma\\). Questo riflette la convinzione a priori che le deviazioni standard siano distribuite normalmente attorno a 0 con deviazione standard 2.\nmu ~ normal(0, 2);: Impone una distribuzione a priori normale (\\(\\mathcal{N}(0, 2)\\)) sui parametri \\(\\mu\\). Questo rappresenta l’assunzione che le medie delle due gaussiane siano anch’esse distribuite normalmente attorno a 0 con deviazione standard 2.\ntheta ~ beta(5, 5);: Impone una distribuzione a priori beta (\\(\\text{Beta}(5, 5)\\)) su \\(\\theta\\), che è una distribuzione simmetrica con valori centrati attorno a 0.5. Questo riflette l’assunzione che ciascuna delle due gaussiane abbia una probabilità iniziale del 50% di generare un dato, con un po’ di flessibilità.\nfor (n in 1 : N): Questo ciclo for scorre su tutte le osservazioni \\(y[n]\\).\ntarget += log_mix(...): Questa riga è fondamentale per calcolare la log-verosimiglianza del modello. La funzione log_mix(theta, ...) calcola la log-verosimiglianza di una mistura di due distribuzioni:\n\nnormal_lpdf(y[n] | mu[1], sigma[1]): Calcola la log-verosimiglianza del dato \\(y[n]\\) sotto la prima distribuzione normale con parametri \\(\\mu[1]\\) e \\(\\sigma[1]\\).\nnormal_lpdf(y[n] | mu[2], sigma[2]): Calcola la log-verosimiglianza del dato \\(y[n]\\) sotto la seconda distribuzione normale con parametri \\(\\mu[2]\\) e \\(\\sigma[2]\\).\nlog_mix(theta, ..., ...): Mescola queste due log-verosimiglianze pesandole con \\(\\theta\\) (per la prima gaussiana) e \\(1 - \\theta\\) (per la seconda).\n\n\nIn sintesi, questo modello Stan cerca di adattare una mistura di due distribuzioni gaussiane ai dati osservati \\(y\\). Il modello assume che ciascun dato provenga da una delle due gaussiane e cerca di stimare i parametri delle due distribuzioni (le medie \\(\\mu\\) e le deviazioni standard \\(\\sigma\\)), insieme alla proporzione \\(\\theta\\) che indica la probabilità che un dato provenga dalla prima distribuzione. Il codice utilizza distribuzioni a priori per informare il modello sulle aspettative dei parametri, ma è abbastanza flessibile da adattarsi ai dati osservati.\nCreiamo il dizionario con i dati nel formato richiesto da Stan.\n\nstan_data = {\"N\": len(dati_sad[\"Sad_z\"]), \"y\": dati_sad[\"Sad_z\"]}\nprint(stan_data)\n\n{'N': 80, 'y': 0    -0.596309\n1    -0.870798\n2    -0.531045\n3    -0.152652\n4    -0.912249\n        ...   \n75    1.273390\n76    0.955725\n77    0.788841\n78    0.957763\n79    0.058908\nName: Sad_z, Length: 80, dtype: float64}\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri del modello.\n\naz.plot_trace(fit, var_names=[\"mu\", \"sigma\", \"theta\"], figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\naz.summary(fit)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu[0]\n-0.859\n0.096\n-1.045\n-0.688\n0.002\n0.001\n3873.0\n3587.0\n1.0\n\n\nmu[1]\n0.942\n0.085\n0.791\n1.103\n0.001\n0.001\n6252.0\n4828.0\n1.0\n\n\nsigma[0]\n0.468\n0.079\n0.334\n0.623\n0.001\n0.001\n4663.0\n4282.0\n1.0\n\n\nsigma[1]\n0.390\n0.076\n0.267\n0.532\n0.001\n0.001\n4461.0\n4506.0\n1.0\n\n\ntheta\n0.520\n0.060\n0.410\n0.633\n0.001\n0.001\n5590.0\n5627.0\n1.0\n\n\n\n\n\n\n\nRappresentiamo graficamente la distribuzione ottenuta dai parametri medi posteriori.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Using the provided posterior estimates\nmu_0 = -0.859\nmu_1 = 0.942\nsigma_0 = 0.468\nsigma_1 = 0.390\ntheta = 0.520  # Probability for the first component (mu_0)\n\n# Assuming dati_sad is your DataFrame, you need to provide the actual data\n# For this example, I'll generate some random data\nnp.random.seed(42)\ndata = np.concatenate(\n    [\n        np.random.normal(mu_0, sigma_0, int(1000 * theta)),\n        np.random.normal(mu_1, sigma_1, int(1000 * (1 - theta))),\n    ]\n)\n\n# Generate the histogram from the data\nfig, axes = plt.subplots(1, figsize=(10, 6))\n\n# Plot the histogram with actual counts\ncounts, bins, _ = axes.hist(data, bins=50, alpha=0.6, color=\"g\", density=False)\n\n# Calculate the KDE with a higher resolution\nx = np.linspace(data.min(), data.max(), 1000)\nkde = theta * norm.pdf(x, loc=mu_0, scale=sigma_0) + (1 - theta) * norm.pdf(\n    x, loc=mu_1, scale=sigma_1\n)\n\n# Scale the KDE to match the histogram's area\nhist_area = np.sum(counts) * np.diff(bins)[0]\nkde_scaled = kde * hist_area\n\n# Plot the KDE\naxes.plot(x, kde_scaled, linewidth=2, color=\"black\")\n\n# Additional plot settings\naxes.set_title(\"Estimated Bimodal Distribution from Posterior Parameters\")\naxes.set_xlabel(\"Sadness Score\")\naxes.set_ylabel(\"Counts\")\n\nplt.show()\n\n\n\n\n\n\n\n\nNotiamo la buona corrispondenza tra il grafico precedente e quello sopra che rappresenta i dati in input.\nPossiamo anche convertire i parametri recuperati in modo che siano espressi sulla scala dei dati grezzi.\n\n# I valori di media e deviazione standard della distribuzione originale\nmean_original = dati_sad[\"Sad\"].mean()\nstd_original = dati_sad[\"Sad\"].std()\n\n# Parametri posteriori delle distribuzioni standardizzate\nmu_0_standardized = -0.859\nmu_1_standardized = 0.942\nsigma_0_standardized = 0.468\nsigma_1_standardized = 0.390\n\n# Convertire i parametri alla scala originale\nmu_0_original = mu_0_standardized * std_original + mean_original\nmu_1_original = mu_1_standardized * std_original + mean_original\nsigma_0_original = sigma_0_standardized * std_original\nsigma_1_original = sigma_1_standardized * std_original\n\n\nprint(\n    f\"Media a posteriori della prima sottopopolazione: {mu_0_original:.2f}\\nMedia a posteriori della seconda sottopopolazione: {mu_1_original:.2f}\"\n)\nprint(\n    f\"Deviazione standard a poseriori della prima sottopopolazione: {sigma_0_original:.2f}\\nDeviazione standard a posteriori della seconda sottopopolazione: {sigma_1_original:.2f}\"\n)\n\nMedia a posteriori della prima sottopopolazione: 18.89\nMedia a posteriori della seconda sottopopolazione: 60.55\nDeviazione standard a poseriori della prima sottopopolazione: 10.83\nDeviazione standard a posteriori della seconda sottopopolazione: 9.02\n\n\nNella simulazione, i valori di \\(\\mu\\) erano \\([20, 60]\\) e i due valori di \\(\\sigma\\) erano entrambi pari a 10. Si osserva quindi una corrispondenza molto buona tra i valori utilizzati per simulare i dati e i parametri stimati per ciascun gruppo. È importante notare che il codice Stan non includeva l’informazione che assegnava ogni osservazione a un gruppo specifico. Questo dimostra come la tecnica della mistura di gaussiane sia in grado di classificare correttamente le osservazioni dei dati campionari nelle diverse sottopopolazioni e di stimare con precisione i parametri per ciascuna di esse.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_gaussian_mixture.html#considerazioni-conlusive",
    "href": "chapters/mcmc/14_stan_gaussian_mixture.html#considerazioni-conlusive",
    "title": "64  Modelli Mistura Gaussiani",
    "section": "64.2 Considerazioni Conlusive",
    "text": "64.2 Considerazioni Conlusive\nIn questo capitolo, abbiamo esplorato l’applicazione dei modelli di mistura gaussiana nel contesto della ricerca psicologica, utilizzando come esempio uno studio sugli effetti del training di mindfulness sui giudizi di tristezza.\nImplicazioni per la ricerca psicologica:\n\nQuesti modelli possono aiutare i ricercatori a identificare sottogruppi nascosti all’interno dei loro dati, portando a una comprensione più sfumata dei fenomeni psicologici.\nL’approccio bayesiano offre una flessibilità che può essere particolarmente utile quando si lavora con campioni di dimensioni ridotte o dati complessi.\n\nIn conclusione, i modelli di mistura gaussiana rappresentano uno strumento statistico che può arricchire l’analisi dei dati in psicologia, permettendo ai ricercatori di scoprire strutture latenti e di modellare la complessità intrinseca dei fenomeni psicologici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/14_stan_gaussian_mixture.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/14_stan_gaussian_mixture.html#informazioni-sullambiente-di-sviluppo",
    "title": "64  Modelli Mistura Gaussiani",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\nlogging   : 0.5.1.2\narviz     : 0.18.0\nscipy     : 1.14.0\nseaborn   : 0.13.2\npandas    : 2.2.2\n\n\n\n\n\n\n\nRowland, Z., & Wenzel, M. (2020). Mindfulness and affect-network density: Does mindfulness facilitate disengagement from affective experiences in daily life? Mindfulness, 11, 1253–1266.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>Modelli Mistura Gaussiani</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/15_stan_nuisance_parameters.html",
    "href": "chapters/mcmc/15_stan_nuisance_parameters.html",
    "title": "65  Modelli con più di un parametro",
    "section": "",
    "text": "65.1 Introduzione\nIn statistica, è comune dover affrontare problemi che coinvolgono più parametri sconosciuti o non osservabili. Tuttavia, anche in presenza di numerosi parametri, l’interesse principale è spesso limitato a uno o pochi di essi. L’obiettivo principale di un’analisi bayesiana è quindi ottenere la distribuzione marginale a posteriori dei parametri di interesse specifico.\nEsistono due approcci principali per ottenere questa distribuzione marginale a posteriori. Il primo approccio consiste nel calcolare esplicitamente la distribuzione congiunta a posteriori di tutti i parametri e successivamente integrare analiticamente (o numericamente) rispetto ai parametri di disturbo per ottenere la distribuzione marginale dei parametri di interesse. Questo metodo, sebbene teoricamente corretto, può risultare complesso o addirittura impraticabile nei modelli più sofisticati, a causa della difficoltà dell’integrazione.\nIl secondo approccio, più pratico e comunemente utilizzato, si basa sulla simulazione della distribuzione congiunta a posteriori tramite tecniche come il campionamento MCMC (Markov Chain Monte Carlo). In questo caso, si generano campioni da tutta la distribuzione congiunta e, nella fase di analisi, si ignorano i campioni relativi ai parametri di disturbo, concentrandosi solo su quelli di interesse. Questo metodo è particolarmente vantaggioso per modelli complessi, dove l’integrazione analitica sarebbe proibitiva.\nSpesso, in molti problemi statistici, non c’è un interesse diretto a fare inferenze su numerosi parametri sconosciuti, anche se sono essenziali per la costruzione di un modello realistico. Questi parametri sono comunemente noti come “parametri di disturbo” o “nuisance parameters”.\nIn questo tutorial, esamineremo un modello che include sia parametri di interesse, come le medie dei punteggi dei test tra due gruppi (\\(\\mu_1\\) e \\(\\mu_2\\)), sia parametri di disturbo, come le abilità cognitive di base dei partecipanti (\\(\\theta\\)). Attraverso il processo di marginalizzazione, ci concentreremo sui parametri di interesse ignorando i campioni relativi ai parametri di disturbo, mantenendo comunque la complessità del modello necessaria per descrivere accuratamente i dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/15_stan_nuisance_parameters.html#stima-delleffetto-di-un-intervento-cognitivo-sui-punteggi-dei-test",
    "href": "chapters/mcmc/15_stan_nuisance_parameters.html#stima-delleffetto-di-un-intervento-cognitivo-sui-punteggi-dei-test",
    "title": "65  Modelli con più di un parametro",
    "section": "65.2 Stima dell’effetto di un intervento cognitivo sui punteggi dei test",
    "text": "65.2 Stima dell’effetto di un intervento cognitivo sui punteggi dei test\nSupponiamo di voler valutare l’effetto di un intervento cognitivo, come un programma di formazione progettato per migliorare la memoria di lavoro, sui punteggi di un test che misura la performance dei partecipanti. I partecipanti sono suddivisi in due gruppi: uno che riceve l’intervento e un gruppo di controllo che non lo riceve.\nL’obiettivo principale è stimare la differenza nei punteggi medi dei test tra i due gruppi dopo l’intervento. Tuttavia, siamo consapevoli che i punteggi dei test possono essere influenzati da una serie di fattori, come le differenze individuali nelle capacità cognitive di base, i livelli di motivazione e gli errori di misurazione.\nIn questo contesto, il parametro di interesse è la differenza nei punteggi medi dei test tra il gruppo che ha ricevuto l’intervento e il gruppo di controllo, tenendo conto delle capacità cognitive di base. Tuttavia, queste capacità cognitive di base e gli errori di misurazione sono considerati parametri di disturbo—elementi indispensabili per costruire un modello accurato, ma che non rappresentano il focus principale dell’analisi.\n\n65.2.1 Specificazione del modello:\nPer stimare la distribuzione marginale a posteriori del parametro di interesse—la differenza nei punteggi medi dei test tra il gruppo che ha ricevuto l’intervento e il gruppo di controllo—definiamo il modello nel seguente modo:\n\n\\(y_{ij}\\): Il punteggio del test per il partecipante \\(j\\) nel gruppo \\(i\\) (dove \\(i = 1\\) per il gruppo di intervento e \\(i = 2\\) per il gruppo di controllo).\n\\(\\mu_i\\): La media dei punteggi del test per il gruppo \\(i\\).\n\\(\\delta\\): La differenza tra le medie (\\(\\mu_1 - \\mu_2\\))—questo è il parametro di interesse principale.\n\\(\\sigma_y\\): La deviazione standard dei punteggi dei test, considerata un parametro di disturbo comune a entrambi i gruppi.\n\\(\\theta_j\\): La capacità cognitiva di base del partecipante \\(j\\), modellata come un effetto casuale e trattata anch’essa come un parametro di disturbo.\n\\(\\sigma_\\theta\\): La deviazione standard delle capacità cognitive di base, anch’essa considerata un parametro di disturbo.\n\nAssumiamo che i punteggi dei test \\(y_{ij}\\) siano distribuiti normalmente con media \\(\\mu_i + \\theta_j\\) e varianza \\(\\sigma_y^2\\).\nIl codice Stan che implementa questo modello è il seguente:\n\nstan_file = os.path.join(project_directory, \"stan\", \"nuisance_params_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N1; // Number of participants in group 1 (intervention)\n  int&lt;lower=0&gt; N2; // Number of participants in group 2 (control)\n  array[N1] real y1; // Test scores for group 1\n  array[N2] real y2; // Test scores for group 2\n}\nparameters {\n  real mu1; // Mean test score for group 1\n  real mu2; // Mean test score for group 2\n  real&lt;lower=0&gt; sigma_y; // Standard deviation of test scores\n  real&lt;lower=0&gt; sigma_theta; // Standard deviation of baseline cognitive ability\n  array[N1 + N2] real theta; // Baseline cognitive abilities for all participants\n}\nmodel {\n  // Priors\n  mu1 ~ normal(0, 10);\n  mu2 ~ normal(0, 10);\n  sigma_y ~ normal(0, 5);\n  sigma_theta ~ normal(0, 5);\n  \n  for (j in 1 : (N1 + N2)) {\n    theta[j] ~ normal(0, sigma_theta); // Random effects for baseline abilities\n  }\n  \n  // Likelihood\n  for (j in 1 : N1) {\n    y1[j] ~ normal(mu1 + theta[j], sigma_y);\n  }\n  \n  for (j in 1 : N2) {\n    y2[j] ~ normal(mu2 + theta[N1 + j], sigma_y);\n  }\n}\ngenerated quantities {\n  real delta = mu1 - mu2; // Difference in means\n}\n\n\n\nEsaminiamo ora il codice Stan in dettaglio. I partecipanti sono suddivisi in due gruppi:\n\nGruppo 1 (Intervento): Partecipanti che hanno ricevuto l’intervento cognitivo.\nGruppo 2 (Controllo): Partecipanti che non hanno ricevuto l’intervento.\n\nOgni partecipante ha un punteggio al test, influenzato sia dall’appartenenza al gruppo (che riflette l’effetto del trattamento) sia dalle capacità cognitive di base individuali, che variano da persona a persona.\nIl punteggio di ciascun partecipante può essere visto come la somma di due componenti principali:\n\nComponente di gruppo: Questa componente rappresenta l’effetto generale dell’appartenenza al gruppo, ossia se il partecipante ha ricevuto l’intervento (Gruppo 1) o meno (Gruppo 2). Questo effetto è costante per tutti i partecipanti dello stesso gruppo.\n\nNel Gruppo 1 (Intervento), questa componente è rappresentata da \\(\\mu_1\\).\nNel Gruppo 2 (Controllo), questa componente è rappresentata da \\(\\mu_2\\).\nLa differenza tra \\(\\mu_1\\) e \\(\\mu_2\\) (\\(\\delta = \\mu_1 - \\mu_2\\)) è il parametro di interesse, poiché rappresenta l’effetto medio dell’intervento.\n\nComponente individuale: Questa componente cattura le differenze individuali nei punteggi dei test, attribuibili a vari fattori, come le capacità cognitive di base di ciascun partecipante. Questa componente varia tra i partecipanti ed è modellata come un “effetto casuale”.\n\nQuesto effetto è rappresentato da \\(\\theta_j\\), dove \\(j\\) indica il partecipante. Ogni \\(\\theta_j\\) descrive la deviazione del punteggio di un partecipante rispetto al valore previsto solo dall’effetto di gruppo.\n\n\nParametri di Disturbo. Il modello include diversi parametri di disturbo che, pur non essendo di interesse primario, sono essenziali per una descrizione accurata dei dati:\n\n\\(\\theta_j\\): Rappresenta le abilità cognitive di base dei partecipanti, distribuite normalmente attorno a 0 con deviazione standard \\(\\sigma_\\theta\\). Questi parametri sono considerati di disturbo poiché non sono il focus dell’analisi, ma sono necessari per modellare correttamente i punteggi.\n\\(\\sigma_y\\): Rappresenta la variabilità residua nei punteggi dei test che non può essere spiegata né dall’appartenenza al gruppo né dalle capacità cognitive individuali. Anche questo è un parametro di disturbo.\n\nIl modello descrive i punteggi come una combinazione dell’effetto di gruppo (\\(\\mu_i\\)) e delle differenze individuali (\\(\\theta_j\\)). Tuttavia, l’obiettivo principale è stimare \\(\\delta = \\mu_1 - \\mu_2\\), ovvero la differenza tra gli effetti medi dei due gruppi.\nMarginalizzazione. Per concentrarci su \\(\\delta\\), dobbiamo “marginalizzare” i parametri di disturbo \\(\\theta_j\\) e \\(\\sigma_y\\). In un contesto bayesiano, questo si ottiene integrando rispetto a questi parametri, cioè calcolando la distribuzione a posteriori di \\(\\delta\\) indipendentemente dai valori specifici dei parametri di disturbo. Questo processo avviene simulando l’intera distribuzione a posteriori (di tutti i parametri) e poi estraendo solo l’informazione rilevante su \\(\\delta\\).\nIn sintesi, i punteggi dei partecipanti del gruppo di intervento (\\(y_1\\)) e del gruppo di controllo (\\(y_2\\)) vengono scomposti in una componente di gruppo e una componente individuale. L’interesse principale risiede nella differenza tra le componenti di gruppo dei due gruppi (\\(\\delta\\)), mentre le differenze individuali (\\(\\theta_j\\)) sono considerate ma non sono l’oggetto principale dell’analisi.\nQuesto modello ci permette di stimare l’effetto dell’intervento cognitivo sui punteggi dei test, tenendo conto delle differenze individuali nelle capacità cognitive di base, e dimostra come i parametri di disturbo possano essere gestiti in modo efficace all’interno di un quadro bayesiano.\n\n\n65.2.2 Dati\nSimuliamo un campione di dati.\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Parameters for the simulation\nN1 = 50  # Number of participants in group 1 (intervention)\nN2 = 50  # Number of participants in group 2 (control)\n\nmu1_true = 10  # True mean test score for group 1\nmu2_true = 8  # True mean test score for group 2\nsigma_y_true = 2  # True standard deviation of test scores\nsigma_theta_true = 1  # True standard deviation of baseline cognitive abilities\n\n# Simulate baseline cognitive abilities for all participants\ntheta = np.random.normal(0, sigma_theta_true, N1 + N2)\n\n# Simulate test scores for group 1 (intervention)\ny1 = np.random.normal(mu1_true + theta[:N1], sigma_y_true)\n\n# Simulate test scores for group 2 (control)\ny2 = np.random.normal(mu2_true + theta[N1:], sigma_y_true)\n\n# Create the dictionary for Stan input\nstan_data = {\n    \"N1\": N1, \n    \"N2\": N2, \n    \"y1\": y1.tolist(), \n    \"y2\": y2.tolist()\n}\n\n# Output the generated data for verification\nprint(stan_data)\n\n{'N1': 50, 'N2': 50, 'y1': [7.665972668910404, 9.020445053298097, 9.962259505047152, 9.918475317964788, 9.443275201944646, 10.573964756679896, 15.351584617928452, 11.116590354816587, 10.045626395510576, 10.393668212053631, 5.699039876589454, 9.48124249553131, 10.362422691448087, 13.013203980312774, 7.890360237924723, 10.040807155426252, 8.91774534025509, 7.976891257356209, 11.37762155350883, 10.091562364038257, 13.047712663007648, 7.955448789923987, 12.873116826560123, 5.771549688201982, 10.629331463075358, 14.491833841329822, 6.86793377231632, 9.243102559140128, 9.598664040256478, 8.701354941974325, 6.2969665256383385, 11.989404134120992, 7.861895347809856, 9.889473932314464, 8.983696443635582, 11.879025160064057, 8.642357010332281, 7.396206843708874, 10.298848385840909, 7.7351326030012135, 11.19338644920367, 12.785653789754827, 6.669385248489304, 10.06816402147532, 9.04124359812942, 10.843801535159912, 7.065459807284048, 8.416209000050362, 11.387501420802256, 8.830929191103637], 'y2': [8.825069670086549, 8.307814138577635, 5.9630285565370595, 9.076183683162876, 9.617144469093313, 7.502577283063463, 10.892331499066875, 8.638453465972361, 5.948656436998267, 10.28865234439002, 5.571462421700067, 9.388510230821087, 9.21085618400878, 5.162428739215908, 10.739278080882842, 10.18180188244382, 9.572110198408646, 12.797118863199918, 7.870859793041893, 5.847407916679897, 6.5823667462573665, 7.906415996535093, 7.80997054206184, 10.246947605447293, 5.933636494570293, 10.476269002447271, 8.113050851993984, 10.608060803848765, 7.56244711005959, 11.452769418578345, 9.0316628076925, 6.642797458679182, 7.336109048619292, 8.446674612212723, 6.7445808264551115, 8.926243944599648, 9.861877366849164, 8.183093284345938, 5.7766523600961515, 5.4835729837416265, 7.204047645213997, 10.681442579179834, 7.726134394383055, 5.180860295978256, 7.954253698570206, 7.307119811325555, 6.52840540466231, 8.568505484070945, 8.12153089353446, 5.479472270963607]}\n\n\n\n\n65.2.3 Campionamento e Sintesi della Distribuzione a Posteriori\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo visivamente la distribuzione a posteriori.\n\naz.plot_trace(fit, var_names=[\"delta\"])\nplt.show()\n\n\n\n\n\n\n\n\nOtteniamo un sommario numerico della distribuzione a posteriori del parametro di interesse.\n\naz.summary(fit, var_names=[\"delta\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ndelta\n1.502\n0.406\n0.689\n2.231\n0.01\n0.007\n1666.0\n1863.0\n1.0\n\n\n\n\n\n\n\nSi osserva che la stima di \\(\\delta\\) è coerente con il valore teorico utilizzato per la simulazione dei dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/15_stan_nuisance_parameters.html#considerazioni-conclusive",
    "href": "chapters/mcmc/15_stan_nuisance_parameters.html#considerazioni-conclusive",
    "title": "65  Modelli con più di un parametro",
    "section": "65.3 Considerazioni Conclusive",
    "text": "65.3 Considerazioni Conclusive\nL’approccio bayesiano discusso in questo capitolo è strettamente correlato ai modelli gerarchici con intercette casuali, ma esistono importanti differenze che possono influenzare la scelta tra i due metodi.\nEntrambi gli approcci mirano a stimare la differenza tra i punteggi medi dei test nei due gruppi (\\(\\delta = \\mu_1 - \\mu_2\\)). Sia la marginalizzazione dei parametri di disturbo sia l’adozione di un modello gerarchico conducono a una distribuzione a posteriori per \\(\\delta\\), tenendo conto delle variazioni individuali nei punteggi (\\(\\theta_j\\)). Queste variazioni individuali, che non possono essere attribuite direttamente all’effetto di gruppo, vengono considerate in entrambi i metodi per garantire una stima accurata di \\(\\delta\\).\nTuttavia, ci sono differenze chiave tra i due approcci. La marginalizzazione si concentra sulla riduzione della complessità del modello, permettendo di isolare i parametri di interesse dopo aver considerato quelli di disturbo. Al contrario, il modello gerarchico prevede sin dall’inizio una struttura che include relazioni gerarchiche tra i parametri. In questo caso, la marginalizzazione avviene naturalmente durante il processo di inferenza, rendendo l’approccio gerarchico più integrato e coerente nella modellazione di dati complessi.\nIn termini di flessibilità e interpretazione, il modello gerarchico offre vantaggi significativi. La sua struttura consente di aggiungere facilmente ulteriori livelli di variazione o effetti casuali, rendendolo particolarmente adatto a contesti complessi con molteplici livelli gerarchici o dipendenze strutturate. D’altra parte, la marginalizzazione è un metodo diretto per concentrarsi sui parametri di interesse, ma potrebbe risultare meno flessibile quando si tratta di estendere il modello per includere nuove variabili o fonti di variazione.\nInfine, i modelli gerarchici bayesiani sono noti per la loro robustezza in contesti con più fonti di variazione e sono spesso preferiti in situazioni complesse. La loro capacità di modellare relazioni gerarchiche e dipendenze nei dati li rende strumenti particolarmente potenti per l’inferenza. Sebbene la marginalizzazione sia un approccio efficace, può risultare limitata rispetto ai modelli gerarchici quando si affrontano problemi con strutture dati più complesse.\nIn conclusione, sebbene entrambi gli approcci producano stime simili per parametri come \\(\\delta\\), il modello gerarchico bayesiano offre un quadro più generale e flessibile per gestire la complessità dei dati, soprattutto in presenza di più livelli di variazione o dipendenze strutturate. Pertanto, i modelli gerarchici sono generalmente preferibili in contesti più complessi o quando è necessaria una maggiore flessibilità nella modellazione, in linea con le indicazioni della letteratura scientifica.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/15_stan_nuisance_parameters.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/15_stan_nuisance_parameters.html#informazioni-sullambiente-di-sviluppo",
    "title": "65  Modelli con più di un parametro",
    "section": "65.4 Informazioni sull’Ambiente di Sviluppo",
    "text": "65.4 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Oct 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\npandas    : 2.2.2\narviz     : 0.18.0\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nscipy     : 1.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Modelli con più di un parametro</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "",
    "text": "Introduzione\nNel capitolo precedente, abbiamo esplorato un modello gerarchico focalizzato sulla marginalizzazione dei parametri di disturbo. In questo nuovo capitolo, introduciamo una variante del modello gerarchico, applicata a un contesto in cui osserviamo il numero di successi ottenuti da ciascun partecipante su un numero fisso di prove. In questo caso, trattiamo la probabilità di successo di ciascun partecipante come una variabile incerta che vogliamo inferire.\nSebbene entrambi i modelli adottino un approccio gerarchico per gestire la variabilità individuale, si distinguono per i parametri di interesse e il modo in cui affrontano questa variabilità. Nel modello precedente, l’attenzione era rivolta alla stima di una differenza media di gruppo, marginalizzando esplicitamente i parametri individuali. Il modello attuale, invece, è orientato principalmente a stimare le probabilità di successo individuali, consentendo l’inferenza bayesiana in un contesto diverso, con obiettivi specifici.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html#motivazione-per-i-modelli-gerarchici-bayesiani",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html#motivazione-per-i-modelli-gerarchici-bayesiani",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "66.1 Motivazione per i Modelli Gerarchici Bayesiani",
    "text": "66.1 Motivazione per i Modelli Gerarchici Bayesiani\nI modelli gerarchici bayesiani sono potenti strumenti per stimare parametri individuali basandosi su dati raccolti da un campione di partecipanti. In un mondo ideale, potremmo osservare direttamente i parametri di interesse, ma nella realtà dobbiamo inferirli dalle scelte o risposte dei partecipanti. Se disponiamo di un modello probabilistico che collega i parametri ai dati osservati e forniamo una distribuzione a priori ragionevole per tali parametri, possiamo usare l’inferenza bayesiana per apprendere su di essi.\nUn aspetto fondamentale dei modelli gerarchici è che, avendo dati da più partecipanti, possiamo sfruttare questa informazione condivisa per migliorare le stime dei parametri di ciascun individuo. Questo è particolarmente utile negli esperimenti psicologici, dove si presume che i partecipanti appartengano a una popolazione omogenea e che i loro parametri siano estratti dalla stessa distribuzione.\n\n66.1.1 Inferenza sui Parametri a Livello di Popolazione\nUn aspetto chiave dei modelli gerarchici è l’inferenza sui parametri a livello di popolazione. Ogni partecipante fornisce informazioni non solo sul proprio parametro, ma anche sui parametri che governano la distribuzione dell’intera popolazione. Conoscere questi parametri di livello superiore ci consente di migliorare la stima dei parametri individuali, in quanto agiscono come distribuzioni a priori per ogni partecipante. Inoltre, la conoscenza dei parametri a livello di popolazione è spesso di maggiore interesse per i ricercatori, in quanto consente di fare affermazioni che si estendono oltre il campione osservato e riguardano la popolazione generale.\n\n\n66.1.2 Struttura Gerarchica dei Dati\nPer illustrare l’uso dei modelli gerarchici, consideriamo uno studio sulla “terapia tattile”, una pratica infermieristica controversa (Kruschke, 2014). L’esperimento, condotto da Rosa et al. (1998), mirava a testare la capacità degli operatori di percepire “campi energetici” senza contatto visivo. Gli operatori dovevano identificare quale delle loro mani era stata “selezionata” da un esaminatore, senza poter vedere, in 10 prove per operatore, con risposte classificate come “corrette” o “errate”.\nIn questo contesto, la struttura gerarchica emerge naturalmente. Al livello più basso, abbiamo le singole prove di ciascun operatore. Queste prove sono raggruppate per operatore, formando il secondo livello della gerarchia. Infine, tutti gli operatori appartengono alla popolazione generale di praticanti di terapia tattile, rappresentando il livello più alto della gerarchia.\nQuesta struttura ci permette di stimare non solo le abilità individuali degli operatori, ma anche i parametri che descrivono la distribuzione delle abilità nella popolazione complessiva. Possiamo così quantificare l’eterogeneità tra gli operatori e valutare se le loro prestazioni superano ciò che ci aspetteremmo dal caso. L’approccio gerarchico bayesiano diventa un potente strumento per comprendere la variabilità nei dati e migliorare la nostra capacità di fare inferenze sia a livello individuale che di popolazione.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html#modelli-gerarchici-bayesiani-una-panoramica-tecnica",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html#modelli-gerarchici-bayesiani-una-panoramica-tecnica",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "66.2 Modelli Gerarchici Bayesiani: Una Panoramica Tecnica",
    "text": "66.2 Modelli Gerarchici Bayesiani: Una Panoramica Tecnica\nNei modelli gerarchici bayesiani (BHM), non specifichiamo direttamente la distribuzione a priori dei parametri individuali. Invece, facciamo dipendere questa distribuzione da altri parametri, chiamati iperparametri. Questo approccio riflette una gerarchia di inferenza: inferiamo prima i parametri a livello di popolazione, e poi usiamo queste informazioni per inferire i parametri individuali.\nAd esempio, in un modello non-gerarchico, potremmo specificare una distribuzione a priori completamente definita per ogni parametro individuale (ad es., una Gaussiana univariata per ciascun parametro). Nei modelli gerarchici, invece, la distribuzione dei parametri individuali dipende da iperparametri che descrivono la distribuzione a livello di popolazione.\nLa formulazione di questi modelli può essere scritta come:\n\nVerosimiglianza: \\(p(y \\mid \\theta)\\)\nPrior: \\(p(\\theta \\mid \\xi)\\)\nIperprior: \\(p(\\xi)\\)\n\nDunque, la differenza chiave è che la distribuzione a priori dei parametri individuali dipende da una distribuzione superiore, introdotta dagli iperparametri, creando così un sistema di inferenza a più livelli. Questo processo, sebbene concettualmente non nuovo, consente un’inferenza più precisa, poiché sfrutta le informazioni a livello di popolazione per migliorare la stima dei parametri individuali.\nIn sintesi, i modelli gerarchici bayesiani rappresentano un approccio flessibile e potente per affrontare problemi inferenziali complessi, particolarmente utili quando si vuole modellare la variabilità tra soggetti in modo rigoroso e coerente.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html#analisi-bayesiana-della-terapia-tattile",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "66.3 Analisi Bayesiana della “Terapia Tattile”",
    "text": "66.3 Analisi Bayesiana della “Terapia Tattile”\nLo studio condotto da Rosa et al. (1998) ha coinvolto un campione di 28 operatori. L’obiettivo della ricerca è valutare la proporzione di risposte corrette per ciascun operatore e confrontarla con una proporzione attesa di 0.50, che rappresenta l’ipotesi nulla di performance casuale. L’analisi principale mira a determinare se, complessivamente, il gruppo di operatori mostra una prestazione statisticamente superiore a quella attesa in base al puro caso. Inoltre, verranno esplorate le differenze individuali tra gli operatori.\nPer iniziare, importeremo i dati forniti da Kruschke (2014).\n\n# Define the URL of the CSV file on GitHub\nurl = \"https://raw.githubusercontent.com/boboppie/kruschke-doing_bayesian_data_analysis/master/2e/TherapeuticTouchData.csv\"\n# Download the content of the CSV file\nresponse = requests.get(url)\ntt_dat = pd.read_csv(StringIO(response.text))\nprint(tt_dat.head())\n\n   y    s\n0  1  S01\n1  0  S01\n2  0  S01\n3  0  S01\n4  0  S01\n\n\n\ntt_dat.shape\n\n(280, 2)\n\n\nNella colonna y, il valore 1 indica una risposta corretta, mentre 0 indica una risposta errata. La seconda colonna contiene il codice identificativo di ciascun operatore.\nCalcoliamo la proporzione di risposte corrette per ciascun operatore.\n\ntt_agg = tt_dat.groupby(\"s\").agg(proportion_correct=(\"y\", \"mean\")).reset_index()\nprint(tt_agg)\n\n\n\n\n\n\n\n\ns\nproportion_correct\n\n\n\n\n0\nS01\n0.1\n\n\n1\nS02\n0.2\n\n\n2\nS03\n0.3\n\n\n3\nS04\n0.3\n\n\n4\nS05\n0.3\n\n\n5\nS06\n0.3\n\n\n6\nS07\n0.3\n\n\n7\nS08\n0.3\n\n\n8\nS09\n0.3\n\n\n9\nS10\n0.3\n\n\n10\nS11\n0.4\n\n\n11\nS12\n0.4\n\n\n12\nS13\n0.4\n\n\n13\nS14\n0.4\n\n\n14\nS15\n0.4\n\n\n15\nS16\n0.5\n\n\n16\nS17\n0.5\n\n\n17\nS18\n0.5\n\n\n18\nS19\n0.5\n\n\n19\nS20\n0.5\n\n\n20\nS21\n0.5\n\n\n21\nS22\n0.5\n\n\n22\nS23\n0.6\n\n\n23\nS24\n0.6\n\n\n24\nS25\n0.7\n\n\n25\nS26\n0.7\n\n\n26\nS27\n0.7\n\n\n27\nS28\n0.8\n\n\n\n\n\n\n\nCostruiamo un modello gerarchico partendo dall’ipotesi che il numero di risposte corrette di ciascun operatore sia modellato da una variabile casuale binomiale. Per ciascuno dei ventotto operatori, possiamo esprimere questo come segue:\n\\[\ny_i \\sim \\text{Binomial}(n_i, p_i),\n\\]\ndove \\(i = 0, \\dots, 27\\).\nPer modellare la distribuzione a priori del parametro sconosciuto \\(p_i\\), possiamo utilizzare una distribuzione Beta con parametri \\(a\\) e \\(b\\) – si veda {cite:t}doingbayesian:\n\\[\np_i \\sim \\text{Beta}(a, b).\n\\]\nÈ importante notare che gli iperparametri \\(a\\) e \\(b\\) sono condivisi tra tutti gli operatori, caratteristica che definisce un modello gerarchico.\nSe \\(a\\) e \\(b\\) sono noti, la distribuzione a posteriori del parametro \\(p\\) per ciascun operatore, dati i risultati osservati \\(y_i\\), è anch’essa una distribuzione Beta:\n\\[\np_i \\mid y_i \\sim \\text{Beta}(a + y_i, b + n_i - y_i).\n\\]\nNel caso più generale, dove gli iperparametri \\(a\\) e \\(b\\) sono incogniti, è necessario stabilire una distribuzione a priori anche per questi. Nell’esempio seguente, useremo i seguenti prior:\n\\[\na \\sim \\text{Gamma}(8, 12)\\\\\nb \\sim \\text{Gamma}(27, 5)\n\\]\nPer applicare il modello gerarchico descritto sopra ai dati del therapeutic touch, iniziamo a calcolare il numero di risposte corrette di ciascun operatore.\n\nresult = tt_dat.groupby(\"s\")[\"y\"].sum().reset_index()\ny = result[\"y\"]\nprint(y)\n\n0     1\n1     2\n2     3\n3     3\n4     3\n5     3\n6     3\n7     3\n8     3\n9     3\n10    4\n11    4\n12    4\n13    4\n14    4\n15    5\n16    5\n17    5\n18    5\n19    5\n20    5\n21    5\n22    6\n23    6\n24    7\n25    7\n26    7\n27    8\nName: y, dtype: int64\n\n\nCreiamo il vettore N che fornisce il numero di prove per ciascun operatore.\n\nN = tt_dat.groupby(\"s\")[\"y\"].count()\n\nEsaminiamo dunque i dati a disposizione.\n\nprint(*N)\n\n10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n\n\n\nprint(y)\n\n0     1\n1     2\n2     3\n3     3\n4     3\n5     3\n6     3\n7     3\n8     3\n9     3\n10    4\n11    4\n12    4\n13    4\n14    4\n15    5\n16    5\n17    5\n18    5\n19    5\n20    5\n21    5\n22    6\n23    6\n24    7\n25    7\n26    7\n27    8\nName: y, dtype: int64\n\n\nCreaiamo un dizionario con i dati necessari per Stan.\n\ndata = {\n    \"N\": 28,\n    \"y\": y.tolist(),\n    \"n_trials\": N.tolist()\n}\n\nprint(data)\n\n{'N': 28, 'y': [1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 7, 8], 'n_trials': [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html#modello-stan",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html#modello-stan",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "66.4 Modello Stan",
    "text": "66.4 Modello Stan\nLeggiamo il codice Stan che implementa il modello gerarchico.\n\nstan_file = os.path.join(project_directory, \"stan\", \"h_beta_binom_model.stan\")\n\nwith open(stan_file, \"r\") as f:\n    print(f.read())\n\ndata {\n  int&lt;lower=0&gt; N;  // Number of participants\n  array[N] int&lt;lower=0&gt; y;  // Number of successes for each participant\n  array[N] int&lt;lower=0&gt; n_trials;  // Number of trials for each participant\n}\n\nparameters {\n  real&lt;lower=0&gt; alpha;  // Alpha parameter for the Beta distribution\n  real&lt;lower=0&gt; beta;   // Beta parameter for the Beta distribution\n  array[N] real&lt;lower=0, upper=1&gt; p;  // Success probability for each participant\n}\n\nmodel {\n  // Priors\n  alpha ~ gamma(8, 2);\n  beta ~ gamma(27, 5);\n  \n  // Each participant's success probability follows a Beta distribution\n  p ~ beta(alpha, beta);\n  \n  // Likelihood of the observed data\n  for (i in 1:N) {\n    y[i] ~ binomial(n_trials[i], p[i]);\n  }\n}\n\ngenerated quantities {\n  real overall_p = alpha / (alpha + beta);  // Calculate the mean success probability\n}\n\n\n\nNel modello:\n\nN è il numero totale di partecipanti\ny è un array che contiene il numero di successi per ogni partecipante\nn_trials è un array che contiene il numero di prove per ogni partecipante\n\nIl modello è chiamato “gerarchico” perché considera due livelli:\n\nIl livello individuale: ogni partecipante ha la propria probabilità di successo\nIl livello di gruppo: c’è una distribuzione generale che descrive come variano le probabilità di successo tra i partecipanti\n\n\np: È un array che contiene la vera probabilità di successo per ogni partecipante.\nalpha e beta: Sono i parametri che definiscono la distribuzione Beta, che descrive come variano le probabilità di successo tra i partecipanti.\n\nImpostiamo delle prior per alpha e beta:\nalpha ~ gamma(8, 2);\nbeta ~ gamma(27, 5);\nQueste prior riflettono le nostre conoscenze o supposizioni iniziali sui possibili valori di questi parametri.\np ~ beta(alpha, beta);\nQuesta riga è il cuore del modello gerarchico. Dice che la probabilità di successo di ogni partecipante (p) segue una distribuzione Beta, i cui parametri sono alpha e beta. Questo crea un legame tra tutti i partecipanti: le loro prestazioni individuali sono considerate come variazioni attorno a una tendenza generale del gruppo.\nfor (i in 1:N) {\n  y[i] ~ binomial(n_trials[i], p[i]);\n}\nQuesta parte del modello descrive come i dati osservati (y) sono generati, dato il numero di prove (n_trials) e la vera probabilità di successo (p) per ogni partecipante.\nreal overall_p = alpha / (alpha + beta);\nQuesta riga calcola la probabilità di successo media per l’intero gruppo.\nIn conclusione, questo modello ci permette di stimare la probabilità di successo individuale per ogni partecipante, comprendere come queste probabilità variano nel gruppo e ottenere una stima della probabilità di successo media per l’intero gruppo. Il vantaggio principale di questo approccio gerarchico è che combina informazioni a livello individuale e di gruppo, permettendo stime più precise, specialmente per i partecipanti con pochi dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html#compilazione-e-sampling",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html#compilazione-e-sampling",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "66.5 Compilazione e sampling",
    "text": "66.5 Compilazione e sampling\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(\n    data=data,\n    iter_warmup=2000, \n    iter_sampling=4000,\n    seed=84735, \n    chains=4,\n    show_progress=False, \n    show_console=False\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html#esame-delle-distribuzioni-a-posteriori",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html#esame-delle-distribuzioni-a-posteriori",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "66.6 Esame delle distribuzioni a posteriori",
    "text": "66.6 Esame delle distribuzioni a posteriori\nEsaminiamo le stime a posteriori dei parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"p\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n4.591\n0.866\n2.991\n6.359\n0.008\n0.006\n10600.0\n10141.0\n1.0\n\n\nbeta\n5.756\n0.932\n4.009\n7.623\n0.008\n0.006\n12032.0\n11787.0\n1.0\n\n\np[0]\n0.273\n0.100\n0.091\n0.469\n0.001\n0.000\n20279.0\n11628.0\n1.0\n\n\np[1]\n0.324\n0.103\n0.129\n0.524\n0.001\n0.001\n20614.0\n11911.0\n1.0\n\n\np[2]\n0.373\n0.107\n0.174\n0.588\n0.001\n0.001\n20791.0\n11355.0\n1.0\n\n\np[3]\n0.372\n0.106\n0.179\n0.590\n0.001\n0.001\n22416.0\n11620.0\n1.0\n\n\np[4]\n0.373\n0.107\n0.173\n0.582\n0.001\n0.001\n22260.0\n11753.0\n1.0\n\n\np[5]\n0.374\n0.106\n0.173\n0.583\n0.001\n0.001\n21443.0\n12716.0\n1.0\n\n\np[6]\n0.372\n0.106\n0.172\n0.580\n0.001\n0.001\n21992.0\n12317.0\n1.0\n\n\np[7]\n0.372\n0.106\n0.173\n0.582\n0.001\n0.001\n21133.0\n11017.0\n1.0\n\n\np[8]\n0.372\n0.105\n0.176\n0.583\n0.001\n0.001\n21459.0\n11369.0\n1.0\n\n\np[9]\n0.372\n0.108\n0.167\n0.580\n0.001\n0.001\n22007.0\n11102.0\n1.0\n\n\np[10]\n0.422\n0.108\n0.209\n0.627\n0.001\n0.001\n21331.0\n12556.0\n1.0\n\n\np[11]\n0.421\n0.109\n0.217\n0.634\n0.001\n0.001\n22045.0\n11591.0\n1.0\n\n\np[12]\n0.422\n0.108\n0.213\n0.632\n0.001\n0.001\n22874.0\n12190.0\n1.0\n\n\np[13]\n0.421\n0.110\n0.214\n0.637\n0.001\n0.001\n22807.0\n12055.0\n1.0\n\n\np[14]\n0.421\n0.109\n0.213\n0.634\n0.001\n0.001\n21851.0\n12199.0\n1.0\n\n\np[15]\n0.471\n0.112\n0.257\n0.689\n0.001\n0.001\n22072.0\n10892.0\n1.0\n\n\np[16]\n0.471\n0.111\n0.249\n0.680\n0.001\n0.001\n22559.0\n11739.0\n1.0\n\n\np[17]\n0.470\n0.111\n0.258\n0.683\n0.001\n0.001\n23384.0\n11679.0\n1.0\n\n\np[18]\n0.471\n0.111\n0.259\n0.688\n0.001\n0.001\n22495.0\n11479.0\n1.0\n\n\np[19]\n0.471\n0.111\n0.264\n0.691\n0.001\n0.001\n22949.0\n11720.0\n1.0\n\n\np[20]\n0.472\n0.110\n0.251\n0.680\n0.001\n0.001\n22288.0\n11847.0\n1.0\n\n\np[21]\n0.472\n0.109\n0.264\n0.685\n0.001\n0.001\n24414.0\n12216.0\n1.0\n\n\np[22]\n0.519\n0.109\n0.306\n0.728\n0.001\n0.001\n22363.0\n11502.0\n1.0\n\n\np[23]\n0.521\n0.111\n0.305\n0.732\n0.001\n0.001\n20720.0\n11618.0\n1.0\n\n\np[24]\n0.570\n0.109\n0.357\n0.780\n0.001\n0.001\n22438.0\n11048.0\n1.0\n\n\np[25]\n0.570\n0.109\n0.349\n0.772\n0.001\n0.001\n20850.0\n12520.0\n1.0\n\n\np[26]\n0.569\n0.110\n0.358\n0.786\n0.001\n0.001\n21973.0\n11715.0\n1.0\n\n\np[27]\n0.620\n0.107\n0.409\n0.821\n0.001\n0.001\n22119.0\n11629.0\n1.0\n\n\n\n\n\n\n\nLe distribuzioni posteriori degli iperparametri, prese da sole, non hanno un significato chiaro. Tuttavia, possiamo utilizzarle per calcolare la distribuzione a posteriori della probabilità di una risposta corretta per tutto il gruppo.\nConvertiamo l’oggetto fit creato da cmdstanpy in un oggetto InferenceData usando ArviZ:\n\nidata = az.from_cmdstanpy(posterior=fit)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html#schrinkage-bayesiano",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html#schrinkage-bayesiano",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "66.7 Schrinkage bayesiano",
    "text": "66.7 Schrinkage bayesiano\nNel contesto dei modelli gerarchici bayesiani, il fenomeno dello “shrinkage” (contrazione o riduzione) è un aspetto fondamentale e desiderabile, specialmente quando si modellano dati provenienti da gruppi o sotto-popolazioni con campionature di dimensioni diverse o variazioni intrinseche. Questo fenomeno può essere particolarmente rilevante e utile nel tuo modello gerarchico per il numero di risposte corrette di ciascun operatore, modello che utilizza una distribuzione binomiale per le osservazioni e una Beta per i priori dei parametri di successo \\(p_i\\).\nLo “shrinkage” in un modello bayesiano gerarchico si riferisce al processo per cui le stime dei parametri individuali (ad esempio, le probabilità di successo per ciascun operatore nel presente modello) sono “spostate” verso una media di gruppo. Questo accade perché il modello considera sia i dati osservati per ciascun gruppo (o individuo) sia le informazioni aggiuntive fornite dalla struttura gerarchica e dai dati degli altri gruppi.\nNel presente modello:\n\nogni operatore ha una probabilità di successo \\(p_i\\) che segue una distribuzione \\(\\text{Beta}(a, b)\\), dove \\(a\\) e \\(b\\) sono iperparametri condivisi tra tutti gli operatori;\ngli iperparametri \\(a\\) e \\(b\\) sono stimati dai dati di tutti gli operatori, e quindi forniscono una base comune che riflette le caratteristiche medie di tutti gli operatori.\n\nSe un operatore ha pochi dati (ad esempio, pochi tentativi o risposte), la stima di \\(p_i\\) per quell’operatore sarà fortemente influenzata dai valori di \\(a\\) e \\(b\\), “spostando” la stima di \\(p_i\\) verso la media di gruppo. Questo riduce l’impatto delle fluttuazioni casuali nei dati di quell’operatore, che potrebbero altrimenti portare a stime eccessivamente ottimistiche o pessimistiche.\nLo shrinkage ha i seguenti benefici:\n\nmigliore Stima per Gruppi con Pochi Dati. Operatori con meno dati beneficiano maggiormente dello shrinkage, in quanto le loro stime sono stabilizzate attraverso l’informazione “prestata” dagli altri operatori;\nriduzione dell’Overfitting. Il modello evita di adattarsi troppo ai dati di un singolo operatore, specialmente quando questi sono limitati o rumorosi, risultando in generalizzazioni più robuste;\nincorporazione della Struttura dei Dati. Lo shrinkage riflette l’assunzione che gli operatori siano simili ma non identici, permettendo una certa individualità ma entro un quadro comune che li lega.\n\nSupponiamo che alcuni operatori abbiano mostrato risultati estremamente buoni o cattivi, che potrebbero essere dovuti a varianze casuali. Lo shrinkage modera queste stime estreme, specialmente se non sono supportate da una grande quantità di dati, rendendo le previsioni finali più credibili e meno soggette a errori casuali.\nIn conclusione, lo shrinkage in un modello gerarchico aiuta a ottenere stime più accurate e credibili per tutti i membri del gruppo, sfruttando le informazioni collettive e limitando l’impatto delle anomalie nei dati individuali.\nPer rappresentare visivamente questo fenomeno, iniziamo con il recuperare le stime a posteriori di alpha e beta.\n\nalphas = idata.posterior[\"alpha\"]\nbetas = idata.posterior[\"beta\"]\n\nCreiamo un array che contiene le stime bayesiane della probabilità di successo di ciascun operatore fornite sopra dalla funzione summary di ArviZ. Per fare questo usiamo le funzionalità di xarray.\n\n# Calcola la media lungo le dimensioni 'chain' e 'draw'\nbayesian_estimates = idata.posterior[\"p\"].mean(dim=(\"chain\", \"draw\"))\nprint(bayesian_estimates.values)\n\n[0.27273311 0.32377131 0.37344338 0.37214022 0.37257493 0.37351838\n 0.37219305 0.37214675 0.37185773 0.37173435 0.42165569 0.42127528\n 0.42172633 0.42118034 0.42149943 0.47116033 0.47087155 0.46970487\n 0.47107502 0.47138671 0.47205312 0.47221249 0.51906367 0.52052519\n 0.57032404 0.57017976 0.56928041 0.62016621]\n\n\nGeneriamo un array con le probabilità empiriche.\n\n# Empirical probabilities\nempirical_probs = y.values / N.values\nprint(empirical_probs)\n\n[0.1 0.2 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.5 0.5 0.5\n 0.5 0.5 0.5 0.5 0.6 0.6 0.7 0.7 0.7 0.8]\n\n\nIl grafico seguente confronta le probabilità empiriche con le stime Bayesiane per la probabilità di successo associata a ciascun operatore. Questa rappresentazione evidenzia il fenomeno di “shrinkage” intrinseco ai modelli Bayesiani gerarchici. In particolare, il grafico illustra come le stime Bayesiane delle probabilità di successo per gli operatori tendono a convergere verso la media generale, in confronto alle probabilità empiriche.\n\n# Calcola la media generale delle probabilità empiriche\nmean_empirical_prob = np.mean(empirical_probs)\nmean_empirical_prob\n\n0.43928571428571417\n\n\n\n# Calcola la media generale delle stime Bayesiane\nmean_bayesian_estimate = np.mean(bayesian_estimates)\nmean_bayesian_estimate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'p' ()&gt; Size: 8B\narray(0.44112334)xarray.DataArray'p'0.4411array(0.44112334)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\n\n# Crea il grafico\nplt.figure()\n\n# Traccia le probabilità empiriche\nplt.scatter(range(1, 29), empirical_probs, label=\"Probabilità Empiriche\")\n\n# Traccia le stime Bayesiane\nplt.scatter(range(1, 29), bayesian_estimates, color=\"C1\", label=\"Stime Bayesiane\")\n\n# Aggiungi linee orizzontali per indicare le medie generali\nplt.axhline(\n    y=mean_empirical_prob,\n    linestyle=\"--\",\n    label=f\"Media Generale Empirica: {mean_empirical_prob:.2f}\",\n)\nplt.axhline(\n    y=mean_bayesian_estimate,\n    linestyle=\"--\",\n    label=f\"Media Generale Bayesiana: {mean_bayesian_estimate:.2f}\",\n)\n\n# Etichette e titolo\nplt.xlabel(\"Indice dell'Operatore\")\nplt.ylabel(\"Probabilità di Successo\")\nplt.title(\"Fenomeno dello Shrinkage in un Modello Bayesiano Gerarchico\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nEsaminiamo la distribuzione a posteriori dei parametri alpha e beta.\n\naz.plot_posterior(idata, var_names=[\"alpha\", \"beta\"], figsize=(9, 3))\nplt.show()\n\n\n\n\n\n\n\n\n\n_ = az.plot_trace(idata, combined=True, figsize=(9, 6), kind=\"rank_bars\")\n\n\n\n\n\n\n\n\nLe distribuzioni posteriori degli iperparametri, prese da sole, non hanno un significato chiaro. Tuttavia, possiamo utilizzarle per calcolare la distribuzione a posteriori della probabilità di una risposta corretta per tutto il gruppo.\n\n# Function to calculate the mean of a Beta distribution\ndef beta_mean(alpha, beta):\n    return alpha / (alpha + beta)\n\n# Calculate the means for each pair of alpha and beta\nsample_posterior_x_means = np.array([beta_mean(a, b) for a, b in zip(alphas, betas)])\n\n\nsample_posterior_x_means.shape\n\n(4, 4000)\n\n\n\nsample_posterior_x_means\n\narray([[0.37604496, 0.41922669, 0.47345362, ..., 0.49569844, 0.47777766,\n        0.4247707 ],\n       [0.45096577, 0.41051049, 0.49462864, ..., 0.50996786, 0.53271226,\n        0.4371311 ],\n       [0.47134244, 0.47201767, 0.44473739, ..., 0.35595368, 0.41136842,\n        0.46184053],\n       [0.36027889, 0.42282699, 0.43706697, ..., 0.41162794, 0.43983373,\n        0.46031791]])\n\n\n\nprint(sample_posterior_x_means.mean())\n\n0.4428264916259948\n\n\n\n_ = az.plot_posterior(sample_posterior_x_means)\n\n\n\n\n\n\n\n\nL’intervallo [0.37, 0.51] rappresenta l’intervallo di credibilità al 94% per la probabilità di risposta corretta p, considerando l’insieme del gruppo degli operatori. Questo intervallo ci fornisce un’indicazione sulla variabilità delle probabilità di successo tra gli operatori, considerando sia le differenze tra di loro che le somiglianze all’interno del gruppo.\nPoiché l’intervallo di credibilità include il valore 0.5, possiamo concludere che non ci sono evidenze credibili che gli operatori, considerati nel loro insieme, siano in grado di “percepire il campo energetico di una persona senza vedere le mani” ad un livello diverso rispetto a quello che ci si potrebbe aspettare dal caso soltanto.\n\n66.7.1 Considerazioni Conclusive\nIn questo capitolo, abbiamo introdotto l’approccio gerarchico bayesiano, un potente strumento per l’analisi di dati strutturati su più livelli. Per comprendere meglio la sua rilevanza e applicazione, consideriamo la seguente analogia.\nImmaginiamo un’urna contenente palline blu e rosse. Stimare la proporzione di palline blu in un campione estratto da questa urna è un problema statistico elementare. Tuttavia, la realtà è spesso più complessa. Pensiamo invece a uno scenario più articolato: un’urna grande che contiene diverse urne più piccole, ognuna con la propria proporzione di palline blu e rosse. Questa situazione riflette meglio la complessità dei dati che incontriamo nel mondo reale.\nIn questo contesto più complesso, emergono due approcci estremi, entrambi insoddisfacenti. Da un lato, potremmo trattare ogni urna piccola come completamente indipendente dalle altre, ignorando il fatto che tutte provengono dalla stessa urna grande e sono quindi potenzialmente correlate. Dall’altro, potremmo concentrarci esclusivamente sull’urna grande, trascurando le peculiarità di ciascuna urna piccola. Entrambi questi approcci perdono informazioni cruciali sulla struttura dei dati.\nÈ qui che l’approccio gerarchico bayesiano rivela la sua potenza. Esso ci permette di modellare simultaneamente sia le caratteristiche individuali delle urne piccole sia la loro relazione con l’urna grande che le contiene. In termini statistici, questo si traduce nella capacità di stimare non solo i parametri specifici di ogni gruppo (le urne piccole), ma anche i parametri che descrivono la distribuzione di questi gruppi nella popolazione più ampia (l’urna grande).\nNel corso del capitolo, abbiamo applicato questo concetto a un modello con verosimiglianza binomiale. Questo esempio ci ha permesso di illustrare come l’approccio gerarchico possa essere implementato per gestire dati organizzati su più livelli. Abbiamo visto come sia possibile stimare le probabilità di successo per ogni unità individuale (equivalente alle urne piccole nella nostra analogia), tenendo conto al contempo della distribuzione di queste probabilità nella popolazione generale (l’urna grande).\nI vantaggi di questo approccio sono molteplici. In primo luogo, ci consente di effettuare stime più precise per ogni unità individuale, sfruttando l’informazione proveniente dall’intero dataset. Questo è particolarmente utile quando abbiamo poche osservazioni per alcune unità. In secondo luogo, ci permette di quantificare la variabilità tra le unità, fornendo preziose informazioni sulla struttura della popolazione. Infine, ci offre un framework naturale per fare previsioni su nuove unità non osservate, basandoci sulla distribuzione stimata a livello di popolazione.\nL’approccio gerarchico bayesiano si rivela quindi uno strumento estremamente versatile e potente per affrontare problemi statistici complessi. Esso ci permette di modellare esplicitamente la struttura multilivello dei dati, migliorando la nostra comprensione delle relazioni intrinseche tra le variabili e fornendo inferenze più robuste e informative.\nIn conclusione, l’adozione di modelli gerarchici bayesiani apre nuove possibilità nell’analisi dei dati, permettendoci di affrontare con maggiore efficacia la complessità e la ricchezza delle informazioni presenti in molti domini psicologici. Mentre ci muoviamo verso analisi sempre più sofisticate, l’approccio gerarchico bayesiano si configura come un pilastro fondamentale nel toolkit del moderno analista di dati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/16_stan_hier_beta_binom.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/16_stan_hier_beta_binom.html#informazioni-sullambiente-di-sviluppo",
    "title": "66  Modello gerarchico beta-binomiale con Stan",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nrequests  : 2.32.3\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nKruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nRosa, L., Rosa, E., Sarner, L., & Barrett, S. (1998). A close look at therapeutic touch. Jama, 279(13), 1005–1010.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Modello gerarchico beta-binomiale con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html",
    "href": "chapters/mcmc/17_stan_categorical.html",
    "title": "67  Modello categoriale",
    "section": "",
    "text": "Introduzione\nNel capitolo Capitolo 105, utilizzeremo Stan per stimare i parametri di un processo dinamico utilizzando un modello di Markov di primo ordine. In quella discussione, impiegheremo la distribuzione di probabilità categoriale. L’obiettivo di questo capitolo è familiarizzare con questa distribuzione.\nLa variabile casuale più semplice può assumere solo due stati, comunemente denominati “successo” e “fallimento”. Tuttavia, variabili casuali più complesse possono avere più di due stati possibili. In questo capitolo, esploreremo come la teoria della probabilità tratta questi diversi scenari.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#distribuzioni-bernoulliana-e-binomiale",
    "href": "chapters/mcmc/17_stan_categorical.html#distribuzioni-bernoulliana-e-binomiale",
    "title": "67  Modello categoriale",
    "section": "67.1 Distribuzioni Bernoulliana e Binomiale",
    "text": "67.1 Distribuzioni Bernoulliana e Binomiale\n1. Distribuzione Bernoulliana:\n\nLa distribuzione Bernoulliana (o di Bernoulli) è una distribuzione di probabilità discreta che descrive l’esito di un singolo esperimento dicotomico, cioè un evento che ha due possibili risultati: “successo” (generalmente codificato come 1) o “fallimento” (codificato come 0).\nUn esempio classico è il lancio di una moneta: “testa” (successo) o “croce” (fallimento).\nLa probabilità di successo è denotata con \\(p\\) e quella di fallimento con \\(1 - p\\).\n\n2. Distribuzione Binomiale:\n\nLa distribuzione Binomiale descrive il numero di successi in una sequenza di \\(N\\) esperimenti indipendenti, ognuno dei quali segue una distribuzione di Bernoulli con probabilità di successo \\(p\\).\nUn esempio potrebbe essere il numero di volte in cui si ottiene “testa” quando si lancia una moneta 10 volte.\nLa distribuzione binomiale ha due parametri: il numero di prove \\(N\\) e la probabilità di successo \\(p\\).",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#distribuzioni-categoriale-e-multinomiale",
    "href": "chapters/mcmc/17_stan_categorical.html#distribuzioni-categoriale-e-multinomiale",
    "title": "67  Modello categoriale",
    "section": "67.2 Distribuzioni Categoriale e Multinomiale",
    "text": "67.2 Distribuzioni Categoriale e Multinomiale\n1. Distribuzione Categoriale:\n\nLa distribuzione Categoriale è una generalizzazione della distribuzione di Bernoulli per variabili aleatorie con più di due categorie possibili.\nÈ utilizzata per descrivere l’esito di un singolo esperimento che può avere più di due risultati discreti (categorie), ciascuno con una propria probabilità.\nUn esempio psicologico potrebbe essere una prova in cui un partecipante deve scegliere tra quattro colori diversi (ad esempio, rosso, verde, blu, giallo). Le probabilità associate a ciascun colore rappresentano le probabilità categoriali.\nSe \\(K\\) è il numero di categorie, la distribuzione categoriale è descritta da un vettore di probabilità \\(\\mathbf{p} = (p_1, p_2, \\ldots, p_K)\\) dove la somma di tutte le probabilità è 1 (\\(\\sum_{i=1}^{K} p_i = 1\\)).\n\n2. Distribuzione Multinomiale:\n\nLa distribuzione Multinomiale è una generalizzazione della distribuzione Binomiale per esperimenti con più di due risultati.\nDescrive la distribuzione del numero di successi in ciascuna delle \\(K\\) categorie in una sequenza di \\(N\\) esperimenti indipendenti, dove ogni esperimento segue una distribuzione categoriale con probabilità specifiche per ciascuna categoria.\nUn esempio psicologico potrebbe essere una serie di 20 prove in cui un partecipante sceglie uno dei quattro colori in ogni prova. La distribuzione multinomiale descrive il numero di volte in cui ciascun colore è scelto.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#relazioni-tra-distribuzioni",
    "href": "chapters/mcmc/17_stan_categorical.html#relazioni-tra-distribuzioni",
    "title": "67  Modello categoriale",
    "section": "67.3 Relazioni tra Distribuzioni",
    "text": "67.3 Relazioni tra Distribuzioni\nIn sintesi, possiamo descrivere le relazioni tra le distribuzioni nel modo seguente.\n\nBernoulliana e Binomiale: sono appropriate per eventi dicotomici (due possibili risultati). Una singola prova è modellata da una distribuzione Bernoulliana; una serie di prove da una distribuzione Binomiale.\nCategoriale e Multinomiale: sono appropriate per eventi con più di due risultati. Una singola prova è modellata da una distribuzione categoriale; una serie di prove da una distribuzione Multinomiale.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#esempio-con-la-distribuzione-binomiale",
    "href": "chapters/mcmc/17_stan_categorical.html#esempio-con-la-distribuzione-binomiale",
    "title": "67  Modello categoriale",
    "section": "67.4 Esempio con la Distribuzione Binomiale",
    "text": "67.4 Esempio con la Distribuzione Binomiale\nUn risultato consolidato nella letteratura psicologica è che le persone con disturbi emotivi, come il disturbo d’ansia sociale (SAD), il disturbo d’ansia generalizzata (GAD) e la depressione, mostrano una tendenza costante, o bias, a generare interpretazioni negative di materiali ambigui. Questo è diverso rispetto alle persone senza disturbi emotivi, che tendono, in generale, a fornire interpretazioni positive agli stimoli ambigui (Hirsch et al. (2016)).\nImmaginiamo un compito psicologico in cui a ciascun partecipante di un campione di \\(N\\) individui depressi viene chiesto di completare una singola prova. Viene presentata un’immagine ambigua e il partecipante deve scegliere tra due emozioni: felice o triste. L’uso di una singola prova per ciascun soggetto può essere giustificato per evitare di allertare il soggetto rispetto alle caratteristiche richieste dal compito, presentando questa prova cruciale all’interno di una serie di altre prove diverse che fungono da “filler”.\nNegli esperimenti effettivi in quest’area di ricerca si utilizzano stimoli come omofoni (ciascuno con un significato negativo e uno non negativo, ad esempio “die/dye”) oppure compiti di comprensione del testo in cui ogni set di frasi include una frase ambigua che ha un significato negativo e uno non correlato alla depressione (ad esempio, Mogg et al. (2006)).\nNell’esempio presente, immaginiamo che i dati raccolti siano costituiti da \\(N\\) osservazioni, dove 1 indica un’interpretazione negativa e 0 indica un’interpretazione non negativa. La variabile casuale che rappresenta l’esito dell’esperimento è Bernoulliana, poiché ogni prova può avere solo due risultati possibili (negativo o non negativo). Lo scopo dell’inferenza è stimare il parametro \\(\\theta\\), che rappresenta la probabilità di un’interpretazione negativa.\nEcco un esempio di codice Stan che modella questo scenario:\ndata {\n  int&lt;lower=1&gt; N; // Numero di partecipanti\n  int&lt;lower=0, upper=1&gt; y[N]; // Risultati delle prove (valori 0 e 1)\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Probabilità di interpretazione negativa\n}\nmodel {\n  y ~ bernoulli(theta); // Likelihood: distribuzione Bernoulliana per ciascuna prova\n}\ngenerated quantities {\n  int y_pred; // Predizione per una nuova prova\n  y_pred = bernoulli_rng(theta);\n}\nSpiegazione del Codice Stan:\n\nDati:\n\nN: il numero totale di partecipanti.\ny: un array di lunghezza \\(N\\) che contiene i risultati delle prove per ciascun partecipante, con valori 0 (interpretazione non negativa) o 1 (interpretazione negativa).\n\nParametri:\n\ntheta: un parametro che rappresenta la probabilità di un’interpretazione negativa, vincolato tra 0 e 1.\n\nModello:\n\ny ~ bernoulli(theta): specifica che ogni osservazione \\(y[i]\\) segue una distribuzione Bernoulliana con parametro \\(\\theta\\). Questa è la likelihood del modello, che indica come i dati osservati sono generati dato il parametro \\(\\theta\\).\n\nQuantità Generate:\n\ny_pred: una variabile che rappresenta la predizione di un nuovo esito sulla base delle probabilità posteriori stimate. Utilizza la funzione bernoulli_rng(theta) per generare un’osservazione simulata secondo la distribuzione Bernoulliana con parametro \\(\\theta\\).\n\n\nQuesto modello Stan permette di stimare la probabilità \\(\\theta\\) che un individuo con depressione interpreti un’ambiguità in modo negativo, sulla base dei dati osservati.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#esempio-con-la-distribuzione-categoriale",
    "href": "chapters/mcmc/17_stan_categorical.html#esempio-con-la-distribuzione-categoriale",
    "title": "67  Modello categoriale",
    "section": "67.5 Esempio con la Distribuzione Categoriale",
    "text": "67.5 Esempio con la Distribuzione Categoriale\nPer illustrare il modello categoriale, possiamo partire dallo scenario descritto in precedenza, con una piccola modifica. Immaginiamo che venga presentata un’immagine ambigua al partecipante, ma questa volta il partecipante deve scegliere tra quattro emozioni possibili: felice, triste, arrabbiato o neutrale. Ogni scelta rappresenta un risultato categoriale, poiché ci sono più di due possibili risposte.\nIn questo caso, la variabile casuale \\(X\\) che rappresenta la risposta del soggetto può assumere quattro valori distinti, corrispondenti alle quattro emozioni. La funzione di massa di probabilità (PMF) di \\(X\\) è descritta da un simplex a 4 dimensioni, il che significa che ogni probabilità è non negativa e la somma delle probabilità di tutte le categorie è pari a uno. Formalmente, se \\(\\theta = (\\theta_1, \\theta_2, \\theta_3, \\theta_4)\\) rappresenta il vettore delle probabilità per ciascuna emozione, allora per \\(x \\in \\{1, 2, 3, 4\\}\\), la probabilità categoriale è data da:\n\\[\nP(X = x) = \\theta_x,\n\\]\ndove \\(\\theta_x\\) rappresenta la probabilità di ciascun risultato \\(x\\).\nAd esempio, supponiamo che le probabilità per le quattro emozioni siano:\n\n\\(P(X = 1) = 0.2\\) (felice),\n\\(P(X = 2) = 0.4\\) (triste),\n\\(P(X = 3) = 0.1\\) (arrabbiato),\n\\(P(X = 4) = 0.3\\) (neutrale).\n\nIn questo caso, il vettore delle probabilità è \\(\\theta = (0.2, 0.4, 0.1, 0.3)\\), che rappresenta una distribuzione categoriale in cui le probabilità di ogni emozione sommano a 1, come richiesto da un simplex.\nEcco come modellare questo scenario utilizzando Stan:\ndata {\n  int&lt;lower=1&gt; N; // Numero di partecipanti\n  array[N] int&lt;lower=1, upper=4&gt; y;  // Risultati delle prove (valori da 1 a 4)\n}\nparameters {\n  simplex[4] theta; // Vettore delle probabilità categoriali per le quattro emozioni\n}\nmodel {\n  y ~ categorical(theta); // Likelihood: distribuzione categoriale per ciascuna prova\n}\ngenerated quantities {\n  int y_pred; // Predizione per una nuova prova\n  y_pred = categorical_rng(theta);\n}\nNel codice precedente\n\nDati:\n\nN: il numero totale di partecipanti.\ny: un array di lunghezza \\(N\\) che contiene i risultati delle prove per ciascun partecipante, dove ogni valore può essere 1 (felice), 2 (triste), 3 (arrabbiato), o 4 (neutrale).\n\nParametri:\n\ntheta: un vettore di probabilità di tipo simplex[4], che rappresenta la distribuzione delle probabilità per le quattro emozioni. Il tipo simplex garantisce che tutte le probabilità siano non negative e che la loro somma sia pari a 1.\n\n\nQuando \\(\\theta\\) è dichiarato come simplex[4] senza una specifica dichiarazione di prior nel blocco model, Stan assume automaticamente una distribuzione a priori uniforme sulla superficie del simplex. In altre parole, ogni possibile configurazione di \\(\\theta\\) che soddisfa le condizioni di un simplex (ovvero, tutte le componenti sono non negative e sommano a 1) ha la stessa probabilità a priori. Questo significa che, prima di vedere i dati, tutte le combinazioni di valori di \\(\\theta\\) che sommano a 1 sono considerate ugualmente probabili. Non c’è alcun bias a priori che favorisca una particolare configurazione di probabilità tra le quattro emozioni (felice, triste, arrabbiato, neutrale). Quindi, nel modello Stan, la distribuzione a priori su \\(\\theta\\) è effettivamente uniforme sul simplex, riflettendo una posizione a priori non informativa.\n\nModello:\n\ny ~ categorical(theta): specifica che ogni osservazione \\(y[i]\\) segue una distribuzione categoriale con parametro \\(\\theta\\). Questa è la likelihood del modello, che descrive come i dati osservati sono generati dato il vettore di probabilità \\(\\theta\\).\n\nQuantità Generate:\n\ny_pred: una variabile che rappresenta la predizione di un nuovo esito sulla base delle probabilità posteriori stimate. Utilizza la funzione categorical_rng(theta) per generare un’osservazione simulata secondo la distribuzione categoriale con parametro \\(\\theta\\).\n\n\nQuesto modello Stan consente di stimare le probabilità associate a ciascuna emozione scelta dai partecipanti in risposta a un’immagine ambigua.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#simulazione",
    "href": "chapters/mcmc/17_stan_categorical.html#simulazione",
    "title": "67  Modello categoriale",
    "section": "67.6 Simulazione",
    "text": "67.6 Simulazione\nVediamo ora come implementare il modello categoriale in pratica. Iniziamo simulando dei dati dalla distribuzione categoriale.\n\n# Definire i valori possibili e le probabilità associate\nvalori = [1, 2, 3, 4]\nprobabilita = [0.2, 0.4, 0.1, 0.3]\n\n# Generare 50 valori casuali dalla distribuzione categoriale\ny = np.random.choice(valori, size=50, p=probabilita)\nprint(y)\n\n[3 2 2 2 1 1 2 2 4 2 4 1 3 2 1 4 2 2 2 2 4 3 3 1 3 4 1 4 1 4 2 4 4 2 1 2 4\n 3 2 2 2 1 1 4 2 4 2 4 2 4]\n\n\nInseriamo i dati in un dizionario come richiesto da Stan.\n\nstan_data = {\n    \"N\": len(y),\n    \"y\": y.tolist()\n}\n\nImportiamo il codice Stan che abbiamo discusso in precedenza.\n\nstan_file = os.path.join(project_directory, \"stan\", \"categorical_model.stan\")\n\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\nEseguiamo il campionamento MCMC utilizzando i dati simulati.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2000, \n    iter_sampling=2000,\n    seed=42, \n    chains=4,\n    show_progress=False, \n    show_console=False\n)\n\nEsaminiamo le stime a posteriori dei parametri.\n\naz.summary(fit, var_names=\"theta\", hdi_prob=0.95).round(2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntheta[0]\n0.20\n0.05\n0.10\n0.31\n0.0\n0.0\n15575.0\n10516.0\n1.0\n\n\ntheta[1]\n0.39\n0.06\n0.27\n0.52\n0.0\n0.0\n15457.0\n12342.0\n1.0\n\n\ntheta[2]\n0.13\n0.04\n0.05\n0.22\n0.0\n0.0\n14350.0\n10458.0\n1.0\n\n\ntheta[3]\n0.28\n0.06\n0.16\n0.40\n0.0\n0.0\n15702.0\n11989.0\n1.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#interpretazione-dei-risultati",
    "href": "chapters/mcmc/17_stan_categorical.html#interpretazione-dei-risultati",
    "title": "67  Modello categoriale",
    "section": "67.7 Interpretazione dei Risultati",
    "text": "67.7 Interpretazione dei Risultati\nNel contesto di questo esempio, immaginiamo un gruppo di pazienti depressi che giudicano delle immagini ambigue, assegnando loro un’emozione tra “felice”, “triste”, “arrabbiato” o “neutrale”. I parametri \\(\\theta[0]\\), \\(\\theta[1]\\), \\(\\theta[2]\\) e \\(\\theta[3]\\) rappresentano le stime a posteriori delle probabilità che un partecipante scelga rispettivamente ciascuna di queste emozioni.\n\n67.7.1 Interpretazione Specifica dei Parametri\n\n\\(\\theta[0]\\): Emozione “felice”\nLa stima a posteriori della probabilità che un partecipante scelga l’emozione “felice” (\\(P(X = 1)\\)) è 0.20, con un intervallo di credibilità al 95% (HDI) che va da 0.10 a 0.31. Questo suggerisce che, per questo gruppo di pazienti depressi, c’è una probabilità relativamente bassa di interpretare un’immagine ambigua come “felice”.\n\\(\\theta[1]\\): Emozione “triste”\nLa stima a posteriori della probabilità che un partecipante scelga l’emozione “triste” (\\(P(X = 2)\\)) è 0.39, con un HDI al 95% tra 0.27 e 0.52. Questo valore più alto rispetto alle altre emozioni indica che i pazienti depressi nel campione hanno una tendenza maggiore a interpretare immagini ambigue come “tristi”. Questo risultato è coerente con le aspettative teoriche secondo cui le persone con depressione hanno una propensione a percepire situazioni ambigue in modo più negativo.\n\\(\\theta[2]\\): Emozione “arrabbiato”\nLa stima a posteriori della probabilità che un partecipante scelga l’emozione “arrabbiato” (\\(P(X = 3)\\)) è 0.13, con un HDI al 95% che va da 0.05 a 0.22. Questa probabilità relativamente bassa suggerisce che interpretare un’immagine come “arrabbiato” non è un’interpretazione comune tra i pazienti depressi nel campione.\n\\(\\theta[3]\\): Emozione “neutrale”\nLa stima a posteriori della probabilità che un partecipante scelga l’emozione “neutrale” (\\(P(X = 4)\\)) è 0.28, con un HDI al 95% tra 0.16 e 0.40. Una probabilità del 28% indica che un’interpretazione “neutrale” delle immagini ambigue è relativamente comune, ma non dominante, tra i pazienti depressi.\n\nIn sintesi, queste stime posteriori forniscono una chiara indicazione delle tendenze emotive dei partecipanti depressi nel contesto di interpretazioni di stimoli ambigui. L’alta probabilità di scegliere “triste” e le basse probabilità associate alle altre emozioni sono coerenti con la letteratura esistente che indica un bias negativo nelle interpretazioni tra persone con depressione.\nIn questo esempio simulato, le stime posteriori di \\(\\theta\\) riflettono accuratamente i valori delle probabilità utilizzati per generare i dati, dimostrando che anche con un numero limitato di dati, il modello bayesiano è capace di recuperare le distribuzioni delle probabilità a posteriori in modo efficace.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#considerazioni-conclusive",
    "href": "chapters/mcmc/17_stan_categorical.html#considerazioni-conclusive",
    "title": "67  Modello categoriale",
    "section": "67.8 Considerazioni Conclusive",
    "text": "67.8 Considerazioni Conclusive\nL’obiettivo di questo breve capitolo era fornire un esempio della distribuzione categoriale, che rappresenta un’estensione della distribuzione di Bernoulli per il caso in cui vi siano più di due categorie possibili. Abbiamo mostrato come utilizzare Stan per eseguire inferenze su questa distribuzione, permettendo di stimare le probabilità associate a ciascuna categoria basandosi sui dati osservati. Questo approccio è utile in vari contesti psicologici in cui le risposte dei partecipanti non si limitano a scelte dicotomiche, ma comprendono più opzioni.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/17_stan_categorical.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/17_stan_categorical.html#informazioni-sullambiente-di-sviluppo",
    "title": "67  Modello categoriale",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy \n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nrequests  : 2.32.3\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nHirsch, C. R., Meeten, F., Krahé, C., & Reeder, C. (2016). Resolving ambiguity in emotional disorders: The nature and role of interpretation biases. Annual Review of Clinical Psychology, 12(1), 281–305.\n\n\nMogg, K., Bradbury, K. E., & Bradley, B. P. (2006). Interpretation of ambiguous information in clinical depression. Behaviour Research and Therapy, 44(10), 1411–1419.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>Modello categoriale</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/19_approximations.html",
    "href": "chapters/mcmc/19_approximations.html",
    "title": "69  Metodi approssimativi nell’inferenza Bayesiana",
    "section": "",
    "text": "Introduzione\nNell’inferenza bayesiana, spesso ci troviamo di fronte a situazioni in cui i metodi di campionamento come MCMC richiedono tempi di calcolo proibitivi. In questi casi, i metodi approssimativi offrono un’alternativa pratica, sacrificando una parte della precisione per ottenere risultati in tempi ragionevoli.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Metodi approssimativi nell'inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/19_approximations.html#panoramica-dei-metodi-approssimativi",
    "href": "chapters/mcmc/19_approximations.html#panoramica-dei-metodi-approssimativi",
    "title": "69  Metodi approssimativi nell’inferenza Bayesiana",
    "section": "69.1 Panoramica dei Metodi Approssimativi",
    "text": "69.1 Panoramica dei Metodi Approssimativi\n\n69.1.1 1. Approximate Bayesian Computation (ABC)\nL’ABC è utile quando la funzione di verosimiglianza è difficile o impossibile da calcolare (Lintusaari et al., 2017). Invece di calcolare direttamente la verosimiglianza, l’ABC:\n\nGenera parametri dalla distribuzione a priori\nSimula dati usando questi parametri\nConfronta i dati simulati con i dati osservati\nAccetta i parametri se la differenza è inferiore a una soglia\n\nL’ABC è particolarmente utile per modelli complessi in biologia, ecologia e genetica delle popolazioni.\n\n\n69.1.2 2. Linear Bayes (LB)\nIl Linear Bayes semplifica l’inferenza concentrandosi solo sui primi due momenti (media e varianza) della distribuzione (Goldstein, 2015). Non richiede distribuzioni complete, ma fornisce aggiornamenti approssimativi simili al filtro di Kalman.\n\n\n69.1.3 3. Laplace Approximation (LA)\nLa LA approssima la distribuzione a posteriori con una distribuzione gaussiana multivariata (MacKay, 1992). Trova il massimo a posteriori (MAP) e usa la curvatura intorno a questo punto per stimare la matrice di covarianza. È efficace quando la vera posteriori è approssimativamente gaussiana.\n\n\n69.1.4 4. Integrated Nested Laplace Approximation (INLA)\nINLA estende l’idea della LA ai modelli gerarchici (Simpson et al., 2023). Si concentra sulle distribuzioni marginali a posteriori dei singoli parametri, evitando di calcolare le correlazioni complete tra tutti i parametri.\n\n\n69.1.5 5. Variational Bayes (VB)\nIl VB cerca di approssimare la vera distribuzione a posteriori p(θ|y) con una distribuzione più semplice q(θ), scelta da una famiglia trattabile di distribuzioni (Barber & Bishop, 1998).\n\n69.1.5.1 Funzionamento del VB\n\nScelta della Famiglia di Distribuzioni: Si sceglie una famiglia di distribuzioni q(θ) che sia facile da manipolare. Spesso si usa una famiglia fattorizzata, dove q(θ) = Π q_i(θ_i).\nOttimizzazione: Si cerca di minimizzare la divergenza di Kullback-Leibler (KL) tra q(θ) e p(θ|y). Questo equivale a massimizzare un limite inferiore dell’evidenza del modello (ELBO - Evidence Lower BOund).\nAggiornamento Iterativo: Si aggiornano iterativamente i parametri di q(θ) per massimizzare l’ELBO.\n\n\n\n69.1.5.2 Vantaggi del VB\n\nEfficienza Computazionale: Spesso molto più veloce di MCMC per modelli complessi.\nScalabilità: Adatto per grandi dataset e modelli ad alta dimensionalità.\nLimite Inferiore dell’Evidenza: Fornisce automaticamente una stima dell’evidenza del modello, utile per il confronto tra modelli.\n\n\n\n69.1.5.3 Limitazioni del VB\n\nApprossimazione: La distribuzione approssimata potrebbe non catturare completamente la struttura della vera posteriori, soprattutto in caso di multimodalità o forti correlazioni.\nSottostima dell’Incertezza: Tende a sottostimare la varianza della posteriori.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Metodi approssimativi nell'inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/19_approximations.html#conclusione",
    "href": "chapters/mcmc/19_approximations.html#conclusione",
    "title": "69  Metodi approssimativi nell’inferenza Bayesiana",
    "section": "69.2 Conclusione",
    "text": "69.2 Conclusione\nI metodi approssimativi offrono soluzioni pratiche quando l’inferenza bayesiana esatta è computazionalmente proibitiva. Ogni metodo ha i suoi punti di forza e limitazioni, e la scelta dipende dalla natura del problema, dalla dimensione dei dati e dalle risorse computazionali disponibili. Il Variational Bayes, in particolare, si è dimostrato un approccio versatile e potente in molti campi applicativi.\n\n\n\n\nOijen, M. van. (2024). Bayesian Compendium (2nd ed.). Springer. https://doi.org/10.1007/978-3-031-66085-6",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>Metodi approssimativi nell'inferenza Bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/introduction_linear_models.html",
    "href": "chapters/linear_models/introduction_linear_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo un approccio all’analisi dei dati basato sull’uso della regressione lineare, esaminandolo dalla prospettiva dell’inferenza bayesiana. La regressione è un metodo che consente ai ricercatori di riassumere come le previsioni o i valori medi di un risultato variano tra individui definiti da un insieme di predittori.\nCome indicato da Gelman et al. (2020), alcuni degli usi più importanti della regressione sono:\n\nPrevisione: Modellare osservazioni esistenti o prevedere nuovi dati. Esempi con risultati continui o approssimativamente continui includono la previsione dei punteggi in un test futuro, la misurazione dei livelli di stress in un contesto di lavoro, o il monitoraggio del benessere psicologico in uno studio longitudinale. Esempi con risultati discreti o categoriali (a volte chiamati classificazione) includono la diagnosi di un disturbo psicologico, la riuscita o il fallimento in un compito cognitivo, e le decisioni individuali di partecipare a una terapia.\nEsplorazione delle associazioni: Riassumere quanto bene una variabile, o un insieme di variabili, predica il risultato. Esempi includono l’identificazione dei tratti di personalità associati a una maggiore resilienza allo stress. Oppure l’analisi della relazione tra stili di attaccamento infantile e capacità relazionali in età adulta. Oppure lo studio di come diversi fattori socio-economici influenzano lo sviluppo cognitivo nei bambini.\nEstrapolazione: Adeguare le analisi per tenere conto delle differenze conosciute tra il campione osservato e la popolazione di interesse. Per esempio, la generalizzazione dei risultati di uno studio sulla depressione condotto su studenti universitari alla popolazione generale. Oppure la stima dell’efficacia di una nuova terapia cognitivo-comportamentale testata in un contesto clinico controllato su una popolazione più ampia e diversificata. Oppure la previsione dell’impatto di un programma di prevenzione del bullismo testato in alcune scuole su un intero distretto scolastico.\nInferenza causale: Forse l’uso più importante della regressione è stimare gli effetti di un trattamento. Abbiamo già definito l’inferenza causale più dettagliatamente nel 23  Causalità dai dati osservazionali. Per esempio, la valutazione dell’effetto di un intervento di mindfulness sui livelli di ansia, controllando per variabili confondenti come l’età e precedenti esperienze di meditazione. Oppure la stima dell’impatto di un programma di sviluppo delle competenze emotive sulle performance lavorative, tenendo conto di fattori come l’ambiente di lavoro e la personalità dei partecipanti. Oppure l’analisi dell’efficacia di diverse tecniche psicoterapeutiche nel trattamento del disturbo post-traumatico da stress, considerando la gravità iniziale dei sintomi e il supporto sociale dei pazienti.\n\nIn tutti questi scenari, è cruciale che il modello di regressione includa tutte le variabili rilevanti. Ad esempio, in uno studio sull’efficacia di una terapia per la depressione negli anziani, è essenziale includere fattori come l’età, le condizioni di salute preesistenti e il supporto sociale. Omettere questi predittori potrebbe portare a stime inaccurate e conclusioni fuorvianti sull’effettiva efficacia del trattamento in questa popolazione specifica.\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html",
    "href": "chapters/linear_models/01_reglin_bayesian.html",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "Introduzione\nI modelli lineari sono stati impiegati in molteplici contesti per lungo tempo. Come descritto da Stigler (1986), il metodo dei minimi quadrati, una tecnica per adattare una semplice regressione lineare, veniva già utilizzato nel XVIII secolo per affrontare problemi di analisi dei dati in astronomia. Ad esempio, questo metodo era impiegato per determinare il moto della Luna e per riconciliare i movimenti non periodici di Giove e Saturno. All’epoca, gli astronomi erano tra i primi a sentirsi a proprio agio nell’uso di tali metodi, poiché raccoglievano personalmente le loro osservazioni e sapevano che le condizioni di raccolta dei dati erano omogenee, anche se i valori osservati potevano differire. Questo contrastava con l’approccio più cauto delle scienze sociali, dove la riluttanza a combinare dati eterogenei ritardava l’adozione dei modelli lineari (Stigler, 1986).\nIn questa sezione della dispensa, esploreremo due modelli statistici fondamentali: la regressione lineare bivariata e la regressione lineare multipla. Il primo modello considera una sola variabile esplicativa, mentre il secondo ne include diverse.\nÈ cruciale sottolineare che i modelli statistici sono principalmente utilizzati per due scopi: inferenza e previsione. La previsione si limita a descrivere l’associazione tra le variabili, mentre l’inferenza mira a stabilire relazioni di causa-effetto attraverso l’uso del modello lineare. Mentre la previsione non è una tecnica controversa e può essere facilmente verificata sulla base della sua effettiva capacità di predire la variabile dipendente, l’uso della regressione per l’inferenza causale è molto più problematico. Esso richiede una profonda comprensione del fenomeno in esame e una progettazione sperimentale o quasi-sperimentale adeguata per giustificare le assunzioni necessarie.\nIndipendentemente dall’approccio scelto, è fondamentale tenere presente che l’analisi di regressione è essenzialmente una forma di media ponderata. Di conseguenza, i risultati ottenuti riflettono inevitabilmente i bias e le peculiarità del dataset utilizzato.\nPer ciascun modello, esamineremo due approcci distinti:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#introduzione",
    "href": "chapters/linear_models/01_reglin_bayesian.html#introduzione",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "",
    "text": "L’utilizzo delle funzioni di pingouin, particolarmente utile per l’analisi esplorativa dei dati (EDA) quando si necessita di risultati rapidi.\nL’approccio bayesiano, ideale quando l’obiettivo principale è l’inferenza statistica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "href": "chapters/linear_models/01_reglin_bayesian.html#adattare-una-retta-di-regressione-a-dati-simulati",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.1 Adattare una Retta di Regressione a Dati Simulati",
    "text": "70.1 Adattare una Retta di Regressione a Dati Simulati\nSimuliamo 20 osservazioni di \\(x\\) e \\(y\\), dove \\(y\\) è generato in base a un modello di regressione teorico con i parametri specificati di seguito.\n\n# Set seed for reproducibility\nnp.random.seed(123)\n\n# Define variables\nx = np.arange(1, 21)\nn = len(x)\na = 0.2\nb = 0.3\nsigma = 0.5\n\n# Generate y values\ny = a + b * x + sigma * np.random.normal(size=n)\n\nfake = pd.DataFrame({\"x\": x, \"y\": y})\nfake.head()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1\n-0.042815\n\n\n1\n2\n1.298673\n\n\n2\n3\n1.241489\n\n\n3\n4\n0.646853\n\n\n4\n5\n1.410700\n\n\n\n\n\n\n\nAdattiamo ai dati un modello di regressione bayesiano. Compiliamo e stampiamo il codice Stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"bivariate_linreg_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  sigma ~ normal(0, 2.5);\n}\ngenerated quantities {\n  array[N] real y_rep = normal_rng(alpha + beta * x, sigma);\n}\n\n\n\nDefiniamo un dizionario che contiene i dati nel formato attesto da Stan.\n\nstan_data = {\"N\": len(fake[\"x\"]), \"x\": fake[\"x\"], \"y\": fake[\"y\"]}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo una sintesi della distribuzione a posteriori dei parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94).round(2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.15\n0.30\n-0.73\n0.40\n0.01\n0.0\n2639.0\n3041.0\n1.0\n\n\nbeta\n0.34\n0.02\n0.29\n0.39\n0.00\n0.0\n2692.0\n3281.0\n1.0\n\n\nsigma\n0.64\n0.12\n0.45\n0.86\n0.00\n0.0\n3531.0\n4126.0\n1.0\n\n\n\n\n\n\n\nLe prime due righe dell’output ci indicano che l’intercetta stimata è -0.15 con un’incertezza di 0.30, e la pendenza stimata è 0.34 con un’incertezza di 0.02. La deviazione standard residua \\(\\sigma\\) è stimata a 0.64 con un’incertezza di 0.12.\nÈ utile disegnare un diagramma a dispersione con la retta di regressione stimata.\n\n# Estrarre i parametri stimati dal modello bayesiano\nalpha_hat = -0.15  # Stima media di alpha\nbeta_hat = 0.34  # Stima media di beta\n\n# Scatterplot dei dati\nplt.scatter(fake[\"x\"], fake[\"y\"], color=\"blue\", label=\"Dati osservati\")\n\n# Disegnare la retta di regressione usando i parametri stimati\nx_values = np.linspace(fake[\"x\"].min(), fake[\"x\"].max(), 100)\ny_values = alpha_hat + beta_hat * x_values\nplt.plot(x_values, y_values, color=\"red\", label=\"Retta di regressione stimata\")\n\n# Aggiungere titoli e etichette\nplt.title(\"Scatterplot con Retta di Regressione\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.legend()\n\n# Mostrare il grafico\nplt.show()\n\n\n\n\n\n\n\n\nVediamo che la retta stimata si adatta bene alla nube di punti del campione. Possiamo ora confrontare le stime con i valori dei parametri assunti. Cominciamo con l’intercetta \\(a\\), che abbiamo impostato a 0.2 nelle simulazioni. Dopo aver adattato il modello ai dati simulati, la stima risulta essere −0.15, che è molto diversa dal valore assunto di 0.2 – ma l’incertezza, o errore standard, nella stima è di 0.30. Approssimativamente, ci aspettiamo che la differenza tra la stima e il valore reale rientri in 1 errore standard nel 68% dei casi, e in 2 errori standard nel 95% dei casi. Quindi, se il valore reale è 0.2, e l’errore standard è 0.30, non è sorprendente che la stima risulti essere −0.15. Allo stesso modo, per le stime di \\(b\\) e σ, l’intervallo di credibilità al 95% contiene i loro valori reali.\nCome appena illustrato, una qualsiasi simulazione di dati fittizi con dati continui non riprodurrà esattamente i valori dei parametri assunti. Tuttavia, sotto simulazioni ripetute, dovremmo osservare una copertura adeguata.\nPer semplicità, adottiamo l’approccio frequentista e consideriamo l’intervallo di confidenza al 95%. Per livello di copertura si intende la proporzione di volte in cui, nelle simulazioni, il valore reale del parametro rientra nell’intervallo di confidenza stimato a partire dai dati.\n\n# Imposta il seme per la riproducibilità\nnp.random.seed(42)\n\n# Parametri veri\na_true = 0.2\nb_true = 0.3\nsigma_true = 0.5\n\n# Numero di simulazioni\nnum_simulations = 1000\n\n# Per tracciare il livello di copertura\ncoverage_a = 0\ncoverage_b = 0\n\n# Intervalli di confidenza al 95%\nz_value = 1.96  # valore z per il 95% di confidenza\n\nfor _ in range(num_simulations):\n    # Simula i dati\n    x = np.arange(1, 21)\n    n = len(x)\n    y = a_true + b_true * x + sigma_true * np.random.normal(size=n)\n\n    # Crea un DataFrame con i dati simulati\n    fake = pd.DataFrame({\"x\": x, \"y\": y})\n\n    # Fitting del modello\n    X = sm.add_constant(fake[\"x\"])  # Aggiunge il termine di intercetta\n    model = sm.OLS(fake[\"y\"], X).fit()\n\n    # Estrazione dei parametri stimati\n    a_hat = model.params[0]\n    b_hat = model.params[1]\n\n    # Calcolo degli errori standard\n    se_a = model.bse[0]\n    se_b = model.bse[1]\n\n    # Calcolo degli intervalli di confidenza al 95%\n    ci_a_low = a_hat - z_value * se_a\n    ci_a_high = a_hat + z_value * se_a\n    ci_b_low = b_hat - z_value * se_b\n    ci_b_high = b_hat + z_value * se_b\n\n    # Controlla se il valore vero è all'interno degli intervalli di confidenza\n    if ci_a_low &lt;= a_true &lt;= ci_a_high:\n        coverage_a += 1\n    if ci_b_low &lt;= b_true &lt;= ci_b_high:\n        coverage_b += 1\n\n# Calcola e stampa i livelli di copertura\ncoverage_a_rate = coverage_a / num_simulations * 100\ncoverage_b_rate = coverage_b / num_simulations * 100\n\nprint(f\"Livello di copertura per l'intercetta a: {coverage_a_rate:.2f}%\")\nprint(f\"Livello di copertura per la pendenza b: {coverage_b_rate:.2f}%\")\n\nLivello di copertura per l'intercetta a: 93.80%\nLivello di copertura per la pendenza b: 94.10%\n\n\nI valori di copertura ottenuti empiricamente mediante la simulazione sono prossimi ai valori teorici attesi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "href": "chapters/linear_models/01_reglin_bayesian.html#modellare-lassociazione-statistica-tra-variabili",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.2 Modellare l’associazione statistica tra variabili",
    "text": "70.2 Modellare l’associazione statistica tra variabili\nAvendo verificato che il modello di regressione è in grado di recuperare in modo attendibile i valori teorici dell’intercetta e della pendenza della retta di regressione, passiamo ora ad applicare il modello a un insieme di dati reali.\nEsamineremo un set di dati che riguarda la relazione tra i punteggi di affect e arousal. Questi dati provengono da due studi condotti presso il Personality, Motivation, and Cognition Laboratory della Northwestern University, nei quali sono stati utilizzati film per indurre stati affettivi (Rafaeli & Revelle, 2006).\nCi concentreremo sull’associazione tra l’ansia di stato, considerata come variabile indipendente, e la scala di Tense Arousal del Motivational State Questionnaire (MSQ), considerata come variabile dipendente.\nIn precedenza, abbiamo applicato il modello normale a una singola variabile. Tuttavia, solitamente siamo interessati a modellare come una variabile di esito sia associata a una variabile predittiva. Se esiste un’associazione statistica tra la variabile predittiva e quella di esito, possiamo utilizzarla per predire il risultato. Quando la variabile predittiva viene incorporata nel modello in un modo specifico, otteniamo una regressione lineare.\nI dati dell’esempio sono forniti di seguito.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"affect.csv\")\n\n# Leggere il file CSV in un DataFrame pandas\ndata = pd.read_csv(file_path)\n\n# Selezionare le colonne state1 e TA1\ndf = data[[\"state1\", \"TA1\"]]\ndf.head()\n\n\n\n\n\n\n\n\nstate1\nTA1\n\n\n\n\n0\n41\n11.0\n\n\n1\n26\n5.0\n\n\n2\n31\n8.0\n\n\n3\n28\n8.0\n\n\n4\n47\n12.0\n\n\n\n\n\n\n\nL’associazione tra le due variabili, ansia di stato e Tense Arousal, è rappresentata nel grafico sottostante. Il grafico suggerisce che l’associazione può essere approssimata da una semplice funzione matematica, come una retta. Tuttavia, è evidente che una funzione lineare sia troppo semplicistica per rappresentare accuratamente questi dati, poiché non è possibile trovare una singola retta che passi per tutti i punti del diagramma di dispersione.\n\nplt.scatter(df[\"state1\"], df[\"TA1\"])\nplt.xlabel(\"State Anxiety\")\nplt.ylabel(\"Tense Arousal\")\nplt.show()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#minimi-quadrati",
    "href": "chapters/linear_models/01_reglin_bayesian.html#minimi-quadrati",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.3 Minimi Quadrati",
    "text": "70.3 Minimi Quadrati\nCi poniamo il duplice obiettivo di identificare la retta che meglio si adatta ai dati del diagramma e di valutare la qualità di tale adattamento. In altre parole, vogliamo misurare quanto, in media, i punti del diagramma si discostano dalla retta trovata.\nNel modello di regressione lineare classica, espresso come \\(y_i = \\beta_0 + \\beta_1 x_i + e_i\\), i coefficienti \\(\\beta_0\\) e \\(\\beta_1\\) vengono stimati minimizzando la somma dei quadrati degli errori \\(\\epsilon_i\\).\nPossiamo utilizzare la funzione linear_regression() del pacchetto pingouin per calcolare i coefficienti del modello seguendo questo approccio:\n\nx = df[\"state1\"]\ny = df[\"TA1\"]\n\nlm = pg.linear_regression(x, y)\nlm.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n1.56\n1.25\n1.25\n0.22\n0.52\n0.52\n-0.93\n4.04\n\n\n1\nstate1\n0.27\n0.03\n9.14\n0.00\n0.52\n0.52\n0.21\n0.33\n\n\n\n\n\n\n\nRecuperiamo i coefficienti b0 e b1 dall’oggetto lm creato da linear_regression().\n\nbeta = lm[\"coef\"]  # Coefficienti\nbeta\n\n0    1.555463\n1    0.267071\nName: coef, dtype: float64\n\n\n\nb0 = beta[0]\nb1 = beta[1]\n\nCalcoliamo i valori predetti dal modello di regressione:\n\nyhat = b0 + b1 * x\nyhat\n\n0     12.505379\n1      8.499312\n2      9.834668\n3      9.033455\n4     14.107806\n        ...    \n73    12.238308\n74    17.579731\n75     7.965170\n76    10.368810\n77    10.368810\nName: state1, Length: 78, dtype: float64\n\n\nI valori predetti \\(\\hat{y}\\) corrispondono alla retta di regressione:\n\nplt.plot(x, yhat)\nplt.xlabel(\"Ansia di stato\")\nplt.ylabel(\"Tense Arousal, $\\\\hat{y}$\")\n_ = plt.title(\"Retta di regressione\")\n\n\n\n\n\n\n\n\nAggiungiamo i dati osservati al grafico.\n\nplt.plot(x, yhat)\nplt.plot(x, y, \"x\")\nplt.xlabel(\"Ansia di stato\")\nplt.ylabel(\"Tense Arousal, $\\\\hat{y}$\")\n_ = plt.title(\"Retta di regressione\")\n\n\n\n\n\n\n\n\n\n70.3.1 Interpretazione\nIl coefficiente \\(\\beta_0\\) indica il valore atteso della distribuzione condizionata \\(p(y_i \\mid x_i = 0)\\). Nel caso presente, indica la media di Tense Arousal quando l’ansia di stato è uguale a 0. Ovviamente questa non è un’informazione di una qualche importanza pratica. Vedremo come migliorare l’interpretabilità dell’intercetta usando una parametrizzazione alternativa dei dati.\nIl coefficiente \\(\\beta_1\\) indica il cambiamento del valore atteso della variabile dipendente quando la variabile indipendente aumenta di un’unità. Nel caso presente abbiamo che il punteggio di Tense Arousal aumenta in media di 0.27 punti quando l’ansia di stato aumenta di un punto. In una parametrizzazione alternativa, standardizzando la variabile indipendente, \\(\\beta_1\\) indicherebbe di quanto varia in media Tense Arousal quando l’ansia di stato aumenta di una deviazione standard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#residui",
    "href": "chapters/linear_models/01_reglin_bayesian.html#residui",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.4 Residui",
    "text": "70.4 Residui\nCalcoliamo i residui\n\\[\ne_i = y_i - \\hat{y}_i\n\\]\n\ne = y - yhat\n\nLa retta di regressine calcolata con il metodo della massima verosimiglianza ha le seguenti proprietà:\n\nil valore atteso dei residui è zero,\ni residui sono incorrelati con i valori predetti.\n\nValutiamo la media dei residui:\n\nnp.mean(e)\n\n2.1065770210836304e-15\n\n\nCalcoliamo la correlazione tra i residui \\(e\\) e i valori predetti \\(\\hat{y}\\):\n\nnp.corrcoef(e, yhat)[0, 1]\n\n3.7592426344877714e-16\n\n\nIl modello di regressione bivariato\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + e_i\n\\]\nscompone la variabile dipendente \\(y_i\\) in due componenti tra loro incorrelate, una componente deterministica\n\\[\n\\hat{y}_i = \\beta_0 + \\beta_1 x_i\n\\]\ne una componente aleatoria\n\\[\ne_i = y_i - \\hat{y}_i.\n\\]\n\ndf = pd.DataFrame()\ndf[\"x\"] = x\ndf[\"y\"] = y\ndf[\"yhat\"] = yhat\ndf[\"e\"] = e\ndf[\"sum\"] = df[\"yhat\"] + df[\"e\"]\ndf\n\n\n\n\n\n\n\n\nx\ny\nyhat\ne\nsum\n\n\n\n\n0\n41\n11.0\n12.505379\n-1.505379\n11.0\n\n\n1\n26\n5.0\n8.499312\n-3.499312\n5.0\n\n\n2\n31\n8.0\n9.834668\n-1.834668\n8.0\n\n\n3\n28\n8.0\n9.033455\n-1.033455\n8.0\n\n\n4\n47\n12.0\n14.107806\n-2.107806\n12.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n73\n40\n13.0\n12.238308\n0.761692\n13.0\n\n\n74\n60\n20.0\n17.579731\n2.420269\n20.0\n\n\n75\n24\n10.0\n7.965170\n2.034830\n10.0\n\n\n76\n33\n10.0\n10.368810\n-0.368810\n10.0\n\n\n77\n33\n6.0\n10.368810\n-4.368810\n6.0\n\n\n\n\n78 rows × 5 columns\n\n\n\n\n70.4.1 Errore Standard della Regressione\nL’errore standard della regressione rappresenta la stima della deviazione standard dei residui nell’intera popolazione. Questo parametro può essere calcolato attraverso la formula:\n\\[\n\\hat{\\sigma}_e = \\sqrt{\\frac{\\sum_i (e_i - \\bar{e})^2}{n-2}},\n\\]\ndove $ {e} $ indica la media dei residui, che teoricamente è zero dato che si assume che la media degli errori sia zero.\nIl denominatore “n-2” deriva dalla perdita di due gradi di libertà, necessaria per la stima dei due coefficienti, $ _0 $ (intercetta) e $ _1 $ (pendenza), che sono utilizzati per calcolare le stime previste $ _i = _0 + _1 x_i $. Questi gradi di libertà vengono sottratti perché ciascun parametro stimato consuma un grado di libertà dal totale disponibile.\nNel caso dell’esempio, la numerosità campionaria è\n\nn = len(x)\nn\n\n78\n\n\nL’errore standard della regressione diventa\n\nnp.sqrt(np.sum(e**2) / (n - 2))\n\n2.671556929795855\n\n\nQuesto valore indica che, in media, nella popolazione la distanza tra i valori osservati e la retta di regressione è di 2.67 punti.\nCome discusso da {cite}gelman2020regression, la radice quadrata media dei residui, $ _{i=1}^n (y_i - ( + x_i))^2 $, tende a sottostimare la deviazione standard \\(\\sigma\\) dell’errore nel modello di regressione. Questa sottostima è spesso il risultato di un sovradimensionamento, dato che i parametri \\(a\\) e \\(b\\) sono stimati utilizzando gli stessi \\(n\\) punti dati usati anche per calcolare i residui.\nLa validazione incrociata rappresenta un approccio alternativo per valutare l’errore predittivo che evita alcuni dei problemi legati al sovradimensionamento. La versione più semplice della validazione incrociata è l’approccio leave-one-out, in cui il modello è adattato \\(n\\) volte, escludendo ogni volta un punto dati, adattando il modello ai rimanenti \\(n-1\\) punti dati, e utilizzando questo modello adattato per predire l’osservazione esclusa: - Per \\(i = 1, \\ldots, n\\): - Adatta il modello \\(y = a + bx + \\text{errore}\\) ai \\(n-1\\) punti dati \\((x,y)_j, j \\neq i\\). Denomina i coefficienti di regressione stimati come \\(\\hat{a}_{-i}, \\hat{b}_{-i}\\). - Calcola il residuo validato incrociato, $ r_{} = y_i - ({-i} + {-i} x_i) $. - Calcola la stima di \\(\\sigma_{\\text{CV}} = \\frac{1}{n} \\sum_{i=1}^n r_{\\text{CV}}^2\\).\nPer fare un esempio, eseguiamo i passaggi sopra descritti per il modello che predice Tense Arousal dall’ansia di stato.\n\n# Inizializzazione di un modello di regressione lineare\nmodel = LinearRegression()\n\n# Array per salvare i residui cross-validated\nresiduals_cv = []\n\n# Loop per la validazione incrociata leave-one-out\nfor i in range(len(df)):\n    # Dati di training escludendo l'i-esimo punto\n    X_train = df.loc[df.index != i, [\"x\"]]\n    y_train = df.loc[df.index != i, \"y\"]\n\n    # Dati di test\n    X_test = df.loc[[i], [\"x\"]]\n    y_test = df.loc[i, \"y\"]\n\n    # Addestramento del modello\n    model.fit(X_train, y_train)\n\n    # Predizione sull'i-esimo punto\n    y_pred = model.predict(X_test)\n\n    # Calcolo del residuo validato incrociato\n    residual_cv = y_test - y_pred[0]\n    residuals_cv.append(residual_cv**2)\n\n# Calcolo di sigma_cv\nsigma_cv = np.sqrt(np.mean(residuals_cv))\n\nprint(\"Stima di σ_CV:\", sigma_cv)\n\nStima di σ_CV: 2.7114997423207527\n\n\nNel caso dei dati analizzati, si osserva che la stima ottenuta attraverso la validazione incrociata è leggermente superiore rispetto a quella calcolata usando la formula $ _e = $. Questo incremento, sebbene minimo, riflette le differenze metodologiche tra i due approcci di stima dell’errore standard.\n\n\n70.4.2 Parametrizzazione Alternativa\nPer consentire una migliore interpretazione dell’intercetta, centriamo i valori della variabile indipendente.\n\nx = df[\"state1\"]\ny = df[\"TA1\"]\n\nxc = x - np.mean(x)\nnp.mean(xc)\n\n-1.8219044506669234e-15\n\n\nEseguiamo l’analisi di regressione.\n\nlm2 = pg.linear_regression(xc, y)\nlm2.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n12.62\n0.30\n41.73\n0.0\n0.52\n0.52\n12.02\n13.22\n\n\n1\nstate1\n0.27\n0.03\n9.14\n0.0\n0.52\n0.52\n0.21\n0.33\n\n\n\n\n\n\n\nNotiamo che la stima della pendenza della retta di regressione è rimasta immutata, mentre cambia il coefficiente \\(\\beta_0\\). Nel caso in cui la variabile indipendente sia centrata, il coefficiente \\(\\beta_0\\) rappresenta il valore atteso della variabile dipendente quando la variabile indipendente assume il suo valore medio.\nNel caso presente, il valore 12.62 indica la media di Tense Arousal quando l’ansia di stato assume il valore medio nel campione.\nAdesso standardizziamo sia la variabile dipendente che la variabile indipendente.\n\n# Standardizzazione\nzx = standardize(x)\nzy = standardize(y)\n\n\nprint(np.mean(zx), np.std(zx))\n\n-2.049642507000289e-16 1.0\n\n\n\nprint(np.mean(zy), np.std(zy))\n\n-1.25255930983351e-16 1.0\n\n\n\nlm3 = pg.linear_regression(zx, zy)\nlm3.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-0.00\n0.08\n-0.00\n1.0\n0.52\n0.52\n-0.16\n0.16\n\n\n1\nstate1\n0.72\n0.08\n9.14\n0.0\n0.52\n0.52\n0.57\n0.88\n\n\n\n\n\n\n\nDopo aver standardizzato entrambe le variabili, i coefficienti di regressione possono essere interpretati nel seguente modo:\n\n\\(\\beta_0\\) = 0: Questo si verifica perché la retta di regressione, calcolata attraverso il metodo dei minimi quadrati (ML), interseca il punto delle medie delle variabili standardizzate, ovvero \\((\\bar{X}, \\bar{Y})\\).\n\\(\\beta_1\\): Rappresenta la variazione media della variabile dipendente, espressa in termini di deviazioni standard, per ogni aumento di una deviazione standard nella variabile indipendente.\n\n\n\n70.4.3 Derivazione delle stime dei minimi quadrati\nL’approccio classico al modello di regresione fa uso del metodo dei minimi quadrati per trovare la retta che meglio si adatta a un insieme di dati. L’obiettivo è minimizzare la somma dei quadrati delle differenze (residui) tra i valori osservati e quelli predetti dal modello lineare.\nSupponiamo di avere un insieme di dati \\((x_i, y_i)\\), dove \\(i = 1, 2, \\dots, n\\). Il modello lineare si esprime come:\n\\[\ny_i = \\alpha + \\beta x_i + \\epsilon_i,\n\\]\ndove:\n\n\\(\\alpha\\) è l’intercetta,\n\\(\\beta\\) è il coefficiente angolare (pendenza),\n\\(\\epsilon_i\\) è il residuo, ossia l’errore associato al punto \\(i\\).\n\nIl metodo dei minimi quadrati mira a minimizzare la somma dei quadrati dei residui \\(\\epsilon_i\\):\n\\[\nS(\\alpha, \\beta) = \\sum_{i=1}^n \\epsilon_i^2 = \\sum_{i=1}^n (y_i - (\\alpha + \\beta x_i))^2\n\\]\nGeometricamente, trovare i valori di \\(\\alpha\\) e \\(\\beta\\) che minimizzano la funzione \\(S(\\alpha, \\beta)\\) significa trovare il punto in cui la funzione è piatta, ossia dove la sua pendenza è zero. Questo si fa calcolando le derivate parziali di \\(S(\\alpha, \\beta)\\) rispetto a \\(\\alpha\\) e \\(\\beta\\), e ponendole uguali a zero:\n\\[\n\\frac{\\partial S}{\\partial \\alpha} = 0 \\quad \\text{e} \\quad \\frac{\\partial S}{\\partial \\beta} = 0.\n\\]\nRisolvendo questo sistema di equazioni, si trovano le espressioni per \\(\\alpha\\) e \\(\\beta\\):\n\\[\n\\beta = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2},\n\\]\n\\[\n\\alpha = \\bar{y} - \\beta \\bar{x},\n\\]\ndove \\(\\bar{x}\\) e \\(\\bar{y}\\) sono le medie dei valori \\(x_i\\) e \\(y_i\\) rispettivamente.\nPer chiarire, ora consideriamo il caso in cui i dati sono standardizzati. Quando i dati sono standardizzati (cioè \\(x_i\\) e \\(y_i\\) hanno media 0 e deviazione standard 1), l’intercetta \\(\\alpha\\) è 0, quindi il modello diventa:\n\\[\ny_i = \\beta x_i + \\epsilon_i\n\\]\nDi conseguenza, dobbiamo solo stimare \\(\\beta\\).\nEcco come eseguire una simulazione in Python per questo caso:\n\n# Serie di valori di beta tra 0 e 1\nbeta_values = np.linspace(0.5, 1, 1000)\n\n# Calcolo della somma dei quadrati dei residui (SSE) per ciascun valore di beta\nSSE = []\nfor beta in beta_values:\n    residuals = zy - beta * zx\n    SSE.append(np.sum(residuals**2))\n\n# Convertiamo SSE in un array numpy per maggiore facilità nella visualizzazione\nSSE = np.array(SSE)\n\nbeta_true = 0.72 # trovato da pingouin\n\n# Visualizzazione della curva SSE in funzione di beta\nplt.plot(beta_values, SSE, label=\"SSE vs Beta\", color=\"blue\")\nplt.axvline(beta_true, color=\"red\", linestyle=\"--\", label=f\"Beta True = {beta_true}\")\nplt.xlabel(\"Beta\")\nplt.ylabel(\"SSE (Somma dei quadrati dei residui)\")\nplt.title(\"Curva SSE in funzione di Beta\")\nplt.legend()\nplt.show()\n\n# Troviamo il valore di beta che minimizza SSE\nbeta_min_index = np.argmin(SSE)\nbeta_min = beta_values[beta_min_index]\n\nprint(f\"Valore di beta stimato con la formula dei minimi quadrati: {beta_true}\")\nprint(f\"Valore stimato di beta (minimo SSE): {beta_min}\")\n\n\n\n\n\n\n\n\nValore di beta stimato con la formula dei minimi quadrati: 0.72\nValore stimato di beta (minimo SSE): 0.7232232232232232",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#metodo-della-massima-verosimiglianza",
    "href": "chapters/linear_models/01_reglin_bayesian.html#metodo-della-massima-verosimiglianza",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.5 Metodo della Massima Verosimiglianza",
    "text": "70.5 Metodo della Massima Verosimiglianza\nDopo aver discusso il metodo dei minimi quadrati, possiamo affrontare il metodo della massima verosimiglianza, che in molti casi porta agli stessi risultati ma con un approccio leggermente diverso.\n\n70.5.0.1 Connessione con il Metodo dei Minimi Quadrati\nNel contesto della regressione lineare, se gli errori del modello sono indipendenti e distribuiti normalmente, cioè se \\(y_i \\sim \\text{Normale}(\\alpha + \\beta x_i, \\sigma^2)\\) per ogni \\(i\\), allora la stima dei parametri ottenuta con il metodo dei minimi quadrati coincide con quella ottenuta usando il metodo della massima verosimiglianza. Questo significa che i valori di \\(\\alpha\\) e \\(\\beta\\) che minimizzano la somma dei quadrati degli errori residui sono anche quelli che massimizzano la probabilità di osservare i dati dati quei parametri.\n\n\n70.5.0.2 La Funzione di Verosimiglianza\nIn un modello di regressione, la funzione di verosimiglianza è definita come la probabilità (o densità di probabilità) di osservare i dati effettivi in funzione dei parametri e dei predittori del modello. In altre parole, dato un insieme di parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), la funzione di verosimiglianza ci dice quanto è probabile osservare i dati \\(y\\) dati quei parametri.\nMatematicamente, la funzione di verosimiglianza per un modello di regressione lineare è espressa come:\n\\[\np(y|\\alpha, \\beta, \\sigma, X) = \\prod_{i=1}^{n} N(y_i|\\alpha + \\beta x_i, \\sigma^2).\n\\]\nQui, \\(N(\\cdot|\\cdot, \\cdot)\\) rappresenta la funzione di densità della distribuzione normale.\nQuesta formula indica che la verosimiglianza totale è il prodotto delle densità di probabilità per ciascun punto dati \\(y_i\\), considerando che ogni \\(y_i\\) segue una distribuzione normale con media \\(\\alpha + \\beta x_i\\) e varianza \\(\\sigma^2\\).\n\n\n70.5.0.3 Minimizzare i Residui Quadratici\nUn’analisi della funzione di verosimiglianza mostra che massimizzare questa funzione equivale a minimizzare la somma dei quadrati dei residui, proprio come si fa nel metodo dei minimi quadrati. Questo perché la funzione di densità normale \\(N(y_i|\\alpha + \\beta x_i, \\sigma^2)\\) ha un massimo quando il valore di \\(y_i\\) è vicino alla media prevista \\(\\alpha + \\beta x_i\\), e il prodotto delle densità è massimizzato quando i residui sono minimi.\n\n\n70.5.0.4 Differenza nella Stima di \\(\\sigma\\)\nC’è una piccola differenza nella stima della deviazione standard \\(\\sigma\\) tra i due metodi. Nel metodo della massima verosimiglianza, la stima di \\(\\sigma\\) viene calcolata come:\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^{n} \\left(y_i - (\\hat{\\alpha} + \\hat{\\beta} x_i)\\right)^2\n\\]\nIn questo caso, il denominatore è \\(n\\), mentre nel metodo dei minimi quadrati il denominatore è \\(n-2\\), che riflette l’aggiustamento per i gradi di libertà.\nIn sintesi, il metodo della massima verosimiglianza trova i parametri che rendono i dati osservati i più probabili, dato il modello. Quando gli errori sono normalmente distribuiti, questo approccio porta agli stessi risultati del metodo dei minimi quadrati, ma con un’interpretazione basata sulla probabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#coefficiente-di-determinazione",
    "href": "chapters/linear_models/01_reglin_bayesian.html#coefficiente-di-determinazione",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.6 Coefficiente di Determinazione",
    "text": "70.6 Coefficiente di Determinazione\nI modelli lineari, sia quelli stimati con il metodo dei minimi quadrati che quelli ottenuti tramite massima verosimiglianza, permettono una decomposizione della varianza totale della variabile dipendente \\(y\\) in due componenti indipendenti: la devianza spiegata e la devianza residua. Questa decomposizione deriva dal teorema della decomposizione della devianza, come descritto nell’Appendice T.\nLa devianza spiegata (DS) rappresenta la parte della varianza totale che è attribuibile al modello, ed è definita come:\n\\[\nDS = \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2,\n\\]\ndove \\(\\hat{y}_i\\) è il valore predetto dal modello per l’osservazione \\(i\\), e \\(\\bar{y}\\) è la media delle osservazioni di \\(y\\).\nLa devianza residua (DR), invece, rappresenta la parte della varianza totale che non è spiegata dal modello, ovvero l’errore, ed è calcolata come:\n\\[\nDR = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2.\n\\]\nLa somma delle due componenti, ovvero la devianza spiegata e la devianza residua, è pari alla devianza totale (DT):\n\\[\nDT = \\sum_{i=1}^n (y_i - \\bar{y})^2.\n\\]\nIl coefficiente di determinazione \\(R^2\\) è definito come il rapporto tra la devianza spiegata e la devianza totale:\n\\[\nR^2 = \\frac{DS}{DT}.\n\\]\nIl coefficiente di determinazione \\(R^2\\) fornisce una misura della proporzione della varianza totale di \\(y\\) che viene spiegata dal modello di regressione. Un valore di \\(R^2\\) vicino a 1 indica che il modello spiega una grande parte della variabilità osservata nei dati, mentre un valore vicino a 0 suggerisce che il modello spiega poco della variabilità della variabile dipendente.\nQuesto coefficiente è particolarmente utile per valutare l’adeguatezza di un modello lineare, permettendo di comprendere quanto del fenomeno studiato viene catturato dalle variabili indipendenti incluse nel modello. Tuttavia, è importante ricordare che un alto valore di \\(R^2\\) non implica necessariamente che il modello sia il migliore in senso assoluto; altri fattori come la complessità del modello e la presenza di potenziali errori di specificazione devono essere considerati nella valutazione complessiva del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#modello-di-regressione-bayesiano",
    "href": "chapters/linear_models/01_reglin_bayesian.html#modello-di-regressione-bayesiano",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.7 Modello di Regressione Bayesiano",
    "text": "70.7 Modello di Regressione Bayesiano\nL’approccio bayesiano si distingue dal metodo dei minimi quadrati o dalla massima verosimiglianza, poiché non si limita a determinare i parametri che meglio si adattano ai dati osservati secondo un criterio fisso. Al contrario, integra queste stime con informazioni a priori sui parametri stessi, combinando la verosimiglianza dei dati con una distribuzione a priori che rappresenta le ipotesi o le conoscenze preesistenti. In questo modo, l’inferenza bayesiana diventa un processo di aggiornamento delle credenze: la distribuzione a posteriori dei parametri riflette la conoscenza aggiornata dopo aver osservato i dati. Mentre i metodi classici forniscono stime puntuali, l’inferenza bayesiana genera distribuzioni a posteriori che descrivono la probabilità di ogni possibile valore dei parametri, tenendo conto dell’incertezza complessiva nel modello.\nNel contesto di un modello lineare bayesiano, si utilizzano le seguenti convenzioni: le variabili di risposta sono indicate con \\(y\\), le variabili predittive (note anche come covariate o caratteristiche) con \\(x\\), e l’indice di osservazione con \\(n\\), che va da 1 al numero totale di osservazioni \\(N\\). Con questa notazione, la verosimiglianza di un semplice modello lineare (gaussiano) si può esprimere come:\n\\[\ny_n \\sim \\text{Normale}(\\mu_n, \\sigma),\n\\]\n\\[\n\\mu_n = b_0 + b_1 x_n.\n\\]\nIn questo caso, la distribuzione normale univariata è definita in termini di media \\(\\mu\\) e deviazione standard \\(\\sigma\\).\nNel modello bayesiano lineare, i parametri principali sono l’intercetta \\(b_0\\) e il coefficiente \\(b_1\\) associato alla variabile predittiva \\(x\\). Questi parametri insieme formano il predittore lineare \\(\\mu\\). Il parametro \\(\\sigma\\), invece, rappresenta la deviazione standard residua, ovvero la variabilità che non può essere spiegata dal modello lineare e che cattura l’errore o il “rumore” presente nei dati.\nAd esempio, se si vuole modellare la relazione tra ansia di stato (\\(x\\)) e Tense Arousal (\\(y\\)), l’approccio bayesiano permette di strutturare il modello in modo simile a quanto fatto con i metodi classici. Anche qui, si assume che gli errori siano indipendenti tra loro, distribuiti normalmente con media zero e varianza costante \\(\\sigma^2\\). Tuttavia, l’approccio bayesiano consente anche di specificare distribuzioni a priori per i parametri del modello (\\(b_0\\), \\(b_1\\) e \\(\\sigma\\)), che rappresentano la conoscenza iniziale sui parametri prima di osservare i dati.\nDopo aver raccolto i dati, si utilizza il teorema di Bayes per aggiornare queste distribuzioni a priori e ottenere le distribuzioni a posteriori dei parametri. Le distribuzioni a posteriori combinano l’informazione fornita dai dati con le credenze iniziali, offrendo così stime dei parametri che riflettono sia l’evidenza empirica che le conoscenze preesistenti, garantendo un’inferenza più robusta e flessibile.\n\n70.7.1 Verosimiglianza\nIl modello di verosimiglianza per descrivere la relazione tra \\(x\\) (ansia di stato) e \\(y\\) (Tense Arousal) assume che:\n\\[ y \\sim \\text{Normale}(\\alpha + \\beta x, \\sigma) \\]\nQuesto implica che i valori osservati di \\(y\\) sono distribuiti normalmente attorno alla retta di regressione \\(\\alpha + \\beta x\\), con una deviazione standard \\(\\sigma\\). In altre parole, ogni osservazione di \\(y\\) è una combinazione lineare dell’intercetta \\(\\alpha\\), del coefficiente \\(\\beta\\) che moltiplica la variabile \\(x\\), e di un termine di errore normalmente distribuito.\n\n\n70.7.2 Distribuzioni a Priori\nPer implementare l’approccio bayesiano, definiamo delle distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\), e \\(\\sigma\\). In una prima versione del modello, possiamo utilizzare delle distribuzioni a priori uniformi, che esprimono una mancanza di conoscenza specifica o una neutralità nelle credenze iniziali sui valori di questi parametri.\n\n\n70.7.3 Distribuzioni a Posteriori\nLe distribuzioni a posteriori sono ottenute combinando la verosimiglianza con le distribuzioni a priori mediante il teorema di Bayes. Queste distribuzioni a posteriori riflettono il nostro stato di conoscenza sui parametri dopo aver osservato i dati, incorporando sia le informazioni contenute nei dati che le credenze iniziali espresse dalle distribuzioni a priori. L’approccio bayesiano, quindi, non solo fornisce stime dei parametri, ma anche una quantificazione dell’incertezza associata a queste stime, rendendolo particolarmente utile in situazioni con dati limitati o incertezza significativa.\nQuesta metodologia ci permette di modellare e comprendere in modo più completo e robusto la relazione tra ansia di stato e Tense Arousal, integrando informazioni preesistenti con nuove evidenze empiriche.\nIn sintesi, il modello di regressione bayesiano può essere riassunto come segue. La verosimiglianza è data da:\n\\[\ny_i \\sim \\text{Normal}(\\alpha + \\beta \\cdot x_i, \\sigma).\n\\]\nIn una prima formulazione del modello, possiamo utilizzare prior uniformi per ciascuno dei parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\):\n\\[\n\\alpha \\sim \\text{Uniform}(-\\infty, \\infty),\n\\] \\[\n\\beta \\sim \\text{Uniform}(-\\infty, \\infty),\n\\] \\[\n\\sigma \\sim \\text{Uniform}(0, \\infty).\n\\]\n\n\n70.7.4 Codice Stan\nIl codice Stan che implementa il modello descritto in precedenza è contenuto nel file arousal_model_1.stan. Compiliamo e stampiamo il modello.\n\nstan_file = os.path.join(project_directory, 'stan', 'arousal_model1.stan')\nmodel1 = CmdStanModel(stan_file=stan_file)\nprint(model1.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nSi osservi che, in questa prima istanziazione del modello bayesiano, non avendo specificato le distribuzioni a priori per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\), Stan assume distribuzioni a priori uniformi per questi parametri.\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = {\n    \"N\": len(df[\"TA1\"]),\n    \"x\": df[\"state1\"],\n    \"y\": df[\"TA1\"]\n}\nprint(stan_data)\n\n{'N': 78, 'x': 0     41\n1     26\n2     31\n3     28\n4     47\n      ..\n73    40\n74    60\n75    24\n76    33\n77    33\nName: state1, Length: 78, dtype: int64, 'y': 0     11.0\n1      5.0\n2      8.0\n3      8.0\n4     12.0\n      ... \n73    13.0\n74    20.0\n75    10.0\n76    10.0\n77     6.0\nName: TA1, Length: 78, dtype: float64}\n\n\nEseguiamo il campionamento MCMC.\n\nfit1 = model1.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(fit1, var_names=([\"alpha\", \"beta\", \"sigma\"]))\n\n\n\n\n\n\n\n\nLe tracce delle quattro catene indicano che sono ben mescolate e convergono verso una distribuzione stazionaria, segnalando una buona esplorazione dello spazio dei parametri. Questo è evidenziato dal fatto che le tracce non mostrano trend evidenti e oscillano intorno a un valore centrale, suggerendo che le catene hanno raggiunto l’equilibrio.\nLa forma della distribuzione a posteriori, visibile nei grafici a densità, appare approssimativamente gaussiana per ciascun parametro (alpha, beta, e sigma). Questo suggerisce che, dato il modello e i dati, le stime a posteriori sono stabili e ben definite, con una concentrazione delle probabilità attorno ai valori medi e una simmetria che riflette una distribuzione normale.\nIn sintesi, i grafici di traccia indicano una buona convergenza e una distribuzione a posteriori stabile e ben definita, rafforzando la fiducia nelle stime bayesiane ottenute.\nL’oggetto fit generato da cmdstanpy appartiene alla classe cmdstanpy.stanfit.mcmc.CmdStanMCMC. Questo oggetto è funzionalmente equivalente a un oggetto della classe InferenceData, consentendo la sua manipolazione tramite le funzioni offerte da ArviZ. Procediamo quindi con l’esame di un sommario delle distribuzioni a posteriori dei parametri del modello lineare.\n\naz.summary(fit1, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.552\n1.256\n-0.859\n3.816\n0.026\n0.019\n2395.0\n2748.0\n1.0\n\n\nbeta\n0.267\n0.029\n0.213\n0.323\n0.001\n0.000\n2436.0\n2858.0\n1.0\n\n\nsigma\n2.716\n0.227\n2.314\n3.149\n0.004\n0.003\n3410.0\n3273.0\n1.0\n\n\n\n\n\n\n\n\nAlpha (Intercetta): La stima media di alpha è 1.552, con un intervallo di credibilità (HDI - Highest Density Interval) al 3% e 97% che va da -0.859 a 3.816. Questo significa che, date le informazioni disponibili e il modello specificato, c’è una probabilità del 94% che l’intercetta reale si trovi all’interno di questo intervallo. L’intercetta corrisponde al valore atteso di Tense Arousal quando l’ansia di stato vale 0.\nBeta (Coefficiente angolare): La stima media di beta è 0.267. Anche qui, l’intervallo di credibilità al 94% va da 0.213 a 0.323, suggerendo che è molto probabile che l’effetto del predittore x sulla variabile di risposta y sia positivo e compreso in questo intervallo. La pendenza \\(\\beta\\) ci informa sull’incremento atteso di Tense Arousal quando l’ansia di stato aumenta di un’unità.\nSigma (Deviazione standard residua): La stima media di sigma è 2.716, con un intervallo di credibilità da 2.314 a 3.149. Questa è una misura della variabilità residua, ovvero la deviazione standard degli errori rispetto alla linea di regressione.\n\nLa colonna mean dell’output riporta la media della distribuzione a posteriori di ciasccun parametro, mentre nella colonna sd troviamo una misura di dispersione della distribuzione a posteriori del parametro, ovvero la quantificazione dell’intertezza della stima a posteriori. In pratica è la deviazione standard della distribuzione a posteriori, ovvero la radice quadrata della varianza dei campioni della distribuzione a posteriori del parametro.\nSupponiamo di avere \\(S\\) campioni per il parametro \\(\\theta\\). Questi campioni possono essere denotati come \\(\\theta_1, \\theta_2, \\dots, \\theta_S\\). La media campionaria (o stima puntuale bayesiana) del parametro \\(\\theta\\) si calcola come:\n\\[\n\\bar{\\theta} = \\frac{1}{S} \\sum_{i=1}^{S} \\theta_i.\n\\]\nLa deviazione standard della distribuzione a posteriori, che è ciò che è indicato con sd, si calcola come la radice quadrata della varianza campionaria dei campioni posteriori:\n\\[\n\\text{Var}(\\theta) = \\frac{1}{S-1} \\sum_{i=1}^{S} (\\theta_i - \\bar{\\theta})^2,\n\\]\n\\[\n\\text{sd}(\\theta) = \\sqrt{\\text{Var}(\\theta)}.\n\\]\nIn sintesi, sd è calcolato come la deviazione standard dei campioni ottenuti dalla distribuzione a posteriori di un parametro.\nLe altre colonne sono le seguenti.\n\nHDI (Intervallo di Massima Densità): Questo intervallo rappresenta la regione più densa dell’intera distribuzione a posteriori, contenente il 94% delle probabilità. È l’equivalente bayesiano dell’intervallo di confidenza, ma con un’interpretazione probabilistica diretta.\nR_hat: È un indicatore di convergenza per le catene di Markov Monte Carlo (MCMC). Un valore di R_hat prossimo a 1 segnala che la catena è probabilmente convergente, suggerendo che le stime a posteriori sono affidabili.\nESS (Dimensione Campionaria Effettiva): Indica l’equivalente di un campione indipendente in un’analisi MCMC, valutando quanto efficacemente i campioni generati dalla catena rappresentano la distribuzione a posteriori.\n\nInfine, mcse_mean che mcse_sd sono misure che valutano la precisione delle stime ottenute tramite MCMC, quantificando quanto queste stime possono variare a causa della natura stocastica del processo di campionamento.\n\nmcse_mean (Monte Carlo Standard Error of the Mean): Questo valore rappresenta l’errore standard Monte Carlo associato alla stima della media del parametro. In altre parole, mcse_mean quantifica l’incertezza introdotta dal processo di campionamento MCMC stesso. Un valore basso indica che la catena di Markov Monte Carlo ha fornito una stima della media del parametro con un’alta precisione.\nmcse_sd (Monte Carlo Standard Error of the Standard Deviation): Analogamente, mcse_sd è l’errore standard Monte Carlo associato alla stima della deviazione standard della distribuzione a posteriori del parametro. Questo valore misura l’incertezza nella stima della dispersione del parametro, dovuta al processo di campionamento MCMC. Anche qui, un valore basso indica che la stima della deviazione standard è stabile e precisa.\n\nPossiamo confrontare i valori ottenuti con l’approccio bayesiano con quelli trovati usando la procedura di massima verosimiglianza.\n\nlm = pg.linear_regression(df[\"state1\"], df[\"TA1\"])\nlm.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n1.56\n1.25\n1.25\n0.22\n0.52\n0.52\n-0.93\n4.04\n\n\n1\nstate1\n0.27\n0.03\n9.14\n0.00\n0.52\n0.52\n0.21\n0.33\n\n\n\n\n\n\n\nLa somiglianza tra le due soluzioni indica che, quando usiamo dei prior uniformi per i parametri, i due approcci producono risultati sostanzialmente equivalenti.\nL’interpretazione del significato dei parametri è la stessa anche per l’approccio frequentista:\n\nL’intercetta rappresenta il valore atteso della variabile di risposta TA1 quando il predittore state1 è pari a zero.\nIl coefficiente beta rappresenta la variazione attesa nella variabile di risposta TA1 per ogni unità di incremento in state1.\n\nCi sono però delle differenze sostanziali nell’interpretazione dell’incertezza associata alle stime dei parametri.\n\nStima Puntuale vs Distribuzione a Posteriori:\n\nFrequentista: Le stime di alpha e beta sono considerate come valori puntuali, ottenuti attraverso il metodo dei minimi quadrati. Gli errori standard associati a queste stime forniscono un’indicazione della variabilità delle stime se ripetessimo il campionamento molte volte.\nBayesiano: Le stime di alpha e beta sono presentate come distribuzioni a posteriori. La media di queste distribuzioni può essere considerata la stima puntuale, ma l’intera distribuzione riflette la nostra incertezza attorno a queste stime, basata sia sui dati osservati che sulle informazioni a priori.\n\nIntervallo di Confidenza vs Intervallo Credibile:\n\nFrequentista: L’intervallo di confidenza al 95% indica che, se ripetessimo l’esperimento molte volte, il 95% di tali intervalli conterrà il vero valore del parametro. Questo intervallo si basa sulla stima puntuale e sull’assunzione di distribuzione normale degli errori.\nBayesiano: L’intervallo credibile al 94% (ad esempio l’HDI - Highest Density Interval) rappresenta la probabilità che il parametro si trovi entro quell’intervallo dato il modello, i dati osservati e le informazioni a priori. È un’intervallo che ha una diretta interpretazione probabilistica.\n\np-value vs Significato Bayesiano:\n\nFrequentista: Il p-value è utilizzato per testare l’ipotesi nulla che il coefficiente sia uguale a zero. Un p-value molto basso (come in questo caso per beta) suggerisce che c’è una forte evidenza contro l’ipotesi nulla.\nBayesiano: In un’analisi bayesiana, non si fa riferimento a p-value; l’accento è posto sulla distribuzione a posteriori e sull’intervallo credibile, che forniscono una comprensione diretta dell’incertezza attorno ai parametri senza bisogno di test di ipotesi tradizionali.\n\n\nIn sintesi,\n\nInterpretazione delle stime: Nell’approccio frequentista, le stime dei parametri sono valori puntuali accompagnati da un intervallo di confidenza che riflette la variabilità campionaria. Nell’approccio bayesiano, ogni parametro è rappresentato come una distribuzione a posteriori che incorpora sia i dati osservati sia le informazioni a priori.\nGestione dell’incertezza: L’approccio frequentista usa errori standard e intervalli di confidenza, mentre l’approccio bayesiano utilizza l’intera distribuzione a posteriori per descrivere l’incertezza.\nProbabilità e significatività: Nell’approccio frequentista, il p-value è cruciale per determinare la significatività statistica, mentre nell’approccio bayesiano si utilizza l’intervallo credibile e la probabilità a posteriori per descrivere quanto è probabile un parametro dato i dati e le informazioni a priori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti",
    "href": "chapters/linear_models/01_reglin_bayesian.html#interpretare-i-coefficienti-di-regressione-come-confronti-non-come-effetti",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.8 Interpretare i coefficienti di regressione come confronti, non come effetti",
    "text": "70.8 Interpretare i coefficienti di regressione come confronti, non come effetti\nGelman et al. (2021) sottolineano che i coefficienti di regressione sono spesso chiamati “effetti”, ma questa terminologia può essere fuorviante. Gli effetti, infatti, sono conseguenze di una relazione causale. Tuttavia, ciò che il modello di regressione stima non è necessariamente un effetto causale, ma piuttosto un pattern osservazionale. In particolare, quello che viene osservato è che la media della variabile \\(y\\) nella sottopopolazione con \\(X = x + 1\\) è \\(b\\) volte maggiore o minore (a seconda del segno di \\(\\beta\\)) rispetto alla media della sottopopolazione con \\(X = x\\).\nLa regressione è uno strumento matematico utilizzato principalmente per fare previsioni. I coefficienti di regressione devono essere sempre interpretati come confronti medi. Solo in circostanze specifiche, quando la regressione descrive un processo causale ben definito, è possibile interpretarli come effetti. Tuttavia, questa interpretazione causale deve essere giustificata dal disegno dello studio e non può essere derivata unicamente dall’uso del modello statistico.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#ricodifica-dei-dati",
    "href": "chapters/linear_models/01_reglin_bayesian.html#ricodifica-dei-dati",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.9 Ricodifica dei dati",
    "text": "70.9 Ricodifica dei dati\nL’intercetta (\\(\\alpha\\)) rappresenta il valore atteso di Tense Arousal quando l’ansia di stato è pari a 0. Tuttavia, poiché l’ansia di stato è misurata su una scala ad intervalli, l’origine è arbitraria e non rappresenta l’assenza della proprietà. Lo stesso vale per la variabile Tense Arousal. Per entrambe le variabili, inoltre, anche l’unità di misura è arbitraria.\nIn queste circostanze, una trasformazione utile è la standardizzazione. La standardizzazione fa sì che il valore 0 corrisponda alla media campionaria e che l’unità di misura sia una deviazione standard.\nQuando standardizziamo l’ansia di stato, il valore 0 della variabile standardizzata corrisponde alla media della variabile originale. Dato che la retta di regressione passa per il punto \\((\\bar{x}, \\bar{y})\\), utilizzando i valori standardizzati di \\(x\\) e \\(y\\), la nuova intercetta (\\(\\alpha\\)) sarà 0. La pendenza (\\(\\beta\\)) avrà un’interpretazione utile: nel caso di dati standardizzati, la pendenza stima l’incremento (o decremento) atteso di \\(y\\) quando \\(x\\) aumenta di una deviazione standard.\n\n# Calcolo della media e della deviazione standard di state1\nmean_state1 = np.mean(df[\"state1\"])\nstd_state1 = np.std(df[\"state1\"])\n# Standardizzazione \ndf[\"state1_z\"] = (df[\"state1\"] - mean_state1) / std_state1\n\n# Calcolo della media e della deviazione standard di TA1\nmean_ta1 = np.mean(df[\"TA1\"])\nstd_ta1 = np.std(df[\"TA1\"])\n# Standardizzazione \ndf[\"ta1_z\"] = (df[\"TA1\"] - mean_ta1) / std_ta1\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_79156/3940630615.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"state1_z\"] = (df[\"state1\"] - mean_state1) / std_state1\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_79156/3940630615.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"ta1_z\"] = (df[\"TA1\"] - mean_ta1) / std_ta1\n\n\nCreiamo il dizionario dei dati con le nuove variabli standardizzate.\n\nstan_data2 = {\n    \"N\": len(df[\"state1_z\"]), \n    \"x\": df[\"state1_z\"], \n    \"y\": df[\"ta1_z\"]\n}\n\nEseguiamo il campionamento.\n\nfit2 = model1.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit2, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.000\n0.081\n-0.152\n0.155\n0.001\n0.001\n6678.0\n5110.0\n1.0\n\n\nbeta\n0.723\n0.082\n0.571\n0.879\n0.001\n0.001\n7508.0\n5666.0\n1.0\n\n\nsigma\n0.712\n0.059\n0.603\n0.822\n0.001\n0.000\n7985.0\n5955.0\n1.0\n\n\n\n\n\n\n\nOra possiamo assegnare al parametro \\(\\beta\\) la seguente interpretazione: quando l’ansia di stato aumenta di una deviazione standard Tense Arousal aumenta, in media, di 0.72 deviazioni standard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#distribuzioni-a-priori-sui-parametri",
    "href": "chapters/linear_models/01_reglin_bayesian.html#distribuzioni-a-priori-sui-parametri",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.10 Distribuzioni a Priori sui Parametri",
    "text": "70.10 Distribuzioni a Priori sui Parametri\nNei modelli precedenti, abbiamo adottato distribuzioni a priori uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Tuttavia, in generale, quando non disponiamo di informazioni pregresse sul valore dei parametri, è preferibile specificare distribuzioni debolmente informative. Queste distribuzioni sono progettate per essere centrate su un valore neutro, come lo zero, in modo tale da non influenzare in modo significativo la distribuzione a posteriori nella direzione “desiderata” dal ricercatore. L’obiettivo delle distribuzioni a priori debolmente informative è, infatti, quello di regolarizzare il modello, penalizzando le osservazioni più estreme e contribuendo a una stima più robusta dei parametri.\nPer il caso in esame, specificheremo le seguenti distribuzioni a priori debolmente informative sui parametri del modello.\n\nIntercetta (\\(\\alpha\\)):\n\n\\(\\alpha \\sim \\text{Normale}(0, 1)\\)\nLa scelta di una deviazione standard ampia (2) riflette l’incertezza riguardo al valore iniziale dell’intercetta. Si crede che l’intercetta possa essere qualsiasi valore vicino a 0, ma con una variazione significativa.\n\nCoefficiente Angolare (\\(\\beta\\)):\n\n\\(\\beta \\sim \\text{Normale}(0, 2)\\)\nUn’ampia deviazione standard (2) per \\(\\beta\\) permette di incorporare l’incertezza riguardo all’influenza della temperatura sui ricavi del gelato. Questo prior permette che \\(\\beta\\) possa essere sia positivo che negativo con una vasta gamma di valori.\n\nDeviazione Standard Residua (\\(\\sigma\\)):\n\n\\(\\sigma \\sim \\text{Cauchy}^+(0, 2)\\)\nLa distribuzione Half-Cauchy è scelta perché è debolmente informativa e adatta per i parametri di scala come la deviazione standard residua. La scala di 2 consente a \\(\\sigma\\) di assumere una vasta gamma di valori positivi, riflettendo l’incertezza riguardo alla variabilità residua.\n\n\nLe distribuzioni normali per \\(\\alpha\\) e \\(\\beta\\) con deviazioni standard ampie permettono una grande flessibilità, mentre la distribuzione Half-Cauchy per \\(\\sigma\\) è scelta per la sua capacità di gestire bene i parametri di scala. Queste scelte garantiscono che il modello sia debolmente informativo, permettendo ai dati osservati di avere un’influenza predominante sulle stime posteriori dei parametri.\nCompiliamo e stampiamo il modello Stan che include le specificazioni delle distribuzioni a priori dei parametri su elencate.\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model_prior_raw.stan\")\nmodel3 = CmdStanModel(stan_file=stan_file)\nprint(model3.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nAdattiamo il modello ai dati.\n\nfit3 = model3.sample(\n    data=stan_data2,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit3, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.000\n0.081\n-0.147\n0.155\n0.001\n0.001\n6463.0\n5733.0\n1.0\n\n\nbeta\n0.724\n0.080\n0.569\n0.869\n0.001\n0.001\n8212.0\n6155.0\n1.0\n\n\nsigma\n0.710\n0.058\n0.605\n0.825\n0.001\n0.000\n7705.0\n5931.0\n1.0\n\n\n\n\n\n\n\nSi noti che, utilizzando distribuzioni a priori debolmente informative, le distribuzioni a posteriori dei parametri risultano molto simili a quelle ottenute usando distribuzioni uniformi. Tuttavia, le distribuzioni a priori debolmente informative sono preferibili poiché forniscono una maggiore stabilità numerica e sono generalmente più affidabili e robuste, specialmente quando si lavora con dati reali. L’uso di distribuzioni uniformi è sconsigliato per via delle possibili instabilità numeriche che possono introdurre nei modelli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi",
    "href": "chapters/linear_models/01_reglin_bayesian.html#verifica-della-procedura-di-fitting-del-modello-utilizzando-una-simulazione-con-dati-fittizi",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.11 Verifica della procedura di fitting del modello utilizzando una simulazione con dati fittizi",
    "text": "70.11 Verifica della procedura di fitting del modello utilizzando una simulazione con dati fittizi\nL’esempio precedente è abbastanza semplice da permetterci di tracciare un grafico e vedere se la linea di regressione attraversa i punti. Tuttavia, in generale, è una buona pratica verificare l’adattamento del modello eseguendo la procedura in condizioni controllate, dove conosciamo la verità. Mostriamo questo approccio utilizzando il modello precedente.\nPasso 1: Creazione di un mondo fittizio.\nIniziamo assumendo dei valori reali per tutti i parametri del modello. In questo caso, abbiamo già adattato un modello ai dati, quindi procediamo assumendo che questi particolari valori dei parametri siano la verità. In altre parole, assumiamo che la relazione \\(y = 1.126 + 2.2x + \\text{errore}\\) sia vera, con gli errori estratti da una distribuzione normale con media 0 e deviazione standard 2.688. Successivamente, utilizzando i valori predittori \\(x\\) già presenti nel nostro dataset, esaminiamo se questi predittori generano una distribuzione di \\(y\\) coerente con i valori osservati di \\(y\\).\n\na = 1.126   \nb = 0.277\nsigma = 2.688\nx = df[\"state1\"]\nn = len(x)\n\nPasso 2: Simulazione di dati fittizi.\nSuccessivamente, simuleremo un vettore \\(y\\) di dati fittizi e inseriremo tutto questo in un data frame:\n\ny = a + b * x + np.random.normal(0, sigma, size=n)\nfake = pd.DataFrame({\"x\": x, \"y\": y})\nfake.head()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n41\n14.560092\n\n\n1\n26\n10.537546\n\n\n2\n31\n11.326387\n\n\n3\n28\n8.181064\n\n\n4\n47\n13.802861\n\n\n\n\n\n\n\nPasso 3: Adattamento del modello e confronto tra i valori stimati e quelli assunti.\nIl passo successivo è adattare un modello di regressione a questi dati. Durante l’adattamento, non si fa alcun uso dei valori veri assunti di α, β e σ.\n\nlm = pg.linear_regression(fake[\"x\"], fake[\"y\"])\nlm.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n1.44\n1.30\n1.11\n0.27\n0.53\n0.52\n-1.15\n4.03\n\n\n1\nx\n0.28\n0.03\n9.17\n0.00\n0.53\n0.52\n0.22\n0.34\n\n\n\n\n\n\n\nLe stime ottenute dai dati fittizzi sono molto simili a quelle ottenute con i dati veri.\nPasso 4: Inserire la simulazione in un loop.\nPer ottenere una stima dell’incertezza delle nostre stime, ripetiamo la simulazione molte volte e calcoliamo il livello di copertura dei parametri.\nIl livello di copertura rappresenta la proporzione delle volte in cui l’intervallo di confidenza calcolato contiene il vero valore del parametro \\(b\\). In altre parole, se l’intervallo di confidenza al 68% (o 95%) è calcolato correttamente, ci aspetteremmo che, rispettivamente, il 68% (o 95%) di questi intervalli contenga il vero valore di \\(b\\).\n\nIl codice seguente esegue n_fake = 10_000 simulazioni, ciascuna delle quali genera un set di dati fittizio e adatta un modello di regressione a questi dati.\nI valori critici t_68 e t_95 sono calcolati utilizzando la funzione t.ppf di scipy.stats, che fornisce i quantili della distribuzione t di Student per il livello di confidenza desiderato:\n\nt_68 corrisponde al quantile dell’84%, che definisce l’intervallo di confidenza al 68%.\nt_95 corrisponde al quantile del 97,5%, che definisce l’intervallo di confidenza al 95%.\n\nPer ogni simulazione (s da 0 a n_fake - 1):\n\nVengono generati dati fittizi per la variabile indipendente x e per la variabile dipendente y usando i valori di a, b, e sigma.\nViene adattato un modello di regressione lineare ai dati fittizi usando la libreria pingouin.\nIl coefficiente stimato b_hat e il suo errore standard b_se sono estratti dai risultati della regressione.\nViene verificato se il vero valore di \\(b\\) si trova all’interno dell’intervallo \\(b_hat \\pm t_68 \\times b_se\\).\n\ncover_68[s] = np.abs(b - b_hat) &lt; t_68 * b_se memorizza True (1) se il vero valore di \\(b\\) è all’interno dell’intervallo di confidenza al 68%, altrimenti False (0).\n\nViene verificato se il vero valore di \\(b\\) si trova all’interno dell’intervallo \\(b_hat \\pm t_95 \\times b_se\\).\ncover_95[s] = np.abs(b - b_hat) &lt; t_95 * b_se memorizza True (1) se il vero valore di \\(b\\) è all’interno dell’intervallo di confidenza al 95%, altrimenti False (0).\n\n\nDopo aver completato tutte le simulazioni, i livelli di copertura sono calcolati come la media dei valori in cover_68 e cover_95:\n\ncover_68.mean() fornisce la proporzione di simulazioni in cui l’intervallo di confidenza al 68% ha contenuto il vero valore di \\(b\\).\ncover_95.mean() fornisce la proporzione di simulazioni in cui l’intervallo di confidenza al 95% ha contenuto il vero valore di \\(b\\).\n\nSe il risultato è vicino a 0.68, significa che l’intervallo di confidenza al 68% calcolato per ogni simulazione ha contenuto il vero valore di \\(b\\) nel 68% delle simulazioni, come previsto teoricamente. Se il risultato è vicino a 0.95, significa che l’intervallo di confidenza al 95% calcolato per ogni simulazione ha contenuto il vero valore di \\(b\\) nel 95% delle simulazioni, in linea con le aspettative teoriche.\nSe i livelli di copertura risultano sostanzialmente inferiori ai valori teorici (68% e 95%), potrebbe indicare problemi nella stima degli intervalli di confidenza o nelle assunzioni del modello.\n\nfrom scipy.stats import t\n\n# Parametri della simulazione\nn_fake = 10_000  # numero di simulazioni\n\n# Inizializzazione delle liste di copertura\ncover_68 = np.zeros(n_fake)\ncover_95 = np.zeros(n_fake)\n\n# Calcola i valori critici t per il 68% e il 95% utilizzando scipy.stats.t.ppf\nt_68 = t.ppf(0.84, df=n - 2)\nt_95 = t.ppf(0.975, df=n - 2)\n\n# Ciclo per la simulazione\nfor s in range(n_fake):\n    x = np.random.normal(size=n)\n    y = a + b * x + np.random.normal(0, sigma, size=n)\n    fake = pd.DataFrame({\"x\": x, \"y\": y})\n\n    # Fit del modello usando pingouin\n    fit = pg.linear_regression(fake[[\"x\"]], fake[\"y\"])\n    b_hat = fit[\"coef\"][1]\n    b_se = fit[\"se\"][1]\n\n    # Calcolo della copertura\n    cover_68[s] = np.abs(b - b_hat) &lt; t_68 * b_se\n    cover_95[s] = np.abs(b - b_hat) &lt; t_95 * b_se\n\n# Output dei risultati\nprint(f\"68% coverage: {cover_68.mean()}\")\nprint(f\"95% coverage: {cover_95.mean()}\")\n\n68% coverage: 0.6798\n95% coverage: 0.9462\n\n\nSi noti come la simulazione produce una copertura molto prossima a quella teorica. Ciò significa che, nel caso di questa analisi, possiamo assegnare agli intervalli di confidenza o credibilità l’interpretazione usuale. Se il livello di copertura della simulazione fosse stato inferiore a quello teorico (per modelli più complessi), allora questo sarebbe un’indicazione che si dovrebbero interpetare gli intervalli di confidenza o credibilità con cautela.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#il-paradosso-della-regressione-verso-la-media",
    "href": "chapters/linear_models/01_reglin_bayesian.html#il-paradosso-della-regressione-verso-la-media",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.12 Il Paradosso della Regressione verso la Media",
    "text": "70.12 Il Paradosso della Regressione verso la Media\nIl fenomeno della regressione verso la media è un concetto statistico importante, spesso frainteso e talvolta interpretato erroneamente come un effetto causale. Questo fenomeno fu osservato inizialmente da Galton in uno studio classico sull’ereditarietà dell’altezza.\nGelman et al. (2021) discutono questo fenomeno analizzando i dati pubblicati nel 1903 da Karl Pearson e Alice Lee. Applicando un modello di regressione lineare a questi dati, si ottiene la seguente equazione:\n\\[\ny = 63.9 + 0.54(x − 62.5) + \\text{errore},\n\\]\ndove \\(y\\) rappresenta l’altezza delle figlie e \\(x\\) l’altezza delle madri. La variabile indipendente è stata centrata per evitare interpretazioni prive di senso dell’intercetta.\nIl paradosso emerge dal coefficiente di regressione, che è inferiore a 1. Questo implica che:\n\nSe una madre ha un’altezza nella media, si prevede che sua figlia adulta avrà anch’essa un’altezza nella media.\nPer ogni pollice in più (o in meno) rispetto alla media dell’altezza materna, ci si aspetta che la figlia sia circa mezzo pollice più alta (o più bassa) rispetto alla media della sua generazione.\n\nQuesto porta a una domanda apparentemente paradossale: se le madri alte tendono ad avere figlie solo leggermente alte, e le madri basse figlie solo leggermente basse, non significa che le figlie saranno più vicine alla media rispetto alle loro madri? E se questo processo continua, non dovremmo aspettarci che dopo poche generazioni tutti abbiano un’altezza vicina alla media?\nLa risoluzione di questo apparente paradosso sta nel fatto che la previsione dell’altezza di una donna è più vicina alla media rispetto all’altezza di sua madre, ma l’altezza effettiva non è la stessa cosa della previsione, che ha un margine di errore. Le previsioni puntuali regrediscono verso la media - ecco perché il coefficiente è inferiore a 1 - e questo riduce la variazione. Allo stesso tempo, però, l’errore nel modello - l’imperfezione della previsione - aggiunge variazione, sufficiente a mantenere la variazione totale dell’altezza approssimativamente costante da una generazione all’altra.\nLa regressione verso la media si verifica sempre in qualche forma quando le previsioni sono imperfette in un ambiente stabile. L’imperfezione della previsione induce variazione, e la regressione nella previsione puntuale è necessaria per mantenere costante la variazione totale.\nQuesto fenomeno è controintuitivo e spesso porta a interpretazioni causali errate. Per chiarire come ciò possa accadere, possiamo considerare uno scenario matematicamente equivalente: studenti che affrontano due esami. Coloro che ottengono punteggi alti nel primo esame tendono a ottenere risultati solo leggermente superiori alla media nel secondo; d’altra parte, chi ottiene punteggi bassi nel primo esame tende a migliorare leggermente, ottenendo risultati nel secondo esame che, pur restando inferiori alla media, non sono così bassi come i primi.\nPotrebbe sembrare naturale dare a questo fenomeno una spiegazione causale, suggerendo che gli studenti che eccellono nel primo esame possano avere alte capacità ma poi, diventando troppo sicuri di sé, tendano a rilassarsi, con il risultato di non ripetere la stessa performance nel secondo. Dall’altro lato, si potrebbe ipotizzare che gli studenti con punteggi bassi nel primo esame siano motivati a impegnarsi di più, migliorando così i loro risultati nel secondo.\nIn realtà, il fenomeno della regressione verso la media si verifica anche in assenza di fattori motivazionali, come dimostrano simulazioni in cui sia il primo che il secondo esame sono determinati dalla vera abilità dell’individuo, più un elemento di rumore casuale. La regressione verso la media è un fenomeno puramente statistico, privo di una spiegazione causale intrinseca. Comprendere correttamente questo concetto è essenziale per evitare di trarre conclusioni errate dai dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "href": "chapters/linear_models/01_reglin_bayesian.html#commenti-e-considerazioni-finali",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "70.13 Commenti e considerazioni finali",
    "text": "70.13 Commenti e considerazioni finali\nIn questo capitolo abbiamo esplorato la stima dei parametri di un modello di regressione bivariato utilizzando l’approccio bayesiano. Questo percorso ci ha portato a riflettere sulla natura e sul ruolo dei modelli statistici nella ricerca scientifica, in particolare nel campo della psicologia.\nCome sottolineato da Alexander (2023), è fondamentale comprendere che i modelli statistici non sono strumenti per scoprire una verità assoluta, ma piuttosto mezzi per esplorare e interpretare i dati a nostra disposizione. Questa prospettiva ci invita a considerare i modelli non come rappresentazioni perfette della realtà, ma come lenti attraverso le quali osserviamo e cerchiamo di comprendere il mondo che ci circonda.\nL’affermazione di McElreath che “la regressione è in effetti un oracolo, ma un oracolo crudele. Parla per enigmi e si diletta nel punirci per aver posto domande sbagliate” (McElreath, 2020) mette in luce la natura complessa e talvolta insidiosa dell’uso dei modelli statistici. Questa metafora ci ricorda che l’applicazione dei modelli richiede non solo competenza tecnica, ma anche una profonda comprensione del contesto e una costante riflessione critica.\nNel processo di modellizzazione statistica, è cruciale considerare due dimensioni interconnesse: il “mondo del modello”, con le sue assunzioni e semplificazioni, e il “mondo reale”, caratterizzato da una complessità spesso difficile da catturare pienamente. Questa distinzione ci invita a riflettere costantemente sulla relazione tra il modello e la realtà che cerchiamo di comprendere, ponendoci domande sulla misura in cui il modello ci insegna qualcosa sui dati a disposizione e su quanto accuratamente questi dati riflettano la realtà oggetto del nostro studio.\nL’evoluzione dei metodi statistici, dalle loro origini in campi come l’astronomia e l’agricoltura fino alle applicazioni moderne in psicologia, evidenzia la necessità di adattare e riconsiderare costantemente questi strumenti. Il lavoro pioneristico di Ronald Fisher, sviluppato in gran parte in un contesto di ricerca agricola, pone interrogativi sulla validità delle sue assunzioni fondamentali quando applicate alla psicologia contemporanea. McElreath (2020) sottolinea l’importanza di sviluppare modelli basati su ipotesi relative ai meccanismi psicologici sottostanti al comportamento, suggerendo che questi possano offrire intuizioni più profonde rispetto a un approccio puramente descrittivo come quello della regressione lineare.\nNonostante queste considerazioni, il modello di regressione rimane uno strumento di grande valore per la psicologia. Tuttavia, il suo utilizzo efficace richiede un equilibrio tra una solida conoscenza del fenomeno oggetto di studio e la flessibilità necessaria per adattarsi a contesti di ricerca in continua evoluzione. Gli psicologi sono chiamati a considerare una gamma più ampia di strumenti statistici, cercando quelli più appropriati per descrivere i complessi fenomeni psicologici, superando i limiti di un approccio puramente descrittivo.\nIn conclusione, questo capitolo ci ha permesso di esplorare l’approccio bayesiano alla regressione, offrendo una prospettiva critica sull’uso dei modelli statistici in psicologia. Per un confronto più ampio, l’appendice presenta un’introduzione all’approccio frequentista per il modello di regressione lineare bivariato, consentendo di apprezzare le differenze tra i due metodi nella stima dei parametri e nell’interpretazione dei risultati. Per approfondimenti ulteriori, si consiglia la lettura di Applied Regression Analysis and Generalized Linear Models (Fox, 2015), in particolare il capitolo 2, e, in italiano, Statistica per psicologi (Caudek & Luccio, 2001).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/01_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/01_reglin_bayesian.html#informazioni-sullambiente-di-sviluppo",
    "title": "70  Modello bayesiano di regressione lineare bivariata",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\narviz     : 0.18.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\nlogging   : 0.5.1.2\npingouin  : 0.5.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\n\n\n\n\n\n\nAlexander, R. (2023). Telling Stories with Data: With Applications in R. Chapman; Hall/CRC.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi (III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nFox, J. (2015). Applied regression analysis and generalized linear models. Sage publications.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nRafaeli, E., & Revelle, W. (2006). A premature consensus: are happiness and sadness truly opposite affects? Motivation and Emotion, 30, 1–12.\n\n\nStigler, S. (1986). The History of Statistics. Belknap Harvard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>Modello bayesiano di regressione lineare bivariata</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_non_centered_param.html",
    "href": "chapters/linear_models/02_non_centered_param.html",
    "title": "71  Non-Centered Parameterization",
    "section": "",
    "text": "Introduzione\nLo scopo di questo capitolo è spiegare il concetto di Non-Centered Parameterization.\nIn un modello di regressione bivariata, l’obiettivo è stimare una relazione lineare tra due variabili: ad esempio, l’altezza (\\(y\\)) e il peso (\\(x\\)) di un campione di persone adulte. Supponiamo di avere una relazione del tipo:\n\\[\ny_i = \\alpha + \\beta x_i + \\epsilon_i,\n\\]\ndove:",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Non-Centered Parameterization</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_non_centered_param.html#introduzione",
    "href": "chapters/linear_models/02_non_centered_param.html#introduzione",
    "title": "71  Non-Centered Parameterization",
    "section": "",
    "text": "\\(y_i\\) è l’altezza dell’individuo \\(i\\),\n\\(x_i\\) è il peso dell’individuo \\(i\\) (espresso come differenze dalla media per migliorare l’interpretabilità),\n\\(\\alpha\\) è l’intercetta,\n\\(\\beta\\) è il coefficiente di regressione,\n\\(\\epsilon_i\\) è l’errore residuo, spesso assunto distribuito secondo una normale con media zero e varianza \\(\\sigma^2\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Non-Centered Parameterization</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_non_centered_param.html#un-esempio-concreto",
    "href": "chapters/linear_models/02_non_centered_param.html#un-esempio-concreto",
    "title": "71  Non-Centered Parameterization",
    "section": "71.1 Un Esempio Concreto",
    "text": "71.1 Un Esempio Concreto\nPer fare un esempio, applicheremo il modello di regressione bivariato alla relazione tra altezza e peso. I dati contenuti nel file Howell_18.csv sono parte di un censimento parziale della popolazione !Kung San dell’area di Dobe, raccolti tramite interviste condotte da Nancy Howell alla fine degli anni ’60 (McElreath, 2020). I !Kung San sono una delle popolazioni di raccoglitori-cacciatori più conosciute del ventesimo secolo e sono stati oggetto di numerosi studi antropologici. In questa analisi, consideriamo un sottocampione di dati relativi alla popolazione adulta (di età superiore ai 18 anni).\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"Howell_18.csv\")\n\n# Leggere il file CSV in un DataFrame pandas\ndf = pd.read_csv(file_path)\ndf.head()\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\nEsaminiamo la relazione tra altezza e peso con un diagramma a dispersione.\n\nplt.scatter(\n    df[\"weight\"],\n    df[\"height\"]\n)\nplt.xlabel(\"Peso (kg)\")\nplt.ylabel(\"Altezza (cm)\")\nplt.show()\n\n\n\n\n\n\n\n\nPer facilitare l’analisi successiva, centriamo la variabile \\(X\\) (peso) in modo tale che l’intercetta del modello di regressione corrisponda all’altezza prevista degli individui con un peso medio.\n\ndf[\"weight_c\"] = df[\"weight\"] - np.mean(df[\"weight\"])\n\n\nplt.scatter(\n    df[\"weight_c\"],\n    df[\"height\"]\n)\nplt.xlabel(\"Peso centrato (kg)\")\nplt.ylabel(\"Altezza (cm)\")\nplt.show()\n\n\n\n\n\n\n\n\nEseguiamo l’analisi di regressione con l’approccio della massima verosimiglianza.\n\nlm = pg.linear_regression(df[\"weight_c\"], df[\"height\"])\nlm.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n154.60\n0.27\n570.25\n0.0\n0.57\n0.57\n154.06\n155.13\n\n\n1\nweight_c\n0.91\n0.04\n21.52\n0.0\n0.57\n0.57\n0.82\n0.99",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Non-Centered Parameterization</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_non_centered_param.html#prima-versione-del-modello-utilizzo-dei-dati-grezzi",
    "href": "chapters/linear_models/02_non_centered_param.html#prima-versione-del-modello-utilizzo-dei-dati-grezzi",
    "title": "71  Non-Centered Parameterization",
    "section": "71.2 Prima Versione del Modello: Utilizzo dei Dati Grezzi",
    "text": "71.2 Prima Versione del Modello: Utilizzo dei Dati Grezzi\nIn una priva versione del modello Stan, stimeremo i parametri del modello di regressione direttamente dai dati grezzi. Quando modelliamo direttamente sui dati grezzi, il modello in Stan ha la forma seguente.\n\nstan_file = os.path.join(project_directory, \"stan\", \"howell_model.stan\")\nmodel_raw = CmdStanModel(stan_file=stan_file)\nprint(model_raw.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  vector[N] x; // pesi (differenze dalla media)\n  vector[N] y; // altezze\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente di regressione\n  real&lt;lower=0&gt; sigma; // deviazione standard dell'errore\n}\nmodel {\n  // Priors\n  alpha ~ normal(154, 10); // prior per l'intercetta\n  beta ~ normal(0, 5); // prior per il coefficiente di regressione\n  sigma ~ cauchy(0, 5); // prior per la deviazione standard\n  \n  // Likelihood\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nSi osservi che, in questa prima istanziazione del modello bayesiano, abbiamo specificato le seguenti distribuzioni a priori per i parametri del modello:\nalpha ~ normal(154, 10); // prior per l'intercetta\nbeta ~ normal(0, 5); // prior per il coefficiente di regressione\nsigma ~ cauchy(0, 5); // prior per la deviazione standard\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = {\"N\": len(df[\"height\"]), \"x\": df[\"weight_c\"], \"y\": df[\"height\"]}\n\nEseguiamo il campionamento MCMC.\n\nfit_raw = model_raw.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(fit_raw, var_names=([\"alpha\", \"beta\", \"sigma\"]))\n\n\n\n\n\n\n\n\nProcediamo quindi con l’esame di un sommario delle distribuzioni a posteriori dei parametri del modello lineare.\n\naz.summary(fit_raw, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n154.596\n0.274\n154.086\n155.115\n0.003\n0.002\n8561.0\n5960.0\n1.0\n\n\nbeta\n0.904\n0.042\n0.824\n0.980\n0.000\n0.000\n7766.0\n6003.0\n1.0\n\n\nsigma\n5.096\n0.193\n4.745\n5.471\n0.002\n0.002\n7739.0\n5899.0\n1.0\n\n\n\n\n\n\n\nAvendo usato dei prior debolmente informativi, le medie delle distribuzioni a posteriori dei parametri del modello replicano sostanzialmente i risultati ottenuti con il metodo della massima verosimiglianza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Non-Centered Parameterization</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_non_centered_param.html#seconda-versione-del-modello-non-centered-parameterization",
    "href": "chapters/linear_models/02_non_centered_param.html#seconda-versione-del-modello-non-centered-parameterization",
    "title": "71  Non-Centered Parameterization",
    "section": "71.3 Seconda Versione del Modello: Non-Centered Parameterization",
    "text": "71.3 Seconda Versione del Modello: Non-Centered Parameterization\nIn una seconda versione del modello Stan usiamo la Non-Centered Parameterization.\nLa Non-Centered Parameterization (NCP) è una tecnica utilizzata per migliorare la convergenza dei modelli Bayesiani, specialmente quando i dati sono correlati o quando ci sono differenze di scala tra i parametri. È particolarmente utile nei modelli gerarchici, ma può essere applicata anche a modelli semplici come quello che stiamo considerando.\n\n71.3.1 Cosa Significa Non-Centered Parameterization?\nIn una parametrizzazione classica (“centered”), i parametri sono direttamente campionati dallo spazio dei dati. Tuttavia, in una “non-centered parameterization”, riformuliamo il modello per campionare da uno spazio trasformato (solitamente standardizzato) e poi mappiamo questi campioni indietro allo spazio originale dei dati. Questo aiuta a evitare problemi di convergenza che possono sorgere quando il posteriori dei parametri ha forme non gaussiane o quando i dati presentano varianza su scale diverse.\n\n\n71.3.2 Come si Realizza la Non-Centered Parameterization?\nNel contesto del modello di regressione bivariato, la NCP può essere implementata introducendo parametri ausiliari che trasformano i parametri del modello in uno spazio con prior standardizzati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"howell_ncp_model.stan\")\nmodel_ncp = CmdStanModel(stan_file=stan_file)\nprint(model_ncp.code())\n\ndata {\n  int&lt;lower=0&gt; N; // numero di osservazioni\n  vector[N] x; // pesi (differenze dalla media)\n  vector[N] y; // altezze\n}\nparameters {\n  real alpha_tilde; // parametro ausiliario per l'intercetta\n  real beta_tilde; // parametro ausiliario per il coefficiente di regressione\n  real&lt;lower=0&gt; sigma; // deviazione standard dell'errore\n}\ntransformed parameters {\n  real alpha; // intercetta\n  real beta; // coefficiente di regressione\n  \n  // Trasformazioni per ottenere i parametri nella scala dei dati grezzi\n  alpha = 154 + 10 * alpha_tilde;\n  beta = 0 + 5 * beta_tilde;\n}\nmodel {\n  // Priors standardizzati per i parametri ausiliari\n  alpha_tilde ~ normal(0, 1); // prior standardizzato per alpha_tilde\n  beta_tilde ~ normal(0, 1); // prior standardizzato per beta_tilde\n  sigma ~ cauchy(0, 5); // prior per la deviazione standard\n  \n  // Likelihood sulla scala dei dati grezzi\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nIn questo modello NCP:\n\nParametri Ausiliari Standardizzati:\n\nalpha_tilde ~ normal(0, 1) significa che \\(\\alpha\\_tilde\\) è campionato da una distribuzione normale standardizzata con media 0 e deviazione standard 1.\nbeta_tilde ~ normal(0, 1) significa che \\(\\beta\\_tilde\\) è campionato da una distribuzione normale standardizzata con media 0 e deviazione standard 1.\n\nTrasformazioni per Ottenere \\(\\alpha\\) e \\(\\beta\\) sulla Scala dei Dati Grezzi:\n\n\\(\\alpha\\): viene trasformato utilizzando il prior originale \\(N(154, 10)\\). Qui, \\(\\alpha = 154 + 10 \\cdot \\alpha_{\\text{tilde}}\\). Questo riproduce esattamente il prior \\(N(154, 10)\\) perché: \\[\n\\alpha \\sim 154 + 10 \\cdot N(0, 1) \\equiv N(154, 10).\n\\]\n\\(\\beta\\): viene trasformato utilizzando il prior originale \\(N(0, 5)\\). Qui, \\(\\beta = 0 + 5 \\cdot \\beta_{\\text{tilde}}\\). Questo riproduce esattamente il prior \\(N(0, 5)\\) perché: \\[\n\\beta \\sim 0 + 5 \\cdot N(0, 1) \\equiv N(0, 5).\n\\]\n\n\nEseguiamo il campionamento.\n\nfit_ncp = model_ncp.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit_ncp, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n154.594\n0.275\n154.084\n155.108\n0.003\n0.002\n9429.0\n5648.0\n1.0\n\n\nbeta\n0.905\n0.042\n0.826\n0.985\n0.000\n0.000\n10014.0\n6195.0\n1.0\n\n\nsigma\n5.099\n0.191\n4.742\n5.451\n0.002\n0.001\n8848.0\n6357.0\n1.0\n\n\n\n\n\n\n\nSi noti che le statistiche riassuntive delle distribuzioni a posteriori dei parametri riproducono i risultati trovati in precedenza con la parametrizzazione “centered”.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Non-Centered Parameterization</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_non_centered_param.html#considerazioni-conclusive",
    "href": "chapters/linear_models/02_non_centered_param.html#considerazioni-conclusive",
    "title": "71  Non-Centered Parameterization",
    "section": "71.4 Considerazioni Conclusive",
    "text": "71.4 Considerazioni Conclusive\nLa NCP può migliorare la convergenza e l’efficienza del campionamento, specialmente in modelli con forti correlazioni tra i parametri o quando i dati presentano diverse scale. In questo caso specifico, applicare la NCP non è cruciale a causa della relativa semplicità del modello, ma è comunque una buona pratica da imparare e applicare, specialmente in contesti più complessi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Non-Centered Parameterization</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/02_non_centered_param.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/02_non_centered_param.html#informazioni-sullambiente-di-sviluppo",
    "title": "71  Non-Centered Parameterization",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Mon Sep 16 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nstatsmodels: 0.14.2\nmatplotlib : 3.9.1\ncmdstanpy  : 1.2.4\nnumpy      : 1.26.4\npingouin   : 0.5.4\nseaborn    : 0.13.2\npandas     : 2.2.2\narviz      : 0.18.0\nlogging    : 0.5.1.2\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNicenboim, B., Schad, D., & Vasishth, S. (2024). An introduction to Bayesian data analysis for cognitive science. Chapman and Hall/CRC.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>Non-Centered Parameterization</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_beauty_sex_power.html",
    "href": "chapters/linear_models/03_beauty_sex_power.html",
    "title": "72  Bellezza, sesso e potere",
    "section": "",
    "text": "Introduzione\nGelman & Weakliem (2009) discutono le difficoltà statistiche che emergono nell’analizzare piccoli campioni di dati. Uno degli studi che esaminano è quello di Kanazawa (2007), in cui l’autore propone che i genitori con tratti ereditari che aumentano il successo riproduttivo maschile più di quello femminile in un dato ambiente avranno una proporzione di figli maschi superiore al previsto. Al contrario, i genitori con tratti ereditari che favoriscono maggiormente il successo riproduttivo femminile rispetto a quello maschile avranno una proporzione di figlie superiore al previsto. Kanazawa identifica l’attrattività fisica come un tratto ereditario che aumenta significativamente il successo riproduttivo delle figlie più di quello dei figli. Pertanto, prevede che i genitori fisicamente attraenti avranno una proporzione di figlie superiore al previsto. Inoltre, se l’attrattività è ereditaria e i genitori attraenti hanno più figlie, nel corso dell’evoluzione le donne dovrebbero diventare gradualmente più attraenti degli uomini. Secondo Kanazawa (2007), l’analisi dei dati della National Longitudinal Study of Adolescent Health (Add Health) conferma entrambe queste ipotesi: gli individui molto attraenti hanno il 26% di probabilità in meno di avere un figlio maschio, e le donne risultano significativamente più attraenti degli uomini nel campione rappresentativo americano.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_beauty_sex_power.html#lo-studio-di-kanazawa2007beautiful",
    "href": "chapters/linear_models/03_beauty_sex_power.html#lo-studio-di-kanazawa2007beautiful",
    "title": "72  Bellezza, sesso e potere",
    "section": "72.1 Lo Studio di @Kanazawa (2007)",
    "text": "72.1 Lo Studio di @Kanazawa (2007)\nL’attrattività è stata misurata su una scala da 1 a 5 (“molto poco attraente” a “molto attraente”). Gelman & Weakliem (2009) si concentrano su questo risultato riportato da Kanazawa (2007):\n\nIf I dichotomize the respondents into those who are rated ‘‘very attractive’’ and everyone else, the difference in the proportion of sons between the two groups (0.52 vs. 0.44) is statistically significant (t = 2.44, p \\(\\geq\\) 0.05). There appears to be something qualitatively different about respondents rated “very attractive”.\n\nIn altre parole:\n\nil 56% dei figli di genitori nella categoria 5 erano femmine;\nil 48% dei figli di genitori nelle categorie da 1 a 4 erano femmine.\n\nQuesto risultato risulta ‘statisticamente significativo’.\nGelman & Weakliem (2009) fanno notare come la dicotomizzazione proposta da Kanazawa (2007) sia arbitraria. La variabile indipendente ha 5 livelli e sono possibili quattro confronti tra i livelli. Kanazawa (2007) ha scelto arbitariamente uno di questi confronti.\nÈ dunque più naturale esaminare tutti i dati mediante un modello di regressione. I dati sono i seguenti:\n\nx = np.arange(-2, 3, 1)\ny = np.array([50, 44, 50, 47, 56])\nsexratio = pd.DataFrame({\"x\": x, \"y\": y})\nsexratio\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-2\n50\n\n\n1\n-1\n44\n\n\n2\n0\n50\n\n\n3\n1\n47\n\n\n4\n2\n56\n\n\n\n\n\n\n\nPer comodità, le cinque categorie della \\(X\\) sono state ricodificate in modo tale che la categoria centrale abbia valore 0.\n\n# Calcolo dei prior Bayesiani\ntheta_hat_prior = 0\nse_prior = 0.25\ntheta_hat_data = 8\nse_data = 3\ntheta_hat_bayes = (theta_hat_prior / se_prior**2 + theta_hat_data / se_data**2) / (\n    1 / se_prior**2 + 1 / se_data**2\n)\nse_bayes = np.sqrt(1 / (1 / se_prior**2 + 1 / se_data**2))\n\n\n# Regressione lineare con Pingouin\nfm = pg.linear_regression(sexratio[[\"x\"]], sexratio[\"y\"])\nfm.round(4)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n49.4\n1.9442\n25.4086\n0.0001\n0.2841\n0.0455\n43.2126\n55.5874\n\n\n1\nx\n1.5\n1.3748\n1.0911\n0.3550\n0.2841\n0.0455\n-2.8751\n5.8751\n\n\n\n\n\n\n\n\n# Plot dei dati e della linea di regressione\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(x, y, \"o\", markersize=5)\nplt.ylim(43, 57)\nplt.xlabel(\"Attractiveness of parent\")\nplt.ylabel(\"Percentage of girl babies\")\nplt.title(\"Data on beauty and sex ratio\")\nplt.yticks([45, 50, 55], [f\"{i}%\" for i in [45, 50, 55]])\n\nplt.subplot(1, 2, 2)\nplt.plot(x, y, \"o\", markersize=5)\nplt.ylim(43, 57)\nplt.xlabel(\"Attractiveness of parent\")\nplt.ylabel(\"Percentage of girl babies\")\nplt.title(\"Data and least-squares regression line\")\nplt.yticks([45, 50, 55], [f\"{i}%\" for i in [45, 50, 55]])\nslope, intercept = fm[\"coef\"].values[1], fm[\"coef\"].values[0]\nplt.plot(x, intercept + slope * x, \"-\")\nplt.text(\n    1,\n    52.2,\n    f\"y = {intercept:.1f} + {slope:.1f} x\\n(Std err of slope is {fm['se'].values[1]:.1f})\",\n)\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_32471/3465279703.py:27: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_beauty_sex_power.html#analisi-bayesiana-con-prior-non-informativi",
    "href": "chapters/linear_models/03_beauty_sex_power.html#analisi-bayesiana-con-prior-non-informativi",
    "title": "72  Bellezza, sesso e potere",
    "section": "72.2 Analisi Bayesiana con Prior Non Informativi",
    "text": "72.2 Analisi Bayesiana con Prior Non Informativi\nMediante l’utilizzo di prior non informativi ci possiamo aspettare che l’analisi bayesisana sostanzialmente replichi il risultato dell’analisi frequentista.\nSistemiamo i dati nel formato richiesto da Stan.\n\nstan_data = {\"N\": len(sexratio), \"x\": sexratio[\"x\"].values, \"y\": sexratio[\"y\"].values}\nstan_data\n\n{'N': 5, 'x': array([-2, -1,  0,  1,  2]), 'y': array([50, 44, 50, 47, 56])}\n\n\nFormuliamo il modello di regressione bivariata utilizzando prior non informativi.\n\nstan_file = os.path.join(project_directory, 'stan', 'sex_ratio.stan')\nmodel1 = CmdStanModel(stan_file=stan_file)\nprint(model1.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nEseguiamo il campionamento MCMC.\n\nfit1 = model1.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit1, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n49.512\n6.228\n39.278\n58.560\n0.103\n0.081\n3384.0\n1640.0\n1.0\n\n\nbeta\n1.543\n4.567\n-5.028\n8.927\n0.088\n0.104\n3851.0\n1381.0\n1.0\n\n\nsigma\n9.406\n10.183\n2.109\n22.019\n0.357\n0.252\n912.0\n1188.0\n1.0\n\n\n\n\n\n\n\nLa soluzione ottenuta replica quella del metodo dei minimi quadrati. In entrambi i casi, sia l’intervallo di confidenza che l’intervallo credibile includono lo zero, il che indica che l’attrattività dei genitori non sembra avere un effetto credibile sulla proporzione di nascite femminili. Tuttavia, nonostante la notevole incertezza, l’analisi mostra che il coefficiente \\(\\beta\\) è positivo e pari a 1.5.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_beauty_sex_power.html#analisi-bayesiana-con-prior-debolmente-informativi",
    "href": "chapters/linear_models/03_beauty_sex_power.html#analisi-bayesiana-con-prior-debolmente-informativi",
    "title": "72  Bellezza, sesso e potere",
    "section": "72.3 Analisi Bayesiana con Prior Debolmente Informativi",
    "text": "72.3 Analisi Bayesiana con Prior Debolmente Informativi\nGelman & Weakliem (2009) propongono l’uso di prior debolmente informativi nel contesto di un’analisi sulla relazione tra l’attrattività dei genitori e la percentuale di nascite femminili. Questi prior sono basati su informazioni precedenti e su ipotesi ragionevoli relative al problema studiato. Ecco come vengono definiti i due principali coefficienti del modello di regressione:\n\nIntercetta (a):\n\nLa variabile intercetta rappresenta la percentuale di nascite femminili quando l’attrattività dei genitori è nella media.\nGelman & Weakliem (2009) utilizzano una distribuzione normale centrata a 48.8 con una deviazione standard di 0.5. Questo indica che, sulla base dei dati esistenti, ci si aspetta che la percentuale di nascite femminili per genitori con attrattività media sia circa il 48.8%, con un margine di variazione di ±0.5%. Questo valore è scelto perché, in generale, la percentuale di nascite femminili è stabile tra il 48.5% e il 49%.\n\nCoefficiente angolare (b):\n\nIl coefficiente angolare rappresenta l’effetto dell’attrattività dei genitori sulla percentuale di nascite femminili.\nGelman & Weakliem (2009) scelgono una distribuzione normale centrata a 0 con una deviazione standard di 0.2. Questo riflette l’assenza di una forte convinzione a priori che l’attrattività sia correlata in modo robusto con il sesso del neonato. Il valore della deviazione standard di 0.2 indica che ci si aspetta che il coefficiente possa variare tra -0.2 e 0.2. Dato che la variabile predittiva (l’attrattività) ha un intervallo di 4 punti, questa scelta implica che l’effetto massimo atteso dell’attrattività sulla percentuale di nascite femminili sia di ±0.8 punti percentuali, confrontando la categoria di attrattività più alta con quella più bassa.\n\n\nQuesti prior debolmente informativi aiutano a guidare l’analisi, integrando l’informazione che la percentuale di nascite femminili è molto stabile e suggerendo che, se c’è un effetto dell’attrattività, esso è probabile che sia piuttosto piccolo.\nCompiliamo e stampiamo il modello che include i prior debolmente informativi.\n\nstan_file_ip = os.path.join(project_directory, \"stan\", \"sex_ratio_informative_prior.stan\")\nmodel2 = CmdStanModel(stan_file=stan_file_ip)\nprint(model2.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  alpha ~ normal(48.8, 0.5);\n  beta ~ normal(0, 0.2);\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nEseguiamo il campionamento.\n\nfit2 = model2.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo le distribuzioni a posteriori.\n\naz.summary(fit2, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n48.828\n0.487\n47.879\n49.715\n0.006\n0.004\n6402.0\n5373.0\n1.0\n\n\nbeta\n0.028\n0.201\n-0.352\n0.395\n0.002\n0.002\n7334.0\n5464.0\n1.0\n\n\nsigma\n5.696\n3.290\n2.294\n10.366\n0.060\n0.049\n6248.0\n3964.0\n1.0\n\n\n\n\n\n\n\nSi osserva che, quando vengono utilizzati prior debolmente informativi, l’effetto dell’attrattività dei genitori risulta sostanzialmente nullo.\nI due grafici seguenti mostrano la variabilità della retta di regressione stimata dal modello bayesiano sia con prior non informativi che con prior informativi. Nel caso di prior non informativi, nonostante l’ampia variabilità nella stima della pendenza della retta di regressione, emerge una lieve coerenza che suggerisce una relazione positiva molto debole. Al contrario, con prior debolmente informativi, la pendenza della retta di regressione stimata dal modello bayesiano risulta chiaramente piatta, eliminando qualsiasi incertezza.\n\n# Analisi dei risultati\nfit_bayes = [fit1, fit2]\n\nfor k, fit in enumerate(fit_bayes):\n    sims = fit.draws_pd()\n    coef_est = sims.median()\n    b_se = 1.483 * np.median(np.abs(sims[\"beta\"] - coef_est[\"beta\"]))\n\n    plt.figure(figsize=(10, 5))\n\n    # Plot delle simulazioni posteriori\n    plt.subplot(1, 2, 1)\n    plt.plot(sims[\"alpha\"], sims[\"beta\"], \"o\", markersize=2)\n    plt.xlabel(\"Intercept, a\")\n    plt.ylabel(\"Slope, b\")\n    plt.title(\n        f\"Posterior simulations under {'default prior' if k == 0 else 'informative prior'}\"\n    )\n\n    # Plot dei dati grezzi e della linea di regressione\n    plt.subplot(1, 2, 2)\n    plt.plot(x, y, \"o\", color=\"blue\", markersize=5)  \n    plt.ylim(43, 57)\n    plt.xlabel(\"Attractiveness of parent\")\n    plt.ylabel(\"Percentage of girl babies\")\n    plt.title(\n        f\"{'Least-squares regression line and\\nposterior uncertainty given default prior' if k == 0 else 'Bayes estimated regression line and\\nposterior uncertainty given informative prior'}\"\n    )\n    plt.yticks([45, 50, 55], [f\"{i}%\" for i in [45, 50, 55]])\n\n    # Aggiunta delle linee di regressione dai campioni posteriori\n    for i in range(100):\n        plt.plot(\n            x, sims[\"alpha\"].iloc[i] + sims[\"beta\"].iloc[i] * x, color=\"gray\", lw=0.5\n        )\n\n    # Linea di regressione basata sui valori mediani stimati\n    plt.plot(x, coef_est[\"alpha\"] + coef_est[\"beta\"] * x, color=\"black\", lw=2)\n\n    plt.tight_layout()\n    plt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_32471/2498333150.py:40: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_32471/2498333150.py:40: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_beauty_sex_power.html#considerazioni-conclusive",
    "href": "chapters/linear_models/03_beauty_sex_power.html#considerazioni-conclusive",
    "title": "72  Bellezza, sesso e potere",
    "section": "72.4 Considerazioni Conclusive",
    "text": "72.4 Considerazioni Conclusive\nL’analisi delle relazioni tra bellezza e proporzione di nascite femminili nei campioni di piccole dimensioni mette in luce l’importanza di considerare la potenza statistica e l’uso di prior informativi nei modelli statistici. In studi con campioni ridotti, c’è un rischio notevole di ottenere risultati che, pur sembrando indicativi di un effetto, sono in realtà frutto del caso e non rappresentano una realtà sottostante. Questo fenomeno è reso più insidioso dall’attuale pratiche delle pubblicazioni scientifiche che molto spesso selezionano gli studi da pubblicare solo sulla presenza di effetti “statisticamente significativi”, e che tendono a favorire e amplificare risultati che sembrano innovativi o controintuitivi, anche quando questi risultati non sono supportati da solide evidenze statistiche.\nGelman & Weakliem (2009) sottolineano che l’uso di prior debolmente informativi, come illustrato nel presente modello bayesiano, rappresenta un approccio metodologico che può aiutare a contrastare queste problematiche. Ad esempio, quando vengono applicati prior debolmente informativi, l’effetto dell’attrattività dei genitori sulla proporzione di nascite femminili emerge come sostanzialmente nullo, evidenziando come l’apparente effetto osservato in modelli meno rigorosi possa essere semplicemente un artefatto dovuto a fluttuazioni casuali. Questo non solo rende più chiaro il vero segnale presente nei dati, ma aiuta anche a prevenire l’interpretazione errata dei risultati.\nInoltre, Gelman & Weakliem (2009) mettono in evidenza come le limitazioni legate alla potenza statistica siano spesso ignorate nella pratica di ricerca, portando a stime degli effetti sovrastimate, specialmente in studi con campioni piccoli – si veda il Capitolo 119. Questo problema è accentuato dalla tendenza della comunità scientifica a privilegiare risultati sensazionali, che possono far emergere ipotesi infondate come verità accettate. L’esempio del rapporto tra bellezza e sex-ratio mostra come questi errori possano condurre a una distorsione della conoscenza scientifica, con conseguenze che vanno ben oltre l’ambito accademico.\nPer contrastare questi problemi, è essenziale promuovere una maggiore trasparenza nel processo di revisione e pubblicazione scientifica, così come un uso più diffuso di metodi statistici che incorporino la conoscenza a priori e considerino la potenza statistica in tutte le fasi del processo di ricerca. Solo attraverso un approccio più rigoroso e critico possiamo sperare di ridurre la diffusione di affermazioni infondate e migliorare la qualità complessiva della ricerca in psicologia e nelle scienze sociali. In questo contesto, l’adozione di modelli bayesiani con priori informativi rappresenta un passo avanti importante, permettendo ai ricercatori di evitare trappole comuni e di fornire risultati che riflettono più accuratamente la realtà dei fenomeni studiati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/03_beauty_sex_power.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/03_beauty_sex_power.html#informazioni-sullambiente-di-sviluppo",
    "title": "72  Bellezza, sesso e potere",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\narviz     : 0.18.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\nlogging   : 0.5.1.2\npingouin  : 0.5.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power: Too little attention has been paid to the statistical challenges in estimating small effects. American Scientist, 97(4), 310–316.\n\n\nKanazawa, S. (2007). Beautiful parents have more daughters: A further implication of the generalized Trivers–Willard hypothesis (gTWH). Journal of Theoretical Biology, 244(1), 133–140.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>Bellezza, sesso e potere</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html",
    "href": "chapters/linear_models/04_synt_sugar.html",
    "title": "73  Zucchero sintattico",
    "section": "",
    "text": "73.1 Introduzione\nI modelli lineari sono così ampiamente utilizzati che sono stati sviluppati appositamente una sintassi, dei metodi e delle librerie per la regressione. Una di queste librerie è bambi (BAyesian Model-Building Interface). bambi è un pacchetto Python progettato per adattare modelli gerarchici generalizzati lineari (di cui il modello lineare bivariato è un caso particolare), utilizzando una sintassi simile a quella presente nei pacchetti R, come lme4, nlme, rstanarm o brms. bambi si basa su PyMC, ma offre un’API di livello superiore.\nIn questo capitolo esploreremo come condurre un’analisi di regressione utilizzando bambi invece di cmdstan.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#bayesian-model-building-interface",
    "href": "chapters/linear_models/04_synt_sugar.html#bayesian-model-building-interface",
    "title": "73  Zucchero sintattico",
    "section": "73.2 BAyesian Model-Building Interface",
    "text": "73.2 BAyesian Model-Building Interface\nLeggiamo i dati utilizzati nel capitolo precedente.\n\ndata_file = os.path.join(project_directory, \"data\", \"Howell_18.csv\")\ndf = pd.read_csv(data_file)\n\nGeneriamo un diagramma a dispersione:\n\nplt.plot(df[\"weight\"], df[\"height\"], \"x\")\nplt.xlabel(\"Weight\")\nplt.ylabel(\"Height\")\n\nText(0, 0.5, 'Height')\n\n\n\n\n\n\n\n\n\nBambi si concentra sui modelli di regressione, e questa specializzazione permette di adottare una sintassi più semplice, conosciuta come sintassi di Wilkinson (Wilkinson & Rogers, 1973).\nAd esempio, il modello \\(y = \\alpha + \\beta x + \\varepsilon\\) si implementa come segue:\na_model = bmb.Model(\"y ∼ x\", data)\nNella sintassi di Wilkinson, il simbolo tilde (∼) separa la variabile dipendente (a sinistra) dalle variabili indipendenti (a destra). In questo caso, stiamo specificando solo la media (\\(\\mu\\) nel modello lm di PyMC). Bambi assume di default che la distribuzione di verosimiglianza sia gaussiana, ma è possibile modificarla tramite l’argomento family.\nSe desideriaamo escludere l’intercetta dal modello, possiamo farlo in questo modo:\nno_intercept_model = bmb.Model(\"y ∼ 0 + x\", data)\nOppure in questo modo:\nno_intercept_model = bmb.Model(\"y ∼ -1 + x\", data)\nPer includere ulteriori variabili nel modello, possiamo procedere così:\nmodel_2 = bmb.Model(\"y ∼ x + z\", data)\nBambi consente anche di includere effetti a livello di gruppo (gerarchici). Ad esempio, se desideriamo un modello ad effetti misti nel quale abbiamo un effetto diverso di \\(x\\) in ciascun gruppo g, possiamo usare la seguente sintassi:\nmodel_h = bmb.Model(\"y ∼ x + z + (x | g)\", data)\nLa sintassi delle formule non specifica le distribuzioni a priori, ma solo come le variabili dipendenti e indipendenti sono collegate. Bambi definirà automaticamente delle distribuzioni a priori debolmente informative per noi.\nInoltre, Bambi implementa di default delle distribuzioni a priori debolmente informative, rendendo superflua la loro definizione esplicita. Tuttavia, se preferisci avere un maggiore controllo, possiamo specificarle manualmente.\nPer replicare il modello descritto nel capitolo precedente, possiamo utilizzare la seguente istruzione:\n\ndf[\"weight_c\"] = df[\"weight\"] - np.mean(df[\"weight\"])\n\nmodel = bmb.Model(\"height ~ weight_c\", df)\n\nSul lato sinistro della tilde (∼), abbiamo la variabile dipendente, e sul lato destro, le variabili indipendenti. Con questa sintassi, stiamo semplicemente specificando la media (μ nel modello lm di PyMC). Per impostazione predefinita, Bambi assume che la verosimiglianza sia gaussiana; è possibile modificarla con l’argomento family. La sintassi della formula non specifica la distribuzione delle priors, ma solo come sono associate le variabili dipendenti e indipendenti. Bambi definirà automaticamente delle priors (molto) debolmente informative per noi. Possiamo ottenere ulteriori informazioni stampando il modello Bambi.\n\nprint(model)\n\n       Formula: height ~ weight_c\n        Family: gaussian\n          Link: mu = identity\n  Observations: 352\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 154.5971, sigma: 19.3283)\n            weight_c ~ Normal(mu: 0.0, sigma: 2.9978)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 7.7313)\n\n\nLa descrizione inizia mostrando la formula utilizzata per definire il modello, y ~ x, che indica come la variabile dipendente y è predetta dalla variabile indipendente x in una relazione lineare. La seconda riga specifica che si sta utilizzando una distribuzione gaussiana (normale) come funzione di verosimiglianza per il modello, il che implica l’assunzione che i residui del modello (le differenze tra i valori osservati e i valori predetti) seguano una distribuzione normale.\nLa terza riga menziona la funzione di collegamento, in questo caso l’identità, che non applica alcuna trasformazione al valore atteso della variabile dipendente. Questo è caratteristico dei modelli lineari, dove il valore atteso di y è direttamente modellato come una combinazione lineare delle variabili indipendenti (E(Y) = \\alpha + \\beta x). È importante notare che, nei modelli lineari generalizzati, la funzione di collegamento gioca un ruolo cruciale nel collegare il valore atteso della variabile risposta alla combinazione lineare delle variabili predittive.\nSegue il numero di osservazioni utilizzate per adattare il modello, indicando la dimensione del dataset su cui il modello è stato allenato.\nLa parte successiva dell’output dettaglia i priors utilizzati per i parametri del modello. In Bambi, i priors sono assunzioni a priori sui valori dei parametri prima di osservare i dati. Questi priors aiutano a guidare l’inferenza, soprattutto in presenza di dati limitati o per regolarizzare il modello. L’intercetta (Intercept) ha un prior normale con media (mu) 2.0759 e deviazione standard (sigma) 3.9401, indicando la posizione iniziale attesa della linea di regressione e quanto ci si aspetta che vari. Il coefficiente della variabile x ha anch’esso un prior normale, centrato in zero con una deviazione standard ampia (6.8159), riflettendo incertezza su quale possa essere il vero effetto di x su y senza presupporre una direzione specifica dell’effetto.\nLa sezione finale riguarda i parametri ausiliari del modello, in questo caso il parametro sigma della distribuzione gaussiana, che rappresenta la deviazione standard dei residui del modello. Questo ha un prior HalfStudentT, che è una distribuzione che ammette solo valori positivi (essendo la deviazione standard sempre positiva), con un grado di libertà (nu) 4.0 e una scala (sigma) 0.791. Questo prior è scelto per la sua flessibilità e la capacità di gestire dati con potenziali outlier.\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nSe vogliamo procedere con un’ispezione visiva dei prior dei parametri del modello usiamo:\n\n_ = model.plot_priors()\n\nSampling: [Intercept, sigma, weight_c]\n\n\n\n\n\n\n\n\n\nEseguiamo il campionamento MCMC.\n\nidata = model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\nLe distribuzioni a posteriori dei parametri e i trace plot si ottengono con la seguente istruzione.\n\n_ = az.plot_trace(idata)\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(idata, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n154.59\n0.27\n154.07\n155.07\n0.0\n0.0\n4100.84\n2810.35\n1.0\n\n\nsigma\n5.11\n0.20\n4.74\n5.46\n0.0\n0.0\n4391.39\n2834.61\n1.0\n\n\nweight_c\n0.90\n0.04\n0.82\n0.98\n0.0\n0.0\n4522.69\n3091.93\n1.0\n\n\n\n\n\n\n\nI dati replicano quelli ottenuti in precedenza.\nPossiamo anche generare un grafico che descrive l’incertezza a posteriori delle predizioni del modello.\nLa funzione plot_predictions del pacchetto Bambi serve per facilitare l’interpretazione dei modelli di regressione attraverso la visualizzazione grafica. Il metodo appartiene al sottomodulo interpret di Bambi e si concentra sulla rappresentazione delle previsioni generate dal modello.\nQuando si esegue la funzione plot_predictions con i parametri specificati (model, idata, [\"weight_c\"]), essa produce un grafico che sintetizza le previsioni del modello in relazione a una o più variabili indipendenti. In questo caso, il parametro model indica il modello di regressione Bayesiana costruito con Bambi, idata rappresenta i dati inferenziali (ottenuti tramite il fit del modello), e [\"weight_c\"] specifica la variabile indipendente da considerare per il grafico.\n\nbmb.interpret.plot_predictions(model, idata, [\"weight_c\"]);\n\nDefault computed for conditional variable: weight_c\n\n\n\n\n\n\n\n\n\nIl grafico generato da questa funzione illustra due aspetti principali:\n\nMedia Posteriore di y: Il grafico include una linea che rappresenta la media posteriore della variabile dipendente (height) rispetto alla variabile indipendente specificata (weight_c). La media posteriore è una stima centrale delle previsioni del modello, che riflette la posizione più probabile dei valori di height data l’evidenza fornita dai dati.\nIntervallo di Densità più Alta del 94%: Attorno alla retta della media posteriore, il grafico mostra anche un’area evidenziata che rappresenta l’intervallo di densità più alta (HDI) del 94%. Questo intervallo è un modo per quantificare l’incertezza delle previsioni del modello. L’HDI del 94% significa che, data la distribuzione posteriore delle previsioni di height, c’è il 94% di probabilità che il valore vero di height cada all’interno di questo intervallo per un dato valore di weight_c. Questo fornisce una misura visiva dell’incertezza associata alle stime del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/04_synt_sugar.html#informazioni-sullambiente-di-sviluppo",
    "title": "73  Zucchero sintattico",
    "section": "73.3 Informazioni sull’Ambiente di Sviluppo",
    "text": "73.3 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Aug 14 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\ncmdstanpy : 1.2.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\npandas    : 2.2.2\nnumpy     : 1.26.4\nlogging   : 0.5.1.2\nbambi     : 0.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of factorial models for analysis of variance. Journal of the Royal Statistical Society Series C: Applied Statistics, 22(3), 392–399.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>Zucchero sintattico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_two_means.html",
    "href": "chapters/linear_models/05_two_means.html",
    "title": "74  Confronto tra le medie di due gruppi",
    "section": "",
    "text": "Introduzione\nNel Capitolo 60, abbiamo discusso l’inferenza sulla differenza tra le medie di due campioni indipendenti utilizzando un approccio bayesiano. In quell’analisi, i due gruppi sono stati considerati entità distinte e abbiamo calcolato la differenza tra le loro medie.\nUn’alternativa consiste nell’uso di un modello di regressione. In questo caso, invece di calcolare direttamente la differenza tra le medie, si introduce una variabile indicatrice (“dummy”) nel modello di regressione. La variabile indicatrice codifica l’appartenenza ai gruppi con valori binari: 0 per il gruppo di riferimento e 1 per il gruppo di confronto:\n\\[\nx_i =\n\\begin{cases}\n0 & \\text{se l'osservazione } i \\text{ è nel gruppo 0} \\\\\n1 & \\text{se l'osservazione } i \\text{ è nel gruppo 1}\n\\end{cases}\n\\]\nIl modello di regressione stima un coefficiente per la variabile indicatrice, che rappresenta la differenza tra le medie dei due gruppi. In questo modo, la variabile “dummy” funge da indicatore del gruppo, permettendo di stimare in modo efficiente la differenza tra le medie.\nEntrambi i metodi sono validi per analizzare la differenza tra le medie di due gruppi indipendenti; tuttavia, il modello di regressione offre maggiore flessibilità e potenzialità di espansione. Questo modello permette di includere ulteriori variabili esplicative, ampliando la nostra capacità di comprendere i fattori che influenzano il risultato d’interesse. Tale versatilità è particolarmente vantaggiosa per esaminare come altre variabili possano influire sulla differenza tra le medie o per analizzare più variabili contemporaneamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "href": "chapters/linear_models/05_two_means.html#regressione-bayesiana-per-due-gruppi-indipendenti",
    "title": "74  Confronto tra le medie di due gruppi",
    "section": "74.1 Regressione bayesiana per due gruppi indipendenti",
    "text": "74.1 Regressione bayesiana per due gruppi indipendenti\nNel contesto bayesiano, il modello di regressione può essere formulato nel modo seguente:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta x_i.\n\\end{align*}\n\\]\nIn questa rappresentazione:\n\n\\(\\alpha\\) agisce come intercetta,\n\\(\\beta\\) è il coefficiente angolare o la pendenza,\n\\(\\sigma\\) è l’errore standard associato alle osservazioni.\n\nNel caso specifico, la variabile \\(x\\) è una variabile indicatrice che assume i valori 0 o 1. Per il gruppo identificato da \\(x = 0\\), il modello si riduce a:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha.\n\\end{align*}\n\\]\nQuesto implica che \\(\\alpha\\) rappresenta la media del gruppo codificato come \\(x = 0\\).\nPer il gruppo contrassegnato da \\(x = 1\\), il modello diventa:\n\\[\n\\begin{align*}\ny_i & \\sim \\mathcal{N}(\\mu_i, \\sigma), \\\\\n\\mu_i & = \\alpha + \\beta.\n\\end{align*}\n\\]\nIn termini dei parametri del modello, la media per il gruppo codificato con \\(x = 1\\) è rappresentata da \\(\\alpha + \\beta\\). In questa configurazione, \\(\\beta\\) indica la differenza tra la media del gruppo con $ x = 1 $ e quella del gruppo con \\(x = 0\\). Di conseguenza, l’analisi della differenza tra le medie dei due gruppi può essere effettuata attraverso l’inferenza sul parametro \\(\\beta\\). In sintesi, per confrontare le medie dei due gruppi indipendenti, si può esaminare la distribuzione a posteriori di \\(\\beta\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_two_means.html#un-esempio-illustrativo",
    "href": "chapters/linear_models/05_two_means.html#un-esempio-illustrativo",
    "title": "74  Confronto tra le medie di due gruppi",
    "section": "74.2 Un esempio illustrativo",
    "text": "74.2 Un esempio illustrativo\nEsaminiamo nuovamente i dati relativi al quoziente di intelligenza dei bambini le cui madri hanno completato oppure no la scuola superiore. Ci poniamo il problema di replicare i risultati ottenuti in precedenza usando l’analisi di regressione.\nLeggiamo i dati:\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\n\nkidiq.groupby([\"mom_hs\"]).size()\n\nmom_hs\n0.0     93\n1.0    341\ndtype: int64\n\n\nCi sono 93 bambini la cui madre non ha completato le superiori e 341 bambini la cui madre ha ottenuto il diploma di scuola superiore.\n\nsummary_stats = [st.mean, st.stdev]\nkidiq.groupby([\"mom_hs\"]).aggregate(summary_stats)\n\n\n\n\n\n\n\n\nkid_score\nmom_iq\nmom_work\nmom_age\n\n\n\nmean\nstdev\nmean\nstdev\nmean\nstdev\nmean\nstdev\n\n\nmom_hs\n\n\n\n\n\n\n\n\n\n\n\n\n0.0\n77.548387\n22.573800\n91.889152\n12.630498\n2.322581\n1.226175\n21.677419\n2.727323\n\n\n1.0\n89.319648\n19.049483\n102.212049\n14.848414\n3.052786\n1.120727\n23.087977\n2.617453\n\n\n\n\n\n\n\n\naz.plot_violin(\n    {\n        \"mom_hs=0\": kidiq.loc[kidiq.mom_hs == 0, \"kid_score\"],\n        \"mom_hs=1\": kidiq.loc[kidiq.mom_hs == 1, \"kid_score\"],\n    }\n);\n\n\n\n\n\n\n\n\nIniziamo l’inferenza statistica sulla differenza tra le medie dei due gruppi utilizzando bambi. Questo pacchetto offre una sintassi semplice per formulare il modello bayesiano di interesse. Un altro vantaggio è che bambi selezionerà automaticamente le distribuzioni a priori appropriate per i parametri del modello, rendendo il processo più intuitivo.\nIl modello di regressione sopra descritto si scrive nel modo seguente.\n\nmod = bmb.Model(\"kid_score ~ mom_hs\", kidiq)\n\nEffettuiamo il campionamento.\n\nresults = mod.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nPossiamo ispezionare le proprietà del modello nel modo seguente.\n\nmod\n\n       Formula: kid_score ~ mom_hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 86.7972, sigma: 110.1032)\n            mom_hs ~ Normal(mu: 0.0, sigma: 124.2132)\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\nLe distribuzioni a priori utilizzate di default dal modello possono essere visualizzate nel modo seguente.\n\n_ = mod.plot_priors()\n\nSampling: [Intercept, mom_hs, sigma]\n\n\n\n\n\n\n\n\n\nPer ispezionare il nostro posteriore e il processo di campionamento possiamo utilizzare az.plot_trace(). L’opzione kind='rank_vlines' ci fornisce una variante del grafico di rango che utilizza linee e punti e ci aiuta a ispezionare la stazionarietà delle catene. Poiché non c’è un modello chiaro o deviazioni serie dalle linee orizzontali, possiamo concludere che le catene sono stazionarie.\n\n_ = az.plot_trace(results)\n\n\n\n\n\n\n\n\n\naz.summary(results, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n77.55\n2.01\n73.68\n81.27\n0.03\n0.02\n4272.34\n2738.90\n1.0\n\n\nmom_hs\n11.76\n2.25\n7.74\n16.17\n0.03\n0.03\n4169.77\n2921.90\n1.0\n\n\nsigma\n19.88\n0.66\n18.69\n21.12\n0.01\n0.01\n4540.09\n3039.19\n1.0\n\n\n\n\n\n\n\nIl parametro “Intercept” rappresenta la stima a posteriori del punteggio del QI per il gruppo codificato con “mom_hs” uguale a 0. La media a posteriori di questo gruppo è di 77.6, che è praticamente identica al valore campionario corrispondente.\nIl parametro “mom_hs” corrisponde alla stima a posteriori della differenza nei punteggi del QI tra il gruppo codificato con “mom_hs” uguale a 1 e il gruppo codificato con “mom_hs” uguale a 0. Anche in questo caso, la differenza a posteriori di 11.8 tra le medie dei due gruppi è molto simile alla differenza campionaria tra le medie dei due gruppi. La parte importante della tabella riguarda l’intervallo di credibilità al 94%, che è [7.5, 16.2], e che non include lo 0. Ciò significa che, con un livello di certezza soggettiva del 94%, possiamo essere sicuri che il QI dei bambini le cui madri hanno il diploma superiore sarà maggiore (in media) di almeno 7.5 punti, e tale differenza può arrivare fino a 16.2 punti, rispetto al QI dei bambini le cui madri non hanno completato la scuola superiore.\nSe confrontiamo questi risultati con quelli ottenuti nel capitolo {ref}two_groups_comparison_notebook, notiamo che sono quasi identici. Le piccole differenze che si osservano possono essere attribuite sia all’approssimazione numerica sia al fatto che nel modello precedente abbiamo consentito deviazioni standard diverse per i due gruppi, mentre nel caso attuale abbiamo assumo la stessa variabilità per entrambi i gruppi.\nUsiamo ora l’approccio di massima verosimiglianza.\n\nlm = pg.linear_regression(kidiq[\"mom_hs\"], kidiq[\"kid_score\"])\nlm.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n77.55\n2.06\n37.67\n0.0\n0.06\n0.05\n73.50\n81.59\n\n\n1\nmom_hs\n11.77\n2.32\n5.07\n0.0\n0.06\n0.05\n7.21\n16.34\n\n\n\n\n\n\n\nI risultati sono quasi identici a quelli trovati con l’approccio bayesiano.\nIl test bayesiano di ipotesi può essere svolto, per esempio, calcolando la probabilità che \\(\\beta_{mean\\_diff} &gt; 0\\). Questa probabilità è 1, per cui concludiamo che la media del gruppo codificato con “mom_hs = 1” è maggiore della media del gruppo codificato con “mom_hs = 0”.\n\naz.plot_posterior(results, var_names=\"mom_hs\", ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\nUn valore numerico si ottiene nel modo seguente.\n\nresults.posterior\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 104kB\nDimensions:    (chain: 4, draw: 1000)\nCoordinates:\n  * chain      (chain) int64 32B 0 1 2 3\n  * draw       (draw) int64 8kB 0 1 2 3 4 5 6 7 ... 993 994 995 996 997 998 999\nData variables:\n    Intercept  (chain, draw) float64 32kB 80.81 75.64 77.14 ... 77.32 77.43\n    mom_hs     (chain, draw) float64 32kB 7.963 13.55 10.86 ... 9.91 10.79 12.88\n    sigma      (chain, draw) float64 32kB 19.3 20.92 20.21 ... 19.26 19.12 20.3\nAttributes:\n    created_at:                  2024-07-30T09:47:03.975197+00:00\n    arviz_version:               0.18.0\n    inference_library:           numpyro\n    inference_library_version:   0.15.1\n    sampling_time:               1.772095\n    tuning_steps:                1000\n    modeling_interface:          bambi\n    modeling_interface_version:  0.14.0xarray.DatasetDimensions:chain: 4draw: 1000Coordinates: (2)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Data variables: (3)Intercept(chain, draw)float6480.81 75.64 77.14 ... 77.32 77.43array([[80.81483632, 75.63639888, 77.14478867, ..., 75.72595312,\n        77.5423379 , 77.5423379 ],\n       [79.368775  , 79.97070154, 75.33769344, ..., 74.13336094,\n        80.08358757, 81.84041564],\n       [78.28138375, 76.8210174 , 80.13760742, ..., 77.78397138,\n        76.51013651, 78.79410939],\n       [82.03066779, 73.96217327, 76.20589234, ..., 78.7092881 ,\n        77.31896306, 77.4298698 ]])mom_hs(chain, draw)float647.963 13.55 10.86 ... 10.79 12.88array([[ 7.96339175, 13.55420539, 10.86033092, ..., 13.62558002,\n        11.84062159, 11.84062159],\n       [ 9.35003845,  9.9135694 , 13.79285124, ..., 16.97280286,\n         8.09604384,  5.89320385],\n       [12.97640867, 10.9104082 ,  8.77804029, ..., 11.30792615,\n        12.21403645, 11.0726028 ],\n       [ 5.64421123, 16.74073888, 13.98410457, ...,  9.91029743,\n        10.78713598, 12.8766417 ]])sigma(chain, draw)float6419.3 20.92 20.21 ... 19.12 20.3array([[19.29803974, 20.92199049, 20.21123626, ..., 20.58998924,\n        20.11170957, 20.11170957],\n       [17.91763444, 20.64037291, 19.88999257, ..., 20.09847731,\n        19.51073177, 19.25492589],\n       [19.99147265, 19.78098389, 19.27150942, ..., 20.86967072,\n        19.83582888, 19.83827133],\n       [19.22442038, 20.07102966, 20.0293815 , ..., 19.26291194,\n        19.11822346, 20.29616769]])Indexes: (2)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Attributes: (8)created_at :2024-07-30T09:47:03.975197+00:00arviz_version :0.18.0inference_library :numpyroinference_library_version :0.15.1sampling_time :1.772095tuning_steps :1000modeling_interface :bambimodeling_interface_version :0.14.0\n\n\n\n# Probabiliy that posterior is &gt; 0\n(results.posterior[\"mom_hs\"] &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_two_means.html#parametrizzazione-alternativa",
    "href": "chapters/linear_models/05_two_means.html#parametrizzazione-alternativa",
    "title": "74  Confronto tra le medie di due gruppi",
    "section": "74.3 Parametrizzazione alternativa",
    "text": "74.3 Parametrizzazione alternativa\nConsideriamo adesso il caso in cui, per distinguere i gruppi, anziché una variabile dicotomica, con valori 0 e 1, usiamo una variabile qualitativa con i nomi dei due gruppi. Introduciamo questa nuova variabile nel data frame.\n\n# Add a new column 'hs' with the categories based on 'mom_hs'\nkidiq[\"hs\"] = kidiq[\"mom_hs\"].map({0: \"not_completed\", 1: \"completed\"})\nkidiq.tail()\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\nhs\n\n\n\n\n429\n94\n0.0\n84.877412\n4\n21\nnot_completed\n\n\n430\n76\n1.0\n92.990392\n4\n23\ncompleted\n\n\n431\n50\n0.0\n94.859708\n2\n24\nnot_completed\n\n\n432\n88\n1.0\n96.856624\n2\n21\ncompleted\n\n\n433\n70\n1.0\n91.253336\n2\n25\ncompleted\n\n\n\n\n\n\n\nAdattiamo il modello ai dati, usando questa nuova variabile e forziamo a zero l’intercetta che Bambi aggiunge di default al modello.\n\nmod_2 = bmb.Model(\"kid_score ~ 0 + hs\", kidiq)\nresults_2 = mod_2.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\nIspezionare il modello e le distribuzioni a priori.\n\nmod_2\n\n       Formula: kid_score ~ 0 + hs\n        Family: gaussian\n          Link: mu = identity\n  Observations: 434\n        Priors: \n    target = mu\n        Common-level effects\n            hs ~ Normal(mu: [0. 0.], sigma: [124.2132 124.2132])\n        \n        Auxiliary parameters\n            sigma ~ HalfStudentT(nu: 4.0, sigma: 20.3872)\n------\n* To see a plot of the priors call the .plot_priors() method.\n* To see a summary or plot of the posterior pass the object returned by .fit() to az.summary() or az.plot_trace()\n\n\n\n_ = mod_2.plot_priors()\n\nSampling: [hs, sigma]\n\n\n\n\n\n\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri del modello.\n\n_ = az.plot_trace(results_2)\n\n\n\n\n\n\n\n\n\naz.summary(results_2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nhs[completed]\n89.297\n1.089\n87.209\n91.231\n0.016\n0.012\n4429.0\n3149.0\n1.0\n\n\nhs[not_completed]\n77.506\n1.988\n73.744\n81.191\n0.031\n0.022\n4102.0\n2940.0\n1.0\n\n\nsigma\n19.881\n0.660\n18.647\n21.112\n0.010\n0.007\n4216.0\n2870.0\n1.0\n\n\n\n\n\n\n\nIn questo caso, notiamo che abbiamo ottenuto le distribuzioni a posteriori per i parametri hs[completed] e hs[not_completed] che corrispondono alle medie dei due gruppi. Tali distribuzioni a posteriori illustrano direttamente l’incertezza sulla media dei due gruppi, alla luce della variabilità campionaria e delle nostre credenze a priori.\nPossiamo svolgere il test bayesiano di ipotesi sulla differenza tra le due medie a posteriori nel modo seguente.\n\npost_group = results_2.posterior[\"hs\"]\ndiff = post_group.sel(hs_dim=\"completed\") - post_group.sel(hs_dim=\"not_completed\")\naz.plot_posterior(diff, ref_val=0, figsize=(6, 3));\n\n\n\n\n\n\n\n\n\n# Probabiliy that posterior is &gt; 0\n(post_group &gt; 0).mean().item()\n\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/05_two_means.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/05_two_means.html#informazioni-sullambiente-di-sviluppo",
    "title": "74  Confronto tra le medie di due gruppi",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\nbambi     : 0.14.0\nnumpy     : 1.26.4\npandas    : 2.2.2\npingouin  : 0.5.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>Confronto tra le medie di due gruppi</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction.html",
    "href": "chapters/linear_models/06_prediction.html",
    "title": "75  Predizione e inferenza",
    "section": "",
    "text": "Introduzione\nGelman et al. (2021) osservano che l’inferenza bayesiana si sviluppa in tre passaggi fondamentali, che vanno oltre la stima classica. In primo luogo, i dati e il modello vengono combinati per formare una distribuzione a posteriori, che solitamente viene riassunta tramite le distribuzioni a posteriori dei parametri del modello. In secondo luogo, è possibile propagare l’incertezza presente in questa distribuzione, ottenendo previsioni basate su simulazioni per risultati non osservati o futuri, tenendo conto dell’incertezza nei parametri del modello. Infine, è possibile integrare ulteriori informazioni nel modello utilizzando una distribuzione a priori. Questo capitolo si concentra sui temi della previsione e dell’inferenza.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction.html#predizione",
    "href": "chapters/linear_models/06_prediction.html#predizione",
    "title": "75  Predizione e inferenza",
    "section": "75.1 Predizione",
    "text": "75.1 Predizione\nPer discutere i temi della predizione e dell’inferenza bayesiana nel contesto del modello bayesiano di regressione lineare bivariata, esamineremo nuovamente il set di esaminati nel Capitolo 70 e relativi alla relazione tra Tense Arousal e ansia di stato.\n\n# Definire il percorso del file CSV\nfile_path = os.path.join(project_directory, \"data\", \"affect.csv\")\n\n# Leggere il file CSV in un DataFrame pandas\ndata = pd.read_csv(file_path)\n\n# Selezionare le colonne state1 e TA1\ndf = data[[\"state1\", \"TA1\"]]\n\nConsideriamo il modello bayesiano di regressione lineare bivariata che include prior uniformi per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) che abbiamo discusso nel Capitolo 70. Compiliamo e stampiamo tale modello.\n\nstan_file = os.path.join(project_directory, 'stan', 'arousal_model_prior_raw.stan')\nmodel1 = CmdStanModel(stan_file=stan_file)\nprint(model1.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 5.0);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 5.0);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\n\n\n\nSistemiamo i dati in un dizionario come richiesto dal modello Stan.\n\nstan_data = {\n    \"N\": len(df[\"TA1\"]),\n    \"x\": df[\"state1\"],\n    \"y\": df[\"TA1\"]\n}\n\nEseguiamo il campionamento MCMC.\n\nfit1 = model1.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\naz.summary(fit1, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.469\n1.249\n-0.815\n3.900\n0.027\n0.019\n2109.0\n2603.0\n1.0\n\n\nbeta\n0.269\n0.029\n0.212\n0.322\n0.001\n0.000\n2078.0\n2610.0\n1.0\n\n\nsigma\n2.714\n0.226\n2.302\n3.148\n0.004\n0.003\n3571.0\n3461.0\n1.0\n\n\n\n\n\n\n\nIl punto importante qui è che la distribuzione a posteriori non fornisce solo informazioni sui singoli parametri, ma anche sulle loro interdipendenze. Queste relazioni sono riflesse nei campioni a posteriori, che possono essere trasformati in vari modi. Ad esempio, possiamo calcolare la predizione a posteriori del modello lineare per il valore atteso di Tense Arousal quando l’ansia di stato è pari a 30 usando il seguente comando nel blocco generated quantities:\npred = alpha + beta * 30;\nModifichiamo il modello Stan che include la specifica di distribuzioni debolmente informative sui parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) per aggiungere questo comando nel blocco generated quantities e compiliamo il modello.\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model2.stan\")\nmodel2 = CmdStanModel(stan_file=stan_file)\nprint(model2.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 5.0);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 5.0);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  real pred; // predizione\n  \n  pred = alpha + beta * 30;\n}\n\n\n\nIn questo modello Stan aggiornato, il blocco generated quantities calcola la predizione a posteriori pred per una variabile predittore con valore 30. Questa modifica permette di ottenere la distribuzione a posteriori della predizione per un valore specifico del predittore.\nEseguiamo il campionamento.\n\nfit2 = model2.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la stima a posteriori del valore atteso di Tense Arousal quando l’ansia di stato è pari a 30. Questa analisi fornirà sia una stima puntuale di Tense Arousal che una misura dell’incertezza associata, rappresentata dall’intervallo di credibilità al livello di confidenza scelto.\n\naz.summary(fit2, var_names=([\"pred\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\npred\n9.544\n0.442\n8.713\n10.381\n0.008\n0.005\n3443.0\n4427.0\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction.html#quantificazione-dellincertezza",
    "href": "chapters/linear_models/06_prediction.html#quantificazione-dellincertezza",
    "title": "75  Predizione e inferenza",
    "section": "75.2 Quantificazione dell’incertezza",
    "text": "75.2 Quantificazione dell’incertezza\nPer quantificare l’incertezza complessiva nelle predizioni del modello, possiamo calcolare la distribuzione a posteriori delle predizioni per tutti i valori di \\(x\\) del campione. Questo ci permette di ottenere sia le stime puntuali delle predizioni sia una misura dell’incertezza associata.\nPer fare ciò, modifichiamo il blocco generated quantities nel seguente modo:\ngenerated quantities {\n  vector[N] y_rep; // Predizioni a posteriori per ciascun valore di x\n  \n  for (n in 1:N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\nEsaminiamo le modifiche:\n\nDichiarazione del vettore y_rep:\n\nvector[N] y_rep;: Dichiara un vettore y_rep di lunghezza N per contenere le predizioni a posteriori per ciascun valore di x.\n\nCiclo for per generare le predizioni:\n\nfor (n in 1:N): Itera su tutte le osservazioni.\ny_rep[n] = normal_rng(alpha + beta * x[n], sigma);: Per ogni valore di x[n], genera una predizione dalla distribuzione normale con media alpha + beta * x[n] e deviazione standard sigma. La funzione normal_rng genera numeri casuali dalla distribuzione normale specificata, rappresentando l’incertezza nelle predizioni.\n\n\nQuesto approccio consente di ottenere la distribuzione a posteriori delle predizioni, fornendo una visione completa dell’incertezza associata. Dalla distribuzione a posteriori di y_rep, possiamo calcolare sia la stima puntuale (come la media o la mediana delle predizioni) sia gli intervalli di credibilità (come l’intervallo al 95%) per ogni valore di x. Questo offre una misura dell’incertezza delle predizioni, riflettendo la variabilità e l’affidabilità del modello.\nModifichiamo il modello imponendo distribuzioni a priori debolmente informative sui parametri:\n\nPer \\(\\alpha\\) e \\(\\beta\\), utilizziamo una distribuzione Normale centrata su 0 con una deviazione standard di 2.\nPer \\(\\sigma\\), utilizziamo una distribuzione di Cauchy centrata su 0 con una scala di 2.\n\n\nstan_file = os.path.join(project_directory, \"stan\", \"arousal_model3.stan\")\nmodel3 = CmdStanModel(stan_file=stan_file)\nprint(model3.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero totale di osservazioni \n  vector[N] y; // variabile di risposta\n  vector[N] x; // variabile predittore\n}\nparameters {\n  real alpha; // intercetta\n  real beta; // coefficiente angolare\n  real&lt;lower=0&gt; sigma; // deviazione standard residua\n}\nmodel {\n  // distribuzioni a priori\n  alpha ~ normal(0, 5.0);\n  beta ~ normal(0, 1.0);\n  sigma ~ cauchy(0, 1.0);\n  // verosimiglianza\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // variabili predette\n  \n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\nEseguiamo il campionamento.\n\nfit3 = model3.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori dei parametri.\n\naz.summary(fit3, var_names=([\"alpha\", \"beta\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n1.436\n1.227\n-0.926\n3.694\n0.026\n0.020\n2185.0\n2421.0\n1.0\n\n\nbeta\n0.270\n0.029\n0.217\n0.324\n0.001\n0.000\n2050.0\n2391.0\n1.0\n\n\nsigma\n2.679\n0.219\n2.264\n3.070\n0.004\n0.003\n3724.0\n3418.0\n1.0\n\n\n\n\n\n\n\n\n75.2.1 Manipolare le Stime a Posteriori dei Parametri\nCostruiamo ora un grafico che rappresenta i valori osservati insieme alla linea di regressione stimata tramite il modello bayesiano. Al grafico aggiungeremo diverse linee di regressione, ciascuna orientata in base ai valori campionati casualmente dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\nPoniamoci dunque il problema di recuperare le stime a posteriori dei parametri dall’oggetto fit3, creato dal metodo sample(). La User’s Guide specifica quanto segue:\n\nThe sampler outputs are the set of per-chain Stan CSV files, a non-standard CSV file format. Each data row of the Stan CSV file contains the per-iteration estimate of the Stan model parameters, transformed parameters, and generated quantities variables.\n\nUtilizzando il metodo stan_variable(), possiamo ottenere un numpy.ndarray la cui struttura corrisponde a quella delle variabili del programma Stan, ossia i valori della distribuzione a posteriori di ciascun parametro. In questo caso, otteniamo i valori della distribuzione a posteriori di \\(\\alpha\\) e \\(\\beta\\):\n\n# Extract posterior samples\nalpha_samples = fit3.stan_variable(\"alpha\")\nbeta_samples = fit3.stan_variable(\"beta\")\n\nPer esempio, stampiamo i primi 20 valori di alpha_samples:\n\nprint(alpha_samples[0:20])\n\n[ 2.01713    2.37308    1.14274    2.80078    3.10586    1.77013\n  1.77256    0.529561   1.81511    0.0353212  0.125      0.722485\n -0.0975432 -0.364862   0.0669098 -1.44573   -2.34803   -1.87964\n -1.9525    -0.156463 ]\n\n\n\nlen(alpha_samples)\n\n8000\n\n\nAvendo ottenuto 8,000 stime della distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) (2,000 valori per ciascuna delle 4 catene), possiamo calcolare la stima puntuale a posteriori dei parametri nel seguente modo:\n\nmean_alpha = np.mean(alpha_samples)\nmean_beta = np.mean(beta_samples)\n\nprint(mean_alpha, mean_beta)\n\n1.4358008241905 0.26977196924999997\n\n\nPossiamo sovrapporre la retta di regressione al grafico a dispersione utilizzando le stime a posteriori dei parametri.\n\n# Plot y vs x\nx = df[\"state1\"] \nplt.scatter(\n    x, df[\"TA1\"], label=\"Data\", s=10\n)  # s is the size of the point\n\n# Draw lines from posterior samples\nfor i in range(300):  # assuming you have at least 300 samples\n    plt.plot(\n        x,\n        alpha_samples[i] + beta_samples[i] * x,\n        color=\"gray\",\n        linestyle=\"-\",\n        linewidth=0.5,\n        alpha=0.05,\n    )\n\n# Line using the mean of posterior estimates\nmean_alpha = np.mean(alpha_samples)\nmean_beta = np.mean(beta_samples)\ncolor_edge = \"#8f2727\"\nplt.plot(\n    x,\n    mean_alpha + mean_beta * x,\n    color=color_edge,\n    linewidth=2,\n    label=\"Mean Posterior Prediction\",\n)\n\n# Additional plot formatting\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Regression with Posterior Samples\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLe numerose linee di regressione presenti nel grafico visualizzano la nostra incertezza riguardo l’inclinazione esatta della linea di regressione principale. Tuttavia, il grafico mostra chiaramente che questa incertezza è minima.\nPossiamo procedere in un altro modo per descrivere l’incertezza della stima. Anziché utilizzare le distribuzioni a posteriori di alpha e beta, possiamo utilizzare la distribuzione a posteriori di y_rep. Procedendo in questo modo otteniamo il grafico mostrato qui sotto.\nIn questo plot, la linea rossa rappresenta la media delle predizioni a posteriori, mentre l’area grigia rappresenta l’intervallo di credibilità al 95%, mostrando l’incertezza delle predizioni del modello. Questo approccio fornisce una visione più completa e realistica dell’incertezza nelle predizioni rispetto all’approccio che utilizza solo alpha e beta.\n\n# Estrai i campioni posteriori di y_rep\ny_rep_samples = fit3.stan_variable(\"y_rep\")\n\n# Calcola la media e l'intervallo di credibilità (ad esempio, 95%) per y_rep\ny_rep_mean = np.mean(y_rep_samples, axis=0)\ny_rep_lower = np.percentile(y_rep_samples, 2.5, axis=0)\ny_rep_upper = np.percentile(y_rep_samples, 97.5, axis=0)\n\n# Plot y vs x\nx = df[\"state1\"]\ny = df[\"TA1\"]\nplt.scatter(x, y, label=\"Dati\", s=10)\n\n# Plot della media delle predizioni a posteriori\nplt.plot(x, y_rep_mean, color=color_edge, linewidth=2, label=\"Media delle predizioni\")\n\n# Plot dell'intervallo di credibilità\nplt.fill_between(\n    x,\n    y_rep_lower,\n    y_rep_upper,\n    color=\"gray\",\n    alpha=0.3,\n    label=\"Intervallo di credibilità 95%\",\n)\n\n# Formattazione del plot\nplt.xlabel(\"State Anxiety\")\nplt.ylabel(\"Tense Arousal\")\nplt.title(\"Incertezza delle predizioni del modello\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNel primo approccio, calcoliamo l’incertezza delle predizioni utilizzando le distribuzioni a posteriori di alpha e beta. Questo metodo consiste nel generare predizioni lineari per ciascun campione a posteriori di alpha e beta, tracciando quindi le linee di regressione risultanti. Questo ci permette di vedere come varia la linea di regressione in base alle incertezze nei parametri alpha e beta. Questo metodo visualizza come l’incertezza nei parametri del modello si traduce in incertezza nelle predizioni.\nNel secondo approccio, descriviamo l’incertezza delle predizioni utilizzando direttamente la distribuzione a posteriori di y_rep. In questo caso, generiamo predizioni per ciascun valore osservato di x nel modello Stan, tenendo conto delle distribuzioni a posteriori dei parametri del modello. Questo metodo visualizza direttamente l’incertezza nelle predizioni, tenendo conto delle variazioni nei dati osservati e delle distribuzioni a posteriori dei parametri.\nLe due descrizioni dell’incertezza delle predizioni del modello sono diverse perché riflettono aspetti differenti della distribuzione a posteriori:\n\nDistribuzione a posteriori di alpha e beta: Questo approccio considera solo l’incertezza nei parametri del modello (alpha e beta). Le linee di regressione tracciate variano in base a questi parametri, ma non tengono conto dell’incertezza residua (sigma).\nDistribuzione a posteriori di y_rep: Questo approccio include non solo l’incertezza nei parametri alpha e beta, ma anche l’incertezza residua (sigma). La distribuzione di y_rep riflette la variabilità totale nel modello, inclusa la variabilità nei dati osservati. Pertanto, l’incertezza nelle predizioni è maggiore perché tiene conto di tutte le fonti di variabilità.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction.html#verifica-predittiva-delle-distribuzioni-a-priori",
    "href": "chapters/linear_models/06_prediction.html#verifica-predittiva-delle-distribuzioni-a-priori",
    "title": "75  Predizione e inferenza",
    "section": "75.3 Verifica Predittiva delle Distribuzioni a Priori",
    "text": "75.3 Verifica Predittiva delle Distribuzioni a Priori\nLe verifiche predittive delle distribuzioni a priori (prior predictive checks) costituiscono una parte fondamentale del flusso di lavoro nella modellazione bayesiana. In sostanza, queste verifiche offrono due principali vantaggi:\n\nConsentono di verificare se si sta effettivamente incorporando la conoscenza scientifica nel modello. In altre parole, aiutano a controllare la credibilità delle ipotesi formulate prima di osservare i dati. Questo passaggio è essenziale per assicurarsi che le assunzioni del modello riflettano realisticamente la realtà che si sta cercando di modellare.\nPossono facilitare il processo di campionamento, limitando lo spazio dei risultati e dei parametri a valori “ragionevoli”. In pratica, questa restrizione contribuisce a migliorare l’efficienza del campionamento, evitando che il modello esplori aree dello spazio dei parametri che sono poco plausibili o che producono previsioni irrealistiche.\n\nConsideriamo qui il odello precedente che impone le seguenti distribuzioni a priori sui parametri alpha, beta e sigma del modello di regressione:\n\\[\n\\alpha \\sim \\text{Normal}(0, 5),\n\\] \\[\n\\beta \\sim \\text{Normal}(0, 2.5),\n\\] \\[\n\\sigma \\sim \\text{Chaucy}(0, 5).\n\\]\nLa verificha predittiva delle distribuzioni a priori genera un grafico nel quale vengono mostrate un certo numero (qui 30) di rette di regressione, ciascuna delle quali determinata da un valore a caso estratto dalla distribuzione a priori di alpha e un valore a caso estratto dalla distribuzione a priori di beta.\n\n# Number of samples to generate from the prior\nnum_samples = 50\n\n# Define the prior distributions for alpha and beta\nalpha_prior = np.random.normal(0, 5.0, num_samples)\nbeta_prior = np.random.normal(0, 2.5, num_samples)\n\n# Prepare a figure for plotting\nplt.figure(figsize=(10, 6))\n\n# Plot 30 regression lines from the prior distribution\nfor i in range(num_samples):\n    alpha_sample_prior = alpha_prior[i]\n    beta_sample_prior = beta_prior[i]\n\n    # Calculate the predicted y_hat without the noise term (sigma)\n    y_hat = alpha_sample_prior + beta_sample_prior * x\n\n    # Plot the regression line\n    plt.plot(x, y_hat, color=\"blue\", alpha=0.3)\n\n# Optional: Add labels and title to the plot\nplt.xlabel(\"x\")\nplt.ylabel(\"y_hat\")\nplt.title(\"Prior Predictive Checks with 50 Regression Lines\")\nplt.show()\n\n\n\n\n\n\n\n\nQueste distribuzioni a priori consentono di modellare relazioni plausibili tra la variabile dipendente e il predittore. Esse garantiscono che i valori dell’esito rimangano entro un intervallo ragionevole, permettendo al contempo che sia l’intercetta che il coefficiente angolare possano assumere valori sia positivi che negativi.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction.html#posterior-predictive-check",
    "href": "chapters/linear_models/06_prediction.html#posterior-predictive-check",
    "title": "75  Predizione e inferenza",
    "section": "75.4 Posterior-predictive check",
    "text": "75.4 Posterior-predictive check\nIl Posterior Predictive Check (PPC) è un passaggio cruciale nella modellazione bayesiana, che ci permette di valutare quanto bene il modello si adatta ai dati osservati, tenendo conto delle informazioni aggiornate dai dati stessi. L’idea alla base del PPC è confrontare le predizioni del modello, basate sulla distribuzione a posteriori dei parametri, con i dati reali, per vedere se il modello riesce a catturare correttamente le caratteristiche dei dati osservati.\n\nDopo aver adattato il modello ai dati, otteniamo campioni dai parametri a posteriori (\\(\\alpha\\), \\(\\beta\\), \\(\\sigma\\)). Questi campioni riflettono le nostre credenze aggiornate sui parametri, basate sia sulle distribuzioni a priori che sui dati osservati.\nUtilizzando i campioni della distribuzione a posteriori, simuliamo nuovi dati predetti (\\(y_{rep}\\)). Questi dati simulati rappresentano le previsioni del modello, date le nostre stime a posteriori dei parametri.\nConfrontiamo le osservazioni simulate (\\(y_{rep}\\)) con i dati osservati reali (\\(y\\)). Il PPC plot ci permette di vedere se il modello, con i parametri aggiornati, è in grado di riprodurre correttamente i dati osservati.\n\nPer creare il PPC plot, usiamo ArviZ. Creiamo un oggetto InferenceData che contiene sia le predizioni a posteriori che i dati osservati, organizzati nel formato richiesto da ArviZ.\n\nidata = az.from_cmdstanpy(\n    posterior=fit3,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": df[\"TA1\"]},\n)\n\nAvendo generato l’oggetto idata, possiamo ora creare il pp-check plot.\n\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"}, num_pp_samples=200)\n\n\n\n\n\n\n\n\nIl Posterior Predictive Check è uno strumento potente per verificare la validità del modello dopo l’analisi, assicurando che le predizioni del modello siano realistiche e che riflettano accuratamente le osservazioni effettive.\n\nEsempio 75.1 Il modo più fondamentale per verificare l’adeguatezza di un modello è visualizzare i dataset replicati e confrontarli con i dati effettivi. Qui illustriamo questo concetto con un semplice esempio tratto da un famoso dataset storico che non si adattava alla distribuzione normale. L’obiettivo di questo esempio è dimostrare come la mancanza di adattamento possa essere osservata utilizzando repliche predittive.\nI dati provengono da una serie di misurazioni effettuate da Simon Newcomb nel 1882, nell’ambito di un esperimento per stimare la velocità della luce. Abbiamo (inappropriatamente) adattato una distribuzione normale a questi dati, cosa che nel contesto della regressione può essere fatta tramite una regressione lineare senza predittori. Il nostro modello implicito per la regressione lineare prevede errori distribuiti normalmente, e stimare la media è equivalente a fare una regressione su una costante.\nImportiamo i dati:\n\ndata_file = os.path.join(project_directory, \"data\", \"newcomb.txt\")\nnewcomb = pd.read_csv(data_file)\nnewcomb.head()\n\n\n\n\n\n\n\n\ny\n\n\n\n\n0\n28\n\n\n1\n26\n\n\n2\n33\n\n\n3\n24\n\n\n4\n34\n\n\n\n\n\n\n\nEsaminiamo i dati con un istogramma. Si vede che ci sono alcune osservazioni devianti.\n\nplt.hist(newcomb[\"y\"], bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.3)\nplt.xlabel(\"y\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of y\")\nplt.show()\n\n\n\n\n\n\n\n\nIl valore mediano stimato, nei termini di una deviazione dal valore di 24.800 nanosecondi, è\n\nnp.median(newcomb[\"y\"])\n\n27.0\n\n\nPer questi dati adattiamo un modello normale, ovvero un modello di regressione con la sola intercetta. Importiamo e compiliamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"newcomb_model.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of observations\n  vector[N] y; // Outcome variable\n}\nparameters {\n  real alpha; // Intercept\n  real&lt;lower=0&gt; sigma; // Standard deviation of the errors\n}\nmodel {\n  // Prior for the intercept\n  alpha ~ normal(27, 20);\n  \n  // Likelihood\n  y ~ normal(alpha, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // Replicated data\n  \n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(alpha, sigma);\n  }\n}\n\n\n\nCreiamo un dizionario con i dati nel formato atteso da Stan:\n\nstan_data = {\"N\": len(newcomb[\"y\"]), \"y\": newcomb[\"y\"]}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori del parametro \\(\\alpha\\).\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"sigma\"]))\n\n\n\n\n\n\n\n\n\naz.summary(fit, var_names=([\"alpha\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n26.226\n1.368\n23.584\n28.797\n0.017\n0.012\n6737.0\n4534.0\n1.0\n\n\nsigma\n10.947\n0.979\n9.102\n12.707\n0.012\n0.008\n6881.0\n5259.0\n1.0\n\n\n\n\n\n\n\nEsaminiamo la distribuzione predittiva a posteriori.\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": newcomb[\"y\"]},\n)\n_ = az.plot_ppc(idata, data_pairs={\"y\": \"y_rep\"})\n\n\n\n\n\n\n\n\nÈ evidente che il modello non riesce a predire adeguatamente i dati osservati nel campione.\nL’istogramma precedente rivela la presenza di alcune osservazioni anomale. Di conseguenza, è più appropriato utilizzare un modello “robusto”, come la distribuzione t di Student, che è meglio in grado di gestire i dati devianti presenti nelle code della distribuzione.\nModifichiamo quindi il codice Stan per utilizzare una verosimiglianza basata sulla distribuzione t di Student, stimando i gradi di libertà direttamente dal modello.\n\nstan2_file = os.path.join(project_directory, \"stan\", \"newcomb_t_model.stan\")\nmodel2 = CmdStanModel(stan_file=stan2_file)\nprint(model2.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of observations\n  vector[N] y; // Outcome variable\n}\nparameters {\n  real alpha; // Intercept\n  real&lt;lower=0&gt; sigma; // Standard deviation of the errors\n  real&lt;lower=1&gt; nu; // Degrees of freedom for the Student's t-distribution\n}\nmodel {\n  // Prior for the intercept\n  alpha ~ normal(27, 20);\n  \n  // Prior for degrees of freedom\n  nu ~ gamma(2, 0.1); // Weakly informative prior for nu, adjust as needed\n  \n  // Likelihood using Student's t-distribution\n  y ~ student_t(nu, alpha, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep; // Replicated data\n  \n  for (n in 1 : N) {\n    y_rep[n] = student_t_rng(nu, alpha, sigma);\n  }\n}\n\n\n\nEseguiamo il campionamento con la nuova versione del modello.\n\nfit2 = model2.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\nEsaminiamo la distribuzione a posteriori dei parametri.\n\n_ = az.plot_trace(fit2, var_names=([\"alpha\", \"nu\", \"sigma\"]))\n\n\n\n\n\n\n\n\n\naz.summary(fit2, var_names=([\"alpha\", \"nu\", \"sigma\"]), hdi_prob=0.94)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n27.436\n0.646\n26.125\n28.584\n0.009\n0.006\n5103.0\n4626.0\n1.0\n\n\nnu\n2.800\n0.943\n1.328\n4.579\n0.013\n0.009\n4799.0\n3810.0\n1.0\n\n\nsigma\n4.209\n0.650\n2.997\n5.470\n0.009\n0.007\n4882.0\n3769.0\n1.0\n\n\n\n\n\n\n\n\nidata2 = az.from_cmdstanpy(\n    posterior=fit2,\n    posterior_predictive=\"y_rep\",\n    observed_data={\"y\": newcomb[\"y\"]},\n)\n# Plot the posterior predictive checks\n_ = az.plot_ppc(idata2, data_pairs={\"y\": \"y_rep\"})\nplt.xlim(0, 50)\nplt.show()\n\n\n\n\n\n\n\n\nIl posterior predictive check è ora adeguato.\nLa stima della deviazione dal valore di 24.800 nanosecondi è ora di 27.436.\nSenza entrare nei dettagli delle trasformazioni algebriche, questo porta a una stima della velocità della luce di 299.762.442 m/s. Sebbene questo valore sia una sottostima rispetto al valore “accettato” di 299.792.458 m/s, l’errore è inferiore a quello che si otterrebbe utilizzando una stima a posteriori di 26.226, che condurrebbe a una stima della velocità della luce di 296.992.741 m/s.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction.html#commenti-e-considerazioni-finali",
    "href": "chapters/linear_models/06_prediction.html#commenti-e-considerazioni-finali",
    "title": "75  Predizione e inferenza",
    "section": "75.5 Commenti e Considerazioni Finali",
    "text": "75.5 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo approfondito i temi della predizione bayesiana nel contesto del modello di regressione bivariato, evidenziando l’importanza delle verifiche predittive a priori e a posteriori per la valutazione e la validazione del modello.\nAbbiamo visto come il Prior Predictive Check sia essenziale per verificare che le distribuzioni a priori siano appropriate per il modello e i dati del campione. Questo passaggio consente di esaminare se le ipotesi iniziali sono coerenti con la conoscenza preesistente e con i risultati attesi. Un’adeguata verifica predittiva a priori aiuta a prevenire l’adozione di distribuzioni a priori che possano portare a previsioni irrealistiche o fuorvianti. Se le predizioni basate sulle distribuzioni a priori risultano incompatibili con ciò che ci si aspetta dai dati, è un segnale che le distribuzioni a priori devono essere riviste.\nSuccessivamente, abbiamo esaminato il Posterior Predictive Check come strumento per valutare la capacità del modello di adattarsi ai dati osservati. Dopo aver integrato le informazioni dei dati con le distribuzioni a priori, il posterior predictive check permette di confrontare le predizioni del modello con i dati effettivamente osservati. Se il modello è adeguato, le sue predizioni dovrebbero essere in linea con i dati reali. Tuttavia, se emerge una discrepanza sostanziale tra le predizioni e i dati osservati, questo è un chiaro segnale che il modello potrebbe non essere appropriato per il fenomeno in esame e potrebbe richiedere una revisione. Tale revisione può comportare la modifica delle assunzioni di base, l’inclusione di nuovi predittori, o l’adozione di un modello completamente diverso.\nIn conclusione, l’approccio bayesiano alla predizione e alla verifica dei modelli offre un framework robusto e flessibile per l’analisi statistica. I prior e posterior predictive checks non sono semplici passaggi tecnici, ma costituiscono una parte integrante del processo di modellizzazione, assicurando che il modello non solo sia ben adattato ai dati, ma anche che le sue assunzioni siano giustificate e realistiche. L’utilizzo di questi strumenti permette di costruire modelli che siano coerenti con la realtà che intendono rappresentare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/06_prediction.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/06_prediction.html#informazioni-sullambiente-di-sviluppo",
    "title": "75  Predizione e inferenza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Tue Aug 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nsys       : 3.12.4 | packaged by conda-forge | (main, Jun 17 2024, 10:13:44) [Clang 16.0.6 ]\npandas    : 2.2.2\ncmdstanpy : 1.2.4\nlogging   : 0.5.1.2\n\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>Predizione e inferenza</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_design.html",
    "href": "chapters/linear_models/07_design.html",
    "title": "76  Disegno della ricerca e potere statistico",
    "section": "",
    "text": "Introduzione\nbla bla",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_design.html#problema-della-potenza-statistica",
    "href": "chapters/linear_models/07_design.html#problema-della-potenza-statistica",
    "title": "76  Disegno della ricerca e potere statistico",
    "section": "76.1 Problema della potenza statistica",
    "text": "76.1 Problema della potenza statistica\nLa potenza statistica è definita come la probabilità, prima che uno studio venga eseguito, che un determinato confronto raggiunga la “significatività statistica” a un livello predefinito (tipicamente un p-value inferiore a 0.05), dato un certo effetto reale presunto. Un’analisi della potenza viene eseguita ipotizzando prima una dimensione dell’effetto, poi facendo alcune assunzioni sulla variazione dei dati e sulla dimensione del campione dello studio, e infine utilizzando calcoli di probabilità per determinare la probabilità che il p-value sia inferiore alla soglia.\nLa visione convenzionale suggerisce di evitare studi con bassa potenza perché è improbabile che abbiano successo. Tuttavia, supponiamo che uno studio abbia bassa potenza ma possa essere eseguito a un costo molto basso rispetto ai potenziali benefici che potrebbero derivare da un successo nella ricerca. In questo caso, un ricercatore potrebbe concludere che vale ancora la pena condurre uno studio con bassa potenza, considerandolo una scommessa che vale la pena tentare. Pertanto, quando i costi sono bassi, i ricercatori sono spesso inclini a rischiare, nella convinzione che un risultato positivo potrebbe portare grandi benefici (per la carriera del ricercatore). Tuttavia, questo non è necessariamente una buona idea, come verrà discusso successivamente.\n\n76.1.1 La maledizione del vincitore negli studi a bassa potenza\nIl problema con il ragionamento convenzionale è che, in uno studio a bassa potenza, il presunto “successo” della significatività statistica può essere in realtà una trappola. Concentrandosi su confronti che sono statisticamente significativi, la comunità accademica e i singoli ricercatori ottengono una visione sistematicamente distorta e eccessivamente ottimistica del mondo.\nIn termini semplici, quando il segnale è debole e il rumore è alto, i modelli statisticamente significativi nei dati sono probabilmente errati, nel senso che i risultati difficilmente si replicheranno.\nIn termini tecnici, i risultati statisticamente significativi sono soggetti a errori di tipo M e di tipo S (si veda il Capitolo 119). Uno studio a bassa potenza non ha praticamente alcuna possibilità di fornire informazioni utili, e possiamo affermarlo anche prima che i dati siano raccolti. Pertanto, un rischio chiave per uno studio a bassa potenza non è tanto che abbia poche probabilità di successo, ma piuttosto che un apparente successo mascheri un fallimento più grande. La pubblicazione di risultati rumorosi può contribuire alla crisi di replicazione quando queste affermazioni fragili crollano sotto un’analisi più attenta o non si manifestano in tentativi di replicazione.\n\n\n76.1.2 Ipotesi di dimensione dell’effetto\nUn’altra sfida è che qualsiasi analisi della potenza o calcolo della dimensione del campione è condizionato da una dimensione dell’effetto presunta, che è l’obiettivo dello studio e quindi non è mai conosciuta in anticipo. Esistono diversi modi per scegliere una dimensione dell’effetto per eseguire un’analisi di uno studio pianificato. Una strategia è provare una gamma di valori coerenti con la letteratura precedente sull’argomento. Un’altra è decidere quale grandezza dell’effetto sarebbe di interesse pratico.\nGelman et al. (2021) raccomandano di non prendere decisioni di progettazione basate sulla stima di un singolo studio rumoroso. È meglio utilizzare un insieme di informazioni da studi precedenti per prendere decisioni informate sulla potenza statistica e la dimensione del campione. Gelman et al. (2021) notano come i risultati pubblicati tendono ad essere sovrastime degli effetti reali per vari motivi, tra cui il fatto che gli interventi vengono spesso testati su persone e in scenari in cui saranno più efficaci, e i risultati “statisticamente significativi” sono più probabilmente riportati e pubblicati, portando a sovrastime.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_design.html#stimare-la-dimensione-del-campione",
    "href": "chapters/linear_models/07_design.html#stimare-la-dimensione-del-campione",
    "title": "76  Disegno della ricerca e potere statistico",
    "section": "76.2 Stimare la dimensione del campione",
    "text": "76.2 Stimare la dimensione del campione\nPrima di raccogliere i dati, può essere utile stimare la precisione delle inferenze che ci si aspetta di ottenere con una determinata dimensione del campione, o stimare la dimensione del campione necessaria per ottenere una certa precisione.\nIn sintesi, per avere una potenza dell’80%, il vero valore del parametro deve essere 2.8 errori standard lontano dal punto di confronto. Tuttavia, questi calcoli sono validi solo quanto le loro assunzioni, e solitamente non si conosce il vero valore del parametro prima di eseguire lo studio.\n\n76.2.1 Determinazione della dimensione del campione per un errore standard specificato\nSupponiamo di voler stimare un valore medio della popolazione \\(\\theta\\) a partire dai dati \\(y_1, \\dots, y_n\\), un campione casuale di dimensione \\(n\\). Una stima veloce di \\(\\theta\\) è la media campionaria \\(\\bar{y}\\), che ha un errore standard pari a \\(\\sigma/\\sqrt{n}\\), dove \\(\\sigma\\) è la deviazione standard di \\(y\\) nella popolazione.\nSe l’obiettivo è ottenere un errore standard specifico per \\(\\bar{y}\\), allora la dimensione del campione deve essere almeno:\n\\[\nn = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2,\n\\]\ndove \\(\\text{s.e.}\\) è l’errore standard desiderato.\nPer capire questo risultato, iniziamo ricordando la formula dell’errore standard della media campionaria:\n\\[\\text{s.e.}(\\bar{y}) = \\frac{\\sigma}{\\sqrt{n}},\\]\ndove:\n\n\\(\\text{s.e.}(\\bar{y})\\) è l’errore standard della media campionaria,\n\\(\\sigma\\) è la deviazione standard della popolazione,\n\\(n\\) è la dimensione del campione.\n\nOra, supponiamo di voler ottenere un errore standard specifico, che chiameremo semplicemente \\(\\text{s.e.}\\). Possiamo quindi impostare l’equazione:\n\\(\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}\\)\nPer isolare \\(n\\), prima moltiplichiamo entrambi i lati per \\(\\sqrt{n}\\):\n\\(\\text{s.e.} \\cdot \\sqrt{n} = \\sigma\\)\nOra, eleviamo al quadrato entrambi i lati:\n\\((\\text{s.e.} \\cdot \\sqrt{n})^2 = \\sigma^2\\)\nSemplifichiamo il lato sinistro:\n\\(\\text{s.e.}^2 \\cdot n = \\sigma^2\\)\n6Infine, dividiamo entrambi i lati per \\(\\text{s.e.}^2\\):\n\\(n = \\frac{\\sigma^2}{\\text{s.e.}^2}\\)\nQuesta può essere riscritta come:\n\\(n = \\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2\\)\nQuindi, se vogliamo ottenere un errore standard specifico per \\(\\bar{y}\\), la dimensione del campione deve essere almeno pari a \\(\\left(\\frac{\\sigma}{\\text{s.e.}}\\right)^2\\), dove \\(\\text{s.e.}\\) è l’errore standard desiderato.\nQuesta formula ci permette di calcolare la dimensione minima del campione necessaria per ottenere un determinato livello di precisione (misurato dall’errore standard) nella stima della media della popolazione.\n\n\n76.2.2 Dimensione del campione per una potenza dell’80%\nSe l’obiettivo è ottenere l’80% di potenza per distinguere \\(\\theta\\) da un valore specificato \\(\\theta_0\\), allora la dimensione del campione richiesta può essere calcolata con una formula conservativa:\n\\[\nn = \\left(\\frac{2.8 \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\nQui, il valore \\(2.8\\) deriva dalla somma dei quantili della distribuzione normale per l’80% di potenza e il 95% di confidenza.\nPer derivare la formula per la dimensione del campione necessaria a ottenere l’80% di potenza per distinguere \\(\\theta\\) da un valore specificato \\(\\theta_0\\), seguiamo i passaggi seguenti.\nI termini che useremo sono i seguenti:\n\n\\(\\theta\\): Il valore medio della popolazione che stiamo cercando di stimare.\n\\(\\theta_0\\): Il valore specificato con cui vogliamo confrontare \\(\\theta\\).\n\\(\\sigma\\): La deviazione standard della popolazione.\n\\(\\text{s.e.}\\): L’errore standard della media campionaria \\(\\bar{y}\\), che è dato da \\(\\sigma/\\sqrt{n}\\).\n\nL’obiettivo è determinare la dimensione del campione \\(n\\) necessaria per avere una potenza dell’80% nel distinguere \\(\\theta\\) da \\(\\theta_0\\), con un livello di significatività del 5%.\nLa differenza \\(\\theta - \\theta_0\\) è l’effetto che stiamo cercando di rilevare. L’errore standard associato a questa differenza è dato da:\n\\[\n\\text{s.e.} = \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nLa precisione della stima della differenza \\(\\theta - \\theta_0\\) dipende dalla dimensione del campione \\(n\\).\nPer una potenza dell’80%, vogliamo che la probabilità di rifiutare l’ipotesi nulla (quando in realtà \\(\\theta \\neq \\theta_0\\)) sia almeno dell’80%. Ciò corrisponde a un’area sotto la curva normale standard di \\(0.8\\).\nIl livello di significatività del 5% corrisponde a un valore critico di \\(1.96\\) (dalla distribuzione normale standard), che è il valore z corrispondente al 97,5% della distribuzione (poiché stiamo lavorando con un test a due code).\nPer ottenere l’80% di potenza, il valore osservato deve trovarsi non solo al di fuori dell’intervallo di confidenza del 95%, ma anche a una certa distanza dalla media, tale da coprire il restante 80% della distribuzione della differenza \\(\\theta - \\theta_0\\). Questo valore z corrispondente al restante 80% è \\(0.84\\).\nQuindi, il valore z totale da considerare è:\n\\[\nz_{\\text{totale}} = 1.96 + 0.84 = 2.8.\n\\]\nLa differenza \\(\\theta - \\theta_0\\) deve essere almeno \\(2.8\\) volte l’errore standard per garantire l’80% di potenza. Pertanto, possiamo scrivere:\n\\[\n\\theta - \\theta_0 = 2.8 \\times \\frac{\\sigma}{\\sqrt{n}}.\n\\]\nRisolviamo per \\(n\\):\n\\[\n\\sqrt{n} = \\frac{2.8 \\sigma}{\\theta - \\theta_0}.\n\\]\nElevando al quadrato entrambi i lati:\n\\[\nn = \\left(\\frac{2.8 \\sigma}{\\theta - \\theta_0}\\right)^2.\n\\]\nQuesta formula ci dice che, per avere l’80% di potenza nel rilevare una differenza \\(\\theta - \\theta_0\\) con una deviazione standard \\(\\sigma\\), dobbiamo avere una dimensione del campione pari a \\(n = \\left(\\frac{2.8 \\sigma}{\\theta - \\theta_0}\\right)^2\\). Il valore \\(2.8\\) deriva dalla somma dei quantili della distribuzione normale standard: \\(1.96\\) (per un intervallo di confidenza del 95%) e \\(0.84\\) (per la potenza dell’80%). Questo valore assicura che l’intervallo di confidenza per \\(\\theta\\) non includa \\(\\theta_0\\) nel 80% dei casi, il che ci dà l’80% di potenza.\n\n76.2.2.1 Correzione per la distribuzione t e incertezze nella deviazione standard\nNelle analisi di progettazione, utilizziamo la distribuzione normale per la regressione lineare quando la deviazione standard residua \\(\\sigma\\) è conosciuta. Tuttavia, per studi molto piccoli, i gradi di libertà sono bassi, e la deviazione standard residua non è stimata con precisione dai dati. In questi casi, le incertezze inferenziali seguono la distribuzione t di Student anziché la normale. Di conseguenza, il valore \\(2.8\\) deve essere sostituito con un numero più grande per tenere conto di questa ulteriore fonte di incertezza.\nAd esempio, per uno studio che confronta due gruppi di 6 pazienti ciascuno, i gradi di libertà sono 10. In Python, la somma dei quantili della distribuzione t con 10 gradi di libertà per l’80% di potenza e il 95% di confidenza è \\(3.1\\), quindi \\(2.8\\) viene sostituito da \\(3.1\\) nei calcoli per la potenza dell’80%.\n\nimport scipy.stats as stats\n\n# Calcola i valori critici dalla distribuzione t di Student con 10 gradi di libertà\ndf = 10\n\n# Calcola il quantile per l'80% di potenza (quindi 0.8) e il 95% di confidenza (quindi 0.975)\nt_value_80 = stats.t.ppf(0.8, df)\nt_value_95 = stats.t.ppf(0.975, df)\n\n# Somma dei due quantili\nt_total = t_value_80 + t_value_95\nt_total\n\n3.1071966805155227\n\n\nUtilizzando Python, abbiamo calcolato i valori critici dalla distribuzione t di Student con 10 gradi di libertà. La somma dei quantili per l’80% di potenza e il 95% di confidenza è pari a \\(3.107\\). Questo valore sostituisce il valore \\(2.8\\) nei calcoli per la potenza dell’80% quando si utilizzano piccoli campioni con una distribuzione t invece della distribuzione normale standard.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_design.html#confronto-di-medie",
    "href": "chapters/linear_models/07_design.html#confronto-di-medie",
    "title": "76  Disegno della ricerca e potere statistico",
    "section": "76.3 Confronto di medie",
    "text": "76.3 Confronto di medie\nConsideriamo ora il caso del confronto tra due medie. L’errore standard della differenza tra due medie campionarie \\(\\bar{y}_1 - \\bar{y}_2\\) è dato da:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}.\n\\]\nSe supponiamo che le dimensioni dei campioni nei due gruppi siano uguali (\\(n_1 = n_2 = n/2\\)), l’errore standard diventa semplicemente:\n\\[\n\\text{s.e.} = \\sqrt{\\frac{\\sigma_1^2 + \\sigma_2^2}{n/2}} = \\sqrt{\\frac{2\\sigma^2}{n}} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{n}}.\n\\]\nQuindi, la dimensione del campione richiesta per ottenere un errore standard specifico sarà:\n\\[\nn = \\frac{2(\\sigma_1^2 + \\sigma_2^2)}{\\text{s.e.}^2}.\n\\]\nSe inoltre assumiamo che la variazione all’interno di ciascun gruppo sia la stessa (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), allora:\n\\[\n\\text{s.e.} = \\frac{2\\sigma}{\\sqrt{n}}\n\\]\ne la dimensione del campione richiesta è:\n\\[\nn = \\left(\\frac{2\\sigma}{\\text{s.e.}}\\right)^2.\n\\]\n\n76.3.1 Dimensione del campione per una differenza \\(\\Delta\\) con l’80% di potenza\nPer ottenere l’80% di potenza, la differenza \\(\\Delta\\) che vogliamo rilevare deve essere abbastanza grande rispetto all’errore standard della differenza tra le medie. Dato che abbiamo già calcolato che il valore \\(2.8\\) è la somma dei quantili per l’80% di potenza e il 95% di confidenza, possiamo scrivere:\n\\[\n   \\Delta = 2.8 \\times \\text{s.e.}.\n   \\]\nSostituendo l’espressione per \\(\\text{s.e.}\\), otteniamo:\n\\[\n   \\Delta = 2.8 \\times \\sqrt{\\frac{2(\\sigma_1^2 + \\sigma_2^2)}{n}}.\n   \\]\nOra, risolviamo per \\(n\\):\n\\[\n   \\sqrt{n} = \\frac{2.8 \\times \\sqrt{2(\\sigma_1^2 + \\sigma_2^2)}}{\\Delta}.\n   \\]\nElevando al quadrato entrambi i lati, otteniamo:\n\\[\n   n = 2\\left(\\frac{2.8 \\sqrt{\\sigma_1^2 + \\sigma_2^2}}{\\Delta}\\right)^2 = 2\\left(\\frac{\\sigma_1^2 + \\sigma_2^2}{\\left(\\frac{\\Delta}{2.8}\\right)^2}\\right).\n   \\]\nSe assumiamo che la variazione all’interno dei due gruppi sia la stessa (\\(\\sigma_1 = \\sigma_2 = \\sigma\\)), allora possiamo semplificare ulteriormente la formula. In questo caso, abbiamo:\n\\[\n   n = 2\\left(\\frac{\\sigma^2 + \\sigma^2}{\\left(\\frac{\\Delta}{2.8}\\right)^2}\\right) = 2\\left(\\frac{2\\sigma^2}{\\left(\\frac{\\Delta}{2.8}\\right)^2}\\right).\n   \\]\nSemplificando, otteniamo:\n\\[\n   n = \\left(\\frac{5.6 \\sigma}{\\Delta}\\right)^2.\n   \\]\nQui, \\(5.6\\) è semplicemente \\(2 \\times 2.8\\).\nQuesta formula ci dice che, per rilevare una differenza \\(\\Delta\\) tra due gruppi con una potenza dell’80%, la dimensione del campione richiesta dipende dalla deviazione standard \\(\\sigma\\) comune a entrambi i gruppi e dalla differenza \\(\\Delta\\) che vogliamo rilevare.\n\nSe la deviazione standard \\(\\sigma\\) è alta: Avremo bisogno di un campione più grande per rilevare una differenza \\(\\Delta\\).\nSe la differenza \\(\\Delta\\) è piccola: Anche in questo caso avremo bisogno di un campione più grande per garantire che la differenza sia rilevabile con l’80% di potenza.\n\n\nEsempio 76.1 Se la differenza \\(\\Delta\\) che vogliamo rilevare è pari a metà della deviazione standard (\\(\\Delta = 0.5\\sigma\\)), allora la formula ci dirà quanti partecipanti sono necessari in ciascun gruppo per rilevare questa differenza con l’80% di potenza. Ad esempio, se \\(\\Delta = 0.5\\sigma\\), la dimensione totale del campione sarà:\n\\[\nn = \\left(\\frac{5.6 \\sigma}{0.5\\sigma}\\right)^2 = (11.2)^2 = 125.44 \\approx 126.\n\\]\nQuindi, servirebbero 63 partecipanti per gruppo.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/07_design.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/07_design.html#informazioni-sullambiente-di-sviluppo",
    "title": "76  Disegno della ricerca e potere statistico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -m  \n\nLast updated: Sun Aug 11 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\ncmdstanpy : 1.2.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\npingouin  : 0.5.4\nnumpy     : 1.26.4\narviz     : 0.18.0\nlogging   : 0.5.1.2\n\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other stories. Cambridge University Press.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>Disegno della ricerca e potere statistico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html",
    "href": "chapters/linear_models/08_linear_algebra.html",
    "title": "77  Elementi di algebra lineare",
    "section": "",
    "text": "77.1 Introduzione\nQuesto capitolo presenta alcune nozioni di base dell’algebra lineare, una branca della matematica essenziale per la comprensione e l’analisi dei modelli di regressione lineare.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#rappresentazione-dei-vettori",
    "href": "chapters/linear_models/08_linear_algebra.html#rappresentazione-dei-vettori",
    "title": "77  Elementi di algebra lineare",
    "section": "77.2 Rappresentazione dei Vettori",
    "text": "77.2 Rappresentazione dei Vettori\nNell’algebra lineare, un vettore, che rappresenta una lista ordinata di scalari, è solitamente indicato con una lettera minuscola in grassetto, come \\(\\mathbf{v}\\). Gli elementi di un vettore sono generalmente indicati con un indice, ad esempio \\(\\mathbf{v}_1\\) si riferisce al primo elemento del vettore \\(\\mathbf{v}\\).\nUn vettore \\(\\mathbf{v}\\) di \\(n\\) elementi può essere rappresentato sia come una colonna che come una riga, a seconda della convenzione scelta. Ad esempio, un vettore colonna di \\(n\\) elementi è scritto come:\n\\[\n\\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix},\n\\]\nmentre un vettore riga appare come:\n\\[\n\\mathbf{v} = \\begin{bmatrix} v_1 & v_2 & \\cdots & v_n \\end{bmatrix}.\n\\]\nQuesta notazione consente di visualizzare chiaramente i singoli elementi del vettore e di riferirsi a ciascuno di essi in modo specifico.\nUna lista di \\(n\\) scalari organizzata in un vettore \\(\\mathbf{v}\\) è chiamata “dimensione” del vettore. Formalmente, si esprime come \\(\\mathbf{v} \\in \\mathbb{R}^n\\), indicando che il vettore \\(\\mathbf{v}\\) appartiene all’insieme di tutti i vettori reali di dimensione \\(n\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#visualizzazione-geometrica-dei-vettori",
    "href": "chapters/linear_models/08_linear_algebra.html#visualizzazione-geometrica-dei-vettori",
    "title": "77  Elementi di algebra lineare",
    "section": "77.3 Visualizzazione Geometrica dei Vettori",
    "text": "77.3 Visualizzazione Geometrica dei Vettori\nI vettori possono essere rappresentati come frecce in uno spazio \\(n\\)-dimensionale, con l’origine come punto di partenza e la punta della freccia che corrisponde alle coordinate specificate dal vettore. La norma \\(L_2\\) (o lunghezza) di un vettore, denotata come \\(\\|\\mathbf{v}\\|\\), rappresenta la distanza euclidea dall’origine alla punta del vettore.\nPer un vettore \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\), la norma è definita come:\n\\[\n\\|\\mathbf{v}\\| = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}.\n\\]\n\n77.3.1 Esempio Numerico\nConsideriamo un vettore in uno spazio bidimensionale, ad esempio \\(\\mathbf{v} = [3, 4]\\). Geometricamente, questo vettore parte dall’origine \\((0, 0)\\) e termina nel punto \\((3, 4)\\) del piano cartesiano.\nPer calcolare la norma \\(L_2\\) di questo vettore, applichiamo la formula:\n\\[\n\\|\\mathbf{v}\\| = \\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = \\sqrt{25} = 5.\n\\]\nQuindi, la norma del vettore \\(\\mathbf{v} = [3, 4]\\) è 5, che rappresenta la lunghezza della freccia dal punto di origine \\((0, 0)\\) al punto \\((3, 4)\\) nello spazio bidimensionale.\n\n\n77.3.2 Rappresentazione Geometrica\ny\n^\n|       * (3, 4)\n|      /\n|     /\n|    /\n|   /\n|  /\n| / \n|/____________&gt; x\n(0, 0)\nIn questo diagramma, il punto * rappresenta la fine del vettore \\(\\mathbf{v}\\) e la linea inclinata mostra il vettore stesso che parte dall’origine. L’altezza della linea fino al punto (3, 4) rappresenta visivamente la norma del vettore, che è la distanza di 5 unità dall’origine.\nQuesto esempio illustra chiaramente la relazione tra la rappresentazione numerica di un vettore e la sua interpretazione geometrica, facilitando la comprensione della lunghezza del vettore e della sua direzione nello spazio bidimensionale.\nSebbene noi siamo principalmente limitati a ragionare su spazi bidimensionali (2D) e tridimensionali (3D), i dati che raccogliamo spesso risiedono in spazi di dimensioni superiori. L’algebra lineare permette di ragionare e sviluppare intuizioni su vettori e spazi di dimensioni molto più elevate, superando i limiti della visualizzazione diretta.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#operazioni-di-base-sui-vettori",
    "href": "chapters/linear_models/08_linear_algebra.html#operazioni-di-base-sui-vettori",
    "title": "77  Elementi di algebra lineare",
    "section": "77.4 Operazioni di Base sui Vettori",
    "text": "77.4 Operazioni di Base sui Vettori\n\n77.4.1 1. Moltiplicazione di un Vettore per uno Scalare\nLa moltiplicazione di un vettore per uno scalare produce un nuovo vettore. Questa operazione può essere interpretata come una “scalatura” del vettore nello spazio: il vettore risultante mantiene la stessa direzione dell’originale, ma la sua lunghezza viene modificata in base allo scalare.\nSe \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\) è un vettore e \\(c\\) è uno scalare, la moltiplicazione del vettore per lo scalare è data da:\n\\[\nc\\mathbf{v} = [cv_1, cv_2, \\ldots, cv_n]\n\\]\n\n\n77.4.2 2. Addizione di Vettori\nÈ possibile sommare due vettori della stessa dimensione. La somma vettoriale si ottiene sommando gli elementi corrispondenti di ciascun vettore.\nSe \\(\\mathbf{u} = [u_1, u_2, \\ldots, u_n]\\) e \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\) sono due vettori di dimensione \\(n\\), la loro somma è:\n\\[\n\\mathbf{u} + \\mathbf{v} = [u_1 + v_1, u_2 + v_2, \\ldots, u_n + v_n]\n\\]\n\n\n77.4.3 3. Prodotto Scalare (o Prodotto Interno)\nIl prodotto scalare tra due vettori della stessa dimensione è uno scalare che fornisce informazioni sull’angolo tra i vettori nello spazio. Formalmente, il prodotto scalare di \\(\\mathbf{u} = [u_1, u_2, \\ldots, u_n]\\) e \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\) è definito come:\n\\[\n\\mathbf{u} \\cdot \\mathbf{v} = u_1v_1 + u_2v_2 + \\cdots + u_nv_n\n\\]\nQuesto prodotto scalare può anche essere espresso in termini dell’angolo \\(\\theta\\) tra i vettori:\n\\[\n\\mathbf{u} \\cdot \\mathbf{v} = \\|\\mathbf{u}\\| \\|\\mathbf{v}\\| \\cos(\\theta)\n\\]\nSe due vettori sono ortogonali, ovvero formano un angolo di \\(90^\\circ\\) tra loro, il loro prodotto scalare è zero: \\(\\mathbf{u} \\cdot \\mathbf{v} = 0\\).\n\n\n77.4.4 4. Prodotto Scalare di un Vettore con Se Stesso\nIl prodotto scalare di un vettore con se stesso fornisce il quadrato della sua lunghezza. Se \\(\\mathbf{v} = [v_1, v_2, \\ldots, v_n]\\), allora:\n\\[\n\\mathbf{v} \\cdot \\mathbf{v} = v_1^2 + v_2^2 + \\cdots + v_n^2 = \\|\\mathbf{v}\\|^2\n\\]\nQueste operazioni di base sui vettori sono fondamentali per molte applicazioni in matematica, fisica, informatica e altre scienze, fornendo una struttura potente per analizzare e risolvere problemi in spazi multidimensionali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#vettori-in-numpy",
    "href": "chapters/linear_models/08_linear_algebra.html#vettori-in-numpy",
    "title": "77  Elementi di algebra lineare",
    "section": "77.5 Vettori in NumPy",
    "text": "77.5 Vettori in NumPy\nNumPy è la libreria di Python più usata per manipolare vettori e matrici.\nUsiamo NumPy per creare un vettore con tre elementi: 1, 2 e 3:\n\nv = np.array([1, 2, 3])\nprint(v)\n\n[1 2 3]\n\n\nIn questo esempio, v è un array NumPy che rappresenta un vettore con tre elementi: 1, 2 e 3.\nPer fare il prodotto tra un vettore e uno scalare, puoi semplicemente moltiplicare l’array NumPy per uno scalare. Questa operazione moltiplica ogni elemento del vettore per lo scalare:\n\na = 5\n\n# Prodotto vettore-scalare\nva = v * a\nprint(va)\n\n[ 5 10 15]\n\n\nQuesto moltiplicherà ogni elemento del vettore per 5, dando come risultato [5, 10, 15].\nIl prodotto interno (o prodotto scalare) tra due vettori è una somma dei prodotti dei loro elementi corrispondenti. In NumPy, si può calcolare usando la funzione np.dot() oppure l’operatore @:\n\nv2 = np.array([4, 5, 6])\n\n# Prodotto interno usando np.dot()\nprodotto_interno = np.dot(v, v2)\nprint(prodotto_interno)\n\n# Prodotto interno usando l'operatore @\nprodotto_interno2 = v @ v2\nprint(prodotto_interno2)\n\n32\n32\n\n\nEntrambi i metodi daranno il risultato 32, dato che il prodotto interno è calcolato come \\(1*4 + 2*5 + 3*6 = 32\\).\nIl prodotto esterno tra due vettori produce una matrice dove ogni elemento è il prodotto degli elementi dei due vettori. In NumPy, si utilizza la funzione np.outer():\n\n# Prodotto esterno\nprodotto_esterno = np.outer(v, v2)\nprint(prodotto_esterno)\n\n[[ 4  5  6]\n [ 8 10 12]\n [12 15 18]]\n\n\nOgni elemento di questa matrice è il risultato della moltiplicazione degli elementi corrispondenti dei due vettori.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#matrici",
    "href": "chapters/linear_models/08_linear_algebra.html#matrici",
    "title": "77  Elementi di algebra lineare",
    "section": "77.6 Matrici",
    "text": "77.6 Matrici\nUna matrice è una struttura matematica bidimensionale costituita da elementi disposti in righe e colonne. Formalmente, una matrice \\(\\mathbf{A}\\) di dimensioni \\(m \\times n\\) (si legge “m per n”) è un array rettangolare di numeri reali o complessi, denotato come:\n\\[ \\mathbf{A} = (a_{ij})_{m \\times n} = \\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{bmatrix} \\]\ndove \\(a_{ij}\\) rappresenta l’elemento nella \\(i\\)-esima riga e \\(j\\)-esima colonna della matrice.\nLe matrici sono comunemente indicate con lettere maiuscole in grassetto, come \\(\\mathbf{A}\\), \\(\\mathbf{B}\\), \\(\\mathbf{C}\\), etc. Una matrice con \\(m\\) righe e \\(n\\) colonne si dice di ordine \\(m \\times n\\).\nIn molte matrici di dati, ogni elemento \\(a_{ij}\\) è uno scalare che rappresenta il valore della \\(j\\)-esima variabile del \\(i\\)-esimo campione. Formalmente, possiamo indicare \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\), il che significa che la matrice \\(\\mathbf{A}\\) ha \\(m\\) righe e \\(n\\) colonne. Si dice comunemente che la “dimensione” di \\(\\mathbf{A}\\) è \\(m \\times n\\).\n\n77.6.1 Matrici come Collezioni di Vettori Colonna\nLe matrici possono essere interpretate come collezioni di vettori colonna. Ad esempio, una matrice di dati può essere rappresentata come:\n\\[\n\\mathbf{A} = \\begin{bmatrix} \\mathbf{a}_1 & \\mathbf{a}_2 & \\cdots & \\mathbf{a}_n \\end{bmatrix}\n\\]\nIn questo caso, \\(\\mathbf{A}\\) è composta da una sequenza di \\(n\\) vettori colonna \\(\\mathbf{a}_1, \\mathbf{a}_2, \\ldots, \\mathbf{a}_n\\), ciascuno dei quali è un vettore di dimensione \\(m\\). Più precisamente, ogni vettore colonna \\(\\mathbf{a}_j\\) rappresenta i dati di tutti i campioni per la \\(j\\)-esima variabile o feature.\n\n\n77.6.2 Matrici come Collezioni di Vettori Riga\nIn alternativa, una matrice può essere vista come una collezione di vettori riga. In questo contesto, ogni riga di \\(\\mathbf{A}\\) rappresenta tutte le variabili misurate per un dato campione:\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n\\mathbf{a}_1^T \\\\\n\\mathbf{a}_2^T \\\\\n\\vdots \\\\\n\\mathbf{a}_m^T\n\\end{bmatrix}\n\\]\nQui, la matrice \\(\\mathbf{A}\\) è composta da \\(m\\) vettori riga, denotati come \\(\\mathbf{a}_i^T\\). Ognuno di questi vettori riga \\(\\mathbf{a}_i^T\\) è di dimensione \\(n\\), indicando che ciascun campione ha \\(n\\) variabili o feature associate.\n\n\n77.6.3 Trasposta di una Matrice\nIl simbolo \\(T\\) rappresenta la trasposta di una matrice. La trasposta di una matrice, denotata con un apice \\(T\\) (es. \\(\\mathbf{A}^T\\)), è un’operazione che trasforma ciascuna delle righe di \\(\\mathbf{A}\\) in colonne di \\(\\mathbf{A}^T\\). In altre parole, se \\(\\mathbf{A}\\) ha dimensione \\(m \\times n\\), allora \\(\\mathbf{A}^T\\) avrà dimensione \\(n \\times m\\):\n\\[\n\\mathbf{A}^T = \\begin{bmatrix}\na_{11} & a_{21} & \\cdots & a_{m1} \\\\\na_{12} & a_{22} & \\cdots & a_{m2} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\cdots & a_{mn}\n\\end{bmatrix}\n\\]\nCon la trasposta, le variabili misurate diventano colonne e i campioni diventano righe. Essenzialmente, i vettori riga sono le trasposte dei vettori colonna. Questo concetto è molto utile in algebra lineare, poiché permette di passare facilmente da una rappresentazione dei dati a un’altra.\nIn NumPy, una matrice è semplicemente un array bidimensionale. Per esempio, possiamo creare una matrice 3x4 utilizzando la funzione np.array() e fornendo una lista di liste (dove ogni lista interna rappresenta una riga della matrice).\nEcco come definire una matrice 3x4:\n\n# Definizione della matrice 3x4\nM = np.array([\n    [1, 2, 3, 4], \n    [5, 6, 7, 8], \n    [9, 10, 11, 12]\n    ])\nprint(M)\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n\nIn NumPy, puoi calcolare la trasposta di una matrice utilizzando l’attributo .T o la funzione np.transpose().\n\n# Calcolo della trasposta\ntrasposta = M.T\n\nprint(\"\\nTrasposta della matrice:\")\nprint(trasposta)\n\n\nTrasposta della matrice:\n[[ 1  5  9]\n [ 2  6 10]\n [ 3  7 11]\n [ 4  8 12]]",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#moltiplicazione-tra-matrici",
    "href": "chapters/linear_models/08_linear_algebra.html#moltiplicazione-tra-matrici",
    "title": "77  Elementi di algebra lineare",
    "section": "77.7 Moltiplicazione tra Matrici",
    "text": "77.7 Moltiplicazione tra Matrici\nLa moltiplicazione tra matrici è un’operazione fondamentale nell’algebra lineare. Per poter moltiplicare due matrici, è necessario che siano conformabili, il che significa che il numero di colonne della prima matrice deve essere uguale al numero di righe della seconda matrice.\nSe abbiamo una matrice \\(\\mathbf{A}\\) di dimensioni \\(m \\times n\\) (cioè, \\(m\\) righe e \\(n\\) colonne) e una matrice \\(\\mathbf{B}\\) di dimensioni \\(n \\times p\\) (cioè, \\(n\\) righe e \\(p\\) colonne), allora il prodotto delle due matrici \\(\\mathbf{A} \\mathbf{B}\\) sarà una matrice \\(\\mathbf{C}\\) di dimensioni \\(m \\times p\\).\nIl prodotto tra due matrici \\(\\mathbf{A}\\) e \\(\\mathbf{B}\\) si ottiene calcolando il prodotto interno tra le righe della prima matrice e le colonne della seconda matrice.\nPer ciascun elemento \\(c_{ij}\\) della matrice risultante \\(\\mathbf{C}\\), si esegue il seguente calcolo:\n\\[\nc_{ij} = \\sum_{k=1}^{n} a_{ik} b_{kj}.\n\\]\nQuesto significa che l’elemento \\(c_{ij}\\) è il risultato del prodotto interno tra la \\(i\\)-esima riga della matrice \\(\\mathbf{A}\\) e la \\(j\\)-esima colonna della matrice \\(\\mathbf{B}\\).\nLa moltiplicazione di una matrice per un vettore è un caso particolare della moltiplicazione tra matrici, dove il vettore può essere visto come una matrice con una delle dimensioni uguale a 1.\nSe \\(\\mathbf{A}\\) è una matrice \\(m \\times n\\) e \\(\\mathbf{x}\\) è un vettore di dimensione \\(n\\) (cioè una matrice di dimensione \\(n \\times 1\\)), allora il prodotto \\(\\mathbf{A} \\mathbf{x}\\) è un vettore di dimensione \\(m\\). Ogni elemento del vettore risultante è il prodotto interno tra una riga della matrice \\(\\mathbf{A}\\) e il vettore \\(\\mathbf{x}\\).\nConsideriamo le seguenti matrici:\n\\[\n\\mathbf{A} = \\begin{bmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{bmatrix}, \\quad \\mathbf{B} = \\begin{bmatrix}\n7 & 8 \\\\\n9 & 10 \\\\\n11 & 12\n\\end{bmatrix}\n\\]\n\n\\(\\mathbf{A}\\) è una matrice \\(2 \\times 3\\).\n\\(\\mathbf{B}\\) è una matrice \\(3 \\times 2\\).\n\nIl prodotto \\(\\mathbf{A} \\mathbf{B}\\) è una matrice \\(2 \\times 2\\) calcolata come segue:\n\\[\n\\mathbf{C} = \\mathbf{A} \\mathbf{B} = \\begin{bmatrix}\n(1 \\cdot 7 + 2 \\cdot 9 + 3 \\cdot 11) & (1 \\cdot 8 + 2 \\cdot 10 + 3 \\cdot 12) \\\\\n(4 \\cdot 7 + 5 \\cdot 9 + 6 \\cdot 11) & (4 \\cdot 8 + 5 \\cdot 10 + 6 \\cdot 12)\n\\end{bmatrix}\n\\]\nCalcolando ogni elemento:\n\\[\n\\mathbf{C} = \\begin{bmatrix}\n58 & 64 \\\\\n139 & 154\n\\end{bmatrix}\n\\]\nIn questo esempio, ogni elemento della matrice risultante \\(\\mathbf{C}\\) è stato ottenuto calcolando il prodotto interno tra le righe di \\(\\mathbf{A}\\) e le colonne di \\(\\mathbf{B}\\).\nSvolgiamo ora i calcoli usando NumPy.\n\n# Definizione della matrice A (2x3)\nA = np.array([[1, 2, 3], [4, 5, 6]])\n\n# Definizione della matrice B (3x2)\nB = np.array([[7, 8], [9, 10], [11, 12]])\n\n# Calcolo del prodotto A * B usando np.dot()\nprodotto_AB = np.dot(A, B)\nprint(\"\\nProdotto A * B usando np.dot():\")\nprint(prodotto_AB)\n\n# Calcolo del prodotto A * B usando l'operatore @\nprodotto_AB_operator = A @ B\nprint(\"\\nProdotto A * B usando l'operatore @:\")\nprint(prodotto_AB_operator)\n\n\nProdotto A * B usando np.dot():\n[[ 58  64]\n [139 154]]\n\nProdotto A * B usando l'operatore @:\n[[ 58  64]\n [139 154]]\n\n\n\n77.7.1 Matrice Identità e Matrice Inversa\n\n\n77.7.2 Matrice Identità\nLa matrice identità, denotata come \\(\\mathbf{I}_n\\), è una matrice quadrata di dimensione \\(n \\times n\\) con tutti gli elementi sulla diagonale principale uguali a 1 e tutti gli altri elementi uguali a 0. Ad esempio, una matrice identità 3x3 è:\n\\[\n\\mathbf{I}_3 = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]\nIn generale, una matrice identità di dimensione \\(n \\times n\\) è:\n\\[\n\\mathbf{I}_n = \\begin{bmatrix}\n1 & 0 & \\cdots & 0 \\\\\n0 & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & 1\n\\end{bmatrix}\n\\]\nLa matrice identità ha la proprietà fondamentale di essere l’elemento neutro per la moltiplicazione matriciale. Per qualsiasi matrice \\(\\mathbf{A}\\) di dimensioni \\(n \\times n\\):\n\\[\n\\mathbf{A} \\mathbf{I}_n = \\mathbf{A} \\quad \\text{e} \\quad \\mathbf{I}_n \\mathbf{A} = \\mathbf{A}.\n\\]\nIn NumPy, per creare la matrice identià usiamo il modulo .eye(). Per esempio:\n\nI = np.eye(3)\nprint(I)\n\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n\n\n\n\n77.7.3 Determinante di una Matrice\nIl determinante è un numero associato a una matrice quadrata che fornisce informazioni essenziali sulle proprietà della matrice stessa. È uno scalare che può indicare se una matrice è invertibile, se un sistema di equazioni lineari ha una soluzione unica, e molto altro.\nIl determinante di una matrice può essere interpretato in diversi modi:\n\nIn termini geometrici, il determinante di una matrice \\(2 \\times 2\\) o \\(3 \\times 3\\) rappresenta rispettivamente l’area o il volume del parallelogramma o del parallelepipedo definito dai vettori delle righe (o colonne) della matrice. Un determinante pari a zero indica che i vettori sono linearmente dipendenti e che l’area o il volume è nullo, suggerendo che la matrice non ha un’inversa.\nAlgebraicamente, il determinante di una matrice quadrata può dirci se la matrice è invertibile. Se il determinante è diverso da zero, la matrice è invertibile, cioè esiste una matrice inversa tale che il prodotto delle due sia la matrice identità. Se il determinante è zero, la matrice non è invertibile.\nNel contesto dei sistemi di equazioni lineari, se il determinante del coefficiente della matrice associata a un sistema è zero, il sistema può non avere soluzioni o avere un numero infinito di soluzioni. Se è diverso da zero, il sistema ha una soluzione unica.\n\n\n77.7.3.1 Calcolo del Determinante per una Matrice 2x2\nPer una matrice \\(2 \\times 2\\):\n\\[\n\\mathbf{A} = \\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\n\\]\nil determinante è calcolato come:\n\\[\n\\det(\\mathbf{A}) = ad - bc\n\\]\nQuesto semplice calcolo deriva dalla differenza tra il prodotto degli elementi della diagonale principale (dall’angolo superiore sinistro all’angolo inferiore destro) e il prodotto degli elementi della diagonale secondaria (dall’angolo superiore destro all’angolo inferiore sinistro).\n\n\n77.7.3.2 Calcolo del Determinante per Matrici di Dimensioni Superiori\nPer matrici di dimensioni superiori a \\(2 \\times 2\\), il calcolo del determinante diventa più complesso. Un metodo comune per calcolare il determinante di matrici più grandi è l’espansione di Laplace o espansione per cofattori. Questo metodo si basa sulla ricorsione, calcolando il determinante attraverso una somma pesata di determinanti di matrici più piccole (minori) che si ottengono eliminando una riga e una colonna dalla matrice originale.\n\n\n77.7.3.3 Calcolo del Determinante con NumPy\nÈ possibile calcolare il determinante di una matrice utilizzando la funzione np.linalg.det(). Questa funzione può essere utilizzata per calcolare il determinante di matrici quadrate di qualsiasi dimensione.\nEcco come calcolare il determinante di una matrice \\(2 \\times 2\\) con NumPy:\n\n# Definizione di una matrice 2x2\nA = np.array([[1, 2], [3, 4]])\n\n# Calcolo del determinante\ndeterminante = np.linalg.det(A)\nprint(\"Determinante di A:\", determinante)\n\nDeterminante di A: -2.0000000000000004\n\n\nPer una matrice \\(3 \\times 3\\) o di dimensioni superiori, il procedimento è lo stesso:\n\n# Definizione di una matrice 3x3\nB = np.array([[6, 1, 1], [4, -2, 5], [2, 8, 7]])\n\n# Calcolo del determinante\ndeterminante_B = np.linalg.det(B)\nprint(\"Determinante di B:\", determinante_B)\n\nDeterminante di B: -306.0\n\n\nIn conclusione, il determinante è uno strumento fondamentale per la comprensione delle proprietà di una matrice. Attraverso il determinante, è possibile comprendere la geometria della trasformazione rappresentata dalla matrice, verificare l’invertibilità e determinare il comportamento di sistemi di equazioni lineari.\n\n\n\n77.7.4 Inversa di una Matrice\nL’inversa di una matrice quadrata \\(\\mathbf{A}\\), denotata come \\(\\mathbf{A}^{-1}\\), è una matrice che, moltiplicata per \\(\\mathbf{A}\\), restituisce la matrice identità \\(\\mathbf{I}_n\\). L’inversa di una matrice esiste solo per matrici quadrate non singolari, ovvero matrici il cui determinante è diverso da zero.\nLa proprietà fondamentale dell’inversa è:\n\\[\n\\mathbf{A} \\mathbf{A}^{-1} = \\mathbf{I}_n \\quad \\text{e} \\quad \\mathbf{A}^{-1} \\mathbf{A} = \\mathbf{I}_n.\n\\]\ndove \\(\\mathbf{I}_n\\) è la matrice identità di dimensione \\(n \\times n\\).\n\n77.7.4.1 Esempio: Calcolo dell’Inversa di una Matrice \\(2 \\times 2\\)\nPer una matrice \\(2 \\times 2\\):\n\\[\n\\mathbf{A} = \\begin{bmatrix}\na & b \\\\\nc & d\n\\end{bmatrix}\n\\]\nl’inversa, se esiste, è data dalla formula:\n\\[\n\\mathbf{A}^{-1} = \\frac{1}{ad-bc} \\begin{bmatrix}\nd & -b \\\\\n-c & a\n\\end{bmatrix}\n\\]\ndove \\(ad-bc\\) è il determinante della matrice \\(\\mathbf{A}\\). L’inversa esiste solo se questo determinante è diverso da zero (cioè, se \\(\\mathbf{A}\\) è non singolare).\n\n\n\n77.7.5 Utilizzo dell’Inversa di una Matrice\nL’inversa di una matrice è particolarmente utile per risolvere sistemi di equazioni lineari. Ad esempio, consideriamo un sistema rappresentato in forma matriciale come \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\), dove \\(\\mathbf{A}\\) è la matrice dei coefficienti, \\(\\mathbf{x}\\) è il vettore delle variabili incognite e \\(\\mathbf{b}\\) è il vettore dei termini noti.\nSe \\(\\mathbf{A}\\) è una matrice invertibile, possiamo risolvere per \\(\\mathbf{x}\\) moltiplicando entrambi i lati dell’equazione per \\(\\mathbf{A}^{-1}\\):\n\\[\n\\mathbf{A}^{-1} \\mathbf{A} \\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}.\n\\]\nPoiché \\(\\mathbf{A}^{-1} \\mathbf{A} = \\mathbf{I}\\), otteniamo:\n\\[\n\\mathbf{I} \\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b},\n\\]\n\\[\n\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}.\n\\]\nQuesta proprietà è utile anche per altre applicazioni, come nella derivazione della formula per i coefficienti della regressione lineare.\n\n\n77.7.6 Calcolo dell’Inversa con NumPy\nIn Python, possiamo usare la libreria NumPy per calcolare l’inversa di una matrice in modo semplice ed efficiente. La funzione np.linalg.inv() permette di calcolare l’inversa di una matrice quadrata, a condizione che sia invertibile (cioè, il suo determinante non è zero).\nEcco come calcolare l’inversa di una matrice \\(2 \\times 2\\) utilizzando NumPy:\n\n# Definizione di una matrice 2x2\nA = np.array([[1, 2], [3, 4]])\n\n# Calcolo dell'inversa\nA_inv = np.linalg.inv(A)\nprint(\"Inversa di A:\")\nprint(A_inv)\n\nInversa di A:\n[[-2.   1. ]\n [ 1.5 -0.5]]\n\n\nPer verificare che il calcolo dell’inversa sia corretto, possiamo moltiplicare la matrice originale \\(\\mathbf{A}\\) per la sua inversa \\(\\mathbf{A}^{-1}\\) e verificare che il risultato sia la matrice identità:\n\n# Verifica del calcolo dell'inversa\nidentita = np.dot(A, A_inv)\nprint(\"Prodotto di A e A_inv (matrice identità):\")\nprint(identita)\n\nProdotto di A e A_inv (matrice identità):\n[[1.0000000e+00 0.0000000e+00]\n [8.8817842e-16 1.0000000e+00]]\n\n\nIn conclusione, l’inversa di una matrice è uno strumento utile per risolvere sistemi di equazioni lineari e molte altre applicazioni. Con NumPy, calcolare l’inversa di una matrice è semplice e veloce, permettendo di eseguire operazioni complesse in modo efficiente. Tuttavia, è importante ricordare che non tutte le matrici hanno un’inversa; una matrice deve essere quadrata e avere un determinante diverso da zero per essere invertibile.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#regressione-lineare-e-stima-dei-coefficienti",
    "href": "chapters/linear_models/08_linear_algebra.html#regressione-lineare-e-stima-dei-coefficienti",
    "title": "77  Elementi di algebra lineare",
    "section": "77.8 Regressione Lineare e Stima dei Coefficienti",
    "text": "77.8 Regressione Lineare e Stima dei Coefficienti\nLa regressione lineare è una tecnica statistica utilizzata per modellare la relazione tra una variabile dipendente (o risposta) e una o più variabili indipendenti (o predittori). È possibile rappresentare questo modello in termini di algebra matriciale per semplificare il calcolo dei coefficienti.\n\n77.8.1 Regressione Lineare Semplice\nLa regressione lineare semplice descrive una relazione lineare tra una variabile indipendente \\(x\\) e una variabile dipendente \\(y\\). Quando abbiamo un campione di \\(n\\) osservazioni, il modello assume la seguente forma:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + e_i, \\quad \\text{per} \\; i = 1, 2, \\ldots, n,\n\\]\ndove:\n\n\\(y_i\\) è il valore osservato della variabile dipendente per l’osservazione \\(i\\),\n\\(\\beta_0\\) è l’intercetta, che rappresenta il valore di \\(y\\) quando \\(x = 0\\),\n\\(\\beta_1\\) è il coefficiente di regressione, che indica quanto varia \\(y\\) per una variazione unitaria di \\(x\\),\n\\(x_i\\) è il valore della variabile indipendente per l’osservazione \\(i\\),\n\\(e_i\\) è l’errore o residuo per l’osservazione \\(i\\), rappresenta la differenza tra il valore osservato \\(y_i\\) e il valore previsto \\(\\hat{y}_i = \\beta_0 + \\beta_1 x_i\\).\n\nPer un campione di \\(n\\) osservazioni, possiamo rappresentare la regressione lineare in forma matriciale, che rende il modello più compatto e facilita i calcoli statistici. La rappresentazione matriciale del modello di regressione lineare è:\n\\[\n\\mathbf{y} = \\mathbf{Xb} + \\mathbf{e},\n\\]\ndove:\n\n\\(\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\) è il vettore delle osservazioni della variabile dipendente,\n\\(\\mathbf{X} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix}\\) è la matrice di design, in cui la prima colonna è costituita da 1 per includere l’intercetta \\(\\beta_0\\),\n\\(\\mathbf{b} = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\end{bmatrix}\\) è il vettore dei coefficienti del modello,\n\\(\\mathbf{e} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\) è il vettore degli errori o residui.\n\nQuesta forma matriciale sintetizza tutte le \\(n\\) equazioni del modello di regressione lineare semplice in un’unica espressione compatta, che rappresenta la relazione tra le osservazioni della variabile dipendente \\(y\\) e le corrispondenti osservazioni della variabile indipendente \\(x\\), tenendo conto degli errori di previsione.\n\n\n77.8.2 Regressione Lineare Multipla\nLa regressione lineare multipla estende la regressione lineare semplice includendo più variabili indipendenti, consentendo di modellare la relazione tra una variabile dipendente e diverse variabili indipendenti. Il modello di regressione lineare multipla per un campione di \\(n\\) osservazioni con \\(p\\) variabili indipendenti può essere scritto come:\n\\[\ny_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} + e_i, \\quad \\text{per} \\; i = 1, 2, \\ldots, n,\n\\]\ndove:\n\n\\(y_i\\) è il valore osservato della variabile dipendente per l’osservazione \\(i\\),\n\\(\\beta_0\\) è l’intercetta del modello,\n\\(\\beta_1, \\beta_2, \\ldots, \\beta_p\\) sono i coefficienti di regressione associati alle variabili indipendenti,\n\\(x_{i1}, x_{i2}, \\ldots, x_{ip}\\) sono i valori delle variabili indipendenti per l’osservazione \\(i\\),\n\\(e_i\\) è l’errore o residuo per l’osservazione \\(i\\), che rappresenta la differenza tra il valore osservato \\(y_i\\) e il valore previsto \\(\\hat{y}_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip}\\).\n\nIn termini matriciali, il modello di regressione lineare multipla può essere scritto come:\n\\[\n\\mathbf{y} = \\mathbf{Xb} + \\mathbf{e},\n\\]\ndove:\n\n\\(\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\) è il vettore delle osservazioni della variabile dipendente, di dimensione \\(n \\times 1\\),\n\\(\\mathbf{X} = \\begin{bmatrix} 1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\ 1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{n1} & x_{n2} & \\cdots & x_{np} \\end{bmatrix}\\) è la matrice di design, di dimensione \\(n \\times (p+1)\\), dove la prima colonna è composta da 1 per includere l’intercetta \\(\\beta_0\\),\n\\(\\mathbf{b} = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix}\\) è il vettore dei coefficienti, di dimensione \\((p+1) \\times 1\\),\n\\(\\mathbf{e} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\) è il vettore degli errori o residui, di dimensione \\(n \\times 1\\).\n\nL’equazione in forma matriciale esplicita per il campione di \\(n\\) osservazioni con \\(p\\) variabili indipendenti è:\n\\[\n\\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & x_{11} & x_{12} & \\cdots & x_{1p} \\\\\n1 & x_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & x_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{bmatrix} +\n\\begin{bmatrix}\ne_1 \\\\\ne_2 \\\\\n\\vdots \\\\\ne_n\n\\end{bmatrix}.\n\\]\nIn questa rappresentazione:\n\nIl prodotto \\(\\mathbf{Xb}\\) rappresenta i valori previsti (o stimati) del modello come combinazione lineare delle colonne della matrice di design \\(\\mathbf{X}\\), ponderata dai coefficienti \\(\\mathbf{b}\\).\nIl vettore \\(\\mathbf{e}\\) rappresenta gli errori o residui, che sono le differenze tra i valori osservati \\(\\mathbf{y}\\) e i valori previsti \\(\\mathbf{Xb}\\).\n\nQuesta forma compatta e ordinata consente un’efficiente analisi statistica e facilita i calcoli necessari per stimare i coefficienti del modello di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#stima-dei-coefficienti-con-il-metodo-dei-minimi-quadrati",
    "href": "chapters/linear_models/08_linear_algebra.html#stima-dei-coefficienti-con-il-metodo-dei-minimi-quadrati",
    "title": "77  Elementi di algebra lineare",
    "section": "77.9 Stima dei Coefficienti con il Metodo dei Minimi Quadrati",
    "text": "77.9 Stima dei Coefficienti con il Metodo dei Minimi Quadrati\nPer ogni osservazione \\(i\\), l’errore (o residuo) è definito come la differenza tra il valore osservato \\(y_i\\) e il valore predetto \\(\\hat{y}_i\\) dal modello:\n\\[\ne_i = y_i - \\hat{y}_i,\n\\]\ndove:\n\n\\(y_i\\) è il valore osservato dell’output per l’osservazione \\(i\\),\n\\(\\hat{y}_i\\) è il valore predetto dal modello per l’osservazione \\(i\\).\n\nIn forma matriciale, possiamo rappresentare l’errore per tutte le \\(n\\) osservazioni come segue:\n\\[\n\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}},\n\\]\ndove:\n\n\\(\\mathbf{e} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}\\) è il vettore degli errori o residui,\n\\(\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}\\) è il vettore delle osservazioni della variabile dipendente,\n\\(\\hat{\\mathbf{y}} = \\begin{bmatrix} \\hat{y}_1 \\\\ \\hat{y}_2 \\\\ \\vdots \\\\ \\hat{y}_n \\end{bmatrix} = \\mathbf{Xb}\\) è il vettore dei valori predetti dal modello.\n\nL’equazione matriciale esplicita per il vettore degli errori \\(\\mathbf{e}\\) è quindi:\n\\[\n\\mathbf{e} = \\mathbf{y} - \\mathbf{Xb}.\n\\]\nQuesta equazione mostra che il vettore degli errori \\(\\mathbf{e}\\) è la differenza tra il vettore delle osservazioni \\(\\mathbf{y}\\) e il vettore dei valori predetti \\(\\hat{\\mathbf{y}} = \\mathbf{Xb}\\). In altre parole, ogni elemento \\(e_i\\) del vettore degli errori rappresenta la differenza tra il valore osservato \\(y_i\\) e il valore predetto \\(\\hat{y}_i\\) per l’osservazione \\(i\\).\nL’obiettivo della regressione lineare è minimizzare la somma degli errori quadrati (\\(SSE\\), Sum of Squared Errors) per tutte le osservazioni. Questa somma è data da:\n\\[\n\\text{SSE} = \\sum_{i=1}^m e_i^2 = \\sum_{i=1}^m (y_i - \\hat{y}_i)^2.\n\\]\nUtilizzando la notazione matriciale, possiamo esprimere la somma degli errori quadrati come:\n\\[\n\\text{SSE} = \\mathbf{e}^T \\mathbf{e} = (\\mathbf{y} - \\mathbf{X} \\mathbf{b})^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}).\n\\]\nIl problema di ottimizzazione per minimizzare la somma degli errori quadrati si traduce in:\n\\[\n\\min_{\\mathbf{b}} (\\mathbf{y} - \\mathbf{X} \\mathbf{b})^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}),\n\\]\ndove:\n\n\\(\\mathbf{b}\\) è il vettore dei coefficienti da stimare.\n\\(\\mathbf{X}\\) è la matrice di design che include tutte le osservazioni delle variabili indipendenti.\n\\(\\mathbf{y}\\) è il vettore delle osservazioni della variabile dipendente.\n\nPer trovare i coefficienti ottimali \\(\\mathbf{b}\\), calcoliamo la derivata parziale dell’errore quadratico totale rispetto a \\(\\mathbf{b}\\) e la impostiamo a zero:\n\\[\n\\frac{\\partial}{\\partial \\mathbf{b}} (\\mathbf{y} - \\mathbf{X} \\mathbf{b})^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}) = -2 \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}).\n\\]\nImpostando questa derivata uguale a zero, otteniamo:\n\\[\n-2 \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X} \\mathbf{b}) = 0.\n\\]\nSemplificando, possiamo riscrivere l’equazione come:\n\\[\n\\mathbf{X}^T \\mathbf{y} = \\mathbf{X}^T \\mathbf{X} \\mathbf{b}.\n\\]\nAssumendo che la matrice \\(\\mathbf{X}^T \\mathbf{X}\\) sia invertibile, risolviamo per \\(\\mathbf{b}\\):\n\\[\n\\mathbf{b} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}.\n\\]\nPer gli scopi presenti, non è necessario comprendere la derivazione formale in dettaglio. Tuttavia, possiamo fare un parallelo con il metodo dei minimi quadrati per il caso univariato per ottenere un’intuizione geometrica su cosa stiamo facendo.\nNel caso della regressione lineare semplice (univariata), minimizzare la somma degli errori quadrati significa trovare la retta che meglio si adatta ai dati in uno spazio bidimensionale (2D). Dal punto di vista geometrico, questo processo equivale a calcolare la derivata della funzione di errore rispetto ai coefficienti della retta, quindi impostando la derivata a zero per trovare il punto in cui la pendenza della tangente è piatta. In altre parole, cerchiamo il punto in cui la pendenza della funzione di errore è zero, che corrisponde a un minimo della funzione.\nNel caso della regressione lineare multipla, invece di lavorare in uno spazio bidimensionale, stiamo operando in uno spazio multidimensionale. Ogni dimensione aggiuntiva rappresenta una variabile indipendente (regressore) nel nostro modello. Quando prendiamo la derivata dell’errore quadratico totale rispetto ai coefficienti \\(\\mathbf{b}\\) e la impostiamo a zero, stiamo essenzialmente cercando il punto in questo spazio multidimensionale in cui tutte le “pendenze” (derivate parziali) sono zero. Questo punto rappresenta il minimo dell’errore quadratico totale e corrisponde alla migliore stima dei coefficienti del nostro modello di regressione lineare, minimizzando l’errore di previsione su tutti i dati.\nQuindi, mentre nel caso univariato minimizzare l’errore quadratico trova la migliore linea retta che si adatta ai dati in 2D, nel caso multivariato troviamo il miglior piano o iperpiano che si adatta ai dati in uno spazio di dimensioni superiori.\n\n77.9.1 Stima dei Coefficienti OLS\nQuesta formula:\n\\[\n\\mathbf{b} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}\n\\]\nè conosciuta come stima dei minimi quadrati ordinari (Ordinary Least Squares, OLS) per i coefficienti della regressione lineare multivariata. Essa fornisce i valori dei coefficienti \\(\\mathbf{b}\\) che minimizzano la somma degli errori quadrati e, quindi, rappresenta la migliore approssimazione lineare dei dati osservati.\nPer fare un esempio, consideriamo un piccolo insieme di dati nel caso della regressione bivariata e implementiamo la formula precedente in NumPy per trovare i coefficienti dei minimi quadrati.\n\n# Simulazione di una regressione lineare semplice\n\n# Scegli valori casuali per b_0 e b_1\nb = np.array([3.4, 12.35])  # pendenza e intercetta\nb = b[:, np.newaxis]\n\n# Simula n punti dati. x è distribuito normalmente\nn = 30\ndata_mean = 0\ndata_std = 1\ndata = np.random.normal(\n    data_mean, data_std, size=(n, 1)\n)  # rendi l'array 2D per semplificare\n\n# Poiché abbiamo b_0 nel nostro vettore dei pesi, aggiungiamo una colonna di 1s alla nostra matrice di dati\nones = np.ones((n, 1))\nx = np.hstack((ones, data))  # x è la nostra matrice di design\n\n# Aggiungi rumore gaussiano\nnoise_loc = 0\nnoise_scale = 5\ne = np.random.normal(loc=noise_loc, scale=noise_scale, size=(n, 1))\n\n# Simula i valori di y\ny = x.dot(b) + e\n\n# Calcola le stime per b, le predizioni\nb_hat = np.linalg.inv(x.T @ x) @ x.T @ y\n\nprint(\"Valori veri di b:\\n\", b)\nprint(\"La nostra stima:\\n\", b_hat)\n\nValori veri di b:\n [[ 3.4 ]\n [12.35]]\nLa nostra stima:\n [[ 2.06167676]\n [12.96660755]]\n\n\nUtilizziamo i coefficienti dei minimi quadrati per calcolare i valori predetti e il coefficiente di determinazione.\n\ny_hat = x.dot(b_hat)\n\n# Calcola R^2\nSS_res = e.T @ e\nstd = y - y.mean()\nSS_tot = std.T @ std\nr2 = 1 - (SS_res / SS_tot)\n\nprint(r2)\n\n[[0.85247043]]\n\n\nRappresentiamo ora i valori predetti con la retta di regressione sovrapposta al diagramma a dispersione del campione dei dati.\n\n# Grafico dei dati\nfig, ax = plt.subplots()\nax.scatter(data, y)  # Tracciamento dei dati\nax.set(xlabel=\"x\", ylabel=\"y\", title=\"Regressione lineare semplice\")\n\n# Traccia la linea vera\nb_0, b_1 = b\nax.plot(data, b_0 + (b_1 * data), color=\"k\", label=\"Valore reale\")\n\n# Traccia il nostro fit\nax.plot(data, y_hat, color=\"r\", label=\"Il nostro fit\")\n_ = ax.legend()\n\n\n\n\n\n\n\n\nReplichiamo i risultati usando pingouin:\n\ny = np.array(y).flatten()\nlm = pg.linear_regression(x, y)\nlm.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n2.06\n1.02\n2.02\n0.05\n0.86\n0.86\n-0.03\n4.16\n\n\n1\nx2\n12.97\n0.98\n13.29\n0.00\n0.86\n0.86\n10.97\n14.97",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/08_linear_algebra.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/08_linear_algebra.html#informazioni-sullambiente-di-sviluppo",
    "title": "77  Elementi di algebra lineare",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Aug 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>Elementi di algebra lineare</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html",
    "href": "chapters/linear_models/09_stan_multreg.html",
    "title": "78  Il modello di regressione multipla",
    "section": "",
    "text": "Introduzione\nIn questo capitolo introdurremo il modello di regressione multipla mostrando come possa essere implementato in Stan. Ci concentreremo sull’interpretazione dei coefficienti parziali di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#regressione-multipla",
    "href": "chapters/linear_models/09_stan_multreg.html#regressione-multipla",
    "title": "78  Il modello di regressione multipla",
    "section": "78.1 Regressione multipla",
    "text": "78.1 Regressione multipla\nLa regressione multipla rappresenta un’estensione del modello di regressione semplice, e permette di esplorare e quantificare le relazioni tra una variabile dipendente e più variabili indipendenti.\nUn modello lineare univariato può essere descritto, in forma matriciale, come\n\\[\n\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon},\n\\tag{78.1}\\]\ndove \\(\\mathbf{y} \\in \\mathbb{R}^n\\) è il vettore delle variabili di risposta, \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times p}\\) è la matrice delle costanti note, \\(\\boldsymbol{\\beta} \\in \\mathbb{R}^p\\) è il vettore dei parametri sconosciuti, e \\(\\boldsymbol{\\epsilon} \\in \\mathbb{R}^n\\) è il vettore degli errori casuali non osservabili. Espanso in forma completa, il modello dell’Equazione 78.1 può essere espresso come\n\\[\n\\begin{pmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_n\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nx_{11} & x_{12} & \\cdots & x_{1p} \\\\\nx_{21} & x_{22} & \\cdots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2} & \\cdots & x_{np}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\vdots \\\\\n\\beta_p\n\\end{pmatrix}\n+\n\\begin{pmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{pmatrix},\n\\tag{78.2}\\]\ndove la prima colonna di \\(\\mathbf{X}\\) è spesso un vettore di uno, denotato \\(\\mathbf{1}_n\\). Il modello dell’Equazione 78.2 esprime ciascuna delle \\(n\\) osservazioni in \\(\\mathbf{y}\\) come una combinazione lineare dei parametri sconosciuti in \\(\\boldsymbol{\\beta}\\) con coefficienti da \\(\\mathbf{X}\\), cioè,\n\\[ y_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta} + \\epsilon_i = \\sum_{j=1}^p x_{ij} \\beta_j + \\epsilon_i, \\]\nper \\(i = 1, \\ldots, n\\), dove \\(\\mathbf{x}_i \\in \\mathbb{R}^p\\) è l’ennesima riga di \\(\\mathbf{X}\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#interpretazione",
    "href": "chapters/linear_models/09_stan_multreg.html#interpretazione",
    "title": "78  Il modello di regressione multipla",
    "section": "78.2 Interpretazione",
    "text": "78.2 Interpretazione\nPassando dal modello semplice \\(y = a + bx + \\text{errore}\\) al modello più generale \\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\text{errore}\\), emergono nuove complessità. Queste includono le decisioni su quali predittori \\(x\\) includere nel modello, l’interpretazione dei coefficienti e delle loro interazioni, e la costruzione di nuovi predittori a partire dalle variabili esistenti per catturare elementi di discrezionalità e non linearità.\nI coefficienti di regressione, in un contesto di regressione multipla, sono tipicamente più complicati da interpretare rispetto a quelli di un modello con un solo predittore. L’interpretazione di un dato coefficiente, infatti, è parzialmente condizionata dalle altre variabili presenti nel modello. Il coefficiente \\(\\beta_k\\) rappresenta la differenza media o attesa nella variabile risposta \\(y\\), confrontando due individui che differiscono di un’unità nel predittore \\(x_k\\) ma sono identici per quanto riguarda gli altri predittori. Questo concetto è talvolta sintetizzato con l’espressione “confrontare due osservazionni (o persone) che differiscono per \\(x_k\\) a parità delle altre variabili”.\nDal punto di vista dell’implementazione con Stan, l’estensione del modello per includere molteplici predittori dell’intelligenza del bambino è relativamente semplice. È necessario costruire una matrice \\(X\\) contenente le colonne che rappresentano i vari predittori che intendiamo analizzare. Per l’esempio specifico in questione, i predittori selezionati per l’intelligenza del bambino includono: la scolarità della madre (codificata come 0 o 1 a seconda che la madre abbia completato o meno le scuole superiori), l’intelligenza della madre e l’età della madre. Prima di procedere con l’analisi, è importante standardizzare tutte queste variabili per facilitare l’interpretazione dei risultati e migliorare la stabilità numerica del modello.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#un-esempio-pratico",
    "href": "chapters/linear_models/09_stan_multreg.html#un-esempio-pratico",
    "title": "78  Il modello di regressione multipla",
    "section": "78.3 Un esempio pratico",
    "text": "78.3 Un esempio pratico\nPer fare un esempio pratico, analizzeremo nuovamente i dati sull’intelligenza di un gruppo di bambini. In questo caso, cercheremo di predire l’intelligenza media dei bambini considerando tre fattori: se le madri hanno completato la scuola superiore, l’intelligenza della madre e l’età della madre.\nImportiamo i dati:\n\ndata_file = os.path.join(project_directory, \"data\", \"kidiq.dta\")\nkidiq = pd.read_stata(data_file)\nkidiq.head()\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\nCompiliamo e stampiamo il modello Stan di regressione multipla per questi dati. Il modello assume che i dati siano standardizzati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"mreg.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n    int&lt;lower=1&gt; N;   // Numero di osservazioni\n    int&lt;lower=1&gt; K;   // Numero di variabili indipendenti, intercetta inclusa\n    vector[N] x1;     // Prima variabile indipendente\n    vector[N] x2;     // Seconda variabile indipendente\n    vector[N] x3;     // Seconda variabile indipendente\n    // Aggiungi altri vettori se ci sono più variabili indipendenti\n    vector[N] y;      // Vettore della variabile dipendente\n}\nparameters {\n    real alpha;           // Intercetta\n    real beta1;           // Coefficiente per la prima variabile indipendente\n    real beta2;           // Coefficiente per la seconda variabile indipendente\n    real beta3;           // Coefficiente per la terza variabile indipendente\n    // Definisci altri real per ulteriori coefficienti\n    real&lt;lower=0&gt; sigma;  // Errore del modello\n}\nmodel {\n    // Prior\n    alpha ~ student_t(3, 0, 2.5);\n    beta1 ~ student_t(3, 0, 2.5);\n    beta2 ~ student_t(3, 0, 2.5);\n    beta3 ~ student_t(3, 0, 2.5);\n    // Definisci prior per altri coefficienti\n    sigma ~ exponential(1);\n\n    // Likelihood\n    for (n in 1:N) {\n        y[n] ~ normal(alpha + beta1 * x1[n] + beta2 * x2[n] + + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n    }\n}\ngenerated quantities {\n    vector[N] log_lik; // Log-likelihood per ogni osservazione\n    vector[N] y_rep;  // Predizioni posteriori per ogni osservazione\n\n    for (n in 1:N) {\n        log_lik[n] = normal_lpdf(y[n] | alpha + beta1 * x1[n] + beta2 * x2[n] + + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n        y_rep[n] = normal_rng(alpha + beta1 * x1[n] + beta2 * x2[n] + beta3 * x3[n], sigma);\n        // Aggiungi termini per altri coefficienti se necessario\n    }\n}\n\n\n\nStandaridizziamo i predittori:\n\nx1 = stats.zscore(kidiq[\"mom_hs\"])\nx2 = stats.zscore(kidiq[\"mom_iq\"])\nx3 = stats.zscore(kidiq[\"mom_age\"])\n\n\ndf = pd.DataFrame({\n    \"one\": [1] * len(x1),  # Crea una lista di 1 della stessa lunghezza di x1\n    \"x1\": x1,\n    \"x2\": x2,\n    \"x3\": x3\n})\n\ndf.head()\n\n\n\n\n\n\n\n\none\nx1\nx2\nx3\n\n\n\n\n0\n1\n0.522233\n1.409460\n1.562029\n\n\n1\n1\n0.522233\n-0.710026\n0.820727\n\n\n2\n1\n0.522233\n1.030732\n1.562029\n\n\n3\n1\n0.522233\n-0.036733\n0.820727\n\n\n4\n1\n0.522233\n-0.484177\n1.562029\n\n\n\n\n\n\n\n\n# Convert scaled DataFrame to numpy matrix\nX = df.to_numpy()\n\n\n# Verificare le dimensioni di X\nprint(\"Dimensioni di X:\", X.shape)\n\nDimensioni di X: (434, 4)\n\n\nCreiamo un dizionario con i dati nel formato atteso da Stan:\n\nstan_data = {\n    \"N\": X.shape[0],\n    \"K\": X.shape[1],  # Nota: questa include anche la colonna dell'intercetta\n    \"x1\": df[\"x1\"],\n    \"x2\": df[\"x2\"],\n    \"x3\": df[\"x3\"],\n    \"y\": stats.zscore(\n        kidiq[\"kid_score\"]\n    )\n}\n\nEseguiamo il campionamento MCMC:\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n21:00:45 - cmdstanpy - INFO - CmdStan start processing\n21:00:45 - cmdstanpy - INFO - Chain [1] start processing\n21:00:45 - cmdstanpy - INFO - Chain [2] start processing\n21:00:45 - cmdstanpy - INFO - Chain [3] start processing\n21:00:45 - cmdstanpy - INFO - Chain [4] start processing\n21:00:46 - cmdstanpy - INFO - Chain [2] done processing\n21:00:46 - cmdstanpy - INFO - Chain [1] done processing\n21:00:46 - cmdstanpy - INFO - Chain [4] done processing\n21:00:46 - cmdstanpy - INFO - Chain [3] done processing\n\n\nEsaminiamo le tracce dei parametri:\n\n_ = az.plot_trace(fit, var_names=([\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"sigma\"]))\n\n\n\n\n\n\n\n\nAnche nel caso della regressione multipla, i risultati ottenuti con l’approccio bayesiano sono molto simili a quelli prodotti dall’approccio basato sulla massima verosimiglianza.\nCalcoliamo una sintesi delle distribuzioni a posteriori dei parametri:\n\naz.summary(\n    fit, var_names=([\"alpha\", \"beta1\", \"beta2\", \"beta3\", \"sigma\"]), hdi_prob=0.94\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.000\n0.043\n-0.082\n0.080\n0.0\n0.001\n9553.0\n5261.0\n1.0\n\n\nbeta1\n0.114\n0.045\n0.031\n0.201\n0.0\n0.000\n9409.0\n6308.0\n1.0\n\n\nbeta2\n0.414\n0.044\n0.330\n0.496\n0.0\n0.000\n9556.0\n6280.0\n1.0\n\n\nbeta3\n0.029\n0.043\n-0.050\n0.112\n0.0\n0.000\n9647.0\n6545.0\n1.0\n\n\nsigma\n0.891\n0.031\n0.835\n0.949\n0.0\n0.000\n9403.0\n5961.0\n1.0\n\n\n\n\n\n\n\nReplichiamo il risultato usando l’approccio di massima verosimiglianza:\n\nlm = pg.linear_regression(X, stats.zscore(kidiq[\"kid_score\"]))\nlm.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-0.00\n0.04\n-0.00\n1.00\n0.21\n0.21\n-0.08\n0.08\n\n\n1\nx2\n0.11\n0.05\n2.50\n0.01\n0.21\n0.21\n0.02\n0.20\n\n\n2\nx3\n0.41\n0.04\n9.28\n0.00\n0.21\n0.21\n0.33\n0.50\n\n\n3\nx4\n0.03\n0.04\n0.68\n0.50\n0.21\n0.21\n-0.06\n0.12",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#interpretazione-dei-coefficienti",
    "href": "chapters/linear_models/09_stan_multreg.html#interpretazione-dei-coefficienti",
    "title": "78  Il modello di regressione multipla",
    "section": "78.4 Interpretazione dei coefficienti",
    "text": "78.4 Interpretazione dei coefficienti\nNel contesto della regressione multipla, l’interpretazione dei coefficienti parziali differisce da quella della regressione bivariata. Una differenza chiave rispetto al modello di regressione bivariato è nell’interpretazione dei coefficienti. Nel caso bivariato, il coefficiente \\(\\beta_1\\) viene interpretato come il cambiamento atteso in \\(Y\\) al variare di una unità in \\(X_1\\). Tuttavia, nel modello di regressione multipla, l’interpretazione di \\(\\beta_1\\) cambia. In questo caso, \\(\\beta_1\\) rappresenta il cambiamento atteso in \\(Y\\) al variare di una unità in \\(X_1\\), mantenendo costanti gli effetti di tutte le altre variabili \\(X_2, X_3, \\ldots, X_p\\). In altre parole, \\(\\beta_1\\) ci dice come varia in media \\(Y\\) quando \\(X_1\\) cambia, ma considera che altre variabili possono variare insieme a \\(X_1\\), e \\(\\beta_1\\) tiene conto di queste variazioni.\nNel nostro caso, il coefficiente associato all’intelligenza della madre, indicato come \\(\\beta\\) = 0.41, assume il seguente significato: prevediamo che l’intelligenza del bambino aumenti di 0.41 deviazioni standard in media per ogni deviazione standard aggiuntiva nell’intelligenza della madre, mantenendo costanti gli effetti del livello di istruzione e dell’età della madre. Questo implica che stiamo considerando l’impatto dell’intelligenza della madre sull’intelligenza del bambino all’interno di una popolazione di madri che sono omogenee per quanto riguarda il livello di istruzione e l’età.\nCosa significa mantenere costante l’effetto di altre variabili? Consideriamo l’esempio della correlazione tra il numero di scarpe e le abilità matematiche. Esiste una marcata correlazione positiva tra queste due variabili. Tuttavia, è evidente che i bambini, avendo in genere numeri di scarpe più piccoli rispetto agli adulti, mostrano anche, presumibilmente, minori capacità matematiche. Questo esempio illustra che, se controlliamo per l’età, ossia se consideriamo solo soggetti della stessa età, la correlazione tra il numero di scarpe e le abilità matematiche scompare. Pertanto, nell’analisi della relazione tra abilità matematiche (Y) e numero di scarpe (X), l’età (Z) agisce come variabile confondente. Controllare per Z significa esaminare la relazione tra Y e X limitandosi a individui della stessa età.\nMa ovviamente questo controllo empirico non è sempre possibile. Nel modello di regressione, esso viene “approssimato” con una procedura statistica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#distribuzione-predittiva-a-posteriori",
    "href": "chapters/linear_models/09_stan_multreg.html#distribuzione-predittiva-a-posteriori",
    "title": "78  Il modello di regressione multipla",
    "section": "78.5 Distribuzione predittiva a posteriori",
    "text": "78.5 Distribuzione predittiva a posteriori\nCalcoliamo la distribuzione predittiva a posteriori e generiamo il PPC plot:\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive='y_rep',\n    observed_data={'y': stats.zscore(kidiq[\"kid_score\"])},\n)\n\n\n_ = az.plot_ppc(idata, data_pairs={'y': 'y_rep'})",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#il-controllo-statisico",
    "href": "chapters/linear_models/09_stan_multreg.html#il-controllo-statisico",
    "title": "78  Il modello di regressione multipla",
    "section": "78.6 Il Controllo Statisico",
    "text": "78.6 Il Controllo Statisico\nNella seguente simulazione illustreremo la procedura statistica utilizzata per isolare l’effetto di una variabile controllando per un’altra.\n\n# Creiamo dei dati di esempio\nnp.random.seed(0)\nN = 100\nX1 = np.random.normal(0, 1, N)\nX2 = X1 + np.random.normal(0, 0.5, N)\nY = 1 + 2 * X1 + 3 * X2 + np.random.normal(0, 1, N)\n\n# Modello completo Y ~ X1 + X2\nmodel_full = sm.OLS(Y, sm.add_constant(np.column_stack((X1, X2))))\nresults_full = model_full.fit()\n\n# Regressione di Y su X2\nmodel_Y_on_X2 = sm.OLS(Y, sm.add_constant(X2))\nresiduals_Y = model_Y_on_X2.fit().resid\n\n# Regressione di X1 su X2\nmodel_X1_on_X2 = sm.OLS(X1, sm.add_constant(X2))\nresiduals_X1 = model_X1_on_X2.fit().resid\n\n# Regressione dei residui di Y sui residui di X1\nmodel_residuals = sm.OLS(residuals_Y, sm.add_constant(residuals_X1))\nresults_residuals = model_residuals.fit()\n\n# Stampiamo i risultati\nprint(\"Coefficient from full model for X1: {:.4f}\".format(results_full.params[1]))\nprint(\n    \"Coefficient from regression of residuals: {:.4f}\".format(\n        results_residuals.params[1]\n    )\n)\n\nCoefficient from full model for X1: 1.9782\nCoefficient from regression of residuals: 1.9782\n\n\nQuesto esempio illustra il concetto di coefficiente parziale di regressione. Questo coefficiente quantifica l’effetto della variabile esplicativa \\(X_j\\) sulla variabile dipendente \\(Y\\), depurando l’effetto di \\(X_j\\) dall’influenza degli altri predittori nel modello. In sostanza, il coefficiente parziale di regressione valuta l’impiego di \\(X_j\\) su \\(Y\\) quando \\(X_j\\) è considerata linearmente indipendente rispetto agli altri predittori \\(X\\). L’effetto misurato è quindi quello della sola componente di \\(X_j\\) che non è spiegata linearmente dai restanti predittori \\(X\\) sulla parte di \\(Y\\) che è anch’essa indipendente dai medesimi predittori.\nPer chiarire ulteriormente, questo approccio statistico si focalizza sull’analizzare l’effetto di \\(X_j\\) eliminando l’influenza lineare degli altri predittori \\(X\\). È simile a valutare la relazione tra \\(Y\\) e \\(X_j\\) in un contesto ideale dove tutti gli individui presentano livelli identici per le altre variabili \\(X\\). Tale metodo non eguaglia gli effetti non lineari che possono essere presenti tra le variabili, limitandosi a correggere solo per le associazioni lineari. In questo modo, il controllo statistico tenta di approssimare una condizione di omogeneità tra i soggetti rispetto alle altre variabili \\(X\\), consentendo di isolare e valutare più precisamente l’effetto puro di \\(X_j\\) su \\(Y\\).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#quali-predittori-includere-nel-modello",
    "href": "chapters/linear_models/09_stan_multreg.html#quali-predittori-includere-nel-modello",
    "title": "78  Il modello di regressione multipla",
    "section": "78.7 Quali Predittori Includere nel Modello?",
    "text": "78.7 Quali Predittori Includere nel Modello?\nL’uso del modello di regressione multipla ha principalmente due scopi. In primo luogo, è impiegato per la predizione, ovvero per ottenere la migliore stima possibile di \\(Y\\) utilizzando una combinazione lineare delle variabili \\(X_1, X_2, \\ldots, X_p\\). In questo contesto, i coefficienti \\(\\beta_i\\) sono interpretati come pesi che ottimizzano la previsione di \\(Y\\) in base ai valori delle variabili indipendenti.\nIn secondo luogo, il modello di regressione multipla viene spesso utilizzato per descrivere le relazioni tra variabili. Tuttavia, è cruciale comprendere che il modello non è stato originariamente creato per stabilire relazioni causali. Pertanto, bisogna essere cauti nell’attribuire interpretazioni causali dirette ai coefficienti \\(\\beta_i\\). Il modello stima correttamente i coefficienti parziali di regressione solo quando tutte le variabili che influenzano \\(Y\\) sono incluse nel modello. Nella pratica, spesso non conosciamo tutte le variabili rilevanti, il che può portare a errori di specificazione.\nIl modello di regressione multipla è uno strumento potente per predire e analizzare le relazioni tra variabili, ma è fondamentale riconoscerne le limitazioni, soprattutto quando si cercano interpretazioni causali. In campi come la psicologia, dove è cruciale comprendere le dinamiche causali, diventa essenziale una scelta accurata delle variabili da includere nel modello per prevenire distorsioni nelle stime dei coefficienti di regressione.\nTradizionalmente, si riteneva vantaggioso includere nel modello il maggior numero possibile di variabili per ottenere un livello di “controllo” statistico più elevato. Tuttavia, come sottolineato da McElreath (2020), questo approccio può portare a una “insalata causale”. Questo termine descrive una situazione in cui la mancanza di attenzione alla struttura causale tra le variabili porta all’inclusione di variabili di controllo inappropriate, causando distorsioni nelle stime.\nIn alcuni casi, l’inserimento di determinate variabili di controllo è indispensabile per evitare distorsioni, mentre in altri casi, l’inclusione di variabili non pertinenti può portare a risultati fuorvianti. Questo sottolinea l’importanza di formulare ipotesi chiare e ben ponderate sulla struttura causale tra le variabili in esame.\nL’efficacia e la validità dei risultati ottenuti tramite regressione dipendono strettamente dalla correttezza delle ipotesi causali formulate, sia esplicitamente che implicitamente, dal ricercatore. Per superare i limiti dell’approccio dell’“insalata causale”, è cruciale che la costruzione del modello di regressione rifletta attentamente queste ipotesi causali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#interpretazione-dei-coefficienti-parziali-di-regressione",
    "href": "chapters/linear_models/09_stan_multreg.html#interpretazione-dei-coefficienti-parziali-di-regressione",
    "title": "78  Il modello di regressione multipla",
    "section": "78.8 Interpretazione dei Coefficienti Parziali di Regressione",
    "text": "78.8 Interpretazione dei Coefficienti Parziali di Regressione\nLa regressione lineare è un metodo statistico utilizzato per adattare una linea (o un iperpiano in spazi multidimensionali) che descrive la relazione tra una variabile dipendente e una o più variabili indipendenti. L’obiettivo principale di questo metodo è spiegare la variazione della variabile dipendente in base alle variazioni delle variabili indipendenti. È importante sottolineare che il modello di regressione, di per sé, non implica alcun tipo di relazione causale tra le variabili. Nonostante ciò, è comune, e spesso errato, attribuire ai coefficienti del modello un’interpretazione causale.\nAd esempio, si dice spesso che il coefficiente parziale \\(\\beta_j\\) rappresenta l’incremento atteso della variabile dipendente \\(Y\\) per una variazione unitaria della variabile indipendente \\(X_j\\), mantenendo costanti gli effetti lineari degli altri predittori inclusi nel modello. Questa interpretazione suggerisce implicitamente una relazione causale: se \\(X_j\\) cambia di un’unità, allora, tenendo conto dell’effetto lineare delle altre variabili, la media di \\(Y\\) cambierà necessariamente di una quantità pari a \\(\\beta_j\\) (Westreich & Greenland, 2013).\nTuttavia, questa interpretazione è valida solo sotto condizioni specifiche che sono raramente soddisfatte nella pratica. Nella maggior parte dei casi, il coefficiente \\(\\beta_j\\) riflette semplicemente una descrizione di ciò che accade nel campione di dati analizzato. La sua validità al di fuori del campione, cioè nella popolazione generale, dipende dal fatto che il modello di regressione rappresenti accuratamente il processo generativo dei dati nella popolazione. Se il modello è mal specificato o se esistono variabili confondenti non incluse nel modello, l’interpretazione causale dei coefficienti diventa invalida.\nIn altre parole, i risultati di un’analisi di regressione lineare su un campione di dati non possono essere utilizzati direttamente per inferire nessi causali. L’inferenza causale richiede una conoscenza approfondita del dominio e l’uso di metodi appropriati, come esperimenti controllati o modelli di equazioni strutturali, che permettono di identificare relazioni causali. Solo una volta stabiliti i nessi causali, la regressione lineare può essere impiegata per quantificare la forza di queste relazioni. Pertanto, non è possibile procedere nel modo opposto, ovvero dedurre relazioni causali direttamente dai coefficienti di regressione — si vedano le sezioni relative all’errore di specificazione del modello e all’inferenza causale nei modelli di regressione per maggiori dettagli.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#considerazioni-conclusive",
    "href": "chapters/linear_models/09_stan_multreg.html#considerazioni-conclusive",
    "title": "78  Il modello di regressione multipla",
    "section": "78.9 Considerazioni Conclusive",
    "text": "78.9 Considerazioni Conclusive\nNel suo libro Statistical Rethinking, McElreath (2020) introduce una metafora per i modelli statistici, paragonandoli ai Golem, creature della mitologia antica, prive di volontà propria e animate solo dall’intento di chi le crea. Questi esseri, dotati di grande forza ma privi di giudizio autonomo, possono diventare pericolosi se non vengono guidati con saggezza. Allo stesso modo, i modelli statistici sono strumenti potenti che, se utilizzati senza una comprensione adeguata del contesto e delle loro limitazioni, possono portare a conclusioni errate o fuorvianti.\nMcElreath (2020) suggerisce che, nella costruzione di modelli matematici, gli scienziati creano moderni equivalenti di questi Golem. Sebbene tali modelli influenzino il mondo reale attraverso le previsioni che generano e le intuizioni che offrono, non dovrebbero essere considerati come rappresentazioni assolute della verità. I modelli statistici, infatti, sono strumenti costruiti per uno scopo specifico: essi eseguono calcoli con grande precisione, ma mancano della capacità di comprendere o interpretare il contesto più ampio in cui vengono applicati.\nIl modello di regressione, in particolare, è un esempio di come questi strumenti possano produrre risultati numerici concreti, ma siano limitati nella loro capacità di affrontare questioni che richiedono un approccio più creativo e comprensivo. McElreath (2020) sottolinea che nessun modello statistico, da solo, è sufficiente per risolvere il complesso problema dell’inferenza causale a partire da dati empirici. Il modello di regressione, per quanto utile nel descrivere relazioni tra variabili, non è dotato di una reale comprensione delle dinamiche di causa ed effetto. Senza un’interpretazione critica e un uso consapevole da parte degli studiosi, questo strumento, progettato per scopi specifici, può risultare non solo inefficace, ma anche potenzialmente dannoso.\nCarlin & Moreno-Betancur (2023) sottolineano che il modello di regressione può essere usato per tre scopi diversi:\n\nDescrizione delle associazioni: ad esempio, descrivere la prevalenza di una certa condizione in diverse sottopopolazioni;\nPredizione: utilizzare un insieme di predittori per prevedere in modo attendibile il valore di (Y) per gli individui per i quali sono disponibili le misure di (X);\nAnalisi delle relazioni causali: determinare in che misura un esito dipende da un particolare intervento.\n\nSecondo Carlin & Moreno-Betancur (2023) è importante che i ricercatori chiariscano l’obiettivo specifico per cui utilizzano il modello di regressione. Purtroppo, questa fondamentale classificazione delle domande di ricerca non è ancora penetrata a fondo nell’insegnamento e nella pratica della statistica, soprattutto per quanto riguarda i metodi di regressione. In molti campi, inclusa la psicologia, si continua a insegnare e a utilizzare i modelli di regressione come un toolkit universale, applicato senza un’adeguata considerazione dello scopo reale. Un approccio diffuso è quello di “trovare il miglior modello per i dati” e successivamente sviluppare un’interpretazione del modello adattato.\nInvece, Carlin & Moreno-Betancur (2023) raccomandano che l’insegnamento del modello di regressione sia guidato da una prospettiva basata sull’obiettivo specifico della ricerca. Suggeriscono di utilizzare la classificazione delle tre tipologie di domande di ricerca per orientare l’apprendimento, introducendo gli aspetti tecnici dei modelli di regressione e di altri metodi solo quando sono direttamente rilevanti per il particolare scopo della ricerca. Questo approccio permette di focalizzarsi sull’uso appropriato dei modelli in base al contesto e all’obiettivo specifico, evitando l’applicazione indiscriminata e la conseguente possibilità di fraintendimenti.\nIn conclusione, come afferma McElreath (2020), è fondamentale che i ricercatori utilizzino i modelli statistici con piena consapevolezza delle loro limitazioni e con una considerazione attenta del contesto in cui vengono applicati. I modelli sono strumenti potenti, ma la loro efficacia dipende dalla saggezza e dall’intenzione di chi li utilizza. Solo adottando un approccio critico e informato possiamo evitare di trasformare questi potenti strumenti in Golem senza controllo, assicurando che essi contribuiscano realmente alla comprensione del mondo che ci circonda.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#esercizi",
    "href": "chapters/linear_models/09_stan_multreg.html#esercizi",
    "title": "78  Il modello di regressione multipla",
    "section": "78.10 Esercizi",
    "text": "78.10 Esercizi\n\nEsercizio 78.1 Considera il seguente modello lineare univariato in forma matriciale:\n\\[ \\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon} \\]\nI valori delle variabili indipendenti (\\(x_1\\), \\(x_2\\) e \\(x_3\\)) per cinque osservazioni sono:\n\\[\n  x_1 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix}, \\quad\n  x_2 = \\begin{pmatrix} 11 \\\\ 9 \\\\ 12 \\\\ 10 \\\\ 11 \\end{pmatrix}, \\quad\n  x_3 = \\begin{pmatrix} 12 \\\\ 9 \\\\ 7 \\\\ 8 \\\\ 6 \\end{pmatrix}\n  \\]\nI valori della variabile dipendente sono:\n\\[\n  y = \\begin{pmatrix} 5.7 \\\\ 4.7 \\\\ 12.6 \\\\ 10.8 \\\\ 8.5 \\end{pmatrix}\n\\]\nI coefficienti (\\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\) e \\(\\beta_3\\)) sono:\n\\[\n  \\beta_0 = -1.402020, \\quad \\beta_1 = 0.183838, \\quad \\beta_2 = 1.405051, \\quad \\beta_3 = -0.664646\n  \\]\n\nDetermina le matrici \\(\\mathbf{X}\\), \\(\\boldsymbol{\\beta}\\) e \\(\\boldsymbol{\\epsilon}\\) e scrivi l’equazione completa in forma matriciale.\nEspandi il modello per ottenere cinque equazioni esplicite, una per ciascuna osservazione, utilizzando i valori forniti.\nTrova gli errori casuali (\\(\\epsilon_1\\), \\(\\epsilon_2\\) e \\(\\epsilon_3\\), \\(\\epsilon_4\\), \\(\\epsilon_5\\)).\nTrova i valori predetti (\\(\\hat{y}_1\\), \\(\\hat{y}_2\\) e \\(\\hat{y}_3\\), \\(\\hat{y}_4\\), \\(\\hat{y}_5\\)).\n\n\n\nEsercizio 78.2 Obiettivo: calcolare i coefficienti \\(\\beta\\) del modello lineare univariato usando il metodo dei minimi quadrati.\nI valori delle variabili indipendenti (\\(x_1\\), \\(x_2\\) e \\(x_3\\)) per cinque osservazioni sono:\n\\[\n  x_1 = \\begin{pmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 4 \\\\ 5 \\end{pmatrix}, \\quad\n  x_2 = \\begin{pmatrix} 11 \\\\ 9 \\\\ 12 \\\\ 10 \\\\ 11 \\end{pmatrix}, \\quad\n  x_3 = \\begin{pmatrix} 12 \\\\ 9 \\\\ 7 \\\\ 8 \\\\ 6 \\end{pmatrix}\n\\]\nI valori delle variabili dipendenti (\\(\\mathbf{y}\\)) sono:\n\\[\n  y = \\begin{pmatrix} 5.7 \\\\ 4.7 \\\\ 12.6 \\\\ 10.8 \\\\ 8.5 \\end{pmatrix}\n\\]\nLa formula dei minimi quadrati per calcolare i coefficienti \\(\\beta\\) in un modello lineare è data da:\n\\[ \\boldsymbol{\\beta} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}. \\]\nQuesta formula minimizza la somma dei quadrati degli errori tra i valori osservati e quelli previsti dal modello. In altre parole, cerca di trovare i valori di \\(\\beta\\) che riducono al minimo le discrepanze tra i dati osservati e quelli stimati dal modello lineare.\n\nAggiungi una colonna di 1 alla matrice \\(\\mathbf{X}\\) per includere l’intercetta.\nScrivi la matrice \\(\\mathbf{X}\\) e il vettore \\(\\mathbf{y}\\) utilizzando i dati forniti.\nCalcola i coefficienti \\(\\beta\\) utilizzando la formula dei minimi quadrati. Implementa la formula in Python e calcola i valori di \\(\\beta\\). Controlla i risultati usando pingouin.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/09_stan_multreg.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/09_stan_multreg.html#informazioni-sullambiente-di-sviluppo",
    "title": "78  Il modello di regressione multipla",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas     : 2.2.2\narviz      : 0.18.0\nmatplotlib : 3.9.1\ncmdstanpy  : 1.2.4\npingouin   : 0.5.4\nscipy      : 1.14.0\nstatsmodels: 0.14.2\nnumpy      : 1.26.4\nlogging    : 0.5.1.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nCarlin, J. B., & Moreno-Betancur, M. (2023). On the uses and abuses of regression models: a call for reform of statistical practice and teaching. arXiv preprint arXiv:2309.06668.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nWestreich, D., & Greenland, S. (2013). The table 2 fallacy: presenting and interpreting confounder and modifier coefficients. American Journal of Epidemiology, 177(4), 292–298.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>Il modello di regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html",
    "href": "chapters/linear_models/10_hier_regr.html",
    "title": "79  Il modello lineare gerarchico",
    "section": "",
    "text": "Introduzione\nI modelli gerarchici, noti anche come modelli multilivello, rappresentano uno strumento statistico di fondamentale importanza nella ricerca psicologica moderna. La loro rilevanza deriva dalla capacità di gestire la complessità intrinseca dei dati psicologici, caratterizzati spesso da strutture di dipendenza non triviali.\nNella pratica della ricerca psicologica, è raro imbattersi in dataset composti da osservazioni completamente indipendenti. Al contrario, ci troviamo frequentemente di fronte a strutture dati complesse, dove le osservazioni sono naturalmente raggruppate o ripetute nel tempo. Pensiamo, ad esempio, a studi longitudinali dove gli stessi individui vengono valutati più volte, o a ricerche che coinvolgono studenti raggruppati in classi. In questi scenari, le osservazioni all’interno di un gruppo o relative allo stesso individuo tendono ad essere più simili tra loro rispetto a osservazioni di gruppi o individui diversi.\nI modelli multilivello sono progettati specificamente per catturare e modellare queste dipendenze. Ignorare tali strutture nella fase di analisi potrebbe portare a inferenze statistiche distorte, spesso eccessivamente ottimistiche. I modelli multilivello, invece, permettono di ottenere stime più accurate e affidabili, consentendo ai ricercatori di affrontare domande di ricerca sofisticate. Questi modelli permettono di esaminare come gli effetti varino tra i gruppi, come l’impatto di una variabile possa dipendere dai livelli di un’altra, o come una manipolazione sperimentale influenzi i cambiamenti nel tempo.\nTuttavia, la potenza e la flessibilità dei modelli multilivello portano con sé anche delle sfide. La loro complessità può rendere difficile l’interpretazione dei risultati e aumentare il rischio di errori nell’analisi. Come evidenziato da recenti studi, l’uso inappropriato di questi modelli può contribuire alla crisi di replicabilità in psicologia, portando a conclusioni erronee o sovrastime degli effetti.\nUn esempio emblematico di questo rischio è fornito dalla ri-analisi condotta da Gelman & Brown (2024) sui dati di Aungle & Langer (2023). Utilizzando un modello statistico più appropriato, l’effetto originariamente riportato è scomparso, dimostrando come l’applicazione inadeguata dei modelli multilivello possa condurre a interpretazioni fuorvianti dei dati.\nAlla luce di queste considerazioni, emerge chiaramente l’importanza di una solida comprensione dei modelli multilivello per chi si occupa di ricerca psicologica. Questo capitolo si propone di fornire un’introduzione approfondita a questa classe di modelli statistici. L’obiettivo è dotare gli studenti degli strumenti concettuali necessari per applicare correttamente questi modelli, interpretarne i risultati in modo critico, e navigare le complessità specifiche dell’analisi dei dati multilivello in psicologia.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#concetti-di-base",
    "href": "chapters/linear_models/10_hier_regr.html#concetti-di-base",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.1 Concetti di base",
    "text": "79.1 Concetti di base\nI modelli multilivello affrontano una delle principali limitazioni del modello di regressione tradizionale: l’assunzione di indipendenza delle osservazioni. Nel modello di regressione classico, si presuppone che per ogni valore di \\(x\\), le osservazioni \\(y\\) siano campionate in modo indipendente dalla distribuzione \\(p(y \\mid x)\\). Ciò implica che gli errori \\(y_i - E(α + βx_i)\\) siano tra loro indipendenti, una condizione garantita solo in specifici disegni di ricerca, come il campionamento casuale semplice. Tuttavia, numerosi disegni sperimentali in psicologia violano questa assunzione. È frequente, ad esempio, che lo stesso individuo venga osservato in diverse condizioni, generando una struttura di dati con osservazioni correlate o raggruppate (clustered).\nI modelli ad effetti misti, o multilivello, sono stati sviluppati proprio per gestire queste situazioni complesse, rendendoli particolarmente adatti per i disegni a misure ripetute, così comuni nella ricerca psicologica. Questi modelli, conosciuti anche come modelli gerarchici, modelli ad effetti casuali o modelli nidificati, rappresentano un approccio efficace per l’analisi di dati organizzati in gruppi o livelli.\nLa versatilità dei modelli gerarchici si manifesta nella loro applicabilità a diverse tipologie di dati: geograficamente nidificati (ad esempio, dati di città all’interno di province, province all’interno di stati), organizzati gerarchicamente (come studenti all’interno di scuole o pazienti in ospedali), o implicanti misurazioni ripetute sugli stessi individui. Questa flessibilità consente di gestire le complessità intrinseche a tali dati, tenendo conto sia delle variazioni condivise che di quelle uniche tra i gruppi.\nUn aspetto fondamentale dei modelli gerarchici è la loro capacità di facilitare la condivisione di informazioni tra i gruppi. Ciò avviene mediante l’impiego di distribuzioni priori per i parametri, influenzate a loro volta da distribuzioni priori di livello superiore, comunemente chiamate iperpriori. Il prefisso “iper” deriva dal termine greco per “sopra”, indicando che queste distribuzioni priori operano a un livello superiore rispetto alle distribuzioni priori standard. Le distribuzioni degli iperparametri consentono al modello di equilibrare la descrizione delle caratteristiche specifiche dei gruppi con una descrizione delle tendenze comuni tra i gruppi.\nLa figura successiva illustra graficamente le differenze tra gli approcci dei modelli aggregati (dove i dati sono trattati come se provenissero da un unico gruppo), dei modelli non aggregati (dove ogni gruppo è trattato separatamente) e dei modelli gerarchici (o parzialmente aggregati), dove le informazioni sono condivise tra i gruppi.\n\n\n\nLe differenze tra un modello aggregato (pooled), un modello non aggregato (unpooled) e un modello gerarchico. (Figura tratta da Martin (2024)).\n\n\nNel contesto della regressione lineare gerarchica Bayesiana, l’utilizzo di librerie specializzate come Bambi facilita l’implementazione di questi modelli complessi. Questa metodologia si rivela particolarmente utile nell’analisi di dataset che comprendono diverse unità di osservazione, rappresentate dai soggetti, ciascuna delle quali è associata a multiple misurazioni.\nPer una comprensione visiva più intuitiva dei modelli gerarchici, si consiglia di consultare il demo interattivo di Michael Freeman, accessibile su questo sito.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#complete-pooling-no-pooling-partial-pooling",
    "href": "chapters/linear_models/10_hier_regr.html#complete-pooling-no-pooling-partial-pooling",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.2 Complete Pooling, No Pooling, Partial Pooling",
    "text": "79.2 Complete Pooling, No Pooling, Partial Pooling\nNei capitoli precedenti, è stato introdotto il concetto di modellazione gerarchica bayesiana, con particolare attenzione alla stima dei parametri di distribuzioni di probabilità. Per un approfondimento su questo tema, si veda il Capitolo 66. Il presente capitolo si propone di estendere tale concetto alla stima dei parametri in un modello di regressione lineare, focalizzandosi sull’analisi di dati suddivisi in vari gruppi.\nNell’affrontare l’analisi di dati provenienti da gruppi eterogenei, si possono delineare tre principali approcci metodologici, ciascuno con peculiari vantaggi e limitazioni:\n\nComplete Pooling: Questo modello prescinde dalla struttura gerarchica dei dati, trattando tutte le unità osservative come appartenenti a un’unica popolazione. Sebbene questo approccio possa incrementare la precisione delle stime attraverso l’aggregazione di tutti i dati, rischia di obliterare informazioni cruciali specifiche di ciascun gruppo, risultando potenzialmente eccessivamente generalizzante.\nNo Pooling: In antitesi al precedente, questo modello considera ogni gruppo come entità indipendente, ignorando qualsiasi struttura gerarchica. Questa metodologia, pur consentendo di evidenziare le peculiarità di ogni gruppo, può condurre a conclusioni meno robuste a causa della mancanza di un contesto più ampio e della potenziale scarsità di dati per singoli gruppi.\nPartial Pooling (o Modello Multi-Livello): Rappresenta un approccio intermedio e più equilibrato. Questo modello presuppone che pendenze e intercette di ciascun gruppo siano realizzazioni di variabili casuali, distribuite normalmente con parametri di media e varianza condivisi tra tutti i gruppi.\n\nIl modello di “partial pooling” si distingue per la sua capacità di conciliare l’indipendenza dei gruppi con l’esigenza di un’analisi aggregata. Questa metodologia facilita un adeguato “shrinkage” dei parametri, attenuando l’impatto di valori anomali o di gruppi con campioni limitati. Consente inoltre alle stime parametriche di ogni gruppo di essere influenzate sia dai dati specifici che dalla tendenza generale osservata nei dati aggregati.\nL’analisi gerarchica, incarnata nel modello di partial pooling, offre quindi un compromesso ottimale tra gli approcci di complete pooling e no pooling, sintetizzando i benefici di entrambe le metodologie. Questo approccio permette di preservare le informazioni specifiche di ciascun gruppo, mantenendo al contempo una visione d’insieme che migliora la robustezza e l’accuratezza delle stime.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#eda",
    "href": "chapters/linear_models/10_hier_regr.html#eda",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.3 EDA",
    "text": "79.3 EDA\nIniziamo importando i dati e ispezionando la struttura delle osservazioni suddivise nei diversi cluster.\n\ndata = bmb.load_data(\"sleepstudy\")\ndata.head()\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n0\n249.5600\n0\n308\n\n\n1\n258.7047\n1\n308\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n\n\n\n\n\nEliminiamo le righe in cui la colonna “Days” ha valore 0 o 1 dal dataset “sleepstudy” utilizzando il seguente codice:\n\ndata = data[data['Days'].isin([0, 1]) == False]\ndata.head()\n\n\n\n\n\n\n\n\nReaction\nDays\nSubject\n\n\n\n\n2\n250.8006\n2\n308\n\n\n3\n321.4398\n3\n308\n\n\n4\n356.8519\n4\n308\n\n\n5\n414.6901\n5\n308\n\n\n6\n382.2038\n6\n308\n\n\n\n\n\n\n\nAnalizziamo il tempo di reazione medio in relazione ai giorni di deprivazione del sonno, osservando come questo varia per ciascun soggetto coinvolto nello studio.\n\ndef plot_data(data):\n    fig, axes = plt.subplots(3, 6, sharey=True, sharex=True, dpi=100, constrained_layout=True)\n    fig.subplots_adjust(left=0.075, right=0.975, bottom=0.075, top=0.925, wspace=0.03)\n\n    axes_flat = axes.ravel()\n\n    for i, subject in enumerate(data[\"Subject\"].unique()):\n        ax = axes_flat[i]\n        idx = data.index[data[\"Subject\"] == subject].tolist()\n        days = data.loc[idx, \"Days\"].values\n        reaction = data.loc[idx, \"Reaction\"].values\n\n        # Plot observed data points\n        ax.scatter(days, reaction, color=\"#B17F7D\", ec=\"#832F2B\", alpha=0.7)\n\n        # Add a title\n        ax.set_title(f\"Subject: {subject}\", fontsize=9)\n\n    # Remove axis labels for individual plots\n    for ax in axes_flat:\n        ax.set_xlabel(\"\")\n        ax.set_ylabel(\"\")\n\n    # Set x-axis ticks for the last row\n    for ax in axes[-1]:\n        ax.xaxis.set_ticks([0, 2, 4, 6, 8])\n\n    return axes\n\n\nplot_data(data)\nplt.tight_layout()",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#modello-complete-pooling",
    "href": "chapters/linear_models/10_hier_regr.html#modello-complete-pooling",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.4 Modello complete pooling",
    "text": "79.4 Modello complete pooling\nIl modello complete pooling tratta tutte le osservazioni come se fossero indipendenti, aggregandole in un unico gruppo. In questo modello, le rette di regressione lineare per tutti i soggetti hanno la stessa pendenza e la stessa intercetta. Il modello può essere descritto esplicitamente come segue:\nSe disponiamo di $ m $ soggetti e ciascun soggetto $ i $ ha $ n_i $ osservazioni, il modello può essere definito da:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m, \\text{ e per l'osservazione } j = 1, \\ldots, n_i:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha + \\beta \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2),\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) è il tempo di reazione per il soggetto $ i $ al giorno $ j $.\n\\(\\text{Days}_{ij}\\) è il numero di giorni per il soggetto $ i $ all’osservazione $ j $.\n\\(\\alpha\\) è l’intercetta comune a tutti i soggetti.\n\\(\\beta\\) è la pendenza comune a tutti i soggetti.\n\\(\\epsilon_{ij}\\) è il termine di errore casuale per il soggetto $ i $ all’osservazione $ j $, che si suppone sia distribuito normalmente con media 0 e varianza costante $ ^2 $.\n\nQuesto modello non distingue tra i gruppi di osservazoni che appartengono a soggetti diversi e stima un’unica pendenza e un’unica intercetta dai dati di tutti i soggetti. In Bambi, questo modello può essere specificato utilizzando solo la variabile Days come predittore, senza includere il Subject come fattore.\n\nmodel_pooling = bmb.Model(\"Reaction ~ 1 + Days\", data)\n\nProcediamo con l’esecuzione del campionamento MCMC, utilizzando il metodo NUTS specifico per il campionatore JAX. Questo può essere fatto semplicemente passando l’opzione method=\"nuts_numpyro\" durante la chiamata al campionamento. In questo modo, stiamo invocando direttamente il campionatore JAX, sfruttando le sue caratteristiche avanzate.\n\nresults_pooling = model_pooling.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\n\nmodel_pooling.build()\nmodel_pooling.graph()\n\n\n\n\n\n\n\n\nUn sommario numerico delle distribuzioni a posteriori dei parametri si ottiene con az.summary.\n\naz.summary(results_pooling, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nDays\n11.40\n1.88\n7.89\n14.88\n0.03\n0.02\n3826.84\n2982.56\n1.0\n\n\nIntercept\n245.15\n11.22\n224.18\n266.21\n0.18\n0.13\n3871.91\n2719.25\n1.0\n\n\nsigma\n51.10\n3.03\n45.52\n56.72\n0.05\n0.04\n3277.56\n2502.12\n1.0",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#modello-no-pooling",
    "href": "chapters/linear_models/10_hier_regr.html#modello-no-pooling",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.5 Modello no-pooling",
    "text": "79.5 Modello no-pooling\nIl modello no-pooling tratta ogni soggetto come indipendente e adatta una retta di regressione separata per ciascun soggetto. Se disponiamo di $ m $ soggetti e ciascun soggetto $ i $ ha $ n_i $ osservazioni, il modello può essere definito da:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha_i + \\beta_i \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2), \\quad j = 1, \\ldots, n_i,\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) è il tempo di reazione per il soggetto $ i $ al giorno $ j $.\n\\(\\text{Days}_{ij}\\) è il numero di giorni per il soggetto $ i $ all’osservazione $ j $.\n\\(\\alpha_i\\) è l’intercetta per il soggetto $ i $.\n\\(\\beta_i\\) è la pendenza per il soggetto $ i $.\n\\(\\epsilon_{ij}\\) è il termine di errore casuale per il soggetto $ i $ all’osservazione $ j $, che si suppone sia distribuito normalmente con media 0 e varianza costante $ ^2 $.\n\nQuesto modello non fa alcuna ipotesi sulle relazioni tra diversi soggetti e stima la pendenza e l’intercetta di ciascun soggetto indipendentemente dagli altri soggetti. In Bambi, questo modello viene specificato con l’interazione tra Days e Subject, come descritto in seguito.\n\nmodel_no_pooling = bmb.Model(\"Reaction ~ Days * C(Subject)\", data=data)\nresults_no_pooling = model_no_pooling.fit(nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True})\n\n\nmodel_no_pooling.build()\nmodel_no_pooling.graph()\n\n\n\n\n\n\n\n\n\naz.summary(results_no_pooling, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nC(Subject)[309]\n-55.81\n32.73\n-117.09\n3.39\n1.47\n1.05\n498.93\n1286.54\n1.01\n\n\nC(Subject)[310]\n-29.49\n32.66\n-91.81\n30.77\n1.52\n1.08\n457.16\n1208.49\n1.02\n\n\nC(Subject)[330]\n9.81\n33.06\n-54.38\n70.30\n1.60\n1.13\n424.43\n1467.19\n1.02\n\n\nC(Subject)[331]\n40.59\n33.14\n-17.89\n104.88\n1.65\n1.17\n402.96\n1460.16\n1.02\n\n\nC(Subject)[332]\n63.12\n33.24\n3.03\n130.72\n1.57\n1.11\n454.04\n1248.37\n1.01\n\n\nC(Subject)[333]\n15.92\n32.92\n-47.16\n75.49\n1.46\n1.03\n489.51\n1451.70\n1.02\n\n\nC(Subject)[334]\n-45.95\n32.49\n-105.15\n14.85\n1.75\n1.24\n343.16\n1366.32\n1.02\n\n\nC(Subject)[335]\n23.44\n32.25\n-36.55\n82.48\n1.42\n1.01\n513.56\n1550.53\n1.02\n\n\nC(Subject)[337]\n19.76\n33.12\n-45.71\n77.39\n1.63\n1.15\n414.59\n1451.97\n1.02\n\n\nC(Subject)[349]\n-51.58\n32.86\n-111.09\n10.94\n1.57\n1.11\n437.61\n1557.00\n1.02\n\n\nC(Subject)[350]\n-46.21\n32.82\n-111.98\n13.33\n1.57\n1.11\n439.14\n1107.06\n1.02\n\n\nC(Subject)[351]\n-0.91\n33.30\n-63.92\n58.14\n1.45\n1.03\n532.34\n1525.08\n1.02\n\n\nC(Subject)[352]\n68.96\n32.63\n3.34\n127.98\n1.47\n1.04\n494.89\n1325.51\n1.02\n\n\nC(Subject)[369]\n-8.53\n32.77\n-70.04\n54.41\n1.46\n1.03\n502.71\n1346.09\n1.01\n\n\nC(Subject)[370]\n-54.17\n32.62\n-116.74\n5.41\n1.59\n1.12\n423.29\n1338.47\n1.02\n\n\nC(Subject)[371]\n-14.22\n32.78\n-71.89\n50.01\n1.54\n1.09\n453.79\n1263.58\n1.01\n\n\nC(Subject)[372]\n20.63\n33.07\n-37.39\n84.62\n1.60\n1.13\n426.34\n1288.41\n1.02\n\n\nDays\n21.21\n3.81\n13.66\n27.95\n0.28\n0.20\n190.54\n654.98\n1.03\n\n\nDays:C(Subject)[309]\n-16.90\n5.49\n-27.16\n-6.56\n0.23\n0.16\n563.01\n1286.88\n1.01\n\n\nDays:C(Subject)[310]\n-17.32\n5.46\n-27.41\n-6.81\n0.26\n0.19\n436.01\n1175.22\n1.02\n\n\nDays:C(Subject)[330]\n-13.25\n5.57\n-24.32\n-3.22\n0.26\n0.18\n454.06\n1477.08\n1.01\n\n\nDays:C(Subject)[331]\n-16.33\n5.54\n-26.02\n-5.47\n0.27\n0.19\n431.51\n1061.31\n1.02\n\n\nDays:C(Subject)[332]\n-18.75\n5.52\n-29.33\n-8.71\n0.25\n0.18\n506.42\n1275.26\n1.01\n\n\nDays:C(Subject)[333]\n-10.31\n5.50\n-20.58\n-0.35\n0.25\n0.17\n503.11\n1309.14\n1.01\n\n\nDays:C(Subject)[334]\n-3.09\n5.41\n-13.47\n6.89\n0.30\n0.21\n327.11\n1269.11\n1.02\n\n\nDays:C(Subject)[335]\n-25.37\n5.36\n-34.91\n-14.87\n0.24\n0.17\n499.52\n1632.53\n1.02\n\n\nDays:C(Subject)[337]\n1.31\n5.57\n-9.40\n11.36\n0.26\n0.18\n450.92\n1285.64\n1.02\n\n\nDays:C(Subject)[349]\n-4.81\n5.55\n-15.64\n5.20\n0.24\n0.17\n534.00\n1582.16\n1.01\n\n\nDays:C(Subject)[350]\n2.10\n5.55\n-8.33\n12.57\n0.26\n0.19\n438.22\n1180.72\n1.02\n\n\nDays:C(Subject)[351]\n-12.67\n5.52\n-22.70\n-2.30\n0.24\n0.17\n514.68\n1528.73\n1.02\n\n\nDays:C(Subject)[352]\n-13.89\n5.50\n-23.87\n-3.04\n0.26\n0.19\n430.77\n1230.56\n1.02\n\n\nDays:C(Subject)[369]\n-7.43\n5.45\n-18.21\n2.41\n0.24\n0.17\n495.72\n1255.54\n1.02\n\n\nDays:C(Subject)[370]\n-0.55\n5.51\n-10.04\n10.55\n0.26\n0.18\n450.52\n1328.24\n1.02\n\n\nDays:C(Subject)[371]\n-8.90\n5.52\n-18.74\n1.63\n0.26\n0.18\n461.25\n1229.82\n1.01\n\n\nDays:C(Subject)[372]\n-10.04\n5.57\n-20.17\n0.46\n0.26\n0.18\n473.14\n1291.15\n1.02\n\n\nIntercept\n247.65\n22.86\n205.21\n291.61\n1.55\n1.11\n216.31\n724.03\n1.03\n\n\nsigma\n25.75\n1.79\n22.47\n29.03\n0.03\n0.02\n3843.67\n2795.66\n1.00\n\n\n\n\n\n\n\nPer ricavare i coefficienti \\(\\alpha\\) delle regressioni individuali, dobbiamo sommare Intercept al valore del singolo soggetto. Per esempio, per il soggetto 309 abbiamo\n\n246.98 + -55.29\n\n191.69\n\n\nFacciamo lo stesso per la pendenza individuale delle rette di regressione. Per il soggetto 309 otteniamo\n\n21.30 + -16.97\n\n4.330000000000002\n\n\nQuesti valori sono identici a quelli che si otterrebbero se adattassimo il modello di regressione separatamente per ciascun soggetto. In effetti, abbiamo fatto proprio questo, utilizzando un modello unico. Per esempio, esaminiamo i singoli dati del soggetto 309.\n\ndata_subject_309 = data[data[\"Subject\"] == 309]\ndata_subject_309.shape\n\n(8, 3)\n\n\nStimiamo l’intercetta e la pendenza della retta di regressione usando l’approccio frequentista mediante la funzione linear_regression del pacchetto pingouin.\n\nresult = pg.linear_regression(data_subject_309[\"Days\"], data_subject_309[\"Reaction\"])\nprint(result)\n\n       names        coef        se          T          pval        r2  \\\n0  Intercept  191.576970  3.723259  51.454104  3.615788e-09  0.890144   \n1       Days    4.357144  0.624898   6.972569  4.325982e-04  0.890144   \n\n     adj_r2    CI[2.5%]   CI[97.5%]  \n0  0.871834  182.466483  200.687458  \n1  0.871834    2.828074    5.886214  \n\n\nSi noti che i risultati ottenuti sono sostanzialmente gli stessi, con solo qualche minima differenza numerica. Questa discrepanza deriva dalla diversità degli approcci utilizzati: in un caso abbiamo applicato un metodo bayesiano, mentre nell’altro abbiamo adottato una tecnica di stima frequentista.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#modello-partial-pooling",
    "href": "chapters/linear_models/10_hier_regr.html#modello-partial-pooling",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.6 Modello partial pooling",
    "text": "79.6 Modello partial pooling\nIl modello gerarchico, conosciuto anche come modello di “partial pooling”, consente di gestire la complessità presente nei dati raggruppati o clusterizzati, come nel caso presente. La regressione lineare classica presume che ogni osservazione sia indipendente dalle altre, ma questa ipotesi viene meno quando i dati sono organizzati in gruppi. Le osservazioni all’interno dello stesso gruppo tendono ad essere più correlate tra loro rispetto a quelle in gruppi diversi. Trascurare questa struttura gerarchica potrebbe portare a stime errate e conclusioni fuorvianti.\nIl modello gerarchico affronta questo problema introducendo la nozione di effetti casuali, in contrapposizione agli effetti fissi del modello classico. Gli effetti fissi rappresentano l’effetto medio di una variabile predittiva su tutti gli individui o gruppi, mentre gli effetti casuali considerano come l’effetto di una variabile possa variare da un gruppo all’altro. Mentre gli effetti fissi sono comuni a tutto il dataset, gli effetti casuali tengono conto delle differenze tra i gruppi.\nQuesto modello gerarchico unisce effetti fissi e casuali per fornire una rappresentazione più accurata dei dati, quando questi mostrano relazioni gerarchiche o raggruppate. Il modello gerarchico di “partial pooling” considera le somiglianze tra i soggetti stimando un’intercetta e una pendenza comuni, ma consente anche variazioni individuali attorno a questi valori medi.\nPossiamo rappresentare matematicamente il modello come segue:\n\\[\n\\begin{align*}\n\\text{Per il soggetto } i = 1, \\ldots, m, \\text{ e per l'osservazione } j = 1, \\ldots, n_i:\n\\end{align*}\n\\]\n\\[\n\\begin{align*}\n\\text{Reaction}_{ij} &= \\alpha_i + \\beta_i \\cdot \\text{Days}_{ij} + \\epsilon_{ij}, \\\\\n\\epsilon_{ij} &\\sim \\mathcal{N}(0, \\sigma^2),\n\\end{align*}\n\\]\ndove:\n\n\\(\\text{Reaction}_{ij}\\) è il tempo di reazione del soggetto \\(i\\) al giorno \\(j\\).\n\\(\\text{Days}_{ij}\\) è il numero di giorni per il soggetto \\(i\\) all’osservazione \\(j\\).\n\\(\\alpha_i\\) è l’intercetta per il soggetto \\(i\\), che segue la distribuzione \\(\\alpha_i \\sim \\mathcal{N}(\\alpha, \\tau_\\alpha^2)\\).\n\\(\\beta_i\\) è la pendenza per il soggetto \\(i\\), che segue la distribuzione \\(\\beta_i \\sim \\mathcal{N}(\\beta, \\tau_\\beta^2)\\).\n\\(\\epsilon_{ij}\\) è l’errore casuale per il soggetto \\(i\\) all’osservazione \\(j\\), distribuito normalmente con media 0 e varianza costante \\(\\sigma^2\\).\n\nI parametri \\(\\alpha\\) e \\(\\beta\\) rappresentano l’intercetta e la pendenza medie per tutti i soggetti, e le varianze \\(\\tau_\\alpha^2\\) e \\(\\tau_\\beta^2\\) quantificano le differenze tra gli individui.\nIn questo modo, il modello gerarchico riesce a rappresentare sia le informazioni comuni a tutti i soggetti, sia le differenze individuali, considerando sia gli effetti fissi che quelli casuali. Può quindi offrire una visione più completa e realistica dei dati, tenendo conto della loro struttura gerarchica. In Bambi, questo modello può essere specificato utilizzando la variabile Days come predittore e includendo Subject come effetto casuale.\n\nmodel_partial_pooling = bmb.Model(\n    \"Reaction ~ 1 + Days + (Days | Subject)\", data, categorical=\"Subject\"\n)\n\nEseguiamo il campionamento.\n\nresults_partial_pooling = model_partial_pooling.fit(\n    nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\n\nmodel_partial_pooling.build()\nmodel_partial_pooling.graph()\n\n\n\n\n\n\n\n\nEsaminiamo i risultati.\n\naz.summary(results_partial_pooling, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\n1|Subject[308]\n10.02\n18.26\n-23.88\n45.32\n0.30\n0.24\n3801.21\n3296.70\n1.0\n\n\n1|Subject[309]\n-43.21\n20.82\n-81.90\n-2.40\n0.37\n0.26\n3192.01\n2770.58\n1.0\n\n\n1|Subject[310]\n-25.98\n19.01\n-60.23\n10.11\n0.34\n0.24\n3180.64\n2886.98\n1.0\n\n\n1|Subject[330]\n4.68\n17.93\n-28.33\n39.60\n0.28\n0.25\n4049.42\n3086.98\n1.0\n\n\n1|Subject[331]\n22.05\n18.80\n-12.81\n57.32\n0.32\n0.24\n3416.40\n2908.07\n1.0\n\n\n1|Subject[332]\n34.64\n19.83\n-1.54\n71.69\n0.38\n0.27\n2774.25\n2704.53\n1.0\n\n\n1|Subject[333]\n11.22\n18.56\n-22.97\n47.30\n0.28\n0.24\n4343.31\n3323.77\n1.0\n\n\n1|Subject[334]\n-22.66\n18.29\n-55.72\n13.01\n0.33\n0.25\n3106.34\n2785.24\n1.0\n\n\n1|Subject[335]\n1.42\n18.81\n-33.38\n37.33\n0.33\n0.28\n3188.72\n2799.45\n1.0\n\n\n1|Subject[337]\n26.62\n19.63\n-9.98\n63.52\n0.31\n0.25\n4073.78\n2966.54\n1.0\n\n\n1|Subject[349]\n-27.94\n19.23\n-68.63\n4.02\n0.33\n0.24\n3381.72\n3363.24\n1.0\n\n\n1|Subject[350]\n-17.37\n19.44\n-54.77\n19.69\n0.33\n0.25\n3549.86\n2998.39\n1.0\n\n\n1|Subject[351]\n-2.22\n18.12\n-35.17\n33.75\n0.29\n0.26\n3981.53\n3361.50\n1.0\n\n\n1|Subject[352]\n43.03\n19.80\n3.35\n78.09\n0.40\n0.28\n2495.13\n2423.89\n1.0\n\n\n1|Subject[369]\n-2.06\n18.31\n-35.31\n32.90\n0.31\n0.26\n3570.39\n2953.34\n1.0\n\n\n1|Subject[370]\n-25.09\n18.76\n-58.40\n10.74\n0.34\n0.26\n3062.92\n3093.42\n1.0\n\n\n1|Subject[371]\n-7.11\n18.62\n-45.12\n24.89\n0.30\n0.26\n3873.47\n3069.79\n1.0\n\n\n1|Subject[372]\n15.17\n18.60\n-20.32\n50.26\n0.30\n0.24\n3831.96\n3202.78\n1.0\n\n\n1|Subject_sigma\n31.56\n9.02\n16.45\n50.30\n0.24\n0.17\n1431.60\n1806.76\n1.0\n\n\nDays\n11.50\n1.93\n7.87\n15.22\n0.05\n0.04\n1283.13\n1993.22\n1.0\n\n\nDays|Subject[308]\n8.10\n3.28\n2.23\n14.54\n0.07\n0.05\n2528.98\n2551.19\n1.0\n\n\nDays|Subject[309]\n-8.34\n3.67\n-15.35\n-1.50\n0.07\n0.06\n2401.88\n2808.43\n1.0\n\n\nDays|Subject[310]\n-7.38\n3.41\n-13.66\n-0.92\n0.07\n0.05\n2466.36\n3249.44\n1.0\n\n\nDays|Subject[330]\n-2.28\n3.30\n-8.32\n4.07\n0.07\n0.05\n2202.51\n2665.53\n1.0\n\n\nDays|Subject[331]\n-3.20\n3.36\n-9.57\n2.86\n0.07\n0.05\n2415.10\n2643.60\n1.0\n\n\nDays|Subject[332]\n-4.02\n3.54\n-10.46\n2.85\n0.08\n0.05\n2179.69\n2644.19\n1.0\n\n\nDays|Subject[333]\n0.46\n3.34\n-6.16\n6.42\n0.07\n0.05\n2638.74\n2977.03\n1.0\n\n\nDays|Subject[334]\n3.18\n3.30\n-3.22\n9.10\n0.07\n0.05\n2469.34\n2803.19\n1.0\n\n\nDays|Subject[335]\n-11.26\n3.48\n-18.02\n-4.83\n0.07\n0.05\n2639.50\n2714.43\n1.0\n\n\nDays|Subject[337]\n9.74\n3.53\n2.88\n16.27\n0.06\n0.05\n3136.50\n3060.31\n1.0\n\n\nDays|Subject[349]\n1.56\n3.39\n-4.91\n7.90\n0.07\n0.05\n2458.79\n2962.88\n1.0\n\n\nDays|Subject[350]\n7.23\n3.41\n0.87\n13.50\n0.07\n0.05\n2588.63\n2942.92\n1.0\n\n\nDays|Subject[351]\n-2.24\n3.26\n-7.88\n4.24\n0.06\n0.05\n2652.33\n2599.26\n1.0\n\n\nDays|Subject[352]\n0.18\n3.47\n-6.29\n6.87\n0.08\n0.05\n2071.05\n2663.67\n1.0\n\n\nDays|Subject[369]\n1.52\n3.29\n-4.94\n7.61\n0.07\n0.05\n2545.95\n2919.43\n1.0\n\n\nDays|Subject[370]\n4.78\n3.31\n-1.58\n10.65\n0.07\n0.05\n2263.23\n2665.64\n1.0\n\n\nDays|Subject[371]\n0.05\n3.33\n-6.09\n6.48\n0.06\n0.05\n2652.55\n2772.53\n1.0\n\n\nDays|Subject[372]\n0.77\n3.41\n-5.43\n7.29\n0.07\n0.05\n2455.49\n2748.16\n1.0\n\n\nDays|Subject_sigma\n6.89\n1.64\n4.07\n9.97\n0.04\n0.03\n1596.04\n1911.24\n1.0\n\n\nIntercept\n245.40\n9.34\n228.41\n262.89\n0.18\n0.12\n2855.59\n2917.47\n1.0\n\n\nsigma\n26.06\n1.84\n22.59\n29.37\n0.03\n0.02\n2872.83\n2912.40\n1.0\n\n\n\n\n\n\n\nConsideriamo il soggetto 309. Per questo soggetto l’intercetta è\n\n245.24 + -42.22\n\n203.02\n\n\ne la pendenza della retta di regressione è\n\n11.34 + -8.27\n\n3.0700000000000003\n\n\nSi noti che questi valori sono diversi da quelli ottenuti con la procedura di no-pooling. Entrambi i modelli di no pooling e il modello gerarchico di partial pooling riconoscono che ci possono essere differenze tra i diversi gruppi (o soggetti) nel dataset, ma gestiscono queste differenze in modi diversi.\nNel modello di no pooling, ogni gruppo viene trattato in modo completamente indipendente dagli altri. Ogni intercetta e pendenza viene stimata separatamente per ogni gruppo, senza fare riferimento agli altri gruppi. In altre parole, si adatta una regressione lineare separata per ciascun gruppo. Ciò significa che se si hanno molti gruppi, ci saranno molti parametri da stimare.\nQuesto approccio può catturare le differenze tra i gruppi molto accuratamente se ci sono molte osservazioni in ogni gruppo, ma può essere problematico se ci sono poche osservazioni per gruppo. Inoltre, non sfrutta le informazioni comuni tra i gruppi e può portare a stime molto variabili.\nIl modello gerarchico di partial pooling, invece, riconosce che, anche se ci sono differenze tra i gruppi, questi potrebbero condividere alcune caratteristiche comuni. Invece di stimare le intercette e pendenze completamente separatamente per ogni gruppo, il modello gerarchico stima una media comune e una varianza comune per l’intercetta e la pendenza, e poi consente a ciascun gruppo di variare attorno a questi valori comuni.\nQuesto porta al concetto di “shrinkage”. Le stime delle intercette e pendenze per ciascun gruppo tendono a essere “compresse” verso i valori medi. Se un gruppo ha poche osservazioni, la sua stima sarà più fortemente influenzata dalla media comune. Se ha molte osservazioni, la sua stima sarà meno influenzata dalla media comune. In questo modo, il modello riesce a bilanciare tra due tendenze opposte: rendere conto delle differenze tra i gruppi e sfruttare le informazioni comuni.\nIn sintesi, la differenza principale tra il modello no-pooling e il modello gerarchico partial-pooling sta nel modo in cui gestiscono le intercette e pendenze individuali:\n\nIl modello no-pooling tratta ogni gruppo separatamente, stimando le intercette e pendenze individuali senza considerare gli altri gruppi.\nIl modello gerarchico partial-pooling stima le intercette e pendenze comuni e consente a ciascun gruppo di variare attorno a questi valori comuni, dando luogo al fenomeno dello shrinkage.\n\nIl modello di no pooling può essere più adatto se i gruppi sono veramente indipendenti e molto diversi tra loro, mentre il modello gerarchico è maggiormente appropriato quando ci sono somiglianze tra i gruppi che possono essere sfruttate per ottenere stime più precise e robuste.\n\n79.6.1 Modello Gerarchico e Distribuzione dei Coefficienti\nIn un contesto di modello gerarchico con partial pooling, gli effetti casuali, inclusi intercette e pendenze specifiche per ciascun gruppo o individuo, vengono trattati come esiti di variabili aleatorie. Questo approccio si distingue nettamente da quello adottato nei modelli di no pooling, nei quali ciascun coefficiente viene considerato come un parametro statico e indipendente.\nAll’interno di un modello gerarchico, l’assunzione di base è che questi effetti casuali siano distribuiti normalmente. Ciò implica che ogni coefficiente specifico di un gruppo o individuo (come l’intercetta per un dato soggetto) è visto come una manifestazione di una variabile aleatoria che segue una distribuzione normale. La distribuzione di queste variabili aleatorie, che rappresenta la popolazione degli effetti casuali, è caratterizzata da una media e una varianza condivise tra tutti i gruppi o soggetti, le quali vengono inferite direttamente dai dati raccolti. Questo permette di modellare la variabilità intra-gruppo e inter-gruppo in modo più flessibile e informato, offrendo una rappresentazione più accurata della struttura dei dati e delle relazioni sottostanti.\nAd esempio, le intercette individuali \\(\\alpha_i\\) possono essere modellate come:\n\\[\n\\alpha_i \\sim \\mathcal{N}(\\alpha, \\tau_\\alpha^2),\n\\]\ndove \\(\\alpha\\) è l’intercetta media per tutti i soggetti e \\(\\tau_\\alpha^2\\) è la varianza delle intercette tra i soggetti. Analogamente, le pendenze individuali \\(\\beta_i\\) possono essere modellate come:\n\\[\n\\beta_i \\sim \\mathcal{N}(\\beta, \\tau_\\beta^2),\n\\]\ndove \\(\\beta\\) è la pendenza media e \\(\\tau_\\beta^2\\) è la varianza delle pendenze.\n\n\n79.6.2 Implicazioni\nQuesta struttura ha diverse implicazioni importanti:\n\nShrinkage: Come discusso in precedenza, le stime dei coefficienti individuali tendono a essere “compresse” verso i valori medi. Questo aiuta a stabilizzare le stime, specialmente quando ci sono poche osservazioni per gruppo.\nScambio di informazioni tra i gruppi: Poiché i coefficienti individuali sono considerati come estratti dalla stessa distribuzione, ciò permette uno scambio di informazioni tra i gruppi. Se un gruppo ha molte osservazioni, può aiutare a informare le stime per un gruppo con poche osservazioni.\nInterpretazione gerarchica: Il modello riconosce una struttura gerarchica nei dati, con osservazioni raggruppate all’interno di gruppi, e gruppi che condividono caratteristiche comuni. Questa struttura può riflettere una realtà sottostante nella quale gli individui o i gruppi non sono completamente indipendenti l’uno dall’altro.\n\nIn conclusione, il modello gerarchico di partial-pooling offre un quadro flessibile e potente per analizzare dati raggruppati o clusterizzati, riconoscendo sia le somiglianze che le differenze tra i gruppi e utilizzando una struttura probabilistica per modellare le relazioni tra di loro.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#interpretazione",
    "href": "chapters/linear_models/10_hier_regr.html#interpretazione",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.7 Interpretazione",
    "text": "79.7 Interpretazione\nIniziamo considerando le stime a posteriori degli effetti fissi.\n\naz.summary(results_partial_pooling, var_names=[\"Intercept\", \"Days\"], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n245.4\n9.34\n228.41\n262.89\n0.18\n0.12\n2855.59\n2917.47\n1.0\n\n\nDays\n11.5\n1.93\n7.87\n15.22\n0.05\n0.04\n1283.13\n1993.22\n1.0\n\n\n\n\n\n\n\nIn media, il tempo di reazione medio delle persone all’inizio dello studio è compreso tra 227 e 264 millisecondi. Con ogni giorno aggiuntivo di privazione del sonno, i tempi di reazione medi aumentano, in media, tra 7.9 e 15.1 millisecondi.\nL’interpretazione degli effetti fissi è semplice. Ma quest’analisi sarebbe incompleta e fuorviante se non valutiamo i termini specifici per i singoli soggetti che abbiamo aggiunto al modello. Questi termini ci dicono quanto i soggetti differiscono l’uno dall’altro in termini di tempo di reazione iniziale e dell’associazione tra giorni di privazione del sonno e tempi di reazione.\nDi seguito, utilizziamo ArviZ per ottenere un traceplot delle intercetti specifiche per i soggetti 1|Subject e delle pendenze Days|Subject. Questo traceplot contiene due colonne. A sinistra, abbiamo le distribuzioni posteriori e a destra abbiamo i trace-plots. L’aspetto casuale stazionario, o l’apparenza di rumore bianco, ci dice che il campionatore ha raggiunto la convergenza e le catene sono ben mescolate.\n\naz.plot_trace(\n    results_partial_pooling, combined=True, var_names=[\"1|Subject\", \"Days|Subject\"]\n)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nDall’ampiezza delle distribuzioni a posteriori delle intercette per i singoli soggetti possiamo vedere che il tempo di reazione medio iniziale per un determinato soggetto può differire notevolmente dalla media generale che abbiamo visto nella tabella precedente. C’è anche una grande differenza nelle pendenze. Alcuni soggetti vedono aumentare rapidamente i loro tempi di reazione quando vengono deprivati del sonno, mentre altri hanno una tolleranza migliore e peggiorano più lentamente.\nUna rappresentazione grafica della stima a posteriore dei parametri e dei dati si ottiene con az.plot_forest().\n\naz.plot_forest(data=results_partial_pooling, r_hat=False, combined=True, textsize=8);\n\n\n\n\n\n\n\n\nIn sintesi, il modello gerarchico cattura il comportamento che abbiamo visto nella fase di esplorazione dei dati. Le persone differiscono sia nei tempi di reazione iniziali che nel modo in cui questi tempi di reazione sono influenzati dai giorni di deprivazione del sonno. Possiamo dunque giungere alle seguenti conclusioni:\n\nIl tempo di reazione medio delle persone aumenta quando sono deprivate del sonno.\nI soggetti hanno tempi di reazione diversi all’inizio dello studio.\nAlcuni soggetti sono più colpiti dalla privazione del sonno rispetto ad altri.\n\nMa c’è un’altra domanda a cui non abbiamo ancora risposto: I tempi di reazione iniziali sono associati a quanto la deprivazione del sonno influisce sull’evoluzione dei tempi di reazione?\nCreiamo un diagramma a dispersione per visualizzare le stime a posteriori congiunte delle intercette e delle pendenze specifiche per i soggetti. Questo grafico usa colori diversi per i soggetti. Se guardiamo il quadro generale, cioè trascurando i ragruppamenti dei dati in base ai soggetti, possiamo concludere che non c’è associazione tra l’intercetta e la pendenza. In altre parole, avere tempi di reazione iniziali più bassi o più alti non dice nulla su quanto la deprivazione del sonno influisca sul tempo di reazione medio di un determinato soggetto.\nD’altra parte, se guardiamo la distribuzione a posteriori congiunta per un determinato individuo, possiamo vedere una correlazione negativa tra l’intercetta e la pendenza. Questo indica che, condizionalmente a un determinato soggetto, le stime a posteriori dell’intercetta e della pendenza non sono indipendenti.\n\n#  extract a subsample from the posterior and stack the chain and draw dims\nposterior = az.extract(results_partial_pooling, num_samples=500)\n\n_, ax = plt.subplots()\n\nresults_partial_pooling.posterior.plot.scatter(\n    x=\"1|Subject\", y=\"Days|Subject\",\n    hue=\"Subject__factor_dim\",\n    add_colorbar=False,\n    add_legend=False,\n    edgecolors=None,\n)\n\nax.axhline(c=\"0.25\", ls=\"--\")\nax.axvline(c=\"0.25\", ls=\"--\")\nax.set_xlabel(\"Subject-specific intercept\")\nax.set_ylabel(\"Subject-specific slope\");",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#confronto-dei-modelli",
    "href": "chapters/linear_models/10_hier_regr.html#confronto-dei-modelli",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.8 Confronto dei modelli",
    "text": "79.8 Confronto dei modelli\nUn aspetto finale e cruciale del nostro studio riguarda il confronto tra i diversi modelli che abbiamo esaminato. La nostra intenzione è determinare quale modello fornisce una rappresentazione migliore dei dati, trovando un equilibrio appropriato tra l’accuratezza del modello e la sua complessità, cioè la parsimonia.\nPer raggiungere questo scopo, faremo uso della metrica ELPD (Expected Log Predictive Density), che abbiamo introdotto in precedenza. ELPD ci consente di valutare un modello in termini di adattamento ai dati, considerando sia l’accuratezza delle previsioni che la complessità del modello.\n\n79.8.1 Utilizzo di az.compare()\nIn Python, possiamo sfruttare la funzione az.compare() per confrontare direttamente modelli bayesiani. Questa funzione accetta un dizionario contenente gli oggetti InferenceData, risultanti dalla funzione Model.fit(), e restituisce un dataframe. I modelli vengono ordinati dal migliore al peggiore in base ai criteri selezionati, e di default, ArviZ usa il criterio di convalida incrociata “leave one out” (LOO).\n\n79.8.1.1 Convalida Incrociata “Leave One Out” (LOO)\nLOO è una tecnica di convalida che addestra il modello su tutti i dati disponibili tranne uno, utilizzando il singolo punto escluso come dati di test. Questo processo viene ripetuto per ogni punto dati nel set, e la media delle misure di errore fornisce una stima accurata dell’errore di generalizzazione del modello. Anche se computazionalmente impegnativa, LOO fornisce una valutazione affidabile delle prestazioni del modello. In ArviZ, la funzione loo implementa questo metodo seguendo un approccio bayesiano.\n\n\n79.8.1.2 Widely Applicable Information Criterion (WAIC)\nOltre a LOO, possiamo anche utilizzare il criterio WAIC (Widely Applicable Information Criterion). Il WAIC è uno strumento per la selezione del modello che mira a trovare il modello ottimale in un insieme di candidati, equilibrando l’adattamento ai dati e la complessità del modello, evitando così il sovradattamento. WAIC è particolarmente utile nel contesto bayesiano, poiché tiene conto dell’incertezza associata ai parametri del modello.\nSia LOO che WAIC possono essere visti come stime empiriche dell’ELPD, fornendo un quadro comprensivo delle prestazioni dei modelli.\nUtilizzando la funzione az.compare(), siamo in grado di effettuare una comparazione rapida ed efficace tra i diversi modelli, valutandoli secondo i criteri LOO e WAIC. Nel nostro caso specifico, il modello di “partial pooling” emerge come il migliore, presentando il valore ELPD stimato più alto. Questo risultato conferma la validità del modello nel rappresentare la struttura dei dati, tenendo conto delle differenze individuali all’interno dei cluster, e fornendo una stima coerente e informativa dell’effetto della deprivazione del sonno sul tempo di reazione.\n\nmodels_dict = {\n    \"pooling\": results_pooling,\n    \"no_pooling\": results_no_pooling,\n    \"partial_pooling\": results_partial_pooling\n}\ndf_compare = az.compare(models_dict)\ndf_compare\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\npartial_pooling\n0\n-692.203378\n31.116753\n0.000000\n0.945524\n21.750623\n0.000000\nTrue\nlog\n\n\nno_pooling\n1\n-694.239760\n35.771777\n2.036382\n0.004772\n21.582485\n3.251708\nTrue\nlog\n\n\npooling\n2\n-772.176595\n3.066678\n79.973217\n0.049704\n9.054093\n20.322146\nFalse\nlog\n\n\n\n\n\n\n\nÈ importante sottolineare che, per ottenere una stima dell’ELPD (Expected Log Predictive Density), è necessario includere l’opzione idata_kwargs={\"log_likelihood\": True} all’interno della funzione responsabile dell’esecuzione del campionamento MCMC.\nLa figura che segue illustra visivamente le informazioni rilevanti per il confronto tra i diversi modelli. In grigio è indicata l’incertezza nella stima della differenza tra i valori ELPD dei diversi modelli.\n\n_ = az.plot_compare(df_compare, insample_dev=False)\n\n\n\n\n\n\n\n\nIl confronto tra i modelli guida il processo di selezione. In particolare, la comparazione tra il modello di partial-pooling e il modello completo di pooling è resa chiara dall’elpd_diff di 80.17 e dal suo errore standard di 19.97. Questi valori indicano inequivocabilmente che il modello di partial-pooling è superiore.\nLa situazione diventa più sfumata quando confrontiamo il modello di partial-pooling con il modello di no-pooling. In questo caso, le stime dell’ELPD mostrano una grande sovrapposizione, suggerendo che non c’è una differenza netta tra i due modelli in termini di adattamento ai dati.\nTuttavia, nonostante la vicinanza dei valori di ELPD, il modello di partial-pooling è da preferire. La ragione risiede nelle sue proprietà: esso fornisce stime più robuste e conservative delle differenze individuali. A differenza del modello di no-pooling, che può essere troppo sensibile alle variazioni all’interno dei cluster, il modello di partial-pooling incorpora un equilibrio tra la condivisione delle informazioni all’interno del gruppo e il riconoscimento delle differenze tra i gruppi. Questo lo rende più resistente alle fluttuazioni nei dati e offre una rappresentazione più affidabile delle relazioni sottostanti, rendendolo la scelta preferibile in questo contesto.\n\n\n79.8.1.3 PPC plots\nPer affrontare il tema della selezione di modelli, Johnson et al. (2022) usano anche il metodo dei posterior predictive checks. Creiamo dunque i PPC plots per i tre modelli.\n\nmodel_pooling_fitted = model_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_pooling.predict(model_pooling_fitted, kind=\"pps\")\n\n\n_ = az.plot_ppc(model_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\n\nmodel_no_pooling_fitted = model_no_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_no_pooling.predict(model_no_pooling_fitted, kind=\"pps\");\n\n\n_ = az.plot_ppc(model_no_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\n\nmodel_partial_pooling_fitted = model_partial_pooling.fit(idata_kwargs={\"log_likelihood\": True})\nmodel_partial_pooling.predict(model_partial_pooling_fitted, kind=\"pps\");\n\n\n_ = az.plot_ppc(model_partial_pooling_fitted, num_pp_samples=50)\n\n\n\n\n\n\n\n\nIn questo contesto specifico, l’analisi tramite i PPC (Posterior Predictive Checks) plots non rivela differenze evidenti tra i tre modelli in esame: tutti sembrano egualmente adeguati nell’adattarsi ai dati. Di conseguenza, i PPC plots non forniscono ulteriori chiarimenti o conferme alle conclusioni già raggiunte attraverso il confronto tra modelli basato sulla differenza ELPD (Expected Log Predictive Density). In altre parole, l’analisi visiva tramite i PPC plots non aggiunge valore o informazioni supplementari a quanto già dedotto dalle metriche di confronto.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#quale-modello-scegliere",
    "href": "chapters/linear_models/10_hier_regr.html#quale-modello-scegliere",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.9 Quale modello scegliere?",
    "text": "79.9 Quale modello scegliere?\nRitorniamo ora all’articolo di Gelman & Brown (2024). Questi autori affermano che un lettore ingenuo di molte discussioni sulla crisi della replicazione potrebbe avere l’impressione che tutto andrebbe bene se i ricercatori seguissero semplicemente i protocolli della scienza aperta ed evitassero le pratiche di ricerca disoneste. Tuttavia, i problemi sono più profondi, e uno di essi riguarda le difficoltà nell’analisi statistica dei dati.\nAungle & Langer (2023) hanno seguito le raccomandazioni generali di utilizzare la modellazione multilivello quando si analizzano dati raggruppati, ma non si sono resi conto che era necessario permettere agli effetti del trattamento, non solo all’intercetta, di variare tra i partecipanti. Gelman & Brown (2024) se ne sono accorti grazie agli indici t insolitamente alti e perché sono stati in grado di scaricare e interpretare il codice degli autori.\nNell’affrontare l’analisi di dati con struttura multilivello, Gelman & Brown (2024) suggeriscono come approccio ottimale di consentire la variazione sia delle intercette che degli effetti attraverso ogni livello di raggruppamento quando si stima un effetto causale o un coefficiente di regressione. Tuttavia, gli stessi autori riconoscono i limiti pratici di questa strategia. L’inclusione di componenti di varianza aggiuntivi può infatti compromettere la stabilità del modello, specialmente in presenza di campioni ridotti sia in termini di misurazioni che di partecipanti. Questa considerazione evidenzia come, nell’ambito delle ricerche psicologiche caratterizzate spesso da dati complessi, sia necessario un approccio flessibile e contestualizzato, piuttosto che l’applicazione di linee guida universali.\nIn aggiunta, quando emerge un risultato interessante, secondo Gelman & Brown (2024) è fondamentale consolidarlo attraverso una replicazione esatta (Nosek et al., 2012):\n\nWhen an interesting result arises, nail down the finding by designing and carrying out an exact replication. Contrary to all your expectations, the replication might fail; indeed that is the reason for performing the replication in the first place.\n\nQuesta pratica, oltre a rafforzare la validità delle scoperte, offre l’opportunità di rilevare eventuali falsi positivi, essenziale per il progresso scientifico.\nGelman & Brown (2024) suggeriscono inoltre di progettare nuovi studi basandosi su modelli ipotetici plausibili e di preregistrarli prima della raccolta dati. La fase di progettazione e preregistrazione è un momento opportuno per riflettere attentamente sulle dimensioni degli effetti e sulla loro variazione, nonché per comprendere un disegno sperimentale utilizzando dati simulati (Gelman, 2024).\nRiconoscendo l’importanza della preregistrazione, diverse riviste stanno aumentando il loro supporto a questa pratica. La forma più rigorosa attualmente disponibile, i Registered Reports, richiede che i piani di analisi statistica prespecificati dagli autori siano rivisti prima dell’inizio della raccolta dati, introducendo uno sguardo esterno e imparziale nel processo. I Registered Reports mostrano un notevole potenziale nella riduzione del bias di pubblicazione (Scheel et al., 2021).\nIn conclusione, secondo Gelman & Brown (2024), la scelta del modello statistico appropriato, la replicazione dei risultati e la preregistrazione degli studi sono elementi cruciali per affrontare le sfide metodologiche nella ricerca psicologica contemporanea.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#commenti-e-considerazioni-finali",
    "href": "chapters/linear_models/10_hier_regr.html#commenti-e-considerazioni-finali",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.10 Commenti e considerazioni finali",
    "text": "79.10 Commenti e considerazioni finali\nI modelli gerarchici sono utili per quantificare vari livelli di variabilità o incertezza. In questo capitolo, abbiamo analizzato e confrontato tre approcci statistici: pooling, no pooling e partial pooling, applicandoli ai dati dello studio sul sonno di Belenky et al. (2003). Ogni modello ha caratteristiche distintive:\n\nPooling: assume una struttura comune per tutti i gruppi, trattandoli come se fossero omogenei.\nNo pooling: mantiene l’indipendenza tra i gruppi, trattandoli in modo completamente separato.\nPartial pooling: rappresenta un compromesso tra i due approcci, bilanciando le informazioni condivise tra i gruppi e la loro individualità.\n\nPer selezionare il modello più appropriato, abbiamo utilizzato l’analisi basata sulla differenza della densità predittiva logaritmica attesa (ELPD). Questo metodo fornisce una misura oggettiva della qualità di adattamento, facilitando la scelta del modello che meglio riflette la struttura sottostante dei dati, pur riconoscendo i vantaggi specifici di ciascun approccio.\nAl di là delle considerazioni puramente statistiche, i modelli multilivello rivestono un ruolo importante nella discussione sulla crisi della replicabilità dei risultati della ricerca psicologica. Gelman & Brown (2024) offrono diverse utili raccomandazioni a questo proposito, sottolineando come tali modelli possano contribuire a migliorare la robustezza e l’affidabilità delle analisi.\nIn conclusione, l’adozione di metodologie statistiche avanzate, come la modellazione multilivello, rappresenta un passo cruciale verso una ricerca psicologica più solida. Questi approcci consentono di:\n\ncogliere la complessità dei fenomeni studiati,\nprodurre risultati più facilmente replicabili,\nfornire interpretazioni più accurate e contestualizzate.\n\nL’impiego di tali tecniche, unitamente a una maggiore consapevolezza metodologica, può contribuire significativamente al progresso della disciplina e all’incremento della fiducia nei risultati della ricerca psicologica. Si ricordi però che il loro utilizzo non è esente da insidie, come evidenziato in un recente studio di Gelman & Brown (2024).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#esercizi",
    "href": "chapters/linear_models/10_hier_regr.html#esercizi",
    "title": "79  Il modello lineare gerarchico",
    "section": "79.11 Esercizi",
    "text": "79.11 Esercizi\n\nEsercizio 79.1 Un recente studio (Aungle & Langer, 2023) ha presentato un esperimento che “ha esaminato se i segni lasciati dal cupping guarissero più velocemente o più lentamente in funzione del tempo percepito”. Il cupping “consiste nel creare una suzione localizzata sulla pelle …[che porta a] lividi”.\nTrentatré partecipanti sono stati sottoposti a questo trattamento tre volte. In ogni sessione, al partecipante veniva assegnato un compito della durata di 28 minuti, e venivano scattate fotografie della pelle prima e dopo questo intervallo. Le tre sessioni differivano per la manipolazione del “tempo percepito” dell’intervallo di recupero: ai partecipanti veniva detto che l’intervallo era di 14 minuti, 28 minuti o 56 minuti.\nI risultati riportati sono stati i seguenti:\n\nHealing in the 14-min condition had a mean rating of 6.17 (SD = 2.59, 32 Subjects, 800 ratings); healing in the 28-min condition had a mean rating of 6.43 (SD = 2.54, 33 Subjects, 825 ratings); and healing in the 56-min condition had a mean rating of 7.30 (SD = 2.25, 32 Subjects, 800 ratings).\n\nLa guarigione è stata valutata da 25 osservatori esterni, che hanno esaminato le fotografie prima e dopo il trattamento. La scala di valutazione era: “0.0 = per nulla guarito, 5.0 = parzialmente guarito, 10.0 = completamente guarito”.\nPer ciascuno dei tre confronti (56 min vs 28 min, 56 min vs 14 min, 28 min vs 14 min), è stato calcolato il punteggio t (stima divisa per l’errore standard). I valori risultanti sono stati rispettivamente 7.2, 10.7 e 2.5.\nUsando i dati forniti dagli autori (si veda il file healing.R), si replichi l’analisi di Gelman & Brown (2024) usando Bambi. Si interpretino i risultati alla luce delle considerazioni di Gelman & Brown (2024).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/10_hier_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/10_hier_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "79  Il modello lineare gerarchico",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npingouin  : 0.5.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\nnumpy     : 1.26.4\nbambi     : 0.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nGelman, A. (2024). Before data analysis: Additional recommendations for designing experiments to learn about the world. Journal of Consumer Psychology, 34, 190–191.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt Publishing Ltd.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Il modello lineare gerarchico</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_stan_mixed_models.html",
    "href": "chapters/linear_models/11_stan_mixed_models.html",
    "title": "80  Modelli misti con Stan",
    "section": "",
    "text": "Introduzione\nQuesto capitolo descrive l’utilizzo di Stan nell’analisi dei dati mediante modelli misti. Per un approfondimento, si veda Sorensen & Vasishth (2015).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_stan_mixed_models.html#applicazione-pratica",
    "href": "chapters/linear_models/11_stan_mixed_models.html#applicazione-pratica",
    "title": "80  Modelli misti con Stan",
    "section": "80.1 Applicazione Pratica",
    "text": "80.1 Applicazione Pratica\nPer fornire un esempio pratico, esamineremo i dati discussi da Gibson & Wu (2013) relativi a uno studio sulla comprensione delle frasi nelle proposizioni relative di soggetto e di oggetto. Una proposizione relativa di soggetto è una frase in cui un sostantivo (ad esempio, “senatore”) viene modificato da una proposizione relativa (ad esempio, “che ha interrogato il giornalista”), e il sostantivo modificato è il soggetto grammaticale della proposizione relativa. In una proposizione relativa di oggetto, il sostantivo modificato dalla proposizione relativa è l’oggetto grammaticale della proposizione (per esempio, “Il senatore che il giornalista ha interrogato si è dimesso”). In entrambi i casi, il sostantivo modificato (“senatore”) è chiamato il sostantivo principale.\nUn risultato comune per l’inglese è che le proposizioni relative di soggetto sono più facili da elaborare rispetto a quelle di oggetto. Le lingue naturali, in generale, includono proposizioni relative, e fino a poco tempo fa il vantaggio delle proposizioni di soggetto è stato considerato valido a livello cross-linguistico. Tuttavia, le proposizioni relative in cinese rappresentano un interessante controesempio a questa generalizzazione. Ricerche recenti condotte da Hsiao e Gibson (2003) hanno suggerito che in cinese le proposizioni relative di oggetto sono più facili da elaborare rispetto a quelle di soggetto in un punto specifico della frase (il sostantivo principale della proposizione relativa). Viene presentata un’analisi di un insieme di dati, successivamente pubblicata da Gibson & Wu (2013), che valuta questa affermazione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_stan_mixed_models.html#i-dati",
    "href": "chapters/linear_models/11_stan_mixed_models.html#i-dati",
    "title": "80  Modelli misti con Stan",
    "section": "80.2 I Dati",
    "text": "80.2 I Dati\nLa variabile dipendente dell’esperimento di Gibson & Wu (2013) era il tempo di lettura (rt) in millisecondi del sostantivo principale della proposizione relativa. Questo è stato registrato in due condizioni (proposizione relativa di soggetto e proposizione relativa di oggetto), con 37 soggetti e 15 item, presentati in un disegno standard a quadrato latino. Originariamente c’erano 16 item, ma uno è stato rimosso, risultando in 37 × 15 = 555 punti dati. Tuttavia, otto punti dati da un soggetto (id 27) erano mancanti. Di conseguenza, abbiamo un totale di 555 - 8 = 547 punti dati. La condizione (object relative / subject relative) è codificata dalla variabile so.\n\nfile_path = os.path.join(project_directory, \"data\", \"gibson_wu_2013.csv\")\ngibson_data = pd.read_csv(file_path)\ngibson_data.head()\n\n\n\n\n\n\n\n\nsubj\nitem\ntype\npos\nword\ncorrect\nrt\nregion\ntype2\nso\n\n\n\n\n0\n1\n13\nobj-ext\n8\n男人\n-\n1561\nheadnoun\nobject relative\n1\n\n\n1\n1\n6\nsubj-ext\n8\n女孩\n-\n959\nheadnoun\nsubject relative\n-1\n\n\n2\n1\n5\nobj-ext\n8\n轎車\n-\n582\nheadnoun\nobject relative\n1\n\n\n3\n1\n9\nobj-ext\n8\n探員\n-\n294\nheadnoun\nobject relative\n1\n\n\n4\n1\n14\nsubj-ext\n8\n空服員\n-\n438\nheadnoun\nsubject relative\n-1\n\n\n\n\n\n\n\n\ngibson_data.tail()\n\n\n\n\n\n\n\n\nsubj\nitem\ntype\npos\nword\ncorrect\nrt\nregion\ntype2\nso\n\n\n\n\n542\n9\n15\nobj-ext\n8\n演員\n-\n406\nheadnoun\nobject relative\n1\n\n\n543\n9\n16\nsubj-ext\n8\n記者\n-\n342\nheadnoun\nsubject relative\n-1\n\n\n544\n9\n7\nobj-ext\n8\n狗\n-\n478\nheadnoun\nobject relative\n1\n\n\n545\n9\n8\nsubj-ext\n8\n業餘選手\n-\n510\nheadnoun\nsubject relative\n-1\n\n\n546\n9\n11\nobj-ext\n8\n球員\n-\n350\nheadnoun\nobject relative\n1\n\n\n\n\n\n\n\n\ngibson_data.shape\n\n(547, 10)\n\n\n\ngibson_data[\"RT\"] = gibson_data[\"rt\"] / 1000\n\n\n_ = sns.kdeplot(data=gibson_data, x='RT', hue='so', fill=True, common_norm=False, alpha=0.5)",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_stan_mixed_models.html#modello-ad-effetti-fissi",
    "href": "chapters/linear_models/11_stan_mixed_models.html#modello-ad-effetti-fissi",
    "title": "80  Modelli misti con Stan",
    "section": "80.3 Modello ad effetti fissi",
    "text": "80.3 Modello ad effetti fissi\nIniziamo facendo l’assunzione che la variabile dipendente del tempo di lettura (rt) sul sostantivo principale sia distribuita approssimativamente in modo log-normale (Rouder, 2005). Questo presuppone che il logaritmo di rt sia distribuito approssimativamente in modo normale. Il logaritmo dei tempi di lettura, logrt, ha una media β0 sconosciuta. La media della distribuzione log-normale di rt è la somma di β0 e di uno scarto β1so il cui valore dipende dal predittore categoriale so, che assume il valore di -1 quando rt proviene dalla condizione di proposizione relativa di soggetto, e 1 quando rt proviene dalla condizione di proposizione relativa di oggetto.\nIl modello del logaritmo dei tempi di lettura è dunque il seguente:\n\\[\nlogrt_i = \\beta_0 + \\beta_1 so_i + \\epsilon_i.\n\\]\nQuesto è un modello a effetti fissi. L’indice i rappresenta la i-esima riga nel frame dati (in questo caso, i ∈ {1, . . . , 547}); il termine εi rappresenta l’errore nella i-esima riga. Con la variabile so codificata come indicato sopra indicato, β0 rappresenta la media di log rt, indipendentemente dal tipo di proposizione relativa. Il parametro β1 è lo scarto rispetto a β0 in modo che la media di log rt sia β0 + 1β1 quando log rt proviene dalla condizione di proposizione relativa di oggetto, e β0 - 1β1 quando log rt proviene dalla condizione di proposizione relativa di soggetto. In tali circostanze, 2β1 corrisponde alla differenza tra le medie nelle condizioni di proposizione relativa di oggetto e di soggetto. Insieme, β0 e β1 costituiscono le componenti del modello che caratterizzano l’effetto della manipolazione sperimentale (il tipo di proposizione relativa) sulla variabile dipendente rt. Questo è un modello ad effetti fissi perché i parametri β0 e β1 non variano da soggetto a soggetto o da item a item.\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"fixed_effects.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N;                // Number of data points\n  vector[N] rt;                  // Reading time\n  vector[N] so;                  // Predictor, constrained between -1 and 1\n}\nparameters {\n  vector[2] beta;                // Intercept and slope\n  real&lt;lower=0&gt; sigma_e;         // Error standard deviation\n}\nmodel {\n  vector[N] mu;\n\n  // Define the model for mu using vectorized operations\n  mu = beta[1] + beta[2] * so;\n\n  // Vectorized likelihood\n  rt ~ lognormal(mu, sigma_e);\n}\n\n\n\nCreiamo un dizionario che include i dati nel formato atteso dal precedente codice Stan.\n\nstan_data = {\n    \"N\" : gibson_data.shape[0],\n    \"rt\" : gibson_data[\"RT\"],\n    \"so\" : gibson_data[\"so\"] \n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo le tracce.\n\n_ = az.plot_trace(fit, var_names=([\"beta\", \"sigma_e\"]), compact=False)\n\n\n\n\n\n\n\n\nEsaminiamo le medie a posteriori e gli intervalli di credibilità dei parametri.\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.03\n-0.90\n-0.80\n0.0\n0.0\n3535.32\n2985.81\n1.0\n\n\nbeta[1]\n-0.04\n0.03\n-0.09\n0.01\n0.0\n0.0\n4901.41\n3327.06\n1.0\n\n\nsigma_e\n0.60\n0.02\n0.56\n0.63\n0.0\n0.0\n4436.39\n2709.09\n1.0\n\n\n\n\n\n\n\nL’analisi della distribuzione di β1 indica che approssimativamente il 94% della densità di probabilità a posteriori è al di sotto dello zero, suggerendo che, in cinese, ci sia qualche evidenza che le proposizioni relative oggetto siano più facili da elaborare rispetto alle proposizioni relative soggetto, dati i dati di Gibson & Wu (2013). Tuttavia, poiché l’intervallo di credibilità al 95% include lo zero, potremmo essere riluttanti a trarre questa conclusione, se vogliamo adottare un approccio “quasi frequentista” di test di ipotesi.\nTuttavia, è importante notare che il modello ad effetti fissi presentato qui non è comunque appropriato per i dati attuali. L’assunzione di indipendenza degli errori viene violata, perché abbiamo misure ripetute per ciascun soggetto e per ciascun item. I modelli lineari misti estendono il modello lineare per risolvere precisamente questo problema.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_stan_mixed_models.html#modello-ad-intercette-casuali",
    "href": "chapters/linear_models/11_stan_mixed_models.html#modello-ad-intercette-casuali",
    "title": "80  Modelli misti con Stan",
    "section": "80.4 Modello ad Intercette Casuali",
    "text": "80.4 Modello ad Intercette Casuali\nIl modello degli effetti fissi non è adatto per i dati di Gibson & Wu (2013) poiché non tiene conto del fatto che abbiamo misurazioni multiple per ciascun soggetto e item. Come già accennato, queste misurazioni multiple portano a una violazione dell’assunzione di indipendenza degli errori. Inoltre, i coefficienti degli effetti fissi β0 e β1 rappresentano medie su tutti i soggetti e gli item, ignorando il fatto che alcuni soggetti saranno più veloci e alcuni più lenti della media; allo stesso modo, alcuni item saranno letti più rapidamente della media e altri più lentamente.\nNei modelli lineari misti, prendiamo in considerazione questa variabilità per soggetto e per item aggiungendo i termini di correzione u0j e w0k, che aggiustano β0 per il soggetto j e l’item k. Questo scompone parzialmente εi in una somma di termini u0j e w0k, che sono gli aggiustamenti dell’intercetta β0 per il soggetto j e l’item k associato a rt_i. Se il soggetto j è più lento della media di tutti i soggetti, uj sarà un numero positivo, e se l’item k viene letto più velocemente della durata media di tutti gli item, allora wk sarà un numero negativo. Ogni soggetto j ha il proprio aggiustamento u0j, e ogni item ha il proprio aggiustamento w0k. Questi aggiustamenti u0j e w0k sono chiamati intercette casuali (random intercepts) da Pinheiro e Bates (2000) e intercette variabili (varying intercepts) da Gelman e Hill (2007), e aggiustando β0 con questi termini miglioriamo la nostra capacità di tener conto della variabilità per i soggetti e per gli item.\nIl modello statistico ad intercette casuali assume che questi aggiustamenti sono distribuiti normalmente intorno allo zero con deviazione standard sconosciuta:\n\\[\nu_0 \\sim N(0, \\sigma_u),\n\\]\n\\[\nw_0 ∼ N(0, \\sigma_w).\n\\]\nAvendo specificato il modello in questo modo, ci sono tre fonti di varianza: la deviazione standard degli errori σe, la deviazione standard delle intercette casuali per i soggetti, σu, e la deviazione standard delle intercette casuali per gli item, σw. Ci riferiamo a questi valori come alle componenti della varianza.\nEsprimiamo ora il logaritmo del tempo di lettura, prodotto dai soggetti j ∈ {1, . . . , 37} che leggono gli item k ∈ {1,…, 15}, nelle condizioni i ∈ {1, 2} (1 si riferisce alle proposizioni soggetto, 2 alle proposizioni oggetto), come la seguente somma.\n\\[\n\\log rt_{ijk} = \\beta_0 + \\beta_{1i} + u_{0j} + w_{0k} + \\varepsilon_{ijk}.\n\\]\nNotiamo che stiamo utilizzando un modo leggermente diverso per descrivere il modello, rispetto al modello degli effetti fissi. Stiamo utilizzando indici per soggetto, item e condizione per identificare ciascuna riga del data frame. Inoltre, anziché scrivere \\(\\beta_1 so_i\\), indicizziamo direttamente β1 in funzione della condizione i (essendo so \\(\\in \\{-1, 1\\}\\)).\nQuesto è un modello è un modello ad effetti misti, e più specificamente un modello ad intercette casuali. Il coefficiente \\(\\beta_{1i}\\) è quello di maggior interesse; avrà un valore medio −β1 per le proposizioni soggetto e β1 per le proposizioni oggetto a causa della codifica del contrasto. Quindi, se la nostra media a posteriori per β1 è negativa, ciò suggerirebbe che le proposizioni oggetto vengono lette più velocemente delle proposizioni soggetto.\n\nstan_file = os.path.join(project_directory, \"stan\", \"random_intercepts.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:33:49 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts\n12:34:01 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/random_intercepts\n\n\ndata {\n  int&lt;lower=0&gt; N;                  // Number of data points\n  vector[N] rt;                    // Reading time\n  vector[N] so;                    // Predictor, constrained between -1 and 1\n  int&lt;lower=0&gt; J;                  // Number of subjects\n  int&lt;lower=0&gt; K;                  // Number of items\n  array[N] int&lt;lower=0, upper=J&gt; subj;\n  array[N] int&lt;lower=0, upper=K&gt; item;\n}\nparameters {\n  vector[2] beta;                  // Fixed intercept and slope\n  vector[J] u;                     // Subject intercepts\n  vector[K] w;                     // Item intercepts\n  real&lt;lower=0&gt; sigma_e;           // Error standard deviation\n  real&lt;lower=0&gt; sigma_u;           // Subject standard deviation\n  real&lt;lower=0&gt; sigma_w;           // Item standard deviation\n}\nmodel {\n  vector[N] mu;\n\n  // Priors\n  beta ~ normal(0, 5);             // Assuming a weakly informative prior for beta\n  u ~ normal(0, sigma_u);\n  w ~ normal(0, sigma_w);\n  sigma_e ~ exponential(1);\n  sigma_u ~ exponential(1);\n  sigma_w ~ exponential(1);\n\n  // Likelihood\n  mu = beta[1] + beta[2] * so + u[subj] + w[item];  // Vectorized computation of mu\n  rt ~ lognormal(mu, sigma_e);\n}\n\n\n\n\nstan_data = {\n    'subj': pd.factorize(gibson_data['subj'])[0] + 1,\n    'item': pd.factorize(gibson_data['item'])[0] + 1,\n    'rt': gibson_data['RT'].values,\n    'so': gibson_data['so'].values,\n    'N': len(gibson_data),\n    'J': gibson_data['subj'].nunique(),\n    'K': gibson_data['item'].nunique()\n}\n\n\nfit = model.sample(data=stan_data)\n\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\", \"sigma_u\", \"sigma_w\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.07\n-0.97\n-0.70\n0.0\n0.0\n1101.73\n1576.57\n1.0\n\n\nbeta[1]\n-0.04\n0.02\n-0.08\n0.01\n0.0\n0.0\n9851.81\n3141.84\n1.0\n\n\nsigma_e\n0.52\n0.02\n0.49\n0.55\n0.0\n0.0\n7247.72\n2689.88\n1.0\n\n\nsigma_u\n0.25\n0.04\n0.17\n0.33\n0.0\n0.0\n3714.95\n2902.11\n1.0\n\n\nsigma_w\n0.20\n0.05\n0.11\n0.30\n0.0\n0.0\n3978.74\n2983.07\n1.0\n\n\n\n\n\n\n\nSi noti che rispetto al Modello ad effetti fissi, la stima di σe è più piccola; questo perché ora vengono stimate due componenti di varianza aggiuntive. Si noti inoltre che l’intervallo di credibilità al 95% per la stima di β1 include lo zero; quindi, c’è ancora qualche evidenza che le proposizioni oggetto siano più facili delle proposizioni soggetto, ma non possiamo escludere la possibilità che non ci sia una differenza credibile nei tempi di lettura tra i due tipi di proposizioni relative.\nIl presente modello con intercette casuali assume che l’effetto della variabile so sia lo stesso per ciascun soggetto.Ma questo non è necessariamente vero. Per consentire al modello di tenere conto che l’effetto della variabile so possa variare tra i soggetti, dobbiamo estendere il presente modello e trasformarlo in un modello che include sia intercette sia pendenze casuali.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_stan_mixed_models.html#random-intercepts-random-slopes-model",
    "href": "chapters/linear_models/11_stan_mixed_models.html#random-intercepts-random-slopes-model",
    "title": "80  Modelli misti con Stan",
    "section": "80.5 Random Intercepts, Random Slopes Model",
    "text": "80.5 Random Intercepts, Random Slopes Model\nPer esprimere la struttura descritta sopra nel modello lineare misto, dobbiamo specificare le pendenze casuali. Il primo cambiamento consiste nel permettere che la dimensione dell’effetto per so varii per soggetto e per item. Consentiamo che la dimensione dell’effetto vari per soggetto e per item includendo nel modello pendenze variabili per soggetto e per item, che costituiscono degli scarti rispetto alla pendenza fissa β1, allo stesso modo in cui le intercette variabili per soggetto e per item aggiustano l’intercetta fissa β0. Questo aggiustamento della pendenza per soggetto e per item è espresso aggiustando β1 tramite due termini u1j e w1k. Questi termini rappresentano le pendenze casuali. Aggiungendo al modello tali termini aggiuntivi possiamo rendere conto del fatto che l’effetto del tipo di proposizione relativa varia per soggetto j e per item k.\nEsprimiamo il logaritmo del tempo di lettura, prodotto dal soggetto j che legge l’item k, come la seguente somma.\n\\[\n\\text{log } rt_{ijk} = \\beta_0 + u_{0j} + w_{0k} + \\beta_{1i} + u_{1ij} + w_{1ik} + \\epsilon_{ijk},\n\\]\ndove il pedice \\(i\\) indica le condizioni. Questo è un modello di intercette variabili e pendenze variabili.\nIl modello è specificato in linguaggio Stan come indicato nel file random_slopes.stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"random_slopes.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:35:00 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/random_slopes.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/random_slopes\n12:35:11 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/random_slopes\n\n\ndata {\n  int&lt;lower=0&gt; N;                  // Number of data points\n  vector[N] rt;                    // Reading time\n  vector[N] so;                    // Predictor, constrained between -1 and 1\n  int&lt;lower=0&gt; J;                  // Number of subjects\n  int&lt;lower=0&gt; K;                  // Number of items\n  array[N] int&lt;lower=0, upper=J&gt; subj;\n  array[N] int&lt;lower=0, upper=K&gt; item;\n}\nparameters {\n  vector[2] beta;                  // Fixed intercept and slope\n  real&lt;lower=0&gt; sigma_e;           // Error standard deviation\n  matrix[2,J] u;                   // Subject intercepts and slopes\n  vector&lt;lower=0&gt;[2] sigma_u;      // Subject standard deviations\n  matrix[2,K] w;                   // Item intercepts and slopes\n  vector&lt;lower=0&gt;[2] sigma_w;      // Item standard deviations\n}\nmodel {\n  // Priors\n  for (j in 1:J) {\n    u[1,j] ~ normal(0, sigma_u[1]); // Prior for subject intercepts\n    u[2,j] ~ normal(0, sigma_u[2]); // Prior for subject slopes\n  }\n  \n  for (k in 1:K) {\n    w[1,k] ~ normal(0, sigma_w[1]); // Prior for item intercepts\n    w[2,k] ~ normal(0, sigma_w[2]); // Prior for item slopes\n  }\n  \n  // Likelihood\n  for (i in 1:N) {\n    real mu = beta[1] + u[1, subj[i]] + w[1, item[i]]\n              + (beta[2] + u[2, subj[i]] + w[2, item[i]]) * so[i];\n    rt[i] ~ lognormal(mu, sigma_e);\n  }\n}\n\n\n\n\n\nfit = model.sample(\n    data=stan_data,\n    iter_sampling=2000,\n    iter_warmup=1000,\n)\n\n\naz.summary(fit, var_names=([\"beta\", \"sigma_e\", \"sigma_u\", \"sigma_w\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta[0]\n-0.85\n0.07\n-0.98\n-0.71\n0.00\n0.0\n706.84\n302.85\n1.01\n\n\nbeta[1]\n-0.04\n0.03\n-0.09\n0.02\n0.00\n0.0\n1982.52\n4756.68\n1.00\n\n\nsigma_e\n0.52\n0.02\n0.48\n0.55\n0.00\n0.0\n2288.99\n5672.93\n1.00\n\n\nsigma_u[0]\n0.25\n0.04\n0.18\n0.34\n0.00\n0.0\n712.02\n275.18\n1.01\n\n\nsigma_u[1]\n0.06\n0.04\n0.01\n0.12\n0.01\n0.0\n39.10\n29.54\n1.09\n\n\nsigma_w[0]\n0.20\n0.05\n0.11\n0.30\n0.00\n0.0\n4099.46\n5332.27\n1.00\n\n\nsigma_w[1]\n0.04\n0.03\n0.00\n0.11\n0.00\n0.0\n114.76\n68.32\n1.03\n\n\n\n\n\n\n\nAnche in questo caso, Sorensen & Vasishth (2015) commentano che l’intervallo di credibilità al 95% per \\(\\beta_1\\) include lo zero.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_stan_mixed_models.html#modello-a-effetti-misti-con-pendenze-e-intercepce-casuali-correlate",
    "href": "chapters/linear_models/11_stan_mixed_models.html#modello-a-effetti-misti-con-pendenze-e-intercepce-casuali-correlate",
    "title": "80  Modelli misti con Stan",
    "section": "80.6 Modello a Effetti Misti con Pendenze e Intercepce Casuali Correlate",
    "text": "80.6 Modello a Effetti Misti con Pendenze e Intercepce Casuali Correlate\nSorensen & Vasishth (2015), nell’approfondire l’analisi dei dati presentati da Gibson & Wu (2013), propongono un avanzamento metodologico nel modello preso in considerazione, introducendo un modello a effetti misti che incorpora intercette e pendenze casuali correlate. La logica dietro questo approccio consiste nell’esaminare la possibilità che vi sia una relazione tra la velocità di lettura dei soggetti (espressa attraverso intercette casuali) e la loro reazione alle diverse tipologie di proposizioni (oggetto vs. soggetto), ipotizzando che soggetti con una velocità di lettura superiore alla media possano esperire un rallentamento maggiore nel leggere proposizioni oggetto rispetto alle proposizioni soggetto, e viceversa. Questa ipotesi suggerisce l’esistenza di correlazioni tra le intercette casuali (che rappresentano variazioni individuali nella velocità di base di lettura) e le pendenze casuali (che rappresentano la variazione nella risposta al tipo di proposizione).\nPer integrare questa struttura nel modello lineare misto (LMM), è essenziale modellare la correlazione tra intercette casuali e pendenze casuali. La formula del modello, la quale rimane inalterata rispetto alla versione precedente, è rappresentata come segue:\n\\[\n\\text{log } rt_{ijk} = \\beta_0 + u_{0j} + w_{0k} + \\beta_1 + u_{1ij} + w_{1ik} + \\epsilon_{ijk}.\n\\]\nL’introduzione di correlazioni tra intercette e pendenze casuali trasforma il modello in un approccio di intercette e pendenze correlate, richiedendo la definizione di una matrice di varianza-covarianza per gli effetti casuali. Questo implica la necessità di stabilire una relazione di covarianza tra le intercette casuali (per soggetto e per item) e le pendenze casuali (per soggetto e per item), suggerendo che le pendenze per soggetto (u1) potrebbero correlare con le intercette per soggetto (u0), così come le pendenze per item (w1) potrebbero correlare con le intercette per item (w0). Questo approccio offre una visione più dettagliata e accurata della dinamica tra velocità di lettura individuale e reazione alle differenti strutture sintattiche, arricchendo significativamente l’analisi statistica dei dati comportamentali.\nNel contesto di questo insegnamento, non approfondiremo la formulazione del modello Stan che include la correlazione tra pendenze e intercette, data la sua complessità tecnica. Tuttavia, è importante sottolineare che è possibile ottenere risultati analoghi con un approccio più accessibile utilizzando il pacchetto Bambi per Python. Questo strumento consente di specificare modelli statistici in maniera intuitiva e diretta. Per esempio, per incorporare la correlazione tra pendenze e intercette nel nostro modello, possiamo utilizzare la seguente sintassi con Bambi:\nmodel = bmb.Model(\"rt ~ so + (so | subject) + (so | item)\", data)\nQuesta espressione crea un modello in cui rt (il tempo di risposta) è modellato come una funzione del tipo di proposizione so, con pendenze e intercette casuali correlate sia per subject che per item. L’uso di (so | subject) e (so | item) permette di modellare specificamente le variazioni nelle risposte attribuibili a differenze individuali tra i soggetti e caratteristiche uniche degli item, rispettivamente. Questa sintassi semplifica notevolmente l’implementazione di modelli complessi, rendendo l’analisi accessibile anche a chi possiede una conoscenza di base della statistica bayesiana e della modellazione statistica.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/11_stan_mixed_models.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/11_stan_mixed_models.html#informazioni-sullambiente-di-sviluppo",
    "title": "80  Modelli misti con Stan",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanp\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanp: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nmatplotlib: 3.9.1\nscipy     : 1.14.0\narviz     : 0.18.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGibson, E., & Wu, H.-H. I. (2013). Processing Chinese relative clauses in context. Language and Cognitive Processes, 28(1-2), 125–155.\n\n\nSorensen, T., & Vasishth, S. (2015). Bayesian linear mixed models using Stan: A tutorial for psychologists, linguists, and cognitive scientists. arXiv preprint arXiv:1506.06201.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>Modelli misti con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_specification_error.html",
    "href": "chapters/linear_models/12_specification_error.html",
    "title": "81  Errore di specificazione",
    "section": "",
    "text": "Introduzione\nIn questo capitolo esamineremo l’errore di specificazione nei modelli di regressione lineare. L’errore di specificazione si verifica quando una variabile importante viene omessa dal modello, causando stime dei coefficienti che risultano sistematicamente distorte e inconsistenti.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_specification_error.html#dimostrazione",
    "href": "chapters/linear_models/12_specification_error.html#dimostrazione",
    "title": "81  Errore di specificazione",
    "section": "81.1 Dimostrazione",
    "text": "81.1 Dimostrazione\nLa dimostrazione algebrica dell’errore di specificazione nel modello di regressione, in caso di omissione di una variabile rilevante, coinvolge l’analisi delle conseguenze che questa omissione ha sulla stima dei coefficienti di regressione.\nQuando un modello di regressione omette una variabile rilevante che è correlata sia con la variabile dipendente \\(Y\\) sia con almeno una delle variabili indipendenti incluse nel modello, il coefficiente stimato per le variabili indipendenti incluse può essere sistematicamente distorto.\nPer comprendere il bias causato dall’omissione di una variabile rilevante in un modello di regressione, è essenziale analizzare dettagliatamente il calcolo delle covarianze e varianze coinvolte. Di seguito viene fornita una spiegazione dei passaggi algebrici che portano alla formulazione del bias di omissione variabile (Omitted Variable Bias, OVB).\n\n81.1.1 Modello Completo e Modello Ridotto\n\nModello Completo:\n\\[\nY = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\epsilon\n\\]\nQui, \\(Y\\) è la variabile dipendente, \\(X\\) e \\(Z\\) sono variabili indipendenti, \\(\\beta_0, \\beta_1, \\beta_2\\) sono i coefficienti, e \\(\\epsilon\\) è il termine di errore.\nModello Ridotto (con omissione di \\(Z\\)):\n\\[\nY = \\alpha_0 + \\alpha_1 X + u\n\\]\ndove \\(u = \\beta_2 Z + \\epsilon\\) rappresenta il nuovo termine di errore che ora include l’effetto non osservato di \\(Z\\).\n\n\n\n81.1.2 Decomposizione di \\(X\\)\nIpotesi:\n\\[ X = \\gamma_0 + \\gamma_1 Z + V \\]\ndove \\(V\\) è una parte di \\(X\\) indipendente da \\(Z\\), quindi \\(\\text{Cov}(V, Z) = 0\\).\n\n\n81.1.3 Sostituzione nel Modello Ridotto\nSostituendo la decomposizione di \\(X\\) nel modello ridotto, otteniamo:\n\\[ Y = \\alpha_0 + \\alpha_1 (\\gamma_0 + \\gamma_1 Z + V) + u \\]\n\\[ Y = \\alpha_0 + \\alpha_1 \\gamma_0 + \\alpha_1 \\gamma_1 Z + \\alpha_1 V + \\beta_2 Z + \\epsilon \\]\n\\[ Y = (\\alpha_0 + \\alpha_1 \\gamma_0) + (\\alpha_1 \\gamma_1 + \\beta_2) Z + \\alpha_1 V + \\epsilon \\]\n\n\n81.1.4 Calcolo della Covarianza \\(\\text{Cov}(Y, X)\\)\n\\[ \\text{Cov}(Y, X) = \\text{Cov}(\\beta_1 X + \\beta_2 Z + \\epsilon, X) \\]\n\\[ \\text{Cov}(Y, X) = \\beta_1 \\text{Var}(X) + \\beta_2 \\text{Cov}(Z, X) \\]\ndove si usa che \\(\\text{Cov}(\\epsilon, X) = 0\\) poiché \\(\\epsilon\\) è indipendente da \\(X\\).\n\n\n81.1.5 Calcolo della Varianza di \\(X\\)\n\\[ \\text{Var}(X) = \\text{Var}(\\gamma_0 + \\gamma_1 Z + V) \\]\n\\[ \\text{Var}(X) = \\gamma_1^2 \\text{Var}(Z) + \\text{Var}(V) \\]\nAncora, \\(\\text{Cov}(Z, V) = 0\\) perché \\(V\\) è definito come indipendente da \\(Z\\).\n\n\n81.1.6 Formula del Coefficiente Stimato \\(\\hat{\\alpha}_1\\)\n\\[ \\hat{\\alpha}_1 = \\frac{\\text{Cov}(Y, X)}{\\text{Var}(X)} \\]\n\\[ \\hat{\\alpha}_1 = \\beta_1 + \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} \\]\n\n\n81.1.7 Interpretazione del Bias\nIl bias nel coefficiente stimato \\(\\alpha_1\\), rispetto al vero coefficiente \\(\\beta_1\\), è dato da:\n\\[ \\text{Bias}(\\hat{\\alpha}_1) = \\beta_2 \\frac{\\text{Cov}(Z, X)}{\\text{Var}(X)} \\]\nQuesto risultato dimostra che il bias è direttamente proporzionale al coefficiente \\(\\beta_2\\) della variabile omessa \\(Z\\) e al rapporto di covarianza tra \\(Z\\) e \\(X\\) diviso per la varianza di \\(X\\). Questo bias può essere positivo o negativo a seconda della direzione della correlazione tra \\(X\\) e \\(Z\\), e della grandezza di \\(\\beta_2\\).\n\n\n81.1.8 Conclusioni\nIn sintesi, l’omissione di \\(Z\\) introduce un bias nella stima di \\(\\alpha_1\\) che non riflette accuratamente \\(\\beta_1\\) se \\(Z\\) è correlata sia con \\(Y\\) che con \\(X\\). Questo errore di specificazione può portare a conclusioni errate sull’effetto di \\(X\\) su \\(Y\\) e compromettere l’accuratezza delle inferenze tratte dal modello di regressione.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_specification_error.html#un-esempio-numerico",
    "href": "chapters/linear_models/12_specification_error.html#un-esempio-numerico",
    "title": "81  Errore di specificazione",
    "section": "81.2 Un esempio numerico",
    "text": "81.2 Un esempio numerico\nImmaginiamo di analizzare l’impatto di due variabili indipendenti, la motivazione e l’ansia, sulla prestazione in un compito specifico. Supponiamo che l’ansia influenzi negativamente la prestazione, mentre la motivazione abbia un effetto positivo.\nLa nostra simulazione evidenzia due scenari distinti:\n\nModello Completo: Quando sia la motivazione che l’ansia sono incluse nel modello di regressione, il coefficiente di regressione per l’ansia viene stimato correttamente come negativo, riflettendo il suo impatto negativo sulla prestazione. Questo conferma che, quando tutte le variabili rilevanti sono presenti, la stima dei loro effetti è accurata e non distorta.\nModello Ridotto (omissione della motivazione): Se la motivazione, che è positivamente correlata alla prestazione e positivamente correlata all’ansia, viene omessa dal modello, osserviamo un cambiamento notevole nel coefficiente di regressione per l’ansia. In questo modello ridotto, il coefficiente per l’ansia può addirittura diventare positivo, suggerendo erroneamente che l’ansia abbia un effetto benefico sulla prestazione. Questo fenomeno si verifica perché l’effetto indiretto e non osservato della motivazione sull’ansia porta a una stima distorta quando la motivazione non è controllata nel modello.\n\n\n# Generiamo dati casuali\nnp.random.seed(42)\nn = 100  # Numero di osservazioni\n\n# Variabili indipendenti con correlazione negativa tra loro\nmotivazione = np.random.normal(100, 10, n)\nansia = 200 + 0.75 * motivazione + np.random.normal(0, 5, n)\n\n# Variabile dipendente, con peso maggiore sulla motivazione rispetto all'ansia\nprestazione = 5 * motivazione - 1 * ansia + np.random.normal(0, 50, n)\n\n# Creazione DataFrame\ndata = pd.DataFrame(\n    {\"Motivazione\": motivazione, \"Ansia\": ansia, \"Prestazione\": prestazione}\n)\n\n\nmodel_full = bmb.Model(\"Prestazione ~ Motivazione + Ansia\", data=data)\nresults_full = model_full.fit(nuts_sampler=\"numpyro\")\n\n\naz.summary(results_full, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAnsia\n-1.12\n1.18\n-3.33\n1.01\n0.02\n0.02\n2347.49\n2341.41\n1.0\n\n\nIntercept\n-83.86\n250.01\n-521.27\n393.71\n4.87\n3.59\n2641.21\n2665.94\n1.0\n\n\nMotivazione\n6.21\n1.01\n4.38\n8.11\n0.02\n0.01\n2359.56\n2569.60\n1.0\n\n\nPrestazione_sigma\n54.19\n3.86\n47.05\n61.19\n0.06\n0.05\n3580.58\n2684.47\n1.0\n\n\n\n\n\n\n\n\n# Analisi di regressione con pingouin\nresults_full = pg.linear_regression(data[[\"Motivazione\", \"Ansia\"]], data[\"Prestazione\"])\nresults_full\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-84.058695\n244.261908\n-0.344133\n7.314908e-01\n0.467656\n0.456679\n-568.850966\n400.733576\n\n\n1\nMotivazione\n6.222523\n0.977770\n6.363994\n6.510176e-09\n0.467656\n0.456679\n4.281920\n8.163125\n\n\n2\nAnsia\n-1.122768\n1.143817\n-0.981597\n3.287403e-01\n0.467656\n0.456679\n-3.392928\n1.147393\n\n\n\n\n\n\n\n\nmodel_ansia_only = bmb.Model(\"Prestazione ~ Ansia\", data=data)\nresults_ansia_only = model_ansia_only.fit(nuts_sampler=\"numpyro\")\n\n\naz.summary(results_ansia_only, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nAnsia\n4.66\n0.84\n3.01\n6.13\n0.01\n0.01\n3797.94\n2688.34\n1.0\n\n\nIntercept\n-1055.09\n229.27\n-1470.97\n-615.01\n3.71\n2.65\n3810.32\n2766.51\n1.0\n\n\nPrestazione_sigma\n64.14\n4.66\n55.82\n73.16\n0.08\n0.06\n3209.37\n2678.96\n1.0\n\n\n\n\n\n\n\n\nresults_ansia_only = pg.linear_regression(data[[\"Ansia\"]], data[\"Prestazione\"])\nresults_ansia_only\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n-1052.984249\n226.249178\n-4.654091\n1.020933e-05\n0.245386\n0.237686\n-1501.968379\n-604.000119\n\n\n1\nAnsia\n4.653853\n0.824399\n5.645148\n1.608208e-07\n0.245386\n0.237686\n3.017861\n6.289846\n\n\n\n\n\n\n\nQuesta dimostrazione mette in luce l’importanza di includere tutte le variabili rilevanti in un modello di regressione per evitare conclusioni fuorvianti e garantire che le stime dei coefficienti riflettano veramente le relazioni causali tra le variabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/12_specification_error.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/12_specification_error.html#informazioni-sullambiente-di-sviluppo",
    "title": "81  Errore di specificazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\npandas    : 2.2.2\nscipy     : 1.13.1\npymc      : 5.15.1\npingouin  : 0.5.4\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\narviz     : 0.18.0\nbambi     : 0.13.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Errore di specificazione</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html",
    "href": "chapters/linear_models/14_interactions.html",
    "title": "82  Interazioni statistiche",
    "section": "",
    "text": "Introduzione\nNel campo della psicologia, la complessità e la natura multi-causale dei fenomeni psicologici spesso portano i ricercatori a descrivere le relazioni tra variabili come “dipendenti dal contesto” (Spake et al., 2023). Questo significa che le associazioni tra variabili possono variare in base a diversi fattori o condizioni. Un concetto chiave in questo ambito è l’interazione statistica, che si verifica quando l’effetto di una variabile indipendente su una variabile dipendente cambia in base al livello di un’altra variabile indipendente.\nAd esempio, in un recente studio di Pines et al. (2024), è stato osservato che le relazioni tra cognizione e salute mentale nei bambini possono essere sia positive che negative, a seconda del contesto. In particolare, la relazione tra cognizione e salute mentale varia significativamente in base alla popolazione studiata. Se si considerano bambini generalmente sani con pochi sintomi isolati, potrebbe emergere una relazione diversa rispetto a un campione di bambini con sintomi di gravità clinica.\nNello studio di Pines et al. (2024), è stato evidenziato che la direzione della relazione tra cognizione e salute mentale nei bambini cambia in modo significativo a seconda della gravità dei sintomi. Per i sintomi internalizzanti (come ansia e depressione), si è osservato che i bambini con pochi sintomi tendono ad avere punteggi cognitivi più alti rispetto ai bambini senza sintomi, mentre i bambini con sintomi gravi mostrano una cognizione compromessa. Questo cambiamento nella direzione della relazione, a seconda della gravità dei sintomi, rappresenta un esempio di interazione statistica.\nPer quanto riguarda i sintomi esternalizzanti (come comportamenti aggressivi), la pendenza della relazione tra cognizione e salute mentale può variare a seconda della gravità dei sintomi, ma la direzione dell’associazione rimane invariata.\nQuesto esempio dimostra che, quando si parla di interazioni statistiche, è fondamentale considerare come il contesto e le caratteristiche specifiche dei partecipanti possano influenzare le relazioni tra le variabili. Pines et al. (2024) sottolineano che, se l’obiettivo dello studio è comprendere il ruolo della cognizione nella psicopatologia, è essenziale includere individui con sintomi di gravità clinica. Questo perché le relazioni osservate in campioni sani potrebbero non solo non generalizzarsi a campioni clinici, ma potrebbero anche mostrare associazioni opposte.\nIn sintesi, l’interazione statistica ci aiuta a comprendere come le relazioni tra variabili possano cambiare a seconda delle condizioni o dei gruppi specifici, evidenziando l’importanza di un approccio attento e contestualizzato nella ricerca psicologica. Studiare le dipendenze tra i fattori psicologici ha sia motivazioni pratiche che teoriche. Ad esempio, identificare effetti interattivi può aiutare a indirizzare le risorse di intervento in contesti in cui queste saranno più efficaci, mentre l’assenza di interazioni potrebbe suggerire l’esistenza di relazioni generali in uno specifico dominio psicologico.\nSpake et al. (2023) si chiede se un fattore di interesse abbia un effetto che “dipende da” o viene “modificato” in magnitudine o segno da altri fattori. Potrebbe sembrare che la risposta a questa domanda sia semplice utilizzando mezzi grafici come i grafici condizionali (valori previsti di Y tracciati lungo l’intervallo di X e Z, o a valori significativi di questi predittori) o esaminando gli effetti marginali (gli effetti marginali riassumono l’effetto di una variabile indipendente sulla risposta in termini di previsioni di un modello). Tuttavia, tali analisi sono vulnerabili a diverse potenziali interpretazioni errate, che emergono quando si trascurano due aspetti critici della modifica dell’effetto: la scala (se una risposta è analizzata su una scala additiva o moltiplicativa) e la simmetria (se la modifica dell’effetto è esaminata in entrambe le direzioni).\nNel loro articolo, Spake et al. (2023) analizzano gli errori inferenziali che possono sorgere quando la scala e la simmetria della modifica dell’effetto vengono trascurate negli studi di ricerca. Iniziano illustrando con dati empirici e simulazioni come gli errori di tipo D, S e A possano derivare dall’ignorare la scala e la simmetria delle interazioni, anche quando un modello è correttamente specificato.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#la-dipendenza-dal-contesto-può-passare-inosservata-errore-di-tipo-d",
    "href": "chapters/linear_models/14_interactions.html#la-dipendenza-dal-contesto-può-passare-inosservata-errore-di-tipo-d",
    "title": "82  Interazioni statistiche",
    "section": "82.1 La dipendenza dal contesto può passare inosservata (Errore di Tipo D)",
    "text": "82.1 La dipendenza dal contesto può passare inosservata (Errore di Tipo D)\nIl modo più comune per testare la dipendenza dal contesto è introdurre un’interazione statistica (X × Z) in un modello. Le interazioni statistiche indicano che la relazione tra X e Y varia lungo l’intervallo di Z; analogamente, le relazioni Z–Y variano lungo l’intervallo di X (Duncan & Kefford, 2021). Il supporto statistico per un’interazione è poi determinato, ad esempio, utilizzando criteri di selezione del modello per giustificarne l’inclusione in modelli concorrenti (ad esempio, il criterio di informazione di Akaike, AIC).\nTuttavia, il fatto che un termine di interazione sia supportato o meno può dipendere criticamente dalla scala di misura utilizzata per stimare gli effetti in un modello statistico, ovvero se la scala di misura è additiva (ad esempio, unità assolute) o moltiplicativa (ad esempio, log-trasformata).\n\n\n\nTre errori inferenziali comuni nell’investigazione della dipendenza dal contesto. Consideriamo un test di dipendenza dal contesto nella sua forma più semplice: un esperimento fattoriale 2 × 2, che misura una risposta Y in relazione all’incrocio dei fattori X e Z, ciascuno con due livelli. L’analista adatta ai dati un modello statistico con un termine di interazione: (Y X + Z + X Z), per testare e quantificare la dipendenza dal contesto. Sono possibili tre errori inferenziali quando si trascurano la scala di misurazione o la simmetria dell’interazione: la rilevazione e la grandezza (Tipo D), il segno (Tipo S) e la mancata identificazione dei processi sottostanti (Tipo A) (figura tratta da Spake et al. (2023)).",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#mediazione-e-moderazione",
    "href": "chapters/linear_models/14_interactions.html#mediazione-e-moderazione",
    "title": "82  Interazioni statistiche",
    "section": "82.2 Mediazione e moderazione",
    "text": "82.2 Mediazione e moderazione\nL’articolo di Baron e Kenny (1986) ha rappresentato un punto di riferimento fondamentale per l’analisi della mediazione e della moderazione, influenzando numerosi studi successivi. In questo lavoro, gli autori hanno descritto il mediatore come il meccanismo attraverso il quale la variabile indipendente principale esercita un effetto sulla variabile dipendente di interesse (Baron & Kenny, 1986, p. 1173). In altre parole, il mediatore spiega “come” o “perché” si verifica questa relazione. D’altra parte, hanno definito il moderatore come una variabile che altera l’intensità o la direzione della relazione tra la variabile indipendente e la variabile dipendente (Baron & Kenny, 1986, p. 1174). Il moderatore ci dice “quando” o “in quali condizioni” si verifica l’effetto.\nSi parla di mediazione completa quando il legame tra due variabili, A e C, viene eliminato dopo aver controllato per il mediatore B (Baron & Kenny, 1986). Se, invece, la variabile A continua ad avere un effetto diretto su C, oltre a quello indiretto mediato da B, si ha una mediazione parziale (James & Brett, 1984).\nPer studiare mediatori e moderatori, si utilizzano spesso tecniche come l’analisi della varianza (ANOVA), i modelli di regressione e i modelli a equazioni strutturali (SEM) (Baron & Kenny, 1986; Holmbeck, 1997; Judd & Kenny, 1981). Questi metodi sono progettati per indagare la direzione causale degli effetti mediatori (Smith, 1982), distinguere tra mediazione completa e parziale (Holmbeck, 1997; Sobel, 1982), e anche testare modelli che combinano sia mediazione che moderazione (Baron & Kenny, 1986).\nÈ importante sottolineare che, così come vengono comunemente condotte, queste analisi presentano notevoli limitazioni nell’informare un approccio basato sui processi per spiegare i fenomeni psicologici (Hayes et al., 2019). I concetti di mediazione completa e parziale riguardano inferenze sui parametri di popolazione, ma non possono essere estesi ai singoli partecipanti di uno studio, né applicati alle persone, e nemmeno riferiti alle cause specifiche che operano a livello individuale (Grice et al., 2015).\n\n82.2.1 Le interazioni statistiche dipendono dalla scala di misura\nUn altro problema relativo alle interazioni riguarda la loro stessa misurazione (Spake et al., 2023). Le interazioni statistiche, come quelle osservate in un esperimento fattoriale 2x2, sono influenzate dalla scala di misura utilizzata. La rilevazione di un’interazione dipende dal fatto che le linee di un grafico di interazione (che connettono le medie di uno stesso livello di un fattore attraverso i livelli di un altro) siano parallele o meno. Tuttavia, il grado di divergenza dal parallelismo può variare a seconda della scala di misura adottata. Se X e Z influenzano Y in modo indipendente, allora:\n\nSe non c’è una modifica nell’effetto assoluto di X su Y con diversi valori di Z (cioè, le linee sono parallele su una scala additiva), allora l’effetto relativo di X su Y varierà con Z (le linee non saranno parallele su una scala moltiplicativa).\nAl contrario, se l’effetto relativo di X su Y rimane costante per diversi valori di Z (cioè, le linee sono parallele su una scala moltiplicativa), allora l’effetto assoluto di X su Y cambierà con Z su una scala additiva.\n\n\n# Funzione per generare i dati\ndef genera_dati(n_per_gruppo=100):\n    np.random.seed(42)\n    data = []\n    for x in [0, 1]:\n        for z in [0, 1]:\n            y = 10 + 5 * x + 8 * z + np.random.normal(0, 0.5, n_per_gruppo)\n            data.extend([(x, z, yi) for yi in y])\n    return pd.DataFrame(data, columns=[\"X\", \"Z\", \"Y\"])\n\n\n# Genera il dataframe\ndf = genera_dati()\n\n\n# Funzione per creare il grafico di interazione\ndef plot_interazione(data, y_col, title):\n    sns.lineplot(\n        data=data, x=\"X\", y=y_col, hue=\"Z\", marker=\"o\", markersize=10, linewidth=3\n    )\n    plt.legend(title=\"Z\")\n    plt.grid(True, linestyle=\"--\", alpha=0.7)\n    plt.show()\n\n\n# Grafico sulla scala originale\nplot_interazione(df, \"Y\", \"Interazione sulla Scala Originale (Additiva)\")\n\n# Trasforma Y su una scala esponenziale più drastica\ndf[\"Y_exp\"] = np.exp(df[\"Y\"] / 5)\n\n# Grafico sulla scala trasformata\nplot_interazione(df, \"Y_exp\", \"Interazione sulla Scala Trasformata (Esponenziale)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNella simulazione presentata, osserviamo due scenari chiave:\n\nScala Originaria (Additiva):\n\nI dati sulla scala originaria non mostrano interazione.\nLe linee nel grafico sono parallele, indicando che l’effetto di X su Y è costante per diversi livelli di Z.\nQuesto parallelismo suggerisce che gli effetti di X e Z su Y sono additivi e indipendenti.\n\nScala Trasformata (Esponenziale):\n\nApplicando una trasformazione esponenziale ai dati originari, emerge un’apparente interazione.\nLe linee nel grafico non sono più parallele, suggerendo che l’effetto di X su Y varia a seconda del livello di Z.\n\n\nÈ importante notare che:\n\nLa presenza o assenza di interazione dipende dalla scala di misura utilizzata.\nLa trasformazione non crea o elimina relazioni reali tra le variabili, ma cambia il modo in cui interpretiamo queste relazioni.\n\nConsideriamo il caso inverso:\n\nSe il secondo grafico (con interazione apparente) rappresentasse i dati grezzi, una trasformazione logaritmica potrebbe produrre un grafico simile al primo, mostrando assenza di interazione.\nQuesto perché la funzione logaritmica è l’inversa della funzione esponenziale.\nIn generale, se abbiamo dati che mostrano interazione su una scala moltiplicativa, una trasformazione logaritmica potrebbe rivelare una relazione additiva senza interazione.\n\nSpake et al. (2023) notano inoltre che esistono due tipi di interazioni:\n\nInterazioni non rimovibili (crossover o qualitative): queste coinvolgono un cambiamento nel segno di un effetto e non possono essere eliminate attraverso una trasformazione monotona della scala di misura.\nInterazioni rimovibili: queste possono essere eliminate cambiando la scala di misura e sono particolarmente soggette a errori di tipo D (falsi negativi) e S (falsi positivi).\n\nIn conclusione,\n\nla scelta della scala appropriata dovrebbe essere guidata dalla teoria sottostante e dalla natura dei dati, non solo dall’aspetto visivo dei grafici;\nè sempre consigliabile esaminare i dati su diverse scale e considerare attentamente quale scala sia più appropriata per l’interpretazione nel contesto specifico della ricerca.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#la-scala-di-modellizzazione-può-cambiare-il-significato-di-uninterazione-statistica-errore-di-tipo-s",
    "href": "chapters/linear_models/14_interactions.html#la-scala-di-modellizzazione-può-cambiare-il-significato-di-uninterazione-statistica-errore-di-tipo-s",
    "title": "82  Interazioni statistiche",
    "section": "82.3 La scala di modellizzazione può cambiare il significato di un’interazione statistica (Errore di Tipo S)",
    "text": "82.3 La scala di modellizzazione può cambiare il significato di un’interazione statistica (Errore di Tipo S)\nNel pannello B della figura di Spake et al. (2023), viene mostrato come il significato di un’interazione statistica possa cambiare a seconda della scala di modellizzazione utilizzata: nel pannello di sinistra, l’effetto di Z diventa meno negativo man mano che X aumenta, mentre nel pannello di destra, l’effetto di Z diventa più negativo con l’aumentare di X.\nLe scale additive indicano che l’effetto combinato di due predittori è semplicemente la somma dei loro effetti individuali. Al contrario, le scale moltiplicative, spesso utilizzate nei modelli lineari generalizzati (GLM), suggeriscono che l’effetto combinato è il prodotto degli effetti individuali. Questo cambiamento nel significato dell’interazione è dovuto alla natura non lineare delle funzioni di collegamento nei GLM, il che implica che l’effetto marginale di un predittore può variare in base ai valori degli altri predittori, anche se non sono presenti termini di interazione espliciti.\n\n82.3.1 Quale scala di misura è più appropriata: additiva o moltiplicativa?\nLa scelta tra scala additiva e moltiplicativa dipende dal contesto e dagli obiettivi dell’analisi. La scala additiva è spesso considerata più rilevante per la formulazione di politiche perché consente di valutare cambiamenti assoluti, utili per determinare l’impatto di interventi su specifici gruppi. La scala moltiplicativa è utile per comprendere processi relativi, come i tassi di crescita delle popolazioni. In molti casi, è utile presentare e interpretare entrambi i tipi di misure per fornire una comprensione completa dell’effetto di interazioni complesse.\nIn sintesi, le interazioni statistiche sono intrinsecamente dipendenti dalla scala di misura. La corretta interpretazione di queste interazioni richiede attenzione alla scala scelta per modellare i dati e alle implicazioni che questa scelta ha per le conclusioni inferenziali e la rilevanza pratica dei risultati ottenuti. È essenziale non basarsi solo sulla significatività statistica, ma anche considerare il significato scientifico o pratico degli effetti osservati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#le-esplorazioni-asimmetriche-della-dipendenza-dal-contesto-non-sono-sufficienti-per-interpretare-le-interazioni-errore-di-tipo-a",
    "href": "chapters/linear_models/14_interactions.html#le-esplorazioni-asimmetriche-della-dipendenza-dal-contesto-non-sono-sufficienti-per-interpretare-le-interazioni-errore-di-tipo-a",
    "title": "82  Interazioni statistiche",
    "section": "82.4 Le esplorazioni asimmetriche della dipendenza dal contesto non sono sufficienti per interpretare le interazioni (Errore di Tipo A)",
    "text": "82.4 Le esplorazioni asimmetriche della dipendenza dal contesto non sono sufficienti per interpretare le interazioni (Errore di Tipo A)\nSpake et al. (2023) descrivono l’errore di Tipo A che si verifica quando si esplorano in modo asimmetrico le dipendenze dal contesto nelle interazioni statistiche (si veda il pannello C della figura di Spake et al. (2023)). Ciò avviene quando si tratta una variabile come “effetto principale” e l’altra come “modificatore” senza considerare che la relazione potrebbe funzionare in entrambe le direzioni. Questo approccio può portare a una comprensione incompleta o fuorviante dei processi sottostanti.\nNelle ricerche psicologiche, è comune testare come un “modificatore” (variabile Z) influenzi l’effetto di una variabile di interesse principale (variabile X). Questo approccio è spesso giustificato perché la variabile X può essere manipolata direttamente o rappresenta una variabile di “trattamento”, mentre Z è un contesto che non può essere facilmente cambiato. Tuttavia, visualizzare e interpretare le interazioni solo in una direzione (come l’effetto di X su Y modificato da Z) può portare a errori, poiché questa visione potrebbe non riflettere tutte le possibili relazioni condizionali tra X, Y, e Z.\nConsideriamo un esempio in cui studiamo l’effetto dello stress (X) sulla performance cognitiva (Y), e ipotizziamo che questo effetto sia modificato dal supporto sociale (Z).\n\nIpotesi Asimmetrica: Formuliamo l’ipotesi che il supporto sociale (Z) moderi l’effetto dello stress (X) sulla performance cognitiva (Y). Ci aspettiamo che con maggiore supporto sociale, lo stress abbia un impatto minore sulla performance cognitiva. Così, X (stress) è l’effetto principale e Z (supporto sociale) è il modificatore. Costruiamo un modello che include un termine di interazione (stress × supporto sociale) e visualizziamo un grafico degli effetti marginali che mostra come l’effetto dello stress sulla performance cognitiva cambi con diversi livelli di supporto sociale.\n\nRisultato Potenziale: Il grafico mostra che, con alto supporto sociale, l’effetto negativo dello stress sulla performance cognitiva è ridotto. Concludiamo che il supporto sociale può aiutare a mitigare gli effetti negativi dello stress, promuovendo quindi interventi per aumentare il supporto sociale nei contesti lavorativi.\n\nIpotesi Completa: Se esaminiamo l’interazione in modo simmetrico, potremmo anche considerare come lo stress modera l’effetto del supporto sociale sulla performance cognitiva. Questa prospettiva potrebbe rivelare, per esempio, che in condizioni di basso stress, il supporto sociale non ha alcun effetto sulla performance cognitiva, o addirittura che troppo supporto sociale in condizioni di basso stress potrebbe ridurre l’autonomia e la performance.\n\nRisultato Potenziale: Visualizzando gli effetti marginali in entrambe le direzioni (supporto sociale che modera lo stress e viceversa), scopriamo che l’effetto del supporto sociale è positivo solo sotto condizioni di stress elevato, ma negativo quando lo stress è basso. Questo ci suggerisce che promuovere il supporto sociale dovrebbe essere mirato solo a contesti di stress elevato, cambiando completamente la nostra interpretazione e le nostre raccomandazioni.\n\n\nIn sintesi, l’errore di Tipo A evidenzia l’importanza di esaminare le interazioni in modo simmetrico e di considerare come entrambe le variabili possano influenzarsi reciprocamente. In psicologia, ciò potrebbe significare guardare non solo come una variabile contesto influenzi un effetto principale, ma anche come l’effetto principale possa a sua volta modificare l’influenza della variabile contesto. Trascurare questa bidirezionalità può portare a conclusioni incomplete e ad interventi inefficaci.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#interazione-e-condizionamento",
    "href": "chapters/linear_models/14_interactions.html#interazione-e-condizionamento",
    "title": "82  Interazioni statistiche",
    "section": "82.5 Interazione e Condizionamento",
    "text": "82.5 Interazione e Condizionamento\nMcElreath (2020) mette in relazione il concetto di interazione con quello di condizionamento e illustra il concetto di condizionamento utilizzando l’analogia con i bombardieri A.W.38 durante la Seconda Guerra Mondiale. Durante la guerra, i bombardieri A.W.38 della Royal Air Force erano spesso bersagliati da artiglieria e fuoco di intercettazione. Molti di questi aerei non tornavano dalle missioni, ma quelli che riuscivano a tornare portavano evidenti segni di danno. Inizialmente, sembrava logico aggiungere armature nelle aree degli aerei che mostravano più danni, come ali e fusoliera. Tuttavia, questo approccio si basava su un errore di condizionamento.\nCondizionamento significa che i dati che osserviamo (i danni sui bombardieri che sono tornati) sono condizionati dal fatto che questi bombardieri sono sopravvissuti. I bombardieri che tornavano alla base mostravano danni in parti non essenziali per il volo, come le ali. Le parti che risultavano intatte (cabina di pilotaggio e motori) erano in realtà le più critiche: se fossero state danneggiate, l’aereo non sarebbe tornato affatto. Pertanto, per migliorare la sopravvivenza dei bombardieri, si sarebbe dovuto armare le parti che non mostravano danni nei bombardieri sopravvissuti, perché queste erano le parti che, se colpite, avrebbero causato la perdita dell’aereo.\nIl principio del condizionamento è fondamentale per l’inferenza statistica. Indica che i dati che osserviamo sono spesso condizionati da come entrano nel nostro campione, cioè da un insieme di condizioni preesistenti. Nel caso dei bombardieri, i danni osservati sono condizionati dal fatto che l’aereo sia riuscito a tornare alla base.\nAnalogamente, nelle analisi statistiche, dobbiamo considerare che le distribuzioni posteriori (cioè, la probabilità di un certo parametro dato i dati osservati) sono condizionate dai dati stessi. L’inferenza basata su modelli è condizionata dal modello scelto. Ogni inferenza statistica è condizionata da qualcosa, anche se non ce ne rendiamo sempre conto.\nPer quel che riguarda la discussione presente, possiamo sottolineare che il condizionamento è anche alla base delle interazioni nei modelli statistici. Per esempio, se vogliamo permettere che l’associazione tra due variabili dipenda da una terza variabile, stiamo applicando un condizionamento. In un modello lineare, una interazione permette che l’effetto di un predittore vari in base ai valori di un altro predittore. Questo è un esempio di come un parametro può essere condizionato da ulteriori aspetti dei dati.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#interazione-e-nessi-causali",
    "href": "chapters/linear_models/14_interactions.html#interazione-e-nessi-causali",
    "title": "82  Interazioni statistiche",
    "section": "82.6 Interazione e nessi causali",
    "text": "82.6 Interazione e nessi causali\nMcElreath (2020), nel suo libro “Statistical Rethinking”, solleva un punto cruciale riguardo all’analisi delle interazioni statistiche. Egli sottolinea che esaminare un’interazione, ovvero valutare se l’associazione tra due variabili dipende da una terza, implica essenzialmente un processo di condizionamento. In altre parole, si tratta di “controllare” l’effetto di una variabile nel contesto di un modello di regressione. Tuttavia, McElreath (2020) avverte che la decisione di condizionare su una variabile non è sempre appropriata o sensata, ma dipende criticamente dalle relazioni causali che intercorrono tra le variabili in esame.\nQuesto concetto si ricollega direttamente alle discussioni sull’inferenza causale. Come è stato evidenziato nel Capitolo 87, è fondamentale condizionare sui confondenti, ovvero quelle variabili che influenzano sia la variabile indipendente che quella dipendente. D’altra parte, è metodologicamente errato condizionare su un discendente, cioè una variabile che è influenzata dalla variabile dipendente o da quella indipendente. Questa distinzione ha implicazioni profonde per l’analisi delle interazioni.\nDi conseguenza, la quantificazione degli effetti dell’interazione non può essere considerata un’operazione “statisticamente neutra” o universalmente applicabile. La sua validità e interpretazione dipendono strettamente dalla struttura causale sottostante al fenomeno studiato. Senza una comprensione approfondita delle relazioni causali tra le variabili, l’esame delle interazioni statistiche può facilmente portare a conclusioni fuorvianti o errate. Un approccio puramente statistico, che non tenga conto del contesto causale, rischia di condurre a interpretazioni fallaci dei risultati.\nPer condurre un’analisi delle interazioni robusta e significativa, è quindi essenziale integrare la conoscenza specifica del dominio con i metodi statistici. Questo richiede una comprensione dettagliata dei meccanismi causali potenziali nel sistema studiato. Prima di esaminare le interazioni, è cruciale sviluppare un modello causale, anche se preliminare, delle relazioni tra le variabili. L’utilizzo di strumenti come i diagrammi causali (DAG - Directed Acyclic Graphs) può essere di grande aiuto per visualizzare e analizzare queste relazioni causali.\nL’approccio consigliato è quindi quello di basare l’analisi delle interazioni su ipotesi causali ben fondate, piuttosto che su pure associazioni statistiche. Questo metodo sottolinea l’importanza di una progettazione attenta degli studi e di una riflessione approfondita sulle relazioni causali prima dell’analisi dei dati. Tale approccio può portare a una rivalutazione di molte pratiche comuni nell’analisi statistica, specialmente in campi dove le relazioni causali sono complesse o non completamente comprese.\nIn conclusione, l’analisi delle interazioni statistiche richiede una comprensione approfondita del contesto causale. Un approccio che integra la teoria causale con l’analisi statistica è essenziale per trarre conclusioni valide e significative dalle interazioni osservate nei dati. Senza questa integrazione, l’esame delle interazioni statistiche in maniera ingenua può essere molto rischioso e potenzialmente fuorviante.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#misurare-le-interazioni",
    "href": "chapters/linear_models/14_interactions.html#misurare-le-interazioni",
    "title": "82  Interazioni statistiche",
    "section": "82.7 Misurare le interazioni",
    "text": "82.7 Misurare le interazioni\nUna caratteristica fondamentale di una buona pratica di ricerca è testare le ipotesi con un potere statistico adeguato. Condurre studi con un alto potere statistico aumenta la probabilità di documentare non solo effetti reali, ma anche effetti replicabili. Mentre l’analisi della potenza per gli effetti principali è relativamente semplice, l’analisi della potenza per le interazioni di primo ordine (cioè le interazioni a due vie, che qui chiameremo semplicemente “interazioni”) presenta due importanti sfide.\nIn primo luogo, condurre un’analisi di potenza appropriata per le interazioni non è facilmente realizzabile con software come G*Power (Faul et al., 2007) o pacchetti R come pwr (Champely et al., 2017), perché la dimensione dell’effetto attesa di un’interazione dipende dalla sua forma (Maxwell & Delaney, 2004). In secondo luogo, ottenere un potere sufficiente per rilevare le interazioni non è un compito facile, poiché le dimensioni degli effetti delle interazioni sono spesso piccole e, di conseguenza, la dimensione del campione necessaria è spesso molto grande (Brysbaert, 2019).\nNelle simulazioni condotte da Sommet et al. (2023), diversi tipi di interazioni sono stati esaminati per determinare la dimensione del campione necessaria a ottenere un potere di 0.8 con una piccola dimensione dell’effetto atteso.\n\nInterazione di tipo “reversed” (invertita): Se l’interazione mostra un effetto invertito, è necessaria una dimensione campionaria di N = 784 per ottenere un potere di 0.8.\nInterazione “fully attenuated” (completamente attenuata): Quando l’interazione è completamente attenuata, il che significa che l’effetto è notevolmente ridotto o quasi nullo in determinate condizioni, la dimensione campionaria necessaria per ottenere un potere di 0.8 sale a N = 3136.\nInterazione “partially attenuated” (parzialmente attenuata): Per un’interazione parzialmente attenuata, dove l’effetto è ridotto solo parzialmente in alcune condizioni, è necessaria una dimensione campionaria di N = 5575 per raggiungere un potere di 0.8.\n\nAndrew Gelman ha sottolineato che per stimare un’interazione è necessaria una dimensione del campione 16 volte maggiore rispetto a quella necessaria per stimare un effetto principale. In generale, possiamo dire che questa differenza, e i risultati delle simulazioni di Sommet et al. (2023) presentati sopra, si spiegano con la natura delle interazioni: esse rappresentano effetti più sottili e complessi rispetto agli effetti principali, in quanto descrivono come l’effetto di una variabile cambia in funzione dei livelli di un’altra variabile. Questo livello aggiuntivo di complessità richiede una maggiore quantità di dati per essere rilevato e stimato con precisione.\nInoltre, la forma delle interazioni e il modo in cui le pendenze semplici (gli effetti principali a livelli specifici di un’altra variabile) si intersecano dipendono dalla grandezza dell’effetto di interazione rispetto alla magnitudine degli effetti principali. Questo rapporto determina se l’interazione produce:\n\nUn effetto attenuato: l’effetto di una variabile è ridotto, ma non eliminato, dalla presenza di un’altra variabile.\nUn effetto “knock-out”: l’effetto di una variabile è completamente eliminato in presenza di un’altra variabile.\nUn effetto “crossover”: l’effetto di una variabile si inverte in presenza di un’altra variabile, mostrando un cambiamento completo nella direzione dell’effetto.\n\nCiascuno di questi scenari richiede una quantità notevole di dati per essere adeguatamente caratterizzato e distinto dagli effetti principali.\nIn sintesi, le interazioni richiedono un maggiore potere statistico rispetto agli effetti principali in un modello di regressione, poiché rappresentano effetti più complessi che necessitano di una maggiore quantità di dati per essere rilevati e stimati con precisione. La loro dipendenza dal contesto e la relazione con gli effetti principali rendono necessario un campione più ampio per distinguerle in modo affidabile dal rumore statistico e caratterizzarle adeguatamente.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/linear_models/14_interactions.html#commenti-e-considerazioni-conclusive",
    "title": "82  Interazioni statistiche",
    "section": "82.8 Commenti e considerazioni conclusive",
    "text": "82.8 Commenti e considerazioni conclusive\nQuesto capitolo ha introdotto il concetto di interazione, che permette di considerare come l’associazione tra un predittore e un esito possa dipendere dal valore di un altro predittore. Le interazioni sono importanti per fare inferenze accurate, ma possono risultare difficili da interpretare.\nNel capitolo, abbiamo esaminato tre tipi di errori comuni nell’interpretazione delle interazioni, come illustrato da Spake et al. (2023). Inoltre, abbiamo discusso alcune considerazioni presentate da McElreath (2020), che collegano il concetto di interazione a quello di condizionamento e, di conseguenza, all’analisi causale. Infine, abbiamo esplorato le considerazioni relative alla dimensione campionaria necessaria per rilevare e misurare correttamente le interazioni.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/14_interactions.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/14_interactions.html#informazioni-sullambiente-di-sviluppo",
    "title": "82  Interazioni statistiche",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib : 3.8.4\npandas     : 2.2.2\nstatsmodels: 0.14.2\narviz      : 0.18.0\nnumpy      : 1.26.4\nseaborn    : 0.13.2\nxarray     : 2024.5.0\nscipy      : 1.13.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGrice, J. W., Cohn, A., Ramsey, R. R., & Chaney, J. M. (2015). On muddled reasoning and mediation modeling. Basic and Applied Social Psychology, 37(4), 214–225.\n\n\nHayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Sanford, B. T., Curtiss, J. E., & Ciarrochi, J. (2019). The role of the individual in the coming era of process-based therapy. Behaviour Research and Therapy, 117, 40–53.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nPines, A., Tozzi, L., Bertrand, C., Keller, A. S., Zhang, X., Whitfield-Gabrieli, S., Hastie, T., Larsen, B., Leikauf, J., & Williams, L. M. (2024). Psychiatric Symptoms, Cognition, and Symptom Severity in Children. JAMA Psychiatry. https://doi.org/10.1001/jamapsychiatry.2024.2399\n\n\nSommet, N., Weissman, D. L., Cheutin, N., & Elliot, A. J. (2023). How many participants do I need to test an interaction? Conducting an appropriate power analysis and achieving sufficient power to detect an interaction. Advances in Methods and Practices in Psychological Science, 6(3), 25152459231178728.\n\n\nSpake, R., Bowler, D. E., Callaghan, C. T., Blowes, S. A., Doncaster, C. P., Antao, L. H., Nakagawa, S., McElreath, R., & Chase, J. M. (2023). Understanding «it depends» in ecology: a guide to hypothesising, visualising and interpreting statistical interactions. Biological Reviews, 98(4), 983–1002.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>Interazioni statistiche</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/16_missing.html",
    "href": "chapters/linear_models/16_missing.html",
    "title": "83  Dati mancanti",
    "section": "",
    "text": "Introduzione\nNel campo della data science, la gestione dei dati mancanti rappresenta una sfida cruciale e una competenza fondamentale per gli analisti e i ricercatori. I dati mancanti non sono solo una comune occorrenza nei dataset reali, ma possono anche avere un impatto significativo sulla qualità delle analisi, sulle inferenze tratte e sulle decisioni basate su tali dati. L’importanza di affrontare correttamente i dati mancanti risiede nella necessità di mantenere l’integrità delle analisi statistiche e di evitare conclusioni errate o distorte. Una gestione appropriata dei dati mancanti permette di migliorare l’accuratezza dei modelli predittivi, di aumentare la robustezza delle analisi e di garantire che le decisioni basate sui dati siano informate e affidabili. Pertanto, comprendere le cause dei dati mancanti, conoscere le diverse tipologie di assenza dei dati, come classificato nella tassonomia di Rubin, e applicare le tecniche di trattamento più adeguate sono competenze essenziali nella data science per massimizzare il valore estratto dai dati disponibili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/16_missing.html#la-tassonomia-di-rubin",
    "href": "chapters/linear_models/16_missing.html#la-tassonomia-di-rubin",
    "title": "83  Dati mancanti",
    "section": "83.1 La tassonomia di Rubin",
    "text": "83.1 La tassonomia di Rubin\nLa tassonomia dei dati mancanti di Rubin introduce una classificazione che aiuta a comprendere e gestire le situazioni in cui i dati non sono completamente disponibili. Questa classificazione è particolarmente rilevante in ambiti come la statistica, la ricerca scientifica e l’analisi dei dati, dove la presenza di dati mancanti può influenzare significativamente i risultati degli studi. La tassonomia identifica tre categorie principali: Dati Mancanti Completamente a Caso (MCAR), Dati Mancanti a Caso (MAR) e Dati Mancanti Non a Caso (MNAR). Ognuna di queste categorie si basa su specifiche assunzioni relative alla probabilità condizionata che un dato sia mancante. Vediamo nel dettaglio:\n\nDati Mancanti Completamente a Caso (MCAR): Questa categoria rappresenta la situazione meno problematica tra le tre. L’assunzione MCAR suggerisce che la mancanza di dati avviene in modo completamente casuale, senza alcuna relazione sia con i dati osservati che con quelli non osservati. La mancanza è attribuibile a circostanze casuali e non legate alle caratteristiche dei dati stessi. In pratica, questo significa che la probabilità che un dato sia mancante è la stessa per tutte le osservazioni. Quando i dati sono MCAR, le tecniche di analisi possono procedere senza introdurre distorsioni significative nei risultati.\nDati Mancanti a Caso (MAR): In questa categoria, la probabilità che un dato sia mancante può dipendere dai dati osservati, ma non da quelli non osservati. Questo tipo di mancanza viene considerato “ignorabile” perché, conoscendo i dati osservati, è possibile procedere con l’analisi senza compromettere l’affidabilità delle inferenze, sebbene possa esserci una perdita di precisione. Questa situazione si verifica quando la ragione della mancanza di dati è correlata a qualche caratteristica osservabile nel dataset, permettendo di gestire la mancanza attraverso l’analisi dei dati disponibili.\nDati Mancanti Non a Caso (MNAR): Questa è la situazione più complessa e potenzialmente problematica. I dati sono considerati MNAR quando la probabilità che un dato sia mancante dipende dalle informazioni non osservate. Ciò significa che la mancanza di dati è correlata a valori che non sono noti o osservabili, rendendo più difficile l’imputazione e l’analisi. Le tecniche standard di gestione dei dati mancanti potrebbero introdurre distorsioni significative nei risultati a causa del rischio di confondimento. La gestione dei dati MNAR richiede metodi avanzati e cautela nell’interpretazione dei risultati.\n\nLe assunzioni su cui si basa questa tassonomia sono fondamentali per scegliere il metodo di trattamento dei dati mancanti più appropriato. Tuttavia, è importante notare che queste assunzioni sono intrinsecamente non verificabili. L’analisi e le conclusioni di uno studio dipenderanno dalla plausibilità di queste assunzioni nel contesto specifico in cui vengono applicate. La scelta di come trattare i dati mancanti dovrebbe quindi essere attentamente considerata e giustificata nel contesto della ricerca.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/16_missing.html#un-esempio-empirico",
    "href": "chapters/linear_models/16_missing.html#un-esempio-empirico",
    "title": "83  Dati mancanti",
    "section": "83.2 Un Esempio Empirico",
    "text": "83.2 Un Esempio Empirico\nL’analisi e il trattamento dei dati mancanti rivestono un ruolo cruciale nell’interpretazione dei risultati di uno studio. Esaminiamo i diversi scenari di dati mancanti che hai delineato, prendendo spunto dall’esempio metaforico del “cane che mangia i compiti”, presentato nel tutorial di Dustin Stansbury.\n\n83.2.1 1. Perdita di Dati Casuale e Indipendente dalle Cause\n\nEsempio: Il fenomeno del “cane che mangia i compiti” avviene in maniera casuale.\nConseguenze: In questa situazione, la perdita di dati è classificata come “Missing Completely At Random” (MCAR), ovvero l’assenza di dati non è in alcun modo correlata né alle variabili osservate né a quelle non osservate.\nGestione: È possibile eliminare i casi con dati mancanti senza introdurre distorsioni, benché ciò possa ridurre l’efficienza dello studio a causa della diminuzione della dimensione del campione.\n\n\n# Helper function to plot regression line\ndef plot_regression_line(x, y, color, label, **plot_kwargs):\n    valid_idx = ~np.isnan(y)\n    \n    X = np.vstack((np.ones_like(x[valid_idx]), x[valid_idx])).T\n    intercept, slope = np.linalg.lstsq(X, y[valid_idx], rcond=None)[0]\n    \n    xs = np.linspace(x.min(), x.max(), 10)\n    ys = xs * slope + intercept\n    plt.plot(xs, ys, color=color, label=label, **plot_kwargs)\n\n# Function to plot dog homework data\ndef plot_dog_homework(S, H, Hstar, title=None):\n    \n    # Plot S vs H\n    plt.scatter(S, H, color='k', alpha=1, label='total', s=10)\n    plot_regression_line(S, H, label='total trend', color='k', alpha=.5)\n    \n    # Plot S vs Hstar\n    plt.scatter(S, Hstar, color='C0', alpha=.8, label='incomplete')\n    plot_regression_line(S, Hstar, label='incomplete trend', color='C0', alpha=.5)\n    \n    # Set labels and title\n    plt.xlabel(\"S\")\n    plt.ylabel(\"H\")\n    if title is not None:\n        plt.title(title)\n    plt.legend()\n\n    plt.show()  # Display the plot\n\n\nnp.random.seed(123)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Homework score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats 50% of of homework _at random_\nD = stats.bernoulli(0.5).rvs(size=n_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Random missing data\\ncauses loss of precision; little/no bias\")\n\n\n\n\n\n\n\n\nIn scenari di dati mancanti completamente a caso, si verifica una perdita di precisione, ma, mediamente, l’analisi non risulta distorta.\n\n\n83.2.2 2. Perdita di Dati Condizionata dalle Cause\n\nEsempio: Il cane mangia i compiti in base alle abitudini di studio dello studente, ad esempio se lo studente trascura di nutrire il cane dopo aver studiato intensamente.\nConseguenze: Questo caso è definito come “Missing At Random” (MAR), in cui la probabilità di perdita di dati è correlata a variabili osservabili.\nGestione: È necessario adeguare l’analisi in base alla causa per prevenire distorsioni. L’impiego di modelli statistici che considerano le variabili legate alla mancanza di dati può risultare efficace.\n\nIn una prima simulazione, il trattamento (competenza dello studente) e l’effetto (qualità del compito) hanno una relazione lineare. Questo scenario è molto raro.\n\nnp.random.seed(12)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Linear association between student ability and homework score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats based on the student's ability\np_dog_eats_homework = np.where(S &gt; 0, 0.9, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data conditioned on common cause\\nmay work for linear relationships (rare) \")\n\n\n\n\n\n\n\n\nQuando l’associazione tra abilità degli studenti e punteggio dei compiti è lineare, l’adattamento dal campione completo e da quello incompleto può risultare simile, con una perdita di precisione solo agli estremi del campione.\nConsideriamo ora il caso in cui il trattamento (capacità dello studente) e l’effetto (caratteristiche del compito) non sono associati linearmente. Questo scenario è molto più comune.\n\nnp.random.seed(1)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Nonlinear association between student ability and homework score\nmu_score = 1 - np.exp(-0.7 * S)\nH = stats.norm.rvs(mu_score)\n\n# Dog eats all the homework of above-average students\np_dog_eats_homework = np.where(S &gt; 0, 1, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data based on common cause\\nvery bady for non-linear relationships (common)\")\n\n\n\n\n\n\n\n\nIn un tale scenario, l’adattamento dal campione completo e da quello incompleto sono molto diversi. In altre parole, l’analisi del campione incompleto produce un risultato distorto.\n\n\n83.2.3 3. Perdita di Dati Condizionata dal Risultato\n\nEsempio: Il cane mangia i compiti in base al punteggio ottenuto.\nConseguenze: Questo scenario è classificato come “Missing Not At Random” (MNAR), in cui la perdita di dati è direttamente correlata al risultato mancante, complicando significativamente la gestione.\nGestione: Spesso, affrontare questa situazione richiede di modellare il processo causale alla base della perdita di dati, utilizzando tecniche come l’analisi di sopravvivenza o l’impiego di dati censurati.\n\n\nnp.random.seed(1)\nn_homework = 100\n# Student knowledge\nS = stats.norm.rvs(size=n_homework)\n\n# Linear association between ability and score\nmu_score = S * 0.5\nH = stats.norm.rvs(mu_score)\n\n# Dog eats 90% of homework that is below average\np_dog_eats_homework = np.where(H &lt; 0, 0.9, 0)\nD = stats.bernoulli.rvs(p=p_dog_eats_homework)\nHstar = H.copy()\nHstar[D==1] = np.nan\n\nplot_dog_homework(S, H, Hstar, title=\"Missing data conditioned on outcome state\\nusually not benign\")\n\n\n\n\n\n\n\n\nl’adattamento dal campione completo e da quello incompleto sono molto diversi. In altre parole, l’analisi del campione incompleto produce un risultato distorto. La situazione è simile a quella precedene in cui la relazione tra cause e risultati non era lineare.\nSenza conoscere la relazione causale tra il risultato e la perdita di dati, e le forme funzionali di come X è associato con Y, è difficile tenere conto di questo scenario.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/16_missing.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/linear_models/16_missing.html#commenti-e-considerazioni-conclusive",
    "title": "83  Dati mancanti",
    "section": "83.3 Commenti e considerazioni conclusive",
    "text": "83.3 Commenti e considerazioni conclusive\nIn conclusione, la strategia di gestione dei dati mancanti varia a seconda della loro relazione con le variabili nel modello causale. Comprendere la natura della perdita di dati è vitale per scegliere l’approccio analitico corretto e per interpretare con precisione i risultati dello studio. Solo nel caso di dati mancanti completamente a caso, l’analisi che ignora la mancanza di dati produce risultati affidabili.",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/linear_models/16_missing.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/linear_models/16_missing.html#informazioni-sullambiente-di-sviluppo",
    "title": "83  Dati mancanti",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib : 3.8.4\npandas     : 2.2.2\nstatsmodels: 0.14.2\narviz      : 0.18.0\nnumpy      : 1.26.4\nseaborn    : 0.13.2\nxarray     : 2024.5.0\nscipy      : 1.13.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "Regressione",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>Dati mancanti</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html",
    "href": "chapters/causal_inference/01_rct.html",
    "title": "84  Trial controllati randomizzati",
    "section": "",
    "text": "Introduzione\nNel campo della psicologia, come in molte altre discipline scientifiche, la ricerca della causalità è fondamentale per comprendere i fenomeni umani e sviluppare interventi efficaci. Mentre la filosofia ha dibattuto per secoli sulla natura della causalità, la ricerca moderna ha fornito strumenti pratici per affrontare questa questione complessa. Tra questi, i trial controllati randomizzati (RCT) emergono come un metodo particolarmente potente e affidabile.\nGli RCT rappresentano un ponte tra la complessità teorica della causalità e la sua applicazione pratica nella ricerca. Questo approccio, pionieristicamente sviluppato da studiosi come Neyman (1923) e Rubin (1974), permette ai ricercatori di stabilire relazioni causali con un alto grado di confidenza, grazie all’uso attento della randomizzazione e dell’analisi statistica.\nQuesto capitolo, che segue la trattazione presentata nel testo Causal Inference: A Statistical Learning Approach di Stefan Wager, offre una panoramica sintetica delle stime statistiche e dell’inferenza nei trial controllati randomizzati. Quando disponibili, le prove derivate dagli RCT sono spesso considerate il “gold standard” delle evidenze statistiche; pertanto, i metodi per studiare gli RCT costituiscono la base degli strumenti statistici per l’inferenza causale. Inoltre, molti dei disegni di studio osservazionali ampiamente utilizzati, anche in psicologia, si ispirano agli RCT. Di conseguenza, questo capitolo funge anche da punto di partenza per le discussioni successive sulle stime e sull’inferenza negli studi osservazionali.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#concetti-fondamentali-negli-rct",
    "href": "chapters/causal_inference/01_rct.html#concetti-fondamentali-negli-rct",
    "title": "84  Trial controllati randomizzati",
    "section": "84.1 Concetti Fondamentali negli RCT",
    "text": "84.1 Concetti Fondamentali negli RCT\n\n84.1.1 Effetti del Trattamento\nNel contesto degli RCT in psicologia, il “trattamento” potrebbe essere un intervento terapeutico, un programma educativo, o qualsiasi altra variabile manipolata dai ricercatori. L’obiettivo principale è determinare l’effetto di questo trattamento su una o più variabili di risultato.\n\n\n84.1.2 Effetti medi del trattamento (ATE e SATE)\nQuando si vuole studiare l’effetto di un trattamento, una delle sfide principali è quella di capire come cambierebbe l’outcome se a una persona venisse somministrato un trattamento diverso da quello effettivamente ricevuto. Questo concetto è formalizzato nell’effetto causale individuale, che è la differenza tra il risultato osservabile se una persona riceve il trattamento (\\(Y_i(1)\\)) e il risultato se non lo riceve (\\(Y_i(0)\\)). Questa differenza si esprime come:\n\\[\n\\theta_i = Y_i(1) - Y_i(0).\n\\]\nTuttavia, poiché per ogni individuo possiamo osservare solo uno di questi due risultati (non possiamo sapere cosa sarebbe successo se avessero ricevuto un trattamento diverso), non possiamo mai conoscere direttamente l’effetto individuale.\nPer superare questo problema, si ricorre alla media degli effetti del trattamento su un gruppo di persone, ovvero all’effetto medio del trattamento. Questo può essere definito in due modi:\n\nEffetto Medio Campionario del Trattamento (SATE - Sample Average Treatment Effect), che è la media degli effetti del trattamento nel campione:\n\n\\[\n\\hat{\\theta} = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i(1) - Y_i(0)).\n\\]\n\nEffetto Medio del Trattamento nella Popolazione (ATE - Average Treatment Effect), che è la media dell’effetto del trattamento in un’intera popolazione da cui è tratto il campione:\n\n\\[\n\\tau = \\mathbb{E}_P[Y_i(1) - Y_i(0)].\n\\]\nQueste definizioni permettono di stimare l’effetto medio del trattamento anche senza osservare gli effetti individuali per ogni persona.\n\n\n84.1.3 Stima tramite differenza delle medie\nUn metodo comune per stimare l’ATE in un trial randomizzato è usare la differenza tra le medie degli outcome tra il gruppo trattato e il gruppo di controllo. Questo metodo funziona in modo molto intuitivo: calcoliamo la media dei risultati per il gruppo che ha ricevuto il trattamento e la media per il gruppo che non l’ha ricevuto, quindi sottraiamo queste due medie:\n\\[\n\\hat{\\tau}_{DM} = \\frac{1}{n_1} \\sum_{i: W_i = 1} Y_i - \\frac{1}{n_0} \\sum_{i: W_i = 0} Y_i,\n\\]\ndove \\(n_1\\) è il numero di individui che hanno ricevuto il trattamento (gruppo trattato) e \\(n_0\\) è il numero di individui che non lo hanno ricevuto (gruppo di controllo).\nQuesto stimatore è non distorto se il trattamento è stato assegnato in modo casuale. Ciò significa che, in media, la stima dell’ATE fornita dalla differenza delle medie sarà corretta.\n\n\n84.1.4 Teorema del limite centrale e intervalli di confidenza\nPer dare una misura dell’incertezza della stima dell’ATE in termini frequentisti, possiamo applicare il teorema del limite centrale (TLC). Questo teorema afferma che, se il campione è sufficientemente grande e i partecipanti sono selezionati in modo indipendente da una popolazione, la distribuzione della stima dell’ATE tende a seguire una distribuzione normale, con media pari all’ATE vero e una certa varianza:\n\\[\n\\sqrt{n} (\\hat{\\tau}_{DM} - \\tau) \\sim N(0, V_{DM}),\n\\]\ndove \\(V_{DM}\\) rappresenta la varianza asintotica della differenza tra le medie. Questo ci permette di costruire un intervallo di confidenza per l’ATE:\n\\[\n\\hat{\\tau}_{DM} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{V}_{DM}}{n}}.\n\\]\nQui, \\(z_{\\alpha/2}\\) è il valore critico dalla distribuzione normale standard (ad esempio, per un livello di confidenza del 95%, \\(z_{0.025} = 1.96\\)). L’intervallo di confidenza fornisce una stima dell’ATE insieme a una misura della sua incertezza. Se l’intervallo è stretto, abbiamo una maggiore fiducia nella stima; se è largo, la stima è più incerta.\n\n\n84.1.5 Aggiustamenti per regressione\nGli aggiustamenti per regressione permettono di migliorare la precisione della stima dell’ATE includendo informazioni aggiuntive, come covariate pre-trattamento, nel modello. L’idea di base è che, oltre al trattamento, altre variabili (covariate) potrebbero influenzare l’outcome. Quindi, includere queste covariate può aiutarci a spiegare meglio le differenze negli outcome e a ridurre la varianza della stima dell’ATE.\nVediamo passo per passo come funziona:\n\n84.1.5.1 Modello di regressione con covariate\nSi usa una regressione lineare che modella l’outcome \\(Y_i\\) in funzione del trattamento \\(W_i\\) e delle covariate \\(X_i\\):\n\\[\nY_i = \\alpha + W_i \\tau + X_i \\beta + W_i X_i \\gamma + \\epsilon_i,\n\\]\n\n\\(Y_i\\): l’outcome dell’individuo \\(i\\).\n\\(W_i\\): il trattamento (1 se l’individuo è trattato, 0 se non lo è).\n\\(X_i\\): le covariate pre-trattamento (es. età, genere).\n\\(\\alpha\\): l’intercetta, cioè il valore dell’outcome medio quando \\(W_i = 0\\) e \\(X_i = 0\\).\n\\(\\tau\\): il parametro che rappresenta l’effetto medio del trattamento (ATE), che vogliamo stimare.\n\\(\\beta\\): il vettore di parametri associati alle covariate, che misura quanto le covariate influenzano l’outcome.\n\\(\\gamma\\): il vettore di parametri di interazione tra trattamento e covariate (cioè quanto l’effetto del trattamento varia in funzione delle covariate).\n\\(\\epsilon_i\\): l’errore, che rappresenta le variazioni non spiegate dal modello.\n\n\n\n84.1.5.2 Aggiustamento per covariate\nLa regressione permette di aggiustare gli outcome per le covariate \\(X_i\\), separando l’effetto delle covariate dall’effetto del trattamento. Questo è utile perché riduce la “rumorosità” dei dati e rende più facile identificare l’effetto del trattamento \\(\\tau\\).\n\n\n84.1.5.3 Stima dell’ATE\nUna volta stimati i coefficienti del modello tramite una regressione (solitamente con il metodo dei minimi quadrati), possiamo calcolare la stima dell’ATE.\nIl trucco è che possiamo usare i risultati della regressione per predire quale sarebbe stato l’outcome di ciascun individuo sotto entrambi i livelli del trattamento (\\(W_i = 1\\) e \\(W_i = 0\\)):\n\nPer stimare l’outcome atteso se tutti gli individui fossero trattati (\\(W_i = 1\\)):\n\\[\n\\hat{Y}_i(1) = \\hat{\\alpha}(1) + X_i \\hat{\\beta}(1).\n\\]\nPer stimare l’outcome atteso se nessun individuo fosse trattato (\\(W_i = 0\\)):\n\\[\n\\hat{Y}_i(0) = \\hat{\\alpha}(0) + X_i \\hat{\\beta}(0).\n\\]\n\ndove:\n\n\\(\\hat{\\alpha}(1)\\) e \\(\\hat{\\alpha}(0)\\) sono gli intercept stimati per i trattati e non trattati.\n\\(\\hat{\\beta}(1)\\) e \\(\\hat{\\beta}(0)\\) sono i coefficienti stimati per le covariate nei due gruppi.\n\nL’effetto medio del trattamento (ATE) si ottiene quindi come la differenza media tra questi due outcome previsti:\n\\[\n\\hat{\\tau}_{IREG} = \\frac{1}{n} \\sum_{i=1}^{n} \\left[ \\hat{Y}_i(1) - \\hat{Y}_i(0) \\right].\n\\]\nIn pratica, l’algoritmo di regressione ti permette di stimare quale sarebbe stato l’outcome atteso per ciascun individuo se fossero stati trattati o meno, tenendo conto delle loro caratteristiche (covariate). La differenza media tra questi due scenari fornisce una stima più precisa dell’ATE.\n\n\n84.1.5.4 Vantaggio dell’aggiustamento\nL’uso delle covariate nel modello aiuta a ridurre la varianza della stima dell’ATE, poiché le covariate possono spiegare parte della variabilità negli outcome. Ciò significa che, rispetto al semplice confronto delle medie tra trattati e non trattati, l’aggiustamento per covariate porta a una stima più precisa, soprattutto quando le covariate hanno una forte influenza sugli outcome.\nIn conclusione, l’aggiustamento per regressione permette di stimare l’ATE in modo più efficiente, migliorando la precisione senza introdurre distorsioni, anche quando la relazione tra le covariate e gli outcome non è perfettamente lineare.\n\n\n\n84.1.6 Confronto tra stimatori\nIl metodo della differenza delle medie è semplice da implementare, ma non ottimale in termini di efficienza statistica, poiché non sfrutta completamente le informazioni disponibili. Al contrario, l’aggiustamento per regressione migliora l’efficienza statistica riducendo la varianza della stima, senza introdurre distorsioni. In particolare, lo stimatore con regressione può essere sempre uguale o migliore (in termini di varianza) rispetto alla differenza delle medie, e questa riduzione della varianza diventa più significativa quando le covariate hanno una forte influenza sugli outcome.\nIn sintesi, l’uso della regressione per aggiustare i risultati è vantaggioso perché permette di utilizzare tutte le informazioni disponibili (inclusi i dati pre-trattamento), migliorando la precisione delle stime senza compromettere la validità delle inferenze.\nQuesti concetti sono fondamentali per comprendere come condurre inferenze causali in modo robusto, specialmente nei contesti sperimentali come i trial randomizzati.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#simulazione",
    "href": "chapters/causal_inference/01_rct.html#simulazione",
    "title": "84  Trial controllati randomizzati",
    "section": "84.2 Simulazione",
    "text": "84.2 Simulazione\nIn questo esempio, supponiamo di avere:\n\nUna variabile di trattamento (0 o 1),\nDue covariate (\\(X_1\\), \\(X_2\\)) che influenzano l’outcome,\nUn effetto causale del trattamento.\n\nUseremo una regressione per stimare l’ATE aggiustando per le covariate.\n\n# Imposta il seme per la riproducibilità\nnp.random.seed(42)\n\n# Numero di osservazioni\nn = 500\n\n# Generiamo due covariate indipendenti\nX1 = np.random.normal(50, 10, size=n)  # Covariata 1\nX2 = np.random.normal(30, 5, size=n)  # Covariata 2\n\n# Variabile di trattamento casuale (0 o 1)\ntreatment = np.random.binomial(1, 0.5, size=n)\n\n# Effetti veri delle covariate sugli outcome\nbeta_X1 = 2.0\nbeta_X2 = -1.5\n\n# Effetto del trattamento sull'outcome\ntreatment_effect = 5.0\n\n# Generiamo l'outcome vero includendo il trattamento e le covariate\n# Outcome simulato: Y = 5*T + 2*X1 - 1.5*X2 + errore\noutcome = (\n    treatment_effect * treatment\n    + beta_X1 * X1\n    + beta_X2 * X2\n    + np.random.normal(0, 5, size=n)\n)\n\n# Creiamo un DataFrame per contenere i dati\ndata = pd.DataFrame({\"Treatment\": treatment, \"X1\": X1, \"X2\": X2, \"Outcome\": outcome})\n\n# Mostra un'anteprima dei dati\nprint(data.head())\n\n   Treatment         X1         X2    Outcome\n0          0  54.967142  34.630888  56.161344\n1          0  48.617357  39.547083  38.837491\n2          1  56.476885  23.007162  76.707396\n3          1  65.230299  32.814846  81.380258\n4          0  47.658466  26.746787  61.198821\n\n\n\n84.2.1 Stima dell’ATE senza aggiustamento (Differenza tra le medie)\nLa differenza tra le medie può essere calcolata confrontando l’outcome medio per il gruppo trattato e il gruppo non trattato.\n\n# Calcolo della differenza tra le medie\nmean_treated = data[data[\"Treatment\"] == 1][\"Outcome\"].mean()\nmean_control = data[data[\"Treatment\"] == 0][\"Outcome\"].mean()\n\nate_naive = mean_treated - mean_control\nprint(f\"ATE senza aggiustamento (differenza tra le medie): {ate_naive:.2f}\")\n\nATE senza aggiustamento (differenza tra le medie): 9.59\n\n\n\n\n84.2.2 Aggiustamento per regressione\nOra eseguiamo una regressione lineare che include il trattamento e le covariate. Utilizziamo pingouin o statsmodels per eseguire la regressione e stimare l’ATE.\n\n# Aggiunta di un'intercetta al modello\nX = sm.add_constant(data[[\"Treatment\", \"X1\", \"X2\"]])\n\n# Eseguiamo la regressione con statsmodels\nmodel = sm.OLS(data[\"Outcome\"], X).fit()\n\n# Mostriamo i risultati della regressione\nprint(model.summary())\n\n# Estrarre il coefficiente del trattamento, che rappresenta l'ATE aggiustato\nate_adjusted = model.params[\"Treatment\"]\nprint(f\"\\nATE con aggiustamento per le covariate: {ate_adjusted:.2f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                Outcome   R-squared:                       0.952\nModel:                            OLS   Adj. R-squared:                  0.951\nMethod:                 Least Squares   F-statistic:                     3261.\nDate:                Sat, 21 Sep 2024   Prob (F-statistic):               0.00\nTime:                        08:18:33   Log-Likelihood:                -1501.2\nNo. Observations:                 500   AIC:                             3010.\nDf Residuals:                     496   BIC:                             3027.\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -0.0830      1.843     -0.045      0.964      -3.704       3.538\nTreatment      5.9935      0.439     13.648      0.000       5.131       6.856\nX1             1.9780      0.022     88.112      0.000       1.934       2.022\nX2            -1.4672      0.045    -32.658      0.000      -1.555      -1.379\n==============================================================================\nOmnibus:                        0.174   Durbin-Watson:                   1.952\nProb(Omnibus):                  0.917   Jarque-Bera (JB):                0.263\nSkew:                          -0.033   Prob(JB):                        0.877\nKurtosis:                       2.910   Cond. No.                         498.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nATE con aggiustamento per le covariate: 5.99\n\n\n\n\n84.2.3 Interpretazione dei risultati\n\nATE senza aggiustamento (Differenza tra le medie): Questa stima riflette l’effetto medio del trattamento senza tener conto delle covariate.\nATE con aggiustamento per covariate: Questa stima corregge per le differenze nelle covariate \\(X_1\\) e \\(X_2\\) tra i gruppi trattati e non trattati, fornendo una stima più precisa dell’effetto causale del trattamento (nella popolazione, l’ATE simulato era pari a 5).\n\nQuesto esempio mostra come possiamo simulare una popolazione con covariate che influenzano l’outcome e come utilizzare una regressione per aggiustare queste covariate quando stimiamo l’effetto del trattamento (ATE).",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/01_rct.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/causal_inference/01_rct.html#informazioni-sullambiente-di-sviluppo",
    "title": "84  Trial controllati randomizzati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nNeyman, J. (1923). Sur les applications de la théorie des probabilités aux experiences agricoles: Essai des principes. Roczniki Nauk Rolniczych, 10(1), 1–51.\n\n\nRubin, D. B. (1974). Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of educational Psychology, 66(5), 688–701.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>Trial controllati randomizzati</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html",
    "href": "chapters/causal_inference/02_ate_att_atu.html",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "",
    "text": "85.1 Introduzione\nNel Capitolo 84 abbiamo visto come concettualizzare e calcolare l’ATE quando la randomizzazione è possibile, ovvero nel caso degli RCT. Tuttavia, non è sempre possibile o etico condurre esperimenti randomizzati e, in tali casi, abbiamo a disposizione solo i risultati di studi osservazonali. Tali studi, pur rivestendo un ruolo importante nella ricerca empirica, pongono notevoli sfide per l’inferenza causale, principalmente a causa del problema del confondimento. In questo capitolo, esploreremo la stima dell’effetto del trattamento in contesti osservazionali, dove il confondimento si manifesta quando variabili non controllate influenzano sia la probabilità di ricevere il trattamento sia l’outcome di interesse.\nPer comprendere meglio come il confondimento possa distorcere le stime degli effetti causali, è utile esaminare come l’effetto di un trattamento (o intervento) possa variare all’interno di diverse popolazioni o gruppi. Tre concetti chiave in questo ambito sono l’Effetto Medio del Trattamento (Average Treatment Effect, ATE), l’Effetto Medio del Trattamento sui Trattati (Average Treatment Effect on the Treated, ATT), e l’Effetto Medio del Trattamento sui Non Trattati (Average Treatment Effect on the Untreated, ATU). Questi concetti sono fondamentali per comprendere come un intervento possa influenzare non solo l’intera popolazione, ma anche specifici sottogruppi al suo interno.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#effetto-medio-del-trattamento-ate",
    "href": "chapters/causal_inference/02_ate_att_atu.html#effetto-medio-del-trattamento-ate",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.2 Effetto Medio del Trattamento (ATE)",
    "text": "85.2 Effetto Medio del Trattamento (ATE)\nL’ATE rappresenta l’effetto medio che un trattamento ha su tutta la popolazione, indipendentemente dal fatto che gli individui abbiano effettivamente ricevuto il trattamento o meno. Formalmente, l’ATE è definito come la differenza media tra l’outcome che si otterrebbe se tutti fossero trattati e l’outcome che si otterrebbe se nessuno fosse trattato:\n\\[\n\\text{ATE} = E[Y^1 - Y^0]\n\\]\nDove \\(Y^1\\) rappresenta l’outcome se un individuo riceve il trattamento e \\(Y^0\\) rappresenta l’outcome se non lo riceve. L’ATE è utile per politiche che interessano l’intera popolazione, come un programma sanitario nazionale.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#effetto-medio-del-trattamento-sui-trattati-att",
    "href": "chapters/causal_inference/02_ate_att_atu.html#effetto-medio-del-trattamento-sui-trattati-att",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.3 Effetto Medio del Trattamento sui Trattati (ATT)",
    "text": "85.3 Effetto Medio del Trattamento sui Trattati (ATT)\nL’ATT misura l’effetto medio del trattamento solo per gli individui che hanno effettivamente ricevuto il trattamento. Questo concetto è particolarmente utile quando si vuole capire l’impatto del trattamento su coloro che lo hanno scelto o lo hanno ricevuto, ad esempio in uno studio osservazionale dove non tutti gli individui sono trattati:\n\\[\n\\text{ATT} = E[Y^1 - Y^0 \\mid X = 1]\n\\]\nDove \\(X = 1\\) indica che l’individuo ha ricevuto il trattamento. L’ATT è rilevante per valutare l’efficacia di un intervento sui partecipanti effettivi, come l’effetto di un programma di formazione sui partecipanti iscritti.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#effetto-medio-del-trattamento-sui-non-trattati-atu",
    "href": "chapters/causal_inference/02_ate_att_atu.html#effetto-medio-del-trattamento-sui-non-trattati-atu",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.4 Effetto Medio del Trattamento sui Non Trattati (ATU)",
    "text": "85.4 Effetto Medio del Trattamento sui Non Trattati (ATU)\nL’ATU misura l’effetto medio che il trattamento avrebbe avuto sugli individui che non hanno ricevuto il trattamento. È particolarmente utile per prevedere cosa accadrebbe se il trattamento fosse esteso a una popolazione che attualmente non lo riceve:\n\\[\n\\text{ATU} = E[Y^1 - Y^0 \\mid X = 0]\n\\]\nDove \\(X = 0\\) indica che l’individuo non ha ricevuto il trattamento. L’ATU è utile per valutare l’effetto potenziale dell’estensione di un trattamento a una popolazione che non è stata precedentemente trattata.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#dati-ipotetici",
    "href": "chapters/causal_inference/02_ate_att_atu.html#dati-ipotetici",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.5 Dati Ipotetici",
    "text": "85.5 Dati Ipotetici\nEcco una tabella di esempio che mostra i potenziali outcomes e gli effetti causali individuali (ICE) per un gruppo di individui:\n\n\n\n\n\n\n\n\n\n\n\n\nID\nEtà\nTrattato\nOutcome con Trattamento (Y^1)\nOutcome senza Trattamento (Y^0)\nEffetto Causale Individuale (ICE, δ)\nOutcome Osservato (Y)\n\n\n\n\n1\nAnziano\n1\n80\n60\n20\n80\n\n\n2\nAnziano\n1\n75\n70\n5\n75\n\n\n3\nAnziano\n1\n85\n80\n5\n85\n\n\n4\nAnziano\n0\n70\n60\n10\n60\n\n\n5\nGiovane\n1\n75\n70\n5\n75\n\n\n6\nGiovane\n0\n80\n80\n0\n80\n\n\n7\nGiovane\n0\n90\n100\n-10\n100\n\n\n8\nGiovane\n0\n85\n80\n5\n80",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#calcolo-di-ate-att-e-atu",
    "href": "chapters/causal_inference/02_ate_att_atu.html#calcolo-di-ate-att-e-atu",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.6 Calcolo di ATE, ATT e ATU",
    "text": "85.6 Calcolo di ATE, ATT e ATU\nPossiamo calcolare i tre stimatori come segue:\n\nATE: Media degli effetti causali individuali per tutti gli individui.\nATT: Media degli effetti causali individuali solo per i trattati.\nATU: Media degli effetti causali individuali solo per i non trattati.\n\nUsando il seguente codice Python, possiamo calcolare questi valori dai dati della tabella.\n\nimport pandas as pd\n\n# Creazione del dataframe\ndata = {\n    \"ID\": [1, 2, 3, 4, 5, 6, 7, 8],\n    \"Età\": [\n        \"Anziano\",\n        \"Anziano\",\n        \"Anziano\",\n        \"Anziano\",\n        \"Giovane\",\n        \"Giovane\",\n        \"Giovane\",\n        \"Giovane\",\n    ],\n    \"Trattato\": [1, 1, 1, 0, 1, 0, 0, 0],\n    \"Y1\": [80, 75, 85, 70, 75, 80, 90, 85],\n    \"Y0\": [60, 70, 80, 60, 70, 80, 100, 80],\n}\n\ndf = pd.DataFrame(data)\ndf[\"ICE\"] = df[\"Y1\"] - df[\"Y0\"]\n\n# Calcolo di ATE, ATT, ATU\nATE = df[\"ICE\"].mean()\nATT = df[df[\"Trattato\"] == 1][\"ICE\"].mean()\nATU = df[df[\"Trattato\"] == 0][\"ICE\"].mean()\n\nATE, ATT, ATU\n\n(5.0, 8.75, 1.25)\n\n\nEseguendo il codice Python sopra, otteniamo:\n\nATE: 5\nATT: 8.75\nATU: 1.25\n\nQuesti valori illustrano come l’effetto del trattamento vari a seconda del gruppo di interesse e offrono una comprensione più granulare dell’impatto di un intervento.\n\n85.6.1 La Differenza tra Dati Teorici ed Empirici nell’Inferenza Causale\nI dati presentati nella tabella precedente rappresentano una situazione solo teorica, in cui possiamo osservare direttamente l’effetto che il trattamento avrebbe su ciascun individuo. Questo effetto è noto come Effetto Causale Individuale (Individual Causal Effect, ICE). In un tale mondo ipotetico, possiamo confrontare per ogni individuo l’outcome con e senza trattamento, calcolando esattamente quanto il trattamento abbia influenzato l’outcome di quell’individuo. Questo ci permette di calcolare l’ATE (Effetto Medio del Trattamento), l’ATT (Effetto Medio del Trattamento sui Trattati) e l’ATU (Effetto Medio del Trattamento sui Non Trattati) in modo preciso.\n\n\n85.6.2 La Natura Impossibile dei Dati Teorici\nTuttavia, questa situazione ideale è impossibile da realizzarsi empiricamente. Non possiamo osservare contemporaneamente l’outcome per un individuo sia con che senza trattamento. Questo perché, nella realtà, un individuo può trovarsi in una sola delle due condizioni: o riceve il trattamento o non lo riceve. Non possiamo tornare indietro nel tempo per osservare cosa sarebbe successo se un individuo che ha ricevuto il trattamento non l’avesse ricevuto, o viceversa. Questa impossibilità è alla base di ciò che viene chiamato il problema fondamentale dell’inferenza causale.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#dati-empirici-e-il-problema-della-confondimento",
    "href": "chapters/causal_inference/02_ate_att_atu.html#dati-empirici-e-il-problema-della-confondimento",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.7 Dati Empirici e il Problema della Confondimento",
    "text": "85.7 Dati Empirici e il Problema della Confondimento\nIn un contesto empirico, i dati non sono costituiti da osservazioni teoriche come quelle della tabella precedente, ma piuttosto da due gruppi di individui: quelli che hanno ricevuto il trattamento e quelli che non l’hanno ricevuto. Non abbiamo accesso agli ICE per ciascun individuo; possiamo solo osservare i risultati degli individui che hanno ricevuto il trattamento e di quelli che non lo hanno ricevuto.\nUn esempio di questi dati empirici è mostrato nella seguente tabella, dove vediamo solo il risultato osservato per ogni individuo e il fatto che essi abbiano o meno ricevuto il trattamento. Questo tipo di dati è comune negli studi osservazionali, dove il trattamento non è assegnato casualmente, ma piuttosto gli individui scelgono se partecipare o meno al trattamento, o sono selezionati per esso in base a determinati criteri.\n\n\n\nID\nEtà\nTrattato\nOutcome Osservato (Y)\n\n\n\n\n1\nAnziano\n1\n80\n\n\n2\nAnziano\n1\n75\n\n\n3\nAnziano\n1\n85\n\n\n4\nAnziano\n0\n60\n\n\n5\nGiovane\n1\n75\n\n\n6\nGiovane\n0\n80\n\n\n7\nGiovane\n0\n100\n\n\n8\nGiovane\n0\n80\n\n\n\nIn questa tabella, l’ID identifica l’individuo, Età indica la fascia d’età dell’individuo (Anziano o Giovane), Trattato è una variabile binaria che indica se l’individuo ha ricevuto il trattamento (1 = sì, 0 = no), e Outcome Osservato (Y) è il risultato osservato per ciascun individuo. Questa tabella riflette ciò che sarebbe tipicamente disponibile in uno studio empirico, dove non possiamo osservare simultaneamente gli outcome con e senza trattamento per lo stesso individuo.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#il-problema-della-non-equivalenza-dei-gruppi",
    "href": "chapters/causal_inference/02_ate_att_atu.html#il-problema-della-non-equivalenza-dei-gruppi",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.8 Il Problema della Non Equivalenza dei Gruppi",
    "text": "85.8 Il Problema della Non Equivalenza dei Gruppi\nUno dei problemi principali negli studi osservazionali è che i due gruppi—quelli che ricevono il trattamento e quelli che non lo ricevono—non sono equivalenti. Questa non equivalenza è dovuta alla presenza di variabili di confondimento: fattori che influenzano sia la probabilità di ricevere il trattamento sia l’outcome di interesse. Ad esempio, in uno studio che esamina l’effetto di un programma di formazione sul reddito, l’età e il livello di istruzione potrebbero essere variabili di confondimento, poiché influenzano sia la probabilità di partecipare al programma sia il reddito.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#limpossibilità-di-calcolare-diretamente-late",
    "href": "chapters/causal_inference/02_ate_att_atu.html#limpossibilità-di-calcolare-diretamente-late",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.9 L’Impossibilità di Calcolare Diretamente l’ATE",
    "text": "85.9 L’Impossibilità di Calcolare Diretamente l’ATE\nA causa della presenza di queste variabili di confondimento, non possiamo semplicemente calcolare l’ATE come la differenza tra le medie dei due gruppi (trattati e non trattati). Se facessimo così, rischieremmo di ignorare l’influenza delle variabili di confondimento, ottenendo una stima distorta dell’effetto del trattamento. Ad esempio, se il gruppo trattato è composto da individui più giovani e istruiti rispetto al gruppo non trattato, la differenza osservata nei risultati potrebbe essere dovuta in parte a queste caratteristiche, piuttosto che all’effetto del trattamento stesso.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#strategie-per-superare-il-problema-del-confondimento",
    "href": "chapters/causal_inference/02_ate_att_atu.html#strategie-per-superare-il-problema-del-confondimento",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.10 Strategie per Superare il Problema del Confondimento",
    "text": "85.10 Strategie per Superare il Problema del Confondimento\nPer stimare correttamente l’Effetto Medio del Trattamento (ATE) o altri effetti del trattamento in studi osservazionali, è fondamentale affrontare il problema del confondimento. Il confondimento si verifica quando una variabile non osservata o non controllata influenza sia la probabilità di ricevere il trattamento sia l’outcome di interesse, rendendo difficile isolare l’effetto puro del trattamento. Esistono diverse tecniche statistiche sviluppate per tenere conto delle variabili di confondimento, ognuna delle quali offre un approccio diverso per correggere le distorsioni che il confondimento può introdurre.\n\n85.10.1 Matching\nIl matching è una tecnica che mira a creare coppie o gruppi di individui trattati e non trattati che siano simili rispetto alle variabili di confondimento. L’idea alla base del matching è che, confrontando individui che sono simili in tutte le caratteristiche rilevanti tranne che per il trattamento ricevuto, si possa isolare l’effetto del trattamento stesso. Esistono diversi tipi di matching, tra cui:\n\nMatching 1:1: Ogni individuo trattato viene abbinato a un individuo non trattato che ha caratteristiche simili.\nMatching caliper: Gli individui sono abbinati solo se la distanza tra le loro variabili di confondimento è inferiore a una certa soglia.\nPropensity Score Matching (PSM): Si calcola un punteggio di propensione (la probabilità di ricevere il trattamento data una serie di covariate) e si abbinano individui trattati e non trattati con punteggi di propensione simili.\n\nIl matching riduce il bias di confondimento, ma richiede un campione abbastanza grande per trovare corrispondenze adeguate e può non eliminare completamente il confondimento, specialmente se alcune variabili importanti non sono osservate o misurate.\n\n\n85.10.2 Ponderazione Inversa della Probabilità (IPW)\nLa ponderazione inversa della probabilità (Inverse Probability Weighting, IPW) è un’altra tecnica per affrontare il confondimento, basata sull’assegnazione di pesi agli individui in base alla loro probabilità stimata di ricevere il trattamento. L’IPW utilizza modelli statistici per calcolare la probabilità (o punteggio di propensione) che un individuo riceva il trattamento dato un insieme di variabili di confondimento.\n\nGli individui trattati che avevano una bassa probabilità di ricevere il trattamento ricevono un peso maggiore.\nGli individui non trattati che avevano una bassa probabilità di non ricevere il trattamento ricevono un peso maggiore.\n\nQuesto metodo bilancia le distribuzioni delle variabili di confondimento tra i gruppi trattati e non trattati, in modo che i gruppi possano essere confrontati in modo più equo, come se fossero stati creati attraverso una randomizzazione.\nTuttavia, l’IPW richiede un modello accurato per stimare i punteggi di propensione e può essere sensibile ai pesi estremi, che possono amplificare le variazioni e introdurre instabilità nelle stime.\n\n\n85.10.3 Stratificazione\nLa stratificazione implica la divisione della popolazione in sottogruppi (o strati) omogenei rispetto a una o più variabili di confondimento. Una volta creati questi strati, si può calcolare l’effetto del trattamento all’interno di ciascun sottogruppo, riducendo il confondimento all’interno degli strati.\n\nAd esempio, si potrebbe stratificare la popolazione per età, dividendo gli individui in fasce d’età, e poi calcolare l’effetto del trattamento all’interno di ciascuna fascia.\n\nLa stratificazione permette di controllare il confondimento senza la necessità di abbinare direttamente individui trattati e non trattati o di assegnare pesi. Tuttavia, la stratificazione può diventare complessa se ci sono molte variabili di confondimento, e il numero di individui in ciascun strato potrebbe diventare troppo piccolo per produrre stime affidabili.\n\n\n85.10.4 Altre Tecniche\nOltre a queste tecniche, esistono anche altre metodologie avanzate per affrontare il confondimento negli studi osservazionali:\n\nRegressione con covariate: L’inclusione delle variabili di confondimento come covariate in un modello di regressione permette di stimare l’effetto del trattamento al netto del confondimento.\nAnalisi delle variabili strumentali: Si utilizza una variabile strumentale che è correlata con il trattamento ma non con l’outcome, tranne che attraverso il trattamento, per isolare l’effetto causale.\nPropensity Score Weighting: Una combinazione di matching e ponderazione basata sui punteggi di propensione per ottenere una distribuzione bilanciata delle covariate nei gruppi trattati e non trattati.\n\nQueste tecniche, se applicate correttamente, permettono di isolare l’effetto causale del trattamento riducendo l’influenza delle variabili di confondimento. Tuttavia, è importante scegliere la tecnica appropriata in base alla natura dei dati e alle ipotesi sottostanti, nonché considerare la possibilità che il confondimento residuo possa ancora influenzare le stime. In ogni caso, queste metodologie avanzate migliorano significativamente la nostra capacità di fare inferenze causali accurate in studi osservazionali, avvicinandoci a stime più precise dell’ATE, ATT e ATU.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/02_ate_att_atu.html#conclusione",
    "href": "chapters/causal_inference/02_ate_att_atu.html#conclusione",
    "title": "85  Concetti di ATE, ATT e ATU",
    "section": "85.11 Conclusione",
    "text": "85.11 Conclusione\nIn sintesi, mentre i dati teorici ci permettono di calcolare con precisione gli effetti causali individuali, i dati empirici raccolti in studi osservazionali presentano sfide significative a causa della non equivalenza dei gruppi e della presenza di variabili di confondimento. Per affrontare queste sfide, è essenziale utilizzare metodi statistici avanzati che permettano di stimare correttamente gli effetti del trattamento, evitando di commettere errori di interpretazione che potrebbero derivare da stime non corrette.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Concetti di ATE, ATT e ATU</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/03_endogenous_treatments.html",
    "href": "chapters/causal_inference/03_endogenous_treatments.html",
    "title": "86  Inferenza causale con trattamenti endogeni",
    "section": "",
    "text": "Introduzione\nQuando parliamo di stima degli effetti dei trattamenti assumendo l’assenza di confondimento (unconfoundedness), di solito presupponiamo che, una volta considerati i fattori rilevanti, l’assegnazione del trattamento sia essenzialmente casuale. In altre parole, il trattamento è considerato “esogeno”, ossia indipendente dalle variabili che vogliamo studiare. Questo approccio è utile in molte applicazioni, ma ci sono situazioni in cui tali assunzioni non sono realistiche. Ad esempio, quando si cerca di analizzare l’effetto della terapia cognitivo-comportamentale sulla riduzione dei sintomi depressivi, potrebbe non essere realistico supporre che l’assegnazione della terapia sia completamente casuale. Spesso, l’assegnazione può dipendere dalle caratteristiche del paziente o dal giudizio del terapeuta, creando così una relazione endogena tra trattamento e risultato.\nIn questo capitolo, affronteremo i metodi per l’inferenza causale in contesti dove l’assegnazione del trattamento è endogena, cioè dipendente dall’interazione con altre variabili del sistema. Introduciamo prima i modelli di equazioni strutturali (SEM) non-parametrici, che permettono di modellare tali relazioni. Successivamente, discuteremo i metodi delle variabili strumentali, utili quando l’assunzione di esogeneità non regge.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Inferenza causale con trattamenti endogeni</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/03_endogenous_treatments.html#introduzione",
    "href": "chapters/causal_inference/03_endogenous_treatments.html#introduzione",
    "title": "86  Inferenza causale con trattamenti endogeni",
    "section": "",
    "text": "86.0.1 Modelli di equazioni strutturali e il calcolo do\nI modelli di equazioni strutturali (SEM) descrivono le relazioni causali tra variabili usando grafi aciclici diretti (DAG). Un DAG è un insieme di nodi collegati da frecce (o archi) che rappresentano le relazioni di causa-effetto tra variabili. Ad esempio, in un contesto psicologico, un nodo potrebbe rappresentare il livello di ansia di un individuo (Z1), mentre un altro nodo potrebbe rappresentare la probabilità di successo in una terapia cognitivo-comportamentale (Z2). Le frecce tra i nodi indicano la direzione del rapporto causale. Un DAG è aciclico, il che significa che non si creano cicli, cioè una variabile non può influenzare se stessa tramite una serie di effetti intermedi.\nPer esempio, consideriamo un modello in cui l’ansia (Z1) influenza direttamente il successo della terapia (Z2) e, a sua volta, il successo della terapia influenza il benessere generale del paziente (Z3). Possiamo rappresentare questo sistema con un DAG dove ogni freccia mostra una relazione causale diretta tra queste variabili.\nQuando parliamo di inferenza causale, possiamo usare il cosiddetto calcolo do introdotto da Judea Pearl. Questo metodo permette di rispondere a domande causali simulando l’intervento su una variabile e osservando come ciò influenzi le altre. Ad esempio, se vogliamo sapere come il cambiamento del trattamento psicologico influisca sul livello di ansia, possiamo usare l’operatore do per fissare il valore del trattamento e osservare come questo cambiamento si ripercuote sugli altri nodi nel DAG.\n\n\n86.0.2 Il criterio della “back-door”\nIl calcolo do consente anche di identificare condizioni in cui possiamo rispondere a domande causali pur non osservando tutte le variabili rilevanti. Una di queste condizioni è il cosiddetto “criterio della back-door”. Supponiamo di voler studiare l’effetto di una terapia cognitivo-comportamentale (W) sulla riduzione dei sintomi depressivi (Y), ma sospettiamo che ci siano variabili non osservate che influenzano sia l’assegnazione del trattamento che il risultato. Se riusciamo a trovare un insieme di variabili che blocca tutte le “vie” attraverso cui la confusione potrebbe verificarsi, possiamo ancora stimare l’effetto causale della terapia.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Inferenza causale con trattamenti endogeni</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/03_endogenous_treatments.html#le-variabili-strumentali",
    "href": "chapters/causal_inference/03_endogenous_treatments.html#le-variabili-strumentali",
    "title": "86  Inferenza causale con trattamenti endogeni",
    "section": "86.1 Le variabili strumentali",
    "text": "86.1 Le variabili strumentali\nIn molti contesti psicologici, potremmo non essere in grado di osservare direttamente tutte le variabili confondenti. Per esempio, quando studiamo l’effetto della motivazione sul successo in una terapia, la motivazione potrebbe essere influenzata da fattori non osservati, come le esperienze di vita del paziente. In questi casi, le variabili strumentali possono aiutare. Un strumento è una variabile che è correlata al trattamento (ad esempio, la frequenza delle sedute terapeutiche), ma che non ha un effetto diretto sul risultato (la riduzione dei sintomi), se non attraverso il trattamento.\nL’uso di variabili strumentali può essere illustrato con un esempio. Immagina di voler stimare l’effetto del supporto sociale (W) sulla riduzione dell’ansia (Y), ma sospetti che esistano fattori non osservati (U), come la personalità del paziente, che influenzano sia la scelta del supporto sociale che il livello di ansia. Se possiamo trovare una variabile strumentale, come la disponibilità di gruppi di supporto nella comunità (Z), che influenza l’uso del supporto sociale, ma che non è direttamente correlata all’ansia, possiamo usare Z per stimare l’effetto di W su Y.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Inferenza causale con trattamenti endogeni</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/03_endogenous_treatments.html#simulazione",
    "href": "chapters/causal_inference/03_endogenous_treatments.html#simulazione",
    "title": "86  Inferenza causale con trattamenti endogeni",
    "section": "86.2 Simulazione",
    "text": "86.2 Simulazione\nPer chiarire, facciamo un esempio numerico. Per simulare l’effetto del supporto sociale (W) sulla riduzione dell’ansia (Y) utilizzando variabili strumentali in un contesto di inferenza causale, possiamo ipotizzare una struttura con un confondente non osservato (U) e una variabile strumentale (Z).\n\n# Crea un grafo diretto (DAG) usando Graphviz \ndag_supporto_sociale = Digraph(comment=\"DAG Supporto Sociale\")\n\n# Definisci i nodi\ndag_supporto_sociale.node(\n    \"Z\", \"Z (Disponibilità gruppo di supporto)\", shape=\"plaintext\"\n)\ndag_supporto_sociale.node(\"W\", \"W (Supporto sociale)\", shape=\"plaintext\")\ndag_supporto_sociale.node(\"Y\", \"Y (Ansia)\", shape=\"plaintext\")\ndag_supporto_sociale.node(\"U\", \"U (Confondente non osservato)\", shape=\"plaintext\")\n\n# Aggiungi gli archi (relazioni causali)\ndag_supporto_sociale.edge(\"Z\", \"W\")\ndag_supporto_sociale.edge(\"W\", \"Y\")\ndag_supporto_sociale.edge(\"U\", \"W\")\ndag_supporto_sociale.edge(\"U\", \"Y\")\n\ndag_supporto_sociale\n\n\n\n\n\n\n\n\n\n86.2.1 Step 1: Definizione del modello\nConsideriamo il seguente modello lineare:\n\n\\(Y = \\alpha + \\tau W + \\epsilon_Y\\) dove \\(Y\\) è il livello di ansia, \\(W\\) è il supporto sociale, e \\(\\epsilon_Y\\) è un errore.\n\\(W = \\beta Z + \\eta\\) dove \\(Z\\) è la variabile strumentale (ad esempio, la disponibilità di gruppi di supporto sociale), e \\(\\eta\\) è un errore che incorpora il confondente non osservato \\(U\\).\n\\(Z\\) deve essere correlato a \\(W\\) ma non direttamente a \\(Y\\), a parte attraverso \\(W\\).\n\n\n\n86.2.2 Step 2: Simulazione dei dati\nPrima di procedere con la simulazione in Python, ipotizziamo dei valori ragionevoli per i parametri e generiamo i dati:\n\n\\(\\alpha = 5\\) (intercetta per il livello di ansia)\n\\(\\tau = -1.5\\) (effetto del supporto sociale sulla riduzione dell’ansia, che ci aspettiamo negativo)\n\\(\\beta = 0.8\\) (effetto della variabile strumentale sul supporto sociale)\nGli errori \\(\\epsilon_Y\\) e \\(\\eta\\) sono normalmente distribuiti.\n\n\n\n86.2.3 Step 3: Implementazione in Python\n\n# Parametri\nnp.random.seed(42)\nn = 500  # Numero di soggetti\nalpha = 5\ntau = -1.5\nbeta = 0.8\nsigma_Y = 1  # Deviazione standard dell'errore su Y\nsigma_W = 1  # Deviazione standard dell'errore su W\n\n# Simulazione delle variabili\nZ = np.random.normal(0, 1, n)  # Variabile strumentale\neta = np.random.normal(0, sigma_W, n)  # Errore per W\nepsilon_Y = np.random.normal(0, sigma_Y, n)  # Errore per Y\n\n# Modello del supporto sociale (W dipende da Z)\nW = beta * Z + eta\n\n# Modello dell'ansia (Y dipende da W)\nY = alpha + tau * W + epsilon_Y\n\n# Creiamo un dataframe\ndata = pd.DataFrame({\"Z\": Z, \"W\": W, \"Y\": Y})\n\n# Prima analisi: Regressione di W su Z \nX = sm.add_constant(data[\"Z\"])  # Aggiungiamo la costante\nmodel_W_Z = sm.OLS(data[\"W\"], X).fit()  # Regressione W ~ Z\nprint(model_W_Z.summary())\n\n# Prevediamo W (Fase 1 - previsioni di W in funzione di Z)\ndata[\"W_hat\"] = model_W_Z.predict(X)\n\n# Seconda fase: Regressione di Y su W_hat (usando Pingouin)\nreg_y_w_hat = pg.linear_regression(data[\"W_hat\"], data[\"Y\"])\nprint(reg_y_w_hat)\n\n# Visualizziamo la relazione tra le variabili\nplt.figure(figsize=(10, 5))\n\n# Scatter plot di Z vs W\nplt.subplot(1, 2, 1)\nplt.scatter(data[\"Z\"], data[\"W\"])\nplt.title(\"Z vs W (Supporto sociale)\")\nplt.xlabel(\"Z (Variabile strumentale)\")\nplt.ylabel(\"W (Supporto sociale)\")\n\n# Scatter plot di W_hat vs Y\nplt.subplot(1, 2, 2)\nplt.scatter(data[\"W_hat\"], data[\"Y\"])\nplt.title(\"W_hat vs Y (Ansia)\")\nplt.xlabel(\"W_hat (Supporto sociale stimato)\")\nplt.ylabel(\"Y (Ansia)\")\n\nplt.tight_layout()\nplt.show()\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      W   R-squared:                       0.347\nModel:                            OLS   Adj. R-squared:                  0.346\nMethod:                 Least Squares   F-statistic:                     264.7\nDate:                Sat, 21 Sep 2024   Prob (F-statistic):           4.82e-48\nTime:                        09:06:53   Log-Likelihood:                -696.41\nNo. Observations:                 500   AIC:                             1397.\nDf Residuals:                     498   BIC:                             1405.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0323      0.044      0.741      0.459      -0.053       0.118\nZ              0.7246      0.045     16.270      0.000       0.637       0.812\n==============================================================================\nOmnibus:                        0.328   Durbin-Watson:                   2.021\nProb(Omnibus):                  0.849   Jarque-Bera (JB):                0.425\nSkew:                           0.049   Prob(JB):                        0.809\nKurtosis:                       2.895   Cond. No.                         1.02\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n       names      coef        se          T           pval        r2  \\\n0  Intercept  5.111547  0.076923  66.450216  1.064346e-249  0.300567   \n1      W_hat -1.582114  0.108150 -14.628931   1.425191e-40  0.300567   \n\n     adj_r2  CI[2.5%]  CI[97.5%]  \n0  0.299163  4.960414   5.262681  \n1  0.299163 -1.794600  -1.369628  \n\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_45414/4164621354.py:53: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n\n86.2.4 Spiegazione del codice:\n\nSimulazione:\n\nGeneriamo una variabile strumentale \\(Z\\), l’errore \\(\\eta\\) che influenza \\(W\\), e \\(\\epsilon_Y\\), l’errore per \\(Y\\).\nIl supporto sociale \\(W\\) dipende da \\(Z\\) e dall’errore \\(\\eta\\).\nIl livello di ansia \\(Y\\) dipende da \\(W\\) e dall’errore \\(\\epsilon_Y\\).\n\nRegressione con variabili strumentali:\n\nPrima stimiamo \\(W\\) in funzione di \\(Z\\) usando una regressione lineare.\nPoi usiamo il valore stimato \\(W_{\\text{hat}}\\) per stimare l’effetto su \\(Y\\).\n\nVisualizzazione:\n\nTracciamo due grafici che mostrano la relazione tra \\(Z\\) e \\(W\\), e tra \\(W_{\\text{hat}}\\) e \\(Y\\), per evidenziare la validità della nostra variabile strumentale.\n\n\n\n\n86.2.5 Risultati\nNella simulazione che abbiamo eseguito, l’obiettivo era stimare l’effetto del supporto sociale (\\(W\\)) sulla riduzione dell’ansia (\\(Y\\)) utilizzando una variabile strumentale (\\(Z\\)) che rappresenta la disponibilità di gruppi di supporto.\nAbbiamo ipotizzato un modello causale in cui:\n\n\\(Z\\) (disponibilità di gruppi di supporto) influenza direttamente \\(W\\) (supporto sociale).\n\\(W\\), a sua volta, ha un effetto causale negativo su \\(Y\\) (livello di ansia).\nInoltre, abbiamo introdotto un confondente non osservato \\(U\\) (ad esempio, caratteristiche personali come la resilienza), che influenza sia \\(W\\) che \\(Y\\).\n\nPrima fase: Regressione di \\(W\\) su \\(Z\\). Il modello ha mostrato una relazione positiva tra \\(Z\\) e \\(W\\), il che significa che la disponibilità di gruppi di supporto (\\(Z\\)) aumenta il livello di supporto sociale (\\(W\\)). Questo conferma che \\(Z\\) è una variabile strumentale valida perché ha un impatto su \\(W\\).\nSeconda fase: Regressione di \\(Y\\) su \\(\\hat{W}\\). Nella seconda fase, abbiamo trovato che \\(\\hat{W}\\), la stima del supporto sociale, ha un effetto negativo su \\(Y\\) (ansia). Questo risultato è coerente con la nostra aspettativa: un maggiore supporto sociale riduce l’ansia. Questo conferma l’effetto causale negativo del supporto sociale sulla riduzione dell’ansia.\nIn conclusione,\n\n\\(Z\\) è stato un buon strumento, poiché influenza significativamente \\(W\\) e non ha un effetto diretto su \\(Y\\), se non attraverso \\(W\\).\nLa simulazione ha mostrato che il supporto sociale riduce i livelli di ansia, confermando la nostra ipotesi che un maggiore accesso ai gruppi di supporto riduce l’ansia nei soggetti.\n\nQuesto tipo di analisi con variabili strumentali è particolarmente utile quando ci sono confondenti non osservabili (come \\(U\\)) che influenzano sia il trattamento che l’outcome, poiché l’uso di uno strumento esterno come \\(Z\\) consente di isolare l’effetto causale di \\(W\\) su \\(Y\\).",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Inferenza causale con trattamenti endogeni</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/03_endogenous_treatments.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/causal_inference/03_endogenous_treatments.html#informazioni-sullambiente-di-sviluppo",
    "title": "86  Inferenza causale con trattamenti endogeni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Jul 17 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>Inferenza causale con trattamenti endogeni</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "",
    "text": "Introduzione\nLo scopo di questo capitolo è esaminare il modello di regressione multipla come strumento per descrivere le relazioni causali. Il modello di regressione offre indubbi vantaggi: i coefficienti parziali di regressione consentono di isolare l’effetto lineare di una variabile, tenendo conto dell’influenza delle altre variabili presenti nel modello. Questo approccio permette di ottenere quello che viene comunemente chiamato “controllo statistico”.\nTuttavia, è fondamentale riconoscere che questo risultato si raggiunge solo se il modello di regressione include tutte le variabili indipendenti che sono associate con la variabile dipendente e correlate con le altre variabili del modello. Nel capitolo precedente, abbiamo introdotto il concetto di errore di specificazione: se escludiamo dal modello di regressione una variabile che ha un effetto causale su \\(Y\\) ed è correlata con gli altri predittori, le stime degli effetti causali ottenute saranno sistematicamente distorte.\nUn’interpretazione ingenua dell’errore di specificazione potrebbe portare a pensare che la soluzione sia includere il maggior numero possibile di predittori, per massimizzare il controllo statistico e ridurre il rischio di errore. Tuttavia, questo approccio, che McElreath (2020) definisce “insalata causale”, genera più problemi di quanti ne risolva.\nIn questo capitolo, esploreremo come la selezione delle variabili indipendenti da includere nel modello di regressione richieda una conoscenza approfondita della struttura causale del fenomeno in esame. Senza una tale comprensione, l’uso del modello di regressione può risultare più dannoso che utile. I limiti dell’approccio “insalata causale” sono chiaramente evidenziati anche dallo studio di Debertin et al. (2024), che ha come obiettivo identificare i criteri per la selezione delle covariate da includere in un’analisi causale.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html#confondimento",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html#confondimento",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "87.1 Confondimento",
    "text": "87.1 Confondimento\nIniziamo con una definizione del fenomeno del confondimento. Il confondimento si verifica quando l’associazione tra un risultato \\(Y\\) e un predittore di interesse \\(X\\) differisce da quella che si osserverebbe se i valori di \\(X\\) fossero determinati sperimentalmente.\nAd esempio, consideriamo l’associazione tra istruzione (\\(E\\)) e salario (\\(W\\)). Esistono variabili non osservate (\\(U\\)) che influenzano entrambe, come il luogo di residenza e lo status socioeconomico. Nel seguente grafo causale, ci sono due percorsi tra \\(E\\) e \\(W\\):\n\nf = graphviz.Digraph()\nwith f.subgraph() as s:\n    s.attr(rank='same')\n    s.node(\"E\")\n    s.node(\"W\")\n\nf.node(\"U\")\nf.edge(\"U\", \"E\")\nf.edge(\"U\", \"W\")\nf.edge(\"E\", \"W\")\n\nf\n\n\n\n\n\n\n\n\n\nPercorso causale diretto: \\(E \\rightarrow W\\)\nPercorso non causale indiretto: \\(E \\leftarrow U \\rightarrow W\\)\n\nSolo il primo percorso (\\(E \\rightarrow W\\)) rappresenta un effetto causale. Il secondo percorso (\\(E \\leftarrow U \\rightarrow W\\)) crea un’associazione statistica ma non causale.\nPer isolare il percorso causale, la soluzione ideale è condurre un esperimento randomizzato, assegnando i livelli di istruzione \\(E\\) casualmente, eliminando così l’influenza di \\(U\\) su \\(E\\). L’assegnazione casuale dell’istruzione blocca il percorso \\(E \\leftarrow U \\rightarrow W\\), lasciando solo il percorso causale \\(E \\rightarrow W\\).\nTuttavia, questo esperimento non può essere eseguito. In assenza di esperimenti, è necessaria una soluzione statistica che blocchi il percorso non causale. In assenza di esperimenti, si può condizionare su \\(U\\) aggiungendolo al modello statistico. Questo blocca il flusso di informazioni attraverso \\(U\\), isolando l’effetto causale tra \\(E\\) e \\(W\\).\nAd esempio, se \\(U\\) è la ricchezza media di una regione, conoscere \\(U\\) (la regione) elimina l’influenza indiretta su \\(W\\) attraverso \\(E\\). Dopo aver appreso \\(U\\), sapere \\(E\\) non aggiunge ulteriori informazioni su \\(W\\).\nIn sintesi, il confondimento può distorcere l’associazione tra due variabili a causa di percorsi indiretti attraverso variabili non osservate. La randomizzazione o il condizionamento su queste variabili può isolare il percorso causale, permettendo di misurare accuratamente l’effetto di una variabile sull’altra.\nQuesta discussione ha un’implicazione importante per il modello di regressione. Nel caso dell’esempio, solo se introduciamo nel modello di regressione la covariata \\(U\\), ovvero se condizioniamo su \\(U\\), possiamo stimare in maniera non distorta la relazione causale tra \\(E\\) e \\(W\\). Tuttavia, ci sono anche casi in cui introdurre la covariata sbagliata può introdurre distorsioni nei risultati dell’analisi di regressione. Senza una comprensione delle relazioni causali che legano le variabili, non è possibile determinare quali siano le variabili da inserire o da escludere dal modello di regressione.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html#confondimento-1",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html#confondimento-1",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "87.2 Confondimento",
    "text": "87.2 Confondimento\nIniziamo con una definizione del fenomeno del confondimento. Il confondimento si verifica quando l’associazione tra un risultato \\(Y\\) e un predittore di interesse \\(X\\) differisce da quella che si osserverebbe se i valori di \\(X\\) fossero determinati sperimentalmente.\nAd esempio, consideriamo l’associazione tra istruzione (\\(E\\)) e salario (\\(W\\)). Esistono variabili non osservate (\\(U\\)) che influenzano entrambe, come il luogo di residenza e lo status socioeconomico. Nel seguente grafo causale, ci sono due percorsi tra \\(E\\) e \\(W\\):\nimport graphviz\nf = graphviz.Digraph()\nwith f.subgraph() as s:\n    s.attr(rank='same')\n    s.node(\"E\")\n    s.node(\"W\")\nf.node(\"U\")\nf.edge(\"U\", \"E\")\nf.edge(\"U\", \"W\")\nf.edge(\"E\", \"W\")\nf\n\nPercorso causale diretto: \\(E \\rightarrow W\\)\nPercorso non causale indiretto: \\(E \\leftarrow U \\rightarrow W\\)\n\nSolo il primo percorso (\\(E \\rightarrow W\\)) rappresenta un effetto causale. Il secondo percorso (\\(E \\leftarrow U \\rightarrow W\\)) crea un’associazione statistica ma non causale.\nPer isolare il percorso causale, la soluzione ideale è condurre un esperimento randomizzato, assegnando i livelli di istruzione \\(E\\) casualmente, eliminando così l’influenza di \\(U\\) su \\(E\\). L’assegnazione casuale dell’istruzione blocca il percorso \\(E \\leftarrow U \\rightarrow W\\), lasciando solo il percorso causale \\(E \\rightarrow W\\).\nTuttavia, questo esperimento non può essere eseguito. In assenza di esperimenti, è necessaria una soluzione statistica che blocchi il percorso non causale. Si può condizionare su \\(U\\) aggiungendolo al modello statistico. Questo blocca il flusso di informazioni attraverso \\(U\\), isolando l’effetto causale tra \\(E\\) e \\(W\\).\nAd esempio, se \\(U\\) è la ricchezza media di una regione, conoscere \\(U\\) (la regione) elimina l’influenza indiretta su \\(W\\) attraverso \\(E\\). Dopo aver appreso \\(U\\), sapere \\(E\\) non aggiunge ulteriori informazioni su \\(W\\).\nIn sintesi, il confondimento può distorcere l’associazione tra due variabili a causa di percorsi indiretti attraverso variabili non osservate. La randomizzazione o il condizionamento su queste variabili può isolare il percorso causale, permettendo di misurare accuratamente l’effetto di una variabile sull’altra.\nQuesta discussione ha un’implicazione importante per il modello di regressione. Nel caso dell’esempio, solo se introduciamo nel modello di regressione la covariata \\(U\\), ovvero se condizioniamo su \\(U\\), possiamo stimare in maniera non distorta la relazione causale tra \\(E\\) e \\(W\\). Tuttavia, ci sono anche casi in cui introdurre la covariata sbagliata può introdurre distorsioni nei risultati dell’analisi di regressione. Senza una comprensione delle relazioni causali che legano le variabili, non è possibile determinare quali siano le variabili da inserire o da escludere dal modello di regressione.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html#bloccare-i-percorsi-backdoor",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html#bloccare-i-percorsi-backdoor",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "87.3 Bloccare i percorsi backdoor",
    "text": "87.3 Bloccare i percorsi backdoor\nBloccare i percorsi di confondimento tra un predittore \\(X\\) e un risultato \\(Y\\) è noto come “chiudere un percorso backdoor”. Non vogliamo che nessuna associazione spuria entri attraverso un percorso non causale che coinvolge il predittore \\(X\\). Nell’esempio sopra, il percorso \\(E \\leftarrow U \\rightarrow W\\) è un percorso di backdoor, poiché entra in \\(E\\) con una freccia e collega \\(E\\) a \\(W\\). Questo percorso non è causale: intervenire su \\(E\\) non provocherà un cambiamento in \\(W\\) attraverso questo percorso, ma produrrà comunque un’associazione tra \\(E\\) e \\(W\\).\nLa buona notizia è che, dato un grafo aciclico diretto (DAG) causale, è sempre possibile determinare quali variabili controllare per chiudere tutti i percorsi di backdoor. È anche possibile identificare quali variabili non controllare per evitare di creare nuovi confondimenti. Esistono quattro tipi fondamentali di relazioni causali che combinano tutti i possibili percorsi: la biforcazione, la catena, il collider e il discendente. Pertanto, è necessario comprendere solo questi quattro concetti e come fluisce l’informazione in ciascuno di essi.\n\nConfondente: Una variabile \\(U\\) che causa sia il predittore \\(X\\) sia il risultato \\(Y\\). Aggiustare per un confondente (fork) è necessario per ottenere stime non distorte.\n\nEsempio: \\(X \\leftarrow U \\rightarrow Y\\).\n\nCatena: Una sequenza di variabili in cui una causa l’altra, formando un percorso diretto. Non si dovrebbe aggiustare per le variabili lungo questo percorso, poiché rappresenta il percorso causale.\n\nEsempio: \\(X \\rightarrow Z \\rightarrow Y\\).\n\nCollider: Una variabile che è causata da due altre variabili. Aggiustare per un collider può introdurre confondimento, poiché si crea un’associazione spuria tra i due predittori.\n\nEsempio: \\(X \\rightarrow Z \\leftarrow Y\\).\n\nDiscendente: Una variabile che è causata sia dal predittore \\(X\\) sia dal risultato \\(Y\\). Condizionare su un discendente può introdurre un bias, distorcendo l’associazione tra \\(X\\) e \\(Y\\).\n\nEsempio: \\(X \\rightarrow W \\leftarrow Y\\) con \\(W\\) che ha un effetto su \\(Z\\) (discendente).\n\n\nComprendere queste relazioni e sapere come intervenire su di esse è fondamentale per costruire modelli di regressione che riflettano accuratamente le relazioni causali tra le variabili. Questo approccio permette di isolare gli effetti causali e di evitare le distorsioni introdotte da percorsi di backdoor.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html#tipi-di-relazioni-elementari-nei-dag",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html#tipi-di-relazioni-elementari-nei-dag",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "87.4 Tipi di relazioni elementari nei DAG",
    "text": "87.4 Tipi di relazioni elementari nei DAG\nOgni DAG, per quanto grande e complicato, è costruito sulle quattro relazioni elementari descritte in precedenza. Esaminiamole in dettaglio.\n\n87.4.1 Confondimento\nLa configurazione detta “fork” rappresenta un classico caso di confondimento. Nel confondimento, una variabile \\(Z\\) è una causa comune di due variabili \\(X\\) e \\(Y\\), generando una correlazione tra loro: \\(X \\leftarrow Z \\rightarrow Y\\). Se condiamo su \\(Z\\), allora \\(X\\) e \\(Y\\) diventano indipendenti.\n\nfork = Digraph(comment='Forchetta')\nfork.node('X', 'X', shape='plaintext')\nfork.node('Y', 'Y', shape='plaintext')\nfork.node('Z', 'Z', shape='plaintext')\nfork.edge('Z', 'X')\nfork.edge('Z', 'Y')\nfork\n\n\n\n\n\n\n\n\n\n87.4.1.1 Esempio\nConsideriamo l’effetto dell’istruzione (\\(X\\)) sul salario (\\(Y\\)) con \\(Z\\) che rappresenta lo status socioeconomico.\n\n\n87.4.1.2 Conseguenze del Controllo\n\nControllare \\(Z\\): Blocca il percorso non causale, isolando l’effetto diretto di \\(X\\) su \\(Y\\).\nNon controllare \\(Z\\): Introduce confondimento, portando a una stima distorta dell’effetto di \\(X\\) su \\(Y\\).\n\n\nn = 1000\nZ = np.random.normal(0, 1, n)\nX = 0.5 * Z + np.random.normal(0, 1, n)\nY = 0.8 * Z + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})\n\n# Modello senza controllo per Z\nmod1 = bmb.Model('Y ~ X', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.02\n0.04\n-0.09\n0.05\n0.0\n0.0\n6310.32\n3060.06\n1.0\n\n\nX\n0.30\n0.03\n0.23\n0.36\n0.0\n0.0\n5784.06\n2927.95\n1.0\n\n\nsigma\n1.23\n0.03\n1.18\n1.28\n0.0\n0.0\n6424.03\n3165.63\n1.0\n\n\n\n\n\n\n\n\n# Modello con controllo per Z\nmod2 = bmb.Model('Y ~ X + Z', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-0.03\n0.03\n-0.08\n0.03\n0.0\n0.0\n5749.64\n3042.71\n1.0\n\n\nX\n-0.04\n0.03\n-0.10\n0.02\n0.0\n0.0\n3711.94\n3112.96\n1.0\n\n\nZ\n0.84\n0.04\n0.77\n0.90\n0.0\n0.0\n3850.83\n3388.92\n1.0\n\n\nsigma\n0.99\n0.02\n0.95\n1.03\n0.0\n0.0\n5593.71\n2941.94\n1.0\n\n\n\n\n\n\n\n\n\n\n87.4.2 Catena\nIn una catena, una variabile \\(X\\), influenza un mediatore \\(Z\\), che a sua volta influenza l’esito \\(Y\\): \\(X \\rightarrow Z \\rightarrow Y\\). Condizionare su \\(Z\\) blocca il percorso da \\(X\\) a \\(Y\\).\n\npipe = Digraph(comment='Tubo')\npipe.node('X', 'X', shape='plaintext')\npipe.node('Y', 'Y', shape='plaintext')\npipe.node('Z', 'Z', shape='plaintext')\npipe.edge('X', 'Z')\npipe.edge('Z', 'Y')\npipe\n\n\n\n\n\n\n\n\n\n87.4.2.1 Esempio\nConsideriamo l’effetto dell’apprendimento (\\(X\\)) sulla comprensione (\\(Y\\)) mediato dalla conoscenza (\\(Z\\)).\n\n\n87.4.2.2 Conseguenze del Controllo\n\nControllare \\(Z\\): Blocca il percorso causale, fornendo solo l’effetto diretto di \\(X\\) su \\(Y\\).\nNon controllare \\(Z\\): Misura l’effetto totale di \\(X\\) su \\(Y\\).\n\n\nX = np.random.normal(0, 1, n)\nZ = 5 * X + np.random.normal(0, 1, n)\nY = 3 * Z + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'X': X, 'Z': Z, 'Y': Y})\n\n# Modello senza controllo per Z\nmod1 = bmb.Model('Y ~ X', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.04\n0.10\n-0.15\n0.23\n0.0\n0.0\n6356.32\n2949.31\n1.0\n\n\nX\n14.95\n0.10\n14.77\n15.13\n0.0\n0.0\n6321.33\n3376.27\n1.0\n\n\nsigma\n3.20\n0.07\n3.06\n3.33\n0.0\n0.0\n6103.86\n2993.17\n1.0\n\n\n\n\n\n\n\n\n# Modello con controllo per Z\nmod2 = bmb.Model('Y ~ X + Z', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n0.04\n0.03\n-0.03\n0.10\n0.0\n0.0\n3132.72\n2315.01\n1.0\n\n\nX\n0.23\n0.16\n-0.09\n0.52\n0.0\n0.0\n1234.56\n1621.51\n1.0\n\n\nZ\n2.95\n0.03\n2.89\n3.01\n0.0\n0.0\n1231.93\n1656.26\n1.0\n\n\nsigma\n1.03\n0.02\n0.99\n1.07\n0.0\n0.0\n2903.70\n2513.20\n1.0\n\n\n\n\n\n\n\n\n\n\n87.4.3 Collider\nIn un collider, due variabili \\(X\\) e \\(Y\\) influenzano una terza variabile \\(Z\\): \\(X \\rightarrow Z \\leftarrow Y\\). Condizionare su \\(Z\\) può indurre una correlazione spuria tra \\(X\\) e \\(Y\\).\n\ncollider = Digraph(comment='Collider')\ncollider.node('X', 'X', shape='plaintext')\ncollider.node('Y', 'Y', shape='plaintext')\ncollider.node('Z', 'Z', shape='plaintext')\ncollider.edge('X', 'Z')\ncollider.edge('Y', 'Z')\ncollider\n\n\n\n\n\n\n\n\nIl bias di selezione si verifica quando il campione che analizziamo non è rappresentativo della popolazione a causa del processo di selezione. Questo può portare a correlazioni spurie perché il processo di selezione può favorire involontariamente alcune caratteristiche.\nIl bias del collider (o bias di stratificazione del collider) si verifica quando due variabili, \\(X\\) e \\(Y\\), influenzano una terza variabile \\(Z\\) (il collider). Se ci condiamo su \\(Z\\), possiamo indurre un’associazione spuria tra \\(X\\) e \\(Y\\), anche se queste variabili sono scorrelate nella popolazione.\nNell’esempio tratto da McElreath (2020)`, si suggerisce che sembra che gli studi scientifici più degni di nota siano i meno affidabili. Più è probabile che uno studio sia interessante, se vero, meno è probabile che sia vero. Più noioso è il tema, più rigorosi sono i risultati. Come può esistere questa correlazione negativa, ampiamente creduta da molti?\nIn realtà, tutto ciò che è necessario affinché emerga una tale correlazione negativa è che ci si preoccupin sia della rilevanza che dell’affidabilità. Che si tratti di revisione di sovvenzioni o di riviste, se editori e revisori si preoccupano di entrambi gli aspetti, allora l’atto stesso della selezione è sufficiente a rendere gli studi più rilevanti i meno affidabili. Infatti, è difficile immaginare come il processo di peer review possa evitare di creare questa correlazione negativa.\nEcco una semplice simulazione per illustrare il concetto. Supponiamo che un pannello di revisione delle sovvenzioni riceva 200 proposte di ricerca. Tra queste proposte, non vi è alcuna correlazione tra affidabilità (rigore, erudizione, plausibilità del successo) e rilevanza (valore per il benessere sociale, interesse pubblico). Il pannello pesa in ugual misura l’affidabilità e la rilevanza. Successivamente, classificano le proposte in base ai loro punteggi combinati e selezionano il 10% migliore per il finanziamento.\n\n# Numero di proposte da finanziare\nN = 200\n# Proporzione da selezionare\np = 0.1\n# Rilevanza non correlata\nnw = np.random.randn(N)\n# Affidabilità non correlata\ntw = np.random.randn(N)\ncorrelation = np.corrcoef(tw, nw)[0, 1]\nprint(correlation)\n\n0.026051430796600182\n\n\nNello script, il processo di selezione basato sul punteggio combinato s induce una correlazione spuria tra nw e tw. Sebbene nw e tw siano non correlati nell’intero dataset, essi appaiono correlati nel sottoinsieme selezionato.\n\n# Punteggio totale\ns = nw + tw\n# Soglia per il 10% migliore\nq = np.quantile(s, 1 - p)\n# Selezionati\nselected = s &gt;= q\n# Correlazione tra affidabilità e rilevanza nei selezionati\ncorrelation = np.corrcoef(tw[selected], nw[selected])[0, 1]\nprint(correlation)\n\n-0.7082917138754293\n\n\nSi noti che:\n\nIl punteggio combinato s agisce come un collider perché è influenzato sia da nw che da tw.\nQuando selezioniamo le proposte basandoci su s (condizioniamo su s), introduciamo involontariamente una correlazione tra nw e tw nel sottoinsieme selezionato.\n\nIn altre parole, condizionando su una variabile (s) che è influenzata sia da nw che da tw, induciamo una correlazione spuria tra queste due variabili non correlate. Questo è un esempio specifico di bias del collider, dove il processo di selezione agisce come il collider.\nPer riassumere:\n\nBias di selezione: in questo esempio si verifica perché analizziamo solo il 10% delle proposte migliori.\nBias del collider: è introdotto perché la variabile di selezione s (punteggio totale) è influenzata sia da nw che da tw, portando a una correlazione spuria quando condiamo su s.\n\nQuindi, la correlazione spuria osservata nel sottoinsieme selezionato è il risultato del bias del collider introdotto dal processo di selezione basato sul punteggio combinato.\nPerché la correlazione è negativa nel sottoinsieme di dati selezionato? Perché, ad esempio, se una proposta selezionata ha una bassa affidabilità (tw), deve avere un’alta rilevanza (nw). Altrimenti, non sarebbe stata finanziata. Lo stesso vale al contrario: se una proposta ha una bassa rilevanza (nw), possiamo dedurre che deve avere un’affidabilità superiore alla media. Altrimenti, non sarebbe stata selezionata per il finanziamento. Questo è il concetto chiave da comprendere: quando condiamo su un collider, si creano associazioni statistiche, ma non necessariamente causali, tra le sue cause.\n\n\n87.4.4 Discendente\nUn discendente è una variabile influenzata da un’altra variabile. Condizionare su un discendente significa parzialmente condizionare sul suo genitore. Nel DAG seguente, condizionare su \\(D\\) condizionerà anche, in una certa misura, su \\(Z\\).\n\ndescendant = Digraph(comment='Discendente')\ndescendant.node('X', 'X', shape='plaintext')\ndescendant.node('Y', 'Y', shape='plaintext')\ndescendant.node('Z', 'Z', shape='plaintext')\ndescendant.node('D', 'D', shape='plaintext')\ndescendant.edge('X', 'Z')\ndescendant.edge('Y', 'Z')\ndescendant.edge('Z', 'D')\ndescendant\n\n\n\n\n\n\n\n\nQuesto perché \\(D\\) contiene informazioni su \\(Z\\), che a sua volta è un collider tra \\(X\\) e \\(Y\\). Condizionare su \\(D\\) può aprire parzialmente il percorso da \\(X\\) a \\(Y\\) attraverso \\(Z\\), creando un’associazione spuria tra \\(X\\) e \\(Y\\). Tuttavia, l’effetto di condizionare su un discendente dipende dalla relazione tra il discendente e il suo genitore. I discendenti sono comuni nei modelli causali perché spesso non possiamo misurare una variabile direttamente e dobbiamo utilizzare un proxy per essa.\n\n87.4.4.1 Esempio\nConsideriamo l’effetto dell’intelligenza (\\(X\\)) sul punteggio del test (\\(Y\\)) tramite il tempo di apprendimento (\\(Z\\)) e il punteggio in una simulazione (\\(D\\)).\n\n\n87.4.4.2 Conseguenze del Controllo\n\nControllare \\(D\\): Può introdurre bias, creando un percorso non causale da \\(X\\) a \\(Y\\) attraverso \\(Z\\).\nNon controllare \\(D\\): Mantiene il percorso causale corretto da \\(X\\) a \\(Y\\).\n\n\nI = np.random.normal(100, 15, n)\nT = 200 - I + np.random.normal(0, 1, n)\nS = 0.5 * I + 0.1 * T + np.random.normal(0, 1, n)\nD = 0.7 * S + np.random.normal(0, 1, n)\n\ndf = pd.DataFrame({'I': I, 'T': T, 'S': S, 'D': D})\n\n# Modello senza controllo per D\nmod1 = bmb.Model('S ~ T', df)\nresults1 = mod1.fit()\n\n\naz.summary(results1, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n99.39\n0.24\n98.92\n99.82\n0.0\n0.0\n5831.85\n3060.37\n1.0\n\n\nT\n-0.39\n0.00\n-0.40\n-0.39\n0.0\n0.0\n5879.01\n3269.97\n1.0\n\n\nsigma\n1.10\n0.02\n1.05\n1.14\n0.0\n0.0\n6041.49\n3081.54\n1.0\n\n\n\n\n\n\n\n\n# Modello con controllo per D\nmod2 = bmb.Model('S ~ T + D', df)\nresults2 = mod2.fit()\n\n\naz.summary(results2, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nD\n0.50\n0.02\n0.45\n0.54\n0.00\n0.00\n2526.07\n2095.97\n1.0\n\n\nIntercept\n64.78\n1.58\n61.69\n67.64\n0.03\n0.02\n2486.35\n2167.12\n1.0\n\n\nT\n-0.26\n0.01\n-0.27\n-0.24\n0.00\n0.00\n2490.85\n2271.87\n1.0\n\n\nsigma\n0.90\n0.02\n0.86\n0.94\n0.00\n0.00\n3237.43\n2629.65\n1.0",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html#come-aprire-o-chiudere-un-percorso-nei-dag",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html#come-aprire-o-chiudere-un-percorso-nei-dag",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "87.5 Come aprire o chiudere un percorso nei DAG",
    "text": "87.5 Come aprire o chiudere un percorso nei DAG\nPer determinare quali variabili includere o escludere nel modello di regressione, è necessario seguire questa procedura:\n\nElencare tutti i percorsi che collegano \\(X\\) (la potenziale causa di interesse) e \\(Y\\) (il risultato).\nClassificare ciascun percorso come aperto o chiuso. Un percorso è aperto a meno che non contenga un collider.\nIdentificare i percorsi di backdoor. Un percorso di backdoor ha una freccia che entra in \\(X\\).\nChiudere i percorsi di backdoor aperti: Se ci sono percorsi di backdoor aperti, decidere su quali variabili condizionare per chiuderli, se possibile.\n\nCondizionare su una variabile significa includerla nel modello di regressione. Per chiudere un percorso di backdoor, identifichiamo la variabile di confondimento che crea l’associazione spuria e la includiamo nel modello. Questo bloccherà il percorso, impedendo che l’associazione spuria influenzi il risultato.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html#come-costruire-un-dag",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html#come-costruire-un-dag",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "87.6 Come Costruire un DAG?",
    "text": "87.6 Come Costruire un DAG?\nI Directed Acyclic Graphs (DAG) sono strumenti fondamentali per rappresentare relazioni causali. Tuttavia, la loro costruzione pratica presenta sfide significative, soprattutto quando la struttura causale sottostante non è completamente nota. Debertin et al. (2024) affrontano una questione cruciale: come costruire un DAG efficace quando la struttura causale del fenomeno studiato non è completamente conosciuta?\nLa visione tradizionale richiedeva l’identificazione e la correzione di tutte le cause comuni tra esposizione e risultato. L’approccio moderno, invece, si concentra sul bloccare i percorsi di confondimento, senza necessariamente includere tutte le variabili storicamente considerate confondenti. Idealmente, un DAG dovrebbe includere tutte le variabili che fungono da cause comuni, ma in pratica è necessario fare scelte su quali variabili includere, data la conoscenza incompleta delle relazioni causali.\nIdealmente, un DAG dovrebbe includere tutte le variabili che fungono da cause comuni tra altre variabili presenti nel grafico. In pratica, però, è necessario fare delle scelte su quali variabili includere, poiché non tutte le relazioni causali tra esposizione e risultato sono completamente esplorate o conosciute.\nDiversi metodi sono stati proposti per la costruzione dei DAG:\n\nIl criterio della causa disgiuntiva, che consiglia di includere tutte le cause dirette note dell’esposizione o del risultato;\nL’uso di covariate pretrattamento legate all’esposizione, spesso noto come approccio “tutto incluso”;\nL’inclusione di tutti i fattori prognostici noti per il risultato, che concentra l’attenzione sui fattori che influenzano l’outcome indipendentemente dall’esposizione.\n\nPer valutare questi diversi approcci, Debertin et al. (2024) hanno utilizzato i dati del Coronary Drug Project (CDP). Questo studio è particolarmente utile perché si ritiene con elevata certezza che l’aderenza al placebo non abbia un effetto causale sulla mortalità, offrendo così un esempio concreto in cui l’effetto causale vero è noto essere nullo.\n\n87.6.1 Tipologie di DAG costruiti\nNell’analisi di Debertin et al. (2024), sono stati utilizzati tre approcci di costruzione dei DAG:\n\nI DAG basati sui risultati (o outcome-driven DAG) sono grafici causali costruiti con l’obiettivo di includere principalmente variabili che sono forti fattori prognostici dell’outcome, ovvero del risultato che si intende spiegare o prevedere. In altre parole, queste variabili sono scelte perché hanno una forte associazione con l’esito finale, come la mortalità o il successo di un trattamento. L’idea alla base di questo approccio è che includendo variabili che influenzano direttamente l’outcome (come fattori di rischio ben noti), si può ottenere un modello più robusto e meno influenzato da variabili irrilevanti. In questo contesto, non si cerca di includere necessariamente tutte le variabili che potrebbero influenzare l’esposizione (ad esempio, l’aderenza al trattamento), ma piuttosto ci si concentra su quelle che possono spiegare al meglio il risultato finale. L’obiettivo di un DAG basato sui risultati è quindi quello di controllare principalmente le cause dell’outcome, in modo da correggere efficacemente il confondimento senza necessariamente includere variabili legate all’esposizione, che potrebbero non avere una forte relazione con l’outcome stesso.\nI DAG “trimmed” (o DAG ridotti) sono grafici causali che vengono semplificati rimuovendo alcune variabili dopo una revisione critica della letteratura e delle evidenze disponibili. L’obiettivo principale di questo approccio è ridurre il modello a quelle variabili che sono effettivamente rilevanti per la relazione causale che si vuole studiare, evitando di includere variabili che potrebbero non essere utili o addirittura introdurre confondimento non necessario.\nI DAG massimizzati (o maximal DAGs) sono grafici causali costruiti aggiungendo ulteriori covariate che potrebbero potenzialmente influenzare sia l’esposizione sia l’outcome. Questo approccio punta a includere il maggior numero possibile di variabili rilevanti per assicurarsi di catturare tutte le relazioni causali importanti e ridurre il rischio di bias dovuto alla mancata considerazione di fattori chiave. Si parte da un DAG di base che include le variabili principali note identificate attraverso la letteratura o da esperti del campo. Si identificano e si aggiungono ulteriori covariate che, in teoria o secondo studi precedenti, potrebbero influenzare l’esposizione (ad esempio, l’aderenza a un trattamento) o l’outcome (ad esempio, la mortalità). Queste variabili aggiuntive vengono scelte anche se la loro influenza non è ancora stata del tutto dimostrata o quantificata in maniera definitiva.\n\nL’articolo descrive come sono stati costruiti questi diversi DAG per esplorare l’effetto dell’aderenza al placebo sulla mortalità.\n\n\n87.6.2 Risultati dell’analisi\nL’analisi ha rivelato quanto segue.\n\n\n87.6.3 1. DAG basati sui risultati:\nI DAG basati sui risultati si concentrano sull’inclusione di variabili che sono identificabili come fattori prognostici diretti per l’outcome (in questo caso, la mortalità). Questo approccio si basa su una selezione di covariate che, secondo le evidenze disponibili o l’esperienza degli esperti, influenzano direttamente il risultato finale. Ad esempio, potrebbero essere incluse variabili come l’età, la presenza di malattie cardiovascolari preesistenti o altre condizioni mediche rilevanti.\n\nVantaggi: Questo approccio ha prodotto stime che erano coerenti con quelle ottenute nelle precedenti analisi del CDP. Anche se l’inclusione di covariate di base ha ridotto il confondimento, non è stata sufficiente per eliminarlo completamente. Tuttavia, con l’inclusione di covariate che variano nel tempo (ad esempio, l’aderenza che cambia tra le visite di follow-up), il DAG basato sui risultati è riuscito ad avvicinarsi molto al valore nullo atteso. Questo indica che il controllo del confondimento è migliorato quando sono state aggiunte variabili che tengono conto delle dinamiche temporali.\nSvantaggi: L’approccio non è perfetto perché, anche includendo i principali fattori prognostici, il confondimento non viene eliminato del tutto quando si considerano solo variabili di base. Alcune relazioni temporali e dinamiche tra variabili possono essere ignorate se non si considerano covariate variabili nel tempo.\n\n\n\n87.6.4 2. DAG trimmed:\nI DAG trimmed sono una versione semplificata del DAG basato sui risultati. In questo approccio, gli autori hanno rimosso le variabili che, sulla base della letteratura o delle evidenze empiriche, non sembrano avere una forte influenza sull’esposizione o sull’outcome. L’obiettivo è rendere il modello più snello, includendo solo le variabili realmente rilevanti e riducendo il rischio di introdurre sovra-aggiustamento o varianza inutile.\n\nVantaggi: I DAG trimmed hanno prodotto stime più precise rispetto ai DAG basati sui risultati. Questo è dovuto al fatto che la rimozione di variabili irrilevanti ha ridotto la varianza delle stime, rendendo i risultati più stabili e robusti. Nonostante la rimozione di alcune covariate, il DAG trimmed ha mantenuto un buon controllo del confondimento, senza sacrificare la validità delle stime. Inoltre, la semplificazione ha migliorato l’efficienza del modello, permettendo di focalizzarsi su variabili che hanno un reale impatto sul risultato.\nSvantaggi: Anche se questo approccio riduce la varianza, c’è il rischio che alcune variabili, che potrebbero avere un’influenza marginale ma significativa, vengano eliminate. Tuttavia, nel caso analizzato, questo non ha avuto effetti negativi significativi, e il DAG trimmed ha dimostrato di funzionare bene.\n\n\n\n87.6.5 3. DAG massimizzati:\nI DAG massimizzati rappresentano un approccio opposto a quello dei DAG trimmed. In questo caso, gli autori hanno scelto di aggiungere ulteriori covariate che potrebbero influenzare sia l’esposizione che l’outcome. L’obiettivo è assicurarsi di non escludere nessuna variabile potenzialmente rilevante, inclusi fattori legati allo stile di vita, condizioni mediche aggiuntive, fattori psicologici, e altre caratteristiche non incluse nei DAG di base o trimmed.\n\nVantaggi: L’idea di base dietro i DAG massimizzati è che includendo più variabili, si riduca il rischio di bias dovuto a variabili non osservate. Si spera che, catturando un numero più ampio di fattori potenzialmente influenti, si ottenga un modello più completo, che tenga conto di tutte le possibili relazioni causali tra esposizione e outcome.\nSvantaggi: Tuttavia, l’analisi ha mostrato che i DAG massimizzati hanno avuto prestazioni peggiori rispetto agli altri approcci nel controllo del confondimento. Aggiungere molte covariate non ha migliorato il controllo del bias e ha invece prodotto stime meno accurate e distanti dal valore nullo. Questo fenomeno può essere attribuito a un fenomeno noto come sovra-aggiustamento: includere variabili che non sono fortemente associate con l’outcome o che non sono necessarie per il controllo del confondimento può amplificare il bias. Alcune delle variabili aggiunte, come fattori legati allo stile di vita o alla salute mentale, potrebbero aver introdotto rumore nei dati, aumentando l’incertezza nelle stime.\nConclusione sui DAG massimizzati: Anche se l’intenzione era di creare un modello più completo e dettagliato, questo approccio ha introdotto complessità e ha peggiorato la qualità delle stime. Questo conferma la necessità di essere selettivi nell’inclusione delle covariate, evitando l’aggiunta di variabili che non contribuiscono effettivamente al controllo del confondimento.\n\n\n\n87.6.6 Differenze tra i tre approcci:\n\nDAG basati sui risultati: Si concentrano sull’inclusione di variabili chiave che influenzano direttamente l’outcome. Sono un buon punto di partenza ma non eliminano del tutto il confondimento.\nDAG trimmed: Riducono la varianza e migliorano la precisione delle stime eliminando variabili non necessarie, senza introdurre bias significativo.\nDAG massimizzati: Introducono più covariate per coprire ogni potenziale fattore, ma questo può portare a sovra-aggiustamento, peggiorando il controllo del confondimento e aumentando il bias.\n\n\n\n87.6.7 Conclusioni:\nL’analisi di Debertin et al. suggerisce che un approccio equilibrato come quello del DAG trimmed offre il miglior compromesso tra controllo del confondimento e precisione delle stime. Includere solo le variabili strettamente necessarie (come nei DAG basati sui risultati) può essere efficace, ma semplificare ulteriormente il modello eliminando variabili irrilevanti (DAG trimmed) può migliorare ulteriormente la qualità delle stime. Al contrario, l’aggiunta di troppe variabili, come nei DAG massimizzati, può peggiorare i risultati e amplificare il bias, specialmente quando si includono covariate non strettamente collegate all’outcome.\nQuesto caso studio conferma che la selezione delle variabili per il controllo del confondimento tramite i DAG ha un impatto rilevante sui risultati. I risultati supportano teorie secondo cui è importante evitare di includere variabili debolmente associate all’outcome e concentrarsi invece sull’identificazione di fattori prognostici per il risultato.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html#riflessioni-conclusive",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html#riflessioni-conclusive",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "87.7 Riflessioni conclusive",
    "text": "87.7 Riflessioni conclusive\nIn conclusione, le osservazioni precedenti dimostrano che l’inferenza causale non può essere affrontata semplicemente applicando meccanicamente il modello statistico della regressione lineare. Senza ulteriori conoscenze, che non possono essere derivate esclusivamente dai dati osservati, non è possibile ottenere stime non distorte degli effetti causali. L’inferenza causale va oltre le tecniche statistiche: essa richiede informazioni supplementari sulle caratteristiche del fenomeno studiato.\nPer trarre conclusioni corrette sui meccanismi causali, è essenziale disporre di informazioni dettagliate sul processo generativo dei dati. Benché spesso queste informazioni non siano direttamente disponibili, i ricercatori possono adottare strategie per minimizzare il rischio di errori interpretativi. Un passo fondamentale consiste nell’identificare ipotetici meccanismi causali prima di procedere con le stime degli effetti, utilizzando diagrammi causali come i grafici aciclici diretti per mappare le relazioni tra le variabili. Questo processo aiuta a determinare quali fattori includere nell’analisi, seguendo il “backdoor criterion” proposto da Judea Pearl, per chiudere i percorsi indiretti tra esposizione ed esito che potrebbero introdurre confondimenti.\nIn assenza di una comprensione del fenomeno in esame, è cruciale che i ricercatori prestino attenzione all’ordine temporale dei fattori. Questo approccio, fondamentale per l’inferenza causale, implica che l’esposizione avvenga prima dell’esito per stabilire una relazione causale plausibile. Inoltre, è importante che tutte le covariate considerate nell’analisi precedano temporalmente l’esposizione per evitare potenziali bias di specificazione, specialmente nei contesti di collider e mediazione. Seguendo questi principi, i ricercatori possono ridurre il rischio di stime errate degli effetti causali.\n\n\n\n\n\n\n\nTermine Tecnico\nSpiegazione\n\n\n\n\n(1) Collider\nLa variabile \\(X\\), causa \\(Z\\), e l’esito, \\(Y\\), causa \\(Z\\). Aggiustando per \\(Z\\) quando si stima l’effetto di \\(X\\) su \\(Y\\) si ottiene un risultato distorto. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Y = X + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\); \\(Z = 0.45X + 0.77Y + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\)\n\n\n(2) Confounder\nLa variabile \\(Z\\) causa sia la variabile indipendente \\(X\\), sia l’esito, \\(Y\\). Non aggiustando per \\(Z\\) quando si stima l’effetto di \\(X\\) su \\(Y\\) si ottiene un risultato distorto. Meccanismo di generazione dei dati: \\(Z \\sim \\mathcal{N}(0,1)\\), \\(X = Z + \\varepsilon_x\\), \\(\\varepsilon_x \\sim \\mathcal{N}(0,1)\\); \\(Y = 0.5X + Z + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\)\n\n\n(3) Mediator\nLa variabile \\(X\\) causa \\(Z\\) che a sua volta causa l’esito \\(Y\\). Aggiustando per \\(Z\\) quando si stima l’effetto di \\(X\\) su \\(Y\\) si ottiene l’effetto diretto, non aggiustando per \\(Z\\) si ottiene l’effetto totale di \\(X\\) su \\(Y\\). L’effetto diretto rappresenta la relazione tra \\(X\\) e \\(Y\\) indipendentemente da qualsiasi mediatore, mentre l’effetto totale include sia l’effetto diretto sia qualsiasi effetto indiretto mediato dal mediatore potenziale. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Z = X + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\); \\(Y = Z + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\)\n\n\n(4) Discendente\nLa variabile \\(X\\) e l’esito \\(Y\\) hanno una variabile discendente comune \\(Z\\). Non aggiustando per \\(Z\\) quando si stima l’effetto di \\(X\\) su \\(Y\\) si ottiene una stima non distorta. Tuttavia, aggiustando per \\(Z\\), si introduce un bias. Meccanismo di generazione dei dati: \\(X \\sim \\mathcal{N}(0,1)\\), \\(Y = X + \\varepsilon_y\\), \\(\\varepsilon_y \\sim \\mathcal{N}(0,1)\\); \\(Z = 0.5X + 0.5Y + \\varepsilon_z\\), \\(\\varepsilon_z \\sim \\mathcal{N}(0,1)\\)",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/04_mult_reg_causal_inference.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/causal_inference/04_mult_reg_causal_inference.html#informazioni-sullambiente-di-sviluppo",
    "title": "87  Inferenza causale nella regressione multipla",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnetworkx   : 3.3\npandas     : 2.2.2\nbambi      : 0.14.0\nseaborn    : 0.13.2\ngraphviz   : 0.20.3\nnumpy      : 1.26.4\narviz      : 0.18.0\nmatplotlib : 3.9.1\nstatsmodels: 0.14.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nDebertin, J., Vélez, J. A. J., Corlin, L., Hidalgo, B., & Murray, E. J. (2024). Synthesizing subject-matter expertise for variable selection in causal effect estimation: A case study. Epidemiology, 10–1097.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>Inferenza causale nella regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/05_collider_bias.html",
    "href": "chapters/causal_inference/05_collider_bias.html",
    "title": "88  Collider bias",
    "section": "",
    "text": "Introduzione\nUno studio recente di Fitzgerald (2024) ha messo in discussione i risultati di una precedente analisi condotta da Rains & Richards (2024) sull’impatto dei mandati vaccinali COVID-19. Rains & Richards (2024) avevano confrontato stati che avevano introdotto mandati con stati che li avevano vietati, cercando di valutare l’effetto di queste politiche sui tassi di vaccinazione COVID-19 e sui vaccini antinfluenzali.\nFitzgerald (2024) ha evidenziato un problema metodologico nell’analisi di Rains & Richards (2024), indicando la presenza di un “bias del collider”. Questo tipo di bias si verifica quando si controlla per una variabile, chiamata “collider”, che è influenzata da due variabili precedenti (genitori) in un grafo aciclico diretto (DAG) e che, a sua volta, influisce sulla variabile dipendente di interesse. Nel caso specifico, il tasso di vaccinazione COVID-19 fungeva da collider, poiché era influenzato sia dai mandati vaccinali sia da altri fattori, come l’esitazione vaccinale. L’inclusione di questa variabile come controllo nel modello ha distorto i risultati, portando a conclusioni errate.\nLo studio di Fitzgerald (2024) sottolinea l’importanza di considerare attentamente la struttura causale dei dati nelle analisi statistiche. Questo caso evidenzia come la scelta delle variabili di controllo possa influenzare drasticamente i risultati e le conseguenti interpretazioni.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Collider bias</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/05_collider_bias.html#rains-e-richards-2024",
    "href": "chapters/causal_inference/05_collider_bias.html#rains-e-richards-2024",
    "title": "88  Collider bias",
    "section": "88.1 Rains e Richards (2024)",
    "text": "88.1 Rains e Richards (2024)\nLo studio di Rains & Richards (2024) sui mandati di vaccinazione COVID-19 negli Stati Uniti ha portato a due conclusioni principali:\n\nI mandati statali non hanno avuto un effetto significativo sull’adozione del vaccino COVID-19.\nGli stati con mandati di vaccinazione COVID-19 hanno mostrato una minore adozione dei vaccini antinfluenzali e dei richiami del vaccino COVID-19 rispetto agli stati che avevano vietato tali mandati.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Collider bias</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/05_collider_bias.html#fitzgerald-2024",
    "href": "chapters/causal_inference/05_collider_bias.html#fitzgerald-2024",
    "title": "88  Collider bias",
    "section": "88.2 Fitzgerald (2024)",
    "text": "88.2 Fitzgerald (2024)\nFitzgerald (2024) critica la seconda conclusione dello studio di Rains e Richards, identificando un errore metodologico cruciale. Il problema principale risiede nell’inclusione del tasso di vaccinazione COVID-19 come variabile di controllo nei modelli statistici.\nQuesto approccio è problematico per tre ragioni:\n\nFattori comuni come l’esitazione vaccinale influenzano sia l’adozione del vaccino COVID-19 che altri vaccini, come quello antinfluenzale.\nI mandati possono influenzare sia l’adozione dei richiami COVID-19 che dei vaccini antinfluenzali.\nControllare i tassi di vaccinazione COVID-19 nei modelli può distorcere i risultati, introducendo un “bias del collider.”\n\n\n\n\n\n\n\nFigura 88.1: Grafo aciclico diretto che mostra le relazioni tra i mandati di vaccinazione COVID-19, i tassi di vaccinazione COVID-19, l’assunzione di vaccini booster/influenzali COVID-19 e fattori non osservati come l’esitazione nei confronti dei vaccini (Figura tratta da Fitzgerald (2024)).\n\n\n\nFitzgerald (2024) dimostra che, eliminando questa variabile di controllo errata dai modelli di Rains & Richards (2024), i risultati si invertono. Infatti, gli stati che hanno imposto i mandati di vaccinazione mostrano tassi più alti di adozione sia dei richiami COVID-19 che dei vaccini antinfluenzali.\n\n\n\n\n\n\nFigura 88.2: Tabella tratta da Fitzgerald (2024).",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Collider bias</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/05_collider_bias.html#analisi-statistica",
    "href": "chapters/causal_inference/05_collider_bias.html#analisi-statistica",
    "title": "88  Collider bias",
    "section": "88.3 Analisi statistica",
    "text": "88.3 Analisi statistica\nDi seguito è riportato il codice R utilizzato da Fitzgerald (2024) per replicare l’analisi, evidenziando la variazione nei coefficienti relativi alla variabile “Mandate State”. Quando il modello include il tasso di vaccinazione COVID-19 come controllo, i coefficienti risultano negativi. Tuttavia, rimuovendo questo controllo, i coefficienti cambiano di segno, diventando positivi, evidenziando l’impatto del collider bias sull’analisi originale.\nL’inversione del segno dei coefficienti sottolinea come l’inclusione di una variabile di controllo inappropriata possa portare a conclusioni fuorvianti sull’effetto dei mandati vaccinali sull’adozione dei vaccini. L’analisi di Fitzgerald (2024) dimostra l’importanza di considerare attentamente le relazioni causali tra le variabili in studi di epidemiologia e sanità pubblica. La scelta delle variabili di controllo è cruciale per evitare errori metodologici che possono compromettere la validità dei risultati.\n\nlibrary(kableExtra) \nlibrary(here)\nlibrary(lme4)  \nlibrary(lmerTest)  \nlibrary(performance)  \n\n\nbooster_analysis &lt;- read.csv(\n    here(\"data\", \"fitzgerald_2024\", \"booster_analysis.csv\")\n)\nflu_analysis_adult &lt;- read.csv(\n    here(\"data\", \"fitzgerald_2024\", \"flu_analysis_adult.csv\")\n)\nflu_analysis_children &lt;- read.csv(\n    here(\"data\", \"fitzgerald_2024\", \"flu_analysis_children.csv\")\n)\n\n\n# Create space for table data\ntable_data &lt;- as.data.frame(matrix(nrow = 13, ncol = 4))\ncolnames(table_data) &lt;- NULL\n\n# Input column information\ntable_data[1, ] &lt;- \nc(\"\", \"COVID-19 Booster Uptake\", \"Adult Flu Vaccine Uptake\", \"Child Flu Vaccine Uptake\")\n\n###############\n### PANEL A ###\n###############\n\n# Insert panel information\ntable_data[2, ] &lt;- c(\"\\\\textbf{Panel A: Bad Control Included}\", rep(\"\", 3))\n# Insert variables and model characteristics\ntable_data[3, 1] &lt;- \"Mandate State\"\ntable_data[4, 1] &lt;- \"\"\ntable_data[5, 1] &lt;- \"COVID-19\"\ntable_data[6, 1] &lt;- \"Vaccination Rate\"\ntable_data[7, 1] &lt;- \"$N$\"\ntable_data[8, 1] &lt;- \"Conditional/marginal $R^2$\"\n\n# COVID-19 booster uptake model\nmodel &lt;- lmer(\n    prop_boosted ~ mandate_type + prop_vacc_center + (1 | state_ab), \n    data = booster_analysis\n)\nr2 &lt;- r2(model)\nmodel &lt;- summary(model)\n# Insert estimates\ntable_data[3, 2] &lt;- round(model$coefficients[2, 1], 3)\ntable_data[4, 2] &lt;- paste0(\"(\", round(model$coefficients[2, 2], 3), \")\")\ntable_data[5, 2] &lt;- round(model$coefficients[3, 1], 3)\ntable_data[6, 2] &lt;- paste0(\"(\", round(model$coefficients[3, 2], 3), \")\")\ntable_data[7, 2] &lt;- length(model$residuals)\ntable_data[8, 2] &lt;- paste0(round(r2$R2_conditional, 3), \"/\", round(r2$R2_marginal, 3))\n\n# Adult flu vaccine uptake model\nmodel &lt;- lmer(\n    flu_vacc_est ~ mandate_type + cvd_vac_prop_cent + (1 | state_ab), \n    data = flu_analysis_adult\n)\nr2 &lt;- r2(model)\nmodel &lt;- summary(model)\n# Insert estimates\ntable_data[3, 3] &lt;- round(model$coefficients[2, 1], 3)\ntable_data[4, 3] &lt;- paste0(\"(\", round(model$coefficients[2, 2], 3), \")\")\ntable_data[5, 3] &lt;- round(model$coefficients[3, 1], 3)\ntable_data[6, 3] &lt;- paste0(\"(\", round(model$coefficients[3, 2], 3), \")\")\ntable_data[7, 3] &lt;- length(model$residuals)\ntable_data[8, 3] &lt;- paste0(round(r2$R2_conditional, 3), \"/\", round(r2$R2_marginal, 3))\n\n# Child flu vaccine uptake model\nmodel &lt;- lmer(\n    flu_vacc_est ~ mandate_type + cvd_vac_prop_cent + (1 | state_ab), \n    data = flu_analysis_children\n)\nr2 &lt;- r2(model)\nmodel &lt;- summary(model)\n# Insert estimates\ntable_data[3, 4] &lt;- round(model$coefficients[2, 1], 3)\ntable_data[4, 4] &lt;- paste0(\"(\", round(model$coefficients[2, 2], 3), \")\")\ntable_data[5, 4] &lt;- round(model$coefficients[3, 1], 3)\ntable_data[6, 4] &lt;- paste0(\"(\", round(model$coefficients[3, 2], 3), \")\")\ntable_data[7, 4] &lt;- length(model$residuals)\ntable_data[8, 4] &lt;- paste0(round(r2$R2_conditional, 3), \"/\", round(r2$R2_marginal, 3))\n\n###############\n### PANEL B ###\n###############\n\n# Insert panel information\ntable_data[9, ] &lt;- c(\"\\\\textbf{Panel B: Bad Control Removed}\", rep(\"\", 3))\n# Insert variables and model characteristics\ntable_data[10, 1] &lt;- \"Mandate State\"\ntable_data[11, 1] &lt;- \"\"\ntable_data[12, 1] &lt;- \"$N$\"\ntable_data[13, 1] &lt;- \"Conditional/marginal $R^2$\"\n\n# COVID-19 booster uptake model\nmodel &lt;- lmer(\n    prop_boosted ~ mandate_type + (1 | state_ab), \n    data = booster_analysis\n)\nr2 &lt;- r2(model)\nmodel &lt;- summary(model)\n# Insert estimates\ntable_data[10, 2] &lt;- round(model$coefficients[2, 1], 3)\ntable_data[11, 2] &lt;- paste0(\"(\", round(model$coefficients[2, 2], 3), \")\")\ntable_data[12, 2] &lt;- length(model$residuals)\ntable_data[13, 2] &lt;- paste0(round(r2$R2_conditional, 3), \"/\", round(r2$R2_marginal, 3))\n\n# Adult flu vaccine uptake model\nmodel &lt;- lmer(\n    flu_vacc_est ~ mandate_type + (1 | state_ab), \n    data = flu_analysis_adult\n)\nr2 &lt;- r2(model)\nmodel &lt;- summary(model)\n# Insert estimates\ntable_data[10, 3] &lt;- round(model$coefficients[2, 1], 3)\ntable_data[11, 3] &lt;- paste0(\"(\", round(model$coefficients[2, 2], 3), \")\")\ntable_data[12, 3] &lt;- length(model$residuals)\ntable_data[13, 3] &lt;- paste0(round(r2$R2_conditional, 3), \"/\", round(r2$R2_marginal, 3))\n\n# Child flu vaccine uptake model\nmodel &lt;- lmer(\n    flu_vacc_est ~ mandate_type + (1 | state_ab), \n    data = flu_analysis_children\n)\nr2 &lt;- r2(model)\nmodel &lt;- summary(model)\n# Insert estimates\ntable_data[10, 4] &lt;- round(model$coefficients[2, 1], 3)\ntable_data[11, 4] &lt;- paste0(\"(\", round(model$coefficients[2, 2], 3), \")\")\ntable_data[12, 4] &lt;- length(model$residuals)\ntable_data[13, 4] &lt;- paste0(round(r2$R2_conditional, 3), \"/\", round(r2$R2_marginal, 3))\n\n\n# Produce and save table\ntable &lt;- kbl(table_data,\n    format = \"pipe\",\n    align = c(\"l\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"),\n    caption = \"Table 1: Effects of Vaccine Mandates on Vaccine Uptake\"\n)\n\n\ntable\ncat(\"\\nNote: Standard errors are reported in parentheses.\")\n\n\n\nTable: Table 1: Effects of Vaccine Mandates on Vaccine Uptake\n\n|                                       |                         |                          |                          |\n|:--------------------------------------|:-----------------------:|:------------------------:|:------------------------:|\n|                                       | COVID-19 Booster Uptake | Adult Flu Vaccine Uptake | Child Flu Vaccine Uptake |\n|\\textbf{Panel A: Bad Control Included} |                         |                          |                          |\n|Mandate State                          |         -0.072          |          -0.119          |          -0.179          |\n|                                       |         (0.027)         |         (0.021)          |         (0.028)          |\n|COVID-19                               |          3.686          |          1.518           |          2.194           |\n|Vaccination Rate                       |         (0.056)         |          (0.07)          |         (0.029)          |\n|$N$                                    |          1025           |           205            |           1025           |\n|Conditional/marginal $R^2$             |       0.907/0.55        |       0.941/0.643        |        0.975/0.65        |\n|\\textbf{Panel B: Bad Control Removed}  |                         |                          |                          |\n|Mandate State                          |          0.045          |          0.058           |          0.079           |\n|                                       |         (0.021)         |         (0.016)          |         (0.022)          |\n|$N$                                    |          1025           |           205            |           1025           |\n|Conditional/marginal $R^2$             |       0.298/0.034       |       0.512/0.155        |       0.597/0.151        |\n\n\n\nNote: Standard errors are reported in parentheses.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Collider bias</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/05_collider_bias.html#considerazioni-conclusive",
    "href": "chapters/causal_inference/05_collider_bias.html#considerazioni-conclusive",
    "title": "88  Collider bias",
    "section": "88.4 Considerazioni Conclusive",
    "text": "88.4 Considerazioni Conclusive\nIl concetto chiave introdotto da Fitzgerald (2024) è il “bias del collider”. Un “collider” è una variabile influenzata da due o più altre variabili nel modello. Nel caso specifico:\n\nI tassi di vaccinazione COVID-19 sono il collider, poiché sono influenzati sia dai mandati vaccinali che da altri fattori, come l’esitazione vaccinale.\nControllando i tassi di vaccinazione COVID-19 come se fossero una variabile indipendente, si blocca il percorso causale tra i mandati vaccinali e altre variabili, come l’adozione dei richiami o dei vaccini antinfluenzali.\n\nQuesto porta a una stima distorta dell’effetto dei mandati sui comportamenti vaccinali successivi. Contrariamente alle conclusioni di Rains & Richards (2024), che suggerivano un effetto negativo dei mandati sull’adozione dei vaccini, l’analisi corretta di Fitzgerald (2024) ha rivelato un effetto positivo. Questo dimostra come il collider bias possa non solo alterare la magnitudine degli effetti stimati, ma addirittura invertirne la direzione.\nIn conclusione, il bias del collider è un errore comune nelle analisi statistiche che può condurre a risultati fuorvianti se non viene identificato e gestito correttamente. Nel caso specifico dei mandati vaccinali, controllare i tassi di vaccinazione COVID-19 come variabile di controllo blocca una parte della relazione causale tra mandati e comportamenti successivi, come l’adozione di richiami o di vaccini antinfluenzali. Questo errore metodologico può portare a conclusioni errate e fuorvianti. Lo stesso principio si applica a studi in altri ambiti, come la psicologia, dove il controllo di variabili che fungono da collider può mascherare relazioni causali importanti e portare a conclusioni errate. È essenziale, quindi, prestare molta attenzione alla scelta delle variabili di controllo per garantire la validità dei risultati negli studi osservazionali.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Collider bias</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/05_collider_bias.html#esercizi",
    "href": "chapters/causal_inference/05_collider_bias.html#esercizi",
    "title": "88  Collider bias",
    "section": "Esercizi",
    "text": "Esercizi\n\nEsercizio 88.1 Approfondire la comprensione del bias del collider attraverso l’implementazione pratica del codice R messo a disposizione da Cinelli et al. (2024). Esegui il codice passo dopo passo, cercando di comprendere lo scopo di ogni linea. Identifica i punti chiave dell’analisi che evidenziano il bias del collider. Modifica alcune parti del codice per osservare come cambiano i risultati. Prova a simulare diversi scenari per consolidare la tua comprensione del fenomeno.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Collider bias</span>"
    ]
  },
  {
    "objectID": "chapters/causal_inference/05_collider_bias.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/causal_inference/05_collider_bias.html#informazioni-sullambiente-di-sviluppo",
    "title": "88  Collider bias",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sat Jul 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnetworkx   : 3.3\npandas     : 2.2.2\nbambi      : 0.14.0\nseaborn    : 0.13.2\ngraphviz   : 0.20.3\nnumpy      : 1.26.4\narviz      : 0.18.0\nmatplotlib : 3.9.1\nstatsmodels: 0.14.2\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nCinelli, C., Forney, A., & Pearl, J. (2024). A crash course in good and bad controls. Sociological Methods & Research, 53(3), 1071–1104.\n\n\nFitzgerald, J. (2024). US states that mandated COVID-19 vaccination see higher, not lower, take-up of COVID-19 boosters and flu vaccines. Proceedings of the National Academy of Sciences, 121(41), e2403758121. https://doi.org/10.1073/pnas.2403758121\n\n\nRains, S. A., & Richards, A. S. (2024). US state vaccine mandates did not influence COVID-19 vaccination rates but reduced uptake of COVID-19 boosters and flu vaccines compared to bans on vaccine restrictions. Proceedings of the National Academy of Sciences, 121(8), e2313610121.",
    "crumbs": [
      "Causalità",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>Collider bias</span>"
    ]
  },
  {
    "objectID": "chapters/glm/introduction_glm.html",
    "href": "chapters/glm/introduction_glm.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione esploreremo i modelli statistici che vanno oltre la regressione lineare, ossia quelli che fanno ipotesi distributive non gaussiane per la componente stocastica del modello, considerano una relazione non lineare tra il valore atteso della variabile di risposta e i predittori, e indeboliscono l’assunzione di indipendenza tra le osservazioni.",
    "crumbs": [
      "GLM",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html",
    "href": "chapters/glm/01_robust_regr.html",
    "title": "89  Regressione robusta",
    "section": "",
    "text": "Introduzione\nNell’ambito della psicologia, la gestione efficace dei dati anomali è cruciale per garantire l’integrità e l’affidabilità delle inferenze statistiche. La regressione robusta bayesiana rappresenta un approccio metodologico avanzato, specificamente progettato per affrontare le sfide poste da distribuzioni dei dati caratterizzate da deviazioni significative dalla norma, comuni nei dataset psicologici. Questo capitolo si dedica all’esplorazione dettagliata della regressione robusta bayesiana, con un focus particolare sull’impiego della distribuzione Student-t come modello di errore per accrescere la tolleranza ai dati anomali e sul Pareto Smoothed Importance Sampling (PSIS) per individuare la presenza di dati anomali.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#introduzione-alla-gestione-degli-outlier-nelle-analisi-dati",
    "href": "chapters/glm/01_robust_regr.html#introduzione-alla-gestione-degli-outlier-nelle-analisi-dati",
    "title": "89  Regressione robusta",
    "section": "89.1 Introduzione alla Gestione degli Outlier nelle Analisi Dati",
    "text": "89.1 Introduzione alla Gestione degli Outlier nelle Analisi Dati\nLe osservazioni anomale, comunemente note come outlier, ovvero i valori che si situano ai margini della distribuzione complessiva dei dati, hanno un ruolo fondamentale nell’analisi statistica. La loro presenza, infatti, può seriamente compromettere l’integrità e la validità predittiva di un modello statistico, evidenziando una potenziale inadeguatezza del modello stesso nel rappresentare con precisione l’eterogeneità intrinseca dei dati. Questi valori estremi sono indicativi di limitazioni nel modello, suggerendo che esso potrebbe non essere configurato correttamente o che possa non essere in grado di catturare tutte le dinamiche sottostanti i dati. Pertanto, l’identificazione e l’analisi approfondita degli outlier sono essenziali per garantire che le inferenze e le previsioni generate da un modello statistico siano robuste e affidabili.\nIgnorare o rimuovere gli outlier senza un’accurata valutazione delle loro cause e caratteristiche può portare a interpretazioni errate dei dati. Tale pratica può essere paragonata a un tentativo di “correzione” dei dati piuttosto che a un miglioramento del modello, nascondendo di fatto i veri problemi anziché risolverli. Di conseguenza, la sfida principale consiste nel comprendere l’impatto degli outlier sul modello e nel trovare strategie per integrare queste informazioni anziché escluderle, considerandoli un elemento informativo cruciale nell’analisi complessiva.\nPer affrontare gli outlier in modo efficace, è essenziale adottare approcci statistici robusti. Questi possono includere la modifica della funzione di verosimiglianza per aumentare la tolleranza nei confronti di variazioni estreme dei dati, l’impiego di distribuzioni a priori che ammettano esplicitamente la presenza di deviazioni significative, o l’utilizzo di metodi specifici per identificare e analizzare gli outlier.\nIn sintesi, gli outlier non dovrebbero essere visti come un problema da evitare, ma piuttosto come un’occasione per affinare e perfezionare i modelli statistici. La rimozione degli outlier senza un’adeguata analisi può condurre a conclusioni fuorvianti e a previsioni poco affidabili. Al contrario, un esame dettagliato e l’integrazione consapevole degli outlier possono arricchire la nostra comprensione del fenomeno studiato, migliorando la precisione e l’affidabilità delle previsioni del modello.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#mistura-di-gaussiane",
    "href": "chapters/glm/01_robust_regr.html#mistura-di-gaussiane",
    "title": "89  Regressione robusta",
    "section": "89.2 Mistura di Gaussiane",
    "text": "89.2 Mistura di Gaussiane\nNel presente capitolo, esploreremo una metodologia avanzata per mitigare l’effetto degli outlier attraverso l’ottimizzazione della funzione di verosimiglianza, incrementando così la sua robustezza nei confronti di deviazioni estreme nei dati. Una tattica particolarmente efficace per raggiungere tale obiettivo implica l’utilizzo della distribuzione t di Student nella modellazione dei dati. In particolare, nel contesto dell’analisi di regressione, è stato evidenziato come gli outlier possano influenzare negativamente la retta di regressione, facendola deviare dalle zone di maggiore densità dei dati. Attraverso l’utilizzo della distribuzione t di Student, la quale presenta code più pesanti rispetto alla distribuzione Gaussiana (Normale), è possibile ridurre l’impatto distorsivo degli outlier sulla retta di regressione. Questo rappresenta un esempio classico di regressione robusta.\nLa distribuzione t di Student può essere compresa concettualmente come una composizione di diverse distribuzioni gaussiane, ognuna con la propria varianza specifica. Questa caratteristica conferisce alla distribuzione una maggiore flessibilità nel trattare dati con varianze estreme, rendendola particolarmente adatta per l’uso in modelli statistici che richiedono una notevole resistenza agli outlier. Utilizzare questa distribuzione facilita l’esecuzione di analisi più robuste e la generazione di previsioni più accurate, migliorando il livello di inferenza in situazioni dove sono presenti dati anomali.\n\n# Creazione dell'array di valori x\nxs = np.linspace(-6, 6, 100)\n\n# Inizializzazione dell'array per i PDF (Probability Density Function)\npdfs = []\n\n# Numero di gaussiane\nn_gaussians = 20\n\n# Ciclo per tracciare ogni gaussiana\nfor variance in np.linspace(.5, 5, n_gaussians):\n    label = \"Individual\\nGaussians\" if variance == .5 else None\n    pdf = stats.norm(0, variance).pdf(xs)\n    pdfs.append(pdf)\n    plt.plot(xs, pdf, color='k', label=label, alpha=.25)  # Usa matplotlib.pyplot.plot\n\n# Calcolo della somma dei PDFs\nsum_of_pdfs = np.array(pdfs).sum(axis=0)\nsum_of_pdfs /= sum_of_pdfs.max()\nsum_of_pdfs *= (1 - n_gaussians / 100)\n\n# Tracciare la somma dei PDFs\nplt.plot(xs, sum_of_pdfs, label='Mixture of\\nGaussian')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLa natura della distribuzione t di Student come mistura di Gaussiane porta con sé importanti conseguenze analitiche.\nLa caratteristica di essere una somma di distribuzioni gaussiane con varianze eterogenee si riflette nella presenza di code più pesanti rispetto a una distribuzione gaussiana singola. Ciò significa che la distribuzione t è in grado di gestire più efficacemente osservazioni estreme, rendendola una scelta preferenziale per dati che si discostano dalla normalità, soprattutto in presenza di outlier.\nIn numerosi ambiti si osserva frequentemente la presenza di dati provenienti da popolazioni con caratteristiche eterogenee, talvolta non immediatamente identificabili. Questa diversità può essere il risultato di una varietà di meccanismi sottostanti con varianze distinte. Essendo composta da diverse gaussiane, la distribuzione t di Student incorpora implicitamente l’eterogeneità non osservabile nei dati, che può derivare da diverse fonti con varianze distinte.\nUn’altra caratteristica distintiva della distribuzione t di Student è la sua ridotta sensibilità agli outlier rispetto alla distribuzione gaussiana. Grazie alle sue code più pesanti, la distribuzione t attribuisce una maggiore probabilità alle osservazioni estreme, riducendo l’effetto distorsivo degli outlier sull’analisi statistica.\n\n# Creazione dell'array di valori x\nxs = np.linspace(-4, 4, 100)\n\n# Configurazione delle dimensioni del grafico\nplt.subplots(figsize=(6, 3))\n\n# Tracciare la distribuzione normale (Gaussiana)\nplt.plot(xs, stats.norm.pdf(xs), label='Gaussian')\n\n# Tracciare la distribuzione Student-t\nplt.plot(xs, stats.t(2).pdf(xs), color='C2', label='Student-t')\n\nplt.legend()\nplt.show()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#un-esempio-concreto",
    "href": "chapters/glm/01_robust_regr.html#un-esempio-concreto",
    "title": "89  Regressione robusta",
    "section": "89.3 Un esempio concreto",
    "text": "89.3 Un esempio concreto\nPer illustrare la capacità della distribuzione t di Student di mitigare l’effetto degli outlier nell’analisi di regressione, in questo capitolo considereremo un set di dati simulati, così come illustrato nel tutorial fornito sul sito di Bambi.\n\nsize = 100\ntrue_intercept = 1\ntrue_slope = 2\n\nx = np.linspace(0, 1, size)\n# y = a + b*x\ntrue_regression_line = true_intercept + true_slope * x\n# add noise\ny = true_regression_line + np.random.normal(scale=0.5, size=size)\n\n# Add outliers\nx_out = np.append(x, [0.01, 0.1, 0.15])\ny_out = np.append(y, [12, 11, 13])\n\ndata = pd.DataFrame({\n    \"x\": x_out,\n    \"y\": y_out\n})\n\nSi noti che sono stati introdotti 3 valori anomali nel dataset, nonostante il vero meccanismo generativo dei dati implichi che la pendenza della retta di regressione sia pari a 2.\n\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot(111, xlabel=\"x\", ylabel=\"y\", title=\"Generated data and underlying model\")\nax.plot(x_out, y_out, \"x\", label=\"sampled data\")\nax.plot(x, true_regression_line, label=\"true regression line\", lw=2.0)\nplt.legend(loc=0);\n\n\n\n\n\n\n\n\nQueste anomalie possono essere soggette ad un’analisi rigorosa mediante l’applicazione di metodi statistici avanzati. Un approccio per valutare l’impatto di tali outlier sull’analisi è l’utilizzo della statistica PSIS \\(k\\), una tecnica che permette di quantificare l’influenza delle osservazioni estreme su una distribuzione.\nImplementiamo un modello di regressione lineare per analizzare la relazione tra y (variabile dipendente) e x. In questa analisi iniziale, l’ipotesi sottostante è che gli errori (o residui), seguano una distribuzione normale (gaussiana).\n\ngauss_model = bmb.Model(\"y ~ x\", data, family=\"gaussian\")\n\n\ngauss_model.build()\ngauss_model.graph()\n\n\n\n\n\n\n\n\nAdattiamo il modello ai dati. Si noti che l’argomento idata_kwargs={\"log_likelihood\": True} passato alla funzione fit è usato per specificare le opzioni per la creazione dell’oggetto InferenceData che sarà restituito. In questo caso, stiamo indicando che vogliamo che il logaritmo della verosimiglianza sia incluso nell’oggetto InferenceData. Il logaritmo della verosimiglianza può essere utilizzato per ulteriori analisi e diagnostica, come il calcolo del LOO (Leave-One-Out Cross-Validation).\n\ngauss_fitted = gauss_model.fit(\n    nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\nEsaminiamo visivamente i risultati dell’analisi.\n\nax = bmb.interpret.plot_predictions(gauss_model, gauss_fitted, [\"x\"])\nplt.scatter(data['x'], data['y'], color='gray', alpha=0.5, label='Dati Grezzi')\nplt.show()\n\nDefault computed for conditional variable: x\n\n\n\n\n\n\n\n\n\nIpotizzando una distribuzione normale degli errori, l’analisi produce una stima fortemente distorta della pendenza della retta di regressione.\n\n_ = az.plot_trace(gauss_fitted)\n\n\n\n\n\n\n\n\n\naz.summary(gauss_fitted, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n2.20\n0.34\n1.55\n2.82\n0.01\n0.00\n4349.92\n2742.88\n1.0\n\n\nsigma\n1.85\n0.13\n1.61\n2.09\n0.00\n0.00\n3745.05\n3016.41\n1.0\n\n\nx\n0.21\n0.61\n-0.88\n1.37\n0.01\n0.01\n4300.46\n2852.23\n1.0\n\n\n\n\n\n\n\n\nposterior_predictive = gauss_model.predict(gauss_fitted, kind=\"pps\")\nax = az.plot_ppc(gauss_fitted, num_pp_samples=100)\n_ = ax.set_xlabel(\"x\")\n\n\n\n\n\n\n\n\nIn un secondo modello assumiamo che gli errori seguano una distribuzione t di Student.\n\nt_model = bmb.Model(\"y ~ x\", data, family=\"t\")\n\n\nt_model.build()\nt_model.graph()\n\n\n\n\n\n\n\n\n\nt_fitted = t_model.fit(\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\n\nax = bmb.interpret.plot_predictions(t_model, t_fitted, [\"x\"])\n_ = plt.scatter(data['x'], data['y'], color='gray', alpha=0.5, label='Dati Grezzi')\n\nDefault computed for conditional variable: x\n\n\n\n\n\n\n\n\n\nSi noti che, in questo caso, la presenza degli outlier non ha distorto in alcun modo la stima della pendenza della retta di regressione. Nella regressione lineare gaussiana classica, i valori anomali hanno l’effetto di “spingere” la distribuzione a posteriori di \\(\\beta\\) verso lo zero. Invece, il modello student-t è più robusto e meno influenzato dai valori anomali.\n\naz.summary(t_fitted, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n1.19\n0.11\n0.99\n1.40\n0.00\n0.00\n3551.59\n2916.33\n1.0\n\n\nnu\n2.14\n0.46\n1.35\n3.03\n0.01\n0.01\n3267.18\n3114.44\n1.0\n\n\nsigma\n0.41\n0.05\n0.32\n0.50\n0.00\n0.00\n3212.53\n3022.28\n1.0\n\n\nx\n1.58\n0.18\n1.23\n1.92\n0.00\n0.00\n3818.50\n2914.77\n1.0\n\n\n\n\n\n\n\n\nposterior_predictive = t_model.predict(t_fitted, kind=\"pps\")\nax = az.plot_ppc(t_fitted, num_pp_samples=100)\nplt.xlim(-2, 5)\n_ = ax.set_xlabel(\"x\")\n\n\n\n\n\n\n\n\nNella figura successiva, esaminiamo la stima a posteriori della pendenza della retta di regressione per entrambi i modelli.\n\naz.plot_dist(t_fitted.posterior[\"x\"], color=\"C1\", label=\"Student-t Model\")\naz.plot_dist(gauss_fitted.posterior[\"x\"], label=\"Gaussian Model\");\n\n\n\n\n\n\n\n\nSi noti che, in presenza di outlier, l’impiego della distribuzione t di Student ha portato a un adattamento del modello più accurato, come evidenziato dai valori diagnostici Pareto \\(k\\).\n\naz.loo(gauss_fitted)\n\nComputed from 4000 posterior samples and 103 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -218.24    29.86\np_loo       15.13        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100   97.1%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         1    1.0%\n   (1, Inf)   (very bad)    2    1.9%\n\n\n\naz.loo(t_fitted)\n\nComputed from 4000 posterior samples and 103 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -112.62    16.34\np_loo        5.44        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      103  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#waic-e-psis",
    "href": "chapters/glm/01_robust_regr.html#waic-e-psis",
    "title": "89  Regressione robusta",
    "section": "89.4 WAIC e PSIS",
    "text": "89.4 WAIC e PSIS\nNella sezione seguente, approfondiremo il legame tra i valori diagnostici di Pareto \\(k\\) e il Watanabe-Akaike Information Criterion (WAIC), una metrica essenziale per valutare la qualità di un modello statistico. A differenza del più tradizionale criterio di informazione di Akaike (AIC), impiegato nei contesti frequentisti, il WAIC estende il concetto di valutazione della qualità di un modello incorporando sia la sua capacità di adattamento ai dati sia la sua complessità intrinseca. Lo scopo è prevenire l’eccesso di adattamento (overfitting), dove il modello è troppo specifico ai dati di addestramento, e l’insufficiente adattamento (underfitting), dove il modello è troppo semplice per catturare la struttura sottostante dei dati. In termini più accessibili, il WAIC stima l’efficacia con cui un modello può prevedere dati non ancora osservati, basandosi sulla log-verosimiglianza dei dati e correggendo per la dimensione effettiva del modello. Un valore WAIC inferiore segnala una maggiore capacità previsionale del modello.\nPer calcolare il WAIC, si fa spesso ricorso all’importance sampling, una tecnica per approssimare proprietà di una distribuzione di probabilità campionando da una distribuzione alternativa. Il PSIS (Pareto Smoothed Importance Sampling), che migliora questo metodo, e i valori diagnostici di Pareto \\(k\\) giocano un ruolo cruciale nell’evaluazione della qualità dell’approximation impiegata per il calcolo del WAIC. Il valore di Pareto \\(k\\) funge da termometro dell’efficacia dell’importance sampling per un determinato modello e insieme di dati. Valori elevati di Pareto \\(k\\) (solitamente oltre 0.7) segnalano potenziali inaffidabilità nell’approssimazione, il che può tradursi in stime del WAIC distorte. Questo fenomeno suggerisce che il modello potrebbe non essere adeguatamente equipaggiato per prevedere specifiche osservazioni nei dati, spesso a causa della presenza di dati anomali o di una scarsa adattabilità del modello.\nStabilire un collegamento tra WAIC e i valori di Pareto \\(k\\) è fondamentale, poiché offre una panoramica più dettagliata e affidabile della performance di un modello. Se da un lato il WAIC valuta l’adattabilità generale del modello ai dati e la sua gestione della complessità, dall’altro, il valore di Pareto \\(k\\) fornisce insight preziosi sull’affidabilità dell’approssimazione usata per il suo calcolo. Insieme, queste metriche consentono una valutazione più completa della qualità di un modello.\nQuando il calcolo del WAIC viene eseguito in modo puntiforme (pointwise=True), significa che la valutazione è condotta separatamente per ciascuna osservazione all’interno del dataset. Questa modalità di calcolo permette di identificare come ogni dato contribuisca al valore globale del WAIC, facilitando l’individuazione di potenziali dati anomali o punti critici per il modello, diversamente da un calcolo aggregato che fornirebbe un unico valore di WAIC per tutto il modello. Questa analisi dettagliata è particolarmente utile per affinare la comprensione della performance modello e per guidare eventuali miglioramenti.\n\ndef plot_loocv(inference, title=None, outliers_idx=[], divorce=None):\n    plt.subplots(figsize=(6, 3))\n    pareto_k = az.loo(inference, pointwise=True).pareto_k\n    waic = -az.waic(inference, pointwise=True).waic_i\n\n    plt.scatter(pareto_k, waic, color='C0', label=None)\n\n    # Assicurati che outliers_idx e divorce siano definiti\n    for oi in outliers_idx:\n        if divorce is not None and oi in divorce.index:\n            plt.annotate(divorce.loc[oi, \"Location\"], (pareto_k[oi] + .01, waic[oi]), fontsize=14)\n\n    plt.xlabel(\"PSIS Pareto K\")\n    plt.ylabel(\"WAIC\")\n    plt.title(title)\n    plt.show()\n\nCreiamo un grafico che mostra i valori di WAIC in funzione dei valori Pareto \\(k\\). Con questa rappresentazione possiamo esaminare come ogni osservazione influisca sulla performance del modello e sulla sua affidabilità. Se un punto ha un alto valore di Pareto \\(k\\) e un elevato impatto negativo sul WAIC (indicato da un alto valore negativo di WAIC), potrebbe essere un candidato per un’ulteriore revisione o esclusione dal modello.\n\nplot_loocv(gauss_fitted, title=\"Gaussian Likelihood Posterior\\nAffected by Outliers\")\n\n\n\n\n\n\n\n\n\nplot_loocv(t_fitted, title=\"Student Likelihood Posterior\\nAffected by Outliers\")\n\n\n\n\n\n\n\n\nÈ evidente che, per i dati in esame, quando si utilizza un modello di regressione lineare che assume una distribuzione degli errori t di Student, sia il WAIC che i valori diagnostici Pareto \\(k\\) risultano essere inferiori. Questa riduzione indica una maggiore efficienza del modello nella previsione dei dati.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#confronto-tra-modelli",
    "href": "chapters/glm/01_robust_regr.html#confronto-tra-modelli",
    "title": "89  Regressione robusta",
    "section": "89.5 Confronto tra Modelli",
    "text": "89.5 Confronto tra Modelli\nEseguiamo ora un’analisi di validazione incrociata Leave-One-Out (LOO) per confrontare i due modelli statistici, il modello gaussiano e il modello basato sulla distribuzione t di Student. L’analisi di validazione incrociata Leave-One-Out (LOO) è una tecnica di valutazione dei modelli statistici che consente di confrontare le loro prestazioni in termini di capacità previsionale. Questo metodo è particolarmente utile per determinare quale modello possa generalizzare meglio a nuovi dati, non inclusi nel set di addestramento.\nL’analisi di validazione incrociata Leave-One-Out (LOO) è una tecnica di valutazione dei modelli statistici che consente di confrontare le loro prestazioni in termini di capacità previsionale. Questo metodo è particolarmente utile per determinare quale modello possa generalizzare meglio a nuovi dati, non inclusi nel set di addestramento. Ecco una spiegazione dettagliata del processo e di come viene applicato per confrontare un modello gaussiano con un modello basato sulla distribuzione t di Student.\nNello specifico, la validazione incrociata LOO è un caso particolare di validazione incrociata k-fold, dove \\(k\\) è uguale al numero di osservazioni nel dataset. In pratica, questo significa che per un dataset di \\(n\\) osservazioni, il modello viene addestrato \\(n\\) volte, ogni volta usando \\(n-1\\) osservazioni come dati di addestramento e la singola osservazione restante come dato di test. Questo processo viene ripetuto per ogni osservazione nel dataset, permettendo così di valutare la performance del modello su ogni punto dati una volta.\nUtilizzando az.compare, è possibile confrontare i due modelli sulla base della loro performance previsionale, quantificata attraverso metriche specifiche derivate dalla validazione incrociata LOO. Queste metriche aiutano a determinare quale modello ha una migliore capacità di generalizzazione, prendendo in considerazione sia la qualità dell’adattamento ai dati che la complessità del modello.\n\ndf_comp_loo = az.compare({\"Gaussian Model\": gauss_fitted, \"Student t Model\": t_fitted})\ndf_comp_loo\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nStudent t Model\n0\n-112.621991\n5.443246\n0.000000\n1.0\n16.341621\n0.00000\nFalse\nlog\n\n\nGaussian Model\n1\n-218.239844\n15.126661\n105.617853\n0.0\n29.860645\n16.48181\nTrue\nlog\n\n\n\n\n\n\n\n\naz.plot_compare(df_comp_loo, insample_dev=False);\n\n\n\n\n\n\n\n\nCome abbiamo visto in precedenza, la ELPD (Expected Log Predictive Density) è una misura della performance predittiva di un modello statistico. Rappresenta il logaritmo della densità predittiva media attesa, calcolata attraverso la validazione incrociata LOO. Un valore più alto di ELPD indica una migliore capacità del modello di adattarsi ai dati e di fare previsioni accurate su nuovi dati non visti.\n\nrank: Posizione del modello basata sull’elpd_loo.\nelpd_loo: Stima dell’Expected Log Pointwise Predictive Density per LOO-CV. Valori più alti indicano migliori capacità predittive.\np_loo: Stima della complessità effettiva del modello, che riflette il numero di parametri “effettivi”.\nelpd_diff: Differenza di elpd_loo tra il modello corrente e il miglior modello. Per il miglior modello, questo valore è 0.\nweight: Peso basato sull’elpd_loo, indicando l’importanza relativa del modello nel contesto di un ensemble di modelli.\nse (Standard Error): Errore standard dell’elpd_loo.\ndse (Differenza di Standard Error): Errore standard della differenza di elpd_loo tra due modelli.\nwarning: Se vero, indica potenziali problemi con la stima elpd_loo per il modello.\nscale: La scala utilizzata per misurare l’elpd_loo; in questo caso, “log”.\n\nIl modello Student t ha un elpd_loo di -102.284333, il che lo rende il modello con le migliori capacità predittive tra i due, poiché ha il valore elpd_loo più alto (meno negativo). Questo modello ha anche un p_loo di 5.894299, indicando una complessità inferiore rispetto al Gaussian Model. Non ci sono avvertimenti, il che suggerisce che la stima elpd_loo è considerata affidabile. Ha ricevuto un peso di 1.000000, indicando che è il modello preferito per le previsioni.\nIl modello gaussiano mostra un elpd_loo di -219.324176 con una differenza di elpd_loo (elpd_diff) di 117.039843 rispetto al miglior modello. Questo indica che ha prestazioni significativamente peggiori in termini di adattamento predittivo rispetto allo Student t Model. Il suo p_loo più alto di 15.391340 riflette una maggiore complessità del modello, che non sembra tradursi in migliori capacità predittive in questo contesto. Il modello presenta anche un avvertimento, il che potrebbe indicare problemi con la stima LOO, suggerendo cautela nell’interpretazione dei suoi risultati.\nBasandosi sull’output fornito, il modello Student t è considerato il modello migliore tra i due per questi dati, dato il suo elpd_loo più alto (meno negativo), la minore complessità (p_loo inferiore), e l’assenza di avvertimenti. Il Gaussian Model, nonostante una maggiore complessità, mostra prestazioni inferiori e problemi potenziali (come indicato dall’avvertimento), rendendolo meno preferibile per la predizione su questo set di dati.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#commenti-e-considerazioni-conclusive",
    "href": "chapters/glm/01_robust_regr.html#commenti-e-considerazioni-conclusive",
    "title": "89  Regressione robusta",
    "section": "89.6 Commenti e considerazioni conclusive",
    "text": "89.6 Commenti e considerazioni conclusive\nNella pratica statistica, si incontrano spesso situazioni in cui l’eterogeneità non osservata - variazioni o differenze tra osservazioni in un insieme di dati che non sono spiegabili attraverso le variabili misurabili nel contesto dello studio - svolge un ruolo significativo. Questa eterogeneità si manifesta quando le differenze osservate tra i dati non possono essere attribuite completamente alle variabili note e misurabili. Al contrario, esistono fattori ignoti o non misurati che influenzano le osservazioni, che possono essere intrinseci alle unità di osservazione o dipendere da condizioni ambientali o contestuali non contemplate durante la progettazione dello studio o la raccolta dei dati.\nPer modellare questa eterogeneità, spesso si utilizzano miscele di distribuzioni gaussiane o Student-t. La scelta della distribuzione Student-t in particolare implica un modello che è meno sensibile agli effetti dei valori estremi, o “outliers”, grazie alle sue code più pesanti. Tuttavia, una sfida nella modellazione statistica risiede nel corretto posizionamento dei parametri dei gradi di libertà della distribuzione Student-t, specialmente perché gli outliers sono eventi rari e quindi difficili da stimare accuratamente.\nIn assenza di una teoria solida per guidare la scelta del modello statistico, la regressione robusta, basata su una distribuzione Student-t, emerge come una strategia prudente. Questo approccio si contrappone alla metodologia gaussiana standard, che può risultare inadeguata nel gestire gli effetti dei valori estremi e dell’eterogeneità non osservata.\nÈ fondamentale, inoltre, valutare accuratamente la bontà di adattamento del modello ai dati. Strumenti come il Pareto Smoothed Importance Sampling (PSIS) e i valori diagnostici Pareto $ k $ si rivelano preziosi in questo contesto. Il PSIS utilizza la stima di $ k $ per perfezionare l’adattamento del modello, mentre i valori di $ k $ funzionano come indicatori diagnostici per valutare la qualità dell’importance sampling e l’adeguatezza del modello stesso. Questi metodi aiutano a sviluppare modelli più robusti e precisi, specialmente quando si trattano dati complessi con caratteristiche quali outliers e eterogeneità non osservata.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/01_robust_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/01_robust_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "89  Regressione robusta",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\npandas    : 2.2.2\nscipy     : 1.14.0\narviz     : 0.18.0\nnumpy     : 1.26.4\nbambi     : 0.14.0\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>Regressione robusta</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html",
    "href": "chapters/glm/02_stan_binomial_regr.html",
    "title": "90  Modelli lineari generalizzati",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esploreremo i Modelli Lineari Generalizzati (GLM) e, in particolare, il modello di regressione binomiale, che è un’applicazione specifica dei GLM. Discuteremo anche come affrontare questo tipo di modelli utilizzando un approccio bayesiano e illustreremo come implementare la regressione binomiale con Stan.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Modelli lineari generalizzati</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#probabilità-odds-e-logit",
    "href": "chapters/glm/02_stan_binomial_regr.html#probabilità-odds-e-logit",
    "title": "90  Modelli lineari generalizzati",
    "section": "90.1 Probabilità, Odds e Logit",
    "text": "90.1 Probabilità, Odds e Logit\nNel contesto dei GLM, è essenziale comprendere le relazioni tra probabilità, odds e logit. La probabilità \\(P\\) rappresenta la possibilità di successo di un evento ed è un valore compreso tra 0 e 1. Gli odds (o rapporti di possibilità) rappresentano il rapporto tra la probabilità di successo e quella di insuccesso, calcolato come \\(O = \\frac{P}{1 - P}\\). Il logit è il logaritmo naturale degli odds, dato dalla formula \\(L = \\ln(O) = \\ln\\left(\\frac{P}{1 - P}\\right)\\).\nQueste trasformazioni sono fondamentali nei GLM perché consentono di trattare probabilità che, per definizione, sono limitate all’intervallo (0, 1) trasformandole in un intervallo che può coprire tutti i numeri reali. Ad esempio, quando la probabilità \\(P = 0.5\\), gli odds sono 1 e il logit è 0. Logit negativi indicano probabilità inferiori a 0.5, mentre logit positivi indicano probabilità superiori a 0.5.\n\n\n\n\n\n\n\n\nProbabilità (P)\nOdds (O)\nLogit (L)\n\n\n\n\n0.01\n\\(\\frac{0.01}{0.99}\\) = 0.0101\n\\(\\ln\\left(\\frac{0.01}{0.99}\\right)\\) = -4.60\n\n\n0.05\n\\(\\frac{0.05}{0.95}\\) = 0.0526\n\\(\\ln\\left(\\frac{0.05}{0.95}\\right)\\) = -2.94\n\n\n0.10\n\\(\\frac{0.10}{0.90}\\) = 0.1111\n\\(\\ln\\left(\\frac{0.10}{0.90}\\right)\\) = -2.20\n\n\n0.30\n\\(\\frac{0.30}{0.70}\\) = 0.4286\n\\(\\ln\\left(\\frac{0.30}{0.70}\\right)\\) = -0.85\n\n\n0.50\n\\(\\frac{0.50}{0.50}\\) = 1\n\\(\\ln\\left(\\frac{0.50}{0.50}\\right)\\) = 0.00\n\n\n0.70\n\\(\\frac{0.70}{0.30}\\) = 2.3333\n\\(\\ln\\left(\\frac{0.70}{0.30}\\right)\\) = 0.85\n\n\n0.90\n\\(\\frac{0.90}{0.10}\\) = 9\n\\(\\ln\\left(\\frac{0.90}{0.10}\\right)\\) = 2.20\n\n\n0.95\n\\(\\frac{0.95}{0.05}\\) = 19\n\\(\\ln\\left(\\frac{0.95}{0.05}\\right)\\) = 2.94\n\n\n0.99\n\\(\\frac{0.99}{0.01}\\) = 99\n\\(\\ln\\left(\\frac{0.99}{0.01}\\right)\\) = 4.60\n\n\n\n\n90.1.1 Trasformazione Inversa del Logit\nLa trasformazione inversa del logit, nota anche come antilogit, consente di riconvertire un logit in una probabilità. Questa funzione è definita come:\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}},\n\\]\ndove \\(\\eta_i\\) è il predittore lineare. Questa trasformazione garantisce che la stima risultante, \\(\\pi_i\\), sia sempre compresa tra 0 e 1, rendendola interpretabile come una probabilità. Questo è particolarmente utile nei modelli come la regressione binomiale, dove si cerca di modellare la probabilità di successo di un evento binario.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Modelli lineari generalizzati</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#modelli-lineari-generalizzati",
    "href": "chapters/glm/02_stan_binomial_regr.html#modelli-lineari-generalizzati",
    "title": "90  Modelli lineari generalizzati",
    "section": "90.2 Modelli Lineari Generalizzati",
    "text": "90.2 Modelli Lineari Generalizzati\nI Modelli Lineari Generalizzati (GLM) estendono la regressione lineare per affrontare situazioni in cui la variabile dipendente non segue una distribuzione normale e non esiste una relazione lineare tra le variabili indipendenti e dipendenti. Questa flessibilità consente di modellare diversi tipi di dati, come conteggi, proporzioni o dati categoriali.\nUn GLM si compone di tre elementi principali:\n\nComponente Aleatoria: descrive la distribuzione della variabile risposta \\(Y\\), che può provenire da una qualsiasi distribuzione della famiglia esponenziale. Ad esempio, se \\(Y\\) rappresenta un conteggio, si potrebbe usare una distribuzione di Poisson.\nComponente Sistematica: rappresenta il predittore lineare \\(\\eta\\), una combinazione delle variabili indipendenti \\(X\\), espressa come \\(\\eta = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_k X_k\\), dove \\(\\beta\\) sono i parametri del modello.\nFunzione di Legame: stabilisce la relazione tra la media attesa della variabile risposta \\(\\mu = E(Y)\\) e il predittore lineare \\(\\eta\\). Questa funzione di legame, \\(g(\\mu) = \\eta\\), permette di adattare il modello alla natura specifica dei dati. Ad esempio, nella regressione logistica, la funzione di legame è il logit, che trasforma la probabilità di successo \\(p\\) in un valore lineare:\n\n\\[\ng(p) = \\ln\\left(\\frac{p}{1-p}\\right).\n\\]\n\n90.2.1 Modello Normale\nIl modello osservativo in questo caso segue una distribuzione normale con parametri media \\(\\mu\\) e varianza del rumore \\(\\sigma^2\\):\n\\[\np(y|\\mu, \\sigma) = \\mathcal{N}(y|\\mu, \\sigma^2),\\\n\\mu = \\eta.\n\\]\nIn questo modello, la funzione di legame canonica è la funzione identità. Un esempio di questo modello è stato visto nella sezione sul “flusso di lavoro bayesiano”, dove si calcolava \\(\\mu = b_0 + b_1 * \\text{peso}\\).\n\n\n90.2.2 Modello di Poisson\nIn questo caso, le osservazioni sono valori interi non negativi, che si suppone seguano una distribuzione di Poisson con parametro di media \\(\\lambda\\):\n\\[\np(y|\\lambda) = \\text{Pois}(y|\\lambda),\\\n\\log(\\lambda) = \\eta.\n\\]\nIn questo modello, la funzione di legame è la funzione logaritmica, che consente di trasformare il predittore lineare \\(\\eta\\), definito nello spazio reale continuo, nel parametro \\(\\lambda\\) della distribuzione di Poisson, garantendo che \\(\\lambda\\) sia sempre positivo (o zero):\n\\[\n\\lambda = \\exp(\\eta).\n\\]\n\n\n90.2.3 Modello Binomiale\nLe osservazioni in questo modello sono binarie, cioè \\(y \\in \\{0, 1\\}\\). Queste osservazioni si suppone seguano una distribuzione binomiale con parametro di probabilità \\(p\\):\n\\[\np(y|\\eta) = \\text{Binom}(p),\\\n\\text{logit}(p) = \\eta.\n\\]\nIn questo caso, la probabilità \\(p\\) è collegata al predittore lineare \\(\\eta\\) tramite la trasformazione logistica \\(\\text{logit}(·)\\), che converte i valori del predittore lineare (solitamente definiti nello spazio reale continuo) in valori di probabilità compresi nell’intervallo \\([0, 1]\\). In alternativa, è possibile usare anche la funzione di legame ‘probit’ per ottenere lo stesso effetto.\n\n\n90.2.4 Modello Categoriale\nIl modello categoriale, noto anche come “multinomiale”, viene utilizzato nei problemi di classificazione multi-classe, dove le osservazioni possono assumere valori appartenenti a più classi \\(y \\in \\{1, . . . , J\\}\\). In questo caso, il modello osservativo segue una distribuzione multinomiale:\n\\[\np(y | p) = \\text{Categorical}(p),\\\np = \\text{softmax}(\\eta),\n\\]\ndove \\(p = (p_1, \\dots, p_J)\\) è un vettore di probabilità associate a ciascuna classe. La somma delle probabilità per tutte le classi deve essere uguale a 1, ovvero \\(\\sum_{j=1}^J p_j = 1\\).\nLa probabilità di appartenere a una classe \\(j\\) viene calcolata tramite la trasformazione ‘softmax’:\n\\[\np_j = \\frac{\\exp(\\eta_j)}{\\sum_{k=1}^J \\exp(\\eta_k)}.\n\\]\nIn questo modo, si ottiene una rappresentazione probabilistica per ogni classe, garantendo che le probabilità siano sempre non negative e sommino a 1.\n\n\n90.2.5 Approccio Bayesiano\nIn un contesto bayesiano, i parametri del modello, come \\(\\mu\\) e \\(\\phi\\), sono associati a distribuzioni a priori. Quando si modella \\(\\mu\\) attraverso un predittore lineare, si specificano le distribuzioni a priori sui parametri \\(\\beta\\) che definiscono tale predittore. Questo approccio consente di integrare informazioni a priori e aggiornare le stime sulla base dei dati osservati, migliorando la robustezza del modello e la sua interpretazione.\nIn sintesi, i GLM offrono un potente strumento per modellare dati complessi, fornendo flessibilità nella scelta delle distribuzioni e nelle relazioni tra variabili, e consentono di affrontare problemi in numerosi contesti applicativi.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Modelli lineari generalizzati</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#un-esempio-concreto",
    "href": "chapters/glm/02_stan_binomial_regr.html#un-esempio-concreto",
    "title": "90  Modelli lineari generalizzati",
    "section": "90.3 Un esempio concreto",
    "text": "90.3 Un esempio concreto\nSeguiamo il tutorial fornito sul sito ufficiale di PyMC e generiamo dei dati sintetici dove \\(y\\) indica il numero di successi in \\(n = 20\\) prove e \\(x\\) è un predittore.\n\n# true params\nbeta0_true = 0.7\nbeta1_true = 0.4\n# number of yes/no questions\nn = 20\n\nsample_size = 30\nx = np.linspace(-10, 20, sample_size)\n# Linear model\nmu_true = beta0_true + beta1_true * x\n# transformation (inverse logit function = expit)\np_true = expit(mu_true)\n# Generate data\ny = rng.binomial(n, p_true)\n# bundle data into dataframe\ndata = pd.DataFrame({\"x\": x, \"y\": y})\ndisplay(data)\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-10.000000\n1\n\n\n1\n-8.965517\n0\n\n\n2\n-7.931034\n1\n\n\n3\n-6.896552\n2\n\n\n4\n-5.862069\n6\n\n\n5\n-4.827586\n7\n\n\n6\n-3.793103\n4\n\n\n7\n-2.758621\n14\n\n\n8\n-1.724138\n14\n\n\n9\n-0.689655\n9\n\n\n10\n0.344828\n12\n\n\n11\n1.379310\n11\n\n\n12\n2.413793\n17\n\n\n13\n3.448276\n19\n\n\n14\n4.482759\n20\n\n\n15\n5.517241\n20\n\n\n16\n6.551724\n18\n\n\n17\n7.586207\n20\n\n\n18\n8.620690\n20\n\n\n19\n9.655172\n20\n\n\n20\n10.689655\n20\n\n\n21\n11.724138\n19\n\n\n22\n12.758621\n20\n\n\n23\n13.793103\n20\n\n\n24\n14.827586\n20\n\n\n25\n15.862069\n20\n\n\n26\n16.896552\n20\n\n\n27\n17.931034\n20\n\n\n28\n18.965517\n20\n\n\n29\n20.000000\n20\n\n\n\n\n\n\n\nPer questi dati, il modello di regressione binomiale può essere descritto come segue:\n\nModello lineare: \\[\n\\eta_i = \\beta_0 + \\beta_1 x_i\n\\]\nProbabilità di successo: \\[\np_i = \\text{logit}^{-1}(\\eta_i) = \\frac{1}{1 + \\exp(-\\eta_i)}\n\\]\nLikelihood: \\[\ny_i \\mid p_i \\sim \\text{Binomiale}(n, p_i)\n\\]\nPriori: \\[\n\\beta_0 \\sim \\mathcal{N}(0, 1)\n\\] \\[\n\\beta_1 \\sim \\mathcal{N}(0, 1)\n\\]\n\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"binomial_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; sample_size;  // Numero totale di osservazioni\n  vector[sample_size] x;     // Variabile indipendente\n  array[sample_size] int&lt;lower=0&gt; y;  // Successi per ogni tentativo\n  int&lt;lower=0&gt; n;           // Numero di tentativi per osservazione\n}\nparameters {\n  real beta0;  // Intercetta\n  real beta1;  // Pendenza\n}\ntransformed parameters {\n  vector[sample_size] eta = beta0 + beta1 * x;  // Modello lineare\n  vector[sample_size] p = inv_logit(eta);       // Probabilità di successo\n}\nmodel {\n  // Priori\n  beta0 ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n\n  // Likelihood\n  y ~ binomial(n, p);\n}\n\n\n\nCreiamo un dizionario nel formato richiesto per l’input a CmdStan:\n\nstan_data = {\n    \"sample_size\": data.shape[0],\n    \"x\": data[\"x\"],\n    \"y\": data[\"y\"],\n    \"n\": 20\n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\nPer visualizzare e descrivere la distribuzione a posteriori dei parametri è possibile utilizzare ArviZ dopo aver fittato il modello con cmdstanpy. ArviZ utilizza un formato di dati chiamato InferenceData, che è un formato ad alto livello per la memorizzazione di risultati statistici. cmdstanpy restituisce un oggetto CmdStanMCMC, che può essere convertito in InferenceData utilizzando la funzione az.from_cmdstanpy.\n\nidata = az.from_cmdstanpy(fit)\n\nOtteniamo un riassunto delle statistiche posteriori:\n\nsummary = az.summary(fit, var_names=([\"beta0\", \"beta1\"]), hdi_prob=0.94)\nprint(summary)\n\n        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\nbeta0  0.934  0.174   0.603    1.257      0.003    0.002    4147.0    4717.0   \nbeta1  0.462  0.043   0.381    0.543      0.001    0.000    4247.0    4317.0   \n\n       r_hat  \nbeta0    1.0  \nbeta1    1.0  \n\n\nMostriamo le distribuzioni a posteriori e le tracce di campionamento per i parametri:\n\n_ = az.plot_trace(fit, var_names=([\"beta0\", \"beta1\"]))\n\n\n\n\n\n\n\n\nNel pannello superiore della figura seguente vediamo il modello lineare nella sua forma non trasformata. Come si può osservare, questo modello lineare genera valori che escono dall’intervallo [0, 1], sottolineando quindi la necessità di una funzione di collegamento inversa. Questa funzione ha il compito di mappare i valori dal dominio dei numeri reali all’intervallo [0, 1]. Come abbiamo visto, questa trasformazione è realizzata mediante la funzione logistica inversa.\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4), gridspec_kw={\"width_ratios\": [2, 1]})\n\n# Data space plot ========================================================\naz.plot_hdi(\n    data[\"x\"],\n    idata.posterior.p,\n    hdi_prob=0.95,\n    fill_kwargs={\"alpha\": 0.25, \"linewidth\": 0},\n    ax=ax[0],\n    color=\"C1\",\n)\n# posterior mean\npost_mean = idata.posterior.p.mean((\"chain\", \"draw\"))\nax[0].plot(data[\"x\"], post_mean, label=\"posterior mean\", color=\"C1\")\n# plot truth\nax[0].plot(data[\"x\"], p_true, \"--\", label=\"true\", color=\"C2\")\n# formatting\nax[0].set(xlabel=\"x\", title=\"Data space\")\nax[0].set_ylabel(\"proportion successes\", color=\"C1\")\nax[0].tick_params(axis=\"y\", labelcolor=\"C1\")\nax[0].legend()\n# instantiate a second axes that shares the same x-axis\nfreq = ax[0].twinx()\nfreq.set_ylabel(\"number of successes\")\nfreq.scatter(data[\"x\"], data[\"y\"], color=\"k\", label=\"data\")\n# get y-axes to line up\ny_buffer = 1\nfreq.set(ylim=[-y_buffer, n + y_buffer])\nax[0].set(ylim=[-(y_buffer / n), 1 + (y_buffer / n)])\nfreq.grid(None)\n# set both y-axis to have 5 ticks\nax[0].set(yticks=np.linspace(0, 20, 5) / n)\nfreq.set(yticks=np.linspace(0, 20, 5))\n\n# Parameter space plot ===================================================\naz.plot_kde(\n    az.extract(idata, var_names=\"beta0\"),\n    az.extract(idata, var_names=\"beta1\"),\n    ax=ax[1],\n)\nax[1].plot(beta0_true, beta1_true, \"C2o\", label=\"true\")\nax[1].set(xlabel=r\"$\\beta_0$\", ylabel=r\"$\\beta_1$\", title=\"Parameter space\")\nax[1].legend(facecolor=\"white\", frameon=True)\nplt.tight_layout()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_61676/1160461270.py:44: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Modelli lineari generalizzati</span>"
    ]
  },
  {
    "objectID": "chapters/glm/02_stan_binomial_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/02_stan_binomial_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "90  Modelli lineari generalizzati",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\narviz     : 0.18.0\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>Modelli lineari generalizzati</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html",
    "href": "chapters/glm/03_stan_logistic_regr.html",
    "title": "91  Regressione logistica con Stan",
    "section": "",
    "text": "Introduzione\nLa regressione logistica è un modello additivo utilizzato per dati binari, ossia dati \\(y\\) che assumono valori 0 o 1. Per modellare i dati binari, dobbiamo aggiungere due caratteristiche al modello base \\(y = a + bx\\): una trasformazione non lineare che vincola l’output tra 0 e 1 (a differenza di \\(a + bx\\), che è illimitato), e un metodo per interpretare i numeri risultanti come probabilità che un evento si verifichi.\nIn questo capitolo, approfondiremo la regressione logistica bivariata, un modello statistico che ci consente di analizzare le relazioni tra una variabile di esito binaria e una singola variabile indipendente. Esploreremo il processo di stima dei coefficienti del modello attraverso un approccio bayesiano e forniremo un’interpretazione dei risultati ottenuti. Mostreremo come i coefficienti influenzano la probabilità di successo della variabile binaria di esito, nonché come interpretare il loro segno e ampiezza.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-di-regressione-logistica-per-variabili-binarie",
    "title": "91  Regressione logistica con Stan",
    "section": "91.1 Modello di Regressione Logistica per Variabili Binarie",
    "text": "91.1 Modello di Regressione Logistica per Variabili Binarie\nIl modello di regressione logistica è utilizzato per analizzare la relazione tra una variabile dipendente dicotomica, che assume i valori di “successo” e “fallimento”, e una o più variabili indipendenti, che possono essere sia quantitative che qualitative. Qui ci concentreremo sul caso di una sola variabile indipendente.\nConsideriamo \\(n\\) osservazioni i.i.d., dove \\(Y_i\\) indica l’osservazione \\(i\\)-esima della variabile risposta, per \\(i=1, \\dots, n\\). Ogni osservazione è associata a un vettore di variabili esplicative \\((x_1, \\dots, x_p)\\). La relazione che vogliamo esaminare è tra la probabilità di successo \\(\\pi_i\\) e la variabile esplicativa, espressa dalla formula:\n\\[\nP(Y=1 \\mid X=x_i) = \\pi_i.\n\\]\nIn questo contesto, la variabile dipendente \\(Y\\) segue una distribuzione di Bernoulli, con i seguenti possibili valori:\n\\[\ny_i =\n\\begin{cases}\n    1 & \\text{per un successo (per l'osservazione $i$-esima)},\\\\\n    0 & \\text{per un fallimento}.\n\\end{cases}\n\\]\nLe probabilità associate a questi valori sono rispettivamente \\(\\pi\\) per il successo e \\(1-\\pi\\) per il fallimento:\n\\[\n\\begin{aligned}\n    P(Y_i = 1) &= \\pi,\\\\\n    P(Y_i = 0) &= 1-\\pi.\n\\end{aligned}\n\\]\nQuesto modello permette di studiare come le variabili esplicative influenzino la probabilità di un evento binario, come il successo o il fallimento.\nLa media condizionata \\(\\mathbb{E}(Y \\mid X=x)\\) in una popolazione può essere vista come la proporzione di valori 1 per un dato punteggio \\(x\\) sulla variabile esplicativa, ovvero la probabilità condizionata \\(\\pi_i\\) di osservare l’esito \\(Y = 1\\) in corrispondenza di un certo livello \\(X\\):\n\\[\n\\pi_i \\equiv P(Y = 1 \\mid X = x).\n\\]\nIl valore atteso diventa:\n\\[\n\\mathbb{E}(Y \\mid x) = \\pi_i.\n\\]\nSe \\(X\\) è una variabile discreta, possiamo calcolare la proporzione di \\(Y=1\\) per ogni valore di \\(X=x\\) nel campione. Queste proporzioni rappresentano una stima non parametrica della funzione di regressione di \\(Y\\) su \\(X\\), e possono essere stimate tramite tecniche di smoothing.\nPer valori bassi della variabile \\(X\\), la proporzione condizionata di valori \\(Y=1\\) sarà prossima allo 0. Per valori alti di \\(X\\), la proporzione di valori \\(Y=1\\) sarà prossima a 1. A livelli intermedi di \\(X\\), la curva di regressione non parametrica gradualmente approssima i valori 0 e 1 seguendo un andamento sigmoidale.\nPer illustrare, generiamo dei dati simulati con una variabile dicotomica \\(Y\\) e una variabile discreta \\(X\\) nei quali la probabilità che \\(Y=1\\) aumenta con il valore di \\(X\\).\n\n# Simulate data\nnp.random.seed(42)  # For reproducibility\nn = 1000  # Number of samples\nX = np.random.randint(0, 10, size=n)  # Discrete independent variable with levels from 0 to 9\n\n# Define the logistic model\ndef logistic(x, beta0, beta1):\n    return expit(beta0 + beta1 * x)\n\nbeta0 = -2\nbeta1 = 1  # Increase the steepness of the curve\np = logistic(X, beta0, beta1)\n\n# Generate dichotomous outcome variable Y\nY = np.random.binomial(1, p, size=n)\n\n# Compute mean success rate and standard error for each level of X\ndf = pd.DataFrame({'X': X, 'Y': Y})\nmean_success_rate = df.groupby('X')['Y'].mean()\nstandard_error = df.groupby('X')['Y'].sem()\n\n# Plot mean success rates with standard errors\nsns.pointplot(x=mean_success_rate.index, y=mean_success_rate.values, capsize=0.1, linestyle='none')  # Use linestyle='none' to avoid connecting lines\nplt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr=standard_error.values, fmt='o', color='blue')\n\n# Fit a non-parametric smoother (LOESS) and plot the curve\nlowess_smoothed = lowess(mean_success_rate.values, mean_success_rate.index, frac=0.3)\n\nplt.plot(lowess_smoothed[:, 0], lowess_smoothed[:, 1], color='red', label='Non-parametric Smoother')\n\n# Customizing the plot\nplt.xlabel('X')\nplt.ylabel('Mean Success Rate')\nplt.grid(True)\n\n# Display the plot\nplt.show()",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilità",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilità",
    "title": "91  Regressione logistica con Stan",
    "section": "91.2 Modello Lineare nelle Probabilità",
    "text": "91.2 Modello Lineare nelle Probabilità\nPotremmo pensare di usare una funzione lineare per rappresentare la dipendenza di \\(Y\\) da \\(X\\). Introduciamo un modello lineare con le seguenti assunzioni standard:\n\\[\nY_i = \\alpha + \\beta X_i + \\varepsilon_i,\n\\]\ndove \\(\\varepsilon_i\\) segue una distribuzione normale con media 0 e varianza 1 (\\(\\varepsilon_i \\sim \\mathcal{N}(0, 1)\\)) e gli errori \\(\\varepsilon_i\\) e \\(\\varepsilon_j\\) sono indipendenti per ogni \\(i \\neq j\\). Il valore atteso di \\(Y_i\\) è quindi \\(\\mathbb{E}(Y_i) = \\alpha + \\beta X_i\\), portando a:\n\\[\n\\pi_i = \\alpha + \\beta X_i.\n\\]\nQuesto è noto come modello lineare nelle probabilità (linear probability model). Tuttavia, questo approccio presenta una limitazione significativa: non garantisce che i valori predetti di \\(\\pi_i\\) siano confinati nell’intervallo [0,1], come richiesto per le probabilità.\n\n91.2.1 Problemi di Normalità\nConsiderando che \\(Y_i\\) può assumere solo i valori 0 o 1, i residui \\(\\varepsilon_i\\) risultano anch’essi dicotomici e quindi non possono seguire una distribuzione normale. Ad esempio, se \\(Y_i=1\\) con probabilità \\(\\pi_i\\), il residuo sarà:\n\\[\n\\varepsilon_i = 1 - \\mathbb{E}(Y_i) = 1 - (\\alpha + \\beta X_i) = 1 - \\pi_i.\n\\]\nSe, invece, \\(Y_i=0\\) con probabilità \\(1-\\pi_i\\), il residuo sarà:\n\\[\n\\varepsilon_i = 0 - \\mathbb{E}(Y_i) = 0 - (\\alpha + \\beta X_i) = - \\pi_i.\n\\]\nTuttavia, se la dimensione del campione è grande, il teorema del limite centrale può mitigare l’importanza dell’assunzione di normalità per le stime dei minimi quadrati.\n\n\n91.2.2 Problematiche di Eteroschedasticità\nUtilizzare il metodo dei minimi quadrati può essere inappropriato in questo contesto poiché la varianza dei residui non è costante ma dipende dalla media, e quindi dalla variabile \\(X\\). Assumendo che il modello sia lineare, abbiamo che \\(\\mathbb{E}(\\varepsilon_i)=0\\). Sfruttando le relazioni discusse in precedenza, la varianza dei residui si calcola come:\n\\[\n\\mathbb{V}(\\varepsilon_i) = (1-\\pi_i)\\pi_i.\n\\]\nConsideriamo che la varianza dei residui \\(\\varepsilon_i\\) può essere espressa come:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2,\n\\]\ndove \\(\\mathbb{E}(\\varepsilon_i^2)\\) è il valore atteso del quadrato dei residui e \\(\\mathbb{E}(\\varepsilon_i)^2\\) è il quadrato del valore atteso dei residui.\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i^2)\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i^2) &= \\mathbb{E}[(Y_i - \\mathbb{E}(Y_i))^2] \\\\\n&= \\mathbb{E}[(Y_i - \\pi_i)^2] \\\\\n&= \\mathbb{E}[(Y_i^2 - 2Y_i\\pi_i + \\pi_i^2)] \\\\\n&= \\mathbb{E}(Y_i^2) - 2\\mathbb{E}(Y_i\\pi_i) + \\mathbb{E}(\\pi_i^2) \\\\\n&= \\mathbb{E}(Y_i) - 2\\mathbb{E}(Y_i\\pi_i) + \\pi_i^2 \\\\\n&= \\pi_i - 2\\pi_i^2 + \\pi_i^2 \\\\\n&= \\pi_i - \\pi_i^2 \\\\\n&= \\pi_i(1 - \\pi_i)\n\\end{align*}\n\\]\nOra calcoliamo \\(\\mathbb{E}(\\varepsilon_i)^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E}(\\varepsilon_i)^2 &= (\\mathbb{E}(Y_i - \\mathbb{E}(Y_i)))^2 \\\\\n&= (\\mathbb{E}(Y_i - \\pi_i))^2 \\\\\n&= (0)^2 \\\\\n&= 0\n\\end{align*}\n\\]\nQuindi, sostituendo questi risultati nella formula della varianza dei residui, otteniamo:\n\\[\n\\text{Var}(\\varepsilon_i) = \\mathbb{E}(\\varepsilon_i^2) - \\mathbb{E}(\\varepsilon_i)^2 = \\pi_i(1 - \\pi_i)\n\\]\nQuindi, abbiamo dimostrato che la varianza dei residui nel modello lineare nelle probabilità può essere espressa come \\((1-\\pi_i)\\pi_i\\).\nDato che \\(\\pi_i\\) dipende da \\(x\\), ciò significa che la varianza non è costante in funzione di \\(x\\). Questa eteroschedasticità dei residui rappresenta un problema per le stime dei minimi quadrati nel modello lineare, specialmente quando le probabilità \\(\\pi_i\\) sono vicine a 0 o 1.\n\n\n91.2.3 Linearità\nIl maggiore inconveniente connesso all’adozione del modello lineare nelle probabilità deriva dal fatto che la stima della probabilità di successo, \\(P(\\hat{Y}_i=1)=\\hat{\\pi}_i\\), non è necessariamente compresa nell’intervallo \\((0,1)\\), ma può essere sia negativa sia maggiore di 1. Nel caso dell’esempio in discussione, ciò significa che la retta dei minimi quadrati produce valori attesi \\(\\hat{\\pi}\\) inferiori a 0 per bassi valori della variabile \\(X\\) e valori \\(\\hat{\\pi}\\) superiori a 1 per valori di \\(X\\) alti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilità-vincolato",
    "href": "chapters/glm/03_stan_logistic_regr.html#modello-lineare-nelle-probabilità-vincolato",
    "title": "91  Regressione logistica con Stan",
    "section": "91.3 Modello Lineare nelle Probabilità Vincolato",
    "text": "91.3 Modello Lineare nelle Probabilità Vincolato\nUna soluzione per mantenere \\(\\pi\\) all’interno dell’intervallo (0, 1) è la seguente specificazione del modello:\n\\[\n\\pi=\n\\begin{cases}\n  0                           &\\text{se $\\alpha + \\beta X &lt; 0$},\\\\\n  \\alpha + \\beta X           &\\text{se $0 \\leq \\alpha + \\beta X \\leq 1$},\\\\\n  1 &\\text{se $\\alpha + \\beta X &gt; 1$}.\n\\end{cases}\n\\]\nQuesto modello lineare nelle probabilità vincolato mostra alcune instabilità, soprattutto a causa della sua dipendenza critica dai valori estremi di \\(\\pi\\), dove assume i valori 0 o 1. La linearità di \\(\\pi = \\alpha + \\beta X\\) si basa fortemente sui punti in cui si verificano questi estremi. In particolare, la stima di \\(\\pi = 0\\) può essere influenzata dal valore minimo di \\(X\\) associato a \\(Y=1\\), mentre la stima di \\(\\pi = 1\\) può dipendere dal valore massimo di \\(X\\) per cui \\(Y=0\\). Questi valori estremi tendono a variare significativamente tra diversi campioni e possono diventare più estremi all’aumentare della dimensione del campione.\nLa presenza di più variabili esplicative (\\(k \\geq 2\\)) complica ulteriormente la stima dei parametri del modello. Inoltre, il modello mostra un cambiamento brusco nella pendenza della curva di regressione ai punti estremi (0 e 1 di \\(\\pi\\)), risultando poco realistico in molte situazioni pratiche. Questo rende il modello meno adatto a descrivere relazioni complesse e gradualmente variabili tra \\(\\pi\\) e \\(X\\).\nUna funzione che modella una relazione più fluida e continua tra \\(\\pi\\) e \\(X\\) sarebbe più realistica e rappresentativa delle dinamiche osservate. Questo motiva la preferenza per modelli alternativi, come il modello di regressione logistica, che tende a fornire una rappresentazione più accurata e realistica delle interazioni tra variabili dicotomiche e esplicative.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica",
    "title": "91  Regressione logistica con Stan",
    "section": "91.4 Regressione Logistica",
    "text": "91.4 Regressione Logistica\nUn metodo efficace per gestire il problema del vincolo sulle probabilità è specificare modelli non direttamente per le probabilità stesse, ma per una loro trasformazione che elimina tale vincolo. Invece di definire un modello lineare per la probabilità condizionata \\(\\pi_i\\), si può specificare un modello lineare per il logaritmo degli odds (logit):\n\\[\n\\eta_i = \\log_e \\frac{\\pi_i}{1-\\pi_i} = \\alpha + \\beta x_i,\n\\]\nQuesto approccio non presenta problemi poiché il logit \\(\\eta_i\\) è sempre un numero reale, permettendo di modellare una trasformazione lineare di \\(\\pi_i\\). La trasformazione inversa, che ci permette di ottenere \\(\\pi_i\\) da \\(\\eta_i\\), è data dalla funzione logistica:\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1 + e^{\\eta_i}} = \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}}.\n\\]\n\n91.4.1 Vantaggi della Regressione Logistica\nLa regressione logistica presenta diversi vantaggi rispetto al modello lineare delle probabilità:\n\nVincolo delle Probabilità: La trasformazione logistica assicura che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell’intervallo [0,1].\nInterpretabilità degli Odds Ratio: Il coefficiente \\(\\beta\\) può essere interpretato come il cambiamento logaritmico negli odds di successo associato a un incremento unitario di \\(X\\). In altre parole, \\(e^\\beta\\) rappresenta il fattore di aumento (o diminuzione) degli odds per un incremento unitario della variabile indipendente.\nGestione dell’Eteroschedasticità: La forma funzionale della varianza del modello di regressione logistica \\(\\pi_i (1 - \\pi_i)\\) è intrinsecamente considerata nel processo di stima tramite il metodo della massima verosimiglianza.\n\n\n\n91.4.2 Esempio Pratico\nPer illustrare l’applicazione della regressione logistica, consideriamo nuovamente i dati simulati precedentemente. Applichiamo il modello di regressione logistica ai dati e tracciamo la curva logistica risultante:\n\n# Plot mean success rates with standard errors\nsns.pointplot(x=mean_success_rate.index, y=mean_success_rate.values, capsize=0.1, linestyle='none')  # Use linestyle='none' to avoid connecting lines\nplt.errorbar(mean_success_rate.index, mean_success_rate.values, yerr=standard_error.values, fmt='o', color='blue')\n\n# Fit logistic regression model and plot logistic curve\nX_design = sm.add_constant(X)\nlogit_model = sm.Logit(Y, X_design).fit()\nx_vals = np.linspace(X.min(), X.max(), 100)\ny_vals = logit_model.predict(sm.add_constant(x_vals))\n\nplt.plot(x_vals, y_vals, color='red', label='Logistic Regression Curve')\n\n# Customizing the plot\nplt.xlabel('X')\nplt.ylabel('Mean Success Rate')\nplt.grid(True)\n\n# Display the plot\nplt.show()\n\nOptimization terminated successfully.\n         Current function value: 0.289256\n         Iterations 8\n\n\n\n\n\n\n\n\n\nQuesto esempio dimostra come la regressione logistica possa essere utilizzata per modellare una variabile dicotomica in funzione di una variabile indipendente. La curva logistica risultante rappresenta adeguatamente la relazione tra \\(X\\) e la probabilità di successo \\(Y\\), garantendo che i valori predetti di \\(\\pi_i\\) siano sempre compresi nell’intervallo [0,1].\nNelle sezioni seguenti, descriveremo in dettaglio il modello di regressione logistica utilizzato per generare la curva logistica mostrata nella figura precedente. Inizieremo chiarendo i concetti di odds e logit e la loro relazione con le probabilità.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#componente-sistematica",
    "href": "chapters/glm/03_stan_logistic_regr.html#componente-sistematica",
    "title": "91  Regressione logistica con Stan",
    "section": "91.5 Componente Sistematica",
    "text": "91.5 Componente Sistematica\nLa componente sistematica mette in relazione un vettore (\\(\\eta_1, \\eta_2, \\dots, \\eta_k\\)) con le variabili esplicative mediante un modello lineare. Sia \\(X_{ij}\\) il valore della \\(j\\)-esima variabile esplicativa (\\(j=1, 2, \\dots, p\\)) per l’\\(i\\)-esima osservazione (\\(i=1, \\dots, k\\)). Allora\n\\[\n\\eta_i = \\sum_j \\beta_j X_{ij}.\n\\]\nQuesta combinazione lineare di variabili esplicative è chiamata il predittore lineare. Un \\(X_{ij}=1, \\forall i\\) viene utilizzato per il coefficiente dell’intercetta del modello (talvolta denotata da \\(\\alpha\\)).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#componente-aleatoria",
    "href": "chapters/glm/03_stan_logistic_regr.html#componente-aleatoria",
    "title": "91  Regressione logistica con Stan",
    "section": "91.6 Componente Aleatoria",
    "text": "91.6 Componente Aleatoria\nLa componente aleatoria del modello suppone l’esistenza di \\(k\\) osservazioni indipendenti \\(y_1, y_2, \\dots, y_k\\), ciascuna delle quali viene trattata come la realizzazione di una variabile casuale \\(Y_i\\). Si assume che \\(Y_i\\) abbia una distribuzione binomiale:\n\\[\nY_i \\sim Bin(n_i, \\pi_i)\n\\]\ncon parametri \\(n_i\\) e \\(\\pi_i\\). Per dati individuali (uno per ciascun valore \\(x_i\\)), \\(n_i=1,\n    \\forall i\\).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#funzione-legame",
    "href": "chapters/glm/03_stan_logistic_regr.html#funzione-legame",
    "title": "91  Regressione logistica con Stan",
    "section": "91.7 Funzione Legame",
    "text": "91.7 Funzione Legame\nLa funzione legame \\(g(\\cdot)\\) mette in relazione il valore atteso della variabile risposta \\(Y_i\\) con la componente sistematica \\(\\eta_i\\) del modello. Abbiamo visto che \\(\\mathbb{E}(Y_i)=\\pi_i\\). Che relazione c’è tra \\(\\pi_i\\) e il predittore lineare \\(\\eta_i= \\alpha + \\sum_j  \\beta_j X_{ij}\\)? La risposta a questa domanda è data dalla funzione legame:\n\\[\n\\eta_i = g(\\pi_i) = \\ln{\\frac{\\pi_i}{1-\\pi_i}}\n\\]\nSi noti che la funzione legame non trasforma la variabile risposta \\(Y_i\\) ma bensì il suo valore atteso \\(\\pi_i\\).\nLa funzione legame è invertibile: anziché trasformare il valore atteso nel predittore lineare si può trasformare il predittore lineare nel valore atteso \\(\\pi_i\\):\n\\[\n\\pi_i = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}} =  \\frac{e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}{1+e^{\\alpha + \\sum_j  \\beta_j X_{ij}}}.\n\\]\nSi ottiene così un modello non lineare per le probabilità \\(\\pi_i\\).\nIn conclusione, la regressione logistica estende il concetto di regressione lineare per modellare le probabilità condizionate di esiti Bernoulliani $ Y \\(, adoperando la funzione logistica come collegamento per trasformare relazioni lineari tra predittori (\\) _i = _0 + 1 X{i} $) in probabilità nell’intervallo [0,1]. Questo metodo permette di passare dalla modellazione diretta della probabilità $ p $ alla modellazione di una funzione di tale probabilità attraverso una relazione lineare, impiegando la funzione logit come funzione di collegamento.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione",
    "href": "chapters/glm/03_stan_logistic_regr.html#coefficienti-del-modello-nella-regressione-logistica-e-la-loro-interpretazione",
    "title": "91  Regressione logistica con Stan",
    "section": "91.8 Coefficienti del Modello nella Regressione Logistica e la loro Interpretazione",
    "text": "91.8 Coefficienti del Modello nella Regressione Logistica e la loro Interpretazione\nUn aspetto cruciale per comprendere la relazione tra le variabili predittive e una variabile di risposta binaria è l’interpretazione dei coefficienti del modello.\n\n91.8.1 Odds Ratio\nIl caso più semplice che consente di interpetare l’odds ratio in una regressione logistica è quando la variabile indipendente (X) è binaria (cioè può assumere solo valori 0 e 1).\nIn una regressione logistica, il modello assume la forma:\n\\[\n\\log \\left( \\frac{P(Y = 1)}{P(Y = 0)} \\right) = \\beta_0 + \\beta_1 X\n\\]\ndove:\n\n\\(\\log \\left( \\frac{P(Y = 1)}{P(Y = 0)} \\right)\\) è il logaritmo dell’odds che l’evento \\(Y = 1\\) avvenga,\n\\(\\beta_0\\) è l’intercetta del modello,\n\\(\\beta_1\\) è il coefficiente per la variabile indipendente \\(X\\).\n\n\n\n91.8.2 Passo 1: Calcolare gli odds per i due valori di \\(X\\)\nQuando \\(X = 0\\), l’equazione diventa:\n\\[\n\\log \\left( \\frac{P(Y = 1 \\mid X = 0)}{P(Y = 0 \\mid X = 0)} \\right) = \\beta_0\n\\]\nQuesto significa che l’odds di \\(Y = 1\\) dato che \\(X = 0\\) è:\n\\[\n\\frac{P(Y = 1 \\mid X = 0)}{P(Y = 0 \\mid X = 0)} = e^{\\beta_0}\n\\]\nAllo stesso modo, quando \\(X = 1\\), l’equazione diventa:\n\\[\n\\log \\left( \\frac{P(Y = 1 \\mid X = 1)}{P(Y = 0 \\mid X = 1)} \\right) = \\beta_0 + \\beta_1\n\\]\nQuindi, l’odds di \\(Y = 1\\) dato che \\(X = 1\\) è:\n\\[\n\\frac{P(Y = 1 \\mid X = 1)}{P(Y = 0 \\mid X = 1)} = e^{\\beta_0 + \\beta_1}\n\\]\n\n\n91.8.3 Passo 2: Calcolare l’odds ratio\nL’odds ratio è il rapporto tra gli odds quando \\(X = 1\\) e quando \\(X = 0\\):\n\\[\n\\text{Odds Ratio} = \\frac{\\frac{P(Y = 1 \\mid X = 1)}{P(Y = 0 \\mid X = 1)}}{\\frac{P(Y = 1 \\mid X = 0)}{P(Y = 0 \\mid X = 0)}} = \\frac{e^{\\beta_0 + \\beta_1}}{e^{\\beta_0}}\n\\]\nSemplificando, otteniamo:\n\\[\n\\text{Odds Ratio} = e^{\\beta_1}\n\\]\n\n\n91.8.4 Interpretazione dell’odds ratio\nL’odds ratio \\(e^{\\beta_1}\\) rappresenta il cambiamento relativo negli odds di \\(Y = 1\\) per un aumento di una unità di \\(X\\) (in questo caso, il passaggio da \\(X = 0\\) a \\(X = 1\\)).\nSe \\(\\beta_1\\) è:\n\nMaggiore di zero (\\(e^{\\beta_1} &gt; 1\\)): l’odds di \\(Y = 1\\) aumenta quando \\(X\\) passa da 0 a 1.\nMinore di zero (\\(e^{\\beta_1} &lt; 1\\)): l’odds di \\(Y = 1\\) diminuisce quando \\(X\\) passa da 0 a 1.\nUguale a zero (\\(e^{\\beta_1} = 1\\)): l’odds di \\(Y = 1\\) non cambia in base ai valori di \\(X\\).\n\nIn sintesi, l’odds ratio \\(e^{\\beta_1}\\) fornisce una misura dell’associazione tra la variabile binaria \\(X\\) e la probabilità dell’evento \\(Y = 1\\), rappresentando il moltiplicatore degli odds nel caso in cui \\(X\\) passi da 0 a 1.\n\n\n91.8.5 Interpretazione sui Logit\nNella regressione logistica, ogni coefficiente \\(\\beta_j\\) del modello può essere interpretato direttamente in termini di log-odds, che sono i logaritmi delle probabilità di ottenere un evento con esito positivo (\\(y=1\\)). Quando interpretiamo i coefficienti:\n\nCoefficienti Positivi (\\(\\beta_j &gt; 0\\)): Un coefficiente positivo indica che c’è una relazione diretta tra il predittore e l’aumento dei log-odds di osservare l’evento di interesse. Questo significa che all’aumentare del valore del predittore, la probabilità dell’evento di interesse aumenta.\nCoefficienti Negativi (\\(\\beta_j &lt; 0\\)): Al contrario, un coefficiente negativo indica una relazione inversa tra il predittore e la probabilità logistica dell’evento. Con l’aumentare del predittore, i log-odds e quindi la probabilità dell’evento diminuiscono.\n\n\n\n91.8.6 Interpretazione sugli Odds Ratio (OR)\nL’interpretazione dei coefficienti nella regressione logistica può estendersi agli odds ratio (OR), che forniscono informazioni sulla relazione tra i predittori e la probabilità dell’evento di interesse. Per esempio, consideriamo un modello con un predittore continuo \\(X\\) e un coefficiente \\(\\beta_1 = 0.50\\). Il logaritmo naturale dell’odds ratio, \\(\\log(OR) = 0.50\\), viene esponenziato per ottenere:\n\\[\nOR = e^{0.50} \\approx 1.65.\n\\]\nQuesto risultato indica che per un’unità di incremento in \\(X\\), l’odds di sperimentare l’evento di interesse è circa 1.65 volte maggiore. In altre parole, l’incremento di una unità nel predittore \\(X\\) aumenta l’odds di sperimentare l’evento di interesse di circa il 65%. Viceversa, un coefficiente negativo indicherebbe una diminuzione dell’odds per un incremento di una unità in \\(X\\).\n\n\n91.8.7 Interpretazione sulla Scala delle Probabilità\nLa regressione logistica consente di interpretare i coefficienti non solo in termini di log-odds, ma anche relativamente alle variazioni di probabilità. Consideriamo un modello che predice la probabilità di superare un esame basandosi sul numero di ore di studio (\\(X\\)).\nSupponiamo che il coefficiente associato alle ore di studio sia \\(\\beta_1 = 0.5\\). Questo valore indica che ogni ora aggiuntiva di studio incrementa i log-odds di successo nell’esame. Per comprendere l’impatto di un’ora in più di studio sulla probabilità di successo, possiamo utilizzare la seguente formula:\n\\[\n\\Delta p = \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot (X_1 + 1))}} - \\frac{1}{1 + e^{-(\\beta_0 + 0.5 \\cdot X_1)}}.\n\\]\nQuesta formula calcola la differenza tra la probabilità di successo dopo aver aggiunto un’ora di studio e la probabilità di successo prima di tale aggiunta. In termini pratici, \\(\\Delta p\\) rappresenta l’incremento della probabilità di superare l’esame attribuibile a un’ora supplementare di studio. Questa interpretazione è cruciale per valutare quantitativamente l’effetto delle ore di studio sulla probabilità di superare l’esame.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#un-esempio-concreto",
    "href": "chapters/glm/03_stan_logistic_regr.html#un-esempio-concreto",
    "title": "91  Regressione logistica con Stan",
    "section": "91.9 Un esempio concreto",
    "text": "91.9 Un esempio concreto\nConsideriamo nuovamente i dati simulati in precedenza\n\ndf.head()\n\n\n\n\n\n\n\n\nX\nY\n\n\n\n\n0\n6\n1\n\n\n1\n3\n1\n\n\n2\n7\n1\n\n\n3\n4\n1\n\n\n4\n6\n1\n\n\n\n\n\n\n\nStimeremo ora i coefficienti del modello di regressione logistica usando Stan. Definiamo i dati nel formato atteso da Stan:\n\nstan_data = {\n    \"N\" : df.shape[0],\n    \"y\" : df[\"Y\"],\n    \"x\" : df[\"X\"] \n}\n\nCompiliamo il modello di regressione logistica e stampiamo lo script Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"logistic_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:47:02 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression\n12:47:13 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/logistic_regression\n\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] x;\n  array[N] int&lt;lower=0, upper=1&gt; y;\n}\nparameters {\n  real alpha;\n  real beta;\n}\nmodel {\n  y ~ bernoulli_logit(alpha + beta * x);\n}\n\n\n\nEseguiamo il campionamento MCMC:\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=1_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n12:47:36 - cmdstanpy - INFO - CmdStan start processing\n12:47:36 - cmdstanpy - INFO - Chain [1] start processing\n12:47:36 - cmdstanpy - INFO - Chain [2] start processing\n12:47:36 - cmdstanpy - INFO - Chain [3] start processing\n12:47:36 - cmdstanpy - INFO - Chain [4] start processing\n12:47:37 - cmdstanpy - INFO - Chain [3] done processing\n12:47:37 - cmdstanpy - INFO - Chain [2] done processing\n12:47:37 - cmdstanpy - INFO - Chain [4] done processing\n12:47:37 - cmdstanpy - INFO - Chain [1] done processing\n\n\nEsaminiamo le tracce:\n\n_ = az.plot_trace(fit)\n\n\n\n\n\n\n\n\nOtteniamo le stime a posteriori dei parametri:\n\naz.summary(fit, var_names=([\"alpha\", \"beta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-1.778\n0.18\n-2.132\n-1.436\n0.004\n0.003\n2261.0\n2634.0\n1.0\n\n\nbeta\n1.004\n0.07\n0.869\n1.144\n0.001\n0.001\n2305.0\n2682.0\n1.0\n\n\n\n\n\n\n\nCreiamo un nuovo DataFrame con 100 valori \\(x\\) nell’intervallo [0, 9]:\n\nnew_data = pd.DataFrame({\n    \"x\": np.linspace(0, 9, 100)\n})\nnew_data\n\n\n\n\n\n\n\n\nx\n\n\n\n\n0\n0.000000\n\n\n1\n0.090909\n\n\n2\n0.181818\n\n\n3\n0.272727\n\n\n4\n0.363636\n\n\n...\n...\n\n\n95\n8.636364\n\n\n96\n8.727273\n\n\n97\n8.818182\n\n\n98\n8.909091\n\n\n99\n9.000000\n\n\n\n\n100 rows × 1 columns\n\n\n\nOtteniamo le medie a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\):\n\nalpha = fit.stan_variable('alpha').mean()\nbeta = fit.stan_variable('beta').mean() \nprint(alpha, beta)\n\n-1.7784477 1.003503126\n\n\nCalcoliamo i logit per ogni valore $ x $ nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilità è una funzione lineare di $ x $:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\n\nlogit_p = alpha + new_data['x'] * beta\nlogit_p\n\n0    -1.778448\n1    -1.687220\n2    -1.595993\n3    -1.504765\n4    -1.413537\n        ...   \n95    6.888170\n96    6.979398\n97    7.070625\n98    7.161853\n99    7.253080\nName: x, Length: 100, dtype: float64\n\n\nEsaminiamo graficamente la relazione tra il logit \\(\\log \\left( \\frac{p}{1-p} \\right)\\) e \\(x\\):\n\nnew_data['logit_p'] = logit_p\n\nplt.plot(new_data['x'], new_data['logit_p'], linestyle='-', color='blue')  # Plot con marcatori e linea\n\nplt.title('Logit Predetti in Funzione di X')  # Titolo del grafico\nplt.xlabel('X')  # Etichetta asse x\nplt.ylabel('Logit')  # Etichetta asse y\nplt.show() \n\n\n\n\n\n\n\n\nCalcoliamo i logit per ogni valore $ x $ nel dataset new_data utilizzando le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) ottenute dal modello di regressione logistica. Nel modello di regressione logistica, il logit della probabilità è una funzione lineare di $ x $. Per ottenere la probabilità $ p $ dalla trasformazione del logit, possiamo utilizzare la funzione logistica inversa. Svolgiamo la conversione:\n\nCalcoliamo il logit per ogni valore di $ x $:\n\\[\n\\text{logit}_p = \\alpha + \\beta x\n\\]\nApplichiamo la funzione logistica inversa (antilogit) per ottenere la probabilità $ p $:\n\\[\np = \\frac{e^{\\text{logit}_p}}{1 + e^{\\text{logit}_p}} = \\frac{e^{\\alpha + \\beta x}}{1 + e^{\\alpha + \\beta x}}\n\\]\n\nQuesta formula ci permette di trasformare il logit in una probabilità compresa tra 0 e 1 per ogni valore di $ x $ nel dataset new_data.\n\nprob = np.exp(logit_p) / (1 + np.exp(logit_p))\n# Aggiungi le probabilità calcolate a `new_data`\nnew_data['prob'] = prob\nnew_data.head()\n\n\n\n\n\n\n\n\nx\nlogit_p\nprob\n\n\n\n\n0\n0.000000\n-1.778448\n0.144495\n\n\n1\n0.090909\n-1.687220\n0.156142\n\n\n2\n0.181818\n-1.595993\n0.168542\n\n\n3\n0.272727\n-1.504765\n0.181716\n\n\n4\n0.363636\n-1.413537\n0.195677\n\n\n\n\n\n\n\n\nplt.plot(new_data['x'], new_data['prob'], linestyle='-', color='blue')  # Plot con marcatori e linea\n\nplt.title('Probabilità Predetta in Funzione di X')  # Titolo del grafico\nplt.xlabel('X')  # Etichetta asse x\nplt.ylabel('Probabilità Predetta')  # Etichetta asse y\nplt.show() \n\n\n\n\n\n\n\n\n\n91.9.1 Interpretazione dei Coefficienti nella Regressione Logistica\nAbbiamo stimato i coefficienti \\(\\alpha\\) e \\(\\beta\\) dal modello di regressione logistica con i seguenti valori: - \\(\\alpha = -1.7784477\\) - \\(\\beta = 1.003503126\\)\nEsamineremo ora l’interpretazione di questi coefficienti sulla scala dei logit, dell’odds ratio e delle probabilità.\n\n91.9.1.1 La regola del dividere per 4\nLa regola del dividere per 4 è un metodo utile per interpretare i coefficienti della regressione logistica. Dividendo il coefficiente \\(\\beta\\) per 4, si ottiene un’approssimazione della massima variazione nella probabilità \\(\\Pr(y = 1)\\) per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.\nLa curva logistica è più ripida al centro, dove $ + x = 0 $ e quindi $ ^{-1}(+ x) = 0.5 $. In questo punto, la pendenza della curva, ovvero la derivata della funzione logistica, è massima e raggiunge il valore $ / 4 $.\nPer esempio, nel modello con $ = -1.778 $ e $ = 1.003 $, dividendo \\(\\beta\\) per 4 otteniamo circa 0.25. Questo valore rappresenta l’aumento massimo, in termini di probabilità, che possiamo aspettarci per un incremento unitario in $ x $, in corrispondenza di $ p = 0.5 $.\nIn sintesi, la regola del dividere per 4 semplifica l’interpretazione dei coefficienti della regressione logistica, fornendo un’indicazione intuitiva di come la variabile indipendente influisce sulla probabilità dell’evento di interesse.\n\n\n91.9.1.2 Scala dei Logit\nNella regressione logistica, la funzione logit rappresenta una relazione lineare tra il logit della probabilità di successo e la variabile indipendente \\(X\\):\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = \\alpha + \\beta x\n\\]\nCon i coefficienti stimati, la funzione logit diventa:\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot x\n\\]\n\n\\(\\alpha = -1.7784477\\): Questo è l’intercetta del modello, il valore del logit quando \\(x = 0\\). Indica che, quando \\(x\\) è 0, il logit della probabilità di successo è \\(-1.7784477\\).\n\\(\\beta = 1.003503126\\): Questo è il coefficiente di \\(x\\) e rappresenta il cambiamento nel logit per ogni incremento unitario in \\(x\\). In altre parole, per ogni incremento di 1 unità in \\(x\\), il logit della probabilità di successo aumenta di circa \\(1.003503126\\).\n\n\n\n91.9.1.3 Odds Ratio\nL’odds ratio (OR) misura il cambiamento relativo nelle odds di successo per un incremento unitario in \\(x\\). È ottenuto esponenziando il coefficiente \\(\\beta\\):\n\\[\n\\text{OR} = e^{\\beta} = e^{1.003503126} \\approx 2.728\n\\]\nUn odds ratio di circa \\(2.728\\) indica che, per ogni incremento unitario in \\(x\\), le odds di successo aumentano di circa \\(172.8\\%\\). In altre parole, l’odds di successo è circa \\(2.728\\) volte maggiore per ogni unità aggiuntiva di \\(x\\).\n\n\n91.9.1.4 Scala delle Probabilità\nPer interpretare l’effetto di \\(\\beta\\) sulla scala delle probabilità, possiamo considerare come la probabilità \\(p\\) cambia in corrispondenza di specifici valori di \\(x\\).\n\nQuando \\(x = 0\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-1.7784477}}{1 + e^{-1.7784477}} \\approx \\frac{0.169} {1 + 0.169} \\approx 0.144\n\\]\nQuindi, la probabilità di successo quando \\(x = 0\\) è circa \\(14.4\\%\\).\n\nPer un incremento unitario in \\(x\\), diciamo \\(x = 1\\):\n\n\\[\n\\log \\left( \\frac{p}{1-p} \\right) = -1.7784477 + 1.003503126 \\cdot 1 \\approx -0.774944574\n\\]\nInvertendo il logit per ottenere \\(p\\):\n\\[\np = \\frac{e^{-0.774944574}}{1 + e^{-0.774944574}} \\approx \\frac{0.461} {1 + 0.461} \\approx 0.316\n\\]\nQuindi, la probabilità di successo quando \\(x = 1\\) è circa \\(31.6\\%\\). Tuttavia questo incremento non è costante per i diversi livelli \\(x\\) e il modo più semplice per mostrare la relazione tra probabilità di successo e la variabile \\(X\\) è quella di generare un grafico come quello che abbimo prodotto in precedenza.\n\n\n\n91.9.2 Riassunto\n\nScala dei Logit: Un incremento unitario in \\(x\\) aumenta il logit della probabilità di successo di \\(1.003503126\\).\nOdds Ratio: Le odds di successo aumentano di circa \\(2.728\\) volte per ogni incremento unitario in \\(x\\).\nScala delle Probabilità: Quando \\(x\\) passa da 0 a 1, la probabilità di successo aumenta da circa \\(14.4\\%\\) a \\(31.6\\%\\). Per la relazione tra ciascun livello \\(x\\) e la probabilità di successo è necessario generare un grafico.\n\nQuesta analisi dimostra come i coefficienti del modello di regressione logistica possono essere interpretati su diverse scale, fornendo un quadro completo della relazione tra la variabile indipendente e la probabilità di successo.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-solo-lintercetta",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-solo-lintercetta",
    "title": "91  Regressione logistica con Stan",
    "section": "91.10 Regressione logistica con solo l’intercetta",
    "text": "91.10 Regressione logistica con solo l’intercetta\nLa regressione lineare con solo l’intercetta è equivalente a stimare una media e la regressione lineare con un singolo predittore binario è equivalente a stimare una differenza tra medie. Allo stesso modo, la regressione logistica con solo l’intercetta è equivalente alla stima di una proporzione.\nEcco un esempio. Un campione casuale di 50 persone viene testato e 10 di loro manifestano una certa caratteristica psicologica. La proporzione è 0.20 con errore standard $ = 0.06 $. In alternativa, possiamo impostare questo come regressione logistica usando Bambi in Python:\n\n# Dati\ny = [0]*40 + [1]*10\ndf = pd.DataFrame({'y': y})\n\n# Modello\nmodel = bmb.Model('y ~ 1', data=df, family='bernoulli')\nfit = model.fit(nuts_sampler=\"numpyro\", random_seed=123)\n\nModeling the probability that y==1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(fit, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.39\n0.35\n-2.05\n-0.73\n0.01\n0.01\n1524.26\n1636.18\n1.0\n\n\n\n\n\n\n\nPossiamo trasformare la previsione nella scala delle probabilità e ottenere un risultato che è essenzialmente lo stesso della stima classica con incertezza di 0.20 ± 0.06.\n\n# Given values\nintercept = -1.4\nerror = 0.35\n\n# Calculate logit^-1(-1.41)\np_hat = expit(intercept)\n\n# Calculate logit^-1(-1.41 ± 0.36)\nlower_bound = expit(intercept - error)\nupper_bound = expit(intercept + error)\n\nprint(f'p_hat: {p_hat:.3f}, Lower bound: {lower_bound:.3f}, Upper bound: {upper_bound:.3f}')\n\np_hat: 0.198, Lower bound: 0.148, Upper bound: 0.259\n\n\nLe stime classiche e quelle della regressione logistica differiscono leggermente, in parte perché Bambi usa una distribuzione a priori e in parte perché l’errore standard classico è solo un’approssimazione all’incertezza inferenziale derivante dai dati discreti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "href": "chapters/glm/03_stan_logistic_regr.html#regressione-logistica-con-un-singolo-predittore-binario",
    "title": "91  Regressione logistica con Stan",
    "section": "91.11 Regressione logistica con un singolo predittore binario",
    "text": "91.11 Regressione logistica con un singolo predittore binario\nLa regressione logistica su una variabile indicatrice è equivalente a un confronto di proporzioni. Per un esempio semplice, consideriamo i test per una malattia su campioni provenienti da due popolazioni diverse, dove 10 su 50 individui della popolazione A risultano positivi, rispetto a 20 su 60 della popolazione B. La stima classica è 0.13 con errore standard di 0.08. Ecco come impostare questo caso come regressione logistica utilizzando Bambi in Python:\n\n# Dati\nx = [0] * 50 + [1] * 60\ny = [0] * 40 + [1] * 10 + [0] * 40 + [1] * 20\ndf = pd.DataFrame({'x': x, 'y': y})\n\n# Definire il modello\nmodel = bmb.Model('y ~ x', data=df, family='bernoulli')\n\n# Adattare il modello con un seed\nfit = model.fit(nuts_sampler=\"numpyro\", random_seed=123)\n\nModeling the probability that y==1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Visualizzare i risultati del fit\naz.summary(fit, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nIntercept\n-1.41\n0.36\n-2.07\n-0.74\n0.01\n0.01\n2661.46\n2476.84\n1.0\n\n\nx\n0.71\n0.45\n-0.09\n1.60\n0.01\n0.01\n3115.18\n2554.46\n1.0\n\n\n\n\n\n\n\nPer ottenere l’inferenza per la differenza di probabilità, confrontiamo le previsioni sulla scala delle probabilità per $ x = 0 $ e $ x = 1 $:\n\n# Given values\nintercept = -1.41\nslope = 0.71\n\n# Calculate probabilities for x = 0 and x = 1\nlogit_0 = intercept\nlogit_1 = intercept + slope\n\nprob_0 = expit(logit_0)\nprob_1 = expit(logit_1)\n\n# Calculate the difference in probabilities\ndiff = prob_1 - prob_0\n\nprob_0, prob_1, diff\nprint(f'prob_0: {prob_0:.3f}, prob_1: {prob_1:.3f}, difference: {diff:.3f}')\n\nprob_0: 0.196, prob_1: 0.332, difference: 0.136\n\n\nPer l’errore standard possiamo eseguire la seguente simulazione:\n\n# Given values\nintercept_mean = -1.41\nslope_mean = 0.71\nintercept_sd = 0.36\nslope_sd = 0.45\n\n# Number of simulations\nnum_simulations = 10000\n\n# Generate samples of the coefficients\nintercept_samples = np.random.normal(intercept_mean, intercept_sd, num_simulations)\nslope_samples = np.random.normal(slope_mean, slope_sd, num_simulations)\n\n# Calculate the corresponding probabilities\nprob_0_samples = expit(intercept_samples)\nprob_1_samples = expit(intercept_samples + slope_samples)\n\n# Calculate the difference in probabilities for each sample\ndiff_samples = prob_1_samples - prob_0_samples\n\n# Calculate the mean and standard deviation of the differences\nmean_diff = np.mean(diff_samples)\nstd_diff = np.std(diff_samples)\n\nmean_diff, std_diff\nprint(f'difference: {mean_diff:.3f}, standard error: {std_diff:.3f}')\n\ndifference: 0.140, standard error: 0.096\n\n\nSebbene abbiamo ottenuto un errore standard di circa 0.095, che è leggermente diverso dall’errore standard di 0.08 menzionato inizialmente, questo valore riflette l’incertezza nelle stime dei coefficienti fornite. Potrebbero esserci delle variazioni dovute al metodo di campionamento utilizzato. Tuttavia, questi calcoli dimostrano l’approccio corretto per stimare l’errore standard utilizzando la simulazione Monte Carlo con le deviazioni standard dei coefficienti stimati. ​",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/03_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/03_stan_logistic_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "91  Regressione logistica con Stan",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanp\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanp: not installed\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz      : 0.18.0\nseaborn    : 0.13.2\nmatplotlib : 3.9.1\nscipy      : 1.14.0\nstatsmodels: 0.14.2\npandas     : 2.2.2\nnumpy      : 1.26.4\nbambi      : 0.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>Regressione logistica con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html",
    "href": "chapters/glm/04_stan_poisson_regr.html",
    "title": "92  Regressione di Poisson con Stan",
    "section": "",
    "text": "Introduzione\nIn questo tutorial, approfondiremo l’utilizzo di CmdStanPy per condurre un’analisi di regressione di Poisson. La regressione di Poisson rappresenta una forma di modello lineare generalizzato impiegato nell’analisi di regressione per modellare dati di conteggio. Essa si basa sull’assunzione che la variabile di risposta Y segua una distribuzione di Poisson, con il logaritmo del suo valore atteso modellabile attraverso una combinazione lineare di parametri sconosciuti.\nIn questo capitolo, dopo aver investigato il calcolo della media a posteriori e dell’incertezza correlata al tasso di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno, ci interrogheremo se vi siano evidenze di una tendenza all’aumento di tale tasso nel corso del tempo.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html#introduzione-alla-regressione-di-poisson",
    "href": "chapters/glm/04_stan_poisson_regr.html#introduzione-alla-regressione-di-poisson",
    "title": "92  Regressione di Poisson con Stan",
    "section": "92.1 Introduzione alla Regressione di Poisson",
    "text": "92.1 Introduzione alla Regressione di Poisson\nUna variabile casuale di Poisson viene utilizzata per modellare conteggi. Poiché una variabile casuale di Poisson è un conteggio, il suo valore minimo è zero e, in teoria, il massimo è illimitato. L’obiettivo è modellare il parametro principale, λ, il numero medio di occorrenze per unità di tempo o spazio, come funzione di una o più covariate.\nIl modello di regressione di Poisson si basa sulla distribuzione di Poisson, una distribuzione probabilistica che descrive eventi con una probabilità costante di occorrenza in un intervallo di tempo o spazio definito. La funzione di probabilità della distribuzione di Poisson è definita come:\n\\[ Pr(Y = y) = \\frac{\\mu^y e^{-\\mu}}{y!}, \\]\ndove \\(\\mu\\) rappresenta il numero atteso di eventi nell’intervallo considerato e \\(y\\) i possibili conteggi di eventi, assumendo valori interi non negativi (0, 1, 2, …). È importante notare che in questa distribuzione, il valore atteso \\(\\mu\\) coincide anche con la varianza.\nNel modello di regressione di Poisson, si cerca di collegare il valore atteso di un conteggio, \\(\\mu_i\\), a un insieme di variabili esplicative (come età, sesso, sintomi di depressione, ecc.) tramite una relazione funzionale. A differenza dei modelli lineari tradizionali, che possono produrre stime di conteggi negative e quindi non sensate, la regressione di Poisson utilizza una funzione di legame esponenziale per garantire che le stime dei conteggi siano sempre non negative. La relazione è espressa come segue:\n\\[ \\mu_i = e^{\\beta_0 + \\beta_1 x_i}, \\]\ndove \\(\\beta_0\\) e \\(\\beta_1\\) sono i parametri del modello che devono essere stimati. Questi parametri quantificano l’effetto delle variabili esplicative sui conteggi previsti. L’utilizzo della funzione esponenziale come legame assicura che il valore atteso \\(\\mu_i\\) sia sempre positivo.\nPer costruire il modello di regressione di Poisson:\n\nSi assume che il conteggio degli eventi per un dato livello della variabile esplicativa segua una distribuzione di Poisson, con un parametro di tasso (\\(\\mu_i\\)) specifico per ciascuna osservazione.\nSi definisce un predittore lineare, \\(\\eta_i\\), come una combinazione lineare dei coefficienti del modello (\\(\\beta\\)) e delle variabili esplicative (\\(x_i\\)).\nSi applica la funzione di legame esponenziale per stabilire che il tasso medio di eventi, \\(\\mu_i\\), sia determinato dal predittore lineare, così che \\(\\mu_i = e^{\\eta_i} = e^{\\alpha + \\beta x_i}\\).\n\nQuesti passaggi consentono di costruire un modello che non solo predice accuratamente i conteggi, ma offre anche insight significativi sull’effetto delle variabili esplicative studiate.\nConsideriamo il seguente esempio. Supponiamo di voler studiare il numero medio di episodi di comportamento aggressivo tra adolescenti in una scuola. In questo caso, il parametro \\(\\lambda_i\\) rappresenta il numero medio di episodi di comportamento aggressivo per lo studente \\(i\\), e ci aspettiamo di mostrare che la variabilità tra gli studenti di \\(\\lambda_i\\) può essere spiegata da variabili come il livello di stress, il supporto familiare, o la presenza di sintomi depressivi. Utilizzando la regressione di Poisson, possiamo modellare il numero medio di episodi di comportamento aggressivo come:\n\\[ \\lambda_i = e^{\\beta_0 + \\beta_1 \\text{Stress}_i + \\beta_2 \\text{SupportoFamiliare}_i + \\beta_3 \\text{Depressione}_i}, \\]\ndove \\(\\beta_0\\), \\(\\beta_1\\), \\(\\beta_2\\) e \\(\\beta_3\\) sono i parametri del modello che quantificano l’effetto delle rispettive variabili esplicative sui conteggi di comportamenti aggressivi previsti.\n\n92.1.1 Assunzioni della Regressione di Poisson\nAnalogamente alla regressione lineare, l’uso della regressione di Poisson per fare inferenze richiede delle assunzioni sul modello:\n\nRisposta di Poisson: La variabile di risposta è un conteggio per unità di tempo o spazio, descritta da una distribuzione di Poisson.\nIndipendenza: Le osservazioni devono essere indipendenti l’una dall’altra.\nMedia = Varianza: Per definizione, la media di una variabile casuale di Poisson deve essere uguale alla sua varianza.\nLinearità: Il logaritmo del tasso medio, log(λ), deve essere una funzione lineare di \\(x\\).\n\n\n\n92.1.2 Un Esempio con Stan\nPer fare un esempio, consideriamo nuovamente i dati corrispondenti alle sparatorie mortale negli Stati Uniti ad opera di agenti di polizia, a partire dal 1° gennaio 2015.\nImportiamo i dati.\n\nurl = \"https://raw.githubusercontent.com/washingtonpost/data-police-shootings/master/v2/fatal-police-shootings-data.csv\"\nfps_dat = pd.read_csv(url)\nfps_dat.head()\n\n\n\n\n\n\n\n\nid\ndate\nthreat_type\nflee_status\narmed_with\ncity\ncounty\nstate\nlatitude\nlongitude\nlocation_precision\nname\nage\ngender\nrace\nrace_source\nwas_mental_illness_related\nbody_camera\nagency_ids\n\n\n\n\n0\n3\n2015-01-02\npoint\nnot\ngun\nShelton\nMason\nWA\n47.246826\n-123.121592\nnot_available\nTim Elliot\n53.0\nmale\nA\nnot_available\nTrue\nFalse\n73\n\n\n1\n4\n2015-01-02\npoint\nnot\ngun\nAloha\nWashington\nOR\n45.487421\n-122.891696\nnot_available\nLewis Lee Lembke\n47.0\nmale\nW\nnot_available\nFalse\nFalse\n70\n\n\n2\n5\n2015-01-03\nmove\nnot\nunarmed\nWichita\nSedgwick\nKS\n37.694766\n-97.280554\nnot_available\nJohn Paul Quintero\n23.0\nmale\nH\nnot_available\nFalse\nFalse\n238\n\n\n3\n8\n2015-01-04\npoint\nnot\nreplica\nSan Francisco\nSan Francisco\nCA\n37.762910\n-122.422001\nnot_available\nMatthew Hoffman\n32.0\nmale\nW\nnot_available\nTrue\nFalse\n196\n\n\n4\n9\n2015-01-04\npoint\nnot\nother\nEvans\nWeld\nCO\n40.383937\n-104.692261\nnot_available\nMichael Rodriguez\n39.0\nmale\nH\nnot_available\nFalse\nFalse\n473\n\n\n\n\n\n\n\n\n# Convert date\nfps_dat[\"date\"] = pd.to_datetime(fps_dat[\"date\"])\n\n# Create a new column 'year' to store the year information from the 'date' column\nfps_dat[\"year\"] = fps_dat[\"date\"].dt.year\n\nfps_dat.columns\n\nIndex(['id', 'date', 'threat_type', 'flee_status', 'armed_with', 'city',\n       'county', 'state', 'latitude', 'longitude', 'location_precision',\n       'name', 'age', 'gender', 'race', 'race_source',\n       'was_mental_illness_related', 'body_camera', 'agency_ids', 'year'],\n      dtype='object')\n\n\n\n# Filter out rows with year equal to 2024\nfps = fps_dat[fps_dat[\"year\"] != 2024]\n\n# Count occurrences of each year in fps\nyear_counts = fps[\"year\"].value_counts()\nprint(year_counts)\n\nyear\n2023    1161\n2022    1095\n2021    1050\n2020    1020\n2019     996\n2015     995\n2018     992\n2017     984\n2016     959\nName: count, dtype: int64\n\n\n\nyears = year_counts.index.to_numpy()\nyear = years - 2019\nyear\n\narray([ 4,  3,  2,  1,  0, -4, -1, -2, -3], dtype=int32)\n\n\n\ncounts = year_counts.values\ncounts\n\narray([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959])\n\n\nCreiamo un dizionario con i dati nel formato richiesto per CmdStan.\n\nstan_data = {\n    \"N\" : len(year),\n    \"y\" : counts,\n    \"x\" : year \n}\nstan_data\n\n{'N': 9,\n 'y': array([1161, 1095, 1050, 1020,  996,  995,  992,  984,  959]),\n 'x': array([ 4,  3,  2,  1,  0, -4, -1, -2, -3], dtype=int32)}\n\n\nCompiliamo il modello e stampiamo il codice Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"poisson_regression.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;  // Numero di osservazioni\n  array[N] int&lt;lower=0&gt; y;  // Dati di conteggio (frequenze)\n  vector[N] x;  // Variabile predittore (anni, già standardizzata)\n}\n\nparameters {\n  real alpha;  // Intercetta\n  real beta;  // Pendenza\n}\n\nmodel {\n  // Priors debolmente informativi\n  alpha ~ normal(0, 10);\n  beta ~ normal(0, 10);\n\n  // Modello di regressione di Poisson\n  y ~ poisson_log(alpha + beta * x);\n}\n\ngenerated quantities {\n  array[N] int&lt;lower=0&gt; y_pred = poisson_log_rng(alpha + beta * x);\n}\n\n\n\nQuesto modello Stan specifica una regressione di Poisson per dati di conteggio, dove l’obiettivo è modellare il numero di eventi (espressi dalla variabile y) in funzione di una variabile predittiva x (in questo caso, anni standardizzati). Il modello è strutturato in quattro blocchi principali: data, parameters, model, e generated quantities. Ecco una panoramica dettagliata di ciascuna sezione e il suo ruolo nel contesto del modello:\n\n\n92.1.3 Blocco data\n\nN: Un intero che specifica il numero totale di osservazioni nel dataset. Serve a definire le dimensioni degli array e dei vettori utilizzati nel modello.\ny: Un array di interi che rappresenta i dati di conteggio osservati. Ogni elemento in y corrisponde al numero di eventi registrati in ciascuna delle N unità di osservazione.\nx: Un vettore di lunghezza N che contiene i valori della variabile predittiva (ad esempio, anni).\n\n\n\n92.1.4 Blocco parameters\n\nalpha: Un parametro reale che rappresenta l’intercetta del modello. In un contesto di regressione di Poisson, alpha corrisponde al logaritmo del tasso atteso di eventi quando la variabile predittiva x è zero.\nbeta: Un parametro reale che rappresenta la pendenza o il coefficiente della variabile predittiva x. Questo parametro indica come il logaritmo del tasso atteso di eventi cambia in risposta a variazioni di una unità in x.\n\n\n\n92.1.5 Blocco model\nI priors per alpha e beta sono definiti come distribuzioni normali con media 0 e deviazione standard 10, rappresentando priors debolmente informativi che permettono ai dati di guidare principalmente l’inferenza sui parametri.\nNella tradizionale regressione di Poisson, il parametro \\(\\mu_i\\) (il tasso medio di eventi per l’unità osservata) è collegato alle variabili esplicative tramite una funzione esponenziale: \\(\\mu_i = e^{\\eta_i} = e^{\\beta_0 + \\beta_1 x_i}\\). Questa trasformazione assicura che il valore predetto di \\(\\mu_i\\) sia sempre positivo, indipendentemente dai valori assunti dalle variabili esplicative, una necessità quando si modellano conteggi che non possono essere negativi.\nLa funzione poisson_log, invece di lavorare direttamente con \\(\\mu_i\\) come nella forma esponenziale \\(e^{\\eta_i}\\), opera sul logaritmo di \\(\\mu_i\\). Questo significa che la funzione specifica il logaritmo del tasso medio di eventi come lineare rispetto ai predittori. In altre parole, anziché modellare \\(\\mu_i\\) direttamente e poi trasformarlo, si modella il logaritmo di \\(\\mu_i\\) (che è \\(\\log(\\mu_i)\\)) come funzione lineare delle variabili esplicative: \\(\\log(\\mu_i) = \\eta_i = \\beta_0 + \\beta_1 x_i\\).\nQuesta specificazione ha diversi vantaggi:\n\nStabilità numerica: Lavorare con il logaritmo di \\(\\mu_i\\) può ridurre i problemi di stabilità numerica che talvolta emergono quando si lavora con valori estremamente grandi o piccoli di \\(\\mu_i\\).\nInterpretazione diretta dei parametri: Poiché si modella il logaritmo di \\(\\mu_i\\), i coefficienti (come \\(\\beta_1\\)) possono essere interpretati in termini di variazione percentuale. Un incremento di una unità in \\(x_i\\) è associato a un moltiplicatore esponenziale di \\(e^{\\beta_1}\\) sul tasso medio di eventi.\n\nNel codice Stan, la linea y ~ poisson_log(alpha + beta * x); specifica quindi che i dati di conteggio y seguono una distribuzione di Poisson, con il logaritmo del parametro di tasso (\\(\\log(\\mu_i)\\)) modellato come una funzione lineare di x attraverso alpha + beta * x.\n\n\n92.1.6 Blocco generated quantities\n\ny_pred: Un array di interi che contiene valori predetti generati dalla distribuzione di Poisson. Per ogni osservazione, poisson_log_rng genera un valore di conteggio casuale basato sul tasso atteso calcolato come alpha + beta * x. Questi valori predetti possono essere utilizzati per verifiche predittive posteriori o per ottenere una distribuzione predittiva degli eventi.\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo un sommario della distribuzione a posteriori per i parametri.\n\naz.summary(fit, var_names=([\"alpha\", \"beta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n6.934\n0.011\n6.911\n6.954\n0.0\n0.0\n2461.0\n2201.0\n1.0\n\n\nbeta\n0.020\n0.004\n0.012\n0.028\n0.0\n0.0\n4171.0\n3115.0\n1.0\n\n\n\n\n\n\n\nL’ess_bulk (Effective Sample Size per il bulk dell’estimatore) e ess_tail (Effective Sample Size per la coda dell’estimatore) sono relativamente alti per entrambi i parametri, indicando che il campionamento ha fornito una buona approssimazione della distribuzione a posteriori. Inoltre, il valore di r_hat vicino a 1.0 per entrambi i parametri suggerisce che il campionamento ha raggiunto la convergenza, indicando che i risultati sono affidabili.\n\n\n92.1.7 Interpretazione del Parametro alpha\nIl parametro alpha è una stima del logaritmo del tasso atteso di eventi (frequenze) quando il valore della variabile esplicativa x è zero, ossia quando si trova nella sua media, che in questo contesto è stata standardizzata e centrata sull’anno 2019. Il valore medio di alpha è 6.934, indicando che il logaritmo naturale del tasso atteso di eventi quando x = 0 è circa 6.934.\nL’intervallo di alta densità (HDI) del 95% per alpha va da 6.912 a 6.954, fornendo un intervallo di stime plausibili per il valore di alpha con un alto grado di certezza statistica.\nPer interpretare alpha in termini di tasso atteso di eventi, usiamo exp(alpha). Questo trasforma il logaritmo del tasso di eventi nel tasso effettivo. Ad esempio, exp(6.934) dà il tasso atteso di eventi per l’anno di riferimento 2019.\n\nnp.exp(6.934)\n\n1026.5921464104808\n\n\n\n\n92.1.8 Interpretazione del Parametro beta\nIl parametro beta rappresenta la variazione logaritmica attesa nelle frequenze per ogni incremento unitario in x (l’anno, in questo caso). Un valore medio di beta pari a 0.020, con un HDI del 95% che va da 0.012 a 0.028, suggerisce una tendenza positiva: all’aumentare degli anni, ci si aspetta un incremento nelle frequenze degli eventi.\nUtilizzando il link logaritmico del modello, l’effetto di un incremento di un anno su x si traduce in una moltiplicazione del tasso di frequenza per exp(beta). Quindi, un aumento di un anno implica che il tasso di frequenza sarà moltiplicato per exp(0.020), che è approssimativamente 1.02, indicando un aumento previsto del 2% nelle frequenze per ogni anno successivo.\n\nnp.exp([0.020, 0.012, 0.028])\n\narray([1.02020134, 1.01207229, 1.02839568])\n\n\n\n\n92.1.9 Calcolo dell’Aumento Effettivo in Frequenza\nPer calcolare l’aumento effettivo in frequenza per ogni anno, utilizziamo la seguente formula:\n\\[ \\text{Aumento atteso} = \\exp(\\alpha) \\times (\\exp(\\beta) - 1) \\]\n\nCalcolo del Fattore di Moltiplicazione: exp(beta) è il fattore di moltiplicazione che descrive come cambia il tasso di frequenza con un incremento di un anno. Con beta = 0.020, exp(beta) è circa 1.0202.\nDeterminazione dell’Aumento Attuale in Frequenza: exp(alpha) fornisce il tasso di base delle frequenze quando x = 0. Moltiplicando questo tasso di base per (\\exp(\\beta) - 1), otteniamo l’aumento effettivo in frequenza per ogni anno aggiuntivo. Sottraendo 1 a exp(beta), otteniamo l’incremento percentuale dovuto solamente all’aumento di un anno.\n\nQuesta metodologia fornisce un modo intuitivo e statistico per quantificare come le variabili nel tempo influenzano la frequenza degli eventi, permettendo di fare previsioni basate su modelli storici e tendenze osservate.\n\n# Parametri del modello\nalpha_mean = 6.934\nbeta_mean = 0.020\n\n# Calcolo del tasso di frequenza base per l'anno centrato (exp(alpha))\ntasso_base = np.exp(alpha_mean)\n\n# Calcolo del fattore di moltiplicazione per l'aumento (exp(beta))\nfattore_moltiplicazione = np.exp(beta_mean)\n\n# Aumento atteso in frequenza per un anno\naumento_atteso = tasso_base * (fattore_moltiplicazione - 1)\naumento_atteso\n\n20.738537018435174\n\n\nBasandosi sul modello di regressione di Poisson, si stima un incremento medio di circa 20.74 nel numero di sparatorie fatali da parte della polizia negli Stati Uniti per ogni anno aggiuntivo. In altre parole, il modello prevede che, anno dopo anno, il numero di tali incidenti potrebbe crescere di circa 21 casi. Questa previsione riflette una dinamica esponenziale tra il passare degli anni e l’aumento della frequenza assoluta di sparatorie fatali, come evidenziato dai dati analizzati.\n\n\n92.1.10 Posterior-Predictive Check\nEsaminiamo il posterior-predictive check per il modello esaminato:\n\ny_observed = stan_data[\"y\"]\n\nidata = az.from_cmdstanpy(\n    posterior=fit,\n    posterior_predictive='y_pred',\n    observed_data={'y': y_observed}\n)\n\n\n_ = az.plot_ppc(idata, data_pairs={'y': 'y_pred'}, kind='cumulative')",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/04_stan_poisson_regr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/04_stan_poisson_regr.html#informazioni-sullambiente-di-sviluppo",
    "title": "92  Regressione di Poisson con Stan",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Fri Aug 02 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\nscipy     : 1.14.0\nseaborn   : 0.13.2\nnumpy     : 1.26.4\npandas    : 2.2.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>Regressione di Poisson con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_simchon_2023.html",
    "href": "chapters/glm/05_simchon_2023.html",
    "title": "93  Tweets",
    "section": "",
    "text": "93.1 Introduzione\nIl rapporto tra linguaggio e pensiero è stato a lungo un argomento di grande interesse per studiosi e artisti. Una delle voci più influenti in questo dibattito è stata quella di George Orwell, che, attraverso il suo romanzo 1984, ha rappresentato una distopia in cui un regime totalitario utilizza il linguaggio per limitare la capacità di pensiero della popolazione. In particolare, Orwell suggeriva nel suo saggio “Politics and the English Language” che alcune strutture linguistiche, come l’uso della forma passiva, possono facilitare ideologie oppressive, riducendo la percezione di agenzia dell’individuo.\nOrwell osservava che le frasi in forma attiva e passiva, pur descrivendo la stessa azione, differiscono per l’enfasi posta sul soggetto dell’azione: la forma attiva lo evidenzia, mentre la forma passiva tende a nasconderlo o eliminarlo. Questo utilizzo del linguaggio non agentivo, secondo Orwell, potrebbe essere strumentalizzato per diminuire l’autonomia e il potere delle persone. Nonostante le sue critiche alla forma passiva, Orwell stesso ha revisionato le prime versioni di 1984 per includere numerose costruzioni passive, presumibilmente per enfatizzare l’idea di un mondo in cui gli individui non hanno controllo sulle proprie vite.\nOltre al suo utilizzo letterario, diversi studiosi sociali hanno sostenuto che l’uso del linguaggio passivo, e più in generale del linguaggio non agentivo, è strettamente correlato al livello di agenzia personale percepito. L’agenzia personale si riferisce alla capacità degli individui di esercitare il controllo sul mondo esterno e su se stessi, e si manifesta in tre aspetti principali: il controllo delle proprie azioni, il controllo dei risultati e delle risorse (come il potere sociale), e la percezione soggettiva di possedere questi controlli.\nStudi psicologici precedenti hanno dimostrato che la formulazione linguistica può influenzare il livello di agenzia attribuito agli altri. Molti di questi studi si sono basati su analisi discorsive qualitative. In questo contesto, il presente studio si propone di esplorare se l’uso del linguaggio agentivo è un riflesso dell’agenzia personale degli individui. In particolare, si è esaminato se diversi fattori, come il potere sociale, il rango sociale e la partecipazione a un forum sulla depressione, influenzano l’uso della forma passiva.\nNel Studio 3, che qui verrà analizzato ulteriormente, Simchon et al. (2023) hanno investigato se il linguaggio utilizzato in un forum dedicato alla depressione fosse caratterizzato da una maggiore frequenza di uso della forma passiva, ipotizzando che ciò fosse un riflesso della perdita di agenzia che molte persone con depressione sperimentano. La depressione è una condizione mentale debilitante associata a episodi ricorrenti di umore depresso, anedonia, bassa autostima e disperazione, spesso accompagnata da un senso di mancanza di controllo sugli eventi negativi della propria vita.\nNel contesto di comunità online, le persone che soffrono di depressione spesso cercano supporto emotivo e condivisione delle esperienze. Di conseguenza, Simchon et al. (2023) hanno analizzato grandi dataset provenienti da Reddit per testare se i partecipanti a forum sulla depressione utilizzano la forma passiva più frequentemente rispetto a utenti di altre comunità. I risultati hanno mostrato che il linguaggio usato nel forum sulla depressione era significativamente meno agentivo rispetto a quello di altri forum, supportando l’ipotesi di una correlazione tra depressione e ridotta agentività linguistica.\nQuesti risultati non solo replicano la relazione tra l’uso di pronomi personali e depressione, ma suggeriscono anche che livelli inferiori di agenzia linguistica possono essere indicativi di una salute mentale deteriorata. Pertanto, comprendere come l’agenzia personale influenzi l’uso del linguaggio agentivo può fornire nuove prospettive sia per la ricerca psicologica sia per gli interventi clinici.\nQui ci concentreremo sull’analisi dell’Esperimento 3. La variabile dipendente è passive_count. Questa rappresenta il numero di verbi passivi utilizzati da ciascun partecipante. Essendo una variabile che corrisponde ad una frequenza assoluta (conteggio), il modello di regressione utilizzato dagli autori è una regressione binomiale negativa, che è adatta per i dati di conteggio con overdispersione (varianza maggiore della media). Il modello utilizzato dagli autori include le seguenti variabili indipendenti.\nNell’analisi considerata qui, I_c e wc_c sono state standardizzate.\nIl modello include anche l’interazione groupdep:I_c. L’interazione verifica se l’effetto del linguaggio autoreferenziale (I_c) sull’uso dei verbi passivi varia tra i gruppi (controllo vs. depressione).",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>Tweets</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_simchon_2023.html#introduzione",
    "href": "chapters/glm/05_simchon_2023.html#introduzione",
    "title": "93  Tweets",
    "section": "",
    "text": "group: Questa è una variabile categorica che rappresenta il gruppo di appartenenza dei partecipanti. Esistonodue livelli per questa variabile: control (gruppo di controllo) e dep (gruppo con depressione). Questa variabile viene utilizzata per verificare se ci sono differenze nell’uso dei verbi passivi tra i due gruppi.\nI_c: Questa è una variabile continua che rappresenta l’intensità dell’uso di un linguaggio autoreferenziale. Valori più alti indicano un uso maggiore.\nwc_c è un’altra variabile continua,che sembra fornisce una misura della frequenza di parole in ciascun post. Viene utilizzata per controllare gli effetti del numero totale di parole prodotte dai partecipanti.\n\n\n\n\n93.1.1 Interpretazione dei risultati del modello\nIl modello considerato ha la forma passive_count ~ group * I_c + wc_c. L’analisi bayesiana dei dati indica che:\n\nEffetto principale di groupdep: L’analisi suggerisce che, quando si controlla per il numero totale di parole (wc_c), il gruppo “dep” tende ad avere un conteggio più alto di verbi passivi rispetto al gruppo di controllo. Questo è supportato dalla distribuzione posteriore che mostra una maggiore concentrazione di valori positivi per il parametro associato a groupdep.\nEffetto di I_c: L’effetto di I_c (linguaggio autoreferenziale) sul conteggio dei verbi passivi, una volta controllato per wc_c, non appare chiaramente delineato. La distribuzione posteriore del parametro associato a I_c è centrata attorno a zero, suggerendo che non ci sono evidenze forti per un effetto positivo o negativo di I_c.\nEffetto di wc_c: Il numero totale di parole (wc_c) sembra avere un impatto consistente sul conteggio dei verbi passivi. La distribuzione posteriore del parametro associato a wc_c mostra una chiara concentrazione verso valori positivi, suggerendo che un maggiore numero di parole è associato a un maggiore uso di verbi passivi.\nInterazione groupdep:I_c: L’interazione tra group e I_c non mostra un effetto evidente sul conteggio dei verbi passivi quando si controlla per wc_c. La distribuzione posteriore del parametro dell’interazione è anch’essa centrata attorno a zero, indicando che non ci sono evidenze per un’interazione sostanziale tra il gruppo e il linguaggio autoreferenziale.\n\nQuesti risultati indicano che l’uso dei verbi passivi è influenzato da una combinazione di fattori, tra cui il gruppo di appartenenza e il numero totale di parole utilizzate.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>Tweets</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_simchon_2023.html#bayesian-model-building-interface",
    "href": "chapters/glm/05_simchon_2023.html#bayesian-model-building-interface",
    "title": "93  Tweets",
    "section": "93.2 BAyesian Model-Building Interface",
    "text": "93.2 BAyesian Model-Building Interface\nLeggiamo i dati utilizzati nel capitolo precedente.\n\ndata_file = os.path.join(project_directory, \"data\", \"simchon_2023_study3a.csv\")\nd = pd.read_csv(data_file)\n\n\ndf = d[d[\"passive_count\"] &lt; 11]\n\n# Rimuovi le colonne 'I_c' e 'wc_c'\ndf.drop([\"I_c\", \"wc_c\"], axis=1, inplace=True)\n\n# Verifica il risultato\nprint(df.head())\n\n       id group  passive_count  word_count  I_liwc\n0  hzx393   dep              1          67       5\n1  hzx265   dep              1         126      23\n2  hzx1c8   dep              0         149      14\n3  hzx0be   dep              1          74       4\n4  hzwyua   dep              1          56       5\n\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/3816525779.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df.drop([\"I_c\", \"wc_c\"], axis=1, inplace=True)\n\n\n\nfrom sklearn.preprocessing import StandardScaler\n\n# Seleziona le colonne da standardizzare\ncolumns_to_standardize = [\"word_count\", \"I_liwc\"]\n\n# Crea un'istanza di StandardScaler\nscaler = StandardScaler()\n\n# Applica la standardizzazione solo sulle colonne selezionate\ndf[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n\n# Rinomina la colonna 'I_liwc' a 'self_ref_lang'\ndf.rename(columns={\n    \"I_liwc\": \"I_c\",\n    \"word_count\": \"wc_c\"\n    }, inplace=True)\n\n# Verifica il risultato\nprint(df.head())\n\n       id group  passive_count      wc_c       I_c\n0  hzx393   dep              1 -0.524040 -0.549527\n1  hzx265   dep              1 -0.203384  0.351386\n2  hzx1c8   dep              0 -0.078382 -0.099071\n3  hzx0be   dep              1 -0.485996 -0.599578\n4  hzwyua   dep              1 -0.583824 -0.549527\n\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/2844295889.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/2844295889.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df.rename(columns={\n\n\n\n# Define the model using Bambi\nmodel = bmb.Model(\"passive_count ~ group * I_c + wc_c\", data=df, family=\"negativebinomial\")\n\nSul lato sinistro della tilde (∼), abbiamo la variabile dipendente, e sul lato destro, le variabili indipendenti. Con questa sintassi, stiamo semplicemente specificando la media (μ nel modello lm di PyMC). Per impostazione predefinita, Bambi assume che la verosimiglianza sia gaussiana; è possibile modificarla con l’argomento family. La sintassi della formula non specifica la distribuzione delle priors, ma solo come sono associate le variabili dipendenti e indipendenti. Bambi definirà automaticamente delle priors (molto) debolmente informative per noi. Possiamo ottenere ulteriori informazioni stampando il modello Bambi.\n\nprint(model)\n\n       Formula: passive_count ~ group * I_c + wc_c\n        Family: negativebinomial\n          Link: mu = log\n  Observations: 8645\n        Priors: \n    target = mu\n        Common-level effects\n            Intercept ~ Normal(mu: 0.0, sigma: 4.2886)\n            group ~ Normal(mu: 0.0, sigma: 5.2627)\n            I_c ~ Normal(mu: 0.0, sigma: 2.5)\n            group:I_c ~ Normal(mu: 0.0, sigma: 2.8047)\n            wc_c ~ Normal(mu: 0.0, sigma: 2.5)\n        \n        Auxiliary parameters\n            alpha ~ HalfCauchy(beta: 1.0)\n\n\n\nmodel.build()\nmodel.graph()\n\n\n\n\n\n\n\n\nSe vogliamo procedere con un’ispezione visiva dei prior dei parametri del modello usiamo:\nEseguiamo il campionamento MCMC.\n\ntrace = model.fit(\n    tune=2000,\n    draws=1000,\n    nuts_sampler=\"numpyro\",\n    idata_kwargs={\"log_likelihood\": True}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(trace, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI_c\n-0.07\n0.05\n-0.16\n0.03\n0.0\n0.0\n1778.50\n1930.11\n1.0\n\n\nIntercept\n-0.39\n0.03\n-0.45\n-0.32\n0.0\n0.0\n2320.60\n2365.65\n1.0\n\n\nalpha\n2.10\n0.10\n1.91\n2.28\n0.0\n0.0\n2987.03\n2463.13\n1.0\n\n\ngroup[dep]\n0.21\n0.04\n0.13\n0.28\n0.0\n0.0\n2508.87\n2688.34\n1.0\n\n\ngroup:I_c[dep]\n-0.05\n0.05\n-0.14\n0.03\n0.0\n0.0\n2053.27\n2463.19\n1.0\n\n\nwc_c\n0.76\n0.03\n0.70\n0.81\n0.0\n0.0\n2611.69\n2458.39\n1.0\n\n\n\n\n\n\n\nIl modello specificato è:\n[ * I_c + wc_c ]\ncon una distribuzione binomiale negativa. Questo modello ha lo scopo di prevedere il passive_count (il numero di verbi ausiliari passivi usati dai partecipanti) in base a:\n\ngroup: Una variabile categorica che indica il gruppo di appartenenza dei partecipanti (ad esempio, controllo vs. depressione, rappresentato qui come group[dep]).\nI_c: Una variabile continua che rappresenta il linguaggio autoreferenziale.\nwc_c: Una variabile continua che rappresenta il conteggio delle parole, centrata.\ngroup:I_c: Un termine di interazione tra group e I_c, che indica come la relazione tra I_c e passive_count varia tra i gruppi.\n\nLa distribuzione binomiale negativa è scelta perché passive_count è una variabile di conteggio, e questa distribuzione è appropriata quando i dati mostrano sovradispersione (cioè, la varianza è maggiore della media).\n\n93.2.1 Interpretazione dei Coefficienti\nI coefficienti del modello di regressione sono riassunti con la loro media a posteriori, deviazione standard (sd), intervallo ad alta densità (HDI) al 3% e 97%, errore standard Monte Carlo della media (mcse_mean), errore standard Monte Carlo della deviazione standard (mcse_sd), dimensione campionaria efficace per il bulk (ess_bulk), dimensione campionaria efficace per la coda (ess_tail) e statistica R-hat (r_hat).\nEcco cosa rappresenta ciascun coefficiente e come interpretarli:\n\nIntercetta (Intercept):\n\nMedia: -0.39\nInterpretazione: L’intercetta rappresenta il logaritmo del conteggio atteso di verbi ausiliari passivi (passive_count) quando tutte le variabili predittive (group[dep], I_c, wc_c, e group:I_c[dep]) sono pari a zero. Poiché questo valore è su scala logaritmica (a causa della funzione di collegamento logaritmica del modello binomiale negativo), un valore di -0.39 indica un conteggio logaritmico di base che corrisponde a exp(-0.39) in termini di conteggi reali.\nHDI 3% a 97%: L’intervallo [-0.45, -0.32] suggerisce che c’è il 94% di probabilità che il vero valore dell’intercetta si trovi in questo intervallo.\n\nLinguaggio Autoreferenziale (I_c):\n\nMedia: -0.07\nInterpretazione: Questo coefficiente indica che, per ogni aumento di una unità in I_c (linguaggio autoreferenziale), il logaritmo del conteggio atteso dei verbi ausiliari passivi diminuisce di 0.07 unità, mantenendo costanti le altre variabili. Questo suggerisce una relazione leggermente negativa, ma l’intervallo HDI dal 3% al 97% (-0.16, 0.03) indica incertezza sul fatto che questo effetto sia effettivamente diverso da zero.\n\nEffetto del Gruppo (group[dep]):\n\nMedia: 0.21\nInterpretazione: Questo coefficiente indica che, per i partecipanti nel gruppo “dep” (gruppo depressione), il logaritmo del conteggio atteso dei verbi ausiliari passivi è superiore di 0.21 unità rispetto ai partecipanti nel gruppo di riferimento (ad esempio, controllo), mantenendo costanti le altre variabili. Questo valore positivo suggerisce che il gruppo depressione tende a utilizzare più verbi ausiliari passivi rispetto al gruppo di controllo.\nHDI 3% a 97%: L’intervallo [0.13, 0.28] mostra una forte certezza che l’effetto è positivo.\n\nInterazione tra Gruppo e Linguaggio Autoreferenziale (group:I_c[dep]):\n\nMedia: -0.05\nInterpretazione: Questo coefficiente rappresenta come l’effetto del linguaggio autoreferenziale (I_c) sul logaritmo del conteggio dei verbi ausiliari passivi differisce per il gruppo “dep” rispetto al gruppo di riferimento. Una media di -0.05 suggerisce che nel gruppo “dep”, la relazione tra I_c e passive_count è leggermente negativa rispetto al gruppo di controllo. Tuttavia, poiché l’intervallo HDI dal 3% al 97% (-0.14, 0.03) include zero, non c’è una chiara evidenza di un effetto differenziale significativo.\n\nConteggio delle Parole (wc_c):\n\nMedia: 0.76\nInterpretazione: Questo coefficiente indica che, per ogni aumento di una unità nel conteggio delle parole centrato (wc_c), il logaritmo del conteggio atteso dei verbi ausiliari passivi aumenta di 0.76 unità, mantenendo costanti le altre variabili. Ciò suggerisce che un maggiore numero di parole è associato a un maggiore uso di verbi ausiliari passivi.\nHDI 3% a 97%: L’intervallo [0.70, 0.81] indica che c’è una forte evidenza di un effetto positivo del conteggio delle parole.\n\nParametro di Dispersione (alpha):\n\nMedia: 2.10\nInterpretazione: Il parametro alpha rappresenta la dispersione del modello binomiale negativo. Un valore di alpha maggiore di 1 indica che i dati mostrano sovradispersione, ovvero la varianza è maggiore della media, il che è tipico dei modelli di conteggio.\n\n\n\n\n93.2.2 Conclusione\nIn sintesi, questo modello suggerisce che il gruppo di appartenenza (dep vs. controllo) e il conteggio delle parole hanno effetti evidenti sul numero di verbi ausiliari passivi utilizzati. L’effetto del linguaggio autoreferenziale e della sua interazione con il gruppo è meno chiaro, suggerendo una necessità di ulteriore esplorazione o considerazione di altri fattori.\n\n# Extract posterior samples\nposterior = az.extract(trace)\n\n# Create a grid of I_c values (using IQR as in your R code)\nI_c_q1, I_c_q3 = np.percentile(df[\"I_c\"], [25, 75])\nI_c_values = np.linspace(I_c_q1, I_c_q3, 100)\n\n# Get unique groups\ngroups = df[\"group\"].unique()\n\n# Ensure 'dep' is treated as the non-reference group\nis_dep_reference = groups[0] == \"dep\"\n\n\n# Helper function to safely get posterior values\ndef get_posterior_values(posterior, key):\n    values = posterior[key].values  # Convert DataArray to NumPy array\n    if values.ndim == 3:\n        values = values.squeeze(axis=1)  # Remove the singleton dimension\n    return values\n\n\n# Calculate posterior predictions\nposterior_preds = {}\n\nfor group in groups:\n    # Create design matrix\n    X = pd.DataFrame(\n        {\n            \"Intercept\": 1,\n            \"group\": (group == \"dep\") if is_dep_reference else (group != \"dep\"),\n            \"I_c\": I_c_values,\n            \"wc_c\": 0,  # Set to 0 as per zero_it in your R code\n            \"group:I_c\": ((group == \"dep\") if is_dep_reference else (group != \"dep\"))\n            * I_c_values,\n        }\n    )\n\n    # Safely reshape group-related posteriors\n    group_values = get_posterior_values(posterior, \"group\").flatten()\n    group_I_c_values = get_posterior_values(posterior, \"group:I_c\").flatten()\n\n    # Calculate linear predictor\n    linear_pred = (\n        get_posterior_values(posterior, \"Intercept\")[:, np.newaxis]\n        + group_values[:, np.newaxis] * X[\"group\"].values\n        + get_posterior_values(posterior, \"I_c\")[:, np.newaxis] * X[\"I_c\"].values\n        + get_posterior_values(posterior, \"wc_c\")[:, np.newaxis] * X[\"wc_c\"].values\n        + group_I_c_values[:, np.newaxis] * X[\"group:I_c\"].values\n    )\n\n    # Transform to response scale\n    posterior_preds[group] = np.exp(linear_pred)\n\n# Plot\ncolors = {\"control\": \"blue\", \"dep\": \"red\"}\n\nfor group, preds in posterior_preds.items():\n    mean = preds.mean(axis=0)\n    ci = np.percentile(preds, [2.5, 97.5], axis=0)\n    plt.plot(I_c_values, mean, label=group, color=colors[group])\n    plt.fill_between(I_c_values, ci[0], ci[1], alpha=0.2, color=colors[group])\n\nplt.xlabel(\"Self-Referential Language (I_c)\")\nplt.ylabel(\"Predicted Number of Passive Auxiliary Verbs\")\nplt.title(\"Interaction Effect: group * I_c\\n(with wc_c held at zero)\")\nplt.legend(title=\"Condition\")\nplt.grid(True, alpha=0.3)\n\n# Adjust x-axis to show more interpretable values\nplt.xlim(I_c_q1, I_c_q3)\nxticks = plt.gca().get_xticks()\nplt.gca().set_xticklabels([f\"{x:.2f}\" for x in xticks])\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63000/1234253612.py:73: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  plt.gca().set_xticklabels([f\"{x:.2f}\" for x in xticks])\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_63000/1234253612.py:75: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nmodel2 = bmb.Model(\n    \"passive_count ~ group * I_c + wc_c\", data=df, family=\"poisson\"\n)\n\n\ntrace2 = model2.fit(\n    tune=2000, draws=1000, nuts_sampler=\"numpyro\", idata_kwargs={\"log_likelihood\": True}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naz.summary(trace2, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nI_c\n-0.09\n0.02\n-0.14\n-0.05\n0.0\n0.0\n2012.27\n2012.51\n1.0\n\n\nIntercept\n-0.35\n0.02\n-0.39\n-0.31\n0.0\n0.0\n2527.49\n2424.84\n1.0\n\n\ngroup[dep]\n0.30\n0.03\n0.25\n0.35\n0.0\n0.0\n2801.92\n2775.68\n1.0\n\n\ngroup:I_c[dep]\n0.01\n0.02\n-0.03\n0.04\n0.0\n0.0\n2428.61\n2259.45\n1.0\n\n\nwc_c\n0.46\n0.01\n0.44\n0.49\n0.0\n0.0\n2376.84\n2675.49\n1.0\n\n\n\n\n\n\n\n\n# Extract posterior samples\nposterior = az.extract(trace2)\n\n# Create a grid of I_c values (using IQR as in your R code)\nI_c_q1, I_c_q3 = np.percentile(df[\"I_c\"], [25, 75])\nI_c_values = np.linspace(I_c_q1, I_c_q3, 100)\n\n# Get unique groups\ngroups = df[\"group\"].unique()\n\n# Ensure 'dep' is treated as the non-reference group\nis_dep_reference = groups[0] == \"dep\"\n\n\n# Helper function to safely get posterior values\ndef get_posterior_values(posterior, key):\n    values = posterior[key].values  # Convert DataArray to NumPy array\n    if values.ndim == 3:\n        values = values.squeeze(axis=1)  # Remove the singleton dimension\n    return values\n\n\n# Calculate posterior predictions\nposterior_preds = {}\n\nfor group in groups:\n    # Create design matrix\n    X = pd.DataFrame(\n        {\n            \"Intercept\": 1,\n            \"group\": (group == \"dep\") if is_dep_reference else (group != \"dep\"),\n            \"I_c\": I_c_values,\n            \"wc_c\": 0,  # Set to 0 as per zero_it in your R code\n            \"group:I_c\": ((group == \"dep\") if is_dep_reference else (group != \"dep\"))\n            * I_c_values,\n        }\n    )\n\n    # Safely reshape group-related posteriors\n    group_values = get_posterior_values(posterior, \"group\").flatten()\n    group_I_c_values = get_posterior_values(posterior, \"group:I_c\").flatten()\n\n    # Calculate linear predictor\n    linear_pred = (\n        get_posterior_values(posterior, \"Intercept\")[:, np.newaxis]\n        + group_values[:, np.newaxis] * X[\"group\"].values\n        + get_posterior_values(posterior, \"I_c\")[:, np.newaxis] * X[\"I_c\"].values\n        + get_posterior_values(posterior, \"wc_c\")[:, np.newaxis] * X[\"wc_c\"].values\n        + group_I_c_values[:, np.newaxis] * X[\"group:I_c\"].values\n    )\n\n    # Transform to response scale\n    posterior_preds[group] = np.exp(linear_pred)\n\n# Plot\ncolors = {\"control\": \"blue\", \"dep\": \"red\"}\n\nfor group, preds in posterior_preds.items():\n    mean = preds.mean(axis=0)\n    ci = np.percentile(preds, [2.5, 97.5], axis=0)\n    plt.plot(I_c_values, mean, label=group, color=colors[group])\n    plt.fill_between(I_c_values, ci[0], ci[1], alpha=0.2, color=colors[group])\n\nplt.xlabel(\"Self-Referential Language (I_c)\")\nplt.ylabel(\"Predicted Number of Passive Auxiliary Verbs\")\nplt.title(\"Interaction Effect: group * I_c\\n(with wc_c held at zero)\")\nplt.legend(title=\"Condition\")\nplt.grid(True, alpha=0.3)\n\n# Adjust x-axis to show more interpretable values\nplt.xlim(I_c_q1, I_c_q3)\nxticks = plt.gca().get_xticks()\nplt.gca().set_xticklabels([f\"{x:.2f}\" for x in xticks])\n\nplt.tight_layout()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/4242554425.py:73: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  plt.gca().set_xticklabels([f\"{x:.2f}\" for x in xticks])\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_67831/4242554425.py:75: UserWarning: The figure layout has changed to tight\n  plt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nmodel2.predict(trace2, kind=\"response\")\n\n\naz.plot_ppc(trace2)\n\n\n\n\n\n\n\n\n\nmodel.predict(trace, kind=\"response\")\n\n\naz.plot_ppc(trace)\n\n\n\n\n\n\n\n\n\n# Compute LOO\nloo_result = az.loo(trace)\n\n# Print the LOO and ELPD results\nprint(loo_result)\n\nComputed from 4000 posterior samples and 8645 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -10494.67    93.09\np_loo        8.27        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     8645  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\n\n# Compute LOO\nloo2_result = az.loo(trace2)\n\n# Print the LOO and ELPD results\nprint(loo2_result)\n\n/opt/anaconda3/envs/cmdstan_env/lib/python3.12/site-packages/arviz/stats/stats.py:789: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n  warnings.warn(\n\n\nComputed from 4000 posterior samples and 8645 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -11267.62   148.51\np_loo       54.61        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     8643  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    2    0.0%\n\n\n\n\ndf_comp_loo = az.compare({\"neg_bin_model\": loo_result, \"poisson _model\": loo2_result})\ndf_comp_loo\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nneg_bin_model\n0\n-10494.665380\n8.268416\n0.000000\n0.95484\n93.094047\n0.000000\nFalse\nlog\n\n\npoisson _model\n1\n-11267.624222\n54.610578\n772.958842\n0.04516\n148.505078\n96.512308\nTrue\nlog\n\n\n\n\n\n\n\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>Tweets</span>"
    ]
  },
  {
    "objectID": "chapters/glm/05_simchon_2023.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/05_simchon_2023.html#informazioni-sullambiente-di-sviluppo",
    "title": "93  Tweets",
    "section": "93.3 Informazioni sull’Ambiente di Sviluppo",
    "text": "93.3 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Wed Aug 14 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\ncmdstanpy : 1.2.4\narviz     : 0.18.0\nmatplotlib: 3.9.1\npandas    : 2.2.2\nnumpy     : 1.26.4\nlogging   : 0.5.1.2\nbambi     : 0.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nSimchon, A., Hadar, B., & Gilead, M. (2023). A computational text analysis investigation of the relation between personal and linguistic agency. Communications Psychology, 1(1), 23.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>Tweets</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html",
    "href": "chapters/glm/06_stan_rct.html",
    "title": "94  Incorporare dati storici di controllo in una RCT",
    "section": "",
    "text": "Introduzione\nQuesto capitolo fornisce una trattazione semplificata di un importante problema affrontato da Frank Harrell in un suo intervento intitolato Incorporating Historical Control Data Into an RCT.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html#studi-controllati-randomizzati",
    "href": "chapters/glm/06_stan_rct.html#studi-controllati-randomizzati",
    "title": "94  Incorporare dati storici di controllo in una RCT",
    "section": "94.1 Studi Controllati Randomizzati",
    "text": "94.1 Studi Controllati Randomizzati\nNella ricerca psicologica, ci troviamo di fronte a notevoli ostacoli nel reclutare un numero sufficiente di partecipanti per condurre studi controllati randomizzati (RCT), un problema che si acuisce quando si prevede l’assegnazione dei partecipanti a gruppi di controllo che ricevono trattamenti standard. Un’altra difficoltà sorge quando i potenziali partecipanti sono riluttanti a iscriversi agli studi a causa della possibilità di non ricevere il trattamento sperimentale. In questo contesto, l’utilizzo di Dati Storici (HD) per informare su possibili esiti nei gruppi di controllo assume un’importanza vitale. Tuttavia, l’integrazione di tali dati richiede strategie sofisticate per adeguare i bias e le disparità tra i diversi disegni di studio.\nStuart Pocock ha proposto un metodo nel quadro frequentista che valorizza la dimensione campionaria degli HD, pur ammettendo che questi possano riflettere realtà diverse rispetto agli esiti attesi nei gruppi di controllo degli RCT prospettici. La discrepanza include sia la vera performance sconosciuta del gruppo di controllo sia il bias inerente agli HD.\nBjörn Holzhauer ha ampliato questa visione attraverso lo sviluppo di approcci Bayesiani per l’appropriazione di dati, in particolare riguardo ai tassi di pericolo esponenziali, mediante l’utilizzo di simulazioni MCMC Bayesiane. Queste metodologie consentono l’elaborazione parallela di più modelli e l’inclusione diretta dei dati grezzi degli HD nell’analisi di nuovi dati sperimentali, affrontando direttamente le possibili discrepanze negli oggetti di stima tra HD e RCT.\nUna caratteristica fondamentale di queste tecniche è l’aggregazione di dati grezzi da diverse fonti, facilitando un’analisi più precisa che considera l’intero spettro delle incertezze. Questo si contrappone agli approcci tradizionali, che spesso si basano su statistiche riassuntive e tendono a trascurare importanti variabilità, conferendo una fiducia ingiustificata nei dati storici. È, inoltre, cruciale l’ajustamento per covariate al fine di gestire l’eterogeneità degli esiti tra i trattamenti, aumentando così l’affidabilità e l’accuratezza delle stime dell’effetto del trattamento.\nProcedendo senza dati diretti per valutare il bias, ci affidiamo a una distribuzione a priori gaussiana con media zero e deviazione standard sigma per descriverlo. Un valore di sigma nullo implica l’assenza di bias, permettendo di integrare gli HD nell’analisi allo stesso livello dei dati di controllo dello studio. Al contrario, un sigma infinito indica una completa ignoranza riguardo al bias, rendendo gli HD non informativi e pertanto trascurabili.\nIl focus principale, l’effetto del trattamento delta, viene esaminato più efficacemente attraverso l’analisi di sigma. Un sigma inferiore a 2 rende lo studio informativo su delta, mentre un sigma superiore a 2 può portare a conclusioni errate, specialmente quando gli HD hanno una media artificiosamente gonfiata. Questo sottolinea l’importanza di una scelta accurata dei parametri analitici, in particolare nell’integrazione dei dati storici con quelli dei nuovi studi clinici, per fornire una rappresentazione equilibrata e critica dell’integrazione di tali dati nell’analisi statistica contemporanea.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html#creazione-di-un-braccio-di-controllo-con-hd",
    "href": "chapters/glm/06_stan_rct.html#creazione-di-un-braccio-di-controllo-con-hd",
    "title": "94  Incorporare dati storici di controllo in una RCT",
    "section": "94.2 Creazione di un Braccio di Controllo con HD",
    "text": "94.2 Creazione di un Braccio di Controllo con HD\nNel contesto di uno studio RCT condotto con un unico braccio sperimentale, dove i dati di controllo derivano unicamente da controlli storici non contemporanei, la sfida si amplifica. In queste circostanze, il bias intrinseco negli HD non può essere quantificato direttamente. Invece, ci si affida completamente alla distribuzione di incertezza prescelta per il bias. Questo approccio offre un’analisi che, pur essendo paragonabile a una verifica di sensibilità, si avvale del rigoroso quadro analitico Bayesiano. Quest’ultimo, per sua natura flessibile, permette un’estensione naturale a include la meta-analisi di dati individuali dei pazienti e l’adeguamento per covariate, arricchendo così la robustezza e l’affidabilità delle inferenze tratte dallo studio.\nImportiamo e compiliamo il modello.\n\nstan_file = os.path.join(project_directory, \"stan\", \"rct.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n12:00:16 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/rct.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/rct\n12:00:26 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/rct\n\n\ndata {\n  int&lt;lower=0&gt; Nb;  // # obs in RCT treatment B\n  int&lt;lower=0&gt; Nh;  // # obs in historical control data\n  vector[Nb] yb;    // vector of tx=B data\n  vector[Nh] yh;    // vector of historical data\n  real&lt;lower=0&gt; sigma;  // standard deviation of prior for bias\n}\nparameters {\n  real mua;  // unknown mean for tx=A\n  real mub;  // unknown mean for tx=B\n  real bias; // unknown bias\n}\ntransformed parameters {\n  real delta;\n  delta = mua - mub;\n}\nmodel {\n  yb   ~ normal(mub, 1.0);\n  yh   ~ normal(mua + bias, 1.0);\n  bias ~ normal(0., sigma);\n}\n\n\n\n\nCreiamo il dizionario che contiene i dati richiesti dal modello.\n\nNa = 20\nNb = 40\nNh = 500\nya = rng.normal(loc=10, scale=1, size=Na)\nyb = rng.normal(loc=5, scale=1, size=Nb)\nyh = rng.normal(loc=20, scale=1, size=Nh)\n\nstan_data = {\"Nb\": Nb, \"Nh\": Nh, \"yb\": yb, \"yh\": yh, \"sigma\": 1.0}\n\nEseguiamo il campionamento MCMC.\n\nfit = model.sample(data=stan_data)\n\nEsaminiamo i risultati ottenuti.\n\nprint(fit.summary())\n\n             Mean      MCSE    StdDev         5%         50%        95%  \\\nlp__  -252.847000  0.035606  1.225860 -255.33900 -252.524000 -251.48100   \nmua     20.034200  0.028866  1.027280   18.35000   20.040900   21.69820   \nmub      5.216960  0.004029  0.160862    4.94483    5.216310    5.47481   \nbias    -0.044748  0.028869  1.026390   -1.71126   -0.042136    1.62836   \ndelta   14.817300  0.029354  1.038220   13.10640   14.832900   16.49740   \n\n         N_Eff  N_Eff/s    R_hat  \nlp__   1185.29  1727.83  1.00003  \nmua    1266.49  1846.20  1.00055  \nmub    1594.19  2323.89  1.00245  \nbias   1264.05  1842.64  1.00058  \ndelta  1250.95  1823.54  1.00088  \n\n\n\naz.summary(fit, var_names=([\"bias\", \"delta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbias\n-0.045\n1.026\n-1.990\n1.917\n0.029\n0.021\n1265.0\n1491.0\n1.0\n\n\ndelta\n14.817\n1.038\n12.911\n16.837\n0.029\n0.021\n1251.0\n1285.0\n1.0\n\n\n\n\n\n\n\n\n_ = az.plot_trace(fit, var_names=([\"bias\", \"delta\"]))\n\n\n\n\n\n\n\n\nSi noti l’utilità dei dati storici nella riduzione dell’incertezza associata a delta. Quando diminuisce sigma, diminuisce anche l’incertezza associata all’effetto del trattamento.\n\nstan_data = {\n    \"Nb\" : Nb, \n    \"Nh\" : Nh, \n    \"yb\" : yb, \n    \"yh\" : yh,\n    \"sigma\" : 0.25\n}\n\n\nfit1 = model.sample(data=stan_data)\n\n\naz.summary(fit1, var_names=([\"bias\", \"delta\"]), hdi_prob=0.95)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbias\n-0.006\n0.250\n-0.505\n0.468\n0.007\n0.005\n1337.0\n1404.0\n1.0\n\n\ndelta\n14.782\n0.304\n14.161\n15.335\n0.008\n0.006\n1483.0\n1538.0\n1.0",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html#conclusioni",
    "href": "chapters/glm/06_stan_rct.html#conclusioni",
    "title": "94  Incorporare dati storici di controllo in una RCT",
    "section": "94.3 Conclusioni",
    "text": "94.3 Conclusioni\nPer stabilire la distribuzione a priori del bias, è fondamentale considerare le informazioni disponibili riguardanti l’evoluzione delle pratiche terapeutiche, il bias di selezione dei pazienti e l’andamento della patologia di interesse. L’approccio Bayesiano ci libera dalla necessità di conoscere con precisione l’entità del bias, indirizzandoci invece a definire la sua distribuzione di incertezza. In caso questa distribuzione sia modellata come gaussiana, ci si avvale dell’ipotesi di simmetria per focalizzarsi sulla deviazione standard, sigma. Un metodo efficace per determinare sigma consiste nel fissarlo in modo che, per esempio, la probabilità che il bias si collochi entro un intervallo di \\([-c, c]\\) sia del 95%, per poi calcolare retrospettivamente il valore di sigma necessario a soddisfare questa condizione. Questo approccio garantisce una gestione più mirata e scientificamente fondata dell’incertezza legata al bias, fondamentale per l’integrazione ottimale dei dati storici nelle analisi statistiche avanzate.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/06_stan_rct.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/06_stan_rct.html#informazioni-sullambiente-di-sviluppo",
    "title": "94  Incorporare dati storici di controllo in una RCT",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\ncmdstanpy: 1.2.4\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\npandas    : 2.2.2\nscipy     : 1.14.0\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>Incorporare dati storici di controllo in una RCT</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html",
    "href": "chapters/glm/07_stan_mediation.html",
    "title": "95  Modello di mediazione con Stan",
    "section": "",
    "text": "95.1 Preparazione del Notebook\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\nimport networkx as nx\n# set seed to make the results fully reproducible\nseed: int = sum(map(ord, \"stan_mediation\"))\nrng: np.random.Generator = np.random.default_rng(seed=seed)\n\naz.style.use(\"arviz-darkgrid\")\nplt.rcParams[\"figure.dpi\"] = 100\nplt.rcParams[\"figure.facecolor\"] = \"white\"\n\n%config InlineBackend.figure_format = \"retina\"\nIl presente capitolo fornisce un riassunto della trattazione dei modelli misti fornita da {cite:t}sorensen2015bayesian, a cui si rimanda per gli approfondimenti.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html#domanda-della-ricerca",
    "href": "chapters/glm/07_stan_mediation.html#domanda-della-ricerca",
    "title": "95  Modello di mediazione con Stan",
    "section": "95.2 Domanda della Ricerca",
    "text": "95.2 Domanda della Ricerca\nLa questione scientifica riguarda la comprensione delle frasi nel caso di proposizioni relative di soggetto e di oggetto. Una proposizione relativa di soggetto è una frase in cui un sostantivo (ad esempio, “senatore”) viene modificato da una proposizione relativa (ad esempio, “che ha interrogato il giornalista”), e il sostantivo modificato è il soggetto grammaticale della proposizione relativa. In una proposizione relativa di oggetto, il sostantivo modificato dalla proposizione relativa è l’oggetto grammaticale della proposizione (per esempio, “Il senatore che il giornalista ha interrogato si è dimesso”). In entrambi i casi, il sostantivo modificato (“senatore”) è chiamato il sostantivo principale.\nUn risultato comune per l’inglese è che le proposizioni relative di soggetto sono più facili da elaborare rispetto a quelle di oggetto. Le lingue naturali in generale includono proposizioni relative, e fino a poco tempo fa il vantaggio delle proposizioni di soggetto è stato considerato valido a livello cross-linguistico. Tuttavia, le proposizioni relative in cinese rappresentano un interessante controesempio a questa generalizzazione; ricerche recenti condotte da Hsiao e Gibson (2003) hanno suggerito che in cinese, le proposizioni relative di oggetto sono più facili da elaborare rispetto a quelle di soggetto in un punto specifico della frase (il sostantivo principale della proposizione relativa). Viene presentata un’analisi di un insieme di dati successivamente pubblicata {cite:p}gibson2013processing che valuta questa affermazione.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html#i-dati",
    "href": "chapters/glm/07_stan_mediation.html#i-dati",
    "title": "95  Modello di mediazione con Stan",
    "section": "95.3 I Dati",
    "text": "95.3 I Dati\nLa variabile dipendente dell’esperimento di {cite:t}gibson2013processing era il tempo di lettura (rt) in millisecondi del sostantivo principale della proposizione relativa. Questo è stato registrato in due condizioni (proposizione relativa di soggetto e proposizione relativa di oggetto), con 37 soggetti e 15 item, presentati in un disegno standard a quadrato latino. Originariamente c’erano 16 item, ma uno è stato rimosso, risultando in 37 × 15 = 555 punti dati. Tuttavia, otto punti dati da un soggetto (id 27) erano mancanti. Di conseguenza, abbiamo un totale di 555 - 8 = 547 punti dati. La condizione (object relative / subject relative) è codificata dalla variabile so.\n\nhowell_data = pd.read_csv(\"../data/Howell1.csv\", sep=';')\nhowell_data.head()\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n0\n151.765\n47.825606\n63.0\n1\n\n\n1\n139.700\n36.485807\n63.0\n0\n\n\n2\n136.525\n31.864838\n65.0\n0\n\n\n3\n156.845\n53.041914\n41.0\n1\n\n\n4\n145.415\n41.276872\n51.0\n0\n\n\n\n\n\n\n\n\nhowell_data.tail()\n\n\n\n\n\n\n\n\nheight\nweight\nage\nmale\n\n\n\n\n539\n145.415\n31.127751\n17.0\n1\n\n\n540\n162.560\n52.163080\n31.0\n1\n\n\n541\n156.210\n54.062497\n21.0\n0\n\n\n542\n71.120\n8.051258\n0.0\n1\n\n\n543\n158.750\n52.531624\n68.0\n1\n\n\n\n\n\n\n\n\nhowell_data.shape\n\n(544, 4)\n\n\n\n_ = sns.kdeplot(data=howell_data, x='weight', hue='male', fill=True, common_norm=False, alpha=0.5)",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html#pensare-scientificamente-prima-di-tutto",
    "href": "chapters/glm/07_stan_mediation.html#pensare-scientificamente-prima-di-tutto",
    "title": "95  Modello di mediazione con Stan",
    "section": "95.4 Pensare scientificamente prima di tutto",
    "text": "95.4 Pensare scientificamente prima di tutto\nDesideriamo prevedere il peso a partire da due predittori: genere e altezza. Pertanto, potremmo prevedere il peso utilizzando queste due variabili mediante un modello di regressione. {cite:t}McElreath_rethinking ci ricorda che il modello di regressione è un “Golem”: è potente e stupido. Se il nostro unico obiettivo è “prevedere” il valore del peso senza attribuire interpretazioni ai coefficienti del modello, questo potrebbe essere adeguato se funziona effettivamente. Tuttavia, il modello di regressione non considera la struttura causale sottostante il meccanismo di generazione dei dati. Se desideriamo comprendere qualcosa sulla struttura causale che lega questi dati, dobbiamo prima pensare in termini scientifici.\n\nCome sono causalmente correlati altezza, peso e sesso?\nCome sono statisticamente correlati altezza, peso e sesso?\n\n\n95.4.1 Le cause non sono nei dati\nL’altezza dovrebbe influenzare il peso, e non il contrario: - ✅ \\(H \\rightarrow W\\) - ❌ \\(W \\rightarrow H\\)\nIl sesso dovrebbe influenzare l’altezza, e non il contrario: - ❌ \\(S \\rightarrow H\\) - ✅ \\(H \\rightarrow S\\)\nQuesto ci porta a un modello di mediazione. In tale modello, il sesso influisce sul peso (\\(S \\rightarrow W\\)) così come sull’altezza (\\(S \\rightarrow H\\)). Inoltre, l’altezza influisce sul peso (\\(H \\rightarrow W\\)). In questa struttura causale, possiamo distinguere tra effetti diretti, indiretti e l’effetto totale.\nL’effetto diretto del genere sul peso è dato dal coefficiente del percorso \\(S \\rightarrow W\\). Questa è la nostra principale questione di interesse. Tuttavia, c’è un altro effetto diretto che influisce sul peso: \\(H \\rightarrow W\\). Se confrontiamo questi due effetti diretti, quale è il più significativo? In aggiunta, abbiamo l’effetto diretto \\(S \\rightarrow H\\). Possiamo anche definire l’effetto indiretto del sesso sul peso come \\(S \\rightarrow H \\rightarrow W\\). Infine, l’effetto totale è dato dalla somma degli effetti diretti e indiretti.\nTutto ciò viene ignorato in un modello di regressione semplice. Solo quando disponiamo di un modello plausibile che descrive le relazioni causali tra le variabili possiamo costruire un modello statistico in grado di rappresentare adeguatamente la struttura causale ipotizzata, permettendoci di rispondere alle domande di interesse. In questo caso, quale è l’effetto più rilevante sul peso? Altezza o genere? Per rispondere a questa domanda, possiamo implementare il modello di mediazione in Stan nel seguente modo.\n\n# Creazione del Directed Acyclic Graph (DAG) per il modello di mediazione\nG = nx.DiGraph()\n\n# Aggiunta dei nodi\nG.add_nodes_from([\"S\", \"W\", \"H\"])\n\n# Aggiunta degli archi che rappresentano le relazioni causali\nG.add_edges_from([(\"S\", \"W\"), (\"S\", \"H\"), (\"H\", \"W\")])\n\n# Posizionamento dei nodi usando il layout 'planar'\npos = nx.planar_layout(G)\n\n# Impostazioni per i nodi più grandi e le dimensioni globali più piccole\noptions = {\n    \"font_size\": 12,\n    \"node_size\": 2000,\n    \"node_color\": \"skyblue\",\n    \"edgecolors\": \"black\",\n    \"linewidths\": 2,\n    \"width\": 2,\n}\n\nplt.figure(figsize=(6, 4))  # Dimensioni globali più piccole\nnx.draw(G, pos, **options, with_labels=True, arrowsize=20)\n\nplt.title(\"Mediation Model DAG\")\nplt.show()\n\n/opt/anaconda3/envs/stan_env/lib/python3.12/site-packages/IPython/core/pylabtools.py:152: UserWarning: There are no gridspecs with layoutgrids. Possibly did not call parent GridSpec with the \"figure\" keyword\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n\n\nRileggiamo il modello Stan. È da notare che i dati sono stati standardizzati per agevolare il campionamento e permettere un confronto diretto tra i diversi coefficienti.\n\nstan_file = os.path.join('stan', 'mediation_model.stan')\nwith open(stan_file, 'r') as f:\n    print(f.read())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of observations\n  array[N] int S; // Sex indicator (0 for F, 1 for M), Predictor\n  array[N] real H; // Height, Mediator\n  array[N] real W; // Weight, Outcome\n}\n\nparameters {\n  real alphaH; // Intercept for height model\n  real betaH; // Effect of sex on height\n  real alphaW; // Intercept for weight model\n  real betaW_H; // Effect of height on weight\n  real betaW_S; // Direct effect of sex on weight\n  real&lt;lower=0&gt; sigmaH; // Std dev for height model\n  real&lt;lower=0&gt; sigmaW; // Std dev for weight model\n}\n\nmodel {\n  // Priors\n  alphaH ~ normal(0, 1); // Less restrictive priors for intercepts and effects\n  betaH ~ normal(0, 1);\n  alphaW ~ normal(0, 1);\n  betaW_H ~ normal(0, 1);\n  betaW_S ~ normal(0, 1);\n  sigmaH ~ cauchy(0, 1); // Using a Cauchy distribution for sigma, more appropriate for std devs\n  sigmaW ~ cauchy(0, 1);\n  \n  // Mediation Model\n  for (i in 1:N) {\n    // A path: Effect of sex on height\n    H[i] ~ normal(alphaH + betaH * S[i], sigmaH);\n    \n    // B and C' path: Effect of height (and sex) on weight\n    W[i] ~ normal(alphaW + betaW_H * H[i] + betaW_S * S[i], sigmaW);\n  }\n}\n\n\n\nCreiamo un dizionario che include i dati nel formato atteso dal precedente codice Stan.\n\nhowell_data['H_standardized'] = (howell_data['height'] - howell_data['height'].mean()) / howell_data['height'].std()\nhowell_data['W_standardized'] = (howell_data['weight'] - howell_data['weight'].mean()) / howell_data['weight'].std()\n\nstan_data = {\n    \"N\": howell_data.shape[0],\n    \"S\": howell_data[\"male\"].to_numpy(),  # Ensuring this is an array if not already\n    \"H\": howell_data[\"H_standardized\"].to_numpy(),  # Use the standardized height\n    \"W\": howell_data[\"W_standardized\"].to_numpy()   # Use the standardized weight\n}\n\nCompiliamo il modello.\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model)\n\nCmdStanModel: name=mediation_model\n     stan_file=/Users/corradocaudek/_repositories/ds4p/chapter_5/stan/mediation_model.stan\n     exe_file=/Users/corradocaudek/_repositories/ds4p/chapter_5/stan/mediation_model\n     compiler_options=stanc_options={}, cpp_options={}\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(data=stan_data, adapt_delta = 0.95)\n\n\nprint(fit.diagnose())\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp21v_i0bp/mediation_model5rm1gdaw/mediation_model-20240522065152_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nEsaminiamo le tracce.\n\n_ = az.plot_trace(fit, var_names=([\"betaH\", \"betaW_H\", \"betaW_S\"]))\n\n\n\n\n\n\n\n\nEsaminiamo le medie a posteriori e gli intervalli di credibilità dei parametri.\n\naz.summary(fit, var_names=([\"betaH\", \"betaW_H\", \"betaW_S\"]), hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbetaH\n0.28\n0.09\n0.11\n0.44\n0.0\n0.0\n3139.90\n2705.84\n1.0\n\n\nbetaW_H\n0.94\n0.01\n0.91\n0.97\n0.0\n0.0\n4113.00\n2834.41\n1.0\n\n\nbetaW_S\n0.05\n0.03\n-0.01\n0.11\n0.0\n0.0\n2796.52\n2773.80\n1.0\n\n\n\n\n\n\n\nIl genere ha scarso o addirittura nullo impatto diretto sul peso. Piuttosto, è principalmente l’altezza ad avere un effetto causale sul peso.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/07_stan_mediation.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/glm/07_stan_mediation.html#informazioni-sullambiente-di-sviluppo",
    "title": "95  Modello di mediazione con Stan",
    "section": "95.5 Informazioni sull’Ambiente di Sviluppo",
    "text": "95.5 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p cmdstanpy\n\nLast updated: Wed May 22 2024\n\nPython implementation: CPython\nPython version       : 3.12.2\nIPython version      : 8.22.2\n\ncmdstanpy: 1.2.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.13.0\nnetworkx  : 3.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>Modello di mediazione con Stan</span>"
    ]
  },
  {
    "objectID": "chapters/glm/08_uses_and_abuses.html",
    "href": "chapters/glm/08_uses_and_abuses.html",
    "title": "96  Usi e abusi dei modelli lineari",
    "section": "",
    "text": "96.1 Introduzione\nSebbene i metodi di regressione siano ampiamente utilizzati in psicologia e nelle scienze sociali, molte applicazioni di queste analisi nella ricerca mancano di chiarezza di scopo e dimostrano una comprensione inadeguata di concetti chiave. Carlin & Moreno-Betancur (2023) sostengono che è necessario un approccio più mirato nell’insegnamento e nell’applicazione dei metodi biostatistici, in particolare per quanto riguarda i modelli di regressione. Carlin & Moreno-Betancur (2023) propongono che i concetti statistici dovrebbero essere insegnati e applicati in stretta relazione con il contesto specifico della loro applicazione, piuttosto che essere trattati come strumenti universali. Carlin & Moreno-Betancur (2023) evidenziano l’importanza di distinguere tra tre tipi di domande di ricerca: descrittive, predittive e causali, sostenendo che tale distinzione è essenziale per evitare fraintendimenti e cattive pratiche nell’uso dei modelli di regressione.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Usi e abusi dei modelli lineari</span>"
    ]
  },
  {
    "objectID": "chapters/glm/08_uses_and_abuses.html#introduzione",
    "href": "chapters/glm/08_uses_and_abuses.html#introduzione",
    "title": "96  Usi e abusi dei modelli lineari",
    "section": "",
    "text": "96.1.1 1. Domande Descrittive\nScopo: Le domande descrittive in psicologia mirano a caratterizzare e descrivere comportamenti, pensieri, emozioni o caratteristiche psicologiche di una popolazione. L’obiettivo è ottenere una panoramica chiara delle variabili psicologiche senza cercare di determinare cause o fare previsioni.\nEsempi: - Uno studio che descrive il livello di ansia in diversi gruppi di età durante una pandemia, utilizzando scale di autovalutazione dell’ansia. - Un’indagine che esplora la prevalenza di sintomi depressivi tra studenti universitari durante il periodo degli esami. - Un’analisi che misura la frequenza di comportamenti di procrastinazione tra professionisti in diversi settori lavorativi.\nApproccio Analitico: Per queste domande, si utilizzano statistiche descrittive come medie, deviazioni standard e percentuali per fornire un quadro generale delle caratteristiche psicologiche della popolazione studiata. I modelli di regressione possono essere impiegati per controllare i potenziali confondenti, ma il loro scopo principale è descrittivo, non predittivo o causale.\n\n\n96.1.2 2. Domande Predittive\nScopo: Le domande predittive in psicologia si concentrano sulla costruzione di modelli che possano prevedere comportamenti o esiti psicologici futuri in base a dati già disponibili. L’obiettivo è identificare i migliori predittori di un risultato psicologico e creare modelli che possano essere applicati per fare previsioni accurate su nuovi individui.\nEsempi: - Uno studio che utilizza i dati dei tratti della personalità per prevedere la probabilità di burnout in professionisti della salute mentale. - Un modello che stima il rischio di abbandono scolastico tra gli adolescenti basandosi su variabili come l’autostima, il supporto familiare e le esperienze di bullismo. - Un’analisi che sviluppa un algoritmo per prevedere la probabilità di recidiva in pazienti con disturbi alimentari, usando dati raccolti su fattori psicologici e comportamentali.\nApproccio Analitico: In questo contesto, vengono utilizzati modelli statistici come la regressione logistica, la regressione lineare, o algoritmi di machine learning per sviluppare modelli predittivi. La qualità di un modello predittivo viene valutata sulla base di metriche come l’accuratezza, la sensibilità, e la specificità, piuttosto che sulla comprensione delle relazioni causali tra variabili.\n\n\n96.1.3 3. Domande Causali\nScopo: Le domande causali in psicologia cercano di determinare l’effetto di una variabile psicologica su un’altra, spesso per comprendere le implicazioni di un intervento o di una modifica in un comportamento o stato psicologico. L’obiettivo è stabilire una relazione di causa-effetto per giustificare interventi o sviluppare teorie.\nEsempi: - Uno studio sperimentale che valuta l’efficacia della terapia cognitivo-comportamentale (CBT) nel ridurre i sintomi d’ansia nei pazienti rispetto a un gruppo di controllo che riceve un trattamento placebo. - Un’indagine longitudinale che esamina se l’incremento della consapevolezza (mindfulness) nel corso del tempo porta a una riduzione significativa dei livelli di stress in studenti universitari. - Una ricerca che esplora se un programma di training sulla regolazione emotiva può causare una diminuzione della frequenza di attacchi di panico nei partecipanti con disturbo da panico.\nApproccio Analitico: Per rispondere a domande causali, sono necessari disegni di studio ben pianificati, come esperimenti randomizzati controllati o studi longitudinali. L’analisi dei dati può coinvolgere modelli di regressione per aggiustare i confondenti e isolare gli effetti causali. In questi casi, l’enfasi è posta sull’uso corretto della randomizzazione, del controllo dei confondenti e dell’inferenza causale per fare dichiarazioni valide sulle relazioni causa-effetto.\n\n\n96.1.4 Conclusione\nComprendere le differenze tra domande di ricerca descrittive, predittive e causali è fondamentale nella ricerca psicologica per utilizzare correttamente i metodi statistici. Ogni tipo di domanda richiede un approccio specifico che tenga conto dell’obiettivo dell’analisi e delle caratteristiche dei dati disponibili, al fine di evitare errori comuni e migliorare la validità e l’applicabilità dei risultati ottenuti.\nUn aspetto importante sottolineato da Carlin & Moreno-Betancur (2023) riguarda l’interpretazione errata dei coefficienti di regressione, che è un problema comune nella pratica della statistica applicata, inclusa la psicologia. Questo errore deriva spesso da una mancanza di chiarezza rispetto allo scopo dell’analisi e alla natura delle domande di ricerca.\n\n\n96.1.5 Problemi Comuni nell’Interpretazione dei Coefficienti di Regressione\n\nAssunzione di Causalità da Modelli Predittivi: Un errore comune è interpretare i coefficienti di regressione come indicativi di relazioni causali quando il modello è stato progettato per uno scopo predittivo. Ad esempio, in un modello di regressione sviluppato per prevedere la depressione basato su variabili come l’età, il livello di stress e il supporto sociale, i coefficienti associati a ciascuna variabile indicano solo l’importanza relativa di queste variabili nel predire la depressione, non che queste variabili siano cause della depressione. Tuttavia, è frequente che tali coefficienti vengano erroneamente interpretati come prove che un aumento del livello di stress causi un aumento della depressione, senza considerare che potrebbero esserci fattori confondenti non misurati o che il modello stesso non sia stato progettato per testare ipotesi causali.\n“Table 2 Fallacy”: L’articolo cita l’errore noto come “Table 2 fallacy”, che si riferisce alla pratica comune di presentare una tabella con coefficienti di regressione stimati da un modello multivariabile come se questi rappresentassero effetti causali. Ad esempio, in un’analisi che esamina il rapporto tra autostima e rendimento accademico, i coefficienti di regressione possono essere interpretati erroneamente come se indicassero l’effetto diretto dell’autostima sul rendimento accademico, ignorando che la relazione potrebbe essere mediata o confusa da altre variabili come il supporto familiare, il contesto scolastico o la motivazione intrinseca.\nErrore nella Definizione di “Fattori di Rischio”: Spesso si utilizzano modelli di regressione per identificare “fattori di rischio” per un determinato esito, come ad esempio la depressione o l’ansia. Tuttavia, il termine “fattore di rischio” viene talvolta utilizzato in modo impreciso per indicare sia predittori che possono avere un’associazione statistica con l’esito, sia cause potenziali. Questo porta a interpretazioni errate quando i coefficienti di regressione vengono visti come indicatori di cause effettive piuttosto che come relazioni associative, senza considerare la necessità di ulteriori analisi per stabilire causalità.\nInterpretazione Ambigua dell’Indipendenza: Nella pratica, i coefficienti di regressione sono spesso interpretati come effetti “indipendenti” delle variabili predittive sull’esito, assumendo che “controllando per” altre variabili nel modello, il coefficiente di una variabile rappresenti il suo effetto isolato. Tuttavia, questa interpretazione è valida solo se il modello è specificato correttamente e se tutte le variabili confondenti rilevanti sono incluse nel modello. In caso contrario, i coefficienti potrebbero essere distorti da confondenti non misurati o mal specificati, portando a conclusioni errate.\n\n\n\n96.1.6 Come Correggere l’Interpretazione Errata dei Coefficienti\n\nChiarezza dello Scopo dell’Analisi: Prima di costruire e interpretare un modello di regressione, è essenziale definire chiaramente l’obiettivo dell’analisi: è descrittivo, predittivo o causale? Questo aiuta a guidare l’interpretazione corretta dei coefficienti. Se lo scopo è predittivo, l’interesse dovrebbe essere rivolto alla qualità delle previsioni piuttosto che all’interpretazione dei coefficienti.\nComprendere i Limiti della Regressione Multivariata: Anche nei modelli multivariati, dove si tenta di aggiustare per diversi confondenti, è importante riconoscere che i coefficienti rappresentano associazioni condizionate e non necessariamente effetti causali. Questo è particolarmente vero in contesti non sperimentali, dove la randomizzazione manca e la selezione dei confondenti è basata sull’osservazione e non su un controllo sperimentale.\nUtilizzo di Metodi di Inferenza Causale: Quando l’obiettivo è comprendere le relazioni causali, è importante utilizzare metodi di inferenza causale, come il controllo dei confondenti attraverso modelli di causalità esplicita (come i DAG, Directed Acyclic Graphs), la randomizzazione o metodi quasi-sperimentali. Questi approcci aiutano a isolare gli effetti causali e a evitare le interpretazioni errate che possono derivare dall’uso ingenuo dei modelli di regressione.\nFormazione e Educazione Statistica: È fondamentale educare i ricercatori e gli analisti sull’importanza della corretta interpretazione dei coefficienti di regressione e sull’uso appropriato dei modelli statistici. Questo dovrebbe includere una formazione sulle differenze tra correlazione e causalità, sui limiti dei modelli di regressione e sui metodi alternativi per stabilire relazioni causali.\n\n\n\n96.1.7 Conclusione\nL’interpretazione errata dei coefficienti di regressione è un problema notevole che può portare a conclusioni fuorvianti e a decisioni errate nella ricerca psicologica. Una chiara comprensione dello scopo dell’analisi, una formazione adeguata e l’uso di metodi appropriati sono essenziali per evitare questi errori e migliorare la validità delle conclusioni derivate dalle analisi statistiche.\n\n\n\n\nCarlin, J. B., & Moreno-Betancur, M. (2023). On the uses and abuses of regression models: a call for reform of statistical practice and teaching. arXiv preprint arXiv:2309.06668.",
    "crumbs": [
      "GLM",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>Usi e abusi dei modelli lineari</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/introduction_entropy.html",
    "href": "chapters/entropy/introduction_entropy.html",
    "title": "Introduzione",
    "section": "",
    "text": "In questa sezione della dispensa, esploreremo il tema cruciale della validazione di un modello statistico e del confronto tra modelli. Vedremo come sia necessario trovare un equilibrio tra due dimensioni: la capacità del modello di predire accuratamente i dati osservati nel campione e la sua capacità di generalizzarsi a campioni diversi.",
    "crumbs": [
      "Entropia",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html",
    "href": "chapters/entropy/01_entropy.html",
    "title": "97  Entropia",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, descriveremo il concetto di entropia, una misura fondamentale sviluppata nell’ambito della teoria dell’informazione. L’entropia ci permette di quantificare l’incertezza associata a una distribuzione di probabilità e, di conseguenza, la quantità di informazione che un evento ci fornisce.\nL’entropia è legata alla nostra capacità di prevedere l’esito di un evento: più un risultato è imprevedibile, maggiore sarà l’entropia. In termini più generali, l’entropia di una variabile casuale misura quanto è incerto o “sorprendente” il valore che essa assumerà in media. Se ogni possibile esito ha la stessa probabilità di verificarsi, l’entropia sarà massima. Se invece alcuni esiti sono molto più probabili di altri, l’entropia diminuirà, poiché l’incertezza complessiva è ridotta.\nUn’intuizione sull’entropia può essere ottenuta considerando il seguente esempio. Pensiamo a un sacchetto di palline colorate. Se il sacchetto contiene solo palline di un unico colore, possiamo essere sicuri di quale pallina estrarremo ogni volta. Non c’è alcuna incertezza o sorpresa, quindi l’entropia è pari a zero. Tuttavia, se il sacchetto contiene un numero uguale di palline di diversi colori, ogni estrazione è un’incognita: l’incertezza è massima e, di conseguenza, lo è anche l’entropia.\nIl concetto di entropia va ben oltre questo semplice esempio. Esso si applica a qualunque situazione in cui ci sia un insieme di risultati possibili con probabilità diverse. In questo capitolo, ci concentreremo sul significato matematico dell’entropia, esplorando come può essere calcolata per diverse distribuzioni di probabilità e come essa si collega alla quantità di informazione che un sistema può fornire. Inizieremo con esempi semplici, come l’entropia di una moneta equa o di un dado, per poi estendere il concetto a situazioni più complesse.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#introduzione",
    "href": "chapters/entropy/01_entropy.html#introduzione",
    "title": "97  Entropia",
    "section": "",
    "text": "Information is the resolution of uncertainty.\n(Shannon C, 1948)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "href": "chapters/entropy/01_entropy.html#che-cosè-linformazione",
    "title": "97  Entropia",
    "section": "97.1 Che cos’è l’Informazione?",
    "text": "97.1 Che cos’è l’Informazione?\nL’informazione è solitamente misurata in bit, e un bit di informazione permette di scegliere tra due alternative ugualmente probabili. La parola bit deriva da binary digit (cioè uno zero o un uno).\nPer capire come l’informazione possa essere misurata in bit, consideriamo il seguente esempio discusso da Stone (2022). Immagina di trovarti ad un incrocio e di dover scegliere una strada tra due possibilità. Ogni volta che incontri un incrocio, devi prendere una decisione: andare a destra o a sinistra. Ogni decisione può essere rappresentata da un bit di informazione: 0 per sinistra, 1 per destra.\nConsideriamo un percorso con più incroci, come quello rappresentato nell’immagine. Ogni percorso completo può essere codificato da una sequenza di bit, dove ogni bit corrisponde ad una decisione presa in un incrocio. Ad esempio, per raggiungere il punto D011, la sequenza di bit corretta è 011.\n\n\n\n\n\n\n\n\n\nQuanti bit sono necessari per identificare una destinazione specifica?\nOgni bit raddoppia il numero di possibili percorsi. Quindi, se abbiamo \\(n\\) bit, possiamo identificare \\(2^n\\) destinazioni distinte. Viceversa, se conosciamo il numero di destinazioni \\(m\\), possiamo calcolare il numero di bit necessari utilizzando la formula:\n\\[\nn = \\log_2 m.\n\\]\nNel nostro esempio, abbiamo 8 destinazioni finali. Pertanto, sono necessari \\(\\log_2 8 = 3\\) bit per identificarne una in modo univoco.\nCosa rappresenta un bit in questo contesto?\nUn bit rappresenta un’unità elementare di informazione. In questo caso, ogni bit risponde alla domanda: “Devo andare a destra o a sinistra?”.\nPerché utilizziamo i logaritmi?\nIl logaritmo in base 2 ci permette di calcolare l’esponente a cui elevare 2 per ottenere un dato numero. In altre parole, ci dice quanti bit sono necessari per rappresentare un certo numero di destinazioni. Per l’esempio considerato, per arrivare a \\(D011\\) partendo da \\(A\\), sono necessarie 3 domande la cui risposta binaria è destra/sinistra.\nIn sintesi, esiste una relazione diretta tra il numero di bit di informazione e il numero di possibili destinazioni in un percorso decisionale binario. Ogni bit ci permette di fare una scelta tra due alternative, raddoppiando così il numero di possibili percorsi.\nPer ricapitolare:\n\nAbbiamo visto che per raggiungere il punto D011 partendo da A, abbiamo bisogno di prendere tre decisioni binarie (sinistra o destra) in corrispondenza di tre incroci.\nOgni decisione binaria può essere rappresentata da un bit (0 o 1). Quindi, per l’intero percorso, abbiamo bisogno di una sequenza di tre bit: 011.\nPer rispondere alla domanda “Come andare da A a D011?”, abbiamo dunque bisogno di 3 bit di informazione.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#la-sorpresa-e-linformazione-di-shannon",
    "title": "97  Entropia",
    "section": "97.2 La Sorpresa e l’Informazione di Shannon",
    "text": "97.2 La Sorpresa e l’Informazione di Shannon\nNel primo esempio, abbiamo visto come l’informazione possa essere misurata in bit, dove ogni bit corrisponde a una decisione binaria che ci aiuta a raggiungere una destinazione specifica in un percorso. Tuttavia, la quantità di informazione può variare anche in base alla probabilità con cui certi eventi o scelte si verificano. È qui che entra in gioco il concetto di informazione di Shannon, che prende in considerazione la sorpresa associata a un risultato.\nImmaginiamo, ad esempio, di avere una moneta che cade testa il 90% delle volte. Poiché il risultato “testa” è molto probabile, non ci sorprenderebbe molto ottenerlo. Al contrario, il risultato “croce”, che accade solo il 10% delle volte, ci sorprenderà di più. Più improbabile è un risultato, maggiore sarà la sorpresa nel vederlo.\nIn termini di informazione, possiamo dire che risultati meno probabili forniscono più informazione, perché ci sorprendono di più. Una prima idea per misurare questa sorpresa è definirla come inversamente proporzionale alla probabilità del risultato: \\(1/p(x)\\). Tuttavia, Shannon ha dimostrato che è più utile esprimere la sorpresa come il logaritmo di \\(1/p(x)\\). Questo ci porta alla definizione dell’informazione di Shannon, che si misura in bit (se usiamo il logaritmo in base 2, lo stesso utilizzato per misurare i percorsi nel primo esempio). L’informazione di Shannon per un risultato \\(x\\) è quindi:\n\\[\nh(x) = \\log_2 \\frac{1}{p(x)} = -\\log_2 p(x) \\text{ bit}.\n\\tag{97.1}\\]\nIn questo modo, vediamo che l’informazione associata a un evento dipende dalla sua probabilità: eventi meno probabili portano più informazione, e viceversa.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#sorpresa-e-probabilità",
    "href": "chapters/entropy/01_entropy.html#sorpresa-e-probabilità",
    "title": "97  Entropia",
    "section": "97.3 Sorpresa e Probabilità",
    "text": "97.3 Sorpresa e Probabilità\nPer comprendere pienamente la sorpresa, dobbiamo conoscere le probabilità dei diversi risultati. Questo significa che l’informazione di Shannon dipende dalla distribuzione di probabilità \\(p(X)\\) della variabile aleatoria \\(X\\). In altre parole, per misurare quanta informazione otteniamo da un risultato, dobbiamo sapere quanto è probabile ciascun possibile esito.\nUn modo per stimare queste probabilità è osservare i risultati di un esperimento ripetuto nel tempo. Utilizzando le osservazioni, possiamo stimare la probabilità di ciascun risultato e quindi calcolare l’informazione di Shannon associata. Questo approccio ci permette di collegare il concetto di informazione misurata in bit (come nel primo esempio sugli incroci) con la sorpresa generata da eventi più o meno probabili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-come-media-dellinformazione-di-shannon",
    "href": "chapters/entropy/01_entropy.html#entropia-come-media-dellinformazione-di-shannon",
    "title": "97  Entropia",
    "section": "97.4 Entropia come Media dell’Informazione di Shannon",
    "text": "97.4 Entropia come Media dell’Informazione di Shannon\nQuando si lavora con fenomeni aleatori, spesso non ci interessa solo la sorpresa associata a un singolo risultato, ma piuttosto la sorpresa media che si può ottenere considerando tutti i possibili risultati di una variabile. Questa sorpresa media è chiamata entropia e si indica con \\(H(X)\\). L’entropia ci dà una misura della quantità di incertezza (o informazione potenziale) contenuta in una variabile aleatoria \\(X\\), la cui distribuzione di probabilità è data da \\(p(X)\\).\nL’entropia rappresenta quindi la quantità media di informazione che otteniamo osservando i risultati della variabile \\(X\\). Se, ad esempio, lanciamo una moneta molte volte, l’entropia della distribuzione dei risultati riflette la media delle informazioni di Shannon ottenute da ciascun lancio. In altre parole, ci dice quanto ci aspettiamo di “imparare” in media da ogni lancio.\nMatematicamente, l’entropia può essere approssimata dalla media delle informazioni di Shannon associate a ciascun possibile risultato \\(x_i\\):\n\\[\nH(X) \\approx \\frac{1}{n} \\sum_{i=1}^{n} h(x_i).\n\\tag{97.2}\\]\nIn questa formula, \\(h(x_i)\\) è l’informazione di Shannon di un singolo risultato \\(x_i\\), come discusso in precedenza. L’entropia, quindi, non si riferisce a un evento specifico, ma alla sorpresa media che ci aspettiamo quando osserviamo ripetutamente una variabile aleatoria. Più equilibrata è la distribuzione delle probabilità dei risultati (ad esempio, se tutti i risultati sono ugualmente probabili), maggiore sarà l’entropia, perché ciascun risultato fornisce una quantità simile di informazione. Al contrario, se alcuni risultati sono molto più probabili di altri (ad esempio, una moneta truccata che dà quasi sempre “testa”), l’entropia sarà minore, poiché otteniamo meno informazione da ogni osservazione.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-equa",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-equa",
    "title": "97  Entropia",
    "section": "97.5 Entropia di una Moneta Equa",
    "text": "97.5 Entropia di una Moneta Equa\nSe una moneta è equa, allora \\(p(x_h) = 0.5\\) e la sorpresa di osservare una testa è\n\\[\n\\begin{align}\nh(x_h) &= \\log_2 \\frac{1}{p(x_h)} \\notag\\\\\n       &= \\log_2(1/0.5) = 1 \\text{ bit}.\\notag\n\\end{align}\n\\]\nDato che \\(p(x_t) = 0.5\\), la sorpresa di osservare una testa (o una croce) è di un bit.\nPossiamo trovare la sorpresa media lanciando la moneta, diciamo, 100 volte, misurando la sorpresa di ogni risultato e poi calcolando la media dei 100 risultati. Se lanciamo una moneta 100 volte, ci aspettiamo di osservare testa circa 50 volte e croce circa 50 volte. Se osserviamo esattamente 50 teste e 50 croci, la quantità media di sorpresa diventa\n\\[\n\\begin{align}\nH(X) &= \\frac{1}{100} \\left( \\sum_{i=1}^{50} \\log_2 \\frac{1}{p(x_h)} + \\sum_{i=1}^{50} \\log_2 \\frac{1}{p(x_t)} \\right)\\notag\\\\\n&=1 \\text{ bit per lancio della moneta}\\notag.\n\\end{align}\n\\]\nIn sintesi, poiché la quantità di sorpresa o informazione di Shannon fornita dall’osservazione del risultato di ogni lancio di questa moneta equa è di un bit, ne segue che l’informazione media \\(H(X)\\) di ogni lancio è anch’essa di un bit.\n\n97.5.1 Interpretazione dell’Entropia (1)\nSe consideriamo una distribuzione di probabilità uniforme, una variabile con entropia \\(H(X)\\) espressa in bit fornisce sufficiente informazione (nel senso della teoria dell’informazione di Shannon) per distinguere tra \\(m = 2^{H(X)}\\) alternative ugualmente probabili. In altre parole, l’entropia misura la quantità di informazione contenuta in una variabile, esprimendola in termini di quante scelte ugualmente probabili sono possibili per quella variabile.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-sbilanciata",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-moneta-sbilanciata",
    "title": "97  Entropia",
    "section": "97.6 Entropia di una moneta sbilanciata",
    "text": "97.6 Entropia di una moneta sbilanciata\nUna moneta sbilanciata ha una quantità media di informazione (o incertezza) inferiore rispetto a una moneta equa.\nLa sorpresa associata a testa è:\n\\[\nh(\\text{testa}) = \\log\\left(\\frac{1}{0.9}\\right) = 0.15 \\text{ bit},\n\\]\nmentre la sorpresa associata a croce è maggiore:\n\\[\nh(\\text{croce}) = \\log\\left(\\frac{1}{0.1}\\right) = 3.32 \\text{ bit}.\n\\]\n\n97.6.1 Interpretazione dell’Entropia (2)\nSe immaginiamo di lanciare la moneta tante volte, la sorpresa media o entropia di questa moneta, considerando considerando \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\), è:\n\\[H(X) = 0.9 \\log_2 \\frac{1}{0.9} + 0.1 \\log_2 \\frac{1}{0.1} = 0.469 \\text{ bit per lancio}.\\]\nL’incertezza media per questa moneta sbilanciata è dunque inferiore a quella di una moneta equa (che ha un’entropia di 1 bit), anche se l’incertezza associata all’esito meno probabile (croce) è maggiore (3.32 bit) rispetto a quella di una moneta equa (1 bit). In generale, nessuna moneta sbilanciata può avere un’entropia media maggiore di quella di una moneta equa.\nPoiché \\(p(\\text{testa}) = 0.9\\) e \\(p(\\text{croce}) = 0.1\\), possiamo scrivere la formula dell’entropia come:\n\\[\nH(X) = p(\\text{testa}) \\log\\left(\\frac{1}{p(\\text{testa})}\\right) + p(\\text{croce}) \\log\\left(\\frac{1}{p(\\text{croce})}\\right) = 0.469 \\text{ bit per lancio}.\n\\]\nPer semplificare ulteriormente, possiamo rappresentare l’entropia sommando sui due possibili esiti (testa e croce):\n\\[\nH(X) = \\sum_{i=1}^{2} p(x_i) \\log\\left(\\frac{1}{p(x_i)}\\right) = 0.469 \\text{ bit per lancio}.\n\\]\nQuesta entropia di 0.469 bit implica che l’informazione contenuta in 1.000 lanci di questa moneta potrebbe essere rappresentata usando solo 469 bit binari, cioè \\(1000 \\times 0.469\\).\nPossiamo interpretare questo risultato considerando l’entropia nei termini di un numero di alternative ugualmente probabili. La variabile \\(X\\), che rappresenta il lancio della moneta, potrebbe essere vista come equivalente a una variabile che può assumere:\n\\[\nm = 2^{H(X)} = 2^{0.469} \\approx 1.38 \\text{ valori equiprobabili}.\n\\]\nA prima vista, questo risultato può sembrare strano, dato che stiamo considerando una moneta, che ha solo due esiti possibili. Tuttavia, interpretare l’entropia nei termini di un numero equivalente di valori ugualmente probabili ci offre un’intuizione sull’informazione rappresentata da una variabile. Un modo per pensare a questo concetto è di immaginare che una moneta con entropia \\(H(X) = 0.469\\) bit abbia la stessa quantità di incertezza di un dado ipotetico con 1.38 facce.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#caratteristiche-dellentropia",
    "href": "chapters/entropy/01_entropy.html#caratteristiche-dellentropia",
    "title": "97  Entropia",
    "section": "97.7 Caratteristiche dell’Entropia",
    "text": "97.7 Caratteristiche dell’Entropia\n\nEntropia Massima: L’entropia raggiunge il suo valore massimo quando tutti gli esiti di un evento hanno la stessa probabilità di verificarsi. In questa situazione, l’incertezza è massima, poiché nessun indizio ci permette di prevedere quale sarà il risultato. Questo rappresenta il massimo grado di imprevedibilità.\nEntropia Minima: L’entropia è minima quando l’esito di un evento è completamente certo (con probabilità pari a 1) o impossibile (con probabilità pari a 0). In questi casi, non esiste incertezza né sorpresa, e quindi non c’è alcuna informazione aggiuntiva da ottenere osservando il risultato.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#additività-dellentropia-per-eventi-indipendenti",
    "href": "chapters/entropy/01_entropy.html#additività-dellentropia-per-eventi-indipendenti",
    "title": "97  Entropia",
    "section": "97.8 Additività dell’Entropia per Eventi Indipendenti",
    "text": "97.8 Additività dell’Entropia per Eventi Indipendenti\nL’entropia è additiva nel caso di eventi indipendenti. Ciò significa che, se si verificano due o più eventi indipendenti, l’entropia totale della loro combinazione è pari alla somma delle entropie di ciascun evento considerato singolarmente. Questa proprietà deriva dall’additività dei logaritmi, che permette di sommare le entropie individuali per ottenere l’entropia complessiva.\n\n97.8.1 Stimare l’Entropia da una Distribuzione di Probabilità\nConsideriamo una variabile casuale discreta \\(X\\), che rappresenta una serie di eventi distinti, ciascuno con una probabilità associata. Per una variabile discreta \\(X\\) con possibili valori \\(x_1, x_2, \\dots, x_n\\) e una funzione di massa di probabilità \\(p(x) = \\Pr\\{X = x\\}\\), l’entropia \\(H(X)\\) misura l’incertezza complessiva associata a questa distribuzione di probabilità e si calcola con la formula:\n\\[\n\\begin{equation}\nH(X) = -\\sum_{x \\in X} p(x) \\log_2 p(x).\n\\end{equation}\n\\tag{97.3}\\]\nIn questo contesto, l’entropia \\(H(X)\\) rappresenta l’incertezza media relativa alla collezione di eventi descritti dalla variabile \\(X\\). La formula fornisce una somma pesata delle sorprese associate a ciascun esito, dove la sorpresa di un risultato \\(x\\) dipende dalla sua improbabilità, calcolata come \\(-\\log_2 p(x)\\). Il segno negativo è necessario perché i logaritmi di probabilità, essendo inferiori a 1, sono negativi; il segno negativo li trasforma in valori positivi, che rappresentano correttamente la sorpresa o l’informazione associata.\nOgni termine della somma, \\(-p(x) \\log_2 p(x)\\), esprime la quantità di informazione o sorpresa relativa a un singolo evento, ponderata dalla sua probabilità \\(p(x)\\). Quanto più uniformemente distribuite sono le probabilità degli eventi, tanto maggiore sarà l’entropia complessiva. Al contrario, se uno o più eventi sono molto più probabili rispetto agli altri, l’entropia sarà inferiore, riflettendo una minore incertezza.\nIn sintesi, l’entropia \\(H(X)\\) misura l’incertezza complessiva associata alla distribuzione di probabilità di una variabile casuale discreta \\(X\\). Essa quantifica la sorpresa media che ci si può aspettare quando si osserva un evento estratto casualmente da questa collezione.\n\nEsempio 97.1 Supponiamo di avere un dado con otto facce. Ci sono \\(m = 8\\) esiti possibili:\n\\[\nA_x = \\{1,2,3,4,5,6,7,8\\}.\n\\]\nPoiché il dado è equo, tutti gli otto esiti hanno la stessa probabilità di \\(p(x) = 1/8\\), definendo così una distribuzione di probabilità uniforme:\n\\[\np(X) = \\left\\{\\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}, \\frac{1}{8}\\right\\}.\n\\]\nL’entropia di questa distribuzione può essere calcolata come:\n\\[\nH(X) = - \\sum_{i=1}^{8} \\frac{1}{8} \\log_2 \\frac{1}{8} = \\log_2 8 = 3 \\text{ bit}.\n\\]\nPoiché l’informazione associata a ciascun esito è esattamente 3 bit, anche l’entropia media è di 3 bit, che rappresenta l’incertezza complessiva della variabile \\(X\\).\nDato che \\(X\\) ha un’entropia di \\(H(X) = 3\\) bit, possiamo dire che \\(X\\) può rappresentare fino a:\n\\[\nm = 2^{H(X)} = 2^3 = 8\n\\]\nesiti equiprobabili.\n\n\nEsempio 97.2 Sia \\(X\\) una variabile casuale discreta che può assumere i valori \\(a, b, c,\\) e \\(d\\) con una distribuzione di probabilità di massa \\(p(a) = \\frac{1}{2}\\), \\(p(b) = \\frac{1}{4}\\), \\(p(c) = \\frac{1}{8}\\), e \\(p(d) = \\frac{1}{8}\\), rispettivamente. L’entropia di \\(X\\), che misura l’incertezza associata alla distribuzione di probabilità, è calcolata come:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\log_2 \\frac{1}{2} + \\frac{1}{4} \\log_2 \\frac{1}{4} + \\frac{1}{8} \\log_2 \\frac{1}{8} + \\frac{1}{8} \\log_2 \\frac{1}{8}\\right).\n\\]\nCalcolando i singoli termini, otteniamo:\n\\[\nH(X) = -\\left(\\frac{1}{2} \\cdot (-1) + \\frac{1}{4} \\cdot (-2) + \\frac{1}{8} \\cdot (-3) + \\frac{1}{8} \\cdot (-3)\\right) = \\frac{7}{4} \\text{ bits}.\n\\]\nÈ importante notare che l’entropia \\(H(X)\\) dipende esclusivamente dalla distribuzione di probabilità dei valori di \\(X\\) e non dai valori stessi.\n\n\n\n97.8.2 Stimare l’Entropia in un Campione di Osservazioni\nL’entropia può essere calcolata non solo per distribuzioni teoriche, ma anche per campioni di dati osservati. In questo caso, l’entropia ci fornisce una misura di quanto sia incerta o imprevedibile la distribuzione dei valori all’interno del campione.\n\nEsempio 97.3 Per comprendere meglio questo concetto, possiamo calcolare l’entropia associata a insiemi di osservazioni. Consideriamo i due vettori seguenti:\n\\[\n\\begin{align}\nx &= \\{1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2\\}, \\notag\\\\\ny &= \\{3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4\\}. \\notag\n\\end{align}\n\\]\nTroviamo l’entropia associata a ciascuno di essi.\n\n# Definisco i vettori\nx = np.array([1, 2, 3, 3, 3, 3, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 1, 2])\ny = np.array([3, 4, 1, 1, 1, 1, 4, 3, 1, 1, 4, 3, 3, 2, 2, 1, 3, 4])\n\n# Calcolo il numero di occorrenze di ciascun valore\nx_counts = Counter(x)\ny_counts = Counter(y)\n\n# Calcolo l'entropia di ciascun vettore\nx_probabilities = np.array(list(x_counts.values())) / len(x)\ny_probabilities = np.array(list(y_counts.values())) / len(y)\n\n# Calcolo l'entropia manualmente per ciascun vettore\ndef calculate_entropy(probabilities):\n    return -np.sum(probabilities * np.log2(probabilities))\n\n# Calcolo manualmente l'entropia\nx_entropy = calculate_entropy(x_probabilities)\ny_entropy = calculate_entropy(y_probabilities)\n\n# Risultati\nx_entropy, y_entropy\n\n(1.8776402831734211, 1.8776402831734211)\n\n\nEntrambi i vettori hanno la stessa entropia di 1.8776 bit.\n\n\nEsempio 97.4 Consideriamo un gioco con due giocatori. In questo gioco, vengono considerate solo le 13 carte del seme di quadri da un mazzo standard di 52 carte, e si suppone che ognuna di queste carte abbia la stessa probabilità di essere scelta. Il primo giocatore sceglie una carta tra le 13 carte di quadri. Il secondo giocatore deve indovinare quale carta di quadri è stata scelta facendo domande a cui il primo giocatore risponderà esclusivamente con “sì” o “no”. L’obiettivo è determinare il numero minimo di domande necessarie per identificare esattamente la carta scelta.\nIn questa situazione, la scelta del primo giocatore può essere rappresentata come un vettore one-hot di dimensione 13: \\(X = (x_1, \\dots, x_{13}) \\in \\{0, 1\\}^{13}\\), dove esattamente un elemento \\(x_i\\) è uguale a 1 (indica la carta scelta), mentre gli altri sono uguali a 0. Quindi ci sono 13 possibili scelte.\nL’incertezza associata alla scelta casuale di una carta tra le 13 disponibili è quantificata dall’entropia. Poiché tutte le carte hanno la stessa probabilità di essere selezionate, l’entropia della distribuzione uniforme è data dalla formula:\n\\[\nH(X) = \\log_2 13 \\approx 3.7 \\text{ bit}.\n\\]\nQuesta quantità rappresenta l’incertezza iniziale, ovvero il numero di bit di informazione necessari per determinare esattamente quale delle 13 carte è stata scelta.\nOgni risposta data dal primo giocatore (“sì” o “no”) fornisce 1 bit di informazione, poiché riduce il numero di possibilità di circa la metà. Dato che l’incertezza iniziale è di circa 3.7 bit, il numero minimo di domande necessarie è:\n\\[\n\\frac{3.7}{1} = 3.7 \\text{ risposte},\n\\]\nche in pratica significa che saranno necessarie almeno 4 domande per determinare con certezza la carta scelta.\nPer esempio, possiamo dividere il set iniziale \\(E^{(0)}\\), formato dalle 13 carte di quadri, in due sottoinsiemi:\n\\[\nE_1^{(0)} = \\{1, 2, 3, 4, 5, 6, 7\\}, \\quad E_2^{(0)} = \\{8, 9, 10, 11, 12, 13\\}.\n\\]\nLa prima domanda potrebbe essere: “La carta scelta si trova in \\(E_1^{(0)}\\)?”.\n\nSe la risposta è sì, eliminiamo \\(E_2^{(0)}\\);\nSe la risposta è no, eliminiamo \\(E_1^{(0)}\\).\n\nIn entrambi i casi, ci resta un nuovo set \\(E^{(1)}\\) contenente al massimo 7 carte. Ripetiamo il processo dividendo nuovamente in due sottoinsiemi. Nel caso peggiore, possiamo dividere \\(E^{(1)}\\) in:\n\\[\nE_1^{(1)} = \\{1, 2, 3, 4\\}, \\quad E_2^{(1)} = \\{5, 6, 7\\},\n\\]\ne chiedere se la carta scelta è in \\(E_1^{(1)}\\).\nDopo ogni domanda, riduciamo progressivamente il set di possibili carte fino ad arrivare a una singola carta. Con la quarta domanda possiamo determinare esattamente quale carta è stata scelta.\nIn questo modo, abbiamo confermato che il numero minimo di domande per identificare la carta è 4, dato che l’entropia iniziale della scelta tra 13 carte è di circa 3.7 bit.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#entropia-di-una-variabile-casuale-continua",
    "href": "chapters/entropy/01_entropy.html#entropia-di-una-variabile-casuale-continua",
    "title": "97  Entropia",
    "section": "97.9 Entropia di una Variabile Casuale Continua",
    "text": "97.9 Entropia di una Variabile Casuale Continua\nNel caso delle variabili casuali continue, il concetto di entropia viene generalizzato sostituendo la somma con un integrale. Questo è necessario perché le variabili continue possono assumere un numero infinito di valori all’interno di un intervallo.\nPer una variabile casuale continua \\(X\\) con una funzione di densità di probabilità \\(p(x)\\), l’entropia (nota anche come entropia differenziale) è definita dalla seguente formula:\n\\[ H(X) = -\\int p(x) \\log_2(p(x)) \\, dx, \\]\ndove:\n\n\\(p(x)\\) è la funzione di densità di probabilità di \\(X\\),\nl’integrale è calcolato su tutto il dominio di \\(X\\).\n\nL’entropia di una variabile casuale continua fornisce una misura dell’incertezza o della sorpresa associata alla distribuzione della variabile. Come nel caso discreto, l’entropia continua quantifica l’incertezza associata a \\(X\\). Una PDF molto concentrata (ad esempio, una distribuzione con picchi stretti) implica bassa entropia, poiché l’evento è più prevedibile. Una PDF distribuita uniformemente implica alta entropia, poiché l’evento è meno prevedibile.\nIl segno negativo assicura che l’entropia sia una quantità positiva, in quanto \\(\\log_2(p(x))\\) è negativo per \\(p(x)\\) compreso tra 0 e 1.\nEsempi relativi al calcolo dell’entropia nel caso di variabili continue sono fornite nel Appendice U.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#la-codifica-huffman",
    "href": "chapters/entropy/01_entropy.html#la-codifica-huffman",
    "title": "97  Entropia",
    "section": "97.10 La Codifica Huffman",
    "text": "97.10 La Codifica Huffman\nLa codifica Huffman è un metodo utilizzato per rappresentare gli esiti di una variabile casuale in un formato binario, ottimizzando la lunghezza del codice necessario per descrivere questi esiti. Questo algoritmo crea una rappresentazione binaria che permette di comprimere i dati senza perdita di informazioni, utilizzando una codifica efficiente basata sulla frequenza dei simboli.\nNella codifica Huffman, i simboli più frequenti sono rappresentati da codici binari più brevi, mentre i simboli meno frequenti sono rappresentati da codici più lunghi. Questo approccio assicura che la lunghezza media del codice per rappresentare una sequenza di simboli sia la più corta possibile, ottimizzando così lo spazio necessario per la memorizzazione o la trasmissione dei dati. In questo modo, la codifica Huffman riesce a ridurre la quantità di bit necessari per codificare una variabile casuale, rispettando il principio della teoria dell’informazione che lega la probabilità di un simbolo alla lunghezza del codice a esso associato.\nLa codifica Huffman può essere descritta nel modo seguente.\n\nCreazione della lista di simboli e frequenze:\n\nIn questa fase, si analizza il testo o i dati da comprimere.\nSi conta quante volte appare ogni simbolo (che può essere un carattere, una parola, o qualsiasi unità di informazione).\nSi crea una tabella che elenca ogni simbolo unico e la sua frequenza di apparizione.\nPer esempio, in un testo, potremmo avere: A: 10, B: 5, C: 12, D: 3, E: 15.\n\nCostruzione dell’albero binario:\n\nSi inizia creando un nodo foglia per ogni simbolo. Ogni nodo contiene il simbolo e la sua frequenza.\nPoi si segue questo processo iterativo:\n\nSi selezionano i due nodi con le frequenze più basse.\nSi crea un nuovo nodo padre che ha questi due come figli.\nLa frequenza del nuovo nodo padre è la somma delle frequenze dei figli.\nSi aggiunge questo nuovo nodo all’insieme dei nodi disponibili.\nSi ripete finché non rimane un solo nodo (la radice dell’albero).\n\nDurante questo processo, i simboli più frequenti tendono a rimanere vicini alla radice, mentre quelli meno frequenti si trovano più in profondità nell’albero.\n\nAssegnazione dei codici:\n\nUna volta costruito l’albero, si assegna un bit ‘0’ a ogni ramo sinistro e un bit ‘1’ a ogni ramo destro.\nPer trovare il codice di un simbolo, si parte dalla radice e si segue il percorso fino alla foglia corrispondente, registrando i bit incontrati lungo il cammino.\nI simboli più frequenti avranno codici più corti (più vicini alla radice), mentre quelli meno frequenti avranno codici più lunghi.\n\n\nLa codifica di Huffman è efficace perché:\n\nÈ ottimale per la compressione di simboli singoli.\nGarantisce la decodifica univoca (essendo una codifica prefissa).\nSi adatta alle specifiche frequenze dei simboli nel messaggio da codificare.\n\nIn conclusione, la codifica Huffman è un metodo di compressione dei dati che utilizza le proprietà della probabilità e della teoria dell’informazione per creare una rappresentazione binaria ottimizzata, riducendo così la quantità di dati necessari per rappresentare una sequenza di simboli.\n\nEsempio 97.5 Supponiamo di avere questi simboli e frequenze: A:20, B:10, C:8, D:5. Generiamo i codici di Huffman per ciascun simbolo.\n\nCreiamo nodi foglia per ogni simbolo: (A:20), (B:10), (C:8), (D:5)\nUniamo D e C: ((D:5,C:8):13)\nUniamo B con (D,C): (B:10,(D:5,C:8):13):23)\nInfine, uniamo A con il resto: (A:20,(B:10,(D:5,C:8):13):23):43\n\nL’albero finale sarà:\n       (43)\n      /    \\\n    (20)   (23)\n     |     /   \\\n     A   (10)  (13)\n          |    /  \\\n          B   (5) (8)\n              |    |\n              D    C\nI codici risultanti saranno:\n\nA: 0\nB: 10\nC: 111\nD: 110\n\nQuesto è un esempio di come la codifica di Huffman assegna codici più brevi ai simboli più frequenti, ottimizzando così la lunghezza totale del messaggio codificato.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#lentropia-come-lunghezza-media-del-codice-binario",
    "href": "chapters/entropy/01_entropy.html#lentropia-come-lunghezza-media-del-codice-binario",
    "title": "97  Entropia",
    "section": "97.11 L’Entropia come Lunghezza Media del Codice Binario",
    "text": "97.11 L’Entropia come Lunghezza Media del Codice Binario\nL’entropia, in termini di teoria dell’informazione, rappresenta la quantità media di informazione necessaria per descrivere gli esiti di una variabile casuale. In altre parole, può essere interpretata come la lunghezza media del codice binario utilizzato per rappresentare questi esiti, tenendo conto delle loro probabilità.\nConsideriamo una variabile casuale discreta \\(X\\) che può assumere quattro valori: \\(A, B, C,\\) e \\(D\\), con le seguenti probabilità:\n\n\\(p(A) = 0.4\\)\n\\(p(B) = 0.3\\)\n\\(p(C) = 0.2\\)\n\\(p(D) = 0.1\\)\n\nUtilizzando la codifica Huffman per questa variabile casuale, otteniamo i seguenti codici binari:\n\n\\(A\\) = “0”\n\\(B\\) = “10”\n\\(C\\) = “110”\n\\(D\\) = “111”\n\nLa lunghezza media del codice in bit può essere calcolata come segue:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= p(A) \\times \\text{lunghezza di } A + p(B) \\times \\text{lunghezza di } B\\notag \\\\\n&\\quad + p(C) \\times \\text{lunghezza di } C\\notag + p(D) \\times \\text{lunghezza di } D\\notag.\n\\end{align}\n\\]\nSostituendo i valori delle probabilità e le lunghezze dei codici:\n\\[\n\\begin{align}\n\\text{Lunghezza media} &= (0.4 \\times 1) + (0.3 \\times 2) + (0.2 \\times 3) + (0.1 \\times 3)\\notag\\\\\n&= 0.4 + 0.6 + 0.6 + 0.3 = 1.9 \\text{ bit}.\\notag\n\\end{align}\n\\]\nPossiamo replicare questo risultato usando una funzione Python:\n\n# Distribuzione di probabilità di una variabile casuale discreta\nprobabilities = {\"A\": 0.4, \"B\": 0.3, \"C\": 0.2, \"D\": 0.1}\n\n# Calcolo della lunghezza media del codice di Huffman\navg_length, huffman_dict = huffman_encoding(probabilities)\n\nprint(f\"Lunghezza media del codice di Huffman: {avg_length:.2f} bit/simbolo\")\nprint(\"Codici di Huffman per ciascun simbolo:\")\nfor symbol, code in huffman_dict:\n    print(f\"{symbol}: {code}\")\n\nLunghezza media del codice di Huffman: 1.90 bit/simbolo\nCodici di Huffman per ciascun simbolo:\nA: 0\nB: 10\nC: 111\nD: 110\n\n\nCalcoliamo ora l’entropia \\(H(X)\\) della variabile casuale \\(X\\):\n\\[\n\\begin{align}\nH(X) &= -\\sum p(x) \\log_2 p(x) \\notag\\\\\n     &= -(0.4 \\log_2 0.4 + 0.3 \\log_2 0.3 + 0.2 \\log_2 0.2 + 0.1 \\log_2 0.1)\\notag\\\\\n     &= 1.8465 \\text{ bit}.\n\\end{align}\n\\]\nIn questo esempio, l’entropia è \\(H(X) = 1.8465\\) bit. La lunghezza media del codice Huffman calcolata è di \\(1.9\\) bit, un valore molto vicino all’entropia. Questo ci permette di interpretare l’entropia come la lunghezza media teorica minima del codice binario necessario per rappresentare la variabile casuale \\(X\\). Possiamo affermare che la codifica di Huffman è quasi ottimale, poiché si avvicina molto al limite inferiore stabilito dall’entropia. In altre parole, l’entropia rappresenta effettivamente la lunghezza minima media del codice binario necessaria per descrivere la distribuzione di probabilità di una variabile casuale.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "href": "chapters/entropy/01_entropy.html#applicazioni-psicologiche",
    "title": "97  Entropia",
    "section": "97.12 Applicazioni Psicologiche",
    "text": "97.12 Applicazioni Psicologiche\nUn esempio di applicazione dell’entropia dell’informazione in psicologia riguarda dell’effetto della sorpresa nello studio dell’umore. La sorpresa, o entropia, è stata documentata sia in laboratorio che in contesti naturali come un fattore che influenza le emozioni. Ad esempio, Spector (1956) osservò l’effetto della probabilità a priori sulla soddisfazione dei soggetti in risposta a una promozione lavorativa. I risultati indicano che gli esiti meno probabili a priori (e quindi più sorprendenti quando si verificano) hanno un impatto maggiore sull’umore. In altre parole, quando un evento inatteso e sorprendente si verifica, esso tende a influenzare l’umore in modo più forte rispetto a eventi previsti e probabili.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "href": "chapters/entropy/01_entropy.html#riflessioni-conclusive",
    "title": "97  Entropia",
    "section": "97.13 Riflessioni Conclusive",
    "text": "97.13 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato il concetto di entropia, sottolineando il suo ruolo cruciale nella quantificazione dell’incertezza all’interno delle distribuzioni di probabilità. Nel prossimo capitolo, vedremo come l’entropia possa essere utilizzata per valutare la “distanza” tra un modello teorico e i dati empirici. A tal fine, introdurremo la divergenza di Kullback-Leibler, una misura che quantifica le discrepanze tra due distribuzioni di probabilità.\nConcludiamo il capitolo con una riflessione tratta da Paradoxes in probability theory and mathematical statistics di Gabor Székely, che ci ricorda come la quantificazione dell’informazione non sia sempre un processo lineare o intuitivo:\n\nThe last paradox in this book is a quotation from my late professor Alfréd Rényi. “Since I started to deal with information theory I have often meditated upon the conciseness of poems; how can a single line of verse contain far more ‘information’ than a highly concise telegram of the same length. The surprising richness of meaning of literary works seems to be in contradiction with the laws of information theory. The key to this paradox is, I think, the notion of ‘resonance’. The writer does not merely give us information, but also plays on the strings of the language with such virtuosity, that our mind, and even the subconscious self resonate. A poet can recall chains of ideas, emotions and memories with a wellturned word. In this sense, writing is magic.”\n\nQuesta citazione ci invita a riflettere sulla natura dell’informazione. Ci ricorda che, mentre la teoria dell’informazione fornisce strumenti potenti per quantificare e analizzare l’incertezza e la complessità, esistono forme di comunicazione e espressione che trascendono le misure puramente quantitative. La “risonanza” di cui parla Rényi suggerisce che l’impatto e il significato dell’informazione possono dipendere non solo dal suo contenuto oggettivo, ma anche dal modo in cui essa interagisce con le nostre esperienze, emozioni e conoscenze pregresse.\nQuesta prospettiva ci incoraggia a mantenere un approccio critico nell’applicazione dei concetti di teoria dell’informazione, riconoscendo sia il loro potere analitico che i loro limiti intrinseci nell’interpretazione di fenomeni complessi.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/01_entropy.html#informazioni-sullambiente-di-sviluppo",
    "title": "97  Entropia",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nscipy     : 1.14.0\npandas    : 2.2.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nSpector, A. J. (1956). Expectations, fulfillment, and morale. The Journal of Abnormal and Social Psychology, 52(1), 51–56.\n\n\nStone, J. V. (2022). Information theory: a tutorial introduction, 2nd edition.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html",
    "href": "chapters/entropy/02_kl.html",
    "title": "98  La divergenza di Kullback-Leibler",
    "section": "",
    "text": "Introduzione\nNel campo della statistica bayesiana, è fondamentale confrontare diversi modelli predittivi per determinare quale si adatta meglio ai dati disponibili. In questo capitolo, analizzeremo come l’entropia può essere utilizzata per valutare la “distanza” tra un modello teorico e i dati osservati, introducendo la divergenza di Kullback-Leibler (\\(D_{\\text{KL}}\\)). Questa misura quantifica le discrepanze tra due distribuzioni di probabilità, fornendo un indicatore di quanto accuratamente un modello rappresenti le osservazioni empiriche.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#la-generalizzabilità-dei-modelli-e-il-metodo-scientifico",
    "href": "chapters/entropy/02_kl.html#la-generalizzabilità-dei-modelli-e-il-metodo-scientifico",
    "title": "98  La divergenza di Kullback-Leibler",
    "section": "98.1 La Generalizzabilità dei Modelli e il Metodo Scientifico",
    "text": "98.1 La Generalizzabilità dei Modelli e il Metodo Scientifico\nLa generalizzabilità dei modelli è un concetto fondamentale nella scienza e uno dei pilastri del metodo scientifico. Questo concetto si riferisce alla capacità di un modello di essere applicato con successo e di produrre risultati accurati al di fuori del contesto specifico o del set di dati per cui è stato inizialmente sviluppato o testato. In altre parole, il valore scientifico di un modello dipende fortemente dalla sua capacità di generalizzare a nuovi dati.\nNella pratica, la generalizzabilità di un modello può essere compromessa da due problemi principali: il sotto-adattamento e il sovra-adattamento.\n\nSotto-adattamento: Si verifica quando un modello è troppo semplice per rappresentare adeguatamente la complessità dei dati. Un modello sotto-adattato non riesce a catturare le relazioni essenziali nei dati, portando a prestazioni scadenti sia sul set di dati di addestramento che su nuovi dati. Questo limita gravemente la sua utilità in applicazioni pratiche.\nSovra-adattamento: Si manifesta quando un modello è eccessivamente complesso e si adatta troppo fedelmente al rumore o alle particolarità specifiche del set di dati di addestramento. Un modello sovra-adattato può mostrare ottime prestazioni sui dati di addestramento, ma fallisce nel generalizzare a nuovi dati, riducendo la sua efficacia predittiva.\n\nL’approccio bayesiano alla modellazione offre un modo efficace per bilanciare la complessità del modello con l’adattamento ai dati. Come descritto da McElreath (2020), la selezione del modello è un processo che richiede un equilibrio tra la semplicità del modello e la sua capacità di rappresentare accuratamente la realtà dei dati.\nUna pratica comune nella scelta tra modelli alternativi si basa sul principio del rasoio di Ockham, che favorisce le spiegazioni più semplici quando ci sono più teorie equivalenti per un fenomeno. Tuttavia, questo principio da solo non è sufficiente; è fondamentale che il modello scelto descriva accuratamente i dati.\nTradizionalmente, la selezione dei modelli è stata spesso basata sull’uso dei valori-p, ma, come evidenziato da McElreath (2020), questo approccio presenta numerosi problemi e manca di una giustificazione teorica solida.\nUn metodo più robusto e teoricamente fondato è l’uso della divergenza di Kullback-Leibler, che misura quanto un modello riesca ad approssimare efficacemente la distribuzione reale dei dati. Questa misura fornisce una stima quantitativa della precisione del modello nel rappresentare il processo generativo sottostante. Questo capitolo introduce il concetto di divergenza di Kullback-Leibler e le sue applicazioni nella selezione dei modelli.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#lentropia-relativa",
    "href": "chapters/entropy/02_kl.html#lentropia-relativa",
    "title": "98  La divergenza di Kullback-Leibler",
    "section": "98.2 L’Entropia Relativa",
    "text": "98.2 L’Entropia Relativa\nNel Capitolo 97 abbiamo illustrato la relazione tra l’entropia e la lunghezza media minima del codice binario necessario per descrivere la distribuzione di una variabile casuale. Possiamo ora introdurre il concetto di entropia relativa, conosciuta anche come divergenza di Kullback-Leibler (Kullback & Leibler, 1951). L’entropia relativa è una misura della “distanza” tra due distribuzioni di probabilità, che quantifica quanto una distribuzione si discosta da un’altra.\n\n98.2.1 Concetto di Divergenza di Kullback-Leibler\nLa divergenza di Kullback-Leibler, indicata come \\(D(P \\parallel Q)\\), è una misura dell’inefficienza che si verifica assumendo che i dati seguano una distribuzione \\(Q\\), quando in realtà la distribuzione corretta è \\(P\\). In altre parole, questa misura quantifica la perdita di efficienza nel codificare dati se si utilizza una distribuzione errata anziché quella reale.\nDal punto di vista della teoria dell’informazione, \\(D(P \\parallel Q)\\) esprime quanto sia meno efficiente, in termini di lunghezza media del codice, utilizzare una distribuzione errata \\(Q\\) per descrivere i dati, rispetto a usare la distribuzione vera \\(P\\).\nSe conoscessimo la distribuzione vera \\(P\\) di una variabile casuale, potremmo costruire un codice ottimale basato sulla codifica di Huffman, con una lunghezza media pari all’entropia \\(H(P)\\). Tuttavia, se si costruisce un codice sulla base di una distribuzione diversa \\(Q\\), la lunghezza media richiesta per descrivere la variabile casuale aumenterebbe. In questo caso, la lunghezza media del codice sarebbe pari a \\(H(P) + D(P \\parallel Q)\\) bit.\nLa quantità \\(D(P \\parallel Q)\\) rappresenta quindi il sovraccarico, o l’inefficienza aggiuntiva, derivante dall’uso di \\(Q\\) al posto di \\(P\\). Più la distribuzione \\(Q\\) differisce da \\(P\\), maggiore sarà la divergenza di Kullback-Leibler, e quindi più inefficiente sarà la codifica basata su \\(Q\\).\n\n\n98.2.2 Definizione della Divergenza di Kullback-Leibler\nPer una variabile casuale discreta, la divergenza di Kullback-Leibler è definita come:\n\\[\nD(P \\parallel Q) = \\sum_{x} p(x) \\log_2 \\left( \\frac{p(x)}{q(x)} \\right),\n\\tag{98.1}\\]\ndove:\n\n\\(p(x)\\) è la probabilità associata al valore \\(x\\) secondo la distribuzione vera \\(P\\).\n\\(q(x)\\) è la probabilità associata al valore \\(x\\) secondo la distribuzione approssimata \\(Q\\).\n\nQuesta formula rappresenta la somma, pesata dalle probabilità \\(p(x)\\), dei logaritmi del rapporto tra le probabilità delle due distribuzioni.\n\n\n98.2.3 Entropia, Entropia Incrociata e Divergenza KL\nPer chiarire ulteriormente il concetto, mostriamo che la divergenza di Kullback-Leibler può essere vista come la differenza tra l’entropia incrociata tra \\(P\\) e \\(Q\\), e l’entropia di \\(P\\):\n\\[\nD_{\\text{KL}}(P \\parallel Q) = H(P, Q) - H(P),\n\\tag{98.2}\\]\nladdove l’entropia incrociata \\(H(P, Q)\\) misura l’incertezza media quando si usa la distribuzione \\(Q\\) per descrivere la variabile casuale \\(X\\) distribuita secondo \\(P\\):\n\\[\nH(P, Q) = -\\sum_x p(x) \\log_2(q(x)).\n\\tag{98.3}\\]\nL’entropia incrociata rappresenta la sorpresa media se si assume che i dati siano distribuiti secondo \\(Q\\) quando in realtà seguono \\(P\\).\nSostituendo le espressioni per \\(H(P)\\) e \\(H(P, Q)\\) nella definizione della divergenza di Kullback-Leibler, otteniamo:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\left(- \\sum_x p(x) \\log_2 q(x)\\right) - \\left(- \\sum_x p(x) \\log_2 p(x)\\right).\n\\]\nNotiamo che i segni negativi possono essere eliminati, portando a:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\log_2 p(x) - \\sum_x p(x) \\log_2 q(x).\n\\]\nOra possiamo raccogliere i due termini in una singola somma:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\left( \\log_2 p(x) - \\log_2 q(x) \\right).\n\\]\nUtilizziamo la proprietà dei logaritmi \\(\\log_2 \\left(\\frac{a}{b}\\right) = \\log_2 a - \\log_2 b\\) per combinare i termini all’interno del logaritmo e otteniamo la formula esplicita della divergenza di Kullback-Leibler:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_x p(x) \\log_2 \\left( \\frac{p(x)}{q(x)} \\right).\n\\]\nQuesta espressione quantifica la differenza tra le distribuzioni \\(P\\) e \\(Q\\), misurando l’inefficienza nell’uso di \\(Q\\) per rappresentare \\(P\\).\n\n\n98.2.4 Interpretazione della Divergenza KL\nLa divergenza \\(D_{\\text{KL}}(P \\parallel Q)\\) rappresenta il “costo” aggiuntivo di sorpresa o inefficienza quando si utilizza la distribuzione \\(Q\\) per modellare i dati che in realtà seguono la distribuzione \\(P\\). Questo “costo” è espresso in bit e rappresenta l’informazione che viene “persa” quando \\(Q\\) è usata al posto di \\(P\\).\nÈ importante notare che la divergenza di Kullback-Leibler è asimmetrica, il che significa che \\(D(P \\parallel Q)\\) non è uguale a \\(D(Q \\parallel P)\\), e non può essere interpretata come una vera e propria “distanza” tra le distribuzioni, ma piuttosto come una misura dell’informazione persa, ovvero di inefficienza di codifica.\nIn sintesi, l’entropia relativa o divergenza di Kullback-Leibler è una misura chiave nella teoria dell’informazione. Essa valuta l’efficacia di un modello probabilistico confrontando una distribuzione teorica con la distribuzione vera dei dati. La divergenza KL fornisce un metodo per quantificare la perdita di informazione e l’incremento di incertezza quando si utilizza una distribuzione approssimativa per descrivere dati reali.\n\nEsempio 98.1 Supponiamo che \\(P\\) e \\(Q\\) siano due distribuzioni di probabilità su un insieme finito di possibili esiti, ad esempio {0, 1, 2}. Consideriamo che \\(P\\) e \\(Q\\) siano definite come segue:\n\n\\(P\\) è la distribuzione “vera”: \\(P = [0.1, 0.6, 0.3]\\);\n\\(Q\\) è una distribuzione alternativa che usiamo per la stima: \\(Q = [0.2, 0.5, 0.3]\\).\n\n\n# Definizione delle distribuzioni\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.2, 0.5, 0.3])\n\n# Calcolo della divergenza KL da P a Q\nKL_divergence = np.sum(kl_div(P, Q))\n\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.0401\n\n\nNel codice precedente, kl_div(P, Q) calcola la divergenza \\(D_{\\text{KL}}\\) elemento per elemento dell’array. Essa calcola \\(\\sum_x p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)\\) per ogni esito \\(x\\), che è esattamente il termine \\(p(x) \\log \\left(\\frac{p(x)}{q(x)}\\right)\\) descritto nella formula della divergenza \\(D_{\\text{KL}}\\). Utilizziamo poi np.sum per sommare tutti i contributi individuali e ottenere il valore totale della divergenza \\(D_{\\text{KL}}\\).\nQuesto esempio fornisce un calcolo diretto della divergenza \\(D_{\\text{KL}}\\) tra due distribuzioni, mostrando come una distribuzione \\(Q\\) possa essere inadeguata nel modellare una distribuzione \\(P\\), con un focus sul “costo” di sorpresa per ogni esito.\n\n\nEsempio 98.2 In altri due esempi, rendiamo via via \\(Q\\) più diverso da \\(P\\). Notiamo come la divergenza \\(D_{\\text{KL}}\\) aumenta.\n\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.35, 0.3, 0.35])\nKL_divergence = np.sum(kl_div(P, Q))\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.2444\n\n\n\nP = np.array([0.1, 0.6, 0.3])\nQ = np.array([0.6, 0.3, 0.1])\nKL_divergence = np.sum(kl_div(P, Q))\nprint(f\"Divergenza KL da P a Q: {KL_divergence:.4f}\")\n\nDivergenza KL da P a Q: 0.5663",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#applicazione-della-divergenza-d_textkl-nella-selezione-di-modelli",
    "href": "chapters/entropy/02_kl.html#applicazione-della-divergenza-d_textkl-nella-selezione-di-modelli",
    "title": "98  La divergenza di Kullback-Leibler",
    "section": "98.3 Applicazione della Divergenza \\(D_{\\text{KL}}\\) nella Selezione di Modelli",
    "text": "98.3 Applicazione della Divergenza \\(D_{\\text{KL}}\\) nella Selezione di Modelli\nLa divergenza di Kullback-Leibler, \\(D_{\\text{KL}}\\), è uno strumento fondamentale nella selezione dei modelli statistici. L’obiettivo è identificare il modello \\(Q\\) che minimizza \\(D_{\\text{KL}}(P \\parallel Q)\\), riducendo al minimo la differenza tra l’entropia della distribuzione vera \\(P\\) e l’entropia incrociata tra \\(P\\) e \\(Q\\). In altre parole, si cerca di minimizzare l’errore introdotto nell’approssimare la distribuzione reale \\(P\\) con il modello \\(Q\\).\n\n98.3.1 Proprietà Chiave\n\nNon-negatività: La divergenza \\(D_{\\text{KL}}(P \\parallel Q)\\) è sempre maggiore o uguale a zero. Questo valore è pari a zero solo quando le distribuzioni \\(P\\) e \\(Q\\) sono identiche, indicando una perfetta corrispondenza tra il modello e la distribuzione vera.\nAsimmetria: \\(D_{\\text{KL}}(P \\parallel Q) \\neq D_{\\text{KL}}(Q \\parallel P)\\). Questa proprietà mostra che la “distanza” percepita tra \\(P\\) e \\(Q\\) dipende dalla direzione in cui è misurata. La divergenza di \\(Q\\) rispetto a \\(P\\) non è la stessa della divergenza di \\(P\\) rispetto a \\(Q\\).\n\n\n\n98.3.2 Selezione dei Modelli Statistici\nNel contesto della selezione dei modelli statistici, l’obiettivo principale è scegliere il modello \\(Q\\) che minimizzi la divergenza \\(D_{\\text{KL}}(P \\parallel Q)\\) rispetto alla distribuzione reale \\(P\\) dei dati. Tuttavia, poiché la distribuzione vera \\(P\\) è spesso sconosciuta o non direttamente osservabile, non è possibile calcolare la divergenza \\(D_{\\text{KL}}\\) in modo diretto.\nPer superare questa limitazione, i ricercatori e gli statistici utilizzano criteri approssimativi per stimare indirettamente la divergenza \\(D_{\\text{KL}}\\). Questi criteri considerano sia la bontà di adattamento del modello ai dati osservati sia la complessità del modello stesso, cercando un equilibrio tra accuratezza e parsimonia. Nel capitolo successivo, esploreremo questi criteri in dettaglio e discuteremo come vengono utilizzati per valutare e selezionare i modelli statistici migliori.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#riflessioni-conclusive",
    "href": "chapters/entropy/02_kl.html#riflessioni-conclusive",
    "title": "98  La divergenza di Kullback-Leibler",
    "section": "98.4 Riflessioni Conclusive",
    "text": "98.4 Riflessioni Conclusive\nIn questo capitolo, abbiamo affrontato la questione di come l’entropia possa essere impiegata per valutare la “distanza” tra un modello teorico e i dati reali. A tale scopo, abbiamo introdotto la divergenza \\(\\mathbb{KL}\\), una misura che quantifica le discrepanze tra due distribuzioni di probabilità.\nNel capitolo successivo, approfondiremo ulteriormente il tema della divergenza \\(\\mathbb{KL}\\). Esploreremo come questo strumento possa essere utilizzato per confrontare modelli teorici con dati empirici e ci concentreremo su come possa fornirci una comprensione più dettagliata dell’adattamento di un modello alla realtà che intende rappresentare. Questa esplorazione ci permetterà di valutare più accuratamente la validità e la generalizzabilità dei modelli scientifici nel loro tentativo di catturare e interpretare la complessità dei fenomeni oggetto di studio. Specificamente, presenteremo la tecnica della Validazione Incrociata Leave-One-Out (LOO-CV), che viene utilizzata per calcolare un’approssimazione della divergenza \\(D_{\\text{KL}}\\). Questa tecnica consente di stimare quanto bene un modello generalizzi i dati, offrendo un’ulteriore metrica per la valutazione dei modelli statistici.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#esercizi",
    "href": "chapters/entropy/02_kl.html#esercizi",
    "title": "98  La divergenza di Kullback-Leibler",
    "section": "98.5 Esercizi",
    "text": "98.5 Esercizi\n\nEsercizio 98.1 Cosideriamo due distribuzioni di probabilità discrete, \\(p\\) e \\(q\\):\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.1, 0.2, 0.7])\nSi calcoli l’entropia di \\(p\\), l’entropia incrociata tra \\(p\\) e \\(q\\), la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).\nSi consideri q = np.array([0.2, 0.55, 0.25]) e si calcoli di nuovo a divergenza di Kullback-Leibler da \\(p\\) a \\(q\\). Si confronti con il risultato precedente e si interpreti.\n\n\nEsercizio 98.2 Sia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\). Sia \\(q_1\\) una approssimazione a \\(p\\): q1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01]). Sia \\(q_2\\) una distribuzione uniforme: q2 = [0.2] * 5. Si calcoli la divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) e da \\(q_2\\) da \\(p\\) e si interpretino i risultati.\n\n\nEsercizio 98.3 La Divergenza \\(\\mathbb{KL}\\) è spesso paragonata a una “distanza” tra due distribuzioni di probabilità, ma è fondamentale capire che non è simmetrica. Questo significa che la misura di quanto \\(p\\) è diversa da \\(q\\) non è la stessa di quanto \\(q\\) è diversa da \\(p\\). Questa asimmetria riflette la differenza nella perdita di informazione quando si sostituisce una distribuzione con l’altra.\nPer le seguenti distribuzioni\np = np.array([0.01, 0.99])\nq = np.array([0.7, 0.3])\nsi calcoli l’entropia di p, l’entropia incrociata da p a q, la divergenza KL da p a q, l’entropia di q, l’entropia incrociata da q a p, e la divergenza KL da q a p. Si commenti.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/02_kl.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/02_kl.html#informazioni-sullambiente-di-sviluppo",
    "title": "98  La divergenza di Kullback-Leibler",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nmatplotlib: 3.9.1\nscipy     : 1.14.0\npandas    : 2.2.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nKullback, S., & Leibler, R. A. (1951). On information and sufficiency. The Annals of Mathematical Statistics, 22(1), 79–86.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>La divergenza di Kullback-Leibler</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html",
    "href": "chapters/entropy/03_model_comparison.html",
    "title": "99  Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esamineremo in dettaglio quattro concetti fondamentali per la valutazione e il confronto di modelli statistici nel contesto bayesiano: la distribuzione predittiva posteriore, la divergenza \\(D_{\\text{KL}}\\), il Log-Pointwise-Predictive-Density (LPPD) e la Densità Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD). Questi strumenti ci permettono di quantificare l’adattamento dei modelli ai dati e la loro capacità predittiva.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#distribuzione-predittiva-posteriore",
    "href": "chapters/entropy/03_model_comparison.html#distribuzione-predittiva-posteriore",
    "title": "99  Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "99.1 Distribuzione Predittiva Posteriore",
    "text": "99.1 Distribuzione Predittiva Posteriore\nLa distribuzione predittiva posteriore \\(q(\\tilde{y} \\mid y)\\) rappresenta la distribuzione dei possibili nuovi dati \\(\\tilde{y}\\), alla luce dei dati osservati \\(y\\). Essa si ottiene combinando:\n\nla distribuzione del modello per i nuovi dati data una configurazione dei parametri \\(\\theta\\): \\(q(\\tilde{y} \\mid \\theta)\\);\nla distribuzione posteriore dei parametri dati i dati osservati: \\(p(\\theta \\mid y)\\).\n\nMatematicamente, la distribuzione predittiva posteriore può essere scritta come:\n\\[\nq(\\tilde{y} \\mid y) = \\int q(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) d\\theta.\n\\]\nQuesta espressione si legge come l’integrale della distribuzione predittiva \\(q(\\tilde{y} \\mid \\theta)\\) pesata dalla distribuzione posteriore dei parametri \\(p(\\theta \\mid y)\\). In altre parole, stiamo “mediando” le previsioni del modello su tutte le possibili configurazioni dei parametri, tenendo conto della loro probabilità posteriore. La distribuzione predittiva posteriore è stata descritta nella Sezione 56.1.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#divergenza-di-kullback-leibler-d_textkl",
    "href": "chapters/entropy/03_model_comparison.html#divergenza-di-kullback-leibler-d_textkl",
    "title": "99  Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "99.2 Divergenza di Kullback-Leibler \\(D_{\\text{KL}}\\)",
    "text": "99.2 Divergenza di Kullback-Leibler \\(D_{\\text{KL}}\\)\nLa divergenza di Kullback-Leibler, \\(D_{\\text{KL}}\\), misura la “distanza” tra due distribuzioni di probabilità, \\(P\\) e \\(Q\\). Essa è definita come:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\mathbb{E}_P[\\log p(X)] - \\mathbb{E}_P[\\log q(X)],\n\\]\ndove \\(\\mathbb{E}_P[\\log p(X)]\\) rappresenta il valore atteso del logaritmo della distribuzione \\(p(X)\\) rispetto a \\(P\\) stessa, e \\(\\mathbb{E}_P[\\log q(X)]\\) è il valore atteso del logaritmo della distribuzione \\(q(X)\\) rispetto alla distribuzione \\(P\\).\nPer variabili discrete, il valore atteso \\(\\mathbb{E}_P[\\log p(X)]\\) è calcolato come:\n\\[\n\\mathbb{E}_P[\\log p(X)] = \\sum_{i=1}^n p_i \\log p_i,\n\\]\ndove \\(p_i = p(x_i)\\) è la probabilità associata al valore \\(x_i\\).\nNel caso di variabili continue, questa espressione diventa:\n\\[\n\\mathbb{E}_P[\\log p(X)] = \\int p(x) \\log p(x) \\, dx,\n\\]\nche rappresenta l’entropia negativa della distribuzione \\(p\\).\nIl termine \\(\\mathbb{E}_P[\\log q(X)]\\) rappresenta il valore atteso del logaritmo della distribuzione \\(q(X)\\) sotto la distribuzione \\(p(X)\\):\n\\[\n\\mathbb{E}_P[\\log q(X)] = \\sum_{i=1}^n p_i \\log q_i\n\\]\nper variabili discrete, e:\n\\[\n\\mathbb{E}_P[\\log q(X)] = \\int p(x) \\log q(x) \\, dx\n\\]\nper variabili continue. Questo termine rappresenta l’entropia incrociata tra \\(P\\) e \\(Q\\).\nQuindi, la divergenza \\(D_{\\text{KL}}\\) può essere espressa per variabili discrete come:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_{i=1}^n p_i (\\log p_i - \\log q_i),\n\\]\ne per variabili continue come:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\int p(x) (\\log p(x) - \\log q(x)) \\, dx.\n\\]\nUn punto importante è che la divergenza \\(D_{\\text{KL}}\\) non è simmetrica, cioè \\(D_{\\text{KL}}(P \\parallel Q) \\neq D_{\\text{KL}}(Q \\parallel P)\\). Questa asimmetria riflette il fatto che la divergenza misura quanta “informazione” si perde usando la distribuzione \\(Q\\) al posto della distribuzione vera \\(P\\).\n\nEsempio 99.1 Per illustrare meglio il concetto di divergenza di Kullback-Leibler \\(D_{\\text{KL}}\\) nel caso discreto, consideriamo un esempio semplice con due distribuzioni di probabilità discrete, \\(P\\) e \\(Q\\), definite su un insieme di eventi \\(\\{A, B, C\\}\\). Supponiamo che le probabilità associate a ciascun evento sotto le distribuzioni \\(P\\) e \\(Q\\) siano le seguenti:\n\nDistribuzione \\(P\\): \\(p(A) = 0.5\\), \\(p(B) = 0.3\\), \\(p(C) = 0.2\\)\nDistribuzione \\(Q\\): \\(q(A) = 0.4\\), \\(q(B) = 0.4\\), \\(q(C) = 0.2\\)\n\nLa divergenza di Kullback-Leibler \\(D_{\\text{KL}}(P \\parallel Q)\\) è definita come:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = \\sum_{i} p(i) \\log \\frac{p(i)}{q(i)},\n\\]\ndove \\(i\\) scorre su tutti gli eventi possibili \\(\\{A, B, C\\}\\). In questo caso, dobbiamo calcolare i seguenti termini: \\(p(A) \\log \\frac{p(A)}{q(A)}\\), \\(p(B) \\log \\frac{p(B)}{q(B)}\\), e \\(p(C) \\log \\frac{p(C)}{q(C)}\\).\nCalcoliamo ciascun termine:\n\\[\np(A) \\log \\frac{p(A)}{q(A)} = 0.5 \\log \\frac{0.5}{0.4} \\approx 0.11155,\n\\]\n\\[\np(B) \\log \\frac{p(B)}{q(B)} = 0.3 \\log \\frac{0.3}{0.4} \\approx -0.08631,\n\\]\n\\[\np(C) \\log \\frac{p(C)}{q(C)} = 0.2 \\log \\frac{0.2}{0.2} = 0.\n\\]\nOra, sommiamo tutti i termini per ottenere la divergenza di Kullback-Leibler:\n\\[\nD_{\\text{KL}}(P \\parallel Q) = 0.11155 + (-0.08631) + 0 = 0.02524.\n\\]\nQuindi, la divergenza KL \\(D_{\\text{KL}}(P \\parallel Q) \\approx 0.025\\) indica che la distribuzione \\(Q\\) è relativamente vicina alla distribuzione \\(P\\), con una piccola discrepanza tra le due. Un valore più elevato di \\(D_{\\text{KL}}\\) suggerirebbe una maggiore differenza tra le distribuzioni \\(P\\) e \\(Q\\), indicando una maggiore perdita di informazione se si utilizza \\(Q\\) al posto di \\(P\\).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#problema-con-p-sconosciuto",
    "href": "chapters/entropy/03_model_comparison.html#problema-con-p-sconosciuto",
    "title": "99  Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "99.3 Problema con \\(p\\) Sconosciuto",
    "text": "99.3 Problema con \\(p\\) Sconosciuto\nIl problema principale nella pratica statistica è che la distribuzione vera dei dati, indicata con \\(p(x)\\), non è nota. Se conoscessimo la distribuzione \\(p(x)\\), non sarebbe necessario fare inferenza statistica. Tuttavia, il nostro obiettivo è confrontare diversi modelli, come \\(q(x)\\) e \\(r(x)\\), per determinare quale di essi si avvicina di più a \\(p(x)\\).\n\n99.3.1 L’Idea della Divergenza Relativa\nFortunatamente, per confrontare due modelli \\(q(x)\\) e \\(r(x)\\), non è necessario conoscere esattamente la distribuzione \\(p(x)\\). Possiamo confrontare i modelli in termini di divergenza relativa da \\(p(x)\\). In pratica, quando confrontiamo le divergenze \\(D_{\\text{KL}}(p \\parallel q)\\) e \\(D_{\\text{KL}}(p \\parallel r)\\), molte componenti legate a \\(p(x)\\) si annullano, perché stiamo considerando la differenza tra le due divergenze. Questa differenza dipende principalmente dalla differenza tra \\(q(x)\\) e \\(r(x)\\), non dalla distribuzione \\(p(x)\\) stessa.\n\n\n99.3.2 Log-Probability Score (Log-Score)\nIl log-probability score (o log-score) è una misura pratica che possiamo utilizzare per valutare i modelli in assenza della conoscenza della distribuzione vera \\(p(x)\\). Per ogni modello \\(q(x)\\), il log-score è calcolato come:\n\\[\nS(q) = \\sum_{i} \\log(q(x_i)),\n\\]\ndove \\(q(x_i)\\) rappresenta la probabilità predetta dal modello \\(q(x)\\) per l’evento \\(x_i\\).\nQuesto score rappresenta una stima dell’aspettativa del logaritmo delle probabilità predette dal modello \\(q(x)\\) rispetto ai dati osservati. In altre parole, misura quanto bene il modello \\(q(x)\\) predice i dati osservati. Un log-score più alto indica un modello con una migliore accuratezza predittiva, poiché il modello assegnerebbe una probabilità maggiore agli eventi che si verificano effettivamente.\n\nEsempio 99.2 Consideriamo un semplice esempio numerico per illustrare il calcolo del log-probability score (o log-score) per un modello \\(q\\). Immaginiamo di avere un piccolo dataset con 3 osservazioni, e che il modello \\(q\\) predica le probabilità per ciascuna osservazione come segue:\n\nOsservazione 1: \\(q_1 = 0.8\\),\nOsservazione 2: \\(q_2 = 0.6\\),\nOsservazione 3: \\(q_3 = 0.7\\).\n\nIl log-score si calcola sommando i logaritmi delle probabilità predette:\n\\[\nS(q) = \\log(0.8) + \\log(0.6) + \\log(0.7) \\approx -0.2231 + (-0.5108) + (-0.3567) = -1.0906.\n\\]\nIl log-score totale per questo modello \\(q\\) è \\(-1.0906\\). Poiché un log-score più alto (meno negativo) indica una migliore accuratezza predittiva, questo risultato suggerisce che \\(q\\) ha una discreta accuratezza per le osservazioni date. Un modello \\(r\\) con un log-score più alto sarebbe preferibile in termini di accuratezza predittiva rispetto a \\(q\\).\n\n\nEsempio 99.3 Per chiarire ulteriormente il concetto di log-probability score, possiamo applicarlo al caso di un modello di regressione. In questo contesto, il calcolo del log-probability score implica la valutazione della probabilità che il modello assegna a ciascuna osservazione, considerando la distribuzione degli errori associata al modello.\nConsideriamo un modello di regressione lineare semplice:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i,\n\\]\ndove \\(y_i\\) è la variabile dipendente, \\(x_i\\) è la variabile indipendente, \\(\\beta_0\\) e \\(\\beta_1\\) sono i coefficienti del modello, e \\(\\epsilon_i\\) è l’errore, tipicamente assunto come distribuito secondo una normale \\(\\mathcal{N}(0, \\sigma^2)\\).\nPer calcolare la probabilità di ciascuna osservazione \\(y_i\\) data la predizione del modello, usiamo la distribuzione degli errori. Se \\(y_i\\) è distribuito secondo una normale con media \\(\\hat{y}_i = \\beta_0 + \\beta_1 x_i\\) e varianza \\(\\sigma^2\\), allora la probabilità di osservare \\(y_i\\) è:\n\\[\np(y_i \\mid x_i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\hat{y}_i)^2}{2\\sigma^2}\\right).\n\\]\nIl log-score per ciascuna osservazione è il logaritmo della probabilità predetta:\n\\[\n\\log p(y_i \\mid x_i) = -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(y_i - \\hat{y}_i)^2}{2\\sigma^2}.\n\\]\nIl log-score totale del modello è la somma dei log-score su tutte le osservazioni:\n\\[\nS(q) = \\sum_{i=1}^n \\log p(y_i \\mid x_i) = -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2.\n\\]\n\nPrimo termine: \\(-\\frac{n}{2} \\log(2\\pi\\sigma^2)\\) è una costante che dipende dal numero di osservazioni \\(n\\) e dalla varianza degli errori \\(\\sigma^2\\).\nSecondo termine: \\(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\) è proporzionale alla somma dei quadrati degli errori (SSE), che misura quanto le predizioni si discostano dai valori osservati.\n\nIl log-score fornisce quindi una misura dell’accuratezza del modello di regressione, con valori più alti (meno negativi) che indicano un modello migliore. In pratica, poiché il primo termine è una costante, la differenza nei log-score tra modelli diversi sarà determinata principalmente dal secondo termine, legato alla SSE.\nIn sintesi, nel contesto di un modello di regressione, la probabilità di ciascuna osservazione si basa sulla distribuzione normale degli errori, e il log-score riflette quanto bene il modello predice i dati osservati, penalizzando modelli con errori più grandi.\n\n\n\n99.3.3 Log-Pointwise-Predictive-Density (LPPD)\nIl Log-Pointwise-Predictive-Density (LPPD) è una versione bayesiana del log-score, che tiene conto dell’incertezza sui parametri del modello. In un contesto bayesiano, non abbiamo un solo set di parametri \\(\\theta_s\\), ma una distribuzione posteriore su di essi. Pertanto, il log-score viene calcolato come una media logaritmica su questa distribuzione. Il LPPD è una misura che deriva direttamente dalla distribuzione predittiva posteriore e rappresenta la somma delle densità predittive logaritmiche calcolate per ogni osservazione, mediate sulla distribuzione posteriore dei parametri. Formalmente, si definisce come:\n\\[\n\\text{LPPD} = \\sum_{i=1}^n \\log \\left(\\frac{1}{S} \\sum_{s=1}^{S} p(y_i \\mid \\theta_s)\\right),\n\\]\ndove:\n\n\\(y_i\\) è l’i-esima osservazione,\n\\(S\\) è il numero di campioni dalla distribuzione posteriore,\n\\(\\theta_s\\) è un campione di parametri dalla distribuzione posteriore.\n\nIl LPPD tiene conto dell’incertezza nei parametri, calcolando il logaritmo della densità predittiva media per ogni punto dati, mediata su tutte le possibili configurazioni dei parametri posteriore. Questo approccio è fondamentale per catturare la reale capacità predittiva di un modello, tenendo conto della variabilità nei parametri.\nIn conclusione, il log-score e il LPPD sono metodi per stimare la bontà di un modello rispetto ai dati osservati, senza richiedere la conoscenza esatta di \\(p\\). Anche se non possiamo calcolare direttamente la divergenza \\(D_{\\text{KL}}\\) perché \\(p\\) è sconosciuto, possiamo comunque confrontare diversi modelli basandoci su queste misure. La differenza tra i log-score (o LPPD) di due modelli \\(q\\) e \\(r\\) ci dà un’informazione su quale modello è “più vicino” alla verità, analogamente a come useremmo la divergenza \\(D_{\\text{KL}}\\) se conoscessimo \\(p\\).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#expected-log-predictive-density-elpd",
    "href": "chapters/entropy/03_model_comparison.html#expected-log-predictive-density-elpd",
    "title": "99  Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "99.4 Expected Log Predictive Density (ELPD)",
    "text": "99.4 Expected Log Predictive Density (ELPD)\nL’Expected Log Predictive Density (ELPD) è una misura che valuta la capacità predittiva di un modello utilizzando la tecnica della cross-validation. Si definisce come:\n\\[\n\\text{ELPD} = \\sum_{i=1}^n \\log p(y_i \\mid \\mathbf{y}_{-i}),\n\\]\ndove:\n\n\\(y_i\\) è l’i-esima osservazione,\n\\(\\mathbf{y}_{-i}\\) rappresenta tutte le osservazioni eccetto \\(y_i\\).\n\nL’ELPD utilizza la Leave-One-Out Cross-Validation (LOO-CV) per stimare la densità predittiva logaritmica di ogni osservazione, escludendo quella stessa osservazione dal training. Questo metodo permette di evitare l’overfitting, valutando la performance del modello su dati non visti.\n\nEsempio 99.4 Per illustrare il calcolo dell’ELPD, vediamo un esempio semplice con un set di dati molto piccolo. Supponiamo di avere un dataset di tre osservazioni: \\(y_1, y_2, y_3\\). Supponiamo che il nostro modello stimi le probabilità per ciascuna osservazione in base a tutte le altre osservazioni, cioè utilizziamo la leave-one-out cross-validation (LOO-CV) per calcolare \\(p(y_i \\mid \\mathbf{y}_{-i})\\).\nImmaginiamo che il modello produca le seguenti probabilità condizionali per ogni osservazione \\(y_i\\):\n\n\\(p(y_1 \\mid y_2, y_3) = 0.6\\),\n\\(p(y_2 \\mid y_1, y_3) = 0.7\\),\n\\(p(y_3 \\mid y_1, y_2) = 0.5\\).\n\nL’ELPD si calcola sommando i logaritmi di queste probabilità:\n\\[\n\\text{ELPD} = \\log p(y_1 \\mid y_2, y_3) + \\log p(y_2 \\mid y_1, y_3) + \\log p(y_3 \\mid y_1, y_2).\n\\]\nCalcoliamo i logaritmi naturali di ciascuna probabilità:\n\n\\(\\log p(y_1 \\mid y_2, y_3) = \\log 0.6 \\approx -0.5108\\),\n\\(\\log p(y_2 \\mid y_1, y_3) = \\log 0.7 \\approx -0.3567\\),\n\\(\\log p(y_3 \\mid y_1, y_2) = \\log 0.5 \\approx -0.6931\\).\n\nSommiamo i logaritmi per ottenere l’ELPD:\n\\[\n\\text{ELPD} = -0.5108 + (-0.3567) + (-0.6931) = -1.5606.\n\\]\nL’ELPD ottenuto è \\(-1.5606\\). In generale, valori più vicini a 0 o positivi indicano una migliore capacità predittiva del modello, poiché suggeriscono che le probabilità condizionali assegnate dal modello alle osservazioni lasciate fuori non sono troppo basse. Valori molto negativi indicherebbero che il modello ha assegnato probabilità molto basse alle osservazioni effettivamente osservate, suggerendo una scarsa capacità predittiva. L’ELPD è un modo efficace per valutare quanto bene un modello generalizza a nuovi dati, evitando l’overfitting.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#collegamento-tra-divergenza-d_textkl-e-elpd",
    "href": "chapters/entropy/03_model_comparison.html#collegamento-tra-divergenza-d_textkl-e-elpd",
    "title": "99  Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "99.5 Collegamento tra Divergenza \\(D_{\\text{KL}}\\) e ELPD",
    "text": "99.5 Collegamento tra Divergenza \\(D_{\\text{KL}}\\) e ELPD\nEntrambe le misure (divergenza \\(D_{\\text{KL}}\\) e ELPD) valutano la qualità del modello, ma da prospettive diverse:\n\nla divergenza \\(D_{\\text{KL}}\\) misura quanto la distribuzione predittiva del modello \\(Q\\) si avvicina alla “vera” distribuzione \\(P\\);\nl’ELPD valuta direttamente la capacità del modello di prevedere nuovi dati, utilizzando la tecnica leave-one-out.\n\nL’ELPD tende a favorire modelli che non solo si adattano bene ai dati osservati, ma che sono anche robusti rispetto all’overfitting, grazie alla sua enfasi sulla capacità predittiva su dati non osservati.\nIn sintesi, la distribuzione predittiva posteriori, la divergenza \\(D_{\\text{KL}}\\) e l’ELPD sono strumenti matematici che ci permettono di valutare la bontà di un modello statistico. La divergenza KL fornisce una misura teoricamente ideale di quanto un modello approssima la vera distribuzione dei dati, mentre l’ELPD offre un’alternativa praticabile che valuta la capacità del modello di fare previsioni su nuovi dati. Questi concetti sono fondamentali nell’inferenza bayesiana, dove è importante non solo adattarsi ai dati esistenti, ma anche generalizzare bene su dati futuri.\n\nEsempio 99.5 Consideriamo un secondo esempio per illustrare il concetto di ELPD utilizzando la distribuzione binomiale. Immaginiamo di condurre un esperimento in cui lanciamo una moneta 10 volte e contiamo il numero di volte in cui otteniamo testa. Supponiamo che la vera probabilità di ottenere testa sia 0.6.\n\nDistribuzione reale dei dati: Segue una distribuzione binomiale con 10 lanci e probabilità di successo pari a 0.6: \\(y \\sim \\text{Binomiale}(10, 0.6).\\)\nDistribuzione stimata dal modello: Il nostro modello ipotizza che la probabilità di ottenere testa sia 0.5, cioè considera la moneta come equa: \\(p(y \\mid \\theta) = \\text{Binomiale}(10, 0.5).\\)\n\nOra procediamo al calcolo dell’ELPD.\n\n# Parametri\nn = 10  # numero di lanci\np = 0.6  # vera probabilità di testa\nq = 0.5  # probabilità stimata dal modello\n\n# Calcolo ELPD\nelpd = 0\nfor y in range(n + 1):\n    # Probabilità di y secondo la vera distribuzione\n    p_y = binom.pmf(y, n, p)\n\n    # Log della densità predittiva del modello\n    log_q_y = binom.logpmf(y, n, q)\n\n    # Somma pesata\n    elpd += p_y * log_q_y\n\nprint(f\"ELPD del modello che stima p=0.5: {elpd:.4f}\")\n\n# Per confronto, calcoliamo l'ELPD per il modello \"vero\"\nelpd_true = 0\nfor y in range(n + 1):\n    p_y = binom.pmf(y, n, p)\n    log_p_y = binom.logpmf(y, n, p)\n    elpd_true += p_y * log_p_y\n\nprint(f\"ELPD del modello vero (con p=0.6): {elpd_true:.4f}\")\n\nELPD del modello che stima p=0.5: -2.0549\nELPD del modello vero (con p=0.6): -1.8536\n\n\nLa conclusione è che l’ELPD del modello vero è maggiore (meno negativo) rispetto a quello del nostro modello stimato, il che riflette una capacità predittiva superiore del modello vero.\nQuesto esempio dimostra come l’ELPD quantifica la capacità predittiva di un modello:\n\nSi considerano tutti i possibili risultati dell’esperimento (da 0 a 10 teste).\nPer ciascun risultato, si calcola:\n\nLa probabilità di osservare quel risultato secondo la distribuzione reale.\nIl logaritmo della densità predittiva del modello stimato \\(q\\) per lo stesso risultato.\n\nSi moltiplicano questi due valori e si sommano i risultati per tutti i possibili esiti.\n\nIn sintesi, l’ELPD permette di confrontare l’efficacia predittiva di diversi modelli: un valore più alto (meno negativo) indica una migliore capacità del modello di prevedere i dati osservati. Nell’esempio presentato, il modello vero (con \\(p = 0.6\\)) ha un ELPD superiore rispetto al modello stimato (con \\(p = 0.5\\)), confermando che il primo ha una capacità predittiva migliore.\n\n\n99.5.1 Collegamento tra LPPD e ELPD\nIl LPPD e l’ELPD sono strettamente collegati e forniscono una valutazione robusta della capacità predittiva di un modello statistico. Il LPPD fornisce una stima del log-score basata sull’intera distribuzione posteriore dei parametri, mentre l’ELPD utilizza la cross-validation per stimare la capacità predittiva del modello su nuovi dati.\nSebbene il LPPD sia una buona misura, esso tende a migliorare con l’aumentare della complessità del modello, a causa del fenomeno dell’overfitting. Il modello, infatti, potrebbe adattarsi perfettamente ai dati di addestramento, ma non generalizzare bene ai nuovi dati, catturando il “rumore” presente nei dati piuttosto che il vero segnale sottostante.\n\n\n99.5.2 Leave-One-Out Cross-Validation (LOO-CV)\nLa cross-validation, in particolare la Leave-One-Out Cross-Validation (LOO-CV), è una tecnica per affrontare questo problema. La LOO-CV valuta un modello lasciando fuori una sola osservazione dal dataset, addestrando il modello sul resto dei dati e poi testandolo sull’osservazione esclusa. Questo processo viene ripetuto per ogni osservazione nel dataset, e il risultato finale è una media delle prestazioni del modello su tutte le osservazioni lasciate fuori.\nCome la divergenza \\(D_{\\text{KL}}\\), anche il calcolo dell’ELPD richiede, in teoria, la conoscenza della vera distribuzione \\(p\\), che è ignota. Tuttavia, a differenza della divergenza \\(D_{\\text{KL}}\\), disponiamo di metodi pratici per approssimare l’ELPD senza la necessità di conoscere la vera distribuzione dei dati. Uno dei metodi più robusti e comunemente utilizzati per questa stima è la Leave-One-Out Cross-Validation (LOO-CV). Questo metodo consiste nel rimuovere una singola osservazione dal dataset, adattare il modello sui dati rimanenti, e poi valutare la densità predittiva per l’osservazione esclusa. Questa procedura viene ripetuta per ogni osservazione, e i risultati vengono sommati per ottenere una stima complessiva dell’ELPD.\nLa LOO-CV è considerata uno dei metodi migliori per la selezione del modello perché fornisce una stima dell’accuratezza predittiva del modello su dati che non sono stati utilizzati per addestrarlo. Questo approccio riduce il rischio di overfitting, poiché misura come il modello si comporta su dati effettivamente “nuovi”.\nQuindi, sebbene il log-probability score sia una buona misura, il suo miglioramento con l’aumentare della complessità del modello può essere mitigato utilizzando tecniche di cross-validation, come la LOO-CV. Questo metodo fornisce una stima accurata della performance del modello su dati non visti, evitando così il problema dell’overfitting.\n\n\n99.5.3 Criteri di Informazione come Approssimazioni alla Divergenza \\(D_{\\text{KL}}\\)\nOltre al LOO-CV, sono stati proposti altri metodi per approssimare l’ELPD, che derivano direttamente dal concetto di divergenza \\(D_{\\text{KL}}\\). Tra questi, i più noti sono i criteri di informazione, come l’errore quadratico medio (MSE), l’Akaike Information Criterion (AIC), il Bayesian Information Criterion (BIC) e il Widely Applicable Information Criterion (WAIC). Questi criteri forniscono approcci alternativi per valutare i modelli, bilanciando la bontà di adattamento del modello ai dati osservati con la sua complessità.\n\n99.5.3.1 Errore Quadratico Medio (MSE)\nL’Errore Quadratico Medio (Mean Squared Error o MSE) misura la discrepanza media tra le previsioni del modello e i valori reali:\n\\[ MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2, \\]\ndove:\n\n\\(n\\) è il numero totale di osservazioni,\n\\(y_i\\) sono i valori reali,\n\\(\\hat{y}_i\\) sono i valori previsti dal modello.\n\nUn MSE inferiore indica un migliore adattamento del modello ai dati.\n\n\n99.5.3.2 Criterio di Informazione di Akaike (AIC)\nIl Criterio di Informazione di Akaike (AIC) va oltre l’MSE, considerando sia l’adattamento del modello che la sua complessità:\n\\[ AIC = -2 \\sum \\log p(y_i \\mid \\hat{\\theta}_{\\text{mle}}) + 2k, \\]\ndove:\n\n\\(\\hat{\\theta}_{\\text{mle}}\\) sono i parametri stimati del modello,\n\\(k\\) è il numero di parametri del modello.\n\nL’AIC bilancia la bontà di adattamento (primo termine) con la complessità del modello (secondo termine). Un valore più basso di AIC indica una minor perdita di informazione, suggerendo un modello preferibile.\nVantaggi e limitazioni:\n\nfacile e veloce da calcolare;\npuò essere meno accurato per campioni piccoli o modelli complessi;\nfornisce un’approssimazione asintoticamente corretta dell’ELPD per modelli regolari e campioni grandi.\n\n\n\n99.5.3.3 Criterio di Informazione Bayesiano (BIC)\nIl Criterio di Informazione Bayesiano (BIC) è definito come:\n\\[\nBIC = \\ln(n)k - 2\\ln(L),\n\\]\ndove:\n\n\\(n\\) è il numero di osservazioni,\n\\(k\\) è il numero di parametri del modello,\n\\(L\\) è il valore massimo della funzione di verosimiglianza del modello.\n\nIl termine \\(\\ln(L)\\) rappresenta il logaritmo naturale della verosimiglianza massima, che indica quanto bene il modello si adatta ai dati osservati.\nIl BIC impone una penalità maggiore per l’incremento dei parametri, rendendolo particolarmente adeguato per dataset di grandi dimensioni.\n\n\n99.5.3.4 Widely Applicable Information Criterion (WAIC)\nIl WAIC è una versione avanzata dell’AIC, particolarmente utile nel contesto bayesiano. Considera l’intera distribuzione a posteriori dei parametri anziché solo la stima puntuale:\n\\[\nWAIC = -2\\left[ \\sum_{i=1}^{n} \\log \\left( \\frac{1}{S} \\sum_{s=1}^{S} p(y_i \\mid \\theta^{(s)}) \\right) - \\sum_{i=1}^{n} \\text{Var}_{\\theta^{(s)}} \\left( \\log p(y_i \\mid \\theta^{(s)}) \\right) \\right],\n\\]\ndove:\n\n\\(S\\) è il numero di campioni dalla distribuzione a posteriori,\n\\(\\text{Var}_{\\theta^{(s)}}\\) è la varianza della log-verosimiglianza.\n\nCaratteristiche del WAIC:\n\ncalcola il logaritmo della densità predittiva per ogni punto dati;\npenalizza la complessità del modello basandosi sulla variabilità delle sue predizioni;\nla somma delle varianze a posteriori del logaritmo della densità predittiva converge al numero effettivo di parametri del modello.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#riflessioni-conclusive",
    "href": "chapters/entropy/03_model_comparison.html#riflessioni-conclusive",
    "title": "99  Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "99.6 Riflessioni Conclusive",
    "text": "99.6 Riflessioni Conclusive\nLa valutazione dei modelli statistici è cruciale per garantire la loro affidabilità e capacità di generalizzazione. Quando si sviluppano modelli, è fondamentale utilizzare strumenti che permettano di confrontare diverse alternative e selezionare quella più adatta ai dati disponibili, assicurando previsioni accurate.\nUno strumento chiave in questo processo è la Expected Log Predictive Density (ELPD), che valuta l’accuratezza con cui un modello può prevedere nuovi dati. Tuttavia, il calcolo diretto dell’ELPD è spesso impraticabile, poiché richiederebbe la conoscenza esatta del meccanismo generatore dei dati, \\(p_t(y)\\). Per ovviare a questa limitazione, si utilizza una stima approssimativa basata sulla distribuzione predittiva a posteriori del modello, \\(p(\\tilde{y} \\mid y)\\).\nPer ottenere una valutazione accurata della capacità di generalizzazione di un modello su futuri set di dati, si ricorre a metodi di validazione incrociata, come la Leave-One-Out Cross-Validation (LOO-CV). Questa tecnica implica l’addestramento del modello su un sottoinsieme dei dati e il suo test su un altro, isolando così le prestazioni del modello dalle variazioni casuali presenti nei dati. L’indice LOO-CV risultante è fondamentale per confrontare diversi modelli.\nLa differenza nei valori di LOO-CV tra due modelli, insieme al calcolo dell’errore standard associato a questa differenza, ci permette di determinare se esistono differenze significative nelle prestazioni dei modelli. Se il rapporto tra la differenza di LOO-CV e il relativo errore standard è superiore a 2, possiamo concludere che le differenze osservate non sono casuali, ma riflettono una vera superiorità di un modello rispetto all’altro.\nNel contesto della statistica bayesiana, il Log Pointwise Predictive Density (LPPD) e l’Expected Log Pointwise Predictive Density (ELPD) sono strumenti essenziali per la valutazione dei modelli. Sebbene la divergenza \\(D_{\\text{KL}}\\) rappresenti una misura ideale per quantificare la distanza tra la distribuzione di probabilità reale dei dati e quella stimata dal modello, la sua applicazione è limitata dal fatto che la distribuzione vera dei dati è generalmente sconosciuta.\nA differenza della divergenza \\(D_{\\text{KL}}\\), il LPPD offre un approccio pratico per valutare la capacità predittiva dei modelli, anche se può soffrire di overfitting. Per mitigare questo problema, si utilizza l’ELPD, che stima la capacità del modello di generalizzare oltre i dati di addestramento.\nL’ELPD e la divergenza \\(D_{\\text{KL}}\\) sono strumenti complementari: l’ELPD misura la capacità predittiva su nuovi dati, con valori più alti che indicano una maggiore capacità di generalizzazione, mentre la divergenza \\(D_{\\text{KL}}\\) quantifica la differenza tra la distribuzione vera dei dati e quella stimata dal modello, con valori più bassi che indicano una migliore approssimazione della distribuzione reale.\nEsiste una relazione diretta tra ELPD e divergenza \\(D_{\\text{KL}}\\): massimizzare l’ELPD equivale a minimizzare la divergenza \\(D_{\\text{KL}}\\), poiché entrambi gli approcci mirano a sviluppare modelli che rappresentino accuratamente la realtà dei dati.\nIn sintesi, la divergenza \\(D_{\\text{KL}}\\) valuta l’adattamento del modello ai dati osservati, mentre l’ELPD e i suoi metodi di approssimazione, come il LOO-CV, misurano la capacità del modello di generalizzare su dati futuri, offrendo una valutazione più completa della qualità del modello. La selezione del modello ottimale richiede un equilibrio tra adattamento ai dati e semplicità. Utilizzando tecniche di validazione incrociata e criteri di informazione come AIC, BIC e WAIC, è possibile costruire modelli che si adattano bene ai dati osservati, forniscono previsioni affidabili su nuovi dati e catturano le tendenze rilevanti senza essere eccessivamente influenzati dal rumore.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/03_model_comparison.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/03_model_comparison.html#informazioni-sullambiente-di-sviluppo",
    "title": "99  Divergenza KL, LPPD, ELPD e LOO-CV",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\narviz     : 0.18.0\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nscipy     : 1.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Divergenza KL, LPPD, ELPD e LOO-CV</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_loo.html",
    "href": "chapters/entropy/04_loo.html",
    "title": "100  Validazione Incrociata Leave-One-Out",
    "section": "",
    "text": "Introduzione\nLa capacità di generalizzazione di un modello statistico, ossia la sua abilità di fare previsioni accurate su nuovi dati, è un aspetto cruciale nella modellazione statistica (per uno studio recente, si veda, ad esempio, Chekroud et al. (2024)). Per valutare quantitativamente questa capacità, sono state sviluppate diverse metriche. Tra queste, la Densità Predittiva Logaritmica Attesa (Expected Log Predictive Density, ELPD) è particolarmente apprezzata per la sua efficacia. L’ELPD fornisce una stima diretta della capacità di un modello di prevedere nuovi dati, rendendola un indicatore fondamentale della sua capacità di generalizzazione.\nUno dei metodi più efficaci e comunemente utilizzati per stimare l’ELPD è la validazione incrociata Leave-One-Out (LOO-CV), come discusso nella sezione Capitolo 99. Questo metodo simula uno scenario di previsione su nuovi dati escludendo sistematicamente ogni singola osservazione dal set di addestramento e valutando la capacità del modello di predire l’osservazione esclusa. In questo capitolo, approfondiremo la metodologia LOO-CV e mostreremo come essa venga applicata per valutare e selezionare modelli statistici in base alla loro capacità di generalizzare.\nNegli esempio successivi, mostreremo come applicare questi concetti utilizzando cmdstan. Questo approccio pratico illustrerà l’intero processo di selezione e valutazione del modello, fornendo un metodo robusto per scegliere il modello più appropriato, tenendo conto sia della sua capacità predittiva che della sua adeguatezza ai dati osservati.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_loo.html#il-problema-del-sovra-adattamento",
    "href": "chapters/entropy/04_loo.html#il-problema-del-sovra-adattamento",
    "title": "100  Validazione Incrociata Leave-One-Out",
    "section": "100.1 Il Problema del Sovra-adattamento",
    "text": "100.1 Il Problema del Sovra-adattamento\nUno dei problemi più comuni che emerge durante la costruzione di un modello statistico è il sovra-adattamento, o overfitting. Questo fenomeno si verifica quando un modello si adatta eccessivamente ai dati di addestramento, catturando non solo le tendenze generali, ma anche le fluttuazioni casuali e gli errori presenti nei dati.\n\n100.1.1 Perché il Sovra-adattamento è un Problema?\nUn modello sovra-adattato può mostrare prestazioni eccellenti sui dati di addestramento, ma tende a fallire quando applicato a nuovi dati. In altre parole, il modello “impara a memoria” i dati di addestramento piuttosto che apprendere le regole generali che li governano. Questo compromette la sua capacità di generalizzazione, rendendolo inaffidabile per previsioni future.\nPer evitare il sovra-adattamento, è necessario bilanciare la capacità del modello di adattarsi ai dati di addestramento con la sua capacità di generalizzare a nuovi dati. Questo equilibrio è noto come il “trade-off” tra bias e varianza.\n\n\n100.1.2 Tecniche di Validazione\nPer prevenire il sovra-adattamento, si utilizzano tecniche di validazione, che permettono di valutare quanto bene un modello si comporterà su dati non visti. Una delle tecniche più importanti in questo contesto è la validazione incrociata (cross-validation).\n\n\n100.1.3 Validazione Incrociata (Cross-Validation)\nLa validazione incrociata è una metodologia che consente di testare il modello su dati che non ha mai visto durante l’addestramento. Esistono diverse varianti di validazione incrociata, tra cui:\n\nK-fold cross-validation:\n\nI dati vengono divisi in K gruppi (o “fold”).\nSi addestra il modello su K-1 gruppi e si testa sull’ultimo gruppo.\nQuesto processo viene ripetuto K volte, utilizzando ogni volta un gruppo diverso per il test.\nI risultati vengono poi mediati per ottenere una stima complessiva della performance del modello.\n\nAd esempio, con K = 5, i dati vengono suddivisi in 5 parti; il modello viene addestrato su 4 parti e testato sulla quinta, ripetendo il processo 5 volte.\nLeave-one-out cross-validation (LOO-CV):\n\nÈ una forma estrema di K-fold in cui K è pari al numero totale di osservazioni.\nOgni volta, si esclude una singola osservazione dal set di addestramento e si utilizza il modello per prevedere quell’osservazione.\nQuesto processo viene ripetuto per ogni osservazione nel dataset.\n\nIl LOO-CV è particolarmente utile per ottenere una stima precisa della capacità del modello di generalizzare, ma può essere computazionalmente intensivo.\n\nQueste tecniche di validazione forniscono una misura accurata della capacità di un modello di generalizzare su nuovi dati.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_loo.html#applicazioni-pratiche",
    "href": "chapters/entropy/04_loo.html#applicazioni-pratiche",
    "title": "100  Validazione Incrociata Leave-One-Out",
    "section": "100.2 Applicazioni Pratiche",
    "text": "100.2 Applicazioni Pratiche\nNel contesto dell’inferenza bayesiana, la selezione del modello si basa principalmente sul confronto delle stime dell’ELPD ottenute tramite la Leave-One-Out Cross-Validation (LOO-CV). Questo processo può essere implementato in modo efficiente utilizzando le funzioni del pacchetto ArviZ.\nÈ importante notare che l’affidabilità di questi confronti dipende dalla qualità dei dati e dall’adeguatezza dei modelli. Per ottenere valutazioni accurate, è essenziale che i modelli si adattino in modo appropriato ai dati disponibili. Un aspetto cruciale di questa valutazione è rappresentato dal calcolo dei valori diagnostici di Pareto \\(k\\).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_loo.html#valori-diagnostici-pareto-k",
    "href": "chapters/entropy/04_loo.html#valori-diagnostici-pareto-k",
    "title": "100  Validazione Incrociata Leave-One-Out",
    "section": "100.3 Valori Diagnostici Pareto \\(k\\)",
    "text": "100.3 Valori Diagnostici Pareto \\(k\\)\nI valori diagnostici di Pareto \\(k\\) sono fondamentali per valutare la stabilità e l’affidabilità delle stime ottenute tramite la Leave-One-Out Cross-Validation (LOO-CV). In particolare, essi misurano l’influenza di singoli punti dati sulle stime del modello. Valori di \\(k\\) elevati possono indicare che alcune osservazioni hanno un’influenza eccessiva, il che può compromettere la validità delle stime fornite dalla LOO-CV.\nIl valore di Pareto \\(k\\) fornisce un’indicazione dell’affidabilità della stima:\n\n\\(k &lt; 0.5\\): L’approssimazione è eccellente e l’errore nella stima dell’ELPD è trascurabile.\n\\(0.5 \\leq k &lt; 0.7\\): L’approssimazione è accettabile, ma potrebbe essere utile esaminare più attentamente il modello e i dati.\n\\(0.7 \\leq k &lt; 1\\): L’approssimazione diventa mediocre, rendendo i risultati della LOO-CV meno affidabili e potenzialmente inadeguati.\n\\(k \\geq 1\\): Un valore così elevato segnala un’approssimazione inadeguata, suggerendo che i risultati ottenuti potrebbero essere significativamente distorti, evidenziando problemi nel modello o nella metodologia.\n\nIl valore di Pareto \\(k\\) si basa sulla distribuzione di Pareto per valutare le discrepanze nelle log-verosimiglianze, cioè le differenze tra la log-verosimiglianza calcolata escludendo un dato e quella ottenuta utilizzando l’intero dataset. Valori alti di \\(k\\) indicano code più pesanti del previsto nella distribuzione delle discrepanze, suggerendo che l’approssimazione potrebbe non essere accurata.\nIn sintesi, i valori di Pareto \\(k\\) forniscono un indicatore chiave dell’accuratezza dell’approssimazione fornita dalla LOO-CV e aiutano a identificare eventuali problemi nel modello statistico o nella metodologia utilizzata.\n\nEsempio 100.1 Per fare un esempio relativo al calcolo dei valore di Pareto \\(k\\), generiamo un set di dati artificiali seguendo una distribuzione normale con una media di 5 e una deviazione standard di 2. Scegliamo una dimensione del campione di 100.\n\ny = np.random.normal(loc=5, scale=2, size=100)\nprint(y[0:10])\n\n[ 3.55144618  7.24614848  3.17600124 10.48005661  0.24404946  3.9483861\n  3.47263944  1.50310884  4.7620044   6.45235628]\n\n\nInseriamo i dati in un dizionario nel formato atteso da Stan.\n\nstan_data = {\"N\": len(y), \"y\": y}\n\nAdattiamo ai dati un modello normale stimando la media (mu) e la deviazione standard (sigma) del modello attraverso il campionamento MCMC.\n\nstan_file = os.path.join(\n    project_directory, 'stan', 'gaussian-mod-log-lik.stan')\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=0&gt; N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  // Priors\n  mu ~ normal(5, 2);         // Prior for mu, centered around the known mean with some uncertainty\n  sigma ~ normal(0, 2);      // Half-normal prior for sigma (implying positive values)\n  \n  // Likelihood\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  for (n in 1:N)\n    log_lik[n] = normal_lpdf(y[n] | mu, sigma);\n}\n\n\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False, \n    show_console=False\n)\n\nEsaminiamo le distribuzioni a posteriori.\n\naz.summary(fit, var_names=['mu', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n4.73\n0.21\n4.33\n5.12\n0.0\n0.0\n6461.15\n5090.21\n1.0\n\n\nsigma\n2.12\n0.15\n1.84\n2.40\n0.0\n0.0\n6389.72\n5247.38\n1.0\n\n\n\n\n\n\n\nConvertiamo l’oggetto creato da cmdstanpy nella classe InferenceData richiesta da ArviZ:\n\nfit_az = az.from_cmdstanpy(posterior=fit)\n\nEseguiamo la LOO-CV usando ArviZ:\n\nloo_result = az.loo(fit_az)\nprint(loo_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -217.79     6.76\np_loo        1.92        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nPoiché il modello si adatta bene a questi dati, tutti i valori di Pareto \\(k\\) sono molto bassi, indicando che nessuna osservazione ha un’influenza eccessiva sulle stime del modello. Di conseguenza, non vi è alcuna evidenza che la stima dell’ELPD, che in questo caso è pari a -217.79, possa essere distorta. Questo suggerisce che la stima è affidabile e rappresenta accuratamente la capacità predittiva del modello.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_loo.html#il-ruolo-dellelpd-nella-valutazione-comparativa-dei-modelli",
    "href": "chapters/entropy/04_loo.html#il-ruolo-dellelpd-nella-valutazione-comparativa-dei-modelli",
    "title": "100  Validazione Incrociata Leave-One-Out",
    "section": "100.4 Il Ruolo dell’ELPD nella Valutazione Comparativa dei Modelli",
    "text": "100.4 Il Ruolo dell’ELPD nella Valutazione Comparativa dei Modelli\nL’ELPD svolge un ruolo cruciale nel confronto tra diversi modelli statistici. Grazie a metodologie come la Leave-One-Out Cross-Validation (LOO-CV), è possibile stimare l’ELPD e ottenere una valutazione oggettiva dell’adeguatezza di ciascun modello rispetto ai dati. Questo è particolarmente importante quando si tratta di scegliere il modello più appropriato tra diverse opzioni o di valutare se un modello più complesso offre un vantaggio significativo rispetto a uno più semplice.\nIn sintesi, l’ELPD fornisce un indicatore affidabile della capacità predittiva di un modello. La LOO-CV, a sua volta, rappresenta un metodo efficace per stimare questa metrica, consentendo un’analisi precisa e robusta delle prestazioni dei diversi modelli. L’automazione di queste procedure attraverso software come PyMC e Arviz rende l’intero processo ancora più pratico e accessibile, consolidando l’ELPD come uno strumento essenziale per la selezione e la validazione dei modelli statistici.\n\n100.4.1 Simulazione\nPer dimostrare come confrontare i modelli utilizzando la LOO-CV, procediamo con una simulazione. Genereremo dati sintetici in cui esiste una relazione lineare tra le variabili \\(x\\) e \\(y\\). In questo contesto, confronteremo un modello lineare con un modello più semplice che considera solo il termine dell’intercetta. Utilizzeremo la LOO-CV per determinare quale dei due modelli si adatta meglio ai dati. La stima dell’ELPD sarà il criterio quantitativo che guiderà la scelta del modello più appropriato.\n\n# Generate synthetic data\nnp.random.seed(42)\nx = np.linspace(0, 10, 100)\ny_true = 3 + 2 * x\ny_obs = y_true + np.random.normal(scale=3, size=100)\nzx = stats.zscore(x)\nzy = stats.zscore(y_obs)\nprint(np.mean(zy), np.std(zy))\n\n-2.19824158875781e-16 1.0\n\n\nAdattiamo ai dati un modello che rispecchia il vero meccanismo generativo dei dati.\nSi noti che, per calcolare LOO e WAIC, ArviZ ha bisogno di accedere alla log-likelihood per ogni campione posteriore. Possiamo trovarla tramite compute_log_likelihood(). In alternativa, possiamo passare idata_kwargs={\"log_likelihood\": True} a sample() per farla calcolare automaticamente alla fine del campionamento.\n\nstan_lin_reg_file = os.path.join(\n    project_directory, 'stan', 'linear-regression.stan'\n)\n\nmodel_lin_reg = CmdStanModel(stan_file=stan_lin_reg_file)\nprint(model_lin_reg.code())\n\n// all data should be scaled to mean 0 and std 1:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha + beta * x, sigma);\n  alpha ~ normal(0, 2.5);\n  beta ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  vector[N] y_rep;\n  for (n in 1:N) {\n    log_lik[n] = normal_lpdf(y[n] | alpha + beta * x[n], sigma);\n    y_rep[n] = normal_rng(alpha + beta * x[n], sigma);\n  }\n}\n\n\n\nInseriamo i dati simulati in un dizionario.\n\n# Prepare the stan_data dictionary\nstan_data = {\n    'N': len(zx),\n    'x': zx,\n    'y': zy\n}\n\nEseguiamo il campionamento.\n\nfit2 = model_lin_reg.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False, \n    show_console=False\n)\n\nEsaminiamo le stime a posteriori dei parametri del modello.\n\naz.summary(fit2, var_names=['beta', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nbeta\n0.91\n0.04\n0.83\n0.99\n0.0\n0.0\n7484.76\n6278.45\n1.0\n\n\nsigma\n0.42\n0.03\n0.37\n0.48\n0.0\n0.0\n7021.01\n5523.71\n1.0\n\n\n\n\n\n\n\nReplichiamo i risultati usando le funzioni di pingouin:\n\n# Create a DataFrame\ndf = pd.DataFrame({\n    \"x\": zx,\n    \"y\": zy\n})\n\n# Perform linear regression using pingouin\nregression_results = pg.linear_regression(df[['x']], df['y'])\n\n# Print the regression results\nprint(regression_results)\n\n       names          coef        se             T          pval        r2  \\\n0  Intercept -2.220446e-16  0.041834 -5.307754e-15  1.000000e+00  0.828492   \n1          x  9.102152e-01  0.041834  2.175778e+01  2.661609e-39  0.828492   \n\n     adj_r2  CI[2.5%]  CI[97.5%]  \n0  0.826742 -0.083018   0.083018  \n1  0.826742  0.827197   0.993233  \n\n\nCalcoliamo l’ELPD con il metodo LOO-CV.\n\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit2_az = az.from_cmdstanpy(posterior=fit2)\n\n# Perform LOO-CV using ArviZ\nloo2_result = az.loo(fit2_az)\nprint(loo2_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   -56.70     6.89\np_loo        2.78        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nAdattiamo ora ai dati un secondo modello che non tiene conto della relazione lineare tra \\(x\\) e \\(y\\), ovvero contiene solo l’intercetta.\n\nstan_lin_reg_file_only_alpha = os.path.join(\n    project_directory, 'stan', 'linear-regression-only-alpha.stan')\n\nmodel_lin_reg_only_alpha = CmdStanModel(stan_file=stan_lin_reg_file_only_alpha)\nprint(model_lin_reg_only_alpha.code())\n\n// all data should be scaled to mean 0 and std 1:\ndata {\n  int&lt;lower=1&gt; N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real&lt;lower=0&gt; sigma;\n}\nmodel {\n  y ~ normal(alpha, sigma);\n  alpha ~ normal(0, 2.5);\n  sigma ~ cauchy(0, 2.5);\n}\ngenerated quantities {\n  vector[N] log_lik;\n  vector[N] y_rep;\n  for (n in 1:N) {\n    log_lik[n] = normal_lpdf(y[n] | alpha, sigma);\n    y_rep[n] = normal_rng(alpha, sigma);\n  }\n}\n\n\n\nEseguiamo il campionamento.\n\nfit3 = model_lin_reg_only_alpha.sample(\n    data=stan_data,\n    iter_warmup = 2_000,\n    iter_sampling = 2_000,\n    seed = 123,\n    show_progress = False, \n    show_console = False\n)\n\n\naz.summary(fit3, var_names=['alpha', 'sigma'], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n-0.00\n0.10\n-0.19\n0.20\n0.0\n0.0\n5474.54\n4913.19\n1.0\n\n\nsigma\n1.02\n0.07\n0.89\n1.16\n0.0\n0.0\n5742.53\n4496.71\n1.0\n\n\n\n\n\n\n\nStimiamo l’ELPD con il metodo LOO-CV per il modello che ignora la relazione lineare.\n\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit3_az = az.from_cmdstanpy(posterior=fit3)\n\n# Perform LOO-CV using ArviZ\nloo3_result = az.loo(fit3_az)\nprint(loo3_result)\n\nComputed from 8000 posterior samples and 100 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -143.65     4.52\np_loo        1.43        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      100  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nInfine, calcoliamo la differenza tra le stime dell’ELPD (elpd_diff) dei due modelli. L’incertezza associata a questa differenza è espressa dal suo errore standard (dse). Se il rapporto tra elpd_diff e dse è pari o superiore a 2, possiamo concludere che esiste una differenza significativa e credibile tra i due modelli.\nNell’output del comando az.compare(), il modello con il valore di elpd_loo più alto (indicativo di una migliore capacità predittiva) viene elencato per primo.\n\ndf_comp_loo = az.compare({\"linear_model\": loo2_result, \"intercept_model\": loo3_result})\ndf_comp_loo\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nlinear_model\n0\n-56.814716\n2.873961\n0.000000\n1.000000e+00\n6.890641\n0.000000\nFalse\nlog\n\n\nintercept_model\n1\n-143.633507\n1.403145\n86.818792\n2.428635e-11\n4.516124\n7.956892\nFalse\nlog\n\n\n\n\n\n\n\nNel caso attuale, il modello linear_model riflette accuratamente il modo in cui i dati sono stati generati. Questo è confermato dal fatto che viene preferito in base al valore di elpd_loo. Inoltre, il rapporto tra elpd_diff e il suo errore standard è notevolmente superiore a 2, il che indica chiaramente che, per questi dati, il modello lineare è nettamente preferibile rispetto al modello che include solo l’intercetta.\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_loo.html#riflessioni-conclusive",
    "href": "chapters/entropy/04_loo.html#riflessioni-conclusive",
    "title": "100  Validazione Incrociata Leave-One-Out",
    "section": "100.5 Riflessioni Conclusive",
    "text": "100.5 Riflessioni Conclusive\nIn questo capitolo, abbiamo esplorato in dettaglio il metodo della Validazione Incrociata Leave-One-Out (LOO-CV) e il suo utilizzo nel framework cmdstan, sottolineando la sua importanza nella pratica della modellazione statistica.\nUn punto centrale della discussione è stato il ruolo fondamentale della LOO-CV nel confronto tra diversi modelli. Questo metodo non solo consente di valutare la capacità predittiva di un singolo modello, ma si rivela anche indispensabile quando si tratta di scegliere il modello più adeguato tra diverse alternative. La LOO-CV fornisce infatti una base di confronto oggettiva e affidabile, permettendo di identificare il modello che meglio si adatta ai dati e che possiede la maggiore capacità di generalizzazione.\nInoltre, abbiamo approfondito l’importanza dei valori diagnostici Pareto \\(k\\) nell’interpretazione delle stime ottenute tramite LOO-CV. Questi valori diagnostici sono cruciali per valutare l’affidabilità delle stime dell’ELPD derivate dalla LOO-CV, poiché forniscono un’indicazione sulla precisione e robustezza di queste stime. Valori di Pareto \\(k\\) elevati possono segnalare che alcune osservazioni influenzano eccessivamente le stime, indicando possibili problemi di modellizzazione che potrebbero compromettere la validità delle conclusioni.\nIn sintesi, la combinazione di LOO-CV e dei valori diagnostici Pareto \\(k\\) offre un approccio robusto e affidabile per la valutazione e selezione dei modelli statistici, garantendo che le scelte effettuate siano basate su criteri solidi e verificabili. Questo metodo si dimostra quindi essenziale non solo per valutare la qualità di un singolo modello, ma anche per assicurare che la selezione del modello ottimale sia supportata da una rigorosa analisi quantitativa.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/04_loo.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/04_loo.html#informazioni-sullambiente-di-sviluppo",
    "title": "100  Validazione Incrociata Leave-One-Out",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sat Jul 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\npingouin  : 0.5.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nChekroud, A. M., Hawrilenko, M., Loho, H., Bondar, J., Gueorguieva, R., Hasan, A., Kambeitz, J., Corlett, P. R., Koutsouleris, N., Krumholz, H. M., et al. (2024). Illusory generalizability of clinical prediction models. Science, 383(6679), 164–167.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>Validazione Incrociata Leave-One-Out</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html",
    "href": "chapters/entropy/05_regularization.html",
    "title": "101  Regolarizzazione",
    "section": "",
    "text": "Introduzione",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html#regolarizzazione-e-selezione-di-variabili",
    "href": "chapters/entropy/05_regularization.html#regolarizzazione-e-selezione-di-variabili",
    "title": "101  Regolarizzazione",
    "section": "101.1 Regolarizzazione e Selezione di Variabili",
    "text": "101.1 Regolarizzazione e Selezione di Variabili\nLa regolarizzazione è un potente strumento per affrontare il problema della selezione di variabili nei modelli statistici, in particolare quando abbiamo a disposizione un numero limitato di dati rispetto alla complessità del modello che desideriamo stimare. Questo approccio è essenziale quando il numero di predittori supera quello delle osservazioni o quando è necessario evitare l’overfitting, ovvero l’adattamento eccessivo del modello ai dati disponibili. La regolarizzazione consente di migliorare l’accuratezza delle previsioni e di aumentare la generalizzazione del modello su nuovi dati.\nIl trade-off bias-varianza è alla base della regolarizzazione. In sostanza, aggiungendo troppe variabili in un modello, il rischio è di ridurre la varianza del modello ma aumentare il bias, cioè la distorsione nelle previsioni. All’opposto, un modello troppo semplice riduce il bias ma aumenta la varianza. La regolarizzazione cerca di trovare il giusto equilibrio riducendo la complessità del modello senza perdere troppa informazione rilevante.\nTradizionalmente, i frequentisti affrontano questo problema con metodi di selezione del modello basati su teorie informative (come il criterio di Akaike, AIC), che permettono di scegliere il modello migliore tra diverse alternative. Tuttavia, anche i bayesiani possono utilizzare queste tecniche (vedi la sezione seguente sugli approcci IT bayesiani). Tuttavia, in molti casi, la regolarizzazione basata su priors è una soluzione più efficace e naturale per controllare la complessità del modello.\n\n101.1.1 Il Ruolo della Regolarizzazione\nLa regolarizzazione tramite priori debolmente informativi o priors restrittivi permette di imporre delle penalizzazioni sui coefficienti dei predittori, spingendoli verso zero se non sono supportati dai dati. Questo approccio è particolarmente utile in contesti in cui abbiamo molti predittori e pochi dati. In questi casi, impostare dei priori restrittivi aiuta a ridurre l’incertezza e a mantenere il modello più semplice e interpretabile.\nL’idea è di utilizzare priori che siano intenzionalmente più restrittivi di quelli che useremmo se volessimo esprimere la nostra “pura” incertezza sui parametri. Questo permette di controllare la complessità del modello, rendendo possibile la selezione automatica delle variabili rilevanti durante il processo di inferenza.\nIn sintesi, la regolarizzazione è uno strumento importante per la selezione di variabili nei modelli statistici complessi. Non solo permette di gestire modelli con molti predittori rispetto al numero di dati disponibili, ma evita anche il rischio di sovra-adattamento, garantendo un compromesso ottimale tra bias e varianza.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html#esempio-di-applicazione",
    "href": "chapters/entropy/05_regularization.html#esempio-di-applicazione",
    "title": "101  Regolarizzazione",
    "section": "101.2 Esempio di Applicazione",
    "text": "101.2 Esempio di Applicazione\nPer illustrare come funziona la regolarizzazione nella selezione delle variabili, consideriamo un esempio con un dataset contenente 100 predittori. Tra questi, solo i primi 10 hanno un effetto reale sui dati, mentre i restanti 90 non hanno alcun effetto. In questo contesto, la regolarizzazione permette di identificare i predittori rilevanti (i primi 10) riducendo o eliminando l’influenza degli altri 90 predittori. Questo processo aiuta a ridurre il rumore nel modello, migliorandone la capacità di fare previsioni accurate. Seguiremo qui la trattazione proposta da Florian Hartig.\n\n# Setting seed for reproducibility\nnp.random.seed(1)\n\n# Generating random data\ndat = pd.DataFrame(np.random.uniform(-0.5, 0.5, size=(200, 100)))\ndat[\"y\"] = np.random.normal(size=200)\ndat[\"y\"] = dat[\"y\"] + dat.iloc[:, :10].sum(axis=1)\n\n# Preparing data for regression\nX = dat.iloc[:, :100].values\ny = dat[\"y\"].values\n\nEseguiamo l’analisi frequentista.\n\n# Fitting full model (equivalent to lm in R)\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression() \n\n\nCalcoliamo l’indice MSE e rappresentiamo visivamente la grandezza delle stime dei coefficienti di regressione delle 100 variabili inserite nel modello.\n\n# True coefficients and estimated coefficients\ntrue = np.concatenate([np.ones(10), np.zeros(90)])\nestimated = model.coef_\n\n# Mean Squared Error\nMSE = np.round(np.var(true - estimated), 4)\n\n\n# Function to plot the estimates\ndef plot_estimates(estimates):\n    MSE = np.round(np.var(true - estimates), 4)\n    plt.bar(np.arange(len(estimates)), estimates)\n    plt.axhline(y=1, xmin=0, xmax=12 / len(estimates), color=\"blue\", linewidth=4)\n    plt.axhline(y=0, xmin=12 / len(estimates), xmax=1, color=\"blue\", linewidth=4)\n    plt.ylim(-0.5, 1.5)\n    # plt.xticks(rotation=90)\n    plt.text(60, 1, f\"MSE: {MSE}\", fontsize=12)\n    plt.show()\n\n\n# Plotting the estimates\nplot_estimates(estimated)\n\n\n\n\n\n\n\n\nNotiamo che alcune variabili irrilevanti hanno coefficienti la cui grandezza è maggiore di quella delle variabili che hanno un vero effetto sulla \\(y\\).",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html#prior-non-informativi",
    "href": "chapters/entropy/05_regularization.html#prior-non-informativi",
    "title": "101  Regolarizzazione",
    "section": "101.3 Prior non informativi",
    "text": "101.3 Prior non informativi\nOvviamente, l’equivalente bayesiano del modello con ampi prior non informativi produce lo stesso risultato.\n\n# Define the Stan model code\nmodel_code_1 = \"\"\"\ndata {\n  int&lt;lower=1&gt; i_max;     // numero di osservazioni\n  int&lt;lower=1&gt; p;         // numero di predittori (dimensione del vettore a)\n  matrix[i_max, p] x;     // matrice delle covariate\n  vector[i_max] y;        // variabile dipendente\n}\n\nparameters {\n  vector[p] a;            // vettore dei coefficienti\n  real b;                 // intercetta\n  real&lt;lower=0&gt; sigma;    // deviazione standard (al posto di tau)\n}\n\nmodel {\n  vector[i_max] mu;\n\n  // Likelihood\n  for (i in 1:i_max) {\n    mu[i] = dot_product(a, x[i]) + b; // calcola la media mu per ogni osservazione\n  }\n  y ~ normal(mu, sigma); // distribuzione normale per y\n\n  // Prior distributions\n  a ~ normal(0, 100);   // priors per i coefficienti (equivalente a dnorm(0, 0.0001))\n  b ~ normal(0, 100);   // prior per l'intercetta\n  sigma ~ cauchy(0, 2); // prior per sigma (alternativa al dgamma per tau)\n}\n\"\"\"\n\n# Create a temporary file for the Stan model\nwith tempfile.NamedTemporaryFile(suffix=\".stan\", mode=\"w\", delete=False) as f:\n    f.write(model_code_1)\n    stan_file = f.name\n\n\nmodel_1 = CmdStanModel(stan_file=stan_file)\n\n\n# Generazione dei dati simulati come fatto in precedenza\nnp.random.seed(1)\ndat = pd.DataFrame(np.random.uniform(-0.5, 0.5, size=(200, 100)))\ndat[\"y\"] = np.random.normal(size=200)\ndat[\"y\"] = dat[\"y\"] + dat.iloc[:, :10].sum(axis=1)\n\n# Preparazione dei dati per Stan\nstan_data = {\n    \"y\": dat[\"y\"].values,  # Vettore delle risposte\n    \"x\": dat.iloc[:, :100].values,  # Matrice delle covariate\n    \"i_max\": len(dat),  # Numero di osservazioni (righe)\n    \"p\": dat.shape[1] - 1,  # Numero di predittori (100 colonne)\n}\n\n# print(stan_data)  # Per vedere i dati\n\n\nsamples_1 = model_1.sample(\n    data=stan_data,\n    seed=123,\n    chains=4,\n    parallel_chains=4,  # No data needed for this model\n    show_progress=False,\n    show_console=False,\n)\n\n\n# Estrazione dei campioni posteriori dai parametri 'a', 'b', e 'sigma'\nposterior_a = samples_1.stan_variable(\"a\")  # Campioni posteriori per 'a'\nposterior_b = samples_1.stan_variable(\"b\")  # Campioni posteriori per 'b'\nposterior_sigma = samples_1.stan_variable(\"sigma\")  # Campioni posteriori per 'sigma'\n\n# Calcolo della mediana per ciascuno dei parametri 'a'\nest_a = np.median(posterior_a, axis=0)\n\n\n# Funzione per il grafico (simile a quella in R)\ndef plot_estimates(estimates):\n    MSE = np.round(np.var(true - estimates), 4)\n    plt.bar(np.arange(len(estimates)), estimates)\n    plt.axhline(y=1, xmin=0, xmax=12 / len(estimates), color=\"blue\", linewidth=4)\n    plt.axhline(y=0, xmin=12 / len(estimates), xmax=1, color=\"blue\", linewidth=4)\n    plt.ylim(-0.5, 1.5)\n    plt.xticks(rotation=90)\n    plt.text(60, 1, f\"MSE: {MSE}\", fontsize=12)\n    plt.show()\n\n\n# Esegui il grafico delle stime di 'a'\ntrue = np.concatenate([np.ones(10), np.zeros(90)])  # Valori veri per confronto\nplot_estimates(est_a)",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html#priori-di-regolarizzazione-moderata",
    "href": "chapters/entropy/05_regularization.html#priori-di-regolarizzazione-moderata",
    "title": "101  Regolarizzazione",
    "section": "101.4 Priori di Regolarizzazione Moderata",
    "text": "101.4 Priori di Regolarizzazione Moderata\nI priori di regolarizzazione moderata sono una tecnica molto utile in modelli di regressione per gestire i problemi di identificabilità dei parametri e prevenire l’overfitting, senza influenzare eccessivamente le stime dei parametri. L’idea alla base è di dare una lieve spinta ai coefficienti di regressione verso zero, riducendo la complessità del modello senza compromettere la capacità di fare previsioni accurate.\nNel contesto dei modelli di regressione, i priori di regolarizzazione moderata (mildly regularizing priors) sono usati per imporre una penalizzazione sui coefficienti di regressione, che li spinge verso zero. Tuttavia, la forza di questa penalizzazione è mantenuta debole in modo da non distorcere significativamente le stime dei parametri, ma sufficiente a stabilizzare il modello.\nUn coefficiente di regressione è il parametro che esprime la forza e la direzione della relazione tra una variabile predittiva (covariata) e la variabile dipendente (risposta). In assenza di regolarizzazione, i coefficienti possono assumere valori molto grandi se ci sono correlazioni tra predittori o se il modello è complesso rispetto alla quantità di dati disponibili. I priori di regolarizzazione moderata impediscono che questo accada.\n\n101.4.1 Implementazione dei Priori Moderati\nNel seguente codice Stan, i priori di regolarizzazione moderata vengono applicati ai coefficienti di regressione \\(a\\), che rappresentano i predittori del modello. Il prior su ogni \\(a[i]\\) è una distribuzione normale centrata su zero con una varianza moderata:\na ~ normal(0, sqrt(0.5));  // prior moderato sui coefficienti a[i]\nCiò significa che i coefficienti \\(a[i]\\) hanno una distribuzione normale con media zero e una deviazione standard di circa 0.7, che corrisponde a una penalizzazione moderata (non troppo forte) verso lo zero. Questa scelta regolarizza il modello senza influenzare eccessivamente i coefficienti stimati.\nInoltre, la prior per l’intercetta \\(b\\) è definita come:\nb ~ normal(0, sqrt(0.0001));  // prior debole per l'intercetta\nQuesto significa che l’intercetta viene trattata con una prior molto più restrittiva, in quanto ci si aspetta che l’intercetta debba essere piccola (vicina a zero) a priori. Ciò permette di regolarizzare il modello senza distorcere l’influenza dei predittori.\n\n\n101.4.2 Quando Usare i Priori Moderati?\nI priori moderati sono particolarmente utili quando:\n\nDati ridotti o rumorosi: In presenza di pochi dati, o di dati rumorosi, i coefficienti di regressione possono diventare non identificabili o altamente instabili. La regolarizzazione moderata aiuta a evitare che i parametri crescano troppo, stabilizzando le stime.\nModelli con molti predittori: Quando il numero di predittori è elevato, c’è il rischio che il modello si adatti troppo ai dati, generando un problema di overfitting. I priori moderati riducono l’effetto di predittori meno importanti spingendoli verso zero.\nEvita la selezione dei modelli: L’uso di priori moderati può spesso rendere superfluo il processo di selezione del modello (che è costoso in termini computazionali), poiché i predittori meno rilevanti vengono naturalmente ridotti verso zero.\n\n\n\n101.4.3 Effetti Pratici\nIl vantaggio principale dei priori di regolarizzazione moderata è che mantengono il modello stabile e ben identificato, specialmente nei casi di modelli con molti predittori, evitando che i coefficienti diventino troppo grandi. Allo stesso tempo, non distorcono significativamente le stime dei parametri, il che significa che i predittori con effetti reali significativi non vengono penalizzati eccessivamente.\nNel contesto di modelli di regressione con predittori scalati e centrati, ci si aspetta che gli effetti forti abbiano dimensioni dell’effetto vicine a 1. Pertanto, un prior che impone una varianza compresa tra 1 e 10 (come nel caso della prior normale con deviazione standard di circa 0.7) è considerato moderato, e aiuta a mantenere il modello sotto controllo.\n\n\n101.4.4 Considerazioni Finali\nIn definitiva, i priori di regolarizzazione moderata rappresentano un compromesso efficace tra la modellizzazione flessibile e la prevenzione del sovra-adattamento. Questa tecnica di regolarizzazione spinge dolcemente i coefficienti verso zero, mantenendo il modello semplice e robusto, senza imporre restrizioni troppo forti che potrebbero distorcere i risultati.\n\n\n101.4.5 Esempio di Implementazione del Modello\nNel codice Stan, l’implementazione dei priori moderati è strutturata come segue:\n\n# Define the Stan model code\nmodel_code_2 = \"\"\"\ndata {\n  int&lt;lower=1&gt; i_max;     // numero di osservazioni\n  int&lt;lower=1&gt; p;         // numero di predittori (dimensione del vettore a)\n  matrix[i_max, p] x;     // matrice delle covariate\n  vector[i_max] y;        // variabile dipendente\n}\n\nparameters {\n  vector[p] a;            // vettore dei coefficienti\n  real b;                 // intercetta\n  real&lt;lower=0&gt; sigma;    // deviazione standard\n}\n\nmodel {\n  vector[i_max] mu;\n\n  // Likelihood\n  for (i in 1:i_max) {\n    mu[i] = dot_product(a, x[i]) + b; // calcola la media mu per ogni osservazione\n  }\n  y ~ normal(mu, sigma);  // distribuzione normale per y\n\n  // Prior distributions\n  a ~ normal(0, sqrt(0.5));  // prior debole per i coefficienti (equivalente a dnorm(0, 0.5))\n  b ~ normal(0, sqrt(0.0001));  // prior debole per l'intercetta (equivalente a dnorm(0, 0.0001))\n  sigma ~ cauchy(0, 2);      // prior debole per sigma (equivalente alla prior gamma su tau)\n}\n\"\"\"\n\n# Create a temporary file for the Stan model\nwith tempfile.NamedTemporaryFile(suffix=\".stan\", mode=\"w\", delete=False) as f:\n    f.write(model_code_2)\n    stan_file = f.name\n\nIn questo esempio, la prior sui coefficienti è una prior moderatamente regolarizzante, che aiuta a stabilizzare il modello senza imporsi eccessivamente sulle stime dei parametri.\n\nmodel_2 = CmdStanModel(stan_file=stan_file)\n\nsamples_2 = model_2.sample(\n    data=stan_data,\n    seed=123,\n    chains=4,\n    parallel_chains=4,  # No data needed for this model\n    show_progress=False,\n    show_console=False,\n)\n\n\n# Estrazione dei campioni posteriori dai parametri 'a', 'b', e 'sigma'\nposterior_a = samples_2.stan_variable(\"a\")  # Campioni posteriori per 'a'\nposterior_b = samples_2.stan_variable(\"b\")  # Campioni posteriori per 'b'\nposterior_sigma = samples_2.stan_variable(\"sigma\")  # Campioni posteriori per 'sigma'\n\n# Calcolo della mediana per ciascuno dei parametri 'a'\nest_a = np.median(posterior_a, axis=0)\n\n# Esegui il grafico delle stime di 'a'\ntrue = np.concatenate([np.ones(10), np.zeros(90)])  # Valori veri per confronto\nplot_estimates(est_a)\n\n\n\n\n\n\n\n\nIl MSE è diminuito, ma la stima degli effetti delle variabili irrilevanti, in molti casi, è simile a quella delle variabili veramente importanti.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html#shrinkage-fisso-e-adattivo",
    "href": "chapters/entropy/05_regularization.html#shrinkage-fisso-e-adattivo",
    "title": "101  Regolarizzazione",
    "section": "101.5 Shrinkage Fisso e Adattivo",
    "text": "101.5 Shrinkage Fisso e Adattivo\nL’approccio di shrinkage in un contesto bayesiano è una tecnica molto utilizzata per la regolarizzazione dei parametri in modelli di regressione complessi, specialmente quando ci sono molti predittori. La regolarizzazione riduce la varianza dei coefficienti di regressione, prevenendo fenomeni come l’overfitting, ovvero l’adattamento eccessivo del modello ai dati osservati.\n\n101.5.1 Shrinkage: Fisso vs Adattivo\nLo shrinkage può essere impostato in due modi:\n\nShrinkage Fisso:\n\nÈ comune negli approcci frequentisti come il Lasso (L1) o il Ridge (L2).\nIn questo caso, si impone una penalizzazione (shrinkage) fissa ai coefficienti, determinata tramite tecniche come la validazione incrociata (cross-validation). Il parametro di shrinkage viene scelto per minimizzare l’errore di previsione.\n\nShrinkage Adattivo:\n\nNell’approccio bayesiano, lo shrinkage può essere trattato come un parametro da stimare direttamente all’interno del modello.\nQuesto approccio implica che non si impone un valore fisso per lo shrinkage, ma si utilizza una distribuzione a priori (detta hyperprior) per stimarlo in base ai dati osservati.\nVantaggio: Questo approccio adattivo è flessibile e permette al modello di “adattare” automaticamente il livello di shrinkage, rendendo l’analisi più robusta.\n\n\n\n\n101.5.2 Struttura del Modello\nNel codice Stan fornito, viene utilizzato uno shrinkage adattivo. Vediamo come funziona:\n\nCoefficiente Shrinkage:\n\nPer ogni predittore \\(a[i]\\), si applica una distribuzione normale con media zero e deviazione standard data da \\(sdShrinkage\\), che dipende dal parametro di shrinkage adattivo:\n\\[\na[i] \\sim \\mathcal{N}(0, sdShrinkage)\n\\]\nQuesto introduce una forma di regolarizzazione che riduce i coefficienti \\(a[i]\\) verso zero, soprattutto per i predittori meno significativi. Ciò aiuta a evitare che il modello sovra-adatti i dati.\n\nParametro di Shrinkage Adattivo:\n\nIl parametro di precisione per lo shrinkage, \\(\\tau_{\\text{shrinkage}}\\), viene modellato come una variabile aleatoria con una distribuzione gamma:\n\\[\n\\tau_{\\text{shrinkage}} \\sim \\Gamma(0.001, 0.001)\n\\]\nDa questo parametro di precisione, si calcola \\(sdShrinkage\\), che controlla l’intensità del shrinkage applicato ai coefficienti \\(a[i]\\).\n\nParallelismo con i Modelli a Effetti Casuali:\n\nQuesto approccio è simile ai modelli misti (mixed models), in cui i coefficienti dei predittori vengono trattati come effetti casuali che seguono una distribuzione normale comune. In questo contesto, i coefficienti \\(a[i]\\) possono essere visti come effetti casuali, la cui varianza è regolata dallo shrinkage.\n\nPrior per il Parametro di Shrinkage:\n\nNel modello, lo shrinkage viene trattato come un parametro ignoto, e quindi viene posto un hyperprior su \\(\\tau_{\\text{shrinkage}}\\) tramite una distribuzione gamma. Questo consente al modello di apprendere automaticamente il giusto livello di regolarizzazione dai dati, migliorando l’adattamento del modello.\n\n\n\n\n101.5.3 Implementazione del Modello in Stan\nNel codice Stan, la struttura del modello per lo shrinkage è implementata come segue:\n\n# Define the Stan model code\nmodel_code_3 = \"\"\"\ndata {\n  int&lt;lower=1&gt; i_max;     // numero di osservazioni\n  int&lt;lower=1&gt; p;         // numero di predittori (dimensione del vettore a)\n  matrix[i_max, p] x;     // matrice delle covariate\n  vector[i_max] y;        // variabile dipendente\n}\n\nparameters {\n  vector[p] a;            // vettore dei coefficienti\n  real b;                 // intercetta\n  real&lt;lower=0&gt; tau;      // parametro di precisione per y (equivalente a sigma^(-2))\n  real&lt;lower=0&gt; tauShrinkage;  // parametro di precisione per il \"shrinkage\"\n}\n\ntransformed parameters {\n  real&lt;lower=0&gt; sigma;        // deviazione standard per y\n  real&lt;lower=0&gt; sdShrinkage;  // deviazione standard per il \"shrinkage\"\n\n  sigma = 1 / sqrt(tau);                // calcola sigma dalla precisione tau\n  sdShrinkage = 1 / sqrt(tauShrinkage); // calcola sdShrinkage dalla precisione tauShrinkage\n}\n\nmodel {\n  vector[i_max] mu;\n\n  // Likelihood\n  for (i in 1:i_max) {\n    mu[i] = dot_product(a, x[i]) + b; // calcola la media mu per ogni osservazione\n  }\n  y ~ normal(mu, sigma);  // distribuzione normale per y\n\n  // Prior distributions\n  a ~ normal(0, sdShrinkage);  // prior per i coefficienti a[i], con shrinkage\n  b ~ normal(0, sqrt(0.001));  // prior per l'intercetta b\n\n  // Prior distributions per i parametri di precisione\n  tauShrinkage ~ gamma(0.001, 0.001);  // prior per tauShrinkage\n  tau ~ gamma(0.001, 0.001);           // prior per tau\n}\n\"\"\"\n\n# Create a temporary file for the Stan model\nwith tempfile.NamedTemporaryFile(suffix=\".stan\", mode=\"w\", delete=False) as f:\n    f.write(model_code_3)\n    stan_file = f.name\n\nQui:\n\n\\(\\tau_{\\text{shrinkage}}\\) è il parametro che controlla lo shrinkage. Un valore più elevato di \\(\\tau_{\\text{shrinkage}}\\) impone un maggiore shrinkage ai coefficienti \\(a[i]\\), riducendo i valori di \\(a[i]\\).\n\\(sdShrinkage\\) rappresenta la deviazione standard per i coefficienti regolarizzati, e viene derivato direttamente da \\(\\tau_{\\text{shrinkage}}\\).\n\nIn conclusione, l’uso dei shrinkage priors (fissi o adattivi) è fondamentale per ottenere stime più stabili e robusti in modelli con molti predittori. Il vantaggio dell’approccio adattivo è che il livello di shrinkage è stimato dal modello stesso, basato sui dati, anziché essere fissato a priori. Questo approccio, molto simile a quanto avviene nel Lasso e nel Ridge Regression, garantisce che i coefficienti dei predittori irrilevanti vengano ridotti verso zero, migliorando la selezione delle variabili e prevenendo l’overfitting.\n\nmodel_3 = CmdStanModel(stan_file=stan_file)\n\nsamples_3 = model_3.sample(\n    data=stan_data,\n    seed=123,\n    chains=4,\n    parallel_chains=4,  # No data needed for this model\n    show_progress=False,\n    show_console=False,\n)\n\n\n# Estrazione dei campioni posteriori dai parametri 'a', 'b', e 'sigma'\nposterior_a = samples_3.stan_variable(\"a\")  # Campioni posteriori per 'a'\nposterior_b = samples_3.stan_variable(\"b\")  # Campioni posteriori per 'b'\nposterior_sigma = samples_3.stan_variable(\"sigma\")  # Campioni posteriori per 'sigma'\n\n# Calcolo della mediana per ciascuno dei parametri 'a'\nest_a = np.median(posterior_a, axis=0)\n\n# Esegui il grafico delle stime di 'a'\ntrue = np.concatenate([np.ones(10), np.zeros(90)])  # Valori veri per confronto\nplot_estimates(est_a)\n\n\n\n\n\n\n\n\nSi noti che vi è una generale tendenza a ridurre le stime dei coefficienti associati a tutte le variabili. Questo consenti di separare meglio le variabili importanti da quelle irrilevanti. MSE è diminuito ancora.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html#selezione-delle-variabili-con-priori-spike-and-slab",
    "href": "chapters/entropy/05_regularization.html#selezione-delle-variabili-con-priori-spike-and-slab",
    "title": "101  Regolarizzazione",
    "section": "101.6 Selezione delle Variabili con Priori Spike and Slab",
    "text": "101.6 Selezione delle Variabili con Priori Spike and Slab\nL’approccio Spike and Slab, noto anche come SSVS (Stochastic Search Variable Selection), è una strategia utilizzata in contesti bayesiani per affrontare il problema della selezione delle variabili nei modelli di regressione. Questo metodo è stato sviluppato per individuare, tra un insieme di predittori, quelli che contribuiscono significativamente alla spiegazione della variabile dipendente.\nNella regressione multipla, ci sono spesso molti predittori disponibili, e non tutti potrebbero essere rilevanti. Il problema della selezione delle variabili consiste nel determinare quali predittori includere nel modello finale, e l’approccio Spike and Slab offre una soluzione che combina regolarizzazione e selezione di variabili.\n\n101.6.1 Concetto di Spike and Slab\nL’idea alla base dell’approccio Spike and Slab è semplice: ogni coefficiente di regressione viene trattato come se potesse essere “acceso” o “spento”. Ciò significa che si assume che alcuni coefficienti siano praticamente pari a zero (spike), mentre altri siano liberi di variare (slab). Questa assunzione viene modellata utilizzando una combinazione di due componenti: - Spike: Una distribuzione che concentra la probabilità attorno a valori molto piccoli (tipicamente intorno a zero), suggerendo che il predittore associato non è rilevante. - Slab: Una distribuzione con maggiore varianza, che consente al coefficiente di variare significativamente, indicando che il predittore associato potrebbe essere rilevante.\nIn termini più concreti, l’approccio Spike and Slab combina una distribuzione concentrata attorno a zero (lo “spike”) per le variabili irrilevanti, con una distribuzione meno restrittiva (lo “slab”) per le variabili rilevanti. Questo modello riflette l’incertezza su quali predittori includere.\n\n\n101.6.2 Struttura del Modello Spike and Slab Utilizzato\nIl modello presentato utilizza l’approccio Spike and Slab per regolarizzare i coefficienti dei predittori (\\(a_j\\)) e selezionare automaticamente le variabili rilevanti.\nIl modello prevede: 1. Coefficiente non ridotto (\\(a_{\\text{raw}}\\)): Ogni predittore ha un coefficiente grezzo che può essere regolarizzato. 2. Probabilità di inclusione (\\(p_{\\text{ind}}\\)): Rappresenta la probabilità che un dato predittore sia incluso nel modello. Questa variabile è trattata come un parametro incerto e viene modellata con una distribuzione beta, che permette di variare tra \\(0\\) e \\(1\\). 3. Shrinkage (\\(\\tau_{\\text{shrinkage}}\\)): Uno shrinkage più forte riduce i coefficienti di regressione, contribuendo alla regolarizzazione. Lo shrinkage riduce l’effetto dei coefficienti, specialmente quelli meno significativi, avvicinandoli a zero. 4. Variabile indicatrice continua (\\(\\theta_{\\text{raw}}\\)): Non si usa una variabile indicatrice binaria (0 o 1) per determinare se un predittore è incluso o meno. Piuttosto, si utilizza una variabile continua tra 0 e 1, che viene moltiplicata per il coefficiente grezzo per modulare l’inclusione del predittore. Questo consente una transizione più morbida tra “incluso” ed “escluso”, permettendo una maggiore flessibilità.\nIn sintesi, il modello funziona nel modo seguente: - Coefficiente finale (\\(a_j\\)): Viene ottenuto moltiplicando il coefficiente grezzo per la variabile indicatrice continua:\n\\[\n  a_j = \\theta_{\\text{raw},j} \\times a_{\\text{raw},j}\n  \\]\nSe \\(\\theta_{\\text{raw},j}\\) è vicino a 0, il predittore \\(x_j\\) sarà considerato irrilevante; se \\(\\theta_{\\text{raw},j}\\) è vicino a 1, \\(x_j\\) verrà considerato rilevante.\n\n\n101.6.3 Regolarizzazione con Spike and Slab\nLa regolarizzazione attraverso lo Spike and Slab funziona introducendo un compromesso tra semplicità del modello e adattamento ai dati. Questo approccio bilancia:\n\nInclusione di troppi predittori (rischio di overfitting).\nInclusione di troppo pochi predittori (rischio di underfitting).\n\nGrazie alla distribuzione Spike and Slab, è possibile assegnare ai coefficienti una probabilità di inclusione, che permette di “accendere” o “spegnere” i predittori in base alla loro importanza. Nel modello presentato, la prior beta assegnata alla probabilità di inclusione (\\(p_{\\text{ind}}\\)) consente di esprimere una preferenza iniziale sulla probabilità che un predittore sia incluso nel modello.\n\n\n101.6.4 Esempio Psicologico: Selezione di Variabili nei Fattori di Rischio per la Depressione\nImmaginiamo uno studio in cui vogliamo identificare i fattori di rischio per la depressione in un campione di popolazione. Abbiamo una lunga lista di potenziali fattori (età, livello di istruzione, esperienze passate, contesto familiare, variabili psicologiche come autostima, ecc.), ma non sappiamo in anticipo quali siano davvero rilevanti.\nUsando un modello Spike and Slab:\n\nOgni fattore di rischio potenziale ha un coefficiente associato (\\(a_j\\)) che può essere “spento” (spike, coefficiente prossimo a 0) o “acceso” (slab, coefficiente rilevante).\nLa variabile indicatrice continua (\\(\\theta_{\\text{raw}}\\)) riflette la probabilità che quel fattore sia un predittore significativo della depressione.\nSe la variabile indicatrice è vicina a 0, il fattore è irrilevante; se è vicina a 1, il fattore è considerato rilevante.\n\nQuesto approccio permette di identificare automaticamente i fattori di rischio più importanti, regolarizzando al contempo il modello per evitare che variabili irrilevanti creino rumore nei dati.\n\n\n101.6.5 Conclusione\nL’approccio Spike and Slab è particolarmente potente per la selezione automatica delle variabili e la regolarizzazione. Permette di bilanciare il modello, evitando di includere troppe variabili irrilevanti (che porterebbero a overfitting) o di escludere variabili rilevanti (che porterebbero a underfitting). Nel contesto bayesiano, questo approccio combina l’uso di distribuzioni informative e non informative per selezionare i predittori migliori, risultando utile in molteplici aree, dalla psicologia alla statistica applicata.\n\n# Define the Stan model code\nmodel_code_4 = \"\"\"\ndata {\n  int&lt;lower=1&gt; i_max;     // numero di osservazioni\n  int&lt;lower=1&gt; p;         // numero di predittori (dimensione del vettore a)\n  matrix[i_max, p] x;     // matrice delle covariate\n  vector[i_max] y;        // variabile dipendente\n}\n\nparameters {\n  vector[p] a_raw;             // Coefficienti non ridotti\n  real b;                      // Intercetta\n  real&lt;lower=0&gt; tau;           // Precisione per la likelihood\n  real&lt;lower=0&gt; tauShrinkage;  // Precisione per lo shrinkage\n  real&lt;lower=0, upper=1&gt; pind; // Probabilità di inclusione\n  vector&lt;lower=0, upper=1&gt;[p] theta_raw;  // Variabile continua tra 0 e 1 per l'inclusione\n}\n\ntransformed parameters {\n  vector[p] a;                 // Coefficienti finali dopo lo shrinkage\n  real sigma;                  // Deviazione standard\n  real sdShrinkage;            // Deviazione standard per lo shrinkage\n\n  // Calcola sigma e sdShrinkage dalle precisioni\n  sigma = 1 / sqrt(tau);\n  sdShrinkage = 1 / sqrt(tauShrinkage);\n\n  // Applica lo shrinkage ai coefficienti basato su theta_raw\n  for (j in 1:p) {\n    a[j] = theta_raw[j] * a_raw[j];  // Moltiplica per la variabile indicatrice continua\n  }\n}\n\nmodel {\n  vector[i_max] mu;\n\n  // Likelihood\n  for (i in 1:i_max) {\n    mu[i] = dot_product(a, x[i]) + b;  // Calcola la media mu per ogni osservazione\n  }\n  y ~ normal(mu, sigma);  // Distribuzione normale per y\n\n  // Prior distributions\n  a_raw ~ normal(0, sdShrinkage);           // Prior per i coefficienti grezzi (slab)\n  b ~ normal(0, 0.001);                    // Prior per l'intercetta\n  theta_raw ~ beta(pind, 1 - pind);         // Prior per l'inclusione dei predittori (continua)\n  pind ~ beta(0.2, 0.8);                   // Prior più estrema per una polarizzazione più forte\n  tauShrinkage ~ gamma(0.01, 0.01);        // Prior per lo shrinkage, ancora più aggressivo\n  tau ~ gamma(0.001, 0.001);               // Prior per tau\n}\n\"\"\"\n\n# Create a temporary file for the Stan model\nwith tempfile.NamedTemporaryFile(suffix=\".stan\", mode=\"w\", delete=False) as f:\n    f.write(model_code_4)\n    stan_file = f.name\n\n\nmodel_4 = CmdStanModel(stan_file=stan_file)\n\nsamples_4 = model_4.sample(\n    data=stan_data,\n    seed=123,\n    chains=4,\n    parallel_chains=4,  \n    show_progress=False,\n    show_console=False,\n)\n\nCalcoliamo la probabilità di inclusione: per ogni campione, contiamo quanti a[j] sono significativamente lontani da 0. Un modo semplice è considerare un cutoff, diciamo |a[j]| &gt; 0.1 come criterio di inclusione.\n\n# Estrai i campioni di 'a' dai risultati di cmdstanpy\nsamples = samples_4.stan_variable(\"a\")\n\nincl_prob = np.mean(np.abs(samples) &gt; 0.1, axis=0)\n\n# Crea un barplot per visualizzare la probabilità di inclusione\nplt.bar(range(1, len(incl_prob) + 1), incl_prob)\nplt.xlabel(\"Predictor\")\nplt.ylabel(\"Inclusion Probability\")\nplt.title(\"Probability of Inclusion for Each Predictor\")\nplt.show()\n\n\n\n\n\n\n\n\nSi noti che c’è una buona separazione tra le variabili importanti e quelle irrilevanti.\nCalcoliamo ora le stime per ciascun predittore.\n\n# Extract the 'a_raw' (the untransformed coefficients) and 'theta_raw' (inclusion indicators)\na_raw_samples = samples_4.stan_variable(\"a_raw\")\ntheta_samples = samples_4.stan_variable(\"theta_raw\")\n\n# Compute the conditional estimates: a_raw * theta for each sample\nconditional_samples = a_raw_samples * theta_samples\n\n# Calculate the median of the conditional estimates for each predictor\ncondEst = np.median(conditional_samples, axis=0)\n\n\nplot_estimates(condEst)\n\n\n\n\n\n\n\n\nAnche in questo caso, osserviamo una netta distinzione tra i due insiemi di predittori.\nInfine, calcoliamo lo stimatore finale come prodotto tra la stima condizionale e la probabilità di inclusione.\n\nfinal_estimator = condEst * incl_prob\n\n# Plot the final estimates\nplot_estimates(final_estimator)\n\n\n\n\n\n\n\n\nI risultati ottenuti suggeriscono che il metodo Spike and Slab si rivela efficace nell’ambito della selezione delle variabili per il problema in esame. In particolare, tale metodo conduce al valore minimo di MSE.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html#riflessioni-conclusive",
    "href": "chapters/entropy/05_regularization.html#riflessioni-conclusive",
    "title": "101  Regolarizzazione",
    "section": "101.7 Riflessioni Conclusive",
    "text": "101.7 Riflessioni Conclusive\nL’uso di priori informativi e dell’approccio Spike and Slab offre un potente strumento per la selezione di variabili nei modelli statistici, specialmente in contesti con un gran numero di predittori e dati limitati. Questi metodi consentono di determinare in modo efficace quali predittori includere nel modello finale, riducendo al minimo il rischio di sovra-adattamento e mantenendo al contempo una buona capacità predittiva.\nIl principale vantaggio dell’approccio Spike and Slab risiede nella sua capacità di combinare l’informazione a priori con l’evidenza dei dati, fornendo un metodo flessibile che permette di identificare le variabili rilevanti e di ridurre l’influenza di quelle irrilevanti. Questo processo di regolarizzazione facilita la costruzione di modelli più parsimoniosi e interpretabili, mantenendo un buon equilibrio tra complessità e accuratezza.\nOltre a questi vantaggi, i metodi basati su prior (come il Spike and Slab) possono essere utilizzati in parallelo con altri strumenti di selezione del modello, come i criteri di informazione (AIC, BIC, WAIC, LOO). Questi criteri, che valutano la qualità del modello sulla base della complessità e della capacità di adattamento ai dati, forniscono un approccio complementare alla selezione delle variabili. L’integrazione di queste diverse tecniche permette di ottenere un processo di selezione del modello più robusto e ben fondato.\nIn conclusione, l’approccio bayesiano alla selezione delle variabili, tramite l’uso di priors informativi e metodi di regolarizzazione come il Spike and Slab, rappresenta una strategia efficace e versatile per migliorare l’inferenza e la predittività dei modelli statistici. Questo approccio non solo permette di selezionare le variabili rilevanti in modo rigoroso, ma consente anche di incorporare le conoscenze pregresse e di ottenere modelli più parsimoniosi senza compromettere l’accuratezza.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/05_regularization.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/05_regularization.html#informazioni-sullambiente-di-sviluppo",
    "title": "101  Regolarizzazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m -p jax\n\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\nLast updated: Wed Oct 16 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\njax: 0.4.28\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 24.0.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.4\nseaborn   : 0.13.2\nlogging   : 0.5.1.2\nscipy     : 1.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>Regolarizzazione</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/06_cognitive_modeling.html",
    "href": "chapters/entropy/06_cognitive_modeling.html",
    "title": "102  Dall’analisi descrittiva alla modellazione cognitiva",
    "section": "",
    "text": "102.1 Introduzione\nNell’analisi dei dati psicologici, l’approccio tradizionale si basa spesso su confronti descrittivi, come la differenza tra le medie di due condizioni sperimentali. Sebbene questo approccio possa fornire informazioni utili, è limitato nella sua capacità di rivelare la complessità dei processi psicologici sottostanti. Un’analisi che si fermi a questo livello rischia di non cogliere la ricchezza dei meccanismi psicologici che realmente generano i dati osservati. Come sottolineato da McElreath (2020), un vero avanzamento nella comprensione dei fenomeni richiede l’adozione di modelli che siano esplicitamente formulati in termini di processi generativi sottostanti.\nUn modello generativo non si limita a descrivere i dati; piuttosto, esso riflette un’ipotesi teorica su come i dati vengano effettivamente prodotti. Questo tipo di modellizzazione consente di testare ipotesi teoriche complesse e di confrontare l’adeguatezza di diversi modelli esplicativi. In questo modo, la ricerca non solo quantifica differenze osservate, ma esplora le cause e i processi che le determinano, permettendo un’interpretazione più profonda e teoricamente informata dei risultati.\nIn questo tutorial, vengono confrontati due approcci modellistici diversi: un modello semplice e descrittivo, e un modello processuale più complesso, che incorpora una teoria esplicita del processo cognitivo sottostante. Il primo modello rappresenta un approccio tradizionale, che si limita a distinguere tra due condizioni senza tener conto del meccanismo generativo che potrebbe differenziarle. Il secondo modello, invece, è costruito su un’ipotesi teorica che descrive come il processo cognitivo operi in ciascuna delle due condizioni. Attraverso questo confronto, mostreremo come un modello che incorpora esplicitamente il processo cognitivo possa fornire un’interpretazione più ricca e accurata dei dati, rispetto a un modello che si limita a descrivere differenze superficiali.\nL’obiettivo di questo capitolo è quindi dimostrare l’importanza di adottare modelli generativi nella ricerca psicologica, evidenziando come essi possano superare le limitazioni degli approcci descrittivi tradizionali e fornire intuizioni più profonde sul funzionamento dei fenomeni psicologici.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/06_cognitive_modeling.html#modello-process",
    "href": "chapters/entropy/06_cognitive_modeling.html#modello-process",
    "title": "102  Dall’analisi descrittiva alla modellazione cognitiva",
    "section": "102.2 Modello “Process”",
    "text": "102.2 Modello “Process”\nIl modello “process” ipotizza un meccanismo cognitivo in cui l’accuratezza delle risposte di un soggetto in un compito può variare in base a due condizioni sperimentali: una condizione di “alto apprendimento” e una condizione di “basso apprendimento”. L’idea di base è che nella condizione di alto apprendimento, il soggetto non solo apprende dalle risposte precedenti, migliorando gradualmente la sua accuratezza, ma subisce anche un decadimento di tale apprendimento nel tempo. Nella condizione di basso apprendimento, invece, il soggetto non migliora nel tempo, mantenendo un livello costante di accuratezza.\nQuesta dinamica riflette un processo di apprendimento che è modulato da due forze opposte: un tasso di apprendimento che permette al soggetto di migliorare la sua performance in base agli errori commessi, e un tasso di decadimento che riduce gradualmente l’effetto dell’apprendimento nel tempo. Questo modello è più complesso rispetto a un modello descrittivo semplice perché tenta di catturare il processo dinamico di come l’accuratezza evolve durante il compito, piuttosto che limitarsi a descrivere una differenza fissa tra due condizioni.\nImplementazione del Modello\n\nDati di Input\n\nN: Il numero totale di prove (trials) a cui il soggetto è sottoposto.\ny: Un array binario (0 o 1) che rappresenta l’accuratezza di ciascuna risposta. Un valore di 1 indica una risposta corretta, mentre un valore di 0 indica una risposta errata.\ncondition: Un array binario che indica la condizione sperimentale per ciascuna prova: 1 se il soggetto è nella condizione di “alto apprendimento” e 0 se è nella condizione di “basso apprendimento”.\n\nParametri del Modello\n\ntheta_initial: Rappresenta l’accuratezza iniziale del soggetto, prima che qualsiasi apprendimento o decadimento abbia avuto luogo.\nlearning_rate: Rappresenta il tasso di apprendimento, ovvero quanto rapidamente il soggetto migliora in risposta agli errori precedenti.\ndecay_rate: Rappresenta il tasso di decadimento, ovvero quanto velocemente l’effetto dell’apprendimento diminuisce nel tempo.\n\nDistribuzioni A Priori\n\nI parametri theta_initial, learning_rate e decay_rate sono tutti modellati come variabili aleatorie con distribuzioni beta. La distribuzione beta è spesso utilizzata per modellare probabilità, poiché è limitata tra 0 e 1 e può assumere varie forme in base ai parametri scelti.\n\nImplementazione del Processo Cognitivo\n\nIl modello si sviluppa in modo iterativo per ciascuna prova, a partire dalla seconda (la prima prova è gestita separatamente perché non ha una risposta precedente da cui apprendere).\nPer ogni prova successiva:\n\nViene calcolata la probabilità di risposta corretta (p) in base alla condizione corrente.\nSe la condizione è di “alto apprendimento” (condition[n] == 1), la probabilità di risposta corretta viene aggiornata in base a una combinazione di decadimento e apprendimento:\n\nLa parte (1 - decay_rate) * theta_initial riduce l’influenza dell’accuratezza iniziale, simulando il decadimento.\nLa parte learning_rate * (1 - y[n - 1]) aumenta la probabilità di una risposta corretta se la prova precedente è stata errata, simulando l’apprendimento dagli errori.\n\nLa funzione fmin e fmax sono utilizzate per assicurarsi che la probabilità p rimanga all’interno dell’intervallo [0, 1].\n\nSe la condizione è di “basso apprendimento” (condition[n] == 0), la probabilità di risposta corretta rimane invariata a theta_initial.\n\nGenerazione dei Dati Simulati\n\nNella sezione generated quantities, il modello genera dati simulati (y_rep) e calcola la log-verosimiglianza (log_lik) per ciascuna prova. Questo è utile per confrontare la bontà di adattamento del modello rispetto ai dati osservati.\nPer ogni prova, viene calcolata la probabilità di una risposta corretta e quindi viene generato un valore simulato usando la funzione bernoulli_rng. Il valore di log-verosimiglianza viene calcolato utilizzando bernoulli_lpmf.\n\n\nIl modello “process” cerca di rappresentare un meccanismo cognitivo complesso, in cui l’accuratezza delle risposte varia dinamicamente in base a un processo di apprendimento e decadimento. Questo approccio permette di testare ipotesi più articolate sui dati, andando oltre una semplice descrizione delle differenze tra condizioni e cercando di catturare la struttura cognitiva che guida il comportamento osservato.\n\nstan_file = os.path.join(project_directory, \"stan\", \"cognitive_process_model.stan\")\nprocess_model = CmdStanModel(stan_file=stan_file)\nprint(process_model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of trials\n  array[N] int&lt;lower=0, upper=1&gt; y; // accuracy (0 or 1)\n  array[N] int&lt;lower=0, upper=1&gt; condition; // 1 if high learning, 0 if low learning\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta_initial; // initial accuracy\n  real&lt;lower=0, upper=1&gt; learning_rate; // learning rate\n  real&lt;lower=0, upper=1&gt; decay_rate; // decay rate\n}\nmodel {\n  // Priors\n  theta_initial ~ beta(2, 2);\n  learning_rate ~ beta(2, 2);\n  decay_rate ~ beta(2, 2);\n  \n  for (n in 2 : N) {\n    real p = condition[n]\n             * fmin(fmax((1 - decay_rate) * theta_initial\n                         + learning_rate * (1 - y[n - 1]), 0),\n                    1)\n             + (1 - condition[n]) * theta_initial;\n    y[n] ~ bernoulli(p);\n  }\n}\ngenerated quantities {\n  array[N] int&lt;lower=0, upper=1&gt; y_rep;\n  array[N] real log_lik;\n  \n  y_rep[1] = bernoulli_rng(theta_initial); // First trial based on initial theta\n  log_lik[1] = bernoulli_lpmf(y[1] | theta_initial);\n  \n  for (n in 2 : N) {\n    real p = condition[n]\n             * fmin(fmax((1 - decay_rate) * theta_initial\n                         + learning_rate * (1 - y[n - 1]), 0),\n                    1)\n             + (1 - condition[n]) * theta_initial;\n    \n    y_rep[n] = bernoulli_rng(p);\n    log_lik[n] = bernoulli_lpmf(y[n] | p);\n    \n    // Optional diagnostic print statement\n    print(\"n: \", n, \" p: \", p, \" y_rep[n]: \", y_rep[n]);\n  }\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/06_cognitive_modeling.html#modello-simpler",
    "href": "chapters/entropy/06_cognitive_modeling.html#modello-simpler",
    "title": "102  Dall’analisi descrittiva alla modellazione cognitiva",
    "section": "102.3 Modello “Simpler”",
    "text": "102.3 Modello “Simpler”\nIl modello “simpler” è un approccio più basilare per modellare i dati, in cui si assume che l’accuratezza delle risposte in ciascuna prova dipenda esclusivamente dalla condizione sperimentale (alta o bassa) in cui si trova il soggetto. A differenza del modello “process”, che tiene conto di come l’accuratezza possa evolvere dinamicamente in funzione dell’apprendimento e del decadimento, il modello “simpler” presuppone che l’accuratezza sia costante all’interno di ciascuna condizione e non cambi nel tempo.\nIn altre parole, il modello “simpler” cerca di cogliere solo la differenza di accuratezza tra due condizioni, senza considerare l’evoluzione della performance nel corso delle prove. Questo approccio è più limitato e descrittivo, e non tenta di spiegare il processo sottostante che potrebbe dare origine ai dati osservati.\nImplementazione del Modello\n\nDati di Input\n\nN: Il numero totale di prove (trials) a cui il soggetto è sottoposto.\ny: Un array binario (0 o 1) che rappresenta l’accuratezza di ciascuna risposta. Un valore di 1 indica una risposta corretta, mentre un valore di 0 indica una risposta errata.\ncondition: Un array binario che indica la condizione sperimentale per ciascuna prova: 1 se il soggetto è nella condizione di “alto apprendimento” e 0 se è nella condizione di “basso apprendimento”.\n\nParametri del Modello\n\ntheta_high: Rappresenta l’accuratezza nelle prove in cui il soggetto è nella condizione di “alto apprendimento”.\ntheta_low: Rappresenta l’accuratezza nelle prove in cui il soggetto è nella condizione di “basso apprendimento”.\n\nDistribuzioni A Priori\n\nI parametri theta_high e theta_low sono modellati come variabili aleatorie con distribuzioni beta. Come nel modello “process”, la distribuzione beta è scelta perché è limitata tra 0 e 1, rendendola adatta per modellare probabilità.\n\nImplementazione del Modello\n\nIl modello assume che per ogni prova ci sia una probabilità p di ottenere una risposta corretta, che dipende dalla condizione in cui si trova il soggetto.\nSe il soggetto è nella condizione di “alto apprendimento” (condition[n] == 1), la probabilità p è semplicemente uguale a theta_high.\nSe il soggetto è nella condizione di “basso apprendimento” (condition[n] == 0), la probabilità p è uguale a theta_low.\nIn pratica, per ogni prova, il modello stima la probabilità di risposta corretta in base alla condizione sperimentale senza considerare alcuna evoluzione dinamica della performance.\n\nGenerazione dei Dati Simulati\n\nNella sezione generated quantities, il modello genera dati simulati (y_rep) e calcola la log-verosimiglianza (log_lik) per ciascuna prova.\nPer ogni prova, viene calcolata la probabilità di una risposta corretta e quindi viene generato un valore simulato usando la funzione bernoulli_rng. Il valore di log-verosimiglianza viene calcolato utilizzando bernoulli_lpmf.\n\n\nIl modello “process” e il modello “simpler” differiscono in modo sostanziale nel modo in cui cercano di spiegare i dati:\n\nDinamica dell’apprendimento vs. Accuratezza fissa:\n\nProcess Model: Tiene conto che l’accuratezza possa variare nel tempo in risposta agli errori e al decadimento, catturando la complessità del processo di apprendimento influenzato dalla condizione sperimentale.\nSimpler Model: Assume un’accuratezza costante all’interno di ciascuna condizione, senza considerare variazioni dinamiche dovute all’apprendimento o al decadimento.\n\nComplessità del Meccanismo Cognitivo:\n\nProcess Model: Rappresenta in modo dettagliato il meccanismo cognitivo che guida la performance, considerando l’evoluzione della performance basata sulle esperienze precedenti.\nSimpler Model: Fornisce una descrizione statica e limitata alle differenze medie tra condizioni, senza approfondire il processo sottostante.\n\nCapacità Predittiva:\n\nProcess Model: Dovrebbe predire meglio i dati quando l’apprendimento o il decadimento sono rilevanti, grazie alla sua considerazione delle dinamiche temporali.\nSimpler Model: Potrebbe non cogliere adeguatamente la struttura dei dati in presenza di tali dinamiche, risultando meno preciso nelle predizioni.\n\n\nIn sintesi, il modello “simpler” non riesce a catturare i cambiamenti dinamici nell’accuratezza legati al compito, offrendo solo una descrizione media delle differenze tra condizioni. Pertanto, quando i dati seguono un processo di apprendimento o decadimento, il modello “simpler” tende a essere meno efficace rispetto al modello “process”.\n\nstan_simpler_file = os.path.join(\n    project_directory, \"stan\", \"cognitive_simpler_model.stan\"\n)\nsimpler_model = CmdStanModel(stan_file=stan_simpler_file)\nprint(simpler_model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // number of trials\n  array[N] int&lt;lower=0, upper=1&gt; y; // accuracy (0 or 1)\n  array[N] int&lt;lower=0, upper=1&gt; condition; // 1 if high learning, 0 if low learning\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta_high; // accuracy in condition 1\n  real&lt;lower=0, upper=1&gt; theta_low; // accuracy in condition 0\n}\nmodel {\n  // Priors\n  theta_high ~ beta(2, 2);\n  theta_low ~ beta(2, 2);\n  \n  for (n in 1 : N) {\n    real p = condition[n] * theta_high + (1 - condition[n]) * theta_low;\n    y[n] ~ bernoulli(p);\n  }\n}\ngenerated quantities {\n  array[N] int&lt;lower=0, upper=1&gt; y_rep;\n  array[N] real log_lik;\n  \n  for (n in 1 : N) {\n    real p = condition[n] * theta_high + (1 - condition[n]) * theta_low;\n    y_rep[n] = bernoulli_rng(p);\n    log_lik[n] = bernoulli_lpmf(y[n] | p);\n  }\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/06_cognitive_modeling.html#simulazione-dei-dati",
    "href": "chapters/entropy/06_cognitive_modeling.html#simulazione-dei-dati",
    "title": "102  Dall’analisi descrittiva alla modellazione cognitiva",
    "section": "102.4 Simulazione dei Dati",
    "text": "102.4 Simulazione dei Dati\nI dati sono stati simulati in base al meccanismo generativo ipotizzato dal modello “process”. Questo modello assume che l’accuratezza delle risposte non sia costante nel tempo, ma che evolva dinamicamente in funzione dell’apprendimento e del decadimento. In altre parole, il modello “process” riflette un processo cognitivo in cui i soggetti possono migliorare la loro performance attraverso l’apprendimento, o al contrario, possono mostrare un calo di prestazioni a causa della fatica o della perdita di concentrazione.\nNel processo di simulazione, quindi, i dati generati riflettono queste dinamiche: l’accuratezza non è semplicemente una funzione statica delle condizioni sperimentali, ma cambia in risposta alle prove precedenti. Questo è in contrasto con il modello “simpler”, che non tiene conto di queste dinamiche e assume che l’accuratezza sia fissa e immutabile all’interno di ciascuna condizione sperimentale. Di conseguenza, i dati simulati seguono il processo cognitivo ipotizzato dal modello “process”, che si basa su un’accuratezza variabile e influenzata dall’apprendimento e dal decadimento, fornendo una base per confrontare l’adattamento dei due modelli ai dati.\n\n# Parameters for data generation\nN = 5000  # Number of trials\ncondition = np.random.binomial(\n    1, 0.5, N\n)  # 50% chance of being in the high-learning condition\n\ntheta_initial = 0.6  # Initial accuracy\nlearning_rate_high = (\n    0.3  # Higher learning rate in the process model for high-learning condition\n)\nlearning_rate_low = (\n    0.1  # Lower learning rate in the process model for low-learning condition\n)\ndecay_rate_high = (\n    0.05  # Lower decay rate in the process model for high-learning condition\n)\ndecay_rate_low = (\n    0.15  # Higher decay rate in the process model for low-learning condition\n)\n\naccuracies = np.zeros(N)\nvalue = theta_initial\n\nfor n in range(N):\n    if condition[n] == 1:  # High-learning condition\n        if n &gt; 0:\n            # Enhanced learning effect when previous trial was incorrect\n            value = (1 - decay_rate_high) * value + learning_rate_high * (\n                1 - accuracies[n - 1]\n            )\n        # Ensure that value remains within [0, 1]\n        value = np.clip(value, 0, 1)\n        accuracies[n] = np.random.binomial(1, value)\n    else:  # Low-learning condition\n        if n &gt; 0:\n            # Weaker learning effect and higher decay rate\n            value = (1 - decay_rate_low) * value + learning_rate_low * (\n                1 - accuracies[n - 1]\n            )\n        # Ensure that value remains within [0, 1]\n        value = np.clip(value, 0, 1)\n        accuracies[n] = np.random.binomial(1, value)\n\n# Prepare data for Stan\nstan_data = {\n    \"N\": N,\n    \"y\": accuracies.astype(int).tolist(),\n    \"condition\": condition.astype(int).tolist(),\n}",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/06_cognitive_modeling.html#campionamento",
    "href": "chapters/entropy/06_cognitive_modeling.html#campionamento",
    "title": "102  Dall’analisi descrittiva alla modellazione cognitiva",
    "section": "102.5 Campionamento",
    "text": "102.5 Campionamento\nEseguiamo il campionamento per i due modelli.\n\nfit_process = process_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n07:54:25 - cmdstanpy - INFO - CmdStan start processing\n07:54:25 - cmdstanpy - INFO - Chain [1] start processing\n07:54:25 - cmdstanpy - INFO - Chain [2] start processing\n07:54:25 - cmdstanpy - INFO - Chain [3] start processing\n07:54:25 - cmdstanpy - INFO - Chain [4] start processing\n07:55:41 - cmdstanpy - INFO - Chain [1] done processing\n07:55:42 - cmdstanpy - INFO - Chain [3] done processing\n07:55:42 - cmdstanpy - INFO - Chain [4] done processing\n07:55:42 - cmdstanpy - INFO - Chain [2] done processing\n\n\n\n_ = az.plot_trace(fit_process, var_names=(\"learning_rate\", \"decay_rate\"))\n\n\n\n\n\n\n\n\n\naz.summary(fit_process, var_names=[\"learning_rate\", \"decay_rate\"])\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nlearning_rate\n0.214\n0.015\n0.187\n0.241\n0.0\n0.0\n4908.0\n5214.0\n1.0\n\n\ndecay_rate\n0.009\n0.006\n0.000\n0.020\n0.0\n0.0\n4692.0\n3553.0\n1.0\n\n\n\n\n\n\n\n\nfit_simpler = simpler_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n07:57:33 - cmdstanpy - INFO - CmdStan start processing\n07:57:33 - cmdstanpy - INFO - Chain [1] start processing\n07:57:33 - cmdstanpy - INFO - Chain [2] start processing\n07:57:33 - cmdstanpy - INFO - Chain [3] start processing\n07:57:33 - cmdstanpy - INFO - Chain [4] start processing\n07:57:44 - cmdstanpy - INFO - Chain [2] done processing\n07:57:44 - cmdstanpy - INFO - Chain [4] done processing\n07:57:44 - cmdstanpy - INFO - Chain [1] done processing\n07:57:45 - cmdstanpy - INFO - Chain [3] done processing",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/06_cognitive_modeling.html#confronto-dei-modelli",
    "href": "chapters/entropy/06_cognitive_modeling.html#confronto-dei-modelli",
    "title": "102  Dall’analisi descrittiva alla modellazione cognitiva",
    "section": "102.6 Confronto dei Modelli",
    "text": "102.6 Confronto dei Modelli\nPer confrontare i modelli, è necessario convertire l’oggetto fit in un formato compatibile con ArviZ.\n\nidata_process = az.from_cmdstanpy(posterior=fit_process)\nidata_simpler = az.from_cmdstanpy(posterior=fit_simpler)\n\nCalcoliamo il criterio LOO (Leave-One-Out) per confrontare i due modelli.\n\nloo_process = az.loo(idata_process)\nloo_simpler = az.loo(idata_simpler)\n\nConfrontiamo i due modelli utilizzando il criterio LOO.\n\nloo_comparison = az.compare(\n    {\"Process Model\": loo_process, \"Simpler Model\": loo_simpler}\n)\nprint(loo_comparison)\n\n               rank     elpd_loo     p_loo  elpd_diff    weight         se  \\\nProcess Model     0 -3123.273484  2.008705   0.000000  0.685872  24.569185   \nSimpler Model     1 -3149.844801  1.991303  26.571317  0.314128  24.127268   \n\n                     dse  warning scale  \nProcess Model   0.000000    False   log  \nSimpler Model  12.069884    False   log  \n\n\nL’output di loo_comparison() confronta i due modelli utilizzando il criterio di Leave-One-Out Cross-Validation (LOO) basato sull’Expected Log Predictive Density (ELPD). Ogni colonna nell’output fornisce informazioni diverse sul confronto tra i modelli. Vediamo cosa significa ciascuna colonna:\n\nrank: Questa colonna indica la posizione del modello in base all’ELPD. Il modello con il valore più alto di ELPD è classificato al primo posto.\nelpd_loo: Questo valore rappresenta la Expected Log Pointwise Predictive Density calcolata usando il metodo LOO. In parole semplici, misura quanto bene il modello predice i dati osservati, tenendo conto della complessità del modello per evitare l’overfitting. Un valore più alto indica che il modello ha una migliore capacità predittiva.\np_loo: Questa colonna stima il numero effettivo di parametri del modello, cioè quanti “gradi di libertà” effettivi il modello sta usando per adattarsi ai dati. Un valore più alto indica un modello più complesso.\nelpd_diff: Questa colonna mostra la differenza di ELPD tra il modello migliore (quello al primo posto) e gli altri modelli. Per il modello migliore, questo valore è 0. Gli altri modelli avranno valori positivi, che indicano quanto peggio si comportano rispetto al modello migliore.\nweight: Questo valore rappresenta la probabilità normalizzata che ciascun modello sia il migliore per fare previsioni su nuovi dati. I pesi sono normalizzati in modo che la somma sia pari a 1. Per esempio, un peso di 0.685872 indica che c’è il 68.6% di probabilità che quel modello sia il migliore nel predire nuovi dati.\nse: Questo è l’errore standard dell’ELPD stimato, che rappresenta l’incertezza associata a questa stima. Un errore standard più basso indica maggiore fiducia nell’ELPD calcolato.\ndse: Significa “errore standard della differenza dell’ELPD”. Indica l’incertezza nella differenza di ELPD tra il miglior modello e un altro modello. Un valore basso di dse suggerisce che siamo abbastanza sicuri che la differenza osservata non sia dovuta al caso.\nwarning: Questa colonna indica se ci sono stati avvertimenti durante il calcolo. Se il valore è False, significa che non ci sono stati problemi.\nscale: Indica la scala utilizzata per il confronto tra modelli. In questo caso, si usa la scala logaritmica (log), che è comune quando si analizzano log-verosimiglianze.\n\nInterpretazione\n\nClassifica dei Modelli: Il Process Model è classificato al primo posto, il che significa che ha l’ELPD più alto e, quindi, si adatta meglio ai dati rispetto al Simpler Model.\nDifferenza in ELPD (elpd_diff): La differenza tra i due modelli è significativa (135,85), il che suggerisce che il Process Model offre una capacità predittiva notevolmente migliore.\nPesi: Il Process Model ha un peso di 0.686, il che indica che, secondo il confronto LOO, c’è una probabilità del 68.6% che sia il miglior modello per fare previsioni su nuovi dati, mentre il Simpler Model ha solo il 31.4% di probabilità.\nErrore Standard della Differenza (dse): La dse relativamente bassa rispetto all’elpd_diff conferma che la differenza tra i modelli è significativa e non è dovuta a variazioni casuali.\n\nIn conclusione, questo output suggerisce chiaramente che il Process Model, che incorpora un processo cognitivo più complesso, è nettamente superiore al Simpler Model per quanto riguarda l’adattamento ai dati. Questa superiorità è supportata sia dal confronto delle stime di ELPD sia dai pesi associati ai modelli.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/06_cognitive_modeling.html#riflessioni-conclusive",
    "href": "chapters/entropy/06_cognitive_modeling.html#riflessioni-conclusive",
    "title": "102  Dall’analisi descrittiva alla modellazione cognitiva",
    "section": "102.7 Riflessioni Conclusive",
    "text": "102.7 Riflessioni Conclusive\nI risultati ottenuti dimostrano chiaramente l’importanza di implementare un modello che rifletta il processo generativo dei dati (McElreath (2020)). Il modello “process,” che cattura la complessità delle dinamiche di apprendimento e decadimento, ha mostrato una performance superiore rispetto al modello più semplice, che si limita a distinguere tra due condizioni. Questo sottolinea come un’analisi basata su un modello che incorpora le ipotesi sul processo sottostante possa portare a una migliore comprensione dei dati e, in ultima analisi, a risultati più solidi.\nÈ fondamentale eseguire simulazioni preliminari prima di raccogliere dati empirici. Queste simulazioni permettono di valutare l’adeguatezza della numerosità campionaria necessaria a rilevare gli effetti ipotizzati, tenendo conto del processo generativo dei dati. Nel caso presente, l’analisi è stata semplificata concentrandosi su un singolo campione di osservazioni indipendenti. Tuttavia, in un contesto più realistico, sarebbe opportuno considerare dati provenienti da più soggetti e riformulare il modello in modo gerarchico per catturare la variabilità tra individui. Lo scopo qui era limitato al confronto tra i due modelli per evidenziare l’importanza di modellare il processo generativo.\nL’approccio bayesiano, e in particolare l’uso di Stan, offre un vantaggio notevole in questo contesto, consentendo di implementare in modo relativamente semplice modelli complessi che riflettono fedelmente il processo generativo ipotizzato. Questo tipo di modellazione risulta molto più difficile, se non impossibile, utilizzando metodi non bayesiani, che spesso non permettono di catturare con la stessa flessibilità le dinamiche sottostanti ai dati.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/06_cognitive_modeling.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/entropy/06_cognitive_modeling.html#informazioni-sullambiente-di-sviluppo",
    "title": "102  Dall’analisi descrittiva alla modellazione cognitiva",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Wed Aug 21 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>Dall'analisi descrittiva alla modellazione cognitiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/07_inductive_inference.html",
    "href": "chapters/entropy/07_inductive_inference.html",
    "title": "103  Limiti dell’inferenza induttiva",
    "section": "",
    "text": "Introduzione\nLa selezione delle ipotesi attraverso il teorema di Bayes e l’uso di strumenti come l’Expected Log Predictive Density (ELPD) per il confronto tra modelli costituiscono approcci potenti, ma non risolvono completamente il problema dell’inferenza statistica. Come sottolineato da McElreath (2020), queste metodologie operano all’interno di un “piccolo mondo” teorico, e non è sempre chiaro come tali soluzioni si estendano al “grande mondo” complesso e variabile che desideriamo realmente comprendere. Questo capitolo si propone di esplorare questa disconnessione, esaminando la distanza tra la teoria empirica dei fenomeni e i modelli statistici semplificati che possiamo effettivamente testare.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/07_inductive_inference.html#inferenza-statistica",
    "href": "chapters/entropy/07_inductive_inference.html#inferenza-statistica",
    "title": "103  Limiti dell’inferenza induttiva",
    "section": "103.1 Inferenza Statistica",
    "text": "103.1 Inferenza Statistica\nL’inferenza statistica è un processo induttivo in cui i dati osservati non forniscono informazioni sufficienti per determinare con certezza il processo che li ha generati. La regola di Bayes offre una soluzione ottimale per aggiornare le nostre convinzioni alla luce di nuovi dati. McElreath (2020) introduce il concetto di “Grande Mondo,” un universo infinito di processi che potrebbero spiegare le nostre osservazioni. Poiché è impossibile considerare tutte le possibilità di questo “Grande Mondo,” ci concentriamo sul “Piccolo Mondo,” una rappresentazione semplificata che limita l’analisi a un insieme finito di modelli e parametri pertinenti.\nAd esempio, consideriamo l’analisi dell’altezza umana utilizzando un modello probabilistico in cui l’altezza segue una distribuzione normale, caratterizzata da una media (µ) e una deviazione standard (σ). L’obiettivo è stimare questi parametri sconosciuti. La funzione di verosimiglianza, derivata dalle distribuzioni di probabilità nel Piccolo Mondo, rappresenta questo insieme di possibilità. Tuttavia, questo insieme può essere troppo vasto per essere gestito in modo efficace, quindi utilizziamo la nostra conoscenza pregressa per restringere il campo.\nNell’inferenza bayesiana, queste conoscenze preesistenti vengono espresse tramite una distribuzione di probabilità a priori, che riflette le nostre convinzioni iniziali sui parametri del modello. La regola di Bayes permette di aggiornare queste convinzioni alla luce dei nuovi dati, producendo una distribuzione a posteriori che offre una stima più accurata dei parametri che descrivono il processo generativo dei dati.\nIn sintesi, l’inferenza statistica ci avvicina alla comprensione di fenomeni complessi attraverso la modellazione semplificata nel “Piccolo Mondo”. L’inferenza bayesiana integra le conoscenze pregresse con i nuovi dati per perfezionare le nostre stime, con l’obiettivo di individuare modelli del “Piccolo Mondo” che, pur non essendo perfetti, siano efficaci nel fare previsioni e nel migliorare la nostra comprensione del fenomeno in esame.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/07_inductive_inference.html#sec-poetic-validity",
    "href": "chapters/entropy/07_inductive_inference.html#sec-poetic-validity",
    "title": "103  Limiti dell’inferenza induttiva",
    "section": "103.2 Validità Poetica",
    "text": "103.2 Validità Poetica\nAbbiamo esplorato il teorema di Bayes come metodo per valutare la plausibilità di un’ipotesi, uno dei motivi principali della sua importanza. Tuttavia, è cruciale riconoscere che quantificare la plausibilità di un’ipotesi non risolve pienamente il problema scientifico dell’inferenza. Come illustrato da Navarro (2019), usando una metafora di Box (1976):\n\nSince all models are wrong, the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.\n\nIn questa metafora, i “topi” rappresentano i dettagli del nostro modello statistico, mentre la “tigre” è la disconnessione tra i dati osservati, modellizzati con il teorema di Bayes, e la teoria del fenomeno, che è al centro del nostro interesse.\nPaul Meehl ha ulteriormente articolato questo problema distinguendo tre livelli: la teoria sostanziale (A), l’ipotesi statistica testabile (T) e le osservazioni (O). La relazione tra questi tre livelli solleva difficoltà significative:\n\nThe map from substantive theory (A) to testable statistical hypothesis (T) goes through a derivation chain involving auxiliary theories, instruments, ceteris paribus assertions, and experimental conditions. The map from hypothesis to observation is through the statistical model manufactured by the derivation chain.\n\nLa teoria statistica offre vari strumenti per inferire la veridicità di T da O, spesso utilizzando la regola di Bayes. Tuttavia, anche se possiamo concludere che T è altamente probabile dato O, non risolviamo il problema di calcolare la probabilità di A da T. Meehl sosteneva che non esiste una procedura formale capace di tradurre rigorosamente le osservazioni empiriche (O) nella teoria scientifica (A).\nIl concetto di “validità poetica” descrive questa disconnessione. La validità poetica si riferisce alla capacità di un’idea di risuonare con l’intelletto umano e con l’esperienza, anche quando non può essere rigorosamente validata scientificamente o statisticamente. Sottolinea l’importanza dell’intuizione e della comprensione qualitativa nella teoria scientifica, completando l’approccio puramente quantitativo e formale (Hardt & Recht, 2022).\nLa dicotomia tra concetti teorici ed empirici, manifestata nel processo di operazionalizzazione, chiarisce ulteriormente questa problematica (Hempel, 1970). L’operazionalizzazione dei concetti teorici in concetti empirici è un processo arbitrario e comporta un mapping uno-a-molti, che comporta diverse implicazioni:\n\nSottodeterminazione delle teorie: Nessun test di ipotesi può essere considerato un test diretto di una teoria, poiché l’operazionalizzazione introduce un elemento di arbitrarietà.\nFlessibilità teorica: La relazione uno-a-molti tra concetti teorici ed empirici consente un raffinamento progressivo delle teorie.\nAmbiguità empirica: Operazionalizzazioni diverse possono portare a risultati contraddittori rispetto alla stessa teoria.\nNecessità di formalizzazione: Le teorie psicologiche devono essere espresse in termini formali per permettere predizioni quantitative.\n\nIn conclusione, il problema della demarcazione tra teoria e osservazione in psicologia rimane un tema aperto e cruciale. La consapevolezza di queste limitazioni epistemologiche dovrebbe guidare la pratica della ricerca empirica e l’interpretazione dei suoi risultati, promuovendo un approccio più critico alla costruzione, validazione e interpretazione delle teorie psicologiche.\n\n103.2.1 Tra il Diavolo e il Mare Aperto\nNel campo della selezione dei modelli, ci troviamo spesso di fronte a teorie concorrenti, ognuna rappresentata da modelli computazionali che offrono interpretazioni diverse degli stessi dati. La questione cruciale è: come decidere quale modello sia meglio supportato dai dati? Questo è un problema centrale dell’inferenza statistica, e la cross-validation è uno dei metodi utilizzati per cercare una risposta, come abbiamo visto nel Capitolo 100.\nTuttavia, Navarro (2019) sottolinea che, sebbene la selezione dei modelli sia un passaggio importante, applicare questa procedura a problemi semplificati non è sufficiente per affrontare le complesse questioni inferenziali che gli scienziati devono affrontare. Gli scienziati sono consapevoli che tutti i modelli sono, in una certa misura, errati; non comprendiamo pienamente i fenomeni che studiamo, e ogni descrizione formale è inevitabilmente approssimativa e soggetta a errori sistematici. Pertanto, devono navigare tra il diavolo della decisione statistica e il mare aperto delle questioni scientifiche sostanziali.\nUn approccio più utile potrebbe essere quello di concentrarsi su come i pattern qualitativi emergano dai dati empirici attraverso un modello computazionale di un processo psicologico, piuttosto che limitarsi a presentare misure quantitative delle prestazioni del modello. Dato quanto poco ancora sappiamo sul comportamento e sulla cognizione umana, e considerando l’artificialità di molti studi sperimentali, è lecito chiedersi quale sia il reale valore di quantificare la capacità di un modello di prevedere ogni dettaglio dei dati. In pratica, una selezione dei modelli basata esclusivamente su misure quantitative tende a privilegiare modelli che fanno affidamento su assunzioni accessorie, senza necessariamente risolvere i problemi scientifici fondamentali.\nLa vera forza di una teoria scientifica, quindi, non risiede solo nella sua capacità di prevedere nuovi dati derivati da esperimenti passati, ma soprattutto nel suo potenziale di aprire la strada a nuove esplorazioni e scoperte.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/entropy/07_inductive_inference.html#riflessioni-conclusive",
    "href": "chapters/entropy/07_inductive_inference.html#riflessioni-conclusive",
    "title": "103  Limiti dell’inferenza induttiva",
    "section": "103.3 Riflessioni Conclusive",
    "text": "103.3 Riflessioni Conclusive\nIn questo capitolo, abbiamo esaminato le complessità e le sfide dell’inferenza statistica e della selezione dei modelli attraverso una lente bayesiana. Sebbene il teorema di Bayes e i suoi strumenti derivati, come l’Expected Log Predictive Density (ELPD), siano potenti per aggiornare e confrontare modelli, essi operano principalmente in un “Piccolo Mondo” semplificato. Questo limita la nostra capacità di trarre conclusioni definitive sul “Grande Mondo” reale che ci interessa.\nLa “validità poetica” sottolinea l’importanza di riconoscere le limitazioni intrinseche delle nostre rappresentazioni statistiche e di valorizzare l’intuizione e la comprensione qualitativa nel contesto scientifico. La distinzione tra concetti teorici e osservazioni empiriche ci ricorda che, nonostante i progressi metodologici, rimane una disconnessione fondamentale tra la teoria e le osservazioni empiriche.\nInfine, la capacità di un modello di generalizzare, piuttosto che di prevedere perfettamente i dati osservati, emerge come un criterio cruciale per la sua utilità scientifica. L’esempio del modello di Rescorla-Wagner illustra come un buon modello possa stimolare nuove esplorazioni e approfondimenti, dimostrando che il vero valore di una teoria scientifica risiede nella sua capacità di guidare l’indagine futura piuttosto che semplicemente adattarsi ai dati esistenti.\nIn sintesi, le riflessioni presentate in questo capitolo ci invitano a mantenere un equilibrio tra rigore quantitativo e intuizione qualitativa, riconoscendo i limiti delle nostre tecniche e cercando continuamente di migliorare le nostre rappresentazioni del mondo reale.\n\n\n\n\nBox, G. E. (1976). Science and statistics. Journal of the American Statistical Association, 71(356), 791–799.\n\n\nHardt, M., & Recht, B. (2022). Patterns, Predictions, and Actions: Foundations of Machine Learning. Princeton University Press.\n\n\nHempel, C. G. (1970). La formazione dei concetti e delle teorie nella scienza empirica. Feltrinelli.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28–34.",
    "crumbs": [
      "Entropia",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>Limiti dell'inferenza induttiva</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/introduction_dynamic_models.html",
    "href": "chapters/dynamic_models/introduction_dynamic_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "Prerequisiti\n\nLeggere The role of the individual in the coming era of process-based therapy (Hayes et al., 2019).\n\nUno degli sviluppi più significativi nella psicologia contemporanea è l’uso di teorie formali per formulare ipotesi sui meccanismi che sottendono i fenomeni psicologici. I modelli matematici sono strumenti essenziali per concettualizzare la cognizione umana e prevedere i comportamenti osservabili. Questi modelli cercano di fornire una formalizzazione matematica dei processi cognitivi, mappando i costrutti cognitivi latenti sui parametri del modello e descrivendo come questi producono i dati osservati.\nLa maggior parte dei modelli cognitivi tradizionali tratta i dati umani come osservazioni indipendenti e identicamente distribuite (IID). Questa assunzione implica che tali modelli spesso trascurano le variazioni temporali dei costrutti cognitivi latenti. Tuttavia, questi costrutti sono intrinsecamente dinamici, indipendentemente dalla scala temporale considerata. Negli esperimenti psicologici, le capacità cognitive sono influenzate non solo dalle richieste esterne del compito, ma anche dai processi mentali interni e dagli stati cerebrali che cambiano nel tempo. Le fluttuazioni sistematiche e non sistematiche che ne derivano possono avere diverse spiegazioni, come la fatica, la pratica, la divagazione mentale o fattori motivazionali. Come evidenziato da Schumacher et al. (2023), i meccanismi cognitivi dovrebbero essere trattati come sistemi dinamici complessi, e i modelli cognitivi dovrebbero tenere conto delle dinamiche dei loro componenti per comprendere appieno e catturare la ricca struttura dei dati empirici umani.\nLa teoria dei sistemi dinamici (Dynamic Systems Theory, DST) fornisce un quadro concettuale per comprendere i fenomeni psicologici come processi complessi, non lineari e spesso auto-organizzanti che si evolvono nel tempo. In psicologia, la DST sottolinea come il comportamento e la cognizione emergano dalle interazioni di molteplici componenti sia all’interno di un individuo sia tra l’individuo e il suo ambiente. Di seguito, presenteremo alcuni esempi di fenomeni psicologici che possono essere compresi attraverso la lente dei sistemi dinamici.\nApprendimento per rinforzo. L’apprendimento per rinforzo è un processo attraverso cui gli individui apprendono a modificare il proprio comportamento in base alle conseguenze che ne derivano. In termini di sistemi dinamici, l’apprendimento per rinforzo può essere visto come un processo adattativo in cui le decisioni di un individuo vengono continuamente aggiornate e migliorate attraverso l’interazione con l’ambiente. In questo contesto, le ricompense (o rinforzi positivi) e le punizioni (o rinforzi negativi) giocano un ruolo cruciale nel modellare il comportamento futuro, creando un ciclo di feedback che rafforza o indebolisce determinate azioni. Ad esempio, un comportamento che porta a una ricompensa tende a essere ripetuto, mentre un comportamento che porta a una punizione tende a essere evitato. Questo meccanismo di apprendimento, che può essere descritto matematicamente attraverso modelli probabilistici, permette di predire come un individuo possa modificare il proprio comportamento in situazioni diverse, sulla base delle esperienze passate e delle aspettative future. I modelli di apprendimento per rinforzo, come il modello di Rescorla-Wagner, sono stati ampiamente utilizzati in psicologia per spiegare non solo comportamenti semplici come il condizionamento classico e operante, ma anche fenomeni più complessi come la dipendenza, i disturbi d’ansia e i disturbi dell’umore. In questi casi, le aspettative disadattive e i bias cognitivi possono essere visti come il risultato di un apprendimento per rinforzo anomalo, in cui le associazioni tra stimoli e conseguenze sono distorte o esagerate. Studi recenti in psichiatria computazionale utilizzano questi modelli per sviluppare interventi terapeutici più efficaci, mirati a ristrutturare le associazioni disfunzionali e promuovere schemi di apprendimento più adattivi.\nRegolazione delle emozioni. La regolazione delle emozioni implica l’interazione dinamica di processi fisiologici, cognitivi e comportamentali. Ad esempio, il modo in cui una persona regola le proprie emozioni in risposta a un evento stressante può essere influenzato da diversi fattori, come esperienze precedenti, contesto attuale, stati fisiologici (come frequenza cardiaca o livelli ormonali) e valutazioni cognitive. Nel tempo, questi componenti possono interagire in modo non lineare, creando circuiti di retroazione. Ad esempio, una persona potrebbe inizialmente cercare di sopprimere le proprie emozioni, il che potrebbe portare a un aumento dell’eccitazione fisiologica, intensificando così l’emozione che stava cercando di regolare.\nAttaccamento e relazioni sociali. Anche gli stili di attaccamento e le relazioni sociali sono sistemi dinamici. La teoria dell’attaccamento descrive come le prime relazioni con i caregiver influenzino le dinamiche interpersonali per tutta la vita. Queste relazioni possono essere viste come sistemi in cui i comportamenti, le emozioni e le cognizioni di una persona influenzano continuamente e sono influenzati da quelli degli altri. Ad esempio, in una relazione genitore-figlio, il comportamento del bambino può influenzare le risposte del genitore, che a loro volta modellano il comportamento e gli stati emotivi futuri del bambino, creando un ciclo di retroazione che evolve nel tempo.\nSviluppo cognitivo. Lo sviluppo cognitivo, soprattutto nei bambini, viene spesso modellato come un sistema dinamico. La teoria dello sviluppo cognitivo di Jean Piaget, sebbene non esplicitamente in termini di DST, può essere reinterpretata in questo modo. Ad esempio, il processo di raggiungimento dell’equilibrio cognitivo comporta interazioni continue tra le strutture di conoscenza esistenti del bambino (schemi) e le nuove esperienze. Questo processo è dinamico perché il sistema cognitivo del bambino si adatta e si riorganizza costantemente in risposta a nuove informazioni, il che può portare a cambiamenti qualitativi nel pensiero.\nControllo motorio e coordinazione. Lo sviluppo e il controllo delle azioni motorie, come camminare o afferrare, sono esempi classici di sistemi dinamici. Il controllo motorio coinvolge il coordinamento di numerosi muscoli, circuiti di retroazione sensoriale e aggiustamenti basati sull’ambiente. L’approccio dei sistemi dinamici allo sviluppo motorio enfatizza come i comportamenti motori emergano dall’auto-organizzazione di molteplici sistemi interagenti, come componenti neurali, muscolari e percettivi. Imparare a camminare, ad esempio, non è solo un’accumulazione lineare di forza ed equilibrio, ma comporta cambiamenti non lineari nel coordinamento muscolare, nell’integrazione sensoriale e nei processi di retroazione.\nDecision making e problem solving. Il processo decisionale e la risoluzione dei problemi coinvolgono l’integrazione di molteplici fattori cognitivi ed emotivi che cambiano nel tempo. La natura dinamica di questi processi è evidente in come le decisioni iniziali possano portare a cambiamenti negli obiettivi, nel comportamento di ricerca delle informazioni e negli stati emotivi, che a loro volta influenzano le decisioni successive. Ad esempio, quando si prende una decisione in condizioni di incertezza, i livelli di fiducia di una persona, le reazioni emotive e le interpretazioni di nuove informazioni possono interagire dinamicamente, creando un modello fluttuante di comportamento decisionale.\nSalute mentale e psicopatologia. La salute mentale e la psicopatologia possono essere comprese anche da una prospettiva di sistemi dinamici. I disturbi come la depressione o l’ansia non sono visti come entità statiche, ma come schemi dinamici di cognizione, emozione e comportamento che evolvono nel tempo. Ad esempio, i sintomi depressivi possono creare un ciclo di retroazione in cui i pensieri negativi portano a una ridotta attività, che a sua volta porta a pensieri ed emozioni ancora più negativi, perpetuando il ciclo. Comprendere la psicopatologia come un sistema dinamico aiuta a sviluppare interventi che mirano a questi cicli di retroazione e promuovono schemi più adattivi.\nSviluppo del linguaggio. Lo sviluppo del linguaggio è un altro ambito in cui la teoria dei sistemi dinamici è applicabile. L’acquisizione del linguaggio nei bambini implica l’interazione di molteplici fattori, come la conoscenza fonologica, sintattica e semantica, nonché l’interazione sociale e le esperienze percettive. Lo sviluppo del linguaggio non è un’accumulazione lineare di vocabolario e regole grammaticali; piuttosto, emerge dall’interazione dinamica di questi fattori mentre i bambini interagiscono con il loro ambiente e i caregiver, portando a cambiamenti qualitativi nelle capacità linguistiche nel tempo.\nDinamiche di gruppo e influenza sociale. Il comportamento di gruppo e l’influenza sociale sono fenomeni che possono essere modellati come sistemi dinamici. Nei gruppi sociali, i comportamenti e gli atteggiamenti individuali possono influenzare gli altri, portando a cambiamenti nelle norme e nelle dinamiche di gruppo. Questi cambiamenti possono quindi influenzare di nuovo i comportamenti individuali, creando un ciclo di retroazione. Ad esempio, in un contesto di gruppo, l’emergere di un leader o la diffusione di una particolare opinione può portare a cambiamenti nel comportamento del gruppo che sono dinamici e talvolta imprevedibili.\nAutoregolazione e funzioni esecutive. L’autoregolazione e le funzioni esecutive coinvolgono la capacità di controllare l’attenzione, le emozioni e i comportamenti per raggiungere obiettivi a lungo termine. Questi processi sono dinamici perché implicano il monitoraggio continuo e l’aggiustamento delle azioni sulla base del feedback dall’ambiente. Ad esempio, rimanere concentrati su un compito implica regolare dinamicamente l’attenzione in risposta alle distrazioni, il che richiede l’integrazione di molteplici processi cognitivi come la memoria di lavoro, l’inibizione e la pianificazione.\nApprendimento e memoria. L’apprendimento e la memoria sono anche processi intrinsecamente dinamici. La codifica, l’immagazzinamento e il recupero dei ricordi coinvolgono l’interazione di molteplici sistemi neurali e cognitivi che cambiano nel tempo. Ad esempio, il processo di consolidamento della memoria, in cui i ricordi a breve termine vengono stabilizzati in ricordi a lungo termine, è dinamico e può essere influenzato da vari fattori come il sonno, lo stato emotivo e le esperienze successive.\nIn questa sezione della dispensa, forniremo un’introduzione ai modelli dinamici, con particolare attenzione ai modelli di apprendimento per rinforzo. Questi modelli sono utilizzati in psicologia per spiegare i bias cognitivi in varie patologie, tra cui la depressione, i disturbi alimentari e il disturbo ossessivo-compulsivo. Questo campo di studio all’avanguardia, noto come psichiatria computazionale, non si limita agli esempi citati ma esplora una vasta gamma di applicazioni. In particolare, introdurremo uno dei modelli più famosi in questo contesto: il modello di apprendimento associativo di Rescorla-Wagner. Questo modello descrive come gli organismi apprendano a prevedere eventi attraverso l’associazione tra stimoli, fornendo una spiegazione quantitativa di come si sviluppano e si modificano le aspettative basate sull’esperienza. In psicologia, il modello di Rescorla-Wagner è utilizzato per comprendere come gli individui apprendano dalle conseguenze delle loro azioni e come questo apprendimento possa essere influenzato da fattori cognitivi e affettivi, contribuendo così alla nostra comprensione dei meccanismi alla base di diverse condizioni psicopatologiche.\n\n\n\n\nHayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Sanford, B. T., Curtiss, J. E., & Ciarrochi, J. (2019). The role of the individual in the coming era of process-based therapy. Behaviour Research and Therapy, 117, 40–53.\n\n\nSchumacher, L., Bürkner, P.-C., Voss, A., Köthe, U., & Radev, S. T. (2023). Neural superstatistics for Bayesian estimation of dynamic cognitive models. Scientific Reports, 13(1), 13778.",
    "crumbs": [
      "Dinamiche",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/01_canoeing.html",
    "href": "chapters/dynamic_models/01_canoeing.html",
    "title": "104  Dinamiche post-errore",
    "section": "",
    "text": "104.1 Introduzione\nIn questo capitolo introdurremo i modelli dinamici utilizzando un semplice processo di Markov di primo livello. Utilizzeremo un esempio specifico per spiegare come questi modelli possano essere applicati per testare teorie psicologiche. In particolare, ci concentreremo su due diverse teorie psicologiche del controllo cognitivo che spiegano la prestazione dopo un errore. Le teorie del controllo cognitivo e della performance post-errore rappresentano un’area di ricerca importante e dibattuta nella psicologia cognitiva e nelle neuroscienze cognitive. Le principali correnti teoriche proposte — le teorie funzionali e non funzionali — offrono interpretazioni contrastanti su come gli individui rispondono agli errori in compiti cognitivi.\nLe teorie funzionali, come quella proposta da Botvinick et al. (2001), si basano sul concetto di “monitoraggio del conflitto”. Secondo questo modello, quando si verifica un errore, il sistema cognitivo rileva un conflitto tra la risposta data e quella corretta, innescando un aumento del controllo cognitivo che migliora la performance nelle prove successive. L’area cingolata anteriore (ACC) è considerata cruciale in questo processo, fungendo da “rilevatore di conflitto” e segnalando la necessità di un maggiore controllo cognitivo, mediato dalla corteccia prefrontale dorsolaterale (DLPFC). Studi successivi, come quello di Kerns et al. (2004) utilizzando la risonanza magnetica funzionale (fMRI), hanno supportato questa teoria mostrando che l’attività nell’ACC durante una prova con errore predice un aumento dell’attività nella DLPFC e un miglioramento della performance nella prova successiva.\nAl contrario, le teorie non funzionali, come quelle proposte da Notebaert et al. (2009), suggeriscono che la performance post-errore sia peggiore rispetto a quella post-corretta. Queste teorie si basano sul concetto di “orientamento attenzionale” o “disturbo” del sistema cognitivo. Secondo la teoria dell’“orientamento post-errore”, gli errori, essendo eventi infrequenti e salienti, catturano l’attenzione del soggetto, distogliendola dal compito in corso, e portano a un rallentamento e peggioramento della performance nelle prove successive.\nÈ importante notare che entrambe le teorie hanno trovato supporto empirico in diversi studi. Ad esempio, Dutilh et al. (2012) hanno trovato evidenze sia di rallentamento post-errore (coerente con le teorie non funzionali) sia di aumento dell’accuratezza post-errore (coerente con le teorie funzionali). Danielmeier & Ullsperger (2011) hanno proposto una sintesi di questi punti di vista, suggerendo che la risposta agli errori potrebbe coinvolgere più meccanismi operanti su scale temporali diverse: un rallentamento immediato dovuto a un orientamento attenzionale, seguito da un miglioramento della performance dovuto all’aumento del controllo cognitivo.\nLa maggior parte di questi studi si è basata su compiti di laboratorio altamente controllati, utilizzando paradigmi di scelta forzata a due alternative (2AFC) ripetuti molte volte. Mentre questi paradigmi offrono un alto grado di controllo sperimentale, possono mancare di validità ecologica e non riflettere accuratamente il comportamento in situazioni reali, dove gli errori hanno conseguenze significative.\nIn questo tutorial, esamineremo il comportamento post-errore e post-prova corretta in situazioni reali, analizzando la performance di atleti durante competizioni di canoa slalom a livello mondiale ed europeo. Utilizzeremo i video degli atleti che attraversano correttamente la linea tra i pali, codificati da due giudici indipendenti, per analizzare la probabilità di commettere un errore dopo un attraversamento corretto o errato di una porta.\nStudiando il comportamento in contesti reali, possiamo testare queste previsioni opposte in condizioni in cui gli errori hanno conseguenze significative per l’individuo. Questo approccio offre diversi vantaggi che sono elencati di seguito.\nStudiando il comportamento in una situazione reale di competizione, possiamo osservare come le teorie del controllo cognitivo si applicano in contesti ad alta posta in gioco. Gli atleti di alto livello sono intrinsecamente motivati a performare al meglio, il che potrebbe portare a risposte agli errori più intense e rilevanti rispetto a quelle osservate in laboratorio. Gli atleti di élite hanno una vasta esperienza nel loro sport, che può influenzare i loro meccanismi di controllo cognitivo in modi interessanti e diversi dai partecipanti tipici degli studi di laboratorio. Il canoa slalom richiede l’integrazione di abilità motorie complesse con processi decisionali rapidi, offrendo una visione più completa del controllo cognitivo rispetto ai tipici compiti di laboratorio. I risultati potrebbero avere implicazioni dirette per l’allenamento e la preparazione degli atleti, aumentando la rilevanza pratica della ricerca.\nI risultati di questo studio potrebbero fornire importanti indicazioni per le teorie del controllo cognitivo:\nIn conclusione, studiare il controllo cognitivo e la performance post-errore in un contesto sportivo di alto livello offre un’opportunità unica per testare e ampliare le teorie esistenti in un ambiente ecologicamente valido. I risultati possono non solo contribuire alla comprensione teorica del controllo cognitivo, ma anche fornire indicazioni pratiche per migliorare le prestazioni in contesti ad alta posta in gioco.\nIniziamo ad importare i dati.\ndata_file = os.path.join(project_directory, \"data\", \"canoeing_data.csv\")\ncanoeing_data = pd.read_csv(data_file)\ncanoeing_data.head()\n\n\n\n\n\n\n\n\nathlete\nboat_craft\nnation\nsex\nrank\ntime\nrun\ncity\nyear\nrunf\ngate\naccuracy\nNGATES\nacc\nn_gate\nlagged_accuracy\nsequence_id\n\n\n\n\n0\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG1\n1.0\n23\n1.0\n1\nNaN\n1.0\n\n\n1\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG2\n1.0\n23\n1.0\n2\n1.0\n1.0\n\n\n2\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG3\n1.0\n23\n1.0\n3\n1.0\n1.0\n\n\n3\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG4\n1.0\n23\n1.0\n4\n1.0\n1.0\n\n\n4\nAABOEN\nK1\nNOR\nM\n78\n108.99\n1\nK1M_worlds\n2017\n1\nG5\n1.0\n23\n1.0\n5\n1.0\n1.0\nCalcoliamo alcune statistiche descrittive.\n# Numero totale di prove\nnum_prove = len(canoeing_data)\n\n# Numero di atleti unici\nnum_atleti = canoeing_data[\"athlete\"].nunique()\n\n# Numero di competizioni uniche\nnum_competizioni = canoeing_data[\"city\"].nunique()\n\n# Anni in cui sono stati raccolti i dati\nanni_raccolti = canoeing_data[\"year\"].unique()\n\n# Stampa dei risultati\nprint(f\"Numero totale di prove: {num_prove}\")\nprint(f\"Numero di atleti: {num_atleti}\")\nprint(f\"Numero di competizioni: {num_competizioni}\")\nprint(f\"Anno in cui sono stati raccolti i dati: {anni_raccolti}\")\n\nNumero totale di prove: 66413\nNumero di atleti: 459\nNumero di competizioni: 20\nAnno in cui sono stati raccolti i dati: [2017]\nCreiamo la variabile is_error, assegnandole il valore 1 se la prova è un errore e 0 altrimenti. Convertiamo inoltre il tipo di variabile in un numero intero, come richiesto dal codice Stan.\ncanoeing_data[\"accuracy\"] = canoeing_data[\"accuracy\"].fillna(1).astype(int)\ncanoeing_data[\"is_error\"] = canoeing_data[\"accuracy\"].apply(\n    lambda x: 1 if x == 0 else 0\n)\nInseriamo i dati in un dizionario nel formato atteso da Stan.\nstan_data = {\n    \"N\": len(canoeing_data[\"accuracy\"]), \n    \"y\": canoeing_data[\"is_error\"]\n}\nCompiliamo e stampiamo il codice Stan che assume che i dati seguano una distribuzione di Poisson, considerando che le prove siano indipendenti tra loro.\nstan_file = os.path.join(\n    project_directory, 'stan', 'canoeing_poisson_model.stan')\n\npoisson_model = CmdStanModel(stan_file=stan_file)\nprint(poisson_model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of trials\n  array[N] int&lt;lower=0&gt; y; // Number of errors in each trial (could be 0 or 1)\n}\nparameters {\n  real&lt;lower=0&gt; lambda; // Rate parameter for the Poisson distribution\n}\nmodel {\n  // Weak prior on lambda\n  lambda ~ normal(0, 10);\n  \n  // Likelihood: Poisson distribution\n  y ~ poisson(lambda);\n}\ngenerated quantities {\n  vector[N] log_lik; // Log-likelihood for each observation\n  for (n in 1 : N) {\n    log_lik[n] = poisson_lpmf(y[n] | lambda);\n  }\n}\nNella sezione model, l’istruzione lambda ~ normal(0, 10); definisce un prior per il parametro lambda, che è il parametro della distribuzione di Poisson. Viene assunto un priore normale debole con media 0 e deviazione standard 10, che riflette l’ipotesi che lambda possa prendere qualsiasi valore positivo con una leggera preferenza per valori vicini a zero.\nL’istruzione y ~ poisson(lambda); definisce la likelihood, ovvero la probabilità di osservare i dati y dati i parametri del modello. In questo caso, si assume che i dati seguano una distribuzione di Poisson con parametro lambda, che rappresenta la media (e varianza) del numero di errori nelle prove. L’assunzione qui è che ogni prova sia indipendente dalle altre e che il numero di errori in ciascuna prova sia distribuito secondo una Poisson.\nNella sezione generated quantities, l’istruzione vector[N] log_lik; crea un vettore per memorizzare i valori del log-likelihood per ciascuna delle N osservazioni.\nL’istruzione for (n in 1:N) { log_lik[n] = poisson_lpmf(y[n] | lambda); }, mediante un ciclo for calcola la log-verosimiglianza per ogni singola osservazione y[n] rispetto alla distribuzione di Poisson con il parametro lambda. La funzione poisson_lpmf calcola la log-probability mass function (log-PMF) della distribuzione di Poisson per un dato valore y[n] e un parametro lambda. Il risultato è un vettore log_lik che contiene la log-verosimiglianza di ciascuna osservazione. Questo è richiesto per effettuare confronti tra modelli usando la Leave-One-Out Cross-Validation (LOO).\nEseguiamo il campionamento.\nfit_poisson = poisson_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False, \n    show_console=False\n)\nEsaminiamo le distribuzioni a posteriori.\naz.summary(fit_poisson, var_names=[\"lambda\"], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nlambda\n0.09\n0.0\n0.09\n0.09\n0.0\n0.0\n3036.8\n3682.58\n1.0\nConvertiamo l’oggetto creato da cmdstanpy nella classe InferenceData richiesta da ArviZ:\nfit_poisson_az = az.from_cmdstanpy(posterior=fit_poisson)\nEseguiamo la validazione incrociata Leave-One-Out (LOO-CV) utilizzando ArviZ:\nloo_poisson_result = az.loo(fit_poisson_az)\nprint(loo_poisson_result)\n\nComputed from 8000 posterior samples and 66413 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -20564.93   177.70\np_loo        0.92        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     66413  100.0%\n (0.5, 0.7]   (ok)           0    0.0%\n   (0.7, 1]   (bad)          0    0.0%\n   (1, Inf)   (very bad)     0    0.0%\nTutti i valori di Pareto \\(k\\) sono molto bassi, indicando che nessuna osservazione ha un’influenza eccessiva sulle stime del modello. Di conseguenza, non vi è alcuna evidenza che la stima dell’ELPD, che in questo caso è pari a -20564.93, possa essere distorta.\nOra calcoleremo l’ELPD per il modello che assume un processo di Markov di primo ordine. Questo modello considera una dipendenza temporale tra le prove, in cui la probabilità di commettere un errore dipende dal risultato della prova precedente. In particolare, il modello stabilisce che la probabilità di una risposta errata in una prova dipende dal fatto che la risposta precedente sia stata corretta o errata.\nCompiliamo e stampiamo il modello canoeing_markov_model.stan.\nstan_file = os.path.join(project_directory, \"stan\", \"canoeing_markov_model.stan\")\n\nmarkov_model = CmdStanModel(stan_file=stan_file)\nprint(markov_model.code())\n\ndata {\n  int&lt;lower=0&gt; N; // Number of trials\n  array[N] int&lt;lower=0, upper=1&gt; y; // Sequence of errors (0 = correct, 1 = error)\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p_error_given_error; // Probability of error given previous error\n  real&lt;lower=0, upper=1&gt; p_error_given_correct; // Probability of error given previous correct\n  real&lt;lower=0, upper=1&gt; p_initial_error; // Initial probability of error\n}\nmodel {\n  // Implicit weak priors on parameters\n  \n  // Likelihood for the first trial\n  y[1] ~ bernoulli(p_initial_error);\n  \n  // Likelihood for the rest of the trials\n  for (n in 2 : N) {\n    if (y[n - 1] == 1) {\n      y[n] ~ bernoulli(p_error_given_error);\n    } else {\n      y[n] ~ bernoulli(p_error_given_correct);\n    }\n  }\n}\ngenerated quantities {\n  vector[N] log_lik; // Log-likelihood for each observation\n  log_lik[1] = bernoulli_lpmf(y[1] | p_initial_error);\n  for (n in 2 : N) {\n    if (y[n - 1] == 1) {\n      log_lik[n] = bernoulli_lpmf(y[n] | p_error_given_error);\n    } else {\n      log_lik[n] = bernoulli_lpmf(y[n] | p_error_given_correct);\n    }\n  }\n}\nQuesto codice Stan modella una sequenza di prove in cui ogni prova può essere corretta (0) o errata (1). Questo modello assume una dipendenza temporale tra le prove, basata su un processo di Markov di primo ordine. Ciò significa che la probabilità di errore in una prova dipende solo dal risultato della prova precedente.\nNella sezione model, i parametri p_error_given_error, p_error_given_correct e p_initial_error hanno priors impliciti deboli poiché sono definiti con limiti tra 0 e 1. Non sono stati specificati priors espliciti, quindi Stan utilizzerà prior uniformi su questi parametri.\nIl primo elemento della sequenza y[1] rappresenta la prima prova. Qui, viene modellata la probabilità che questa prova sia un errore utilizzando una distribuzione di Bernoulli con probabilità p_initial_error.\nPer tutte le prove successive (dal secondo elemento in poi), il modello assume che la probabilità di errore (y[n] = 1) dipenda dal risultato della prova precedente:\nQuesto riflette l’idea che l’esito di una prova sia condizionato dallo stato immediatamente precedente, tipico di un processo di Markov di primo ordine.\nLa sezione generated quantities viene utilizzata per calcolare quantità derivate dai parametri stimati, in questo caso, il log-likelihood per ogni osservazione.\nI valori del log-likelihood sono memorizzati nel vettore log_lik che verrà usato per valutare il modello attraverso la validazione incrociata LOO.\nIn sintesi, il modello rappresenta un processo di Markov di primo ordine in cui l’esito di una prova dipende dall’esito della prova precedente. La sezione generated quantities calcola il log-likelihood per ciascuna osservazione, consentendo di valutare e confrontare il modello utilizzando la tecnica bayesiana della validazione incrociata LOO.\nEseguiamo il campionamento.\nfit_markov = markov_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\nEsaminiamo le stime a posteriori dei parametri del modello.\naz.summary(\n    fit_markov, var_names=[\"p_error_given_error\", \"p_error_given_correct\"], round_to=2\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\np_error_given_error\n0.18\n0.0\n0.17\n0.19\n0.0\n0.0\n7522.48\n5864.69\n1.0\n\n\np_error_given_correct\n0.08\n0.0\n0.08\n0.08\n0.0\n0.0\n7353.13\n5562.07\n1.0\nCalcoliamo l’ELPD con il metodo LOO-CV.\n# Convert CmdStanPy fit to ArviZ InferenceData\nfit_markov_az = az.from_cmdstanpy(posterior=fit_markov)\n\n# Perform LOO-CV using ArviZ\nloo_markov_result = az.loo(fit_markov_az)\nprint(loo_markov_result)\n\nComputed from 8000 posterior samples and 66413 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -20035.74   169.65\np_loo        2.33        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     66413  100.0%\n (0.5, 0.7]   (ok)           0    0.0%\n   (0.7, 1]   (bad)          0    0.0%\n   (1, Inf)   (very bad)     0    0.0%\nInfine, calcoliamo la differenza tra le stime dell’ELPD (elpd_diff) dei due modelli. L’incertezza associata a questa differenza è espressa dal suo errore standard (dse). Se il rapporto tra elpd_diff e dse è pari o superiore a 2, possiamo concludere che esiste una differenza credibile tra i due modelli.\ndf_comp_loo = az.compare({\n    \"poisson_model\": loo_poisson_result, \n    \"markov_model\": loo_markov_result\n})\ndf_comp_loo\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmarkov_model\n0\n-20035.737644\n2.332125\n0.000000\n1.0\n169.648636\n0.000000\nFalse\nlog\n\n\npoisson_model\n1\n-20564.931364\n0.924353\n529.193719\n0.0\n177.702690\n25.801837\nFalse\nlog\n_ = az.plot_compare(df_comp_loo, insample_dev=False)\nLa differenza tra le stime dell’ELPD dei due modelli indica chiaramente che il modello che assume una dipendenza temporale tra le prove, qui modellizzata nei termini di un semplice processo di Markov di primo grado, è più adatto per i dati presenti che un modello di Poisson che assume che le prove siano tra loro indipendenti.\nUna volta stabilito che le prove mostrano una dipendenza temporale, si tratta di capire se la prestazione post-errore sia migliore o peggiore rispetto alla prestazione post-corretta.\nIl modello di Markov di primo ordine assume che la probabilità di commettere un errore in una prova dipenda dall’esito della prova precedente. Qui abbiamo due parametri principali:\nDai dati ottenuti:\nQuesta differenza tra p_error_given_error e p_error_given_correct suggerisce che gli atleti hanno una probabilità maggiore di commettere un errore se hanno appena commesso un errore rispetto a quando hanno eseguito correttamente la prova precedente. Questo è un chiaro segnale che esiste una dipendenza temporale tra le prove, che il modello di Markov cattura meglio rispetto al modello di Poisson.\nDal riepilogo dei dati si ottiene:\n# Step 1: Ordinare per atleta, run, e n_gate per garantire un corretto lagging\ncanoeing_data = canoeing_data.sort_values(by=[\"athlete\", \"run\", \"n_gate\"])\n\n# Creare la colonna lagged_accuracy\ncanoeing_data[\"lagged_accuracy\"] = canoeing_data.groupby([\"athlete\", \"run\"])[\n    \"accuracy\"\n    ].shift(1)\n\n# Step 2: Riassumere la proporzione di prove corrette dopo una risposta corretta o un errore\n# Rimuovere le righe dove lagged_accuracy è NaN (ad esempio, la prima prova di ogni run)\ndf_filtered = canoeing_data.dropna(subset=[\"lagged_accuracy\"])\n\n# Raggruppare per lagged_accuracy e calcolare le proporzioni\nproportions = (\n    df_filtered.groupby(\"lagged_accuracy\")\n    .agg(correct_trials=(\"accuracy\", \"sum\"), total_trials=(\"accuracy\", \"size\"))\n    .reset_index()\n)\n\nproportions[\"proportion_correct\"] = (\n    proportions[\"correct_trials\"] / proportions[\"total_trials\"]\n).round(3)\n\n# Stampare il risultato\nprint(proportions)\n\n   lagged_accuracy  correct_trials  total_trials  proportion_correct\n0              0.0            4828          5898               0.819\n1              1.0           54368         59338               0.916\nQuesta differenza indica chiaramente che la prestazione dell’atleta peggiora dopo aver commesso un errore: è infatti più probabile che l’atleta commetta un altro errore subito dopo.\nIn conclusione, l’accuratezza dell’atleta tende a diminuire dopo un errore. Questo è meglio rappresentato dal modello di Markov, che evidenzia una probabilità maggiore di commettere un errore dopo un errore precedente rispetto a dopo una prova corretta. Al contrario, il modello di Poisson, che presuppone l’indipendenza tra le prove, non riesce a catturare adeguatamente questa dinamica, risultando quindi meno adatto per descrivere i tuoi dati.\nInoltre, l’intervallo di credibilità al 94% dei parametri p_error_given_error e p_error_given_correct non si sovrappone, il che supporta l’idea che queste due condizioni siano credibilmente diverse.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Dinamiche post-errore</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/01_canoeing.html#introduzione",
    "href": "chapters/dynamic_models/01_canoeing.html#introduzione",
    "title": "104  Dinamiche post-errore",
    "section": "",
    "text": "Se si osserva un miglioramento della performance post-errore, questo supporterebbe le teorie funzionali, suggerendo che i meccanismi di controllo cognitivo proposti da Botvinick et al. (2001) si applicano anche in contesti reali ad alta posta in gioco.\nSe si rileva un peggioramento della performance post-errore, ciò potrebbe supportare le teorie non funzionali e indicare che l’orientamento attenzionale verso gli errori è particolarmente pronunciato in situazioni di competizione reale.\nPotrebbe emergere un pattern più complesso, come un peggioramento iniziale seguito da un miglioramento, che supporterebbe modelli integrativi come quello proposto da Danielmeier & Ullsperger (2011).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe la prova precedente (y[n-1]) è stata un errore (1), allora la probabilità di errore nella prova attuale è p_error_given_error.\nSe la prova precedente è stata corretta (0), allora la probabilità di errore nella prova attuale è p_error_given_correct.\n\n\n\n\nPrimo Log-Likelihood: Per la prima prova (y[1]), il log-likelihood è calcolato usando p_initial_error, poiché questa prova non ha una dipendenza da prove precedenti.\nLog-Likelihood delle Prove Successive: Per tutte le prove successive, il log-likelihood è calcolato in base all’esito della prova precedente, utilizzando p_error_given_error o p_error_given_correct a seconda che la prova precedente sia stata un errore o un successo. Il calcolo del log-likelihood utilizza la funzione bernoulli_lpmf, che restituisce il logaritmo della probabilità della funzione di massa della distribuzione Bernoulli per i dati osservati.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np_error_given_error: La probabilità di commettere un errore dato che l’ultima prova è stata un errore.\np_error_given_correct: La probabilità di commettere un errore dato che l’ultima prova è stata corretta.\n\n\n\np_error_given_error = 0.18: Significa che, se un atleta ha commesso un errore nella prova precedente, la probabilità di commettere un altro errore nella prova successiva è del 18%.\np_error_given_correct = 0.08: Significa che, se un atleta ha eseguito correttamente la prova precedente, la probabilità di commettere un errore nella prova successiva è dell’8%.\n\n\n\n\nProporzione di risposte corrette dopo un errore: 0.819.\nProporzione di risposte corrette dopo una prova corretta: 0.916.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Dinamiche post-errore</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/01_canoeing.html#riflessioni-conclusive",
    "href": "chapters/dynamic_models/01_canoeing.html#riflessioni-conclusive",
    "title": "104  Dinamiche post-errore",
    "section": "104.2 Riflessioni Conclusive",
    "text": "104.2 Riflessioni Conclusive\nQuesto esercizio ci ha permesso di introdurre i modelli dinamici attraverso l’utilizzo di un processo di Markov di primo ordine per confrontare due teorie psicologiche che descrivono la prestazione post-errore: le teorie funzionali (Botvinick et al. (2001)), che prevedono un miglioramento della prestazione dopo un errore, e le teorie non funzionali (Notebaert et al. (2009)), che suggeriscono un peggioramento della prestazione in seguito a un errore.\nAbbiamo utilizzato dati relativi alle prestazioni di atleti in eventi sportivi ufficiali per mettere alla prova queste teorie. Questi dati sono particolarmente interessanti rispetto a quelli raccolti in ambienti di laboratorio, poiché riflettono il comportamento reale degli individui in situazioni in cui gli errori hanno conseguenze significative.\nIn questo tutorial, abbiamo inizialmente considerato l’ipotesi che non vi fosse dipendenza temporale nelle prestazioni degli atleti, assumendo che gli errori fossero indipendenti nella sequenza delle prove. Questa ipotesi, che contrasta con entrambe le teorie funzionali e non funzionali, è stata implementata nel modello di Poisson, il quale presuppone l’indipendenza tra le prove.\nConfrontando i modelli tramite la differenza nell’ELPD (Expected Log Predictive Density), abbiamo dimostrato che il modello semplice di Poisson può essere respinto e che i dati sono descritti in modo molto più accurato da un modello che assume una dipendenza temporale nelle prestazioni degli atleti. Il modello che incorpora questa ipotesi è un processo di Markov di primo ordine, che tiene conto dell’influenza della prova precedente sulla performance successiva.\nPer confrontare le teorie funzionali e non funzionali post-errore, è stato fondamentale determinare la direzione della differenza nella prestazione post-errore: questa differenza indica un miglioramento o un peggioramento delle prestazioni?\nLe statistiche descrittive hanno mostrato un peggioramento della prestazione post-errore. L’inferenza bayesiana, calcolando l’intervallo di credibilità al 94% per i parametri p_error_given_error e p_error_given_correct, ha confermato che questa differenza è credibile.\nPossiamo quindi concludere che i dati relativi agli atleti nelle competizioni di alto livello di canoa slalom supportano le teorie non funzionali post-errore.\nÈ importante, tuttavia, considerare alcune limitazioni di questa analisi.\nInnanzitutto, il modello di Markov di primo ordine che abbiamo utilizzato non tiene conto del clustering delle prove, cioè del fatto che i dati provengono da atleti diversi. Ogni atleta ha caratteristiche uniche, e le prove all’interno della sequenza di un singolo atleta sono più simili tra loro rispetto a quelle di atleti diversi. Per semplicità, questo aspetto dei dati non è stato modellizzato. Un’analisi più approfondita richiederebbe l’uso di un modello gerarchico bayesiano, che, sebbene non necessario per gli scopi di questo tutorial, sarebbe più appropriato per un’analisi completa.\nInoltre, i dati presentano una questione più complessa. Abbiamo utilizzato questi dati per testare modelli psicologici che assumono che l’elaborazione delle informazioni e il comportamento restino coerenti dopo una prova corretta o un errore nella prova precedente. Tuttavia, questa assunzione potrebbe non essere valida nel contesto del canoa slalom. Se un atleta commette un errore, ciò potrebbe influenzare la posizione della canoa, rendendo più difficile o più facile superare la porta successiva. Questo potrebbe aumentare la probabilità di commettere un ulteriore errore o, in alcuni casi, ridurla. Per esplorare ulteriormente questo aspetto, sarebbe necessario analizzare i video delle prove, ma tale indagine va oltre gli obiettivi di questo tutorial.\nInfine, non abbiamo analizzato schemi più complessi, come un peggioramento iniziale seguito da un successivo miglioramento, che potrebbero sostenere modelli integrativi come quello proposto da Danielmeier & Ullsperger (2011).\nIn conclusione, nonostante le potenziali limitazioni di questo studio, i dati raccolti offrono un supporto maggiore alle teorie non funzionali rispetto a quelle funzionali della performance post-errore, specialmente quando si considerano dati reali sulle prestazioni di atleti di alto livello. Inoltre, indicano chiaramente che, almeno nel contesto esaminato, esiste una marcata dipendenza temporale tra le prove di una competizione atletica di alto livello.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Dinamiche post-errore</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/01_canoeing.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/01_canoeing.html#informazioni-sullambiente-di-sviluppo",
    "title": "104  Dinamiche post-errore",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sat Jul 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\npingouin  : 0.5.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBotvinick, M. M., Braver, T. S., Barch, D. M., Carter, C. S., & Cohen, J. D. (2001). Conflict monitoring and cognitive control. Psychological review, 108(3), 624–652.\n\n\nDanielmeier, C., & Ullsperger, M. (2011). Post-error adjustments. Frontiers in psychology, 2, 233.\n\n\nNotebaert, W., Houtman, F., Van Opstal, F., Gevers, W., Fias, W., & Verguts, T. (2009). Post-error slowing: an orienting account. Cognition, 111(2), 275–279.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Dinamiche post-errore</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html",
    "href": "chapters/dynamic_models/02_change_across_time.html",
    "title": "105  Modellare il cambiamento nel tempo",
    "section": "",
    "text": "105.1 Introduzione\nL’obiettivo di questo capitolo è introdurre i modelli che descrivono i processi dinamici, seguendo un tutorial proposto da Knight et al. (2023). In molti ambiti della psicologia, come la psicologia sociale, dello sviluppo, clinica e organizzativa, si studiano fenomeni che cambiano nel tempo e sono quindi dinamici. Tuttavia, questi processi dinamici sono spesso difficili da osservare o misurare direttamente, poiché possono essere il risultato di diverse combinazioni di processi che si manifestano in modi variabili a seconda del contesto e delle persone coinvolte. Inoltre, i processi dinamici possono operare su diversi livelli e svilupparsi su scale temporali differenti.\nPer verificare una teoria dinamica, un ricercatore deve adottare un disegno di ricerca longitudinale che consenta di osservare i processi psicologici nel loro sviluppo nel tempo, e utilizzare un modello statistico che traduca in termini operativi i processi descritti dalla teoria. Un approccio particolarmente utile per modellare i processi dinamici è l’approccio bayesiano, che offre maggiore flessibilità rispetto ad altre alternative, come i modelli di curve di crescita latenti e i modelli di punteggi dei cambiamento latenti, nei quali la complessità aumenta drasticamente con l’aumentare del numero di variabili e dei punti temporali.\nLa flessibilità di questo approccio consente di costruire modelli statistici che si allineano più direttamente alla teoria psicologica. Ciò permette una connessione più stretta tra teoria e modello, e consente una verifica più chiara della teoria stessa.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#comprendere-i-processi-dinamici",
    "href": "chapters/dynamic_models/02_change_across_time.html#comprendere-i-processi-dinamici",
    "title": "105  Modellare il cambiamento nel tempo",
    "section": "105.2 Comprendere i Processi Dinamici",
    "text": "105.2 Comprendere i Processi Dinamici\nI processi dinamici sono solitamente rappresentati come sistemi a ciclo chiuso, in cui gli output del sistema influenzano gli input, determinando così cambiamenti continui nei componenti del sistema nel tempo. Una caratteristica fondamentale di un processo dinamico è che almeno una delle variabili mantiene una “memoria” del suo valore nei momenti temporali precedenti. Questo tipo di variabile, spesso chiamata “variabile dinamica”, cambia il suo valore nel tempo in modo coerente con il suo stato passato. Può aumentare o diminuire, ma non può assumere valori che sarebbero incompatibili o illogici rispetto al suo stato precedente.\nI modelli bayesiani che descrivono i processi dinamici sono spesso utilizzati in psicologia cognitiva. Questi includono modelli di apprendimento per rinforzo, che catturano come le persone interagiscono con l’ambiente per massimizzare la ricompensa cumulativa, e modelli di diffusione, che rappresentano come le persone prendono decisioni rapide.\nNel loro tutorial, Knight et al. (2023) utilizzano un esempio di regolazione degli obiettivi per illustrare un processo dinamico rilevante in molte aree della psicologia. La regolazione degli obiettivi è un meccanismo attraverso il quale le persone valutano e modificano i loro obiettivi nel tempo, basandosi sulle loro performance passate.\nPer spiegare il processo dinamico di regolazione degli obiettivi, vengono utilizzati dati reali provenienti da uno studio di simulazione del controllo del traffico aereo condotto da Gee et al. (2018). In questo studio, 60 partecipanti hanno completato dieci prove di 10 minuti ciascuna, durante le quali dovevano classificare coppie di aeromobili come in conflitto o non in conflitto in base alla loro distanza minima di separazione. Prima di ogni prova, i partecipanti fissavano un obiettivo riguardo al numero di coppie di aeromobili che intendevano classificare correttamente o erroneamente. L’obiettivo dello studio era esaminare come le persone rivedessero i loro obiettivi nel tempo sulla base delle loro performance.\nIl modello utilizzato per descrivere questo processo predice che una persona modifica il proprio obiettivo in funzione della discrepanza tra l’obiettivo precedente e la performance ottenuta. Questo modello incorpora una componente auto-regressiva che conserva una “memoria” del passaggio temporale precedente. Formalmente, il processo è descritto dall’equazione:\n\\[\nG_t = G_{t-1} + \\alpha(P_{t-1} - G_{t-1}) + \\beta,\n\\]\ndove \\(G\\) rappresenta il livello dell’obiettivo e \\(P\\) la performance effettiva. Il parametro \\(\\alpha\\) rappresenta il tasso di apprendimento: valori più alti di \\(\\alpha\\) indicano che la revisione dell’obiettivo è più sensibile alla discrepanza tra l’obiettivo precedente e la performance precedente. Il parametro \\(\\beta\\) rappresenta un aggiustamento dell’obiettivo che avviene indipendentemente dalla discrepanza tra obiettivo e performance.\nPer rappresentare adeguatamente questo modello, è necessario considerare il livello dell’obiettivo come una variabile dinamica che conserva una “memoria” del suo stato precedente. Questo tipo di processo dinamico è complesso da rappresentare utilizzando approcci statistici tradizionali, ma è facilmente implementabile all’interno del framework bayesiano.\nQuesta struttura dinamica è concettualmente simile a un modello di Markov di primo ordine, come quello descritto in precedenza. Nel modello di Markov discusso nel Capitolo 104, la probabilità di commettere un errore alla prova attuale (\\(y[n]\\)) dipende esclusivamente dallo stato immediatamente precedente (\\(y[n-1]\\)), caratterizzandolo come un processo senza memoria a lungo termine ma con dipendenza temporale di primo ordine.\nEntrambi i modelli condividono l’idea di dipendenza dal passato immediato: nel modello dinamico utilizzato da Gee et al. (2018), l’obiettivo viene aggiornato in base alla discrepanza tra l’obiettivo e la performance passata, mentre nel modello di Markov del Capitolo 104 la probabilità di errore successivo è determinata dallo stato dell’errore precedente. In entrambi i casi, le transizioni sono influenzate solo dallo stato o dalla condizione immediatamente precedente, una caratteristica fondamentale dei processi di Markov di primo ordine. Tuttavia, mentre il modello del Capitolo 104 considera esclusivamente uno stato binario (errore o non errore), il modello dinamico attuale prende in considerazione una variabile continua e la discrepanza tra obiettivo e performance, permettendo una rappresentazione più dettagliata dei cambiamenti nel comportamento.\nIniziamo ad importare i dati dello studio di Gee et al. (2018).\n\ndata_file = os.path.join(project_directory, \"data\", \"goal_data.csv\")\ngoal_data = pd.read_csv(data_file)\ngoal_data.head()\n\n\n\n\n\n\n\n\nsubject\ncondition\ngoal\nperformance\ntrial\n\n\n\n\n0\n1\napproach\n2\n0\n1\n\n\n1\n1\napproach\n2\n2\n2\n\n\n2\n1\napproach\n2\n2\n3\n\n\n3\n1\napproach\n4\n4\n4\n\n\n4\n1\napproach\n4\n2\n5\n\n\n\n\n\n\n\nCalcoliamo alcune statistiche descrittive.\n\n# Numero totale di prove\nnum_trials = len(goal_data)\n\n# Numero di atleti unici\nnum_subj = goal_data[\"subject\"].nunique()\n\n# Stampa dei risultati\nprint(f\"Numero totale di prove: {num_trials}\")\nprint(f\"Numero di partecipanti: {num_subj}\")\n\nNumero totale di prove: 600\nNumero di partecipanti: 60\n\n\nOrganizziamo i dati in un dizionario nel formato richiesto da Stan per i modelli presentati da Knight et al. (2023), che discuteremo qui.\n\nstan_data = {\n    \"subject\": goal_data[\"subject\"].tolist(),\n    \"condition\": pd.factorize(goal_data[\"condition\"])[0]\n    + 1,  # 1 = approach, 2 = avoidance\n    \"observed_goal\": goal_data[\"goal\"].tolist(),\n    \"trial\": goal_data[\"trial\"].tolist(),\n    \"performance\": goal_data[\"performance\"].tolist(),\n    \"Nsubj\": goal_data[\"subject\"].nunique(),\n    \"Ntotal\": len(goal_data[\"subject\"]),\n}\n\nAnalizziamo ogni elemento del dizionario. Questo passaggio ci sarà utile più avanti per comprendere il funzionamento del codice Stan.\n\n# Iterate through each element in the dictionary and print the length and first 15 elements\nfor key, value in stan_data.items():\n    if (\n        isinstance(value, list)\n        or isinstance(value, pd.Series)\n        or isinstance(value, np.ndarray)\n    ):\n        print(f\"{key}: Length = {len(value)}\")\n        print(f\"First 15 elements of {key}: {value[:15]}\")\n    else:\n        print(f\"{key}: {value}\")\n\nsubject: Length = 600\nFirst 15 elements of subject: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\ncondition: Length = 600\nFirst 15 elements of condition: [1 1 1 1 1 1 1 1 1 1 2 2 2 2 2]\nobserved_goal: Length = 600\nFirst 15 elements of observed_goal: [2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 6, 6, 6]\ntrial: Length = 600\nFirst 15 elements of trial: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5]\nperformance: Length = 600\nFirst 15 elements of performance: [0, 2, 2, 4, 2, 0, 4, 2, 4, 4, 3, 5, 7, 5, 6]\nNsubj: 60\nNtotal: 600",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#modello-a-livello-di-campione",
    "href": "chapters/dynamic_models/02_change_across_time.html#modello-a-livello-di-campione",
    "title": "105  Modellare il cambiamento nel tempo",
    "section": "105.3 Modello a livello di campione",
    "text": "105.3 Modello a livello di campione\nIl primo modello presentato da Knight et al. (2023) è il 1_sample_level_model.stan. Questo modello include due parametri teoricamente rilevanti: α e β. Per implementare il modello di revisione degli obiettivi come modello statistico, si aggiunge un terzo parametro, σ, che rappresenta la deviazione standard residua del livello degli obiettivi.\nNel modello proposto, questi parametri vengono stimati a livello di campione, ovvero il comportamento dell’intero campione viene descritto utilizzando un unico set di parametri. Il modello assume quindi che il processo di revisione degli obiettivi sia identico per tutti i partecipanti.\nProcediamo ora con la compilazione e la stampa del codice Stan di questo modello.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"change_models\", \"1_sample_level_model.stan\"\n)\n\nsample_level_model = CmdStanModel(stan_file=stan_file)\nprint(sample_level_model.code())\n\ndata {\n  int&lt;lower=1&gt; Ntotal; //Total number of trials in the dataset (600)\n  array[Ntotal] real&lt;lower=1&gt; trial; //Trial number\n  array[Ntotal] real observed_goal; //Goal level for each trial\n  array[Ntotal] real performance; //Performance for each trial\n}\nparameters {\n  real alpha; //initialize single alpha parameter for entire sample\n  real beta; //initialize single beta parameter for entire sample\n  real&lt;lower=0&gt; sigma; //initialize single sigma parameter for entire sample and set lower bound at 0.\n}\nmodel {\n  real predicted_goal; //initialize predicted goal level object to store predictions\n  \n  //PRIORS\n  alpha ~ normal(0, 1); //set weakly informative prior on alpha\n  beta ~ normal(0, 1); //set weakly informative prior on beta\n  sigma ~ normal(0, 1); //set weakly informative prior on sigma\n  \n  //LIKELIHOOD\n  //loop through all trials in the dataset performing bracketed operations on each one\n  for (i in 1 : Ntotal) {\n    //if the trial being considered is the first trial for that subject...\n    if (trial[i] == 1) {\n      //set predicted_goal to be equal to observed_goal for that trial\n      predicted_goal = observed_goal[i];\n    }\n    //if the trial being considered is not the first trial for that subject...\n    if (trial[i] &gt; 1) {\n      //increment predicted_goal according to the theory of change\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n    }\n    //evaluate likelihood of observed goal given a normal distribution with mean = predicted_goal and sd = sigma\n    observed_goal[i] ~ normal(predicted_goal, sigma);\n  }\n}\n//NOTE: The generated quantities block (below) is NOT needed for the model to run. However, it can be useful for generating posterior predictives from the model. The posterior predictives from this model were presented in the \"model evalutation\" section of the paper.\n\ngenerated quantities {\n  real predicted_goal; // Initialize object to store goal level predicted by the model\n  array[Ntotal] real&lt;lower=1&gt; sampled_goal; // Initialize object to store set of goal level samples (i.e., the posterior predictives)\n  array[Ntotal] real log_lik; // Initialize array to store the log likelihood for each data point\n  \n  // Loop through all trials in the dataset generating predictions in the same way as above\n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal = observed_goal[i];\n    }\n    if (trial[i] &gt; 1) {\n      predicted_goal += alpha * (performance[i - 1] - predicted_goal) + beta;\n    }\n    \n    // Sample a goal level from the distribution of the predicted goal\n    sampled_goal[i] = normal_rng(predicted_goal, sigma);\n    \n    // Calculate the log likelihood for the observed goal\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal, sigma);\n  }\n}\n\n\n\nNel modello 1_sample_level_model.stan, i dati sono rappresentati da una serie di variabili, tra cui il numero totale di prove (Ntotal), il numero di ciascuna prova (trial), il livello di obiettivo osservato in ciascuna prova (observed_goal), e la performance in ciascuna prova (performance).\nI parametri principali del modello sono alpha, beta e sigma:\n\nalpha e beta: sono parametri a cui vengono assegnate prior distribuzioni normali con media 0 e deviazione standard 1. Questi sono noti come “priori debolmente informativi” perché non esprimono una forte convinzione a priori su una particolare regione dello spazio dei parametri.\nsigma: è un altro parametro che rappresenta la deviazione standard residua del livello degli obiettivi. Anche sigma ha un priore distribuito normalmente, ma con un vincolo aggiuntivo: deve essere positivo (da qui real&lt;lower=0&gt; sigma). Questo significa che l’algoritmo campionerà solo valori positivi da questa distribuzione.\n\nIl “modello” in questo contesto si riferisce alla sequenza di operazioni necessarie per determinare la verosimiglianza dei dati dati i valori campionati dei parametri. Il modello è costruito utilizzando un ciclo for che esegue operazioni per ogni punto dati.\n\nCiclo for: La linea for (i in 1 : Ntotal) inizializza un ciclo che itera attraverso tutti i punti dati, da 1 fino a Ntotal. Durante ogni iterazione, la variabile di ciclo i assume il valore dell’indice corrente.\n\nPrima prova: Se i rappresenta il primo trial per un soggetto (trial[i] == 1), il livello di obiettivo previsto (predicted_goal) è impostato uguale all’obiettivo osservato (observed_goal[i]). Questo è perché non ci sono prove precedenti per determinare un obiettivo previsto basato sulla performance passata. Questo comportamento è definito alle linee 25-27 del modello.\nProve successive: Per tutte le prove successive alla prima (trial[i] &gt; 1), il livello di obiettivo previsto viene aggiornato secondo una teoria del cambiamento: predicted_goal viene incrementato in base alla differenza tra la performance della prova precedente e il livello di obiettivo previsto attuale, aggiungendo anche il parametro beta specifico per l’individuo. Questo è implementato alle linee 28-30. L’operatore += aggiorna il valore corrente di predicted_goal aggiungendo il risultato del calcolo.\n\nVerosimiglianza: Dopo aver calcolato predicted_goal, il modello confronta questo valore con observed_goal. La linea 31 utilizza l’operatore ~ per specificare che observed_goal è trattato come una variabile dipendente. Qui, si assume che observed_goal[i] provenga da una distribuzione normale con una media uguale a predicted_goal e una deviazione standard uguale a sigma. L’algoritmo quindi valuta la verosimiglianza dell’obiettivo osservato dato i valori attuali dei parametri e aggiorna di conseguenza la distribuzione a posteriori.\n\nIn altre parole, il modello effettua una regressione dell’obiettivo osservato sull’obiettivo previsto, fissando l’intercetta a 0 e la pendenza a 1, con sigma che rappresenta la deviazione standard residua dell’obiettivo osservato. Questo permette al modello di adattarsi dinamicamente ai dati e di descrivere come gli obiettivi si modificano nel tempo in funzione delle performance passate.\nEseguiamo il campionamento.\n\nfit_sample = sample_level_model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nConvertiamo l’oggetto fit_sample in un formato compatibile con ArviZ.\n\nfit_sample_az = az.from_cmdstanpy(posterior=fit_sample)\n\nEsaminiamo le distribuzioni a posteriori dei paraemtri.\n\naz.summary(fit_sample_az, var_names=[\"alpha\", \"beta\", \"sigma\"], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.51\n0.03\n0.45\n0.57\n0.0\n0.0\n6395.60\n5448.32\n1.0\n\n\nbeta\n0.17\n0.03\n0.11\n0.23\n0.0\n0.0\n6646.13\n5931.03\n1.0\n\n\nsigma\n1.29\n0.04\n1.22\n1.36\n0.0\n0.0\n6400.46\n5046.39\n1.0\n\n\n\n\n\n\n\nI risultati ottenuti per il modello a livello di campione mostrano i valori stimati per i parametri alpha, beta e sigma:\n\nAlpha: Il valore più probabile per alpha si trova nel range tra 0.45 e 0.57, con una media stimata di 0.51. Questo intervallo suggerisce che i tassi di apprendimento si trovano principalmente in questa gamma, indicando che le persone tendono ad aggiornare il loro obiettivo basandosi sulla differenza tra la performance passata e l’obiettivo previsto in modo moderato.\nBeta: I valori più probabili per beta sono compresi tra 0.11 e 0.23, con una media di 0.17. Questo risultato suggerisce che, indipendentemente dalla discrepanza tra l’obiettivo precedente e la performance precedente, le persone tendono ad aumentare il loro obiettivo di una piccola quantità aggiuntiva.\nSigma: La deviazione standard residua sigma è stimata con una media di 1.29, con un intervallo credibile del 94% che va da 1.22 a 1.36. Questo parametro rappresenta la variabilità residua nei livelli degli obiettivi osservati che non è spiegata dal modello.\n\nNel modello attuale, i parametri alpha e beta rappresentano i valori medi dei parametri per tutti i partecipanti del campione. Questo implica che il modello considera che il processo di revisione degli obiettivi avvenga nello stesso modo per ogni partecipante, utilizzando un unico set di parametri per descrivere il comportamento dell’intero campione. Tuttavia, questo modello non ci fornisce informazioni su come questi parametri possano variare tra i singoli individui.\nPer esaminare le differenze a livello individuale, sarebbe necessario un modello a livello di persona, dove vengono stimati parametri unici per ogni partecipante. Un tale modello permetterebbe di considerare le variazioni individuali, assumendo che il processo di revisione degli obiettivi possa funzionare in modo diverso per ciascuna persona.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#modello-a-livello-di-persona",
    "href": "chapters/dynamic_models/02_change_across_time.html#modello-a-livello-di-persona",
    "title": "105  Modellare il cambiamento nel tempo",
    "section": "105.4 Modello a livello di persona",
    "text": "105.4 Modello a livello di persona\nUn modello a livello di persona è fornito nel codice 2_person_level_model.stan. Tale modello può essere facilmente implementato apportando alcune modifiche al modello precedente:\n\nNuove variabili nel blocco dati: Sono necessarie due nuove variabili: Nsubj, che rappresenta il numero totale di partecipanti (ad esempio, Nsubj = 60), e subject, una colonna di numeri interi che rappresentano il numero del partecipante.\nParametri come array: Nel blocco dei parametri, alpha e beta devono essere dichiarati come array di dimensione Nsubj anziché come valori scalari. Questo implica che ci sarà un parametro alpha e un parametro beta unici stimati per ogni partecipante, permettendo di modellare la variabilità individuale.\nModifiche nel blocco del modello: Nel blocco del modello, i parametri alpha e beta devono essere indicizzati con subject[i] per far sì che il punteggio previsto sia calcolato in base ai parametri associati al partecipante i-esimo, in base ai dati situati nella riga i-esima del dataset.\n\nQueste modifiche permettono di passare da un modello che descrive il comportamento medio del campione a uno che può catturare le differenze individuali, fornendo un’analisi più dettagliata e precisa delle dinamiche di revisione degli obiettivi.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"change_models\", \"2_person_level_model.stan\"\n)\n\nperson_level_model = CmdStanModel(stan_file=stan_file)\nprint(person_level_model.code())\n\ndata {\n  int&lt;lower=0&gt; Ntotal; // Total number of trials in the dataset (600)\n  array[Ntotal] int&lt;lower=1&gt; trial; // Trial number\n  array[Ntotal] real observed_goal; // Goal level for each trial\n  array[Ntotal] real performance; // Performance for each trial\n  int&lt;lower=1&gt; Nsubj; // Number of subjects\n  array[Ntotal] int&lt;lower=1, upper=Nsubj&gt; subject; // Subject number\n}\nparameters {\n  vector[Nsubj] alpha; // Unique alpha parameter for each subject\n  vector[Nsubj] beta; // Unique beta parameter for each subject\n  real&lt;lower=0&gt; sigma; // Single sigma parameter for entire sample\n}\nmodel {\n  vector[Ntotal] predicted_goal; // Vector to store predictions\n  \n  // Priors\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n  \n  // Likelihood\n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      predicted_goal[i] = predicted_goal[i - 1]\n                          + alpha[subject[i]]\n                            * (performance[i - 1] - predicted_goal[i - 1])\n                          + beta[subject[i]];\n    }\n  }\n  \n  observed_goal ~ normal(predicted_goal, sigma);\n}\ngenerated quantities {\n  vector[Ntotal] predicted_goal;\n  array[Ntotal] real sampled_goal;\n  array[Ntotal] real log_lik;\n  \n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      predicted_goal[i] = predicted_goal[i - 1]\n                          + alpha[subject[i]]\n                            * (performance[i - 1] - predicted_goal[i - 1])\n                          + beta[subject[i]];\n    }\n    \n    sampled_goal[i] = normal_rng(predicted_goal[i], sigma);\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal[i], sigma);\n  }\n}\n\n\n\nEseguiamo il campionamento.\n\nfit_person = person_level_model.sample(\n    data=stan_data,\n    iter_warmup=10_000,\n    iter_sampling=20_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nQuesto modello produce un insieme di campioni posteriori di alpha e beta per ogni partecipante.\n\nfit_person_az = az.from_cmdstanpy(posterior=fit_person)\naz.summary(fit_person_az, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha[0]\n0.61\n0.24\n0.16\n1.04\n0.00\n0.00\n4791.24\n3205.07\n1.00\n\n\nalpha[1]\n0.19\n0.21\n-0.21\n0.60\n0.00\n0.00\n5696.38\n23355.82\n1.01\n\n\nalpha[2]\n0.14\n0.20\n-0.21\n0.57\n0.01\n0.01\n482.28\n131.39\n1.01\n\n\nalpha[3]\n0.36\n0.32\n-0.22\n0.96\n0.01\n0.01\n1292.01\n13071.55\n1.00\n\n\nalpha[4]\n0.37\n0.17\n0.05\n0.68\n0.00\n0.00\n1673.29\n27077.52\n1.00\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nsampled_goal[596]\n6.23\n0.96\n4.43\n8.04\n0.01\n0.00\n25829.93\n72786.03\n1.00\n\n\nsampled_goal[597]\n6.88\n0.96\n5.07\n8.66\n0.00\n0.00\n44329.67\n75437.97\n1.00\n\n\nsampled_goal[598]\n6.40\n0.98\n4.55\n8.23\n0.01\n0.01\n17989.62\n68475.72\n1.00\n\n\nsampled_goal[599]\n6.28\n0.98\n4.40\n8.07\n0.01\n0.00\n19943.05\n65972.11\n1.00\n\n\nsigma\n0.90\n0.04\n0.83\n0.98\n0.01\n0.01\n8.79\n25.62\n1.36\n\n\n\n\n1321 rows × 9 columns\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\n\n# Extract the alpha parameters only\nalpha_params = fit_person_az.posterior[\"alpha\"]\n\n# Plot forest plot for alpha parameters\n_ = az.plot_forest(\n    alpha_params,\n    hdi_prob=0.94,  # Set the credible interval to 94%\n    combined=True,  # Combine the chains if there are multiple\n    r_hat=False,  # Display the r_hat values\n    figsize=(10, 6),\n)\n\n\n\n\n\n\n\n\n\n# Extract the beta parameters only\nbeta_params = fit_person_az.posterior[\"beta\"]\n\n# Plot forest plot for beta parameters\n_ = az.plot_forest(\n    beta_params,\n    hdi_prob=0.94,  # Set the credible interval to 94%\n    combined=True,  # Combine the chains if there are multiple\n    r_hat=False,  # Display the r_hat values\n    figsize=(10, 6),\n)\n\n\n\n\n\n\n\n\nCome si può vedere, c’è eterogeneità tra i partecipanti sia per α che per β. Il pannello di destra mostra i parametri α e β di ciascun partecipante rappresentati graficamente l’uno contro l’altro, con le croci che indicano gli intervalli credibili per ciascun parametro.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#modello-gerarchico",
    "href": "chapters/dynamic_models/02_change_across_time.html#modello-gerarchico",
    "title": "105  Modellare il cambiamento nel tempo",
    "section": "105.5 Modello Gerarchico",
    "text": "105.5 Modello Gerarchico\nSebbene la stima dei parametri a livello individuale offra vantaggi rispetto al modello a livello di campione, presenta anche alcune limitazioni. Un problema del modello a livello di persona è che rende difficile fare inferenze sulla popolazione da cui provengono i partecipanti. Analizzare un modello a livello individuale è simile a eseguire un’analisi separata per ciascun partecipante del campione. Questo approccio ha una potenza inferiore perché considera i dati di un solo partecipante alla volta, ignorando il resto del campione. Inoltre, non riesce a catturare le somiglianze tra gli individui che potrebbero derivare dal fatto che i partecipanti appartengono alla stessa popolazione.\nSpesso i ricercatori desiderano esaminare la variazione tra i partecipanti e, al contempo, fare inferenze sulla popolazione nel suo complesso. Un approccio di modellizzazione gerarchica è estremamente utile a questo scopo. I modelli bayesiani gerarchici permettono ai ricercatori di modellare simultaneamente i livelli individuali e quello di popolazione.\nCome nel modello a livello individuale, il modello gerarchico stima parametri unici per ogni individuo. Tuttavia, a differenza del modello a livello individuale, l’approccio gerarchico modella anche la distribuzione dei parametri a livello individuale nella popolazione generale. Di conseguenza, i parametri a livello individuale sono influenzati non solo dai dati di quel singolo individuo, ma anche dalla distribuzione a livello di popolazione del parametro rilevante, riducendo l’influenza degli outlier sulle stime dei parametri.\nCompiliamo e stampiamo il modello 3_hierarchical_model.stan.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"change_models\", \"3_hierarchical_model.stan\"\n)\n\nhierarchical_model = CmdStanModel(stan_file=stan_file)\nprint(hierarchical_model.code())\n\ndata {\n  int&lt;lower=0&gt; Ntotal; // Total number of trials in the dataset (600)\n  array[Ntotal] int&lt;lower=1&gt; trial; // Trial number\n  array[Ntotal] real observed_goal; // Goal level for each trial\n  array[Ntotal] real performance; // Performance for each trial\n  int&lt;lower=1&gt; Nsubj; // Number of subjects\n  array[Ntotal] int&lt;lower=1, upper=Nsubj&gt; subject; // Subject number\n}\nparameters {\n  vector[Nsubj] alpha; // Unique alpha parameter for each subject\n  vector[Nsubj] beta; // Unique beta parameter for each subject\n  real&lt;lower=0&gt; sigma; // Single sigma parameter for entire sample\n  real alpha_mean; // Population mean parameter for the alpha distribution\n  real&lt;lower=0&gt; alpha_sd; // Population sd parameter for the alpha distribution\n  real beta_mean; // Population mean parameter for the beta distribution\n  real&lt;lower=0&gt; beta_sd; // Population sd parameter for the beta distribution\n}\nmodel {\n  vector[Ntotal] predicted_goal; // Vector to store predictions\n  \n  // Priors\n  alpha ~ normal(alpha_mean, alpha_sd);\n  beta ~ normal(beta_mean, beta_sd);\n  sigma ~ normal(0, 1);\n  alpha_mean ~ normal(0, 1);\n  alpha_sd ~ normal(0, 1);\n  beta_mean ~ normal(0, 1);\n  beta_sd ~ normal(0, 1);\n  \n  // Likelihood\n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      predicted_goal[i] = predicted_goal[i - 1]\n                          + alpha[subject[i]]\n                            * (performance[i - 1] - predicted_goal[i - 1])\n                          + beta[subject[i]];\n    }\n  }\n  \n  observed_goal ~ normal(predicted_goal, sigma);\n}\ngenerated quantities {\n  vector[Ntotal] predicted_goal;\n  array[Ntotal] real log_lik;\n  \n  for (i in 1 : Ntotal) {\n    if (trial[i] == 1) {\n      predicted_goal[i] = observed_goal[i];\n    } else {\n      predicted_goal[i] = predicted_goal[i - 1]\n                          + alpha[subject[i]]\n                            * (performance[i - 1] - predicted_goal[i - 1])\n                          + beta[subject[i]];\n    }\n    \n    // Calculate the log likelihood for each observation\n    log_lik[i] = normal_lpdf(observed_goal[i] | predicted_goal[i], sigma);\n  }\n}\n\n\n\nNel modello gerarchico, aggiungiamo nuovi parametri per catturare meglio la variabilità tra i partecipanti e fare inferenze più robuste sulla popolazione. I parametri alpha_mean e alpha_sd descrivono la distribuzione di alpha a livello di popolazione, mentre beta_mean e beta_sd fanno lo stesso per beta. Questo approccio ci permette di non trattare ogni partecipante isolatamente, ma di considerare anche come i loro parametri individuali si distribuiscono all’interno della popolazione.\nI priori in questo modello differiscono dagli altri perché, anziché essere generici e non informativi, si basano sui parametri a livello di popolazione. Quindi, ogni parametro a livello individuale viene stimato tenendo conto della distribuzione a livello di popolazione, rendendo le stime meno sensibili a dati estremi o anomali. Questo approccio ci fornisce una comprensione più dettagliata e accurata di come i parametri variano sia tra gli individui che nella popolazione complessiva.\nEseguiamo il campionamento.\n\nfit_hierarchical = hierarchical_model.sample(\n    data=stan_data,\n    iter_warmup=5_000,\n    iter_sampling=10_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\nfit_hierarchical_az = az.from_cmdstanpy(posterior=fit_hierarchical)\naz.summary(fit_hierarchical_az, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha[0]\n0.54\n0.14\n0.28\n0.80\n0.0\n0.0\n48765.44\n31528.85\n1.0\n\n\nalpha[1]\n0.38\n0.13\n0.13\n0.63\n0.0\n0.0\n44672.18\n29684.11\n1.0\n\n\nalpha[2]\n0.33\n0.12\n0.10\n0.56\n0.0\n0.0\n30957.20\n30389.86\n1.0\n\n\nalpha[3]\n0.47\n0.15\n0.20\n0.75\n0.0\n0.0\n49280.74\n29994.33\n1.0\n\n\nalpha[4]\n0.36\n0.12\n0.14\n0.58\n0.0\n0.0\n29036.20\n28050.90\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\npredicted_goal[596]\n6.28\n0.30\n5.73\n6.86\n0.0\n0.0\n61708.74\n29589.38\n1.0\n\n\npredicted_goal[597]\n6.87\n0.30\n6.29\n7.43\n0.0\n0.0\n63110.37\n31074.04\n1.0\n\n\npredicted_goal[598]\n6.51\n0.32\n5.91\n7.13\n0.0\n0.0\n58823.98\n28862.76\n1.0\n\n\npredicted_goal[599]\n6.38\n0.33\n5.76\n7.01\n0.0\n0.0\n58004.34\n29837.65\n1.0\n\n\nsigma\n0.90\n0.03\n0.84\n0.95\n0.0\n0.0\n37177.28\n31703.27\n1.0\n\n\n\n\n725 rows × 9 columns\n\n\n\nEsaminiamo le stime a posteriori di \\(\\alpha\\) e \\(\\beta\\) per ciascun partecipante.\n\n# Extract the alpha parameters only\nalpha_params = fit_hierarchical_az.posterior[\"alpha\"]\n\n# Plot forest plot for alpha parameters\naz.plot_forest(\n    alpha_params,\n    hdi_prob=0.94,  # Set the credible interval to 94%\n    combined=True,  # Combine the chains if there are multiple\n    r_hat=False,  # Display the r_hat values\n    figsize=(10, 6),\n)\n\narray([&lt;Axes: title={'center': '94.0% HDI'}&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\n\n# Extract the alpha parameters only\nbeta_params = fit_hierarchical_az.posterior[\"beta\"]\n\n# Plot forest plot for alpha parameters\naz.plot_forest(\n    beta_params,\n    hdi_prob=0.94,  # Set the credible interval to 94%\n    combined=True,  # Combine the chains if there are multiple\n    r_hat=False,  # Display the r_hat values\n    figsize=(10, 6),\n)\n\narray([&lt;Axes: title={'center': '94.0% HDI'}&gt;], dtype=object)\n\n\n\n\n\n\n\n\n\nSi osserva che gli intervalli credibili dei parametri a livello individuale sono meno dispersi nel modello gerarchico rispetto al modello a livello individuale. Questo avviene perché, nel modello gerarchico, la distribuzione a livello di popolazione impone un vincolo aggiuntivo sui parametri a livello individuale, spingendo questi parametri verso la media del gruppo. Questo fenomeno è noto come “shrinkage” o “contrazione”.\nOltre ai parametri \\(\\alpha\\) e \\(\\beta\\) per ciascun soggetto, il modello gerarchico stima anche gli iperparametri alpha_mean e beta_mean, oltre a alpha_sd, beta_sd e sigma.\n\n_ = az.plot_posterior(fit_hierarchical, var_names=[\"alpha_mean\", \"beta_mean\"])\n\n\n\n\n\n\n\n\nIl modello gerarchico utilizza alpha_mean e beta_mean per rappresentare le tendenze generali a livello di popolazione. Questi parametri ci danno un’idea di come, mediamente, i partecipanti aggiornano i loro obiettivi sulla base delle performance passate e indipendentemente da esse.\n\nalpha_mean riflette quanto i partecipanti, in media, siano influenzati dalla differenza tra la performance passata e l’obiettivo previsto quando aggiornano il loro obiettivo.\nbeta_mean riflette l’incremento medio fisso che i partecipanti aggiungono al loro obiettivo, indipendentemente da altri fattori.\n\nLa stima di alpha_mean è 0.49, con un intervallo credibile del 94% che va da 0.42 a 0.55. Questo parametro rappresenta la media della distribuzione di alpha a livello di popolazione. In altre parole, alpha_mean è il valore medio del parametro alpha considerando tutti i partecipanti del campione. In questo modello, alpha rappresenta la sensibilità di ogni partecipante alla differenza tra la performance precedente e l’obiettivo previsto. Un valore di alpha_mean di 0.49 suggerisce che, mediamente, i partecipanti tendono ad aggiornare il loro obiettivo basandosi per circa il 49% sulla differenza tra la performance precedente e l’obiettivo precedente. L’intervallo credibile, che va da 0.42 a 0.55, indica che c’è un’alta probabilità che la vera media della popolazione per alpha si trovi in questo range.\nLa stima di beta_mean è 0.18, con un intervallo credibile del 94% che va da 0.048 a 0.3. beta_mean rappresenta la media della distribuzione di beta a livello di popolazione. In questo contesto, beta indica un incremento additivo costante nell’obiettivo del partecipante, indipendentemente dalla differenza tra la performance precedente e l’obiettivo previsto. Un valore di beta_mean di 0.18 suggerisce che, mediamente, i partecipanti tendono ad aumentare il loro obiettivo di un piccolo valore fisso (circa 0.18) in ogni prova, indipendentemente dalle altre variabili. L’intervallo credibile da 0.048 a 0.3 indica che c’è un’alta probabilità che il vero valore medio di beta nella popolazione si trovi in questo intervallo.\nIn sintesi, questi parametri aiutano a comprendere il comportamento generale dei partecipanti rispetto all’aggiornamento degli obiettivi, catturando sia l’adattamento dinamico in base alle performance precedenti che un aggiustamento incrementale costante.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#valutazione-e-confronto-di-modelli",
    "href": "chapters/dynamic_models/02_change_across_time.html#valutazione-e-confronto-di-modelli",
    "title": "105  Modellare il cambiamento nel tempo",
    "section": "105.6 Valutazione e Confronto di Modelli",
    "text": "105.6 Valutazione e Confronto di Modelli\nUna volta che il ricercatore ha specificato un modello appropriato e verificato che il modello ottiene la convergenza, può valutare se il modello descrive adeguatamente i dati. Le stime dei parametri sono interpretabili solo nella misura in cui il modello rappresenta accuratamente il fenomeno che si sta indagando. Se il modello approssima male i dati, le informazioni contenute nelle stime dei parametri potrebbero non essere rappresentative del processo che il ricercatore sta cercando di analizzare. In tali casi, potrebbe essere necessario riformulare il modello per migliorare la sua capacità di spiegare le osservazioni empiriche.\n\n# Run diagnostics and print results\ndiagnostic_info = fit_sample.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/1_sample_level_modelh2kv1c5m/1_sample_level_model-20240824092852_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/1_sample_level_modelh2kv1c5m/1_sample_level_model-20240824092852_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/1_sample_level_modelh2kv1c5m/1_sample_level_model-20240824092852_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/1_sample_level_modelh2kv1c5m/1_sample_level_model-20240824092852_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_person.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/2_person_level_model3rm_zhgj/2_person_level_model-20240824085216_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/2_person_level_model3rm_zhgj/2_person_level_model-20240824085216_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/2_person_level_model3rm_zhgj/2_person_level_model-20240824085216_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/2_person_level_model3rm_zhgj/2_person_level_model-20240824085216_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\n11074 of 80000 (13.84%) transitions ended with a divergence.\nThese divergent transitions indicate that HMC is not fully able to explore the posterior distribution.\nTry increasing adapt delta closer to 1.\nIf this doesn't remove all divergences, try to reparameterize the model.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nThe E-BFMI, 0.16, is below the nominal threshold of 0.30 which suggests that HMC may have trouble exploring the target distribution.\nIf possible, try to reparameterize the model.\n\nThe following parameters had fewer than 0.001 effective draws per transition:\n  alpha[22], beta[22], sigma, predicted_goal[212], predicted_goal[213], predicted_goal[214], predicted_goal[215], predicted_goal[216], predicted_goal[217], predicted_goal[218], predicted_goal[219], predicted_goal[220], sampled_goal[212], sampled_goal[213], sampled_goal[214], sampled_goal[215], sampled_goal[216], sampled_goal[217], sampled_goal[218], sampled_goal[219], sampled_goal[220], log_lik[1], log_lik[3], log_lik[10], log_lik[11], log_lik[12], log_lik[14], log_lik[15], log_lik[21], log_lik[22], log_lik[26], log_lik[31], log_lik[35], log_lik[36], log_lik[41], log_lik[42], log_lik[43], log_lik[44], log_lik[51], log_lik[54], log_lik[57], log_lik[61], log_lik[63], log_lik[71], log_lik[72], log_lik[81], log_lik[82], log_lik[88], log_lik[91], log_lik[95], log_lik[100], log_lik[101], log_lik[111], log_lik[113], log_lik[116], log_lik[121], log_lik[129], log_lik[131], log_lik[136], log_lik[137], log_lik[138], log_lik[141], log_lik[144], log_lik[146], log_lik[148], log_lik[149], log_lik[151], log_lik[154], log_lik[155], log_lik[156], log_lik[157], log_lik[161], log_lik[164], log_lik[165], log_lik[171], log_lik[172], log_lik[175], log_lik[176], log_lik[179], log_lik[181], log_lik[182], log_lik[183], log_lik[184], log_lik[185], log_lik[186], log_lik[191], log_lik[201], log_lik[202], log_lik[203], log_lik[207], log_lik[209], log_lik[211], log_lik[212], log_lik[213], log_lik[214], log_lik[215], log_lik[216], log_lik[217], log_lik[218], log_lik[219], log_lik[220], log_lik[221], log_lik[224], log_lik[225], log_lik[226], log_lik[229], log_lik[230], log_lik[231], log_lik[233], log_lik[236], log_lik[241], log_lik[244], log_lik[245], log_lik[247], log_lik[251], log_lik[255], log_lik[256], log_lik[257], log_lik[258], log_lik[259], log_lik[261], log_lik[271], log_lik[272], log_lik[274], log_lik[275], log_lik[278], log_lik[281], log_lik[282], log_lik[287], log_lik[290], log_lik[291], log_lik[292], log_lik[293], log_lik[295], log_lik[297], log_lik[299], log_lik[301], log_lik[302], log_lik[304], log_lik[306], log_lik[309], log_lik[311], log_lik[314], log_lik[321], log_lik[324], log_lik[330], log_lik[331], log_lik[341], log_lik[342], log_lik[347], log_lik[349], log_lik[351], log_lik[354], log_lik[355], log_lik[356], log_lik[361], log_lik[371], log_lik[374], log_lik[375], log_lik[376], log_lik[378], log_lik[381], log_lik[391], log_lik[398], log_lik[400], log_lik[401], log_lik[408], log_lik[409], log_lik[411], log_lik[412], log_lik[418], log_lik[421], log_lik[423], log_lik[425], log_lik[431], log_lik[434], log_lik[441], log_lik[443], log_lik[444], log_lik[445], log_lik[446], log_lik[447], log_lik[448], log_lik[449], log_lik[451], log_lik[452], log_lik[457], log_lik[458], log_lik[461], log_lik[467], log_lik[471], log_lik[473], log_lik[477], log_lik[478], log_lik[481], log_lik[482], log_lik[487], log_lik[488], log_lik[491], log_lik[493], log_lik[501], log_lik[505], log_lik[511], log_lik[514], log_lik[518], log_lik[521], log_lik[522], log_lik[523], log_lik[524], log_lik[531], log_lik[534], log_lik[537], log_lik[538], log_lik[541], log_lik[546], log_lik[547], log_lik[551], log_lik[553], log_lik[555], log_lik[560], log_lik[561], log_lik[564], log_lik[571], log_lik[581], log_lik[588], log_lik[590], log_lik[591], log_lik[594], log_lik[597]\nSuch low values indicate that the effective sample size estimators may be biased high and actual performance may be substantially lower than quoted.\n\nThe following parameters had split R-hat greater than 1.05:\n  alpha[22], beta[22], sigma, predicted_goal[212], predicted_goal[213], predicted_goal[214], predicted_goal[215], predicted_goal[216], predicted_goal[217], predicted_goal[218], predicted_goal[219], predicted_goal[220], sampled_goal[212], sampled_goal[213], sampled_goal[214], sampled_goal[215], sampled_goal[217], sampled_goal[218], sampled_goal[219], sampled_goal[220], log_lik[1], log_lik[11], log_lik[21], log_lik[22], log_lik[26], log_lik[31], log_lik[35], log_lik[41], log_lik[43], log_lik[51], log_lik[61], log_lik[71], log_lik[81], log_lik[82], log_lik[91], log_lik[101], log_lik[111], log_lik[121], log_lik[131], log_lik[141], log_lik[151], log_lik[154], log_lik[155], log_lik[156], log_lik[157], log_lik[161], log_lik[164], log_lik[171], log_lik[181], log_lik[182], log_lik[183], log_lik[185], log_lik[191], log_lik[201], log_lik[202], log_lik[211], log_lik[213], log_lik[214], log_lik[215], log_lik[216], log_lik[217], log_lik[218], log_lik[219], log_lik[220], log_lik[221], log_lik[224], log_lik[231], log_lik[233], log_lik[241], log_lik[251], log_lik[256], log_lik[257], log_lik[258], log_lik[259], log_lik[261], log_lik[271], log_lik[281], log_lik[282], log_lik[291], log_lik[292], log_lik[293], log_lik[295], log_lik[301], log_lik[311], log_lik[314], log_lik[321], log_lik[331], log_lik[341], log_lik[342], log_lik[351], log_lik[354], log_lik[361], log_lik[371], log_lik[381], log_lik[391], log_lik[398], log_lik[400], log_lik[401], log_lik[411], log_lik[421], log_lik[423], log_lik[425], log_lik[431], log_lik[434], log_lik[441], log_lik[444], log_lik[445], log_lik[446], log_lik[447], log_lik[451], log_lik[461], log_lik[471], log_lik[478], log_lik[481], log_lik[482], log_lik[491], log_lik[501], log_lik[511], log_lik[521], log_lik[522], log_lik[523], log_lik[531], log_lik[534], log_lik[541], log_lik[551], log_lik[561], log_lik[571], log_lik[581], log_lik[590], log_lik[591]\nSuch high values indicate incomplete mixing and biased estimation.\nYou should consider regularizating your model with additional prior information or a more effective parameterization.\n\nProcessing complete.\n\n\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_hierarchical.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/3_hierarchical_modelq19mwkng/3_hierarchical_model-20240824085700_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/3_hierarchical_modelq19mwkng/3_hierarchical_model-20240824085700_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/3_hierarchical_modelq19mwkng/3_hierarchical_model-20240824085700_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp8aprzkhg/3_hierarchical_modelq19mwkng/3_hierarchical_model-20240824085700_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\n27 of 40000 (0.07%) transitions ended with a divergence.\nThese divergent transitions indicate that HMC is not fully able to explore the posterior distribution.\nTry increasing adapt delta closer to 1.\nIf this doesn't remove all divergences, try to reparameterize the model.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete.\n\n\n\nSi noti che sia il modello a livello di persona che il modello gerarchico mostrano dei problemi indicati dalla presenza di transizioni divergenti, anche se il modello gerarchico è meno problematico di quello basato sulle stime dei coefficienti delle persone soltanto.\nEseguiamo comunque il calcolo dei valori k di Pareto e la validazione incrociata Leave-One-Out (LOO-CV) utilizzando ArviZ.\n\nloo_person_result = az.loo(fit_person_az)\nprint(loo_person_result)\n\nComputed from 80000 posterior samples and 600 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -920.94    57.89\np_loo      201.15        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      543   90.5%\n (0.5, 0.7]   (ok)         39    6.5%\n   (0.7, 1]   (bad)        12    2.0%\n   (1, Inf)   (very bad)    6    1.0%\n\n\n\n\nloo_hierarchical_result = az.loo(fit_hierarchical_az)\nprint(loo_hierarchical_result)\n\nComputed from 40000 posterior samples and 600 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -842.54    36.72\np_loo       95.53        -\n\nThere has been a warning during the calculation. Please check the results.\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)      583   97.2%\n (0.5, 0.7]   (ok)         13    2.2%\n   (0.7, 1]   (bad)         2    0.3%\n   (1, Inf)   (very bad)    2    0.3%\n\n\n\nC’è un piccolo numero di valori di Pareto \\(k\\) problematici, i quali indicando che vi sono delle osservazioni che hanno un’influenza eccessiva sulle stime del modello. Tali problemi andrebbero affrontati prima di calcolare l’ELPD. Per gli scopi di questo tutorial, tuttavia, procediamo tenendo comunque a mente la possibilità che la stima dell’ELPD possa essere distorta.\nInfine, calcoliamo la differenza tra le stime dell’ELPD (elpd_diff) dei due modelli. L’incertezza associata a questa differenza è espressa dal suo errore standard (dse). Se il rapporto tra elpd_diff e dse è pari o superiore a 2, possiamo concludere che esiste una differenza credibile tra i due modelli.\n\ndf_comp_loo = az.compare({\n    \"person_model\": loo_person_result, \n    \"hierarchical_model\": loo_hierarchical_result\n})\ndf_comp_loo\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nhierarchical_model\n0\n-842.541615\n95.525862\n0.000000\n0.907237\n36.718759\n0.000000\nTrue\nlog\n\n\nperson_model\n1\n-920.935304\n201.145350\n78.393688\n0.092763\n57.891756\n43.516941\nTrue\nlog\n\n\n\n\n\n\n\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)\n\n\n\n\n\n\n\n\nIl rapporto tra elpd_diff e dse è leggermente inferiore a 2, il che suggerisce una debole evidenza a favore del modello gerarchico rispetto al modello non gerarchico, basandosi sul confronto dell’ELPD dei due modelli. Tuttavia, il modello non gerarchico presenta notevoli problemi con i valori di Pareto \\(k\\), portando alla conclusione che, complessivamente, il modello gerarchico sia da preferire.\nPrima di giungere a una conclusione definitiva, ci sarebbero vari problemi da affrontare. Tuttavia, per gli scopi di questo tutorial, non è necessario entrare nei dettagli, poiché l’obiettivo principale è introdurre un modello dinamico, mostrare come questo modello possa rappresentare le differenze individuali e spiegare perché un modello gerarchico possa essere più appropriato rispetto a un modello che stima i parametri dei partecipanti separatamente.\nKnight et al. (2023) approfondiscono ulteriormente la descrizione di questi dati discutendo due ulteriori modelli: un modello che distingue l’appartenenza a gruppi distinti identificabili in modo esplicito e un modello a mescolanza. A volte, il ricercatore conosce in anticipo il gruppo a cui appartiene ogni partecipante. Tuttavia, ciò non è sempre il caso. In alcune situazioni, il ricercatore potrebbe voler identificare sottogruppi di partecipanti che mostrano comportamenti simili, senza alcuna conoscenza preliminare dell’appartenenza ai gruppi. Per fare ciò, si può utilizzare un modello a mescolanza, un modello che serve a catturare comportamenti risultanti da processi differenti. Ad esempio, potrebbe esserci un sottogruppo di partecipanti che si comporta secondo un processo e un altro sottogruppo il cui comportamento è governato da un processo diverso. Questi diversi processi sono definiti “mescolanze”. L’obiettivo dell’analisi è determinare i parametri che meglio caratterizzano ciascuna mescolanza e fare inferenze sull’influenza relativa di ciascuna mescolanza sul comportamento di ogni partecipante.\nAnche se questi modelli migliorano la descrizione dei dati di questo campione, per gli scopi del presente tutorial non sono necessari.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#riflessioni-conclusive",
    "href": "chapters/dynamic_models/02_change_across_time.html#riflessioni-conclusive",
    "title": "105  Modellare il cambiamento nel tempo",
    "section": "105.7 Riflessioni Conclusive",
    "text": "105.7 Riflessioni Conclusive\nLe teorie dinamiche, pur essendo influenti in psicologia, sono spesso difficili da verificare. Testare una teoria dinamica richiede un modello statistico che rifletta accuratamente i processi descritti dalla teoria stessa. In questo capitolo, seguendo il tutorial di Knight et al. (2023), abbiamo esaminato un approccio bayesiano alla modellizzazione dei processi dinamici. Per illustrare questa flessibilità, Knight et al. (2023) considerano un modello di revisione degli obiettivi pubblicato da Gee et al. (2018). Una caratteristica importante di questo modello, comune a molte teorie dinamiche, è l’assunzione che alcune variabili abbiano una sorta di “memoria”. La capacità di rappresentare variabili dinamiche come queste è fondamentale per testare teorie che presumono processi di feedback ricorsivi, tipici di molte teorie influenti.\nL’approccio bayesiano affronta questo problema e offre un modo intuitivo per implementare modelli complessi di processi dinamici. In questo capitolo abbiamo iniziato con un modello a livello di campione, che quantifica l’incertezza nei valori medi dei parametri del modello di revisione degli obiettivi per tutti i partecipanti. Successivamente, abbiamo mostrato come estendere questo framework per creare modelli più sofisticati che catturano la variabilità tra individui e gruppi. Il modello a livello individuale quantifica i componenti del processo di revisione degli obiettivi separatamente per ogni individuo. Infine, il modello gerarchico combina i modelli a livello di campione e a livello individuale in un unico framework, consentendo di quantificare i componenti separatamente per ogni individuo e di fare inferenze a livello di popolazione.\nKnight et al. (2023) discutono altri modelli qui non considerati, come il modello a gruppi multipli, che quantifica le differenze nei componenti del processo tra gruppi noti (ad esempio, diversi livelli di una manipolazione sperimentale) e il modello a mescolanza, che consente al ricercatore di identificare sottogruppi latenti di partecipanti per i quali il processo dinamico si svolge in modo simile.\nI modelli che abbiamo introdotto in questo capitolo rappresentano solo una piccola parte della vasta gamma di modelli che possono essere implementati utilizzando questo framework. La flessibilità di questo approccio permette di creare modelli con praticamente qualsiasi forma funzionale, offrendo ai ricercatori la possibilità di sviluppare modelli personalizzati che rappresentano più accuratamente la teoria che si sta testando rispetto ai modelli generici disponibili.\nIn conclusione, le teorie dinamiche, comuni in psicologia, possono essere difficili da testare perché i processi che le sottendono sono spesso troppo complessi per essere adeguatamente rappresentati nei modelli statistici tradizionali. L’approccio bayesiano che Knight et al. (2023) illustrano nel loro tutorial consente di superare queste sfide, offrendo un modo flessibile per sviluppare, testare e confrontare modelli dinamici. Questo approccio offre ai ricercatori la possibilità di rappresentare meglio fenomeni dinamici o gerarchici, in cui i processi possono variare nel tempo, a diversi livelli e in diversi contesti e per diverse persone.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/02_change_across_time.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/02_change_across_time.html#informazioni-sullambiente-di-sviluppo",
    "title": "105  Modellare il cambiamento nel tempo",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sat Jul 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\npingouin  : 0.5.4\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\narviz     : 0.18.0\ncmdstanpy : 1.2.3\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nGee, P., Neal, A., & Vancouver, J. B. (2018). A formal model of goal revision in approach and avoidance contexts. Organizational Behavior and Human Decision Processes, 146, 51–61.\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A Tutorial on Bayesian Modeling of Change Across Time, Individuals, and Groups. Computational Brain & Behavior, 6(4), 697–718.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>Modellare il cambiamento nel tempo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html",
    "title": "106  Apprendimento per rinforzo",
    "section": "",
    "text": "Introduzione\nNel Capitolo 105 abbiamo introdotto l’approccio bayesiano per descrivere i processi dinamici. In questo capitolo, presenteremo un altro esempio di questo approccio implementando uno dei modelli psicologici dinamici più influenti: il modello di apprendimento di Rescorla-Wagner. Dopo una breve introduzione storica, esamineremo la definizione del modello, il significato dei suoi parametri e i metodi per stimarli dai dati osservati, con un focus particolare sull’uso del linguaggio di programmazione probabilistica Stan.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#note-storiche",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#note-storiche",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.1 Note Storiche",
    "text": "106.1 Note Storiche\nNegli anni ’50, uno dei concetti fondamentali nell’intelligenza artificiale (AI) era quello dell’apprendimento per rinforzo, che sosteneva l’importanza di incoraggiare le azioni che avevano avuto successo in passato. Questo approccio ha portato allo sviluppo di algoritmi avanzati per il gioco. Nei decenni successivi, l’apprendimento per rinforzo ha visto un’evoluzione significativa, applicandosi con successo a giochi complessi come il Go e al controllo di sistemi robotici altamente sofisticati.\nUn aspetto centrale dell’apprendimento per rinforzo è la capacità di bilanciare l’acquisizione di conoscenza sull’ambiente con l’azione all’interno di esso. Questo equilibrio rappresenta una sfida complessa, anche in situazioni in cui le azioni non comportano un cambiamento nell’ambiente stesso. Nel contesto del machine learning, il processo di esplorazione, ovvero compiere un’azione e osservarne l’effetto, è fondamentale per apprendere. Tuttavia, l’esplorazione comporta il rischio di non sfruttare un’azione che già si conosce come vantaggiosa. Esiste quindi un inevitabile compromesso tra l’esplorazione di nuove opzioni e lo sfruttamento di quelle già note.\nQuesto concetto di apprendimento basato sul bilanciamento tra esplorazione e sfruttamento trova un’interessante applicazione anche nel campo della psicologia, in particolare attraverso il modello di Rescorla-Wagner. Sviluppato negli anni ’70 da Robert Rescorla e Allan Wagner, questo modello è ampiamente utilizzato per spiegare come animali e esseri umani apprendano le associazioni tra stimoli e conseguenze delle azioni (Rescorla & Wagner, 1972). Questo modello è alla base di molti approcci più recenti nell’apprendimento per rinforzo e nelle neuroscienze computazionali (Soto et al., 2023).\nIl modello di Rescorla-Wagner si basa sull’idea che l’apprendimento avvenga in funzione della discrepanza tra ciò che un individuo si aspetta e ciò che effettivamente accade. In altre parole, l’apprendimento è guidato dall’errore di previsione: quando l’esito di una situazione differisce da ciò che ci si aspettava, le associazioni mentali tra gli eventi coinvolti vengono aggiornate. Il modello suggerisce che la forza dell’apprendimento dipende dall’intensità della sorpresa generata dall’esito osservato.\nPer esempio, immagina di partecipare a un esperimento in cui, ogni volta che compi una specifica azione, si verifica un evento che ti sorprende. All’inizio, non ti aspetti che quell’evento segua l’azione, quindi apprendi rapidamente l’associazione tra l’azione e l’evento. Con il tempo, man mano che ti abitui a questa sequenza, l’apprendimento rallenta, perché diventi più bravo a prevedere l’esito e la sorpresa diminuisce.\nQuesto modello ha avuto un impatto significativo nello studio dell’apprendimento e continua a essere un punto di riferimento per comprendere i meccanismi attraverso i quali formiamo associazioni basate sulle nostre esperienze.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#concetti-fondamentali",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#concetti-fondamentali",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.2 Concetti Fondamentali",
    "text": "106.2 Concetti Fondamentali\nPer comprendere l’apprendimento associativo, è importante introdurre alcuni concetti chiave che sono comunemente utilizzati nella letteratura sull’apprendimento per rinforzo.\nNell’apprendimento per rinforzo, immaginiamo un “agente” che interagisce con un “ambiente”, in modo simile a un giocatore che esplora un nuovo videogioco. L’agente esegue una serie di azioni per scoprire quali siano le migliori per ottenere la massima ricompensa. Questo processo si svolge in vari turni, durante i quali l’agente fa delle scelte e riceve feedback sotto forma di ricompense o punizioni (Sutton & Barto, 2018).\nAd ogni turno, l’agente seleziona un’azione tra quelle disponibili. In uno scenario semplice, potrebbe dover scegliere tra due opzioni, come decidere tra due porte in un gioco. Dopo aver fatto la sua scelta, l’agente riceve un feedback, che può essere positivo o negativo, in base al risultato dell’azione intrapresa.\nÈ importante notare che i feedback sono stocastici, ovvero non sono deterministici ma probabilistici: una stessa azione può portare a una ricompensa o a una punizione, in momenti differenti. I feedback vengono generati in base a una distribuzione probabilistica rappresentata come \\(r_t \\sim M^\\star(\\cdot | \\pi_t)\\), dove \\(M^\\star(\\cdot | \\pi_t)\\) è il modello che descrive il comportamento dell’ambiente in risposta alla politica \\(\\pi_t\\).\nDefiniamo \\(f(\\pi) := \\mathbb{E}[r | \\pi]\\) come la funzione di ricompensa media sotto la distribuzione \\(r \\sim M^\\star(\\cdot | \\pi)\\). Ad esempio, un’azione \\(A\\) potrebbe avere una probabilità dell’80% di portare a una ricompensa positiva e del 20% di portare a una punizione. Queste probabilità possono restare costanti nel tempo o variare in base all’esperienza accumulata.\nNel contesto dell’apprendimento per rinforzo, la “storia” \\(\\mathcal{H}^t\\) rappresenta la sequenza di tutte le azioni intraprese e dai feedback ricevuti fino al tempo \\(t\\). Formalmente, può essere espressa come \\(\\mathcal{H}^t = (\\pi^1, r^1), \\ldots, (\\pi^t, r^t)\\). Questa storia è essenziale perché fornisce un quadro completo del percorso di apprendimento dell’agente, aiutandolo a migliorare le sue decisioni nel tempo.\nL’obiettivo principale dell’agente è quello di identificare le azioni che, in media, forniscono la ricompensa più alta. Per misurare l’efficacia delle scelte dell’agente, si utilizza il concetto di “regret” (rimpianto). Il regret misura la differenza tra la ricompensa che l’agente avrebbe potuto ottenere scegliendo sempre l’azione ottimale e la ricompensa effettivamente ottenuta con le sue scelte attuali.\nMatematicamente, il regret (\\(\\text{Reg}\\)) è definito come la differenza cumulativa tra la ricompensa massima possibile (ottenuta scegliendo sempre la politica ottimale \\(\\pi^\\star\\)) e la ricompensa media delle scelte effettuate:\n\\[\n\\text{Reg} := \\sum_{t=1}^{T} \\left(f^\\star(\\pi^\\star) - \\mathbb{E}[f(\\pi^t)]\\right).\n\\]\nIn questa formula, \\(f^\\star(\\pi^\\star)\\) rappresenta la ricompensa media massima ottenibile con la politica ottimale \\(\\pi^\\star\\), che massimizza la ricompensa media attesa. Ad esempio, se \\(f^\\star(A) = 0.75\\) e \\(f^\\star(B) = 0.25\\), allora la politica ottimale \\(\\pi^\\star\\) è quella che seleziona sempre l’azione \\(A\\), la quale offre la maggiore probabilità di ricompensa positiva.\nLa “politica” (\\(\\pi\\)) è un concetto cruciale nell’apprendimento per rinforzo. Essa rappresenta una strategia o regola che guida l’agente nella scelta delle azioni. Una politica potrebbe essere molto semplice, come scegliere sempre la stessa azione, oppure più complessa, basata su un’analisi approfondita delle informazioni disponibili.\nUn approccio comune ma talvolta limitato è la strategia “greedy”, che sceglie sempre l’azione che sembra avere il valore atteso più alto basato sulle esperienze passate. Tuttavia, questo può portare l’agente a “bloccarsi” su un’azione che appare buona ma non è la migliore in assoluto, limitando così la sua capacità di scoprire opzioni potenzialmente migliori attraverso l’esplorazione.\nPer superare questa limitazione, gli algoritmi avanzati cercano di bilanciare due aspetti fondamentali: esplorazione e sfruttamento. L’esplorazione implica provare nuove azioni per acquisire più informazioni, mentre lo sfruttamento si concentra sul selezionare le azioni che hanno fornito i migliori risultati finora. Questo dilemma tra esplorazione e sfruttamento è centrale nell’apprendimento per rinforzo e può essere paragonato alla decisione tra ordinare sempre il nostro piatto preferito al ristorante (sfruttamento) o provare qualcosa di nuovo (esplorazione).\nDiverse tecniche sono state sviluppate per trovare un equilibrio ottimale tra esplorazione e sfruttamento, migliorando così la capacità dell’agente di apprendere nel tempo e di adattarsi a nuovi contesti.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#modello-di-rescorla-wagner",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#modello-di-rescorla-wagner",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.3 Modello di Rescorla-Wagner",
    "text": "106.3 Modello di Rescorla-Wagner\nIl modello di Rescorla-Wagner propone che le scelte siano basate su ‘Q-values’, che approssimano la ricompensa attesa associata a ciascuna azione. Questi valori sono tipicamente calcolati applicando ripetutamente una regola di apprendimento incrementale che confronta l’esito effettivo con la sua stima precedente.\nNel modello, l’aspettativa di valore (cioè la ricompensa attesa) per un’azione scelta viene aggiornata secondo la seguente formula: \\[\nQ(t+1) = Q(t) + \\alpha (R(t) - Q(t)),\n\\]\ndove:\n\n\\(Q(t)\\) rappresenta il valore atteso o ‘Q-value’ al tempo \\(t\\),\n\\(R(t)\\) è la ricompensa effettivamente ottenuta al tempo \\(t\\),\n\\(\\alpha\\) è il tasso di apprendimento (un valore tra 0 e 1).\n\nIn questa formula, l’aggiornamento del valore atteso dipende dalla differenza tra la ricompensa osservata \\(R(t)\\) e il valore atteso corrente \\(Q(t)\\), moltiplicata per il tasso di apprendimento \\(\\alpha\\).\nPossiamo riarrangiare la formula precedente per rendere più chiaro il ruolo del tasso di apprendimento:\n\\[\nQ(t+1) = (1 - \\alpha)Q(t) + \\alpha R(t).\n\\]\nQuesta forma dell’equazione mostra che il valore aggiornato \\(Q(t+1)\\) è una media pesata tra l’informazione nuova derivata dall’osservazione recente \\(R(t)\\) e l’informazione precedente sotto forma di valore atteso attuale \\(Q(t)\\). Il tasso di apprendimento \\(\\alpha\\) agisce come un peso che determina l’influenza delle nuove osservazioni rispetto alle credenze precedenti.\nPossiamo descrivere il funzionamento del modello nel modo seguente.\n\nL’agente ha un’aspettativa iniziale \\(Q(t)\\) riguardo alla ricompensa associata a uno stimolo o a un’azione.\nL’agente sperimenta lo stimolo o compie l’azione, ricevendo una ricompensa effettiva \\(R(t)\\).\nLa differenza tra la ricompensa attesa e quella ottenuta \\((R(t) - Q(t))\\) costituisce l’errore di previsione.\nQuesto errore viene moltiplicato per il tasso di apprendimento \\(\\alpha\\) per determinare l’aggiornamento dell’aspettativa.\nL’aspettativa di valore per il prossimo turno viene aggiornata secondo la formula \\(Q(t+1) = (1 - \\alpha)Q(t) + \\alpha R(t)\\).\n\nIn sintesi, il modello di Rescorla-Wagner descrive come le aspettative di ricompensa vengono aggiornate sulla base dell’errore di previsione. Se la ricompensa ottenuta \\(R(t)\\) è maggiore del valore previsto \\(Q(t)\\), il valore atteso \\(Q(t)\\) aumenta. Se la ricompensa è minore del previsto, il valore atteso diminuisce. La velocità con cui questi aggiornamenti avvengono è regolata dal tasso di apprendimento \\(\\alpha\\).\n\n106.3.1 Bilanciare Sfruttamento ed Esplorazione con la Regola Softmax\nIl modello di Rescorla-Wagner, da solo, non prevede un meccanismo per bilanciare direttamente lo sfruttamento (ossia scegliere l’azione con il valore atteso più alto) e l’esplorazione (ossia provare nuove azioni per ottenere maggiori informazioni). Per integrare questo equilibrio nel processo decisionale, si può utilizzare la regola softmax, che è una strategia di selezione delle azioni che bilancia sfruttamento ed esplorazione in base alle probabilità.\nLa formula della regola softmax è la seguente:\n\\[\nP(\\pi_k) = \\frac{e^{Q_k(t) / \\tau}}{\\sum_{j} e^{Q_j(t) / \\tau}},\n\\]\ndove:\n\n\\(P(\\pi_k)\\) è la probabilità di selezionare l’azione \\(k\\),\n\\(Q_k(t)\\) è il valore atteso dell’azione \\(k\\) al tempo \\(t\\),\n\\(\\tau\\) è il parametro di temperatura che controlla il grado di esplorazione: un valore alto di \\(\\tau\\) aumenta l’esplorazione (le probabilità sono più uniformemente distribuite tra le azioni), mentre un valore basso di \\(\\tau\\) favorisce lo sfruttamento (una maggiore probabilità di scegliere l’azione con il valore atteso più alto).\n\nL’integrazione del modello di Rescorla-Wagner con la regola softmax può essere descritta nel modo seguente:\n\nAggiornamento dei Valori Attesi: Dopo ogni turno, l’agente aggiorna i valori attesi \\(Q_k(t)\\) per tutte le azioni \\(k\\) utilizzando il modello di Rescorla-Wagner basato sull’errore di previsione.\nCalcolo delle Probabilità di Selezione: Le probabilità di selezione per ciascuna azione vengono calcolate utilizzando la regola softmax.\nSelezione dell’Azione: L’agente sceglie un’azione \\(\\pi_k\\) in modo probabilistico, in base alle probabilità \\(P(\\pi_k)\\) determinate dalla regola softmax.\n\nIn sintesi, il modello di Rescorla-Wagner viene utilizzato per aggiornare continuamente le aspettative di valore basate sull’errore di previsione. La regola softmax, invece, viene utilizzata per determinare quale azione scegliere, bilanciando la necessità di sfruttare le azioni con il valore atteso più alto e di esplorare nuove possibilità per migliorare l’apprendimento futuro.\nQuesta combinazione consente all’agente di apprendere in modo adattivo e iterativo, migliorando la sua capacità di prendere decisioni ottimali nel tempo.\n\n\n106.3.2 Limitazioni del Modello di Rescorla-Wagner\nNonostante la sua ampia applicabilità, il modello di Rescorla-Wagner presenta alcune limitazioni nel descrivere fenomeni complessi dell’apprendimento associativo, come il blocco retrospettivo e l’apprendimento latente.\n\nBlocco retrospettivo: È un fenomeno in cui l’apprendimento di una nuova associazione tra uno stimolo e una conseguenza può essere inibito se uno stimolo già noto è associato alla stessa conseguenza. Ad esempio, se un agente ha imparato che uno stimolo A predice una ricompensa e successivamente gli viene presentato uno stimolo composto AB seguito dalla stessa ricompensa, l’agente potrebbe non apprendere l’associazione tra B e la ricompensa.\nApprendimento latente: Riguarda l’acquisizione di conoscenze che non si manifestano immediatamente nel comportamento. Per esempio, un agente che esplora un labirinto senza ricompense apparenti può sembrare non imparare nulla. Tuttavia, quando viene introdotta una ricompensa, l’agente dimostra rapidamente di aver appreso la struttura del labirinto.\n\nIl modello di Rescorla-Wagner, che si basa esclusivamente sull’errore di previsione immediato, non è in grado di spiegare completamente questi fenomeni. Modelli più avanzati cercano di superare queste limitazioni mantenendo la semplicità e l’eleganza del modello originale.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#algoritmi-upper-confidence-bound-ucb-e-thompson-sampling",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#algoritmi-upper-confidence-bound-ucb-e-thompson-sampling",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.4 Algoritmi Upper Confidence Bound (UCB) e Thompson Sampling",
    "text": "106.4 Algoritmi Upper Confidence Bound (UCB) e Thompson Sampling\nGli algoritmi UCB e Thompson Sampling sono maggiormente utilizzati nel campo dell’intelligenza artificiale.\n\n106.4.1 Upper Confidence Bound (UCB)\nL’algoritmo UCB (Upper Confidence Bound) bilancia esplorazione e sfruttamento per scegliere le azioni migliori in un contesto di apprendimento per rinforzo. Per ogni azione \\(\\pi\\), l’algoritmo UCB calcola un valore chiamato “limite superiore di confidenza” che tiene conto sia della ricompensa stimata sia dell’incertezza di tale stima. La formula è:\n\\[ \\text{UCB}(\\pi) = \\hat{r}(\\pi) + \\sqrt{\\frac{2 \\log t}{n(\\pi)}} \\]\ndove:\n\n\\(\\hat{r}(\\pi)\\) è la ricompensa stimata per l’azione \\(\\pi\\).\n\\(t\\) è il turno corrente.\n\\(n(\\pi)\\) è il numero di volte che l’azione \\(\\pi\\) è stata scelta.\n\nIl termine \\(\\sqrt{\\frac{2 \\log t}{n(\\pi)}}\\) rappresenta l’incertezza della stima. Più un’azione viene scelta, più diminuisce l’incertezza, e quindi il termine di esplorazione si riduce.\nL’algoritmo seleziona l’azione con il valore UCB più alto. Questo approccio permette di esplorare nuove azioni ma anche di sfruttare quelle che sembrano offrire le migliori ricompense, garantendo un buon equilibrio tra esplorazione e sfruttamento.\n\n\n106.4.2 Thompson Sampling\nL’algoritmo Thompson Sampling bilancia esplorazione e sfruttamento scegliendo probabilisticamente le azioni in base alla loro probabilità di essere ottimali. Per ogni azione \\(\\pi\\), una ricompensa viene campionata dalla distribuzione a posteriori della sua ricompensa attesa. L’azione con il valore campionato più alto viene scelta. Questo approccio bilancia efficacemente esplorazione (provando azioni meno certe) e sfruttamento (scegliendo l’azione che attualmente sembra la migliore).",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#contextual-bandits",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#contextual-bandits",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.5 Contextual Bandits",
    "text": "106.5 Contextual Bandits\nI contextual bandits rappresentano un’evoluzione rispetto ai tradizionali problemi multi-armed bandit, offrendo un framework più realistico per il processo decisionale interattivo in scenari complessi. Mentre i multi-armed bandits si concentrano sulla scelta ripetuta tra diverse opzioni fisse, i contextual bandits introducono un nuovo elemento: il contesto. In questo scenario, prima di prendere una decisione, l’agente osserva informazioni contestuali che possono influenzare la scelta ottimale.\n\n106.5.1 Il Protocollo dei Contextual Bandits\nIl processo decisionale nei contextual bandits si svolge come segue:\n\nL’agente osserva un contesto \\(x_t\\) (ad esempio, le caratteristiche di una situazione sociale per una persona con anoressia nervosa).\nBasandosi su questo contesto, l’agente seleziona un’azione \\(\\pi_t\\) (ad esempio, la scelta di mangiare o meno in quella situazione).\nL’agente riceve una ricompensa \\(r_t\\) (ad esempio, il livello di ansia o controllo percepito dopo la scelta).\n\nQuesto processo si ripete per \\(T\\) turni.\n\n\n106.5.2 Modello Matematico\n\nLe ricompense sono generate secondo una distribuzione condizionale \\(r_t \\sim \\mathcal{M}^*(\\cdot | x_t, \\pi_t)\\), il che significa che la ricompensa \\(r_t\\) è distribuita secondo una certa legge \\(\\mathcal{M}^*\\) che varia a seconda del contesto e dell’azione.\nLa funzione di ricompensa media \\(f^*(x, \\pi)\\) rappresenta il valore atteso della ricompensa data un certo contesto \\(x\\) e una certa azione \\(\\pi\\).\nLa politica ottimale \\(\\pi^*(x) = \\arg\\max_{\\pi} f^*(x, \\pi)\\) indica che, per ogni contesto \\(x\\), cerchiamo l’azione \\(\\pi\\) che dà la ricompensa media più alta.\n\nL’obiettivo di un agente che utilizza contextual bandits è minimizzare il “regret”. Il “regret” è la differenza tra la ricompensa che avremmo ottenuto se avessimo sempre scelto l’azione ottimale e la ricompensa che abbiamo effettivamente ottenuto.\n\n\n106.5.3 Esempio: Anoressia Nervosa\nConsideriamo un esempio legato all’anoressia nervosa (AN). L’approccio dei contextual bandits può spiegare perché le persone affette da AN mostrano un apprendimento per rinforzo (RL) compromesso in contesti legati al cibo e al corpo, mentre mostrano un RL adeguato in contesti non legati al cibo e al corpo.\nImmaginiamo due scenari distinti:\nScenario 1: Contesto legato al cibo\n\nContesto (\\(x_t\\)): Una persona con AN si trova a una cena con amici dove è presente una varietà di cibi.\nAzione (\\(\\pi_t\\)): La persona deve decidere se mangiare un certo cibo.\nRicompensa (\\(r_t\\)): La ricompensa potrebbe essere misurata in termini di ansia percepita, con alti livelli di ansia che indicano una bassa ricompensa.\n\nIn questo contesto, la persona con AN potrebbe avere una funzione di ricompensa media \\(f^*(x, \\pi)\\) che penalizza fortemente le azioni legate al consumo di cibo, a causa delle elevate preoccupazioni legate al peso e all’immagine corporea. Di conseguenza, l’apprendimento per rinforzo sarà compromesso perché la ricompensa attesa per le azioni legate al cibo è molto bassa.\nScenario 2: Contesto non legato al cibo\n\nContesto (\\(x_t\\)): La stessa persona con AN si trova in una situazione di lavoro dove deve decidere come completare un compito.\nAzione (\\(\\pi_t\\)): La persona deve decidere quale strategia usare per completare il compito.\nRicompensa (\\(r_t\\)): La ricompensa potrebbe essere misurata in termini di successo o soddisfazione per il compito completato, con alti livelli di successo che indicano una alta ricompensa.\n\nIn questo contesto, la funzione di ricompensa media \\(f^*(x, \\pi)\\) non è influenzata dalle preoccupazioni legate al cibo o al corpo. Pertanto, la persona con AN può imparare efficacemente quale azione porta alla ricompensa massima, mostrando un apprendimento per rinforzo adeguato.\nQuesto esempio mostra come i contextual bandits possano spiegare le differenze nell’apprendimento per rinforzo in base al contesto, fornendo un quadro più completo e realistico delle dinamiche decisionali nelle persone con anoressia nervosa.\nIn sintesi, i contextual bandits sono un framework di RL che considera il contesto (o stato) quando si sceglie un’azione, ma non considera gli effetti a lungo termine delle azioni o come le azioni influenzano gli stati futuri.\n\n\n106.5.4 Rigidità Cognitiva e Difficoltà di RL nell’Anoressia Nervosa\nLa rigidità cognitiva nelle decisioni legate a cibo e corpo può essere spiegata in termini di RL come segue:\n\nSovrastima delle ricompense immediate: Le azioni che portano a sensazioni di controllo o riduzione dell’ansia a breve termine (es. restrizione calorica) ricevono un “peso” eccessivo nel processo decisionale.\nSottostima delle ricompense a lungo termine: Le conseguenze positive di un’alimentazione sana o di un’immagine corporea più realistica vengono sottovalutate o ignorate.\nEsplorazione limitata: La persona potrebbe evitare di esplorare nuove azioni (es. mangiare cibi temuti) a causa dell’ansia associata, limitando così l’apprendimento.\nAggiornamento selettivo del modello: Nel caso di apprendimento model-based, la persona potrebbe aggiornare selettivamente il suo modello interno, dando più peso alle informazioni che confermano le sue convinzioni sulla necessità di controllo sul cibo e sul corpo.\n\n\n\n106.5.5 Contextual Bandits nel Contesto dell’Anoressia Nervosa\nUtilizzando il framework dei contextual bandits, possiamo vedere come una persona con anoressia possa mostrare un apprendimento per rinforzo adeguato in alcuni contesti, ma un apprendimento per rinforzo alterato e rigido in situazioni legate al cibo e al corpo. In contesti legati al cibo, l’ansia e la preoccupazione per il controllo del peso e dell’immagine corporea influenzano negativamente la percezione delle ricompense, portando a decisioni che evitano il cibo e rafforzano comportamenti dannosi.\nAl contrario, in contesti non legati al cibo, dove queste preoccupazioni non sono presenti, la persona con anoressia può fare scelte basate su un’analisi più razionale delle ricompense, mostrando un apprendimento per rinforzo normale. Questo dualismo nell’apprendimento decisionale evidenzia come il contesto giochi un ruolo cruciale nelle scelte di una persona con anoressia, spiegando perché possa avere una rigida resistenza al cambiamento in situazioni legate al cibo e al corpo, ma decisioni più flessibili e adeguate in altri ambiti della vita.\nQuesta prospettiva aiuta a spiegare perché le persone con anoressia possono mostrare capacità decisionali normali in molti ambiti della vita, ma una marcata rigidità e resistenza al cambiamento quando si tratta di decisioni legate all’alimentazione e all’immagine corporea.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#simulare-lapprendimento",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#simulare-lapprendimento",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.6 Simulare l’Apprendimento",
    "text": "106.6 Simulare l’Apprendimento\nI modelli precedenti sono spesso chiamati semplicemente ‘modelli RL’ e costituiscono la base di molti studi sulla psicologia e neuroscienza dell’apprendimento guidato dalla ricompensa. In questo tutorial, simuleremo il processo decisionale di un partecipante che sceglie tra due slot machine, utilizzando il modello di apprendimento di Rescorla-Wagner. Questa simulazione ci aiuterà a comprendere come le persone apprendono e prendono decisioni in situazioni di incertezza.\nConfigurazione della simulazione:\n\nNumero di tentativi: \\(T = 100\\). Significa che il partecipante farà 100 scelte consecutive.\nNumero di slot machine: \\(K = 2\\). Il partecipante sceglierà tra due slot machine ad ogni tentativo.\nProbabilità di ricompensa: \\(\\mu = [0.2, 0.8]\\). Ciò significa che la Slot machine 1 ha yna probabilità pari a 0.2 di offrire una ricompensa, mentre la Slot machine 2 ha una probabilità pari a 0.8 di offrire una ricompensa.\n\nAttraverso questa simulazione, osserveremo come il partecipante inizialmente esplora entrambe le opzioni, come gradualmente apprende quale slot machine offre ricompense più frequenti e come adatta le proprie scelte per massimizzare le vincite complessive.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#esempio-di-calcolo-della-softmax",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#esempio-di-calcolo-della-softmax",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.7 Esempio di Calcolo della Softmax",
    "text": "106.7 Esempio di Calcolo della Softmax\nPer capire come funziona la softmax, consideriamo due valori di \\(Q\\) (aspettativa di ricompensa) e un valore fisso di \\(\\theta\\).\nLa funzione softmax trasforma i valori \\(Q\\) e \\(\\theta\\) in una distribuzione di probabilità, mostrando come la probabilità di scelta cambia al variare di \\(\\theta\\).\n\ndef softmax(Q, theta):\n    p = np.exp(theta * Q) / np.sum(np.exp(theta * Q))\n    return p\n\nConsideriamo una situazione in cui la seconda scelta ha un’aspettativa di valore tre volte maggiore la prima.\n\nQ = np.array([0.25, 0.75])\n\nEsaminiamo il caso di un valore \\(\\theta\\) alto.\n\ntheta = 3.5\n\n\nprint(softmax(Q, theta))\n\n[0.1480472 0.8519528]\n\n\nIn tali circostanze, la probabilità di scegliere la seconda azione è quasi sei volte maggiore quella di scegliere la prima azione.\n\n0.8519528 / 0.1480472\n\n5.754602586202238\n\n\nConsideriamo ora il caso in cui il valore \\(\\theta\\) è basso.\n\ntheta = 0.5\nprint(softmax(Q, theta))\n\n[0.4378235 0.5621765]\n\n\nIn tali circostanze, la probabilità di scegliere la seconda azione è appena maggiore di quella di scegliere la prima azione. Quando \\(\\theta\\) è zero, la probabilità di scegliere una delle due azioni è 0.5, indipendentemente dall’aspettativa di ricompensa delle due azioni.\n\ntheta = 0.0\nprint(softmax(Q, theta))\n\n[0.5 0.5]\n\n\nOra manteniamo fisso il valore di \\(Q\\) e facciamo variare \\(\\theta\\).\n\nQ = np.array([0.25, 0.75])\ntheta_values = np.linspace(0, 5, 100)\n\nprobabilities_list = []\nfor theta in theta_values:\n    probabilities = softmax(Q, theta)\n    probabilities_list.append(probabilities)\n\nprobabilities_array = np.array(probabilities_list).T\n\noption_labels = ['Opzione 1: Q = 0.25', 'Opzione 2: Q = 0.75']\n\nplt.figure()\nfor i in range(len(option_labels)):\n    plt.plot(theta_values, probabilities_array[i], label=option_labels[i])\nplt.xlabel('Theta')\nplt.ylabel('Probabilità')\nplt.title('Funzione Softmax - Modello Rescorla-Wagner')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nIl grafico risultante mostra come le probabilità di scelta cambiano al variare del parametro \\(\\theta\\). Quando \\(\\theta\\) è vicino a zero, la scelta è quasi casuale. Quando \\(\\theta\\) è molto grande, la scelta è quasi sempre l’opzione con il valore più alto.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#simulazione-del-modello-di-rescorla-wagner",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#simulazione-del-modello-di-rescorla-wagner",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.8 Simulazione del Modello di Rescorla-Wagner",
    "text": "106.8 Simulazione del Modello di Rescorla-Wagner\nCombiniamo la regola di apprendimento e la regola decisionale per simulare il comportamento del partecipante:\n\ndef simulate_RescorlaWagner(params, T, mu, noisy_choice=True):\n\n    alpha, theta = params\n    \n    # Un array di zeri di lunghezza T\n    c = np.zeros((T), dtype=int)\n    r = np.zeros((T), dtype=int)\n\n    # Un array multidimensionale di zeri di dimensione 2xT\n    Q_stored = np.zeros((2, T), dtype=float)\n    \n    # Inizializza Q per t == 0\n    Q = [0.5, 0.5]\n\n    for t in range(T):\n\n        # Salva i valori Q per Q_{t+1}\n        Q_stored[:, t] = Q\n\n        # Calcola le probabilità di scelta\n        p0 = np.exp(theta*Q[0]) / (np.exp(theta*Q[0]) + np.exp(theta*Q[1]))\n        p1 = 1 - p0\n        \n        # Se noisy_choice è vero, viene simulato un comportamento di scelta rumoroso in \n        # cui l'opzione 0 è scelta con probabilità p0, mentre l'opzione 1 è scelta con \n        # probabilità 1-p0.\n        if noisy_choice:\n            if np.random.random_sample(1) &lt; p0:\n                c[t] = 0\n            else:\n                c[t] = 1\n        else:  # la scelta viene effettuata senza rumore\n            c[t] = np.argmax([p0, p1])\n\n        # Genera la ricompensa sulla base delle probabilità di ricompensa\n        r[t] = np.random.rand() &lt; mu[c[t]]\n\n        # Aggiorna le aspettative di valore\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    return c, r, Q_stored\n\nSimuliamo T = 100 prove utilizzando il modello generativo dei dati definito in precedenza.\n\nT = 100\nK = 2\nmu = [0.2, 0.8]\n\n\nc, r, Q = simulate_RescorlaWagner([.1, 2.5], T=T, mu=mu)\n\nRappresentiamo graficamente i risultati ottenuti dalla simulazione.\n\nplt.plot(range(T), r, 'r--', alpha=.6)\nplt.plot(range(T), c, '+', label='scelta')\nplt.xlabel('Prove')\nplt.ylabel('Feedback (1=Ricompensa,\\n 0=Nessuna ricompensa)')\nplt.title(f'Apprendimento di Rescorla-Wagner')\nplt.show()\n\n\n\n\n\n\n\n\nCome possiamo osservare, le scelte per la slot machine che produce meno ricompense diventano meno frequenti nel corso delle prove.\nIl diagramma seguente illustra l’aggiornamento del valore \\(Q\\), mostrando come l’aspettativa di ricompensa delle due slot machine venga aggiornata in base all’errore di predizione nel corso delle prove.\n\nplt.plot(range(T), Q[1, :], \"r--\", alpha=0.6, label=\"80% machine\")\nplt.plot(range(T), Q[0, :], 'm-', alpha=.6, label='20% machine')\nplt.plot(range(T), c, 'b+', label='choice')\nplt.xlabel('trials')\nplt.ylabel('value')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nSi noti come nel corso delle prove i valori delle slot macchine convergano lentamente verso le probabilità di ricompensa (20% e 80%).\nIn sintesi, il modello di Rescorla-Wagner ci permette di simulare come le persone apprendono e prendono decisioni basate su ricompense. Utilizzando la regola di apprendimento (\\(\\delta\\)-rule) e la regola decisionale softmax, possiamo vedere come le aspettative di valore e le scelte cambiano nel tempo in risposta alle ricompense ottenute.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#adattamento-del-modello",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#adattamento-del-modello",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.9 Adattamento del Modello",
    "text": "106.9 Adattamento del Modello\nDopo aver compreso il funzionamento del modello di Rescorla-Wagner, il passo successivo consiste nello stimare i parametri del modello a partire dai dati osservati. Questo processo è cruciale nella modellazione computazionale poiché ci permette di determinare quali valori dei parametri descrivono meglio il comportamento osservato. Esistono diversi metodi per stimare i parametri. La sezione Appendice V mostra come implementare l’approccio della Massima Verosimiglianza. Qui illustreremo la stima dei parametri del modello Rescorla-Wagner utilizzando un metodo bayesiano, attraverso l’uso di Stan. Procediamo quindi a compilare il modello e a stampare il codice Stan.\n\nstan_file = os.path.join(project_directory, \"stan\", \"rescorla_wagner.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; nTrials; // numero di tentativi\n  array[nTrials] int&lt;lower=1, upper=2&gt; choice; // scelte effettuate (1 o 2)\n  array[nTrials] real&lt;lower=0, upper=1&gt; reward; // ricompense ricevute (0 o 1)\n}\ntransformed data {\n  vector[2] initV; // valori iniziali per V\n  initV = rep_vector(0.5, 2); // inizializzati a 0.5\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; alpha; // tasso di apprendimento\n  real&lt;lower=0&gt; theta; // temperatura\n}\nmodel {\n  vector[2] v; // valori attesi\n  real delta; // errore di previsione\n  \n  // Priori\n  alpha ~ beta(1, 1); // prior uniforme su [0, 1]\n  theta ~ normal(0, 10); // prior normale con media 0 e deviazione standard 10\n  \n  v = initV;\n  \n  for (t in 1 : nTrials) {\n    // Calcolo delle probabilità di scelta usando la funzione softmax con limitazione\n    vector[2] logits;\n    logits = theta * v;\n    logits = fmin(logits, 20); // Limita i valori massimi per evitare overflow\n    logits = fmax(logits, -20); // Limita i valori minimi per evitare underflow\n    \n    choice[t] ~ categorical_logit(logits);\n    \n    // Errore di previsione\n    delta = reward[t] - v[choice[t]];\n    \n    // Aggiornamento dei valori attesi (apprendimento)\n    v[choice[t]] = v[choice[t]] + alpha * delta;\n  }\n}\n\n\n\n\n106.9.1 Sezione data\nQuesta sezione definisce i dati che vengono forniti al modello:\n\nnTrials: Il numero totale di tentativi o scelte effettuate dal partecipante.\nchoice: Un array che contiene le scelte effettuate dal partecipante in ciascun tentativo (1 o 2).\nreward: Un array che contiene le ricompense ricevute per ciascun tentativo (0 o 1).\n\n\n\n106.9.2 Sezione transformed data\nQuesta sezione prepara alcuni dati iniziali trasformati per il modello. Qui initV è un vettore di lunghezza 2 che rappresenta i valori iniziali delle aspettative di ricompensa per le due opzioni, entrambi inizializzati a 0.5.\n\n\n106.9.3 Sezione parameters\nQuesta sezione definisce i parametri del modello che Stan cercherà di stimare:\n\nalpha: Il tasso di apprendimento, che determina quanto rapidamente il partecipante aggiorna le proprie aspettative. Questo valore è compreso tra 0 e 1.\ntheta: La temperatura, che controlla il livello di esplorazione (quanto spesso il partecipante sceglie l’opzione con il valore atteso più alto rispetto a esplorare altre opzioni). Questo valore è positivo.\n\n\n\n106.9.4 Sezione model\nLa sezione model del codice Stan è il cuore del modello, dove avviene il processo di stima e aggiornamento dei valori attesi in base ai dati osservati. Vediamo passo passo come funziona.\n\nInizializzazione.\n\nPartiamo con valori attesi uguali per entrambe le opzioni (v = [0.5, 0.5]).\nScegliamo valori casuali iniziali per alpha e theta.\n\nPer ogni tentativo dell’esperimento:\n\nCalcolo delle probabilità di scelta:\n\nlogits = theta * v;\nlogits = fmin(logits, 20);\nlogits = fmax(logits, -20);\n\nMoltiplichiamo i valori attesi per la temperatura.\nLimitiamo i risultati tra -20 e 20 per evitare problemi numerici.\n\nEsempio:\nSe v = [0.3, 0.7] e theta = 2:\n\nlogits = 2 * [0.3, 0.7] = [0.6, 1.4]\nNessun cambiamento dopo fmin e fmax perché i valori sono già tra -20 e 20.\n\n\nModellazione della scelta:\n\nchoice[t] ~ categorical_logit(logits);\n\nUsiamo i logits per calcolare le probabilità di scelta.\nLa funzione softmax converte i logits in probabilità.\n\nEsempio (continuazione):\n\nsoftmax([0.6, 1.4]) ≈ [0.38, 0.62]\nC’è il 38% di probabilità di scegliere la prima opzione e il 62% per la seconda.\n\n\nCalcolo dell’errore di previsione:\n\ndelta = reward[t] - v[choice[t]];\n\nConfrontiamo la ricompensa ricevuta con quanto ci aspettavamo.\nSe positivo, siamo stati piacevolmente sorpresi; se negativo, delusi.\n\nEsempio:\nSe scegliamo la seconda opzione e riceviamo una ricompensa di 1:\n\ndelta = 1 - 0.7 = 0.3\n\nSiamo stati leggermente sorpresi in positivo.\n\nAggiornamento dei valori attesi:\n\nv[choice[t]] = v[choice[t]] + alpha * delta;\n\nAggiorniamo la nostra aspettativa per l’opzione scelta.\nalpha determina quanto peso diamo alla nuova esperienza.\n\nEsempio (continuazione):\nSe alpha = 0.2:\n\nNuovo valore per la seconda opzione: 0.7 + 0.2 * 0.3 = 0.76\n\nLa nostra aspettativa per la seconda opzione è leggermente aumentata.\nRipetizione.\n\n\nRipetiamo i passaggi 2a-2d per ogni tentativo dell’esperimento.\nAd ogni iterazione, affiniamo le nostre stime di alpha e theta.\n\n\n\n106.9.5 Inferenza\nConsidereremo qui i dati di un singolo partecipante che esegue 300 prove. Definiamo i parametri della simulazione:\n\nparams = [0.1, 2.5]  # alpha, theta\nT = 300  # numero di tentativi\nmu = [0.2, 0.8]  # probabilità di ricompensa per le due opzioni\n\nSimuliamo i dati:\n\nchoices, rewards, Q_stored = simulate_RescorlaWagner(params, T, mu)\n\nPrepariamo i dati per Stan. Si noti che abbiamo sommato 1 a choices per adattarsi agli indici di Stan che partono da 1.\n\nc = choices + 1\n\nstan_data = {\n    'nTrials': T,\n    'choice': c.tolist(),\n    'reward': rewards.tolist()\n}\nprint(stan_data)\n\n{'nTrials': 300, 'choice': [1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2], 'reward': [0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]}\n\n\nEseguiamo il campionamento:\n\ntrace = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=123,\n    show_progress=False,\n    show_console=False\n)\n\n16:00:53 - cmdstanpy - INFO - CmdStan start processing\n16:00:53 - cmdstanpy - INFO - Chain [1] start processing\n16:00:53 - cmdstanpy - INFO - Chain [2] start processing\n16:00:53 - cmdstanpy - INFO - Chain [3] start processing\n16:00:53 - cmdstanpy - INFO - Chain [4] start processing\n16:00:56 - cmdstanpy - INFO - Chain [3] done processing\n16:00:56 - cmdstanpy - INFO - Chain [2] done processing\n16:00:56 - cmdstanpy - INFO - Chain [1] done processing\n16:00:56 - cmdstanpy - INFO - Chain [4] done processing\n\n\nEsaminiamo le distribuzioni a posteriori dei due parametri oggetto dell’inferenza insieme alle loro tracce (cioè i vettori dei campioni dei parametri \\(\\alpha\\) e \\(\\theta\\) prodotti dalla procedura di campionamento MCMC) mediante un trace plot .\n\n_ = az.plot_trace(trace)\n\n\n\n\n\n\n\n\n\n\n106.9.6 Interpretazione delle Stime dei Parametri\nUtilizzando az.summary(trace, hdi_prob=0.94, round_to=2), otteniamo un riassunto delle stime dei parametri del modello, che include la media, la deviazione standard, gli intervalli di credibilità (HDI) e altre statistiche diagnostiche:\n\naz.summary(trace, hdi_prob=0.94, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n0.13\n0.08\n0.02\n0.27\n0.00\n0.00\n1973.89\n1757.85\n1.0\n\n\ntheta\n2.70\n0.41\n2.01\n3.46\n0.01\n0.01\n2095.86\n1581.69\n1.0\n\n\n\n\n\n\n\nCon 300 prove, le stime dei parametri fornite dal modello sono adeguate:\n\nL’intervallo di credibilità al 94% (hdi_3% - hdi_97%) include il valore simulato del parametro. Questo significa che le stime del modello sono coerenti con i parametri originali usati nella simulazione.\nLa deviazione standard della stima a posteriori è relativamente piccola, indicando che le stime sono precise.\nI valori di r_hat sono vicini a 1, indicando che le catene di campionamento sono ben mescolate e hanno ottenuto la convergenza.\n\nQuesti risultati suggeriscono che il modello di apprendimento di Rescorla-Wagner ha stimato correttamente i parametri \\(\\alpha\\) e \\(\\theta\\) dai dati simulati.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#apprendimento-probabilistico-e-reversal-learning",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#apprendimento-probabilistico-e-reversal-learning",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.10 Apprendimento Probabilistico e Reversal Learning",
    "text": "106.10 Apprendimento Probabilistico e Reversal Learning\nUn paradigma sperimentale particolarmente interessante per indagare i meccanismi dell’apprendimento umano è il Probabilistic Reversal Learning (Caudek et al., 2020, 2021). In questo compito, le associazioni tra stimoli e outcomes vengono invertite a metà della procedura sperimentale. Ad esempio, se inizialmente lo stimolo A era associato a una ricompensa, in seguito questa associazione può essere invertita, rendendo lo stimolo A svantaggioso.\nL’apprendimento per rinforzo offre un solido quadro teorico per comprendere come gli individui si adattano a tali cambiamenti. Modelli computazionali come quello di Rescorla-Wagner possono essere impiegati per simulare questo tipo di apprendimento e per studiare i processi cognitivi sottostanti.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#incertezza-attesa-vs.-incertezza-non-attesa",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#incertezza-attesa-vs.-incertezza-non-attesa",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.11 Incertezza Attesa vs. Incertezza Non Attesa",
    "text": "106.11 Incertezza Attesa vs. Incertezza Non Attesa\nNel contesto dell’apprendimento per rinforzo e dei modelli come quello di Rescorla-Wagner, è fondamentale distinguere tra incertezza attesa e incertezza non attesa, poiché influenzano in modo diverso il processo di apprendimento.\n\nIncertezza Attesa: L’incertezza attesa si riferisce alla variabilità che esiste a causa della natura probabilistica delle ricompense, anche quando le condizioni dell’ambiente rimangono invariate. Ad esempio, se un agente sa che un’azione A ha una probabilità dell’80% di fornire una ricompensa positiva e del 20% di fornire una ricompensa negativa, l’incertezza attesa deriva dal fatto che, nonostante la conoscenza delle probabilità, l’esito di ogni singola azione rimane imprevedibile. In altre parole, anche se l’agente sa che un’azione è generalmente buona, non può prevedere con certezza il risultato di ogni tentativo. Questo tipo di incertezza è considerato “irreducibile” perché non può essere eliminato semplicemente con l’accumulo di esperienze.\nIncertezza Non Attesa: L’incertezza non attesa, invece, si riferisce alla variabilità che emerge quando le condizioni o le regole dell’ambiente cambiano in modo imprevisto. Ad esempio, se un’azione A che di solito porta a una ricompensa positiva improvvisamente inizia a portare a una ricompensa negativa, l’incertezza non attesa deriva da questo cambiamento inatteso. Questo tipo di incertezza richiede che l’agente aggiorni rapidamente le sue aspettative e strategie, poiché le informazioni precedenti non sono più valide. L’incertezza non attesa è quindi legata alla “volatilità” dell’ambiente e alla necessità di adattarsi ai cambiamenti.\n\nIn sintesi, l’incertezza attesa riguarda la variabilità nelle ricompense che è già nota e considerata nel processo decisionale dell’agente, mentre l’incertezza non attesa implica un cambiamento nelle regole dell’ambiente che richiede un adattamento rapido. Comprendere la differenza tra questi due tipi di incertezza è cruciale per modellare accuratamente il comportamento di apprendimento e prendere decisioni ottimali in ambienti dinamici.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#anomalie-dellapprendimento",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#anomalie-dellapprendimento",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.12 Anomalie dell’apprendimento",
    "text": "106.12 Anomalie dell’apprendimento\nL’uso dei modelli di apprendimento per rinforzo, come il modello di Rescorla-Wagner, ha importanti implicazioni per comprendere le anomalie dell’apprendimento nelle patologie psicologiche, come l’ansia e la depressione (Pulcu & Browning, 2019). Questi modelli aiutano a spiegare come le persone con disturbi affettivi possano avere difficoltà a stimare correttamente l’incertezza, sia attesa che non attesa, riguardo agli esiti delle loro azioni.\nAd esempio, una sovrastima dell’incertezza attesa o una sottostima dell’incertezza non attesa può rendere un individuo meno reattivo agli eventi recenti e più lento nell’adattarsi a cambiamenti importanti, specialmente in ambienti dinamici e poco rumorosi. Al contrario, una sottostima dell’incertezza attesa o una sovrastima dell’incertezza non attesa può portare a una maggiore influenza degli eventi recenti e a credenze instabili, specialmente in ambienti stabili ma rumorosi. Questa errata stima dell’incertezza può ridurre la capacità di un individuo di tracciare accuratamente lo stato degli ambienti dinamici e, di conseguenza, scegliere le azioni più adatte per ottenere risultati positivi o evitare quelli negativi.\nInoltre, la tendenza a sopravvalutare l’incertezza non attesa degli esiti negativi rispetto a quelli positivi può portare a un’influenza maggiore degli eventi negativi, un profilo cognitivo tipico dell’ansia e della depressione. Studi recenti suggeriscono che i bias nella stima dell’incertezza potrebbero fornire un collegamento meccanicistico tra gli aspetti cognitivi interni della depressione e dell’ansia e i fattori di rischio esterni, come l’esposizione a esperienze avverse. Pertanto, l’integrazione di modelli di apprendimento per rinforzo come il Rescorla-Wagner nelle ricerche cliniche può offrire nuove prospettive per comprendere e trattare questi disturbi (Browning et al., 2015).",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#commenti-e-considerazioni-finali",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#commenti-e-considerazioni-finali",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.13 Commenti e considerazioni finali",
    "text": "106.13 Commenti e considerazioni finali\nIn precedenza abbiamo esaminato il modello di regressione. Sebbene il modello di regressione sia estremamente popolare in psicologia e nelle scienze sociali, presenta dei limiti sostanziali. È utile per descrivere le associazioni tra variabili, ma non è adatto per scoprire nessi causali, che rappresentano l’obiettivo principale delle teorie scientifiche. Come afferma Richard McElreath:\n\nLe persone una volta facevano teoria. Ora fanno solo regressioni.\n\nTrovare associazioni nei dati osservazionali non è un buon metodo per costruire teorie. Abbiamo bisogno di una motivazione per esaminare determinate variabili, poiché le associazioni tra variabili non sono rare, ma raramente ci informano sulle relazioni causali.\nUn approccio preferibile è utilizzare una teoria formale per sviluppare aspettative sui dati osservati, misurare le variabili rilevanti e utilizzare modelli statistici specifici per testare la teoria.\nL’apprendimento per rinforzo offre un potente framework per studiare come gli organismi apprendono dall’interazione con l’ambiente. Modelli come quello di Rescorla-Wagner e algoritmi come UCB e Thompson Sampling forniscono strumenti utili per comprendere i processi cognitivi sottostanti l’apprendimento associativo e per sviluppare agenti intelligenti. Questi modelli hanno raggiunto un notevole successo, fornendo spiegazioni computazionali sia per fenomeni di apprendimento di base che complessi (M. K. Eckstein & Collins, 2020; Frank & Badre, 2012).\nTuttavia, è importante riconoscere alcune limitazioni di questi modelli di apprendimento per rinforzo. La letteratura scientifica ha infatti accumulato una serie di osservazioni che questi modelli faticano a spiegare adeguatamente (M. Eckstein et al., s.d.). In primo luogo, eventi singoli del passato possono influenzare il comportamento in modo sproporzionato (Bornstein & Norman, 2017; Duncan & Shohamy, 2016; Schulz & Gershman, 2019). Questo suggerisce che la memoria rilevante per il compito contiene più che semplici statistiche riassuntive come i Q-values. In altre parole, le esperienze passate possono avere un impatto duraturo e significativo sulle decisioni future, anche se non riflesse nei valori medi appresi. In secondo luogo, il comportamento è spesso sensibile a statistiche globali del passato, come l’intervallo di ricompense ricevute o il raggruppamento delle opzioni di scelta (Khaw et al., 2017; Palminteri et al., 2015). Questi aspetti non sono facilmente catturati dai modelli standard di apprendimento per rinforzo, che tendono a concentrarsi su valori specifici per ogni azione piuttosto che su pattern più ampi. Infine, i segnali neurali precedentemente ritenuti direttamente correlati ai Q-values hanno mostrato una marcata diversità che è in contrasto con le previsioni dei modelli standard di apprendimento per rinforzo (Yaple & Yu, 2019). Questa variabilità suggerisce che i processi neurali sottostanti alle decisioni basate su ricompense sono più complessi di quanto inizialmente si pensasse.\nNell’insieme, questi risultati indicano che le rappresentazioni mnemoniche utilizzate da esseri umani e animali per prendere decisioni basate su ricompense vanno oltre le semplici statistiche riassuntive apprese in modo incrementale e associate a singole azioni. È probabile che queste decisioni si basino su una varietà di meccanismi di memoria interni aggiuntivi, che permettono una rappresentazione più ricca e sfumata delle esperienze passate e del contesto decisionale. Questa complessità sottolinea la necessità di sviluppare modelli più sofisticati che possano catturare la ricchezza dei processi decisionali osservati negli organismi biologici, integrando aspetti di memoria episodica, sensibilità al contesto e variabilità nei segnali neurali.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#esercizi",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#esercizi",
    "title": "106  Apprendimento per rinforzo",
    "section": "106.14 Esercizi",
    "text": "106.14 Esercizi\n\nEsercizio 106.1 Implementa una funzione Python softmax che prende in input un array di valori attesi Q per ciascuna azione e un parametro di temperatura theta. La funzione deve restituire un array di probabilità che rappresenta la probabilità di selezione di ciascuna azione.\nLa formula della regola softmax è la seguente:\n\\[ p_i = \\frac{e^{\\theta Q_i}}{\\sum_{j} e^{\\theta Q_j}}, \\]\ndove \\(p_i\\) è la probabilità di selezionare l’azione \\(i\\), \\(Q_i\\) è il valore atteso dell’azione \\(i\\), \\(\\theta\\) è il parametro di temperatura che controlla il livello di esplorazione.\nUtilizza:\nQ = np.array([0.25, 0.75])\ntheta_values = [0.1, 1, 2, 5]\nQuesto esercizio fornisce una comprensione pratica di come la regola softmax bilancia esplorazione e sfruttamento nei modelli di apprendimento per rinforzo.\n\n\nEsercizio 106.2 L’obiettivo di questo esercizio è implementare il calcolo dell’errore di previsione nel modello di Rescorla-Wagner. Implementa una funzione Python update_value(Q, R, alpha) che prende in input il valore atteso attuale Q, la ricompensa ricevuta R, il tasso di apprendimento alpha, e restituisce il nuovo valore atteso aggiornato. La funzione deve anche restituire l’errore di previsione.\nIl valore atteso \\(Q\\) viene aggiornato secondo la seguente formula:\n\\[ \\Delta Q = \\alpha (R - Q), \\]\ndove \\(\\Delta Q\\) è la variazione del valore atteso, \\(\\alpha\\) è il tasso di apprendimento, \\(R\\) è la ricompensa ricevuta, \\(Q\\) è il valore atteso attuale.\nIl nuovo valore atteso \\(Q'\\) è dato da \\(Q' = Q + \\Delta Q\\).\nUsa:\nQ = 0.5  # Valore atteso iniziale\nR_values = [1, 0, 1, 1, 0]  # Sequenza di ricompense ricevute\nalpha = 0.1  # Tasso di apprendimento\nQuesto esercizio fornisce una comprensione pratica di come il modello di Rescorla-Wagner utilizza l’errore di previsione per aggiornare le aspettative di ricompensa.\n\n\nEsercizio 106.3 L’obiettivo di questo esercizio è comprendere e interpretare i parametri del modello di apprendimento di Rescorla-Wagner. Considera i seguenti scenari in cui un agente sta apprendendo a fare delle scelte basate sulle ricompense ricevute. Per ciascuno scenario, descrivi come il tasso di apprendimento (alpha) e il valore iniziale atteso (Q_0) potrebbero influenzare il comportamento dell’agente.\n\nScenario 1: Apprendimento Rapido in un Ambiente Stabile Un cane sta imparando a eseguire un nuovo trucco e riceve sempre una ricompensa (un bocconcino) ogni volta che esegue il trucco correttamente.\nScenario 2: Apprendimento Lento in un Ambiente Stabile Un bambino sta imparando a risolvere puzzle semplici. Ogni volta che completa un puzzle, riceve una stella adesiva come ricompensa.\nScenario 3: Apprendimento in un Ambiente Variabile Un giocatore di un videogioco sta cercando di capire quale arma è la migliore contro diversi nemici. Le ricompense (punteggi) per l’uso delle armi variano in modo imprevedibile.\nScenario 4: Apprendimento con Informazioni Iniziali Parziali Un ricercatore che ha una conoscenza preliminare su quale farmaco potrebbe funzionare meglio sta conducendo un esperimento per confermare la sua ipotesi.\n\n\n\nEsercizio 106.4 L’obiettivo di questo esercizio è analizzare come il modello di Rescorla-Wagner può essere applicato in diversi contesti di apprendimento e come le variazioni nelle condizioni ambientali e nelle caratteristiche dell’agente possono influenzare l’efficacia dell’apprendimento.\nPer ciascuno dei seguenti contesti di apprendimento, descrivi come l’errore di previsione e l’aggiornamento del valore atteso influenzerebbero il comportamento dell’agente. Discuti anche eventuali limitazioni del modello di Rescorla-Wagner nel catturare tutti gli aspetti del processo di apprendimento in quel contesto.\n\nContesto 1: Addestramento di un Animale Domestico Un cane viene addestrato a eseguire un comando specifico, come “seduto”. Ogni volta che il cane esegue correttamente il comando, riceve una ricompensa.\nContesto 2: Apprendimento Scolastico Uno studente sta imparando una nuova materia a scuola. Riceve un feedback positivo o negativo (es. voti) in base alle sue prestazioni nei compiti e nelle verifiche.\nContesto 3: Terapia Comportamentale Un terapeuta utilizza tecniche di rinforzo per aiutare un paziente a superare una fobia. Il paziente riceve rinforzi positivi ogni volta che riesce ad affrontare la situazione temuta senza evitare.\nContesto 4: Apprendimento nelle Organizzazioni Un’azienda implementa un sistema di premi per i dipendenti che raggiungono determinati obiettivi di performance. I dipendenti ricevono bonus e riconoscimenti in base ai risultati raggiunti.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/03_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/03_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "title": "106  Apprendimento per rinforzo",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun Aug 18 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBornstein, A. M., & Norman, K. A. (2017). Reinstated episodic context guides sampling-based decisions for reward. Nature Neuroscience, 20(7), 997–1003.\n\n\nBrowning, M., Behrens, T. E., Jocham, G., O’reilly, J. X., & Bishop, S. J. (2015). Anxious individuals have difficulty learning the causal statistics of aversive environments. Nature Neuroscience, 18(4), 590–596.\n\n\nCaudek, C., Sica, C., Cerea, S., Colpizzi, I., & Stendardi, D. (2021). Susceptibility to eating disorders is associated with cognitive inflexibility in female university students. Journal of Behavioral and Cognitive Therapy, 31(4), 317–328.\n\n\nCaudek, C., Sica, C., Marchetti, I., Colpizzi, I., & Stendardi, D. (2020). Cognitive inflexibility specificity for individuals with high levels of obsessive-compulsive symptoms. Journal of Behavioral and Cognitive Therapy, 30(2), 103–113.\n\n\nDuncan, K. D., & Shohamy, D. (2016). Memory states influence value-based decisions. Journal of Experimental Psychology: General, 145(11), 1420.\n\n\nEckstein, M. K., & Collins, A. G. (2020). Computational evidence for hierarchically structured reinforcement learning in humans. Proceedings of the National Academy of Sciences, 117(47), 29381–29389.\n\n\nEckstein, M., Summerfield, C., Daw, N., & Miller, K. J. (s.d.). Hybrid Neural-Cognitive Models Reveal How Memory Shapes Human Reward Learning.\n\n\nFrank, M. J., & Badre, D. (2012). Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis. Cerebral Cortex, 22(3), 509–526.\n\n\nKhaw, M. W., Glimcher, P. W., & Louie, K. (2017). Normalized value coding explains dynamic adaptation in the human valuation process. Proceedings of the National Academy of Sciences, 114(48), 12696–12701.\n\n\nPalminteri, S., Khamassi, M., Joffily, M., & Coricelli, G. (2015). Contextual modulation of value signals in reward and punishment learning. Nature Communications, 6(1), 8096.\n\n\nPulcu, E., & Browning, M. (2019). The misestimation of uncertainty in affective disorders. Trends in Cognitive Sciences, 23(10), 865–875.\n\n\nRescorla, R. A., & Wagner, A. R. (1972). A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and non-reinforcement. Classical conditioning II, Current research and theory, 2, 64–69.\n\n\nSchulz, E., & Gershman, S. J. (2019). The algorithmic architecture of exploration in the human brain. Current Opinion in Neurobiology, 55, 7–14.\n\n\nSoto, F. A., Vogel, E. H., Uribe-Bahamonde, Y. E., & Perez, O. D. (2023). Why is the Rescorla-Wagner model so influential? Neurobiology of Learning and Memory, 204, 107794.\n\n\nSutton, R. S., & Barto, A. G. (2018). Reinforcement Learning: an introduction, second edi. The MIT Press.\n\n\nYaple, Z. A., & Yu, R. (2019). Fractionating adaptive learning: A meta-analysis of the reversal learning paradigm. Neuroscience & Biobehavioral Reviews, 102, 85–94.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html",
    "href": "chapters/dynamic_models/04_affect.html",
    "title": "107  Le emozioni influenzano le emozioni",
    "section": "",
    "text": "107.1 Introduzione\nL’obiettivo di questo capitolo è implmentare e commenatare la proposta di Cipresso et al. (2023) relativa all’uso delle catene di Markov per lo studio degli stati affettivi.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#la-modellizzazione-degli-stati-affettivi",
    "href": "chapters/dynamic_models/04_affect.html#la-modellizzazione-degli-stati-affettivi",
    "title": "107  Le emozioni influenzano le emozioni",
    "section": "107.2 La Modellizzazione degli Stati Affettivi",
    "text": "107.2 La Modellizzazione degli Stati Affettivi\nNegli studi di psicologia, il termine “affetto” è utilizzato per descrivere uno stato globale che comprende una vasta gamma di fenomeni, tra cui emozioni, sentimenti e stati d’animo. Gli stati affettivi, in particolare, si riferiscono allo stato emotivo o umore attuale di un individuo in relazione ai suoi obiettivi adattativi. Un’importante contribuzione alla comprensione degli stati affettivi è stata fornita dal modello circomplesso di Russell (1980), che rappresenta le emozioni su un piano bidimensionale, con “attivazione” (arousal) su un asse e “valenza” (valence) sull’altro. Questo modello permette di caratterizzare ogni emozione in base all’intensità dell’esperienza emotiva e alla sua natura positiva o negativa.\nAd esempio, la tristezza è considerata un’emozione con valenza negativa e bassa attivazione, mentre la gioia è vista come un’emozione con valenza positiva e attivazione medio-alta. Negli ultimi vent’anni, sono stati sviluppati numerosi stimoli per studiare questi stati affettivi in modo dettagliato, utilizzando immagini, video, suoni, narrazioni, situazioni reali, realtà virtuale e musica.\nTuttavia, trattare gli affetti come stati indipendenti può non rappresentare accuratamente la complessità della vita reale, dove gli stati emotivi influenzano quelli successivi. Per esempio, uno studente che si sente stressato all’inizio di un esame può continuare a sentirsi stressato durante le fasi successive, rendendo difficile concentrarsi e rispondere alle domande. In questo contesto, è fondamentale riconoscere come gli stati affettivi siano interconnessi e come uno stato possa influenzare quello successivo.\nQuesto ha portato alla necessità di utilizzare modelli matematici più complessi, come il modello di Markov, per rappresentare le transizioni tra stati affettivi. Questi modelli permettono di analizzare in modo più realistico le dinamiche degli stati affettivi, prendendo in considerazione la continuità e l’influenza reciproca degli stati emotivi nel tempo.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#un-processo-stocastico-per-le-dinamiche-degli-stati-affettivi",
    "href": "chapters/dynamic_models/04_affect.html#un-processo-stocastico-per-le-dinamiche-degli-stati-affettivi",
    "title": "107  Le emozioni influenzano le emozioni",
    "section": "107.3 Un Processo Stocastico per le Dinamiche degli Stati Affettivi",
    "text": "107.3 Un Processo Stocastico per le Dinamiche degli Stati Affettivi\nUna catena di Markov è un processo stocastico utilizzato per modellare le dinamiche degli stati affettivi. In termini semplici, è un modello matematico in cui la probabilità di passare da uno stato a un altro dipende solo dallo stato attuale, e non dalla sequenza di eventi precedenti. Questo significa che il futuro stato del sistema è determinato solo dalla sua situazione presente.\n\n107.3.1 Matrice di Transizione\nPer descrivere matematicamente le transizioni tra stati affettivi, utilizziamo una matrice di transizione. Questa matrice rappresenta le probabilità di passaggio da uno stato all’altro. Ad esempio, se abbiamo quattro stati affettivi (rilassato, stressato, impegnato e annoiato), la matrice di transizione mostrerà le probabilità di passare da uno di questi stati a un altro. La somma delle probabilità in ogni riga della matrice deve essere pari a 1, poiché il sistema deve sempre trovarsi in uno degli stati.\nLa matrice di transizione può essere utilizzata per calcolare la probabilità che il sistema si trovi in un determinato stato dopo un certo numero di passaggi. Ad esempio, se la probabilità di essere nello stato A è 0.6 e la probabilità di passare da A a B è 0.3, la probabilità di essere nello stato B dopo un passaggio sarà 0.18 (0.3 * 0.6).\n\n\n107.3.2 Stato Stazionario e Grafici Diretti\nDopo un certo numero di passaggi, la catena di Markov può raggiungere uno stato stazionario, in cui le probabilità di essere in ciascuno stato non cambiano più. Questo stato stazionario può essere utilizzato per capire il comportamento a lungo termine del sistema.\nLe transizioni tra stati affettivi possono anche essere rappresentate graficamente tramite un grafo diretto, dove ogni stato è un nodo e ogni transizione è un arco diretto. Questo aiuta a visualizzare la struttura della catena di Markov e le relazioni tra gli stati.\n\n\n107.3.3 Espansione del Modello: Modelli di Markov Nascosti\nLe catene di Markov possono essere estese con i modelli di Markov nascosti (Hidden Markov Models, HMM) per includere livelli nascosti, ovvero stati che non possono essere osservati direttamente ma possono essere dedotti dai risultati osservabili. In termini di stati affettivi, questi modelli aiutano a comprendere stati latenti sottostanti che danno origine agli stati affettivi osservati, permettendo di tenere conto delle differenze individuali nell’esperienza e nell’espressione degli stati affettivi, così come della possibilità che questi stati possano essere mal classificati o ambigui.\nQuesti modelli sono utili per analizzare le dinamiche degli stati affettivi e prevedere comportamenti, offrendo un potente strumento per comprendere fenomeni comportamentali specifici, come quelli osservati in gruppi di individui con particolari condizioni psicologiche.\n\n107.3.3.1 Rappresentazione degli Stati Affettivi\nPer modellare gli stati affettivi con una catena di Markov, utilizziamo una matrice di transizione in cui ogni elemento rappresenta la probabilità di passare da uno stato affettivo a un altro. Ad esempio, Cipresso et al. (2023) considerano quattro stati affettivi: rilassato, stressato, impegnato e annoiato. Possiamo assegnare a ogni transizione possibile tra questi stati una probabilità, creando così la seguente matrice di transizione:\n\n\n\nDa  A\nAnnoiato\nRilassato\nStressato\nImpegnato\n\n\n\n\nAnnoiato\n0.60\n0.15\n0.15\n0.10\n\n\nRilassato\n0.10\n0.20\n0.40\n0.30\n\n\nStressato\n0.20\n0.10\n0.20\n0.50\n\n\nImpegnato\n0.30\n0.10\n0.20\n0.40\n\n\nStato iniziale (S0)\n0.10\n0.20\n0.40\n0.30\n\n\n\nVettore dello stato stazionario: Dopo un certo numero di passi, le probabilità di essere in ciascuno stato non cambiano più, raggiungendo quello che viene chiamato stato stazionario. Ad esempio, dopo 10 passi, la probabilità di essere nello stato “annoiato” è 0.361351, nello stato “rilassato” è 0.131186, nello stato “stressato” è 0.20817 e nello stato “impegnato” è 0.299293.\n\n\n107.3.3.2 Vincoli e Modello Grafico\nLa matrice di transizione deve rispettare alcuni vincoli: tutte le probabilità devono essere non negative e la somma delle probabilità di transizione da uno stato a tutti gli altri deve essere 1, poiché il sistema deve sempre trovarsi in uno degli stati possibili.\nPer rappresentare graficamente gli stati affettivi e le transizioni tra di essi, si può usare un grafo diretto in cui ogni stato è un nodo e ogni transizione è rappresentata da un arco diretto. Questo tipo di rappresentazione aiuta a visualizzare la struttura della catena di Markov e le relazioni tra gli stati.\n\n\n\nRelazioni tra quattro stati affettivi ipotizzata da Cipresso et al. (2023).\n\n\n\n\n107.3.3.3 Calcolo delle Probabilità nel Tempo\nLe catene di Markov sono un metodo matematico utilizzato per prevedere l’evoluzione nel tempo di un sistema che può trovarsi in uno di diversi stati. Consideriamo un esempio con quattro stati affettivi: rilassato, stressato, impegnato, e annoiato. Utilizzeremo una catena di Markov per modellare come una persona possa passare da uno stato affettivo all’altro nel tempo.\nImmaginiamo che inizialmente la persona si trovi nello stato rilassato. Questa situazione può essere rappresentata da un vettore iniziale \\(x_0\\), che indica la probabilità di essere in ciascuno dei quattro stati:\n\nRilassato: 100%;\nStressato: 0%;\nImpegnato: 0%;\nAnnoiato: 0%.\n\nIl vettore \\(x_0\\) sarà quindi:\n\\[\nx_0 = [1, 0, 0, 0].\n\\]\nSe invece la probabilità iniziale fosse del 50% di essere rilassato e del 50% di essere impegnato, il vettore diventerebbe:\n\\[\nx_0 = [0.5, 0, 0.5, 0].\n\\]\nSuccessivamente, definiamo una matrice di transizione \\(P\\) che descrive le probabilità di transizione da uno stato all’altro in un singolo intervallo di tempo (ad esempio, un’ora o un giorno). Ogni riga della matrice rappresenta lo stato attuale, mentre ogni colonna rappresenta lo stato futuro.\n\\[\nP = \\begin{bmatrix}\n0.60 & 0.15 & 0.15 & 0.10 \\\\\n0.10 & 0.20 & 0.40 & 0.30 \\\\\n0.20 & 0.10 & 0.20 & 0.50 \\\\\n0.30 & 0.10 & 0.20 & 0.40\n\\end{bmatrix}\n\\]\nLe probabilità di transizione per ogni stato sono le seguenti:\n\nAnnoiato: il 60% delle volte rimane annoiato, il 15% delle volte passa a rilassato o stressato, e il 10% delle volte diventa impegnato.\nRilassato: il 10% delle volte diventa annoiato, il 20% delle volte rimane rilassato, il 40% delle volte diventa stressato, e il 30% delle volte diventa impegnato.\nStressato: il 20% delle volte diventa annoiato, il 10% delle volte diventa rilassato, il 20% delle volte rimane stressato, e il 50% delle volte diventa impegnato.\nImpegnato: il 30% delle volte diventa annoiato, il 10% delle volte diventa rilassato, il 20% delle volte diventa stressato, e il 40% delle volte rimane impegnato.\n\nRiconsideriamo il caso in cui la persona sia inizialmente rilassata. Il vettore iniziale \\(x_0\\) sarà quindi:\n\\[\nx_0 = [0, 1, 0, 0].\n\\]\nQuesto vettore indica una probabilità del 100% di essere nello stato “rilassato” all’inizio.\nPer calcolare le probabilità degli stati dopo un giorno, moltiplichiamo il vettore iniziale \\(x_0\\) per la matrice di transizione \\(P\\):\n\\[\nx_1 = x_0 \\cdot P = [0, 1, 0, 0] \\cdot \\begin{bmatrix}\n0.60 & 0.15 & 0.15 & 0.10 \\\\\n0.10 & 0.20 & 0.40 & 0.30 \\\\\n0.20 & 0.10 & 0.20 & 0.50 \\\\\n0.30 & 0.10 & 0.20 & 0.40\n\\end{bmatrix}\n\\]\nCalcoliamo il prodotto per determinare il nuovo vettore delle probabilità:\n\\[\nx_1 = [0.10, 0.20, 0.40, 0.30].\n\\]\nDopo un giorno, le probabilità di essere in ciascuno stato sono le seguenti:\n\n10% probabilità di essere annoiato,\n20% probabilità di essere rilassato,\n40% probabilità di essere stressato,\n30% probabilità di essere impegnato.\n\nPer calcolare le probabilità dopo due giorni, moltiplichiamo il vettore \\(x_1\\) per la matrice \\(P\\):\n\\[\nx_2 = x_1 \\cdot P = [0.10, 0.20, 0.40, 0.30] \\cdot \\begin{bmatrix}\n0.60 & 0.15 & 0.15 & 0.10 \\\\\n0.10 & 0.20 & 0.40 & 0.30 \\\\\n0.20 & 0.10 & 0.20 & 0.50 \\\\\n0.30 & 0.10 & 0.20 & 0.40\n\\end{bmatrix}\n\\]\nEseguendo questo calcolo, otteniamo:\n\\[\nx_2 = [0.225, 0.105, 0.245, 0.425].\n\\]\nDopo due giorni, le probabilità di essere in ciascuno stato sono:\n\n22.5% probabilità di essere annoiato,\n10.5% probabilità di essere rilassato,\n24.5% probabilità di essere stressato,\n42.5% probabilità di essere impegnato.\n\nRipetendo questo processo, possiamo monitorare come le probabilità evolvono nel tempo, permettendoci di modellare l’evoluzione degli stati affettivi di una persona. Continuando a moltiplicare il vettore stato per la matrice di transizione, possiamo raggiungere uno stato stazionario, in cui le probabilità non cambiano più di passo in passo. Questo è utile per prevedere il comportamento a lungo termine di una persona nei diversi stati affettivi.\nIn conclusione, l’approccio basato sulle catene di Markov offre un metodo rigoroso e flessibile per analizzare sistemi complessi che evolvono nel tempo. Questa tecnica non solo permette di modellare dinamiche probabilistiche, ma fornisce anche una base solida per lo sviluppo di modelli predittivi più sofisticati in vari campi di applicazione.\n\n\n\n107.3.4 Un processo di Markov applicato agli stati affettivi\nUtilizzare i modelli di catene di Markov è fondamentale per comprendere le dinamiche degli stati affettivi. Questi modelli catturano accuratamente le probabilità di transizione tra stati affettivi, fornendo uno strumento potente per analizzare le dinamiche sottostanti. Studiando tali modelli, i ricercatori possono ottenere informazioni preziose su come le nostre emozioni e reazioni possono cambiare nel tempo.\nAd esempio, un modello di catena di Markov potrebbe rivelare che un’emozione positiva ha maggiori probabilità di passare a uno stato neutro piuttosto che a uno negativo. Un ricercatore potrebbe scoprire che la felicità tende a trasformarsi più facilmente in un sentimento di soddisfazione piuttosto che di tristezza. Per esempio, la probabilità di passare dalla gioia alla soddisfazione potrebbe essere 0.72, mentre quella di passare dalla gioia alla tristezza potrebbe essere 0.28.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#implementazione",
    "href": "chapters/dynamic_models/04_affect.html#implementazione",
    "title": "107  Le emozioni influenzano le emozioni",
    "section": "107.4 Implementazione",
    "text": "107.4 Implementazione\nNelle sezioni seguenti, ci proponiamo di simulare un set di dati basato sul meccanismo generativo dei dati descritto da Cipresso et al. (2023), utilizzando la matrice di transizione illustrata in precedenza. Successivamente, implementeremo questo meccanismo in Stan per generare i dati simulati e utilizzeremo tali dati per effettuare inferenze sulla matrice di transizione utilizzata nella loro generazione.\nInoltre, svilupperemo in Stan un secondo modello che assume che gli stati affettivi siano indipendenti tra loro, ovvero che non si influenzino reciprocamente. Adatteremo questo secondo modello ai dati simulati e, attraverso l’utilizzo delle tecniche di validazione incrociata LOO, cercheremo di determinare quale modello descrive meglio i dati.\n\n107.4.1 Simulazione dei Dati\nSimuliamo i dati in base al modello generativo ipotizzato da Cipresso et al. (2023). Per gli scopi presenti, non è necessario capire nei dettagli come questo viene ottenuto.\n\n# Define the states\nstates = [\"Bored\", \"Relaxed\", \"Stressed\", \"Engaged\"]\n\n# Define the transition matrix\ntransition_matrix = np.array(\n    [\n        [0.60, 0.15, 0.15, 0.10],  # Bored\n        [0.10, 0.20, 0.40, 0.30],  # Relaxed\n        [0.20, 0.10, 0.20, 0.50],  # Stressed\n        [0.30, 0.10, 0.20, 0.40],  # Engaged\n    ]\n)\n\n\n# Function to generate the next state\ndef next_state(current_state):\n    return np.random.choice(states, p=transition_matrix[current_state])\n\n\n# Function to simulate a sequence of states\ndef simulate_markov_chain(start_state, num_steps):\n    current_state = states.index(start_state)\n    state_sequence = [start_state]\n\n    for _ in range(num_steps - 1):\n        current_state = states.index(next_state(current_state))\n        state_sequence.append(states[current_state])\n\n    return state_sequence\n\n\n# Simulate data\nstart_state = \"Bored\"\nnum_steps = 2000  # Number of steps to simulate\nsimulated_data = simulate_markov_chain(start_state, num_steps)\n\nSistemiamo i dati in un dizionario come richiesto da Stan.\n\n# Convert states to numerical indices for Stan\nstate_to_index = {\"Bored\": 1, \"Relaxed\": 2, \"Stressed\": 3, \"Engaged\": 4}\nstan_data_markov = {\n    \"N\": len(simulated_data),\n    \"states\": [state_to_index[state] for state in simulated_data],\n}\n\n\nprint(stan_data_markov[\"states\"][0:20])\n\n[1, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 3, 4, 4, 4, 4, 1, 2, 3, 1]\n\n\nPer qualche ragione, il posterior predictive check per il modello di Markov porta alla perdita di un’osservazione, mentre il modello che assume l’indipendenza no. Dato che il confronto tra i due modelli mediante ArviZ deve essere basato sullo stesso numero di dati, per semplicità sottraggo un dato dal campione analizzato dal modello che assume l’indipendenza.\n\nstan_data_independence = {\n    \"N\": len(simulated_data) - 1,\n    \"states\": [state_to_index[state] for state in simulated_data[:-1]],\n}\n\nprint(stan_data_independence[\"states\"][0:20])\n\n[1, 3, 3, 4, 4, 4, 1, 1, 1, 2, 2, 3, 4, 4, 4, 4, 1, 2, 3, 1]\n\n\n\n\n107.4.2 Modello Markov\nImplementiamo ora in Stan il modello ipotizzato da Cipresso et al. (2023).\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"cipresso_model.stan\"\n)\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\ndata {\n  int&lt;lower=1&gt; N; // number of transitions\n  array[N] int states; // sequence of observed states\n}\nparameters {\n  array[4] simplex[4] trans_matrix; // 4x4 transition matrix with simplex constraints\n}\nmodel {\n  // Prior distribution for the transition matrix (Dirichlet prior)\n  for (i in 1 : 4) \n    trans_matrix[i] ~ dirichlet(rep_vector(1.0, 4));\n  \n  // Likelihood of the observed data\n  for (n in 1 : (N - 1)) \n    states[n + 1] ~ categorical(trans_matrix[states[n]]);\n}\ngenerated quantities {\n  array[N - 1] real log_lik; // array per la log likelihood\n  array[N] int&lt;lower=1, upper=4&gt; y_rep; // dati simulati per posterior predictive checks\n  \n  // Calcolo della log likelihood per ogni osservazione\n  for (n in 1 : (N - 1)) {\n    log_lik[n] = categorical_lpmf(states[n + 1] | trans_matrix[states[n]]);\n  }\n  \n  // Generazione di dati simulati per posterior predictive checks\n  y_rep[1] = states[1]; // il primo stato simulato è lo stesso dello stato osservato\n  for (n in 1 : (N - 1)) {\n    y_rep[n + 1] = categorical_rng(trans_matrix[y_rep[n]]);\n  }\n}\n\n\n\nIn questo modello incontriamo due concetti nuovi. Il primo concetto è quello di simplex.\nIn Stan, il comando array[4] simplex[4] trans_matrix; definisce una matrice di transizione 4x4 per un modello di catena di Markov.\nUn simplex in Stan è un vettore di numeri positivi che sommano a 1. Nel contesto di una catena di Markov, un simplex rappresenta le probabilità di transizione da uno stato ad altri stati, garantendo che la somma delle probabilità di transizione da un particolare stato sia sempre uguale a 1.\nPer esempio, se consideriamo un vettore simplex di dimensione 4, [p1, p2, p3, p4], allora dobbiamo avere:\n\\[\np1 + p2 + p3 + p4 = 1\n\\]\ne \\(p_i \\geq 0\\) per ogni \\(i\\).\nLa dichiarazione array[4] simplex[4] in Stan crea un array di 4 vettori simplex, ciascuno di dimensione 4. Questo array rappresenta la matrice di transizione per una catena di Markov con 4 stati.\nNel codice, trans_matrix è la matrice di transizione. L’array trans_matrix può essere visto come una matrice 4x4 in cui:\n\nogni riga rappresenta uno stato corrente nella catena di Markov;\nogni colonna rappresenta uno stato successivo possibile;\ngli elementi della matrice rappresentano le probabilità di transizione da uno stato corrente (indicato dalla riga) a uno stato successivo (indicato dalla colonna).\n\nPoiché ogni riga di trans_matrix è un simplex, la somma delle probabilità di ogni riga sarà sempre pari a 1, il che è coerente con le proprietà di una matrice di transizione di Markov.\nConsideriamo un esempio per capire meglio:\n\\[\n\\text{trans\\_matrix} = \\begin{bmatrix}\n0.60 & 0.15 & 0.15 & 0.10 \\\\\n0.10 & 0.20 & 0.40 & 0.30 \\\\\n0.20 & 0.10 & 0.20 & 0.50 \\\\\n0.30 & 0.10 & 0.20 & 0.40\n\\end{bmatrix}\n\\]\nIn questo esempio:\n\nLa prima riga [0.60, 0.15, 0.15, 0.10] rappresenta le probabilità di transizione dallo stato 1 a ciascuno dei quattro stati. La somma è 1.\nLa seconda riga [0.10, 0.20, 0.40, 0.30] rappresenta le probabilità di transizione dallo stato 2 a ciascuno degli stati, e così via.\n\nUsiamo simplex[4] per garantire che le probabilità di transizione da uno stato a tutti gli altri stati sommino a 1. Questa è una proprietà fondamentale di una catena di Markov e assicura che il sistema rimanga all’interno degli stati definiti, senza probabilità negative o somme maggiori di 1.\nIn conclusione, l’uso di array[4] simplex[4] in Stan per definire trans_matrix è un modo per rappresentare una matrice di transizione di una catena di Markov. Ogni riga della matrice è un vettore simplex che rappresenta le probabilità di transizione da un dato stato a tutti gli altri stati, rispettando le proprietà di base delle probabilità in un sistema discreto di stati.\nIl secondo concetto nuovo che viene usato qui è la distribuzione di Dirichlet. In Stan, l’espressione trans_matrix[i] ~ dirichlet(rep_vector(1.0, 4)); rappresenta una dichiarazione di prior per la riga i della matrice di transizione trans_matrix in un modello di catena di Markov. Per capire questa dichiarazione, vediamo cosa significa ogni parte.\nLa distribuzione di Dirichlet è una distribuzione di probabilità continua definita su un simplex. In altre parole, è una distribuzione utilizzata per modellare probabilità che devono sommare a 1, come le righe della matrice di transizione di una catena di Markov.\n\nSimplex: Un simplex di dimensione \\(K\\) è un vettore di \\(K\\) elementi, ognuno dei quali è maggiore o uguale a 0, e la somma di tutti questi elementi è 1. La distribuzione di Dirichlet è una distribuzione su questi vettori simplex.\nDirichlet Prior: Un prior di Dirichlet è spesso utilizzato quando si desidera specificare una distribuzione di probabilità su vettori di probabilità. È particolarmente utile nei modelli bayesiani quando si lavora con probabilità che devono sommare a 1 (come le righe di una matrice di transizione).\n\nNel contesto di una catena di Markov, ogni riga della matrice di transizione trans_matrix rappresenta un vettore di probabilità per le transizioni da uno stato specifico agli altri stati. Queste probabilità devono sommare a 1, il che rende la distribuzione di Dirichlet un’ottima scelta per modellare queste probabilità.\nNell’Espressione trans_matrix[i] ~ dirichlet(rep_vector(1.0, 4));\n\ntrans_matrix[i]: Questa è la riga i-esima della matrice di transizione. Poiché trans_matrix è dichiarata come array[4] simplex[4], trans_matrix[i] è un vettore simplex di dimensione 4, il che significa che è un vettore di quattro probabilità che sommano a 1.\ndirichlet(rep_vector(1.0, 4)): Questa è una distribuzione di Dirichlet con parametri pari a rep_vector(1.0, 4), che è un vettore di 4 elementi tutti uguali a 1.\n\nrep_vector(1.0, 4): Questa funzione crea un vettore di dimensione 4 con tutti gli elementi uguali a 1.\ndirichlet(...): La distribuzione di Dirichlet prende questo vettore come parametro, il che significa che assegna una probabilità uguale a tutte le possibili configurazioni delle probabilità, a patto che sommino a 1. Questo tipo di Dirichlet con parametri uguali a 1 è noto come Dirichlet uniforme, che rappresenta un prior non informativo. Non assume preferenze particolari per alcuna configurazione delle probabilità.\n\n\nIn pratica, l’istruzione trans_matrix[i] ~ dirichlet(rep_vector(1.0, 4)); assegna una prior uniforme a ogni riga i della matrice di transizione trans_matrix. In altre parole, prima di osservare qualsiasi dato, assumiamo che tutte le possibili configurazioni di probabilità di transizione siano ugualmente probabili. Questa è una scelta comune quando non si ha una conoscenza a priori su quali transizioni siano più probabili.\nQuesto prior permette alla stima della matrice di transizione di essere guidata interamente dai dati osservati, senza imporre vincoli iniziali. In un contesto bayesiano, l’uso di un prior di Dirichlet uniforme consente di aggiornare le stime della matrice di transizione in base ai dati, mantenendo un punto di partenza neutrale.\nIn conclusione, l’uso della distribuzione di Dirichlet con rep_vector(1.0, 4) come prior per ogni riga della matrice di transizione in un modello di catena di Markov è un modo di modellare le probabilità di transizione che sono inizialmente considerate ugualmente probabili, consentendo al modello di apprendere le probabilità specifiche dai dati osservati senza pregiudizi forti.\nEseguiamo il campionamento utilizzando in input i dati simulati in precedenza.\n\nfit = model.sample(\n    data=stan_data_markov,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\nConvertiamo l’oggetto fit_sample in un formato compatibile con ArviZ.\n\nfit_az = az.from_cmdstanpy(posterior=fit)\n\nEsaminiamo le distribuzioni a posteriori dei paraemtri.\n\naz.summary(fit_az,var_names=\"trans_matrix\", round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\ntrans_matrix[0, 0]\n0.60\n0.02\n0.57\n0.64\n0.0\n0.0\n17525.12\n6012.02\n1.0\n\n\ntrans_matrix[0, 1]\n0.16\n0.01\n0.13\n0.18\n0.0\n0.0\n17361.50\n6448.52\n1.0\n\n\ntrans_matrix[0, 2]\n0.14\n0.01\n0.11\n0.16\n0.0\n0.0\n15645.66\n6427.68\n1.0\n\n\ntrans_matrix[0, 3]\n0.10\n0.01\n0.08\n0.12\n0.0\n0.0\n17950.00\n5836.37\n1.0\n\n\ntrans_matrix[1, 0]\n0.09\n0.02\n0.06\n0.12\n0.0\n0.0\n15644.09\n6035.12\n1.0\n\n\ntrans_matrix[1, 1]\n0.22\n0.02\n0.18\n0.27\n0.0\n0.0\n17114.35\n6048.90\n1.0\n\n\ntrans_matrix[1, 2]\n0.39\n0.03\n0.33\n0.44\n0.0\n0.0\n18574.00\n5861.02\n1.0\n\n\ntrans_matrix[1, 3]\n0.30\n0.03\n0.25\n0.35\n0.0\n0.0\n16896.79\n5880.78\n1.0\n\n\ntrans_matrix[2, 0]\n0.20\n0.02\n0.16\n0.24\n0.0\n0.0\n14592.28\n6281.19\n1.0\n\n\ntrans_matrix[2, 1]\n0.11\n0.02\n0.08\n0.14\n0.0\n0.0\n15605.08\n5885.06\n1.0\n\n\ntrans_matrix[2, 2]\n0.19\n0.02\n0.15\n0.23\n0.0\n0.0\n18919.38\n5698.41\n1.0\n\n\ntrans_matrix[2, 3]\n0.49\n0.03\n0.44\n0.54\n0.0\n0.0\n16742.89\n6018.64\n1.0\n\n\ntrans_matrix[3, 0]\n0.27\n0.02\n0.24\n0.31\n0.0\n0.0\n20091.50\n5499.41\n1.0\n\n\ntrans_matrix[3, 1]\n0.13\n0.01\n0.10\n0.15\n0.0\n0.0\n17810.08\n6013.07\n1.0\n\n\ntrans_matrix[3, 2]\n0.19\n0.02\n0.16\n0.22\n0.0\n0.0\n17741.60\n5769.42\n1.0\n\n\ntrans_matrix[3, 3]\n0.41\n0.02\n0.37\n0.45\n0.0\n0.0\n18131.15\n6396.45\n1.0\n\n\n\n\n\n\n\nNotiamo come il modello sia stato in grado di recuperare in modo accurato i valori della matrice di transizione utilizzata per simulare i dati.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#modello-indipendenza",
    "href": "chapters/dynamic_models/04_affect.html#modello-indipendenza",
    "title": "107  Le emozioni influenzano le emozioni",
    "section": "107.5 Modello Indipendenza",
    "text": "107.5 Modello Indipendenza\nConsideriamo ora un modello di base che presuppone l’indipendenza tra gli stati affettivi. Se questo modello si adatta ai dati altrettanto bene del modello che considera le influenze reciproche tra stati affettivi, secondo il principio del rasoio di Occam, non sarebbe necessario ipotizzare tali influenze tra gli stati.\n\nstan_ind_file = os.path.join(project_directory, \"stan\", \"cipresso_ind_model.stan\")\n\nmodel_ind = CmdStanModel(stan_file=stan_ind_file)\nprint(model_ind.code())\n\ndata {\n  int&lt;lower=1&gt; N; // numero di osservazioni\n  array[N] int&lt;lower=1, upper=4&gt; states; // sequenza degli stati osservati\n}\nparameters {\n  simplex[4] state_probs; // vettore delle probabilità di ciascuno stato\n}\nmodel {\n  // Distribuzione a priori uniforme per le probabilità degli stati (Dirichlet(1))\n  state_probs ~ dirichlet(rep_vector(1.0, 4));\n  \n  // Verosimiglianza dei dati osservati trattati come indipendenti\n  for (n in 1 : N) \n    states[n] ~ categorical(state_probs);\n}\ngenerated quantities {\n  array[N] real log_lik; // array per la log likelihood\n  array[N] int&lt;lower=1, upper=4&gt; y_rep; // dati simulati per posterior predictive checks\n  \n  // Calcolo della log likelihood per ogni osservazione\n  for (n in 1 : N) {\n    log_lik[n] = categorical_lpmf(states[n] | state_probs);\n  }\n  \n  // Generazione di dati simulati per posterior predictive checks\n  for (n in 1 : N) {\n    y_rep[n] = categorical_rng(state_probs);\n  }\n}\n\n\n\nPer generare il modello di “indipendenza” rispetto al modello “Markov”, sono state introdotte diverse modifiche chiave. Vediamo quali sono queste modifiche e come differenziano i due modelli.\nNel modello di Markov, ogni stato successivo dipende dal precedente, con le probabilità di transizione definite da una matrice di transizione. Questo significa che la probabilità di essere in un dato stato al tempo \\(t+1\\) è condizionata dallo stato al tempo \\(t\\).\nNel modello di Indipendenza, gli stati affettivi sono considerati indipendenti tra loro. Ogni osservazione è trattata come un evento separato, senza dipendenza dal precedente. Le probabilità degli stati sono modellate da un vettore di probabilità di stato (state_probs), e non da una matrice di transizione.\nIl modello di Markov utilizza una matrice di transizione (trans_matrix), dove ogni riga è un vettore simplex che rappresenta le probabilità di transizione da uno stato a tutti gli altri stati possibili.\nIl modello di Indipendenza utilizza un singolo vettore simplex di dimensione 4 (state_probs), che rappresenta le probabilità di ciascuno stato indipendentemente dagli altri stati. Qui, non c’è una matrice di transizione perché non ci sono dipendenze tra stati consecutivi.\nNel modello di Markov, la verosimiglianza dei dati è calcolata in base alla probabilità di transizione tra stati consecutivi. Ogni stato dipende dallo stato precedente, quindi la verosimiglianza riflette questa dipendenza.\nNel modello di Indipendenza, la verosimiglianza è calcolata assumendo che ogni stato osservato sia indipendente dagli altri. La funzione di verosimiglianza usa una distribuzione categorica per ogni stato, basata sul vettore state_probs. Non c’è alcuna relazione tra stati consecutivi.\nIn sintesi, le principali modifiche per passare dal modello “Markov” al modello “indipendenza” sono:\n\nnon esiste dipendenza tra stati successivi;\nutilizza un vettore di probabilità di stato (state_probs) anziché una matrice di transizione;\ntratta ogni osservazione come indipendente, utilizzando una distribuzione categorica basata su state_probs.\n\nEseguiamo il campionamento.\n\nfit_ind = model_ind.sample(\n    data=stan_data_independence,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\nfit_ind_az = az.from_cmdstanpy(posterior=fit_ind)\naz.summary(fit_ind_az, var_names=\"state_probs\", round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nstate_probs[0]\n0.34\n0.01\n0.32\n0.36\n0.0\n0.0\n8456.90\n5927.18\n1.0\n\n\nstate_probs[1]\n0.13\n0.01\n0.12\n0.15\n0.0\n0.0\n7911.11\n5710.21\n1.0\n\n\nstate_probs[2]\n0.22\n0.01\n0.21\n0.24\n0.0\n0.0\n8078.80\n6115.46\n1.0\n\n\nstate_probs[3]\n0.30\n0.01\n0.28\n0.32\n0.0\n0.0\n8308.59\n6358.41\n1.0\n\n\n\n\n\n\n\nUna volta che il ricercatore ha specificato un modello appropriato e verificato che il modello ottiene la convergenza, può valutare se il modello descrive adeguatamente i dati. Le stime dei parametri sono interpretabili solo nella misura in cui il modello rappresenta accuratamente il fenomeno che si sta indagando. Se il modello approssima male i dati, le informazioni contenute nelle stime dei parametri potrebbero non essere rappresentative del processo che il ricercatore sta cercando di analizzare. In tali casi, potrebbe essere necessario riformulare il modello per migliorare la sua capacità di spiegare le osservazioni empiriche.\n\n# Run diagnostics and print results\ndiagnostic_info = fit_ind.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpprjn35f_/cipresso_ind_model8sljhpd5/cipresso_ind_model-20240825085942_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpprjn35f_/cipresso_ind_model8sljhpd5/cipresso_ind_model-20240825085942_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpprjn35f_/cipresso_ind_model8sljhpd5/cipresso_ind_model-20240825085942_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpprjn35f_/cipresso_ind_model8sljhpd5/cipresso_ind_model-20240825085942_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#valutazione-e-confronto-di-modelli",
    "href": "chapters/dynamic_models/04_affect.html#valutazione-e-confronto-di-modelli",
    "title": "107  Le emozioni influenzano le emozioni",
    "section": "107.6 Valutazione e Confronto di Modelli",
    "text": "107.6 Valutazione e Confronto di Modelli\nEseguiamo il calcolo dei valori k di Pareto e la validazione incrociata Leave-One-Out (LOO-CV) utilizzando ArviZ.\n\nloo_result = az.loo(fit_az)\nprint(loo_result)\n\nComputed from 8000 posterior samples and 1999 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -2406.20    26.49\np_loo       12.10        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1999  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\n\nloo_ind_result = az.loo(fit_ind_az)\nprint(loo_ind_result)\n\nComputed from 8000 posterior samples and 1999 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo -2661.47    14.10\np_loo        3.01        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1999  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\n\ndf_comp_loo = az.compare({\n    \"markov_model\": loo_result, \n    \"independence_model\": loo_ind_result\n})\ndf_comp_loo\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nmarkov_model\n0\n-2406.195318\n12.103452\n0.000000\n0.799907\n26.494244\n0.000000\nFalse\nlog\n\n\nindependence_model\n1\n-2661.468120\n3.011688\n255.272802\n0.200093\n14.098377\n29.877077\nFalse\nlog\n\n\n\n\n\n\n\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)\n\n\n\n\n\n\n\n\nIl risultato ottenuto mostra chiaramente che la tecnica di validazione incrociata LOO permette di concludere che il modello “Markov” rappresenta i dati in modo molto più accurato rispetto al modello che presuppone l’indipendenza tra gli stati affettivi. Questo è prevedibile, dato che i dati sono stati generati in base alla verosimiglianza implementata nel modello “Markov”. Tuttavia, questa dimostrazione evidenzia come, utilizzando metodi bayesiani, sia possibile recuperare facilmente la matrice di transizione tra stati, a condizione che i dati siano stati generati da un processo coerente con il modello implementato in Stan.\nStudi di simulazione possono essere condotti per determinare quale dimensione del campione sia necessaria per consentire un recupero accurato dei valori della matrice di transizione. Inoltre, il modello può essere ulteriormente sviluppato per distinguere tra diversi gruppi (ad esempio, pazienti e controlli) o per stimare le caratteristiche individuali dei partecipanti utilizzando un modello gerarchico.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#riflessioni-conclusive",
    "href": "chapters/dynamic_models/04_affect.html#riflessioni-conclusive",
    "title": "107  Le emozioni influenzano le emozioni",
    "section": "107.7 Riflessioni Conclusive",
    "text": "107.7 Riflessioni Conclusive\nSecondo Cipresso et al. (2023), le catene di Markov offrono diversi vantaggi rispetto ai metodi tradizionali per modellare le dinamiche temporali e le interdipendenze degli stati emotivi.\n\nLe catene di Markov sono una strategia di modellazione adattabile che può essere utilizzata per simulare diversi sistemi a stati discreti, inclusi gli stati emotivi. Questa flessibilità consente ai ricercatori di modellare solo gli stati emotivi e le loro connessioni rilevanti per il loro specifico studio.\nLe dinamiche temporali delle emozioni possono essere analizzate in modo semplice e comprensibile utilizzando le catene di Markov. È possibile fare previsioni sugli stati futuri analizzando le probabilità di transizione tra stati diversi.\nLe catene di Markov permettono ai ricercatori di valutare la stabilità degli stati emotivi nel tempo, stimando le probabilità di passaggio da uno stato all’altro sia a breve che a lungo termine.\nLe catene di Markov possono essere facilmente create utilizzando software statistici convenzionali, offrendo un ulteriore vantaggio rispetto ad altri metodi.\n\nOltre a questi vantaggi pratici, c’è un aspetto interessante nell’usare le catene di Markov per rappresentare gli stati affettivi: richiedono un approccio innovativo nel considerare le transizioni tra stati emotivi. I ricercatori devono rivedere le loro ipotesi preliminari sugli affetti e considerare le transizioni in modo diverso, cercando nuovi tipi di disegni sperimentali.\nAd esempio, sarebbe utile evocare stati affettivi in base alla valenza e all’attivazione, mantenendo i partecipanti in uno stato per un tempo sufficiente a evocare esclusivamente lo stato desiderato. Successivamente, si dovrebbe passare a un altro stato, mantenendo anche questo per un periodo simile per evocare realmente i nuovi stati nei partecipanti.\nUna delle sfide principali è definire una misura della probabilità di transizione da uno stato all’altro. Questa potrebbe essere una funzione del tempo di latenza necessario per raggiungere un nuovo stato affettivo una volta presentati nuovi stimoli o una misura psicologica o fisiologica durante le transizioni. Attualmente, non esiste una risposta univoca a questo problema, il che rappresenta un invito all’azione per i ricercatori nel raccogliere nuovi dati per comprendere meglio le dinamiche degli stati affettivi utilizzando vari stimoli (foto, video, suoni, ecc.) e strumenti.\nCipresso et al. (2023) propongono che i modelli di catene di Markov possono essere utilizzati per capire come diversi gruppi di individui (ad esempio, pazienti vs. controlli) mostrino diverse matrici di transizione, evidenziando fenotipi comportamentali specifici e una comprensione approfondita dell’evoluzione della salute mentale basata sulle dinamiche degli affetti.\nAnalizzando questi modelli, potrebbe essere possibile capire come certi disturbi mentali progrediscono e come gli individui esprimono diversi schemi comportamentali basati sui loro stati affettivi. Comprendendo gli affetti nei vari stati, possiamo determinare con maggiore precisione le possibili cause dei disturbi mentali e sviluppare piani di trattamento più efficaci. Ad esempio, i dati possono essere utilizzati per identificare quali emozioni sono più comunemente associate alla depressione, permettendo di focalizzare quelle emozioni come parte del piano di trattamento di un paziente.\nInoltre, i dati possono aiutare a capire quali tipi di interventi e terapie producono i migliori risultati per le persone con malattie mentali, consentendo lo sviluppo di approcci basati sull’evidenza per gestire meglio le condizioni di salute mentale.\nIn conclusione, secondo Cipresso et al. (2023), lo studio delle catene di Markov applicato alle dinamiche degli affetti può fornire nuove intuizioni sui comportamenti fenotipici legati agli stati emotivi attraverso le proprietà matematiche dei dati raccolti in disegni sperimentali. Questo permette di evidenziare le transizioni di stato e calcolare le probabilità correlate. Le limitazioni future riguardano il modo in cui le probabilità vengono stimate e la possibile struttura delle catene di Markov, soprattutto quando lo stato del sistema non è direttamente osservabile ma può essere dedotto da una sequenza di osservazioni. In questi casi, possono essere considerati i modelli di Markov nascosti, che estendono ulteriormente il modello di transizione. Più in generale, il potenziale di questi processi matematici potrebbe chiarire le dinamiche affettive e la misura in cui queste dinamiche spiegano i processi di salute mentale a un livello più alto, portando a una migliore comprensione e interventi.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/04_affect.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/04_affect.html#informazioni-sullambiente-di-sviluppo",
    "title": "107  Le emozioni influenzano le emozioni",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sun Aug 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nbambi     : 0.14.0\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\npandas    : 2.2.2\narviz     : 0.18.0\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nCipresso, P., Borghesi, F., & Chirico, A. (2023). Affects affect affects: A Markov chain. Frontiers in Psychology, 14, 1162655.\n\n\nRussell, J. A. (1980). A circumplex model of affect. Journal of Personality and Social Psychology, 39(6), 1161–1178.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>Le emozioni influenzano le emozioni</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html",
    "href": "chapters/dynamic_models/05_sequential_learning.html",
    "title": "108  Analisi dinamica delle sequenze di apprendimento",
    "section": "",
    "text": "108.1 Introduzione\nL’obiettivo di questo capitolo è implementare il modello basato sulle catene di Markov proposto da Paxinou et al. (2021) per valutare l’efficacia di tre diverse strategie di insegnamento.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#la-modellizzazione-delle-sequenze-dellapprendimento",
    "href": "chapters/dynamic_models/05_sequential_learning.html#la-modellizzazione-delle-sequenze-dellapprendimento",
    "title": "108  Analisi dinamica delle sequenze di apprendimento",
    "section": "108.2 La Modellizzazione delle Sequenze dell’Apprendimento",
    "text": "108.2 La Modellizzazione delle Sequenze dell’Apprendimento\nLa ricerca di Paxinou et al. (2021) si concentra sull’acquisizione di competenze pratiche dopo l’addestramento attraverso una metodologia specifica. In particolare, i partecipanti vengono addestrati a utilizzare un microscopio fotonico, lo strumento di base in un laboratorio di biologia. Vengono formati attraverso tre diversi metodi di insegnamento. Il T-Group ha partecipato a una dimostrazione tradizionale in presenza dell’esperimento di microscopia, il V-Group ha guardato un video didattico sull’esperimento di microscopia, e il VR-Group ha interagito con il microscopio simulato in un ambiente VR per eseguire l’esperimento di microscopia.\nNel presente tutorial considereremo solo i due metodi che producono i risultati più estremi nello studio di Paxinou et al. (2021): il T-Group, che qui sarà chiamato condizione 1, e il VR-Group, che corrisponde alla condizione 2.\nNello studio di Paxinou et al. (2021), ogni studente doveva eseguire individualmente l’esperimento di microscopia, che era suddiviso in 13 fasi. Non sapere come eseguire un passaggio portava al fallimento della prova, poiché non era possibile passare al passaggio successivo senza aver completato quello corrente. Fortunatamente, i supervisori di laboratorio, negli ambienti di laboratorio fisici, o gli avatar e i pulsanti di aiuto/suggerimento, nei sistemi di tutoraggio intelligente come gli ambienti VR, offrivano agli studenti una seconda possibilità e la capacità di andare avanti. Basandosi su ciò, nello studio di Paxinou et al. (2021), la performance di ogni studente in ciascuno dei 13 passaggi veniva valutata secondo 3 categorie: A corrisponde all’azione “Ho completato il passaggio facilmente”; B corrisponde all’azione “Ho eventualmente completato il passaggio, ma con difficoltà”; C corrisponde all’azione “Non sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto (al supervisore o a un compagno di studi)”. Queste 3 diverse valutazioni della performance in ogni passaggio definiscono i tre stati che costituiranno la catena di Markov.\nI dati corrispondono dunque alla sequenza di 13 stati per ogni studente. Nella presente analisi, lo stato A è codificato come 1, lo stato B come 2, e lo stato C come 3. Quindi, per esempio, per un ipotetico studente, la sequenza delle valutazioni registrate nei 13 passaggi potrebbe dare origine alla seguente catena di Markov: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1].\nLo scopo dello studio, e in questo tutorial, è determinare se esiste una differenza nell’apprendimento tra il T-Group (condizione 1) e il VR-Group (condizione 2) e, in caso affermativo, se l’apprendimento procede in modo più fluido in una di queste due condizioni.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#implementazione",
    "href": "chapters/dynamic_models/05_sequential_learning.html#implementazione",
    "title": "108  Analisi dinamica delle sequenze di apprendimento",
    "section": "108.3 Implementazione",
    "text": "108.3 Implementazione\nDai dati empirici raccolti, Paxinou et al. (2021) stima tre matrici di transizione. Qui considereremo solo le matrici di transizione relative ai gruppi T e VR.\nUtilizzando queste due matrici di transizione, genereremo le sequenze di stati di 50 studenti nella condizione T e di 50 studenti nella condizione VR. Analizzeremo i dati con due modelli. Il modello paxinou_single_transition_model.stan ignora la differenza tra i due gruppi e stima una singola matrice di transizione per gli stati A, B e C dai dati dei 100 soggetti. Il modello paxinou_separate_transition_matrices_model.stan stima due matrici di transizione per gli stati A, B e C, una per ciascun gruppo (T e VR). Attraverso l’utilizzo delle tecniche di validazione incrociata LOO, determineremo quale modello descrive meglio i dati.\n\n108.3.1 Simulazione dei Dati\nSimuliamo i dati ipotizzando la presenza di tre stati (A, B, C) e utilizzando le matrici di transizione per le condizioni T e VR riportate da Paxinou et al. (2021). Per gli scopi presenti, non è necessario capire nei dettagli come questo viene ottenuto.\n\ndef generate_markov_chain_data(transition_matrix, initial_state, steps, subjects):\n    states = [\"A\", \"B\", \"C\"]\n    data = []\n\n    for _ in range(subjects):\n        current_state = initial_state\n        state_sequence = [\n            states.index(current_state) + 1\n        ]  # Convert state to integer (1-based index)\n\n        for _ in range(steps - 1):\n            current_state = np.random.choice(\n                states, p=transition_matrix[states.index(current_state)]\n            )\n            state_sequence.append(states.index(current_state) + 1)\n\n        data.append(state_sequence)\n\n    return data\n\n\n# Transition matrices for the two conditions\ntransition_matrix_condition1 = [\n    [0.776, 0.128, 0.096],  # Probabilities for transitions from state A\n    [0.738, 0.167, 0.095],  # Probabilities for transitions from state B\n    [0.630, 0.259, 0.111],  # Probabilities for transitions from state C\n]\n\ntransition_matrix_condition2 = [\n    [0.866, 0.086, 0.048],  # Probabilities for transitions from state A\n    [0.516, 0.452, 0.032],  # Probabilities for transitions from state B\n    [0.900, 0.100, 0.000],  # Probabilities for transitions from state C\n]\n\n# Number of steps (trials) in the experiment\nsteps = 13\n# Number of subjects\nsubjects = 50\n\n# Initial state for each subject\ninitial_state = \"A\"\n\n# Generate data for both conditions\ndata_condition1 = generate_markov_chain_data(\n    transition_matrix_condition1, initial_state, steps, subjects\n)\ndata_condition2 = generate_markov_chain_data(\n    transition_matrix_condition2, initial_state, steps, subjects\n)\n\nSistemiamo i dati in un dizionario come richiesto da Stan.\n\n# Create the data dictionary for the Stan models\nstan_data = {\n    \"N\": 3,  # Number of states (A, B, C)\n    \"M1\": len(data_condition1),  # Number of subjects in condition 1\n    \"M2\": len(data_condition2),  # Number of subjects in condition 2\n    \"L\": steps,  # Length of each sequence (number of trials)\n    \"y1\": data_condition1,  # Data for condition 1\n    \"y2\": data_condition2,  # Data for condition 2\n}\n\nStampiamo i dati di due soggetti simulati nella condizione 1.\n\nprint(stan_data[\"y1\"][0:2])\n\n[[1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1], [1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n\n\n\n\n108.3.2 Modello Baseline\nImplementiamo ora in Stan il modello che non distingue tra le condizioni T e VR.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"paxinou_single_condition_model.stan\"\n)\n\nmodel_single = CmdStanModel(stan_file=stan_file)\nprint(model_single.code())\n\ndata {\n  int&lt;lower=1&gt; N; // number of states\n  int&lt;lower=1&gt; M1; // number of subjects in condition 1\n  int&lt;lower=1&gt; M2; // number of subjects in condition 2\n  int&lt;lower=1&gt; L; // length of each sequence\n  array[M1, L] int&lt;lower=1, upper=N&gt; y1; // observed sequences for condition 1\n  array[M2, L] int&lt;lower=1, upper=N&gt; y2; // observed sequences for condition 2\n}\nparameters {\n  array[N] simplex[N] P; // shared transition matrix for all data\n}\nmodel {\n  for (m in 1 : M1) {\n    for (l in 2 : L) {\n      y1[m, l] ~ categorical(P[y1[m, l - 1]]);\n    }\n  }\n  for (m in 1 : M2) {\n    for (l in 2 : L) {\n      y2[m, l] ~ categorical(P[y2[m, l - 1]]);\n    }\n  }\n}\ngenerated quantities {\n  array[M1 * (L - 1) + M2 * (L - 1)] real log_lik; // combined log likelihoods for all observations\n  \n  int idx = 1;\n  \n  // Compute log likelihoods for condition 1\n  for (m in 1 : M1) {\n    for (l in 2 : L) {\n      log_lik[idx] = categorical_lpmf(y1[m, l] | P[y1[m, l - 1]]);\n      idx += 1;\n    }\n  }\n  \n  // Compute log likelihoods for condition 2\n  for (m in 1 : M2) {\n    for (l in 2 : L) {\n      log_lik[idx] = categorical_lpmf(y2[m, l] | P[y2[m, l - 1]]);\n      idx += 1;\n    }\n  }\n}\n\n\n\nQuesto modello utilizza una catena di Markov per analizzare il progresso degli studenti attraverso diversi stati di apprendimento sotto due differenti condizioni di insegnamento. L’obiettivo è stimare una singola matrice di transizione che rappresenti come gli studenti si spostano tra vari stati di apprendimento, indipendentemente dalla condizione di insegnamento.\nLe componenti principali del modello sono:\n\nStati di Apprendimento: A: “Ho completato il passaggio facilmente”; B: “Ho eventualmente completato il passaggio, ma con difficoltà”; C: “Non sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto”.\nSequenze di Apprendimento: Serie di stati attraversati da ciascuno studente durante l’esperimento.\nMatrice di Transizione: Descrive le probabilità di passare da uno stato all’altro.\n\nI dati in input hanno la seguente struttura:\n\nN: Numero di stati di apprendimento possibili.\nM1 e M2: Numero di studenti per ciascuna condizione di insegnamento.\nL: Numero di passi dell’esperimento che ogni studente deve completare.\ny1 e y2: Sequenze osservate di stati per gli studenti nelle due condizioni di insegnamento.\n\nEsaminiamo ora il funzionamento del modello. La matrice di transizione P è la componente chiave. Ogni riga di P rappresenta uno stato attuale, con i valori che indicano le probabilità di passare agli altri stati. Il modello presuppone che queste probabilità siano uguali per entrambe le condizioni di insegnamento.\nIl processo inizia con una stima iniziale di P. Il modello esamina le sequenze di stati di ogni studente per entrambe le condizioni, calcolando la probabilità di ogni transizione osservata usando P. Successivamente, aggiorna P per massimizzare la probabilità complessiva di tutte le sequenze osservate. Questo processo iterativo continua fino a trovare la migliore stima possibile di P.\nLa matrice P è costituita da righe che rappresentano distribuzioni categoriali per ciascuno stato attuale. La distribuzione categorical è una generalizzazione della distribuzione binomiale per più categorie, permettendo di modellare esiti con più di due possibili risultati (come A, B, C), mantenendo la somma delle probabilità pari a 1.\nIl cuore del modello è costituito dall’istruzione y1[m, l] ~ categorical(P[y1[m, l - 1]]);. Questa istruzione modella la probabilità di osservare una determinata transizione di stato all’interno di una sequenza di apprendimento:\n\ny1[m, l]: Stato osservato per lo studente m al passo l.\ncategorical: Distribuzione di probabilità discreta per modellare eventi con diversi esiti.\nP[y1[m, l - 1]]: Seleziona la riga della matrice P corrispondente allo stato precedente, contenente le probabilità di transizione agli altri stati.\n\nL’istruzione y1[m, l] ~ categorical(P[y1[m, l - 1]]);:\n\nSimula la probabilità che lo studente m passi da uno stato all’altro tra il passo l-1 e l.\nUsa la riga di P corrispondente allo stato precedente per determinare le probabilità di transizione.\nValuta quanto è probabile osservare la sequenza di stati y1 data la matrice P.\n\nQuesta istruzione assegna una probabilità alla transizione osservata, che Stan utilizza per aggiornare le stime dei parametri del modello, migliorando l’accuratezza complessiva della matrice P stimata.\nUna volta chiarito il modello, eseguiamo il campionamento.\n\nfit_single = model_single.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_single.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_single_condition_modeli6rc4wxk/paxinou_single_condition_model-20240826095506_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_single_condition_modeli6rc4wxk/paxinou_single_condition_model-20240826095506_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_single_condition_modeli6rc4wxk/paxinou_single_condition_model-20240826095506_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_single_condition_modeli6rc4wxk/paxinou_single_condition_model-20240826095506_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nConvertiamo l’oggetto fit_sample in un formato compatibile con ArviZ.\n\nfit_single_az = az.from_cmdstanpy(posterior=fit_single)\n\nEsaminiamo la matrice di transizione stimata dal modello.\n\n# Access posterior samples for the shared transition matrix 'P'\nP_samples = fit_single_az.posterior[\"P\"].values\n\n# P_samples likely have the shape: (chains, draws, N, N)\n# where 'chains' is the number of chains, 'draws' is the number of samples, and N is the number of states (3 in this case)\n\n# First, average over the chains axis (axis=0)\nP_samples_mean_over_chains = np.mean(P_samples, axis=0)\n\n# Then, average over the draws axis (axis=0)\nP_mean = np.mean(P_samples_mean_over_chains, axis=0)\n\n# The result is a 3x3 matrix\nprint(\"Estimated Transition Matrix (Mean):\")\nprint(P_mean.round(2))\n\nEstimated Transition Matrix (Mean):\n[[0.83 0.1  0.07]\n [0.6  0.35 0.05]\n [0.75 0.2  0.05]]",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#modello-per-gruppi-separati",
    "href": "chapters/dynamic_models/05_sequential_learning.html#modello-per-gruppi-separati",
    "title": "108  Analisi dinamica delle sequenze di apprendimento",
    "section": "108.4 Modello per Gruppi Separati",
    "text": "108.4 Modello per Gruppi Separati\nEsaminiamo ora il modello che assume diverse matrici di transizioni per i due gruppi.\n\nstan_sep_tran_mat_file = os.path.join(\n    project_directory, \"stan\", \"paxinou_separate_transition_matrices_model.stan\"\n)\n\nmodel_separate = CmdStanModel(stan_file=stan_sep_tran_mat_file)\nprint(model_separate.code())\n\ndata {\n  int&lt;lower=1&gt; N; // number of states\n  int&lt;lower=1&gt; M1; // number of subjects in condition 1\n  int&lt;lower=1&gt; M2; // number of subjects in condition 2\n  int&lt;lower=1&gt; L; // length of each sequence\n  array[M1, L] int&lt;lower=1, upper=N&gt; y1; // observed sequences for condition 1\n  array[M2, L] int&lt;lower=1, upper=N&gt; y2; // observed sequences for condition 2\n}\nparameters {\n  array[N] simplex[N] P1; // transition matrix for condition 1\n  array[N] simplex[N] P2; // transition matrix for condition 2\n}\nmodel {\n  // Likelihood for condition 1 using P1\n  for (m in 1 : M1) {\n    for (l in 2 : L) {\n      y1[m, l] ~ categorical(P1[y1[m, l - 1]]);\n    }\n  }\n  \n  // Likelihood for condition 2 using P2\n  for (m in 1 : M2) {\n    for (l in 2 : L) {\n      y2[m, l] ~ categorical(P2[y2[m, l - 1]]);\n    }\n  }\n}\ngenerated quantities {\n  array[M1 * (L - 1) + M2 * (L - 1)] real log_lik; // combined log likelihoods for all observations\n  int idx = 1; // Index for combined log likelihoods array\n  \n  // Compute log likelihoods for condition 1\n  for (m in 1 : M1) {\n    for (l in 2 : L) {\n      log_lik[idx] = categorical_lpmf(y1[m, l] | P1[y1[m, l - 1]]);\n      idx += 1;\n    }\n  }\n  \n  // Compute log likelihoods for condition 2\n  for (m in 1 : M2) {\n    for (l in 2 : L) {\n      log_lik[idx] = categorical_lpmf(y2[m, l] | P2[y2[m, l - 1]]);\n      idx += 1;\n    }\n  }\n}\n\n\n\nA differenza del modello precedente, che stima una singola matrice di transizione per entrambe le condizioni, questo modello stima due matrici di transizione distinte: una per ciascuna condizione di insegnamento. L’obiettivo è vedere se e come le dinamiche di apprendimento differiscono tra le due condizioni.\nRispetto al modello con una singola matrice di transizione, il codice Stan per il modello con due matrici di transizione presenta alcune differenze fondamentali:\n\nDefinisce due matrici di transizione distinte, P1 e P2, per rappresentare separatamente le probabilità di transizione per ciascuna condizione.\nLa verosimiglianza è calcolata separatamente per ciascuna condizione\n\nEseguiamo il campionamento.\n\nfit_separate = model_separate.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_separate.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_separate_transition_matrices_model782l5f79/paxinou_separate_transition_matrices_model-20240826092027_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_separate_transition_matrices_model782l5f79/paxinou_separate_transition_matrices_model-20240826092027_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_separate_transition_matrices_model782l5f79/paxinou_separate_transition_matrices_model-20240826092027_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp3kv6pme3/paxinou_separate_transition_matrices_model782l5f79/paxinou_separate_transition_matrices_model-20240826092027_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\n\nfit_separate_az = az.from_cmdstanpy(posterior=fit_separate)\n\nEsaminiamo le due matrici di transizione stimate dal modello.\n\n# Access posterior samples for the transition matrices 'P1' and 'P2'\nP1_samples = fit_separate_az.posterior[\"P1\"].values\nP2_samples = fit_separate_az.posterior[\"P2\"].values\n\n# P1_samples and P2_samples likely have the shape: (chains, draws, N, N)\n# where 'chains' is the number of chains, 'draws' is the number of samples, and N is the number of states (3 in this case)\n\n# First, average over the chains axis (axis=0) for both P1 and P2\nP1_samples_mean_over_chains = np.mean(P1_samples, axis=0)\nP2_samples_mean_over_chains = np.mean(P2_samples, axis=0)\n\n# Then, average over the draws axis (axis=0) for both P1 and P2\nP1_mean = np.mean(P1_samples_mean_over_chains, axis=0)\nP2_mean = np.mean(P2_samples_mean_over_chains, axis=0)\n\n# The result for each is a 3x3 matrix\nprint(\"Estimated Transition Matrix for Condition 1 (Mean):\")\nprint(P1_mean.round(2))\n\nprint(\"\\nEstimated Transition Matrix for Condition 2 (Mean):\")\nprint(P2_mean.round(2))\n\nEstimated Transition Matrix for Condition 1 (Mean):\n[[0.77 0.13 0.1 ]\n [0.75 0.15 0.1 ]\n [0.55 0.32 0.12]]\n\nEstimated Transition Matrix for Condition 2 (Mean):\n[[0.85 0.08 0.07]\n [0.57 0.42 0.01]\n [0.8  0.17 0.03]]\n\n\nSi noti la buona corrispondenza tra i valori stimati e i valori usati nella simulazione dei dati.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#valutazione-e-confronto-di-modelli",
    "href": "chapters/dynamic_models/05_sequential_learning.html#valutazione-e-confronto-di-modelli",
    "title": "108  Analisi dinamica delle sequenze di apprendimento",
    "section": "108.5 Valutazione e Confronto di Modelli",
    "text": "108.5 Valutazione e Confronto di Modelli\nEseguiamo il calcolo dei valori k di Pareto e la validazione incrociata Leave-One-Out (LOO-CV) utilizzando ArviZ per il modello di baseline.\n\nloo_single = az.loo(fit_single_az)\nprint(loo_single)\n\nComputed from 8000 posterior samples and 1200 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -728.89    28.51\np_loo        5.79        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1200  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nRipetiamo il processo per il modello che distingue tra i gruppi.\n\nloo_separate = az.loo(fit_separate_az)\nprint(loo_separate)\n\nComputed from 8000 posterior samples and 1200 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo  -709.93    28.46\np_loo       10.55        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1200  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nEseguiamo un confronto tra i due modelli.\n\ndf_comp_loo = az.compare({\n    \"single_model\": loo_single, \n    \"separate_model\": loo_separate\n})\ndf_comp_loo\n\n\n\n\n\n\n\n\nrank\nelpd_loo\np_loo\nelpd_diff\nweight\nse\ndse\nwarning\nscale\n\n\n\n\nseparate_model\n0\n-709.926886\n10.545689\n0.000000\n0.903335\n28.458712\n0.00000\nFalse\nlog\n\n\nsingle_model\n1\n-728.893768\n5.791815\n18.966882\n0.096665\n28.513270\n6.79972\nFalse\nlog\n\n\n\n\n\n\n\n\n_ = az.plot_compare(df_comp_loo, insample_dev=False)\n\n\n\n\n\n\n\n\nSi noti che il rapporto tra elpd_diff e dse è maggiore di 2 e che il modello preferito è quello che distingue tra i gruppi. Questo indica che il modello che distingue tra i gruppi si adatta meglio ai dati. Nuovamente, questo non è sorprendente dato che i dati sono stati generati in questo modo. Ma la simulazione indica che, se questo fosse il meccanismo generatore dei dati, con 50 soggetti per gruppo sarebbe possibile distinguere tra i due modelli.\nLa prossima domanda è stabilire quale metodo d’insegnamento funzioni meglio. Per rispondere a questa domanda, calcoliamo la probabilità che transitare allo stato A sia maggiore nella condizione VR che nella condizione T.\n\n# Extract posterior samples for transition matrices P1 and P2\nP1_samples = fit_separate_az.posterior[\n    \"P1\"\n].values  # Transition matrix for condition 1 (T-Group)\nP2_samples = fit_separate_az.posterior[\n    \"P2\"\n].values  # Transition matrix for condition 2 (VR-Group)\n\n# Number of states (assumed to be 3)\nnum_states = 3\n\n# Initialize lists to store the probabilities for each state transition\nprob_better_performance = []\nprob_worse_performance = []\n\n# Check transitions to state A and from any state to state C\nfor i in range(num_states):\n    # Transition to state A (index 0)\n    P1_to_A = P1_samples[\n        :, :, i, 0\n    ]  # Probability of transitioning to state A in T-Group\n    P2_to_A = P2_samples[\n        :, :, i, 0\n    ]  # Probability of transitioning to state A in VR-Group\n\n    # Compute probability that the VR condition has a higher probability of transitioning to state A\n    prob_to_A_better = np.mean(P2_to_A &gt; P1_to_A)\n    prob_better_performance.append(prob_to_A_better)\n\n    # Transition to state C (index 2)\n    P1_to_C = P1_samples[\n        :, :, i, 2\n    ]  # Probability of transitioning to state C in T-Group\n    P2_to_C = P2_samples[\n        :, :, i, 2\n    ]  # Probability of transitioning to state C in VR-Group\n\n    # Compute probability that the VR condition has a lower probability of transitioning to state C\n    prob_to_C_worse = np.mean(P2_to_C &lt; P1_to_C)\n    prob_worse_performance.append(prob_to_C_worse)\n\n# Print the results\nprint(\n    \"Probability that VR condition has a higher probability of transitioning to state A:\"\n)\nfor i in range(num_states):\n    print(f\"From state {i+1} to state A: {prob_better_performance[i]:.2f}\")\n\nprint(\n    \"\\nProbability that VR condition has a lower probability of transitioning to state C:\"\n)\nfor i in range(num_states):\n    print(f\"From state {i+1} to state C: {prob_worse_performance[i]:.2f}\")\n\nProbability that VR condition has a higher probability of transitioning to state A:\nFrom state 1 to state A: 1.00\nFrom state 2 to state A: 0.00\nFrom state 3 to state A: 0.89\n\nProbability that VR condition has a lower probability of transitioning to state C:\nFrom state 1 to state C: 1.00\nFrom state 2 to state C: 0.77\nFrom state 3 to state C: 0.81\n\n\n\n108.5.1 Interpretazione\nBasandosi sui risultati ottenuti, vediamo di interpretare il significato di ogni probabilità nel contesto della simulazione e dello studio originale.\n\nDallo stato 1 allo stato A: 1.00. La probabilità è 1.00, il che indica che, in tutti i campioni posteriori, la condizione VR (Condizione 2) ha una probabilità più alta di passare dallo stato 1 (“Ho completato il passaggio facilmente”) allo stato A (“Ho completato il passaggio facilmente”) rispetto alla condizione T-Group (Condizione 1). Questo suggerisce che, una volta che i partecipanti nella condizione VR hanno completato con successo un passaggio, è più probabile che continuino a completare facilmente i passaggi successivi.\nDallo stato 2 allo stato A: 0.00. La probabilità è 0.00, il che indica che la condizione VR non ha una probabilità più alta di passare dallo stato 2 (“Ho finalmente completato il passaggio, ma con difficoltà”) allo stato A rispetto alla condizione T-Group. Questo suggerisce che quando i partecipanti stanno affrontando delle difficoltà (stato 2), nella condizione VR non sono più propensi rispetto alla condizione T-Group a passare a completare facilmente il passaggio successivo (stato A).\nDallo stato 3 allo stato A: 0.89. La probabilità è 0.89, il che indica che c’è l’89% di possibilità che la condizione VR abbia una probabilità più alta di passare dallo stato 3 (“Non sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto”) allo stato A rispetto alla condizione T-Group. Questo suggerisce che, anche quando i partecipanti chiedono aiuto (stato 3), è più probabile che nella condizione VR completino facilmente il passaggio successivo (stato A) rispetto alla condizione T-Group.\n\nCalcoliamo la probabilità che la condizione VR abbia una probabilità più bassa di passare allo stato C:\n\nDallo stato 1 allo stato C: 1.00. La probabilità è 1.00, indicando che la condizione VR ha una probabilità costantemente più bassa di passare dallo stato 1 (“Ho completato il passaggio facilmente”) allo stato C (“Non sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto”) rispetto alla condizione T-Group. Questo suggerisce che i partecipanti nella condizione VR sono molto meno propensi a regredire dal completare facilmente un passaggio a dover chiedere aiuto.\nDallo stato 2 allo stato C: 0.77. La probabilità è 0.77, indicando una probabilità del 77% che la condizione VR abbia una probabilità più bassa di passare dallo stato 2 (“Ho finalmente completato il passaggio, ma con difficoltà”) allo stato C rispetto alla condizione T-Group. Questo suggerisce che i partecipanti nella condizione VR sono generalmente meno propensi a passare dal trovarsi in difficoltà al dover chiedere aiuto rispetto a quelli nella condizione T-Group.\nDallo stato 3 allo stato C: 0.81. La probabilità è 0.81, il che indica una probabilità dell’81% che la condizione VR abbia una probabilità più bassa di rimanere nello stato C o di passare a esso (“Non sono riuscito a completare il passaggio da solo, quindi ho chiesto aiuto”) rispetto alla condizione T-Group. Questo suggerisce che, anche quando i partecipanti chiedono aiuto, è meno probabile che continuino a dover chiedere aiuto nella condizione VR rispetto alla condizione T-Group.\n\nI risultati mostrano che, complessivamente, i partecipanti nella condizione VR (Condizione 2) tendono ad avere risultati di performance migliori rispetto a quelli nella condizione T-Group (Condizione 1). In particolare:\n\nMaggiore probabilità di completamento facile (Stato A): La condizione VR mostra una forte tendenza (probabilità 1.00 e 0.89) a portare a una performance migliore (passaggio allo stato A) rispetto alla condizione T-Group, specialmente dallo stato 3 (richiesta di aiuto) allo stato A (completamento facile).\nMinore probabilità di necessità di aiuto (Stato C): La condizione VR mostra anche una tendenza (probabilità 1.00, 0.77 e 0.81) ad avere una minore probabilità di necessità di aiuto (passaggio allo stato C) in diversi scenari. Questo suggerisce che i partecipanti nella condizione VR sono meno propensi a finire per aver bisogno di aiuto, indicando una performance complessivamente migliore.\n\nQuesti risultati sono in linea con la conclusione dello studio originale che la condizione VR migliora la performance riducendo la probabilità di dover chiedere aiuto e aumentando le possibilità di completare facilmente i compiti.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#riflessioni-conclusive",
    "href": "chapters/dynamic_models/05_sequential_learning.html#riflessioni-conclusive",
    "title": "108  Analisi dinamica delle sequenze di apprendimento",
    "section": "108.6 Riflessioni Conclusive",
    "text": "108.6 Riflessioni Conclusive\nIn questo tutorial abbiamo esplorato l’utilizzo di modelli a catena di Markov per valutare la performance degli studenti in esperimenti scientifici. Attraverso una simulazione basata sui dati di Paxinou et al. (2021), abbiamo confrontato l’efficacia di due diverse metodologie di insegnamento: il tradizionale tutorial in laboratorio e l’interazione con un software educativo in realtà virtuale (VR).\nI risultati empirici ottenuti da Paxinou et al. (2021) indicano che la metodologia di apprendimento basata sulla realtà virtuale è più efficace nell’aiutare gli studenti ad acquisire le competenze sperimentali necessarie. Gli studenti del gruppo VR hanno dimostrato una maggiore probabilità di completare i passaggi dell’esperimento facilmente e senza bisogno di assistenza rispetto agli studenti del gruppo T (tradizionale) e del gruppo V (video). In questo tutorial, abbiamo mostrato come sia possibile analizzare dati simili a quelli discussi da Paxinou et al. (2021) utilizzando modelli di catene di Markov di primo livello.\nPaxinou et al. (2021) commentano i loro risultati affermando che i modelli basati sulle catene di Markov sono strumenti utili non solo per valutare le performance e costruire funzioni di punteggio, ma anche per l’analisi delle competenze acquisite. Inoltre, questi modelli possono essere impiegati per prevedere e intervenire efficacemente durante il processo educativo. I risultati suggeriscono che l’analisi delle catene di Markov può fornire valutazioni dinamiche e personalizzate delle competenze degli studenti, permettendo agli educatori di intervenire in modo mirato e fornire feedback tempestivi ed efficaci.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#esercizi",
    "href": "chapters/dynamic_models/05_sequential_learning.html#esercizi",
    "title": "108  Analisi dinamica delle sequenze di apprendimento",
    "section": "108.7 Esercizi",
    "text": "108.7 Esercizi\n\nEsercizio 108.1 Un altro studio interessante che utilizza questo approccio è quello di Zanesco (2020). I flussi di pensiero variano nel contenuto da un momento all’altro, e questi schemi temporali sono ritenuti fondamentali per comprendere il mind wandering. Tuttavia, sono stati proposti pochi metodi analitici in grado di considerare sia il contenuto sia l’ordine temporale delle risposte categoriche che possono essere campionate relativamente a questa esperienza nel tempo. Il flusso di pensiero raramente segue lo stesso percorso per un individuo, ma mostra comunque con una certa prevedibilità nel contesto di un compito cognitivo. In questo studio, i partecipanti hanno selezionato tra 8 opzioni possibili per descrivere se la loro attenzione fosse attualmente concentrata sul “compito” (opzione 1); se stessero sperimentando pensieri rivolti alla “performance e valutazione del compito” (opzione 2); pensieri riguardanti le “preoccupazioni quotidiane” (opzione 3); pensieri sul proprio stato “fisico, cognitivo o emotivo” (opzione 4); pensieri su “preoccupazioni personali” (opzione 5); pensieri fantasiosi e “sogni a occhi aperti” (opzione 6); pensieri sugli stimoli presenti nell’“ambiente esterno” (opzione 7); e “altri” pensieri non descritti dalle altre categorie (opzione 8). Zanesco (2020) ha applicato metodi di analisi sequenziale, utilizzando il modello di Markov di primo ordine, a questi campioni di pensiero categoriale, e i risultati hanno rivelato una certa misura di ordine e coerenza nei flussi di pensiero degli individui.\nUn possibile esercizio consiste nel simulare i dati utilizzando gli 8 stati considerati da Zanesco (2020) e la matrice di transizione riportata nel suo studio. Successivamente, si può applicare il modello di Markov di primo ordine per stimare la matrice di transizione dai dati simulati. Seguendo l’approccio di Zanesco (2020), i risultati ottenuti possono poi essere interpretati per approfondire la comprensione del fenomeno del mind wandering.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/05_sequential_learning.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/05_sequential_learning.html#informazioni-sullambiente-di-sviluppo",
    "title": "108  Analisi dinamica delle sequenze di apprendimento",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Sun Aug 25 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nbambi     : 0.14.0\nlogging   : 0.5.1.2\nnumpy     : 1.26.4\npandas    : 2.2.2\narviz     : 0.18.0\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\nmatplotlib: 3.9.1\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nPaxinou, E., Kalles, D., Panagiotakopoulos, C. T., & Verykios, V. S. (2021). Analyzing sequence data with Markov chain models in scientific experiments. SN Computer Science, 2(5), 385.\n\n\nZanesco, A. P. (2020). Quantifying streams of thought during cognitive task performance using sequence analysis. Behavior Research Methods, 52(6), 2417–2437.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>Analisi dinamica delle sequenze di apprendimento</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html",
    "title": "109  Modello di Markov nascosto",
    "section": "",
    "text": "Introduzione\nImmaginiamo di osservare il comportamento di un amico, ma senza poter leggere la sua mente. Questo è il concetto alla base dei modelli nascosti di Markov (HMM, dall’inglese Hidden Markov Models). Gli HMM sono come un gioco in cui si cerca di indovinare cosa sta pensando qualcuno basandoci solo sulle sue azioni. In questo “gioco”:\nOra, immaginiamo di osservare il nostro amico per diversi giorni. Ogni giorno:\nQuesto è essenzialmente ciò che fa un HMM: cerca di capire la sequenza degli stati nascosti (stati d’animo) basandosi sulla sequenza di osservazioni (azioni).\nIn termini formali, un modello nascosto di Markov (HMM) è un modello probabilistico composto da due processi:\nLa struttura di un HMM può essere visualizzata attraverso un grafico diretto, come mostrato nella figura. In questo grafico:\nIn un HMM, gli stati nascosti controllano la generazione delle osservazioni, ma non possiamo osservare direttamente questi stati, solo le osservazioni risultanti. Gli HMM sono utili in molte situazioni reali dove non possiamo vedere direttamente ciò che sta realmente accadendo. Gli HMM ci aiutano a fare previsioni sugli stati nascosti basandoci su ciò che possiamo effettivamente osservare.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#introduzione",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#introduzione",
    "title": "109  Modello di Markov nascosto",
    "section": "",
    "text": "Il pensiero o lo stato d’animo del nostro amico rappresenta lo “stato nascosto”. Non possiamo vederlo direttamente.\nLe azioni o il comportamento del nostro amico sono le “osservazioni” che possiamo vedere.\nLo stato d’animo del nostro amico cambia nel tempo, ma in modo prevedibile. Ad esempio, se è felice oggi, c’è una buona probabilità che sarà felice anche domani.\nLe azioni del nostro amico dipendono dal suo stato d’animo attuale. Se è felice, potrebbe sorridere di più; se è triste, potrebbe parlare meno.\n\n\n\nIl suo stato d’animo (che non vediamo) dipende principalmente da come si sentiva il giorno prima.\nLe sue azioni (che vediamo) dipendono solo da come si sente quel giorno, non da come si sentiva ieri o da cosa ha fatto ieri.\n\n\n\n\nUn processo nascosto di Markov \\(\\{C_t : t \\in \\mathbb{N}\\}\\)\nUn processo osservabile \\(\\{X_t : t \\in \\mathbb{N}\\}\\) dipendente dagli stati nascosti.\n\n\n\n\nGrafico diretto del modello nascosto di Markov (HMM).\n\n\n\n\nI nodi \\(C_t\\) rappresentano gli stati nascosti.\nI nodi \\(X_t\\) rappresentano le osservazioni.\nLe frecce indicano le dipendenze probabilistiche.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#proprietà-degli-hmm",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#proprietà-degli-hmm",
    "title": "109  Modello di Markov nascosto",
    "section": "109.1 Proprietà degli HMM",
    "text": "109.1 Proprietà degli HMM\nUn HMM è definito dalle seguenti proprietà:\n\nProprietà di Markov per gli stati nascosti: La probabilità di essere in uno stato attuale \\(C_t\\) dipende solo dallo stato immediatamente precedente \\(C_{t-1}\\):\n\\[\\Pr(C_t | C_1, C_2, ..., C_{t-1}) = \\Pr(C_t | C_{t-1}), \\quad t = 2,3, ...\\]\nIndipendenza condizionale delle osservazioni: La probabilità di un’osservazione \\(X_t\\) dipende solo dallo stato corrente \\(C_t\\):\n\\[\\Pr(X_t | X_1, X_2, ..., X_{t-1}, C_1, C_2, ..., C_t) = \\Pr(X_t | C_t), \\quad t \\in \\mathbb{N}.\\]",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#elementi-di-un-hmm",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#elementi-di-un-hmm",
    "title": "109  Modello di Markov nascosto",
    "section": "109.2 Elementi di un HMM",
    "text": "109.2 Elementi di un HMM\nUn HMM è completamente definito da tre elementi:\n\nMatrice di transizione degli stati \\(A = (a_{ij})\\)\n\nLa matrice di transizione degli stati, denotata come \\(A = (a_{ij})\\), descrive le probabilità di transizione tra gli stati nascosti nel modello. Ogni elemento \\(a_{ij}\\) della matrice rappresenta la probabilità di passare dallo stato nascosto \\(i\\) allo stato nascosto \\(j\\) da un tempo \\(t\\) al tempo successivo \\(t+1\\).\nMatematicamente, questo è espresso come:\n\\[\na_{ij} = \\Pr(C_t = j | C_{t-1} = i).\n\\]\nQuesto significa che, dato che il processo si trova nello stato \\(i\\) al tempo \\(t-1\\), la probabilità che si trovi nello stato \\(j\\) al tempo \\(t\\) è \\(a_{ij}\\). La matrice \\(A\\) deve soddisfare la condizione che la somma delle probabilità di ogni riga sia uguale a 1, ovvero \\(\\sum_{j} a_{ij} = 1\\) per ogni stato \\(i\\). Questo riflette il fatto che, partendo da uno stato qualsiasi, il processo deve necessariamente transitare in uno degli stati possibili nel passo successivo.\n\nMatrice di emissione \\(B = (b_{j}(k))\\)\n\nLa matrice di emissione, indicata come \\(B = (b_{j}(k))\\), rappresenta le probabilità di emissione, ovvero le probabilità di osservare un certo output (osservazione) dato uno stato nascosto specifico. Ogni elemento \\(b_{j}(k)\\) della matrice descrive la probabilità di osservare l’output \\(k\\) quando il processo si trova nello stato nascosto \\(j\\).\nMatematicamente, questo è rappresentato da:\n\\[\nb_{j}(k) = \\Pr(X_t = k | C_t = j).\n\\]\nIn altre parole, se il processo è nello stato nascosto \\(j\\) al tempo \\(t\\), \\(b_{j}(k)\\) rappresenta la probabilità che l’osservazione al tempo \\(t\\) sia \\(k\\). La matrice \\(B\\) deve essere costruita in modo tale che, per ogni stato \\(j\\), la somma delle probabilità di emissione per tutti i possibili output \\(k\\) sia pari a 1, ovvero \\(\\sum_{k} b_{j}(k) = 1\\). Questo garantisce che, dato uno stato nascosto, l’emissione deve essere uno degli output possibili.\n\nDistribuzione iniziale degli stati \\(\\pi = (\\pi_i)\\)\n\nLa distribuzione iniziale degli stati, denotata come \\(\\pi = (\\pi_i)\\), specifica la probabilità che il processo inizi in ciascuno dei possibili stati nascosti. Ogni elemento \\(\\pi_i\\) rappresenta la probabilità che il processo inizi nello stato \\(i\\) al tempo iniziale \\(t = 1\\).\nQuesto è definito come:\n\\[\n\\pi_i = \\Pr(C_1 = i).\n\\]\nQuesta distribuzione iniziale fornisce le probabilità di partenza per gli stati nascosti, determinando in quale stato il processo inizia prima che avvengano le osservazioni. La somma di tutte le probabilità nella distribuzione iniziale deve essere uguale a 1, ovvero \\(\\sum_{i} \\pi_i = 1\\), poiché il processo deve iniziare in uno degli stati possibili.\nIn sintesi, un HMM è completamente definito da questi tre elementi: la matrice di transizione degli stati (\\(A\\)), che descrive le probabilità di passaggio tra stati nascosti; la matrice di emissione (\\(B\\)), che descrive le probabilità delle osservazioni date gli stati nascosti; e la distribuzione iniziale degli stati (\\(\\pi\\)), che specifica le probabilità di partenza per gli stati nascosti. Insieme, questi componenti permettono di modellare fenomeni complessi in cui i dati osservabili sono influenzati da stati interni non direttamente osservabili, fornendo una struttura matematica per fare inferenze su tali stati nascosti basandosi sulle osservazioni disponibili.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#le-fluttuazioni-dellumore-in-pazienti-con-disturbo-bipolare",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#le-fluttuazioni-dellumore-in-pazienti-con-disturbo-bipolare",
    "title": "109  Modello di Markov nascosto",
    "section": "109.3 Le Fluttuazioni dell’Umore in Pazienti con Disturbo Bipolare",
    "text": "109.3 Le Fluttuazioni dell’Umore in Pazienti con Disturbo Bipolare\nIn questo capitolo esamineremo un’applicazione degli HMM usata nella recente letteratura psicologica. In particolare, discuteremo lo studio di Mildiner Moraga et al. (2024) che applica un modello di Markov nascosto (Hidden Markov Model, HMM) per analizzare le fluttuazioni dell’umore in pazienti con disturbo bipolare. Mildiner Moraga et al. (2024) applicano un HMM a dati raccolti tramite Ecological Momentary Assessment (EMA) intensivo, basato su dodici item che catturano vari aspetti dell’umore su una base longitudinale intensiva. Questo tipo di dati permette di monitorare in modo dettagliato e continuo i cambiamenti nell’umore dei pazienti, fornendo una ricca fonte di informazioni per l’analisi dinamica.\nMildiner Moraga et al. (2024) hanno sviluppato e testato il modello HMM considerando diverse configurazioni, variando il numero di stati nascosti da due a sette. Questa scelta si basa su evidenze provenienti da studi precedenti, che suggeriscono una variabilità nel numero di stati necessari per descrivere adeguatamente le diverse manifestazioni cliniche del disturbo bipolare. La selezione del modello ottimale è stata effettuata utilizzando criteri di informazione statistica, come il Bayesian Information Criterion (BIC), per identificare il numero di stati che meglio descrivevano le transizioni dell’umore dei pazienti senza sovra-adattamento dei dati.\nIn questo tutorial, utilizzeremo dati simulati per illustrare come applicare un HMM con quattro stati nascosti, considerando i dati di un singolo paziente. Questa configurazione a quattro stati riflette una suddivisione clinicamente rilevante degli stati dell’umore in:\n\nNeutro: uno stato di equilibrio emotivo senza sintomi significativi di mania o depressione.\nElevato: uno stato caratterizzato da umore maniacale o ipomaniacale.\nMisto: uno stato in cui coesistono sintomi sia maniacali che depressivi.\nAbbassato: uno stato di umore depresso con sintomi depressivi predominanti.\n\nL’analisi dei dati simulati con un HMM a quattro stati ci permetterà di esplorare come questo modello può essere utilizzato per identificare e analizzare le transizioni tra diversi stati dell’umore, fornendo un esempio pratico delle potenzialità di questo approccio per la ricerca e la pratica clinica nel campo della salute mentale.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#simulazione-dei-dati",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#simulazione-dei-dati",
    "title": "109  Modello di Markov nascosto",
    "section": "109.4 Simulazione dei Dati",
    "text": "109.4 Simulazione dei Dati\nIn questo tutorial, considereremo un modello HMM generativo con 4 stati nascosti e 3 possibili categorie di osservazione. Definiremo le probabilità iniziali degli stati, una specifica matrice di transizione tra stati nascosti e una matrice di emissione per le osservazioni. Con queste impostazioni, simuleremo un set di dati composto da 5000 osservazioni che seguono la struttura del modello definito.\n\n# Set the number of hidden states and observation categories\nM = 4  # Number of hidden states: neutral, elevated, mixed, lowered\nK = 3  # Number of observation categories (e.g., low, medium, high)\nN = 5000  # Number of observations to simulate\n\n# Initial state probabilities (uniform for simplicity)\npi = np.array([0.25, 0.25, 0.25, 0.25])\n\n# Transition matrix (M x M)\nA = np.array(\n    [\n        [0.6, 0.2, 0.1, 0.1],\n        [0.1, 0.7, 0.1, 0.1],\n        [0.1, 0.1, 0.7, 0.1],\n        [0.2, 0.1, 0.1, 0.6],\n    ]\n)\n\n# Emission matrix for categorical distribution (M x K)\nB = np.array(\n    [\n        [0.7, 0.2, 0.1],  # Emissions from 'neutral' state\n        [0.1, 0.8, 0.1],  # Emissions from 'elevated' state\n        [0.3, 0.3, 0.4],  # Emissions from 'mixed' state\n        [0.2, 0.2, 0.6],  # Emissions from 'lowered' state\n    ]\n)\n\n# Simulate hidden states and observations\nhidden_states = np.zeros(N, dtype=int)\nobservations = np.zeros(N, dtype=int)\n\n# Simulate the initial hidden state based on initial probabilities\nhidden_states[0] = np.random.choice(M, p=pi)\n\n# Simulate the sequence of hidden states and observations\nfor t in range(1, N):\n    # Simulate the next hidden state based on transition matrix A\n    hidden_states[t] = np.random.choice(M, p=A[hidden_states[t - 1]])\n    # Simulate the observation based on the emission matrix B\n    observations[t] = np.random.choice(K, p=B[hidden_states[t]])\n\n# Convert to 1-based indexing for Stan (Stan expects indices to start from 1)\nobservations += 1\nhidden_states += 1\n\n# Prepare the data dictionary for Stan\nstan_data = {\n    \"N\": N,\n    \"M\": M,\n    \"K\": K,\n    \"y\": observations,  # Observations must be 1-based for Stan\n}\n\nprint(stan_data)\n\n{'N': 5000, 'M': 4, 'K': 3, 'y': array([1, 2, 1, ..., 3, 2, 1])}",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#simulazione-dei-dati-1",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#simulazione-dei-dati-1",
    "title": "109  Modello di Markov nascosto",
    "section": "109.5 Simulazione dei Dati",
    "text": "109.5 Simulazione dei Dati\nNella simulazione, le osservazioni sono categorizzate in tre diverse modalità, ciascuna rappresentata da una categoria distinta nei dati. Queste modalità possono essere interpretate come diverse manifestazioni degli stati emotivi dei pazienti. Di seguito, viene fornita una possibile interpretazione di ciascuna modalità nel contesto di un HMM applicato al disturbo bipolare:\n\nModalità 1: Stato Stabile (ad esempio, “Normale” o “Neutro”):\n\nSignificato: Questa modalità rappresenta osservazioni che indicano uno stato di equilibrio emotivo del paziente. In questo contesto, “normale” o “neutro” significa che il paziente non manifesta sintomi evidenti di mania o depressione.\nEsempi di osservazioni: Risposte a questionari EMA che indicano sentimenti di calma, livelli energetici normali e un umore stabile, senza eccessi emotivi. Potrebbe anche includere l’assenza di segni di agitazione o tristezza.\n\nModalità 2: Stato Elevato (ad esempio, “Maniacale” o “Elevato”):\n\nSignificato: Questa modalità rappresenta osservazioni che suggeriscono uno stato di umore elevato, maniacale o ipomaniacale. In questo stato, il paziente mostra sintomi tipici della mania, come alta energia, euforia, irritabilità o comportamento impulsivo.\nEsempi di osservazioni: Risposte che indicano un significativo aumento dell’energia, bisogno ridotto di sonno, discorsi rapidi, incremento dell’attività o una tendenza a prendere decisioni impulsive. Questi sintomi sono coerenti con gli stati elevati osservati nei pazienti con disturbo bipolare.\n\nModalità 3: Stato Abbassato (ad esempio, “Depresso”):\n\nSignificato: Questa modalità indica osservazioni che suggeriscono uno stato di umore abbassato o depresso. In questo stato, il paziente manifesta sintomi di depressione come tristezza, mancanza di energia, sentimenti di inutilità o disperazione e possibile isolamento sociale.\nEsempi di osservazioni: Risposte che riflettono sentimenti di tristezza persistente, perdita di interesse o piacere nelle attività quotidiane, fatica, pensieri negativi e problemi di concentrazione o indecisione. Questi sintomi sono tipici degli episodi depressivi nel disturbo bipolare.\n\n\nNel modello HMM, ogni stato nascosto (neutro, elevato, misto, abbassato) è associato a una distribuzione di probabilità sulle tre modalità di osservazione. La matrice di emissione \\(B\\) specifica queste probabilità, indicando la probabilità di ciascuna osservazione in ogni stato nascosto.\nAd esempio:\n\nStato Nascosto “Neutro”: Questo stato ha una maggiore probabilità di generare osservazioni della Modalità 1 (“Normale” o “Neutro”) e una probabilità significativamente inferiore di generare osservazioni delle Modalità 2 (“Maniacale”) o 3 (“Depresso”).\nStato Nascosto “Elevato”: Questo stato ha una probabilità più alta di generare osservazioni della Modalità 2, che rappresentano sintomi maniacali o ipomaniacali, e una probabilità inferiore di generare osservazioni delle altre modalità.\nStato Nascosto “Abbassato”: Questo stato ha una probabilità maggiore di produrre osservazioni della Modalità 3 (“Depresso”), che corrispondono a sintomi depressivi.\nStato Nascosto “Misto”: Questo stato potrebbe avere una distribuzione più uniforme sulle tre modalità di osservazione, rappresentando la coesistenza di sintomi sia maniacali che depressivi.\n\nIn sintesi, l’HMM utilizza le osservazioni categorizzate per inferire quali stati nascosti sono più probabili in base ai dati raccolti. Un modello ben adattato dovrebbe essere in grado di utilizzare la matrice di emissione \\(B\\) per identificare correttamente i pattern di osservazione che indicano transizioni tra diversi stati emotivi, anche quando questi stati non sono direttamente osservabili.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#modello-hmm",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#modello-hmm",
    "title": "109  Modello di Markov nascosto",
    "section": "109.6 Modello HMM",
    "text": "109.6 Modello HMM\nIl modello HMM è stato implementato nel seguente script Stan.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"hmm_model.stan\"\n)\n\nmodel_single = CmdStanModel(stan_file=stan_file)\nprint(model_single.code())\n\ndata {\n  int&lt;lower=1&gt; N; // Number of observations\n  int&lt;lower=1&gt; M; // Number of hidden states\n  int&lt;lower=1&gt; K; // Number of observation categories\n  array[N] int&lt;lower=1, upper=K&gt; y; // Observations, coded as integers 1:K\n}\nparameters {\n  simplex[M] pi; // Initial state probabilities\n  array[M] simplex[M] A; // Transition matrix for hidden states\n  array[M] simplex[K] B; // Emission matrix for observation categories\n}\nmodel {\n  // Priors\n  pi ~ dirichlet(rep_vector(1.0, M));\n  for (m in 1 : M) {\n    A[m] ~ dirichlet(rep_vector(1.0, M));\n    B[m] ~ dirichlet(rep_vector(1.0, K));\n  }\n  \n  // Forward algorithm for likelihood\n  {\n    array[N, M] real log_alpha;\n    for (m in 1 : M) \n      log_alpha[1, m] = log(pi[m]) + categorical_lpmf(y[1] | B[m]);\n    \n    for (n in 2 : N) {\n      for (m in 1 : M) {\n        real acc = negative_infinity();\n        for (k in 1 : M) \n          acc = log_sum_exp(acc, log_alpha[n - 1, k] + log(A[k, m]));\n        log_alpha[n, m] = acc + categorical_lpmf(y[n] | B[m]);\n      }\n    }\n    target += log_sum_exp(log_alpha[N]);\n  }\n}\n\n\n\nGli stati nascosti seguono una catena di Markov, e le osservazioni sono emesse in base allo stato corrente. Le componenti del modello sono descritte di seguito.\n\nDati di Input (data block):\n\nint&lt;lower=1&gt; N;: Numero di osservazioni nella sequenza. Rappresenta la lunghezza della sequenza di dati osservati.\nint&lt;lower=1&gt; M;: Numero di stati nascosti. Questi stati non sono osservabili direttamente, ma influenzano la probabilità delle osservazioni.\nint&lt;lower=1&gt; K;: Numero di categorie di osservazione. Ogni osservazione può appartenere a una di queste categorie.\narray[N] int&lt;lower=1, upper=K&gt; y;: Un array di osservazioni categoriali, codificate come interi da 1 a \\(K\\).\n\nParametri del Modello (parameters block):\n\nsimplex[M] pi;: Vettore di probabilità iniziali per gli stati nascosti. Essendo un simplex, la somma di tutti gli elementi è pari a 1. Questo rappresenta la distribuzione iniziale degli stati nascosti al tempo \\(t = 1\\).\narray[M] simplex[M] A;: Matrice di transizione degli stati nascosti. Ogni riga \\(A[m]\\) è un simplex, e rappresenta le probabilità di transizione dall’attuale stato \\(m\\) a tutti gli altri stati \\(j\\). La somma di ogni riga è 1.\narray[M] simplex[K] B;: Matrice di emissione per le categorie di osservazione. Ogni riga \\(B[m]\\) è un simplex che rappresenta la distribuzione di probabilità delle osservazioni per uno stato nascosto \\(m\\). La somma di ogni riga è 1.\n\nModello di Inferenza (model block):\n\nPriors:\n\npi ~ dirichlet(rep_vector(1.0, M));: Assegna una prior di Dirichlet uniforme alle probabilità iniziali degli stati nascosti, implicando che ogni stato nascosto è ugualmente probabile all’inizio.\nA[m] ~ dirichlet(rep_vector(1.0, M));: Assegna una prior di Dirichlet uniforme a ogni riga della matrice di transizione \\(A\\), implicando che ogni transizione da uno stato a un altro è ugualmente probabile inizialmente.\nB[m] ~ dirichlet(rep_vector(1.0, K));: Assegna una prior di Dirichlet uniforme a ogni riga della matrice di emissione \\(B\\), implicando che ogni categoria di osservazione è inizialmente ugualmente probabile per ogni stato nascosto.\n\nAlgoritmo Forward per la Verosimiglianza:\n\nQuesto algoritmo calcola la verosimiglianza della sequenza osservata data la struttura del modello (gli stati nascosti e le loro transizioni). Utilizza una rappresentazione logaritmica per evitare problemi di underflow numerico.\nInizializzazione:\n\nlog_alpha[1, m] = log(pi[m]) + categorical_lpmf(y[1] | B[m]);\n\nCalcola la log-verosimiglianza iniziale per il primo elemento della sequenza osservata. Combina la log-probabilità di iniziare in ciascuno stato nascosto con la log-probabilità di osservare \\(y[1]\\) da ciascuno stato.\n\n\nRicorsione:\n\nfor (n in 2 : N): Ciclo attraverso ogni osservazione nella sequenza, dal secondo all’ultimo.\nfor (m in 1 : M): Per ogni possibile stato nascosto al tempo \\(n\\), calcola la log-verosimiglianza.\n\nreal acc = negative_infinity();: Inizializza un accumulatore per sommare in logaritmo le probabilità dei percorsi.\nfor (k in 1 : M) acc = log_sum_exp(acc, log_alpha[n - 1, k] + log(A[k, m]));\n\nSomma le probabilità di tutti i percorsi che portano al nuovo stato \\(m\\), considerando la probabilità di transizione da ciascuno stato precedente \\(k\\) a \\(m\\).\n\nlog_alpha[n, m] = acc + categorical_lpmf(y[n] | B[m]);\n\nAggiorna la log-verosimiglianza per il tempo \\(n\\) e lo stato \\(m\\) aggiungendo la log-probabilità dell’osservazione \\(y[n]\\) data dallo stato \\(m\\).\n\n\n\nTermine Finale:\n\ntarget += log_sum_exp(log_alpha[N]);\n\nSomma le log-verosimiglianze dell’ultimo elemento della sequenza osservata su tutti gli stati nascosti, aggiornando il log-verosimiglianza complessiva del modello.\n\n\n\n\n\nIn sintesi, questo script Stan definisce un HMM in cui:\n\nGli stati nascosti seguono una distribuzione di probabilità iniziale (\\(\\pi\\)) e una matrice di transizione (\\(A\\)) che governa come gli stati cambiano nel tempo.\nLe osservazioni sono generate dagli stati nascosti secondo la matrice di emissione (\\(B\\)), che specifica le probabilità delle osservazioni date ciascuno stato.\nLe priors uniformi per \\(A\\) e \\(B\\) implicano una mancanza di conoscenza a priori riguardo a queste matrici, lasciando che i dati osservati guidino l’inferenza.\nL’algoritmo Forward è utilizzato per calcolare la log-verosimiglianza della sequenza osservata, che viene poi utilizzata per inferire i parametri del modello.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#stima-dei-parametri",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#stima-dei-parametri",
    "title": "109  Modello di Markov nascosto",
    "section": "109.7 Stima dei Parametri",
    "text": "109.7 Stima dei Parametri\nEseguiamo il campionamento.\n\nfit_single = model_single.sample(\n    data=stan_data,\n    iter_warmup=2000,\n    iter_sampling=2000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit_single.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp7qy4zp_b/hmm_model0fh6yuyh/hmm_model-20240903132237_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp7qy4zp_b/hmm_model0fh6yuyh/hmm_model-20240903132237_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp7qy4zp_b/hmm_model0fh6yuyh/hmm_model-20240903132237_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmp7qy4zp_b/hmm_model0fh6yuyh/hmm_model-20240903132237_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nThe following parameters had fewer than 0.001 effective draws per transition:\n  B[2,2]\nSuch low values indicate that the effective sample size estimators may be biased high and actual performance may be substantially lower than quoted.\n\nThe following parameters had split R-hat greater than 1.05:\n  A[1,1], A[3,1], A[2,2], A[3,2], A[4,2], A[1,3], A[1,4], B[1,1], B[2,1], B[3,1], B[4,1], B[1,2], B[2,2], B[3,2], B[4,2], B[1,3], B[2,3], B[3,3]\nSuch high values indicate incomplete mixing and biased estimation.\nYou should consider regularizating your model with additional prior information or a more effective parameterization.\n\nProcessing complete.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#interpretazione",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#interpretazione",
    "title": "109  Modello di Markov nascosto",
    "section": "109.8 Interpretazione",
    "text": "109.8 Interpretazione\nEsaminiamo le stime a posteriori.\n\n# Assuming 'fit_single' is your fitted model object\nposterior_df = fit_single.draws_pd()\n\n# Extract samples for A (transition matrix)\nA_samples = posterior_df.filter(regex=\"^A\")\n\n# Compute posterior mean for each element in A\nA_mean = A_samples.mean()\n\n# Convert the Series to a NumPy array and reshape it\nA_mean_array = A_mean.to_numpy().reshape(M, M)\n\n# Ensure each row of A sums to 1\nrow_sums = A_mean_array.sum(axis=1)\n\nprint(f\"Posterior mean of A:\\n{A_mean_array.round(2)}\")\nprint(f\"Row sums of posterior mean of A (should be close to 1): {row_sums.round(2)}\")\n\n# Extract samples for pi (initial state probabilities)\npi_samples = posterior_df.filter(regex=\"^pi\")\n\n# Compute and print the posterior means for pi\npi_mean = pi_samples.mean()\nprint(f\"Posterior mean of pi:\\n{pi_mean.to_numpy().round(2)}\")\n\n# Extract samples for B (emission matrix)\nB_samples = posterior_df.filter(regex=\"^B\")\n\n# Compute posterior mean for each element in B\nB_mean = B_samples.mean()\n\n# Convert B_mean to NumPy array for further analysis\nB_mean_array = B_mean.to_numpy().reshape(\n    M, K\n)  # Assuming emission matrix has K columns for K categories\nprint(f\"Emission probabilities (B) matrix:\\n{B_mean_array.round(2)}\")\n\n# Ensure each row of B sums to 1\nB_row_sums = B_mean_array.sum(axis=1)\nprint(f\"Row sums of posterior mean of B (should be close to 1): {B_row_sums.round(2)}\")\n\nPosterior mean of A:\n[[0.5  0.16 0.17 0.18]\n [0.17 0.47 0.19 0.19]\n [0.16 0.18 0.46 0.19]\n [0.17 0.18 0.19 0.44]]\nRow sums of posterior mean of A (should be close to 1): [1.01 1.01 1.   0.98]\nPosterior mean of pi:\n[0.24 0.25 0.25 0.26]\nEmission probabilities (B) matrix:\n[[0.32 0.33 0.36]\n [0.42 0.49 0.42]\n [0.41 0.33 0.19]\n [0.25 0.23 0.25]]\nRow sums of posterior mean of B (should be close to 1): [1.01 1.33 0.93 0.73]\n\n\n\nMatrice di Transizione \\(A\\):\n\nInterpretazione: La matrice di transizione \\(A\\) rappresenta le probabilità di passaggio tra gli stati nascosti nel modello di Markov. Ogni elemento \\(A_{ij}\\) della matrice indica la probabilità di transizione dallo stato nascosto \\(i\\) allo stato nascosto \\(j\\) in un singolo passo temporale.\nImportanza: È fondamentale per comprendere la dinamica sottostante del sistema modellato. Ad esempio, nel contesto del disturbo bipolare, \\(A\\) ci dice quanto è probabile che un paziente passi da uno stato dell’umore a un altro nel tempo, il che può essere cruciale per prevedere futuri episodi maniacali o depressivi.\n\nMatrice di Emissione \\(B\\):\n\nInterpretazione: La matrice di emissione \\(B\\) descrive le probabilità con cui ciascun stato nascosto genera ciascuna delle osservazioni possibili. In altre parole, ogni riga di \\(B\\) rappresenta la distribuzione di probabilità delle osservazioni date le diverse condizioni latenti.\nImportanza: È essenziale per collegare gli stati nascosti alle osservazioni misurate. Nel contesto di un HMM applicato ai dati del disturbo bipolare, \\(B\\) ci aiuta a capire come gli stati dell’umore (neutro, elevato, misto, abbassato) si manifestano nei dati osservati (ad esempio, risposte a item maniacali e depressivi).\n\n\nL’importanza relativa di \\(A\\) e \\(B\\) dipende dal focus dell’analisi:\n\nSe l’obiettivo è comprendere le dinamiche temporali degli stati nascosti (come i cambiamenti negli stati dell’umore di un paziente nel tempo), la matrice di transizione \\(A\\) è più importante. Un’accurata stima di \\(A\\) permette di modellare e prevedere i cambiamenti di stato nel tempo, il che è cruciale per molte applicazioni previsionali.\nSe l’obiettivo è inferire gli stati nascosti dalle osservazioni (ad esempio, diagnosticare l’umore di un paziente basandosi su dati osservati come sintomi o risposte ai questionari), allora la matrice di emissione \\(B\\) è più importante. Un’accurata stima di \\(B\\) è essenziale per tradurre le osservazioni in ipotesi sugli stati nascosti, che è fondamentale per interpretare correttamente i dati osservati.\nMatrice di Transizione \\(A\\): Se \\(A\\) è ben stimata (come sembra dai risultati forniti), si può concludere che il modello riesce a catturare correttamente le dinamiche degli stati nascosti. Questo significa che il modello può essere utilizzato per fare previsioni su come gli stati cambieranno nel tempo.\nMatrice di Emissione \\(B\\): D’altra parte, se \\(B\\) non è ben stimata (come indicano le somme delle righe che non sono vicine a 1 e la mancanza di distinzione tra le emissioni), significa che il modello non riesce a collegare correttamente gli stati nascosti alle osservazioni. Questo può limitare la capacità del modello di inferire correttamente gli stati nascosti dai dati osservati.\n\nIn sintesi, entrambi i risultati sono importanti, ma la loro rilevanza dipende dal contesto specifico dell’applicazione. Se si è interessati a modellare il cambiamento degli stati nel tempo, la matrice di transizione \\(A\\) è più critica. Se, invece, si vuole inferire gli stati nascosti basandosi sulle osservazioni, la matrice di emissione \\(B\\) è fondamentale. Dato che \\(A\\) è ragionevolmente ben recuperata nei tuoi risultati, suggerisce che il modello è buono nel catturare le dinamiche degli stati nascosti, ma la difficoltà nel recuperare \\(B\\) indica che il modello potrebbe avere difficoltà a collegare correttamente gli stati nascosti alle osservazioni.\nÈ possibile introdurre altre modifiche al modello per affrontare il problema della difficoltà di stimare la matrice di emissione B, ma per gli scopi presenti non è necessario, anche considerato il focus dello studio di Mildiner Moraga et al. (2024) sulla transizione tra gli stati. Si può concludere, in questa simulazione, che anche con i dati di un solo partecipante, ma un grande numero di osservazioni, il modello HMM sia in grado di recuperare in maniera ragionevole i valori della matrice A.\nTornando allo studio di Mildiner Moraga et al. (2024), si può concludere quanto segue:\n\nIdentificazione degli Stati Latenti: L’HMM ha identificato quattro stati latenti di umore nei pazienti:\n\nNeutro: Stato di equilibrio emotivo senza sintomi maniacali o depressivi significativi.\nElevato: Stato maniacale o ipomaniacale caratterizzato da alta energia e umore elevato.\nMisto: Stato con la coesistenza di sintomi sia maniacali che depressivi.\nAbbassato: Stato depressivo caratterizzato da umore basso e sintomi depressivi.\n\nTransizioni tra Stati: Il modello ha rivelato che i pazienti con disturbo bipolare tendono a transitare frequentemente tra questi stati, con alcuni stati che fungono da “ponti” tra stati elevati e abbassati, in particolare lo stato misto.\nDurata degli Stati: Lo studio ha trovato che la durata media degli stati variava, con lo stato elevato e lo stato abbassato che tendevano ad essere più persistenti rispetto agli stati misti e neutri.\nImplicazioni Cliniche: Questi risultati suggeriscono che l’HMM può essere uno strumento utile per comprendere meglio la dinamica dell’umore nei pazienti con disturbo bipolare, identificando pattern di instabilità dell’umore che possono informare interventi terapeutici più mirati.\n\nIn sintesi, lo studio di Mildiner Moraga et al. (2024) dimostra l’efficacia degli HMM nel modellare e analizzare la complessità delle fluttuazioni dell’umore nei pazienti con disturbo bipolare, fornendo approfondimenti sui pattern di transizione tra stati emotivi.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#considerazioni-conclusive",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#considerazioni-conclusive",
    "title": "109  Modello di Markov nascosto",
    "section": "109.9 Considerazioni Conclusive",
    "text": "109.9 Considerazioni Conclusive\nIn questo capitolo abbiamo esplorato l’applicazione di un modello di Markov nascosto (HMM) utilizzando dati simulati, ispirati dallo studio di Mildiner Moraga et al. (2024). L’analisi ha dimostrato che l’approccio bayesiano può recuperare stime ragionevoli della matrice di transizione \\(A\\) tra gli stati nascosti anche a partire dai dati di un singolo partecipante. Tuttavia, è importante notare che la nostra simulazione ha utilizzato un numero elevato di osservazioni (\\(N = 5000\\)), il che facilita la stima accurata dei parametri del modello.\nLo studio di Mildiner Moraga et al. (2024) ha adottato un modello bayesiano gerarchico, che è stato applicato a un campione di 20 soggetti. Questo approccio consente di incorporare variabilità tra i soggetti e di migliorare la robustezza delle inferenze sui parametri del modello. Nella pratica, un modello gerarchico è particolarmente utile quando si lavora con campioni più piccoli o con dati che presentano elevata variabilità individuale, poiché consente di “condividere” informazioni tra i partecipanti e di ottenere stime più stabili e generalizzabili.\nSulla base dei risultati di Mildiner Moraga et al. (2024), possiamo formulare delle aspettative anche per quanto riguarda un gruppo di controllo (ad esempio, individui senza diagnosi di disturbo bipolare). In un gruppo di controllo, ci si potrebbe aspettare che:\n\nMeno Variabilità tra Stati: Il gruppo di controllo potrebbe mostrare transizioni meno frequenti tra gli stati dell’umore rispetto ai pazienti con disturbo bipolare. Questo suggerisce una maggiore stabilità emotiva, con stati neutri che predominano nel tempo e meno evidenze di stati elevati, misti o abbassati.\nDiversa Matrice di Transizione: La matrice di transizione \\(A\\) in un gruppo di controllo potrebbe avere probabilità di auto-transizione più alte per lo stato neutro e probabilità più basse di transizione verso stati estremi (elevati o abbassati). Questo rifletterebbe una tendenza a mantenere uno stato emotivo stabile piuttosto che fluttuare tra stati diversi.\nDistribuzione Iniziale degli Stati: La distribuzione iniziale degli stati, rappresentata dal vettore di probabilità iniziali \\(\\pi\\), potrebbe essere maggiormente concentrata sullo stato neutro nel gruppo di controllo, suggerendo che le persone senza disturbo bipolare iniziano e rimangono per lo più in uno stato emotivo neutro.\nMeno Evidenza di Stati Misti: È plausibile che un gruppo di controllo mostri meno evidenze di stati misti, che combinano sintomi sia maniacali che depressivi. Gli stati misti potrebbero essere più caratteristici dei pazienti con disturbo bipolare, riflettendo la natura complessa e instabile della condizione.\n\nIn sintesi, gli HMM permettono di modellare la dinamica degli stati emotivi nel tempo, fornendo un quadro dettagliato di come le persone sperimentano le transizioni tra diversi stati emotivi. Questo approccio può essere particolarmente utile per identificare pattern distintivi associati a condizioni psicologiche specifiche, aiutando a migliorare la diagnosi, il monitoraggio e la gestione dei disturbi dell’umore.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/07_bipolar_disorder.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/dynamic_models/07_bipolar_disorder.html#informazioni-sullambiente-di-sviluppo",
    "title": "109  Modello di Markov nascosto",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w \n\nLast updated: Tue Sep 03 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nmatplotlib: 3.9.1\nbambi     : 0.14.0\nnumpy     : 1.26.4\nnetworkx  : 3.3\nlogging   : 0.5.1.2\nscipy     : 1.14.0\ncmdstanpy : 1.2.4\npandas    : 2.2.2\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMildiner Moraga, S., Bos, F. M., Doornbos, B., Bruggeman, R., Krieke, L. van der, Snippe, E., & Aarts, E. (2024). Evidence for mood instability in patients with bipolar disorder: Applying multilevel hidden Markov modeling to intensive longitudinal ecological momentary assessment data. Journal of Psychopathology and Clinical Science.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>Modello di Markov nascosto</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/08_haslbeck.html",
    "href": "chapters/dynamic_models/08_haslbeck.html",
    "title": "110  Recuperare le dinamiche intra-personali dalle serie temporali psicologiche",
    "section": "",
    "text": "Introduzione\nNei capitoli precedenti abbiamo esaminato situazioni in cui i dati sono stati simulati utilizzando un meccanismo generativo che corrispondeva esattamente al modello statistico impiegato per l’analisi e per fare inferenze sui parametri. In altre parole, ci siamo concentrati su una situazione ideale in cui il modello statistico rispecchiava perfettamente il processo che ha generato i dati. In tali circostanze, abbiamo osservato come un modello statistico bayesiano possa fornire stime accurate dei parametri, a condizione che la dimensione del campione sia sufficientemente grande e che il rapporto segnale/rumore sia adeguato.\nTuttavia, non abbiamo ancora affrontato una questione cruciale: nel mondo reale, al di fuori delle simulazioni, il ricercatore non conosce il meccanismo generatore dei dati. Di conseguenza, il modello statistico utilizzato sarà generalmente soggetto a un errore di specificazione. Cosa accade in questi casi? È possibile fare inferenze “poco distorte” sulle caratteristiche del fenomeno osservato anche senza avere informazioni affidabili sul meccanismo generativo? Dopotutto, se conoscessimo questo meccanismo, la ricerca non sarebbe necessaria.\nPer esplorare queste problematiche nel contesto di misurazioni intensive all’interno dei soggetti, discuteremo il lavoro di Haslbeck & Ryan (2022).",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/08_haslbeck.html#la-ricerca-idiografica",
    "href": "chapters/dynamic_models/08_haslbeck.html#la-ricerca-idiografica",
    "title": "110  Recuperare le dinamiche intra-personali dalle serie temporali psicologiche",
    "section": "110.1 La Ricerca Idiografica",
    "text": "110.1 La Ricerca Idiografica\nL’articolo “Recovering Within-Person Dynamics from Psychological Time Series” di Haslbeck & Ryan (2022) affronta un tema di crescente interesse nella ricerca psicologica: la modellazione idiografica. Questo approccio si concentra sullo studio delle dinamiche interne alle persone, in contrasto con le inferenze basate su dati trasversali. La modellazione idiografica risponde alle preoccupazioni sulla validità delle inferenze fatte dai dati trasversali per comprendere i processi intra-personali e sfrutta la crescente disponibilità di dati longitudinali intensivi.\nHaslbeck & Ryan (2022) sottolineano che l’obiettivo principale della ricerca in questo campo non è semplicemente adattare un modello statistico ai dati di serie temporali, ma approfondire la comprensione teorica delle dinamiche intra-personali. Tuttavia, per fare inferenze su questi dati, è necessario affrontare due sfide fondamentali: il problema della specificazione errata del modello e la frequenza di campionamento insufficiente.\nL’errata specificazione del modello si verifica quando il modello utilizzato per analizzare i dati non corrisponde perfettamente alla complessità del vero sistema. Questo può portare a difficoltà nel fare inferenze accurate sui parametri del sistema reale. D’altra parte, la frequenza di campionamento, ovvero quanto spesso i dati vengono raccolti, deve essere sufficientemente alta per catturare le dinamiche di interesse. Se la frequenza è troppo bassa, le dinamiche non saranno ben rappresentate nei dati raccolti e, di conseguenza, non potranno essere inferite correttamente dal modello di serie temporali.\nPer illustrare queste problematiche, Haslbeck & Ryan (2022) adottano un approccio di simulazione. Definiscono un determinato modello come il sistema reale e tentano di recuperarlo utilizzando la metodologia tipica della letteratura psicologica sulle serie temporali. Questo approccio consente di comprendere meglio i limiti della modellazione attuale.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/08_haslbeck.html#un-sistema-dinamico-bistabile-per-le-dinamiche-emotive",
    "href": "chapters/dynamic_models/08_haslbeck.html#un-sistema-dinamico-bistabile-per-le-dinamiche-emotive",
    "title": "110  Recuperare le dinamiche intra-personali dalle serie temporali psicologiche",
    "section": "110.2 Un Sistema Dinamico Bistabile per le Dinamiche Emotive",
    "text": "110.2 Un Sistema Dinamico Bistabile per le Dinamiche Emotive\nHaslbeck & Ryan (2022) scelgono un modello giocattolo (toy model) per le dinamiche delle emozioni, caratterizzato dalla capacità di passare tra due stati emotivi stabili. Questo modello, basato sul modello di Lotka-Volterra, è stato selezionato per due motivi principali: in primo luogo, la bistabilità è una proprietà frequentemente teorizzata nei fenomeni psicologici, e in secondo luogo, nonostante la sua semplicità, il modello è abbastanza complesso da rendere i modelli di serie temporali comunemente usati in psicologia inesatti o specificati erroneamente.\nIl modello utilizzato si basa su equazioni differenziali stocastiche che descrivono come quattro variabili emotive - due con valenza positiva (Felice e Contento) e due con valenza negativa (Ansioso e Triste) - cambiano nel tempo. Queste equazioni includono termini che rappresentano sia gli effetti lineari principali che gli effetti di interazione tra le variabili, con interazioni rinforzanti tra emozioni della stessa valenza e soppressive tra emozioni di valenza opposta.\nIl modello di Lotka-Volterra per le specie concorrenti, noto anche come equazioni di Lotka-Volterra, è un sistema di equazioni differenziali utilizzato per descrivere le dinamiche di popolazioni di specie che interagiscono in un ecosistema. Questo modello fu originariamente sviluppato per descrivere la dinamica predatore-preda, ma può essere esteso per rappresentare competizione tra specie per risorse limitate.\nNel contesto delle specie concorrenti, il modello di Lotka-Volterra è usato per descrivere come due specie che competono per la stessa risorsa limitata influenzano reciprocamente le loro popolazioni. Le equazioni del modello hanno la forma:\n\\[\n\\begin{align*}\n\\frac{dx_1}{dt} &= r_1 x_1 \\left(1 - \\frac{x_1 + \\alpha x_2}{K_1}\\right), \\\\\n\\frac{dx_2}{dt} &= r_2 x_2 \\left(1 - \\frac{x_2 + \\beta x_1}{K_2}\\right),\n\\end{align*}\n\\]\ndove:\n\n\\(x_1\\) e \\(x_2\\) rappresentano le popolazioni delle due specie concorrenti.\n\\(r_1\\) e \\(r_2\\) sono i tassi di crescita intrinseci delle specie.\n\\(K_1\\) e \\(K_2\\) sono le capacità portanti (carrying capacities) dell’ambiente per ciascuna specie.\n\\(\\alpha\\) e \\(\\beta\\) rappresentano i coefficienti di competizione, che misurano l’impatto della competizione tra le specie.\n\nNel lavoro di Leemput et al. (2014), il modello di Lotka-Volterra viene adattato per descrivere le dinamiche delle emozioni. Nel contesto delle dinamiche delle emozioni, le “specie” del modello di Lotka-Volterra sono analoghe a diverse emozioni che possono competere per l’influenza sullo stato emotivo complessivo di un individuo. Le equazioni del modello definiscono come ciascuna emozione cambia nel tempo in base alle interazioni con le altre emozioni. Ogni equazione ha un termine stocastico che rappresenta fluttuazioni casuali, simile a un processo di Wiener, che simula le perturbazioni ambientali o gli stimoli esterni.\nIl modello giocattolo usato da Haslbeck & Ryan (2022) per le dinamiche delle emozioni, basato sul modello di Lotka-Volterra, considera quattro variabili che rappresentano diverse emozioni:\n\nEmozioni con valenza positiva: Felice (\\(x_1\\)) e Contento (\\(x_2\\)).\nEmozioni con valenza negativa: Ansioso (\\(x_3\\)) e Triste (\\(x_4\\)).\n\nLe equazioni differenziali del modello definiscono come ciascuna emozione cambia nel tempo in base alle interazioni con le altre emozioni. Ogni equazione ha un termine stocastico che rappresenta fluttuazioni casuali, simile a un processo di Wiener, che simula le perturbazioni ambientali o gli stimoli esterni.\nEcco il testo corretto secondo le convenzioni tipografiche italiane:\nLe equazioni che descrivono le dinamiche del sistema emotivo sono:\n\\[\n\\frac{dx_i}{dt} = 1{.}6 + x_i - 0{.}2 x_i^2 + \\sum_{j} C_{ij} x_i x_j + \\sigma dW_i(t),\n\\]\ndove:\n\nla costante 1.6 assicura che le variabili emotive assumano valori positivi;\nil termine lineare \\(x_i\\) rappresenta l’effetto diretto di ogni emozione su sé stessa;\nil termine quadratico \\(-0{.}2 x_i^2\\) stabilizza l’emozione attorno a un livello moderato, evitando che cresca indefinitamente;\nla matrice di interazione \\(C\\) definisce come le emozioni interagiscono tra di loro. I termini positivi nella matrice \\(C\\) rappresentano interazioni di rinforzo tra emozioni della stessa valenza, mentre i termini negativi rappresentano effetti soppressivi tra emozioni di valenza opposta;\nil termine stocastico \\(\\sigma dW_i(t)\\) introduce rumore casuale, rappresentando le fluttuazioni ambientali.\n\nIl sistema dinamico risultante è bistabile, il che significa che può stabilizzarsi in due stati emotivi stabili distinti: uno stato “sano” con elevate emozioni positive e basse emozioni negative, e uno stato “non sano” con elevate emozioni negative e basse emozioni positive. Questi stati sono punti fissi stabili del sistema, dove le emozioni si stabilizzano. Tuttavia, a causa del termine stocastico, il sistema può occasionalmente “saltare” da uno stato stabile all’altro, simulando transizioni emotive tra stati sani e non sani.\nNella Figura 1 dell’articolo di Haslbeck & Ryan (2022), tale modello è visualizzato insieme alle equazioni differenziali stocastiche e ad un campo vettoriale che illustra come le variabili emotive cambiano in base ai loro valori attuali. I punti solidi nel campo vettoriale rappresentano punti fissi stabili, mentre il punto vuoto rappresenta un punto fisso instabile. Le linee solide mostrano dove le derivate delle emozioni positive e negative sono zero, e le linee tratteggiate illustrano potenziali traiettorie del sistema attraverso il campo vettoriale.\n\n\n\nNel pannello a sinistra sono riportate le equazioni del modello e i parametri utilizzati per descrivere il sistema emotivo bistabile. Nel pannello a destra, invece, è rappresentato il campo vettoriale definito da questi parametri. I punti pieni indicano i punti fissi stabili, dove il sistema tende a rimanere, mentre il punto vuoto rappresenta un punto fisso instabile, che il sistema evita. Le linee solide mostrano i valori per cui la derivata dell’emozione positiva (in arancione) e dell’emozione negativa (in azzurro chiaro) è pari a zero. Nei punti di intersezione di queste linee, entrambe le derivate si annullano, indicando uno stato in cui il sistema è stabile e rimane invariato. Le linee tratteggiate verdi rappresentano tre diverse traiettorie che il sistema può percorrere all’interno del campo vettoriale, illustrando come le emozioni possono evolversi nel tempo in base alle condizioni iniziali (figura tratta da Haslbeck & Ryan (2022)).\n\n\nSe dal modello rimuoviamo la componente stocastica \\(\\sigma dW_i(t)\\), che rappresenta un processo di Wiener, allora, indipendentemente dalla posizione iniziale dell’emozione, il sistema finirà per stabilizzarsi in uno dei punti fissi stabili. Tuttavia, poiché il sistema è determinato anche dal termine stocastico, se le fluttuazioni sono abbastanza grandi da allontanare l’emozione corrente da uno dei punti fissi stabili, è possibile che il sistema raggiunga il punto fisso instabile, provocando un’inversione dello stato emotivo.\nIn sintesi, il modello di Lotka-Volterra è stato adattato da Haslbeck & Ryan (2022) per esplorare le dinamiche delle emozioni, utilizzando l’interazione tra diverse emozioni come base per modellare cambiamenti complessi nello stato emotivo di un individuo. L’approccio di Haslbeck & Ryan (2022) prevede di simulare dati di serie temporali utilizzando il modello descritto e quindi tentare di recuperare le caratteristiche del sistema sottostante tramite strumenti analitici tipici della ricerca psicologica.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/08_haslbeck.html#generazione-della-serie-temporale",
    "href": "chapters/dynamic_models/08_haslbeck.html#generazione-della-serie-temporale",
    "title": "110  Recuperare le dinamiche intra-personali dalle serie temporali psicologiche",
    "section": "110.3 Generazione della Serie Temporale",
    "text": "110.3 Generazione della Serie Temporale\nPer generare i dati delle serie temporali, Haslbeck & Ryan (2022) utilizzano una soluzione numerica del modello su un intervallo di tempo di due settimane, con l’unità di tempo interpretata come un minuto. I dati generati sono stati successivamente sottocampionati 10 volte al minuto, ottenendo così una serie temporale con 201600 misurazioni. Questa serie temporale viene considerata “ideale” poiché è stata misurata con un’alta frequenza di campionamento, non presenta errori di misurazione né valori mancanti, e mostra frequenti cambiamenti tra stati stabili.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/08_haslbeck.html#caratteristiche-qualitative-del-sistema",
    "href": "chapters/dynamic_models/08_haslbeck.html#caratteristiche-qualitative-del-sistema",
    "title": "110  Recuperare le dinamiche intra-personali dalle serie temporali psicologiche",
    "section": "110.4 Caratteristiche Qualitative del Sistema",
    "text": "110.4 Caratteristiche Qualitative del Sistema\nHaslbeck & Ryan (2022) distinguono tra le caratteristiche locali e globali del sistema definito dalle equazioni differenziali.\n\nLe caratteristiche locali includono gli effetti di soppressione tra valenze e gli effetti di rinforzo all’interno delle valenze, la dimensione relativa di questi effetti, e l’indipendenza dei parametri nel tempo e dalle variabili esterne.\nLe caratteristiche globali comprendono la bistabilità del sistema, la posizione dei punti fissi stabili, la variabilità attorno a questi punti, e la frequenza delle transizioni tra stati.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/08_haslbeck.html#il-problema-dellerrata-specificazione",
    "href": "chapters/dynamic_models/08_haslbeck.html#il-problema-dellerrata-specificazione",
    "title": "110  Recuperare le dinamiche intra-personali dalle serie temporali psicologiche",
    "section": "110.5 Il Problema dell’Errata Specificazione",
    "text": "110.5 Il Problema dell’Errata Specificazione\nPer analizzare i dati simulati, Haslbeck & Ryan (2022) utilizzano diversi modelli comunemente utilizzati in psicologia, come il modello di Markov nascosto (HMM), il modello autoregressivo vettoriale di ordine 1 (VAR(1)) e un’estensione del VAR(1) chiamata Threshold VAR(1) (TVAR(1)). Ognuno di questi modelli presenta limitazioni che possono portare a un’errata specificazione.\nHaslbeck & Ryan (2022) si chiedono in che misura l’errata specificazione di questi modelli comprometta il recupero delle caratteristiche globali e locali del sistema a partire dai dati del campione.\n\n110.5.1 Caratteristiche Globali\nHaslbeck & Ryan (2022) mostrano che, utilizzando un campionamento ad alta frequenza, è possibile recuperare le caratteristiche globali del sistema anche in presenza di errata specificazione.\nSpecificamante, le rappresentazioni grafiche e le statistiche descrittive vengono utilizzate per descrivere accuratamente queste caratteristiche. Ad esempio, analizzando gli istogrammi delle variabili emotive, si osserva che ogni variabile presenta una distribuzione bimodale, suggerendo la presenza di due stati stabili. Le distribuzioni sono centrate approssimativamente intorno ai valori di 1.6 e 4.8, con una maggiore varianza nella distribuzione dei valori più alti. Questi istogrammi, insieme alle relazioni bivariate tra le variabili emotive, confermano la bistabilità del sistema. Le rappresentazioni grafiche mostrano inoltre che il sistema passa frequentemente tra due stati: uno con emozioni positive alte e negative basse, e uno con emozioni negative alte e positive basse.\nPer quel che riguarda l’inferenza, gli autori hanno utilizzato il pacchetto depmixS4 di R, un software specifico per l’analisi di modelli di Markov nascosti (HMM), per stimare vari parametri del modello, come le medie e le deviazioni standard delle distribuzioni per i diversi stati del sistema.\n\nComponenti \\(k_1\\) e \\(k_2\\): Rappresentano i due stati stabili che il sistema può assumere. Il modello HMM è stato utilizzato per stimare le caratteristiche di ciascuno di questi stati, come le medie e le deviazioni standard delle emozioni associate.\nMatrice di transizione \\(\\hat{M}\\): Questa matrice rappresenta le probabilità di transizione tra i due stati \\(k_1\\) e \\(k_2\\). Essa indica la probabilità che il sistema rimanga nello stesso stato o passi all’altro stato in ogni intervallo temporale.\n\nL’analisi tramite modelli di Markov nascosti ha dimostrato di essere efficace nel recuperare le caratteristiche qualitative globali del sistema, anche quando il modello è specificato in modo errato.\n\nStima delle Medie e delle Deviazioni Standard:\n\nL’HMM è riuscito a stimare accuratamente le medie e le deviazioni standard per i due stati del sistema, \\(k_1\\) e \\(k_2\\). Questi stati rappresentano due condizioni stabili nel sistema simulato: uno stato “sano” con emozioni positive alte e emozioni negative basse, e uno stato “non sano” con emozioni negative alte e emozioni positive basse. Le medie stimate per gli stati sono molto vicine ai valori reali dei punti fissi stabili del sistema simulato, indicando una buona capacità del modello HMM di rappresentare la distribuzione dei dati in ciascun stato.\n\nMatrice di Transizione:\n\nLa matrice di transizione stimata dall’HMM (\\(\\hat{M}\\)) mostra valori elevati sulla diagonale (circa 0.9996), il che suggerisce che il sistema tende a rimanere nello stesso stato per periodi prolungati, e valori molto bassi fuori diagonale (circa 0.0004), indicando una bassa probabilità di transizione tra stati. Questi valori riflettono il comportamento osservato nel sistema simulato, dove le transizioni tra stati sono rare.\n\n\nAnche con un’errata specificazione del modello (poiché il sistema reale include dinamiche non lineari non perfettamente catturate da un semplice HMM), Haslbeck & Ryan (2022) mostrano che l’analisi con l’HMM è stata in grado di recuperare accuratamente le caratteristiche qualitative globali del sistema. Questo include la natura bistabile del sistema (due stati stabili), le posizioni approssimative dei punti fissi (medie dei componenti) e la frequenza delle transizioni tra stati.\n\n\n110.5.2 Caratteristiche Locali\nTuttavia, anche senza entrare nei dettagli, possiamo affermare che le inferenze sulle caratteristiche locali del sistema, come le interazioni precise e le dinamiche a breve termine tra le variabili, possono risultare compromesse a causa dell’errata specificazione. In effetti, in presenza di errata specificazione, nessuno dei modelli statistici utilizzati da Haslbeck & Ryan (2022) è stato in grado di recuperare accuratamente le caratteristiche locali del sistema.\n\n\n110.5.3 Conlusioni\nIn sintesi, l’errata specificazione rappresenta una sfida significativa per fare inferenze accurate sui modelli di serie temporali applicati ai sistemi psicologici sottostanti. Sebbene sia possibile recuperare alcune caratteristiche globali del sistema, le inferenze sulle dinamiche locali dipendono fortemente dalla conoscenza teorica del sistema e dall’adeguatezza del modello utilizzato. In presenza di errore di speficicazione e di mancata conoscenza del meccanismo generatore dei dati, le simulazioni di Haslbeck & Ryan (2022) mostrano che non è possibile descrivere in maniera accurata le dinamiche locali del sistema.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/08_haslbeck.html#il-problema-di-una-frequenza-di-campionamento-troppo-bassa",
    "href": "chapters/dynamic_models/08_haslbeck.html#il-problema-di-una-frequenza-di-campionamento-troppo-bassa",
    "title": "110  Recuperare le dinamiche intra-personali dalle serie temporali psicologiche",
    "section": "110.6 Il Problema di una Frequenza di Campionamento Troppo Bassa",
    "text": "110.6 Il Problema di una Frequenza di Campionamento Troppo Bassa\nHaslbeck & Ryan (2022) considerano poi il problema che nasce dal fatto che le ricerche EMA (Ecological Momentary Assessment) molto spesso usano una frequenza di campionamento troppo bassa rispetto alla velocità con cui avvengono i cambiamenti nel sistema. Quando la frequenza di campionamento è troppo bassa, le dipendenze temporali e le micro-dinamiche del sistema non sono catturate nei dati. Questo significa che, anche utilizzando modelli statistici avanzati, è impossibile recuperare accuratamente le dinamiche locali del sistema.\nHaslbeck & Ryan (2022) dimostrano questo problema riducendo la frequenza di campionamento da ogni sei secondi a ogni 90 minuti. Con questa riduzione, tutte le micro-dinamiche vengono eliminate dai dati della serie temporale. Nonostante ciò, alcune caratteristiche globali del sistema (come la bistabilità e la posizione dei punti fissi) possono ancora essere recuperate. Tuttaivia, non è possibile recuperare le dinamiche locali con una frequenza di campionamento insufficiente. La mancanza di informazioni dettagliate tra le osservazioni comporta che i modelli di serie temporali non possano rappresentare accuratamente le interazioni a breve termine tra le variabili.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span>"
    ]
  },
  {
    "objectID": "chapters/dynamic_models/08_haslbeck.html#implicazioni-per-la-ricerca-psicologica",
    "href": "chapters/dynamic_models/08_haslbeck.html#implicazioni-per-la-ricerca-psicologica",
    "title": "110  Recuperare le dinamiche intra-personali dalle serie temporali psicologiche",
    "section": "110.7 Implicazioni per la Ricerca Psicologica",
    "text": "110.7 Implicazioni per la Ricerca Psicologica\nLo studio di Haslbeck & Ryan (2022) evidenzia l’importanza di una modellizzazione idiografica per comprendere le dinamiche interne degli individui in psicologia. Questo approccio si concentra sullo studio delle variazioni all’interno di una persona, piuttosto che su confronti tra individui diversi. Tuttavia, lo studio mette in luce anche le sfide legate a questa metodologia, in particolare quando si utilizzano modelli di serie temporali per fare inferenze sui sistemi sottostanti.\nGli autori sottolineano che l’errata specificazione dei modelli è una delle principali difficoltà nella ricerca psicologica. Un modello è specifica in maniera errata quando non riesce a rappresentare adeguatamente le dinamiche reali del sistema, portando a inferenze imprecise, specialmente per quanto riguarda le caratteristiche locali, come le interazioni tra variabili e le dipendenze temporali. Sebbene alcune caratteristiche globali del comportamento del sistema, come la struttura bistabile, possano ancora essere recuperate, le inferenze sulle dinamiche locali risultano spesso distorte o errate.\nUn altro problema cruciale evidenziato dallo studio è la frequenza di campionamento insufficiente. Quando i dati vengono raccolti a intervalli troppo ampi rispetto alla velocità dei cambiamenti nel sistema, le dinamiche rapide e le dipendenze temporali non vengono catturate. Questo limita la capacità dei modelli di rappresentare accuratamente le dinamiche locali del sistema.\nPer affrontare questi problemi, Haslbeck & Ryan (2022) suggeriscono un approccio basato su una scelta del modello più informata teoricamente. Questo potrebbe ridurre il grado di errata specificazione, avvicinando il modello alle dinamiche reali del sistema. Ad esempio, se il sistema reale è caratterizzato da diversi stati stabili, l’utilizzo di un modello VAR(1) può fornire un’approssimazione lineare utile delle dinamiche vicino a questi stati. Integrando conoscenze teoriche con dati osservazionali, è possibile ottenere una rappresentazione più accurata delle dinamiche complessive del sistema.\nGli autori propongono anche di adottare un approccio di modellizzazione più flessibile, che superi i limiti dei tradizionali modelli di serie temporali e metta le teorie formali al centro dello sviluppo teorico. Questo approccio permetterebbe di affrontare le difficoltà legate all’errata specificazione e alla frequenza di campionamento insufficiente in modo più adattabile, sebbene non risolva completamente questi problemi.\nIn sintesi, lo studio di Haslbeck & Ryan (2022) evidenzia l’importanza di considerare attentamente sia la specificazione del modello sia la frequenza di campionamento per studiare accuratamente le dinamiche intra-personali. Adottare un framework teorico che ponga al centro le dinamiche interne e le teorie formali può facilitare una comprensione più profonda e accurata delle dinamiche psicologiche.\n\n\n\n\nHaslbeck, J. M., & Ryan, O. (2022). Recovering within-person dynamics from psychological time series. Multivariate Behavioral Research, 57(5), 735–766.\n\n\nLeemput, I. A. van de, Wichers, M., Cramer, A. O., Borsboom, D., Tuerlinckx, F., Kuppens, P., Van Nes, E. H., Viechtbauer, W., Giltay, E. J., Aggen, S. H., et al. (2014). Critical slowing down as early warning for the onset and termination of depression. Proceedings of the National Academy of Sciences, 111(1), 87–92.",
    "crumbs": [
      "Dinamiche",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>Recuperare le dinamiche intra-personali dalle serie temporali psicologiche</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html",
    "title": "Introduzione",
    "section": "",
    "text": "I Modelli Computazionali della Cognizione\nComprendere la cognizione umana è stato uno dei principali obiettivi della ricerca psicologica per oltre un secolo. Gli approcci matematici allo studio della cognizione risalgono già al XIX secolo, quando ricercatori come Ernst Heinrich Weber svilupparono modelli matematici per descrivere fenomeni percettivi, come l’effetto della “differenza appena percepibile”, che descrive il modo in cui gli esseri umani percepiscono le differenze tra gli oggetti (Raymond & Rutherford, 2012). Tuttavia, fu solo con l’avvento dell’informatica teorica e dei computer digitali nel XX secolo che la psicologia computazionale emerse come un campo a sé stante. La nascita del computer digitale permise agli psicologi cognitivi di sviluppare formalismi matematici e modelli computazionali che descrivevano la cognizione come un fenomeno di elaborazione delle informazioni, in modo simile a come operano i computer digitali. Ricercatori come George Miller, Allen Newell, Herbert Simon e Frank Rosenblatt applicarono metodi computazionali allo studio della percezione, del linguaggio e della risoluzione dei problemi, gettando le basi per questo campo emergente (Boden, 2008). La psicologia computazionale ha offerto un approccio alternativo allo studio della mente, basato su algoritmi e simulazioni al computer, anziché su correlazioni e sperimentazioni in laboratorio, i paradigmi predominanti all’epoca, come osservato dal presidente dell’American Psychological Association, Lee Cronbach (Cronbach, 1957).\nNel primo quarto del XXI secolo, il campo dei modelli computazionali della cognizione sta vivendo una crescita rapida in un mondo dove nazioni e giganti tecnologici competono per scoprire i segreti dell’intelligenza umana e artificiale. In questa introduzione, offro una panoramica storica degli approcci computazionali in scienza cognitiva, evidenziando l’importanza e la prospettiva unica di questi metodi nello studio del pensiero e del comportamento umano. Adotterò una prospettiva storica, concentrandomi su una narrazione ad alto livello dell’evoluzione del campo, piuttosto che su numerosi esempi individuali di modelli computazionali (Boden, 2008).",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#la-scienza-cognitiva-computazionale",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#la-scienza-cognitiva-computazionale",
    "title": "Introduzione",
    "section": "La Scienza Cognitiva Computazionale",
    "text": "La Scienza Cognitiva Computazionale\nNonostante l’importanza dei modelli computazionali, la scienza cognitiva computazionale ha impiegato molto tempo a consolidarsi tra i paradigmi principali nello studio della mente e del comportamento. Durante la prima metà del XX secolo, lo studio della mente era visto con sospetto da molti, data la nostra incapacità di accedere direttamente ai suoi contenuti (Skinner, 1965; Watson, 1913). Concetti come “coscienza” o “memoria” sono entità che i ricercatori possono misurare solo indirettamente osservando il comportamento delle persone, ma non esiste un modo per “toccare” o “vedere” un frammento di memoria nella mente di qualcuno. Questi sono eventi privati, esperienze soggettive, entità inaccessibili di costituzione eterea. Sebbene all’epoca fossimo in grado di osservare e misurare i pattern di attività elettrica nel cervello, trovare una corrispondenza diretta tra tali pattern e un particolare frammento di memoria era quanto mai ambiguo.\nL’invenzione del computer digitale è stata quindi rivoluzionaria per gli psicologi cognitivi, poiché ha fornito un esempio fisico di qualcosa che poteva fare molte delle cose che fa la mente umana: aritmetica, logica, memorizzazione di informazioni, e altro ancora. Dopo tutto, è possibile costruire, toccare e vedere un computer digitale. Si sa esattamente dove un’informazione viene elaborata e memorizzata. È difficile osservare un computer digitale in azione e non notare la somiglianza con i meccanismi interni della mente umana.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#oltre-le-reti-neurali",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#oltre-le-reti-neurali",
    "title": "Introduzione",
    "section": "Oltre le Reti Neurali",
    "text": "Oltre le Reti Neurali\nSebbene le reti neurali abbiano avuto un ruolo di primo piano nello sviluppo della scienza cognitiva computazionale, i modelli computazionali della cognizione non si limitano a queste. In realtà, esistono diversi approcci modellistici, ciascuno con le proprie specificità e aree di applicazione. I modelli simbolici, ad esempio, descrivono la cognizione umana come il risultato della manipolazione di simboli, basandosi su logica formale e linguistica. I modelli probabilistici, invece, utilizzano la teoria delle probabilità per descrivere il ragionamento umano in condizioni di incertezza.\nNel corso degli anni, questi approcci si sono evoluti e spesso integrati tra loro, portando allo sviluppo di modelli ibridi che combinano elementi simbolici, connessionisti e probabilistici. La psichiatria computazionale, in particolare, ha tratto vantaggio da questo approccio integrato, utilizzando modelli che possono adattarsi a diverse scale di analisi, dai circuiti neuronali ai comportamenti osservabili, per fornire una visione più completa dei disturbi mentali.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#la-psichiatria-computazionale",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#la-psichiatria-computazionale",
    "title": "Introduzione",
    "section": "La Psichiatria Computazionale",
    "text": "La Psichiatria Computazionale\nLa psichiatria computazional è un campo emergente utilizza modelli matematici e computazionali per comprendere i meccanismi mentali e comportamentali che stanno alla base dei disturbi mentali. L’approccio computazionale in psichiatria cerca di modellare in modo preciso le alterazioni nei processi cognitivi e decisionali che possono caratterizzare patologie come la schizofrenia, la depressione e i disturbi d’ansia.\nUn esempio emblematico di questo approccio è il lavoro di Michael Frank, che ha sviluppato modelli computazionali per comprendere i processi di apprendimento e decisione nei disturbi mentali. Frank ha esplorato come i modelli computazionali possano essere utilizzati per comprendere il funzionamento dei circuiti neuronali associati al rinforzo e alla punizione, e come alterazioni in questi circuiti possano contribuire a diverse manifestazioni psicopatologiche (Hitchcock et al., 2022). Ad esempio, i suoi studi sui meccanismi di rinforzo e sulla modulazione dopaminergica hanno fornito nuove prospettive sul funzionamento della malattia di Parkinson e sui disturbi compulsivi, mettendo in luce come alterazioni nei circuiti di rinforzo possano influenzare le decisioni e i comportamenti.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/introduction_cognitive_models.html#conclusioni",
    "href": "chapters/cognitive_models/introduction_cognitive_models.html#conclusioni",
    "title": "Introduzione",
    "section": "Conclusioni",
    "text": "Conclusioni\nI modelli computazionali della cognizione hanno una lunga tradizione, iniziata nella prima metà del XX secolo come un intreccio di teoria computazionale e psicologia cognitiva. Nel tempo, sono emersi quattro principali approcci all’interno di questa prospettiva: modelli basati su simboli, modelli basati su connessionismi, modelli ibridi e modelli basati su probabilità. L’approccio computazionale ha contribuito a migliorare e ampliare la nostra comprensione della cognizione e del comportamento umano. Le recenti avanzate nella disponibilità di risorse computazionali e di dati, insieme all’interesse pubblico e privato nello sviluppo di tecnologie di intelligenza artificiale, forniscono un contesto fertile per la crescita e il consolidamento della prospettiva computazionale nelle scienze cognitive e nella psichiatria.\n\n\n\n\nBoden, M. A. (2008). An evaluation of computational modeling in cognitive science.\n\n\nCronbach, L. J. (1957). The two disciplines of scientific psychology. American psychologist, 12(11), 671–684.\n\n\nHitchcock, P. F., Fried, E. I., & Frank, M. J. (2022). Computational psychiatry needs time and context. Annual review of psychology, 73(1), 243–270.\n\n\nSkinner, B. F. (1965). Science and human behavior. Simon; Schuster.\n\n\nWatson, J. B. (1913). Psychology as the behaviorist views it. Psychological review, 20(2), 158.",
    "crumbs": [
      "Modelli cognitivi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html",
    "href": "chapters/cognitive_models/01_ddm.html",
    "title": "111  Drift Diffusion Model",
    "section": "",
    "text": "111.1 Introduzione\nI meccanismi cognitivi sono sistemi dinamici complessi che richiedono modelli in grado di catturare le intricate dinamiche dei loro componenti. Per comprendere appieno la struttura dei dati empirici umani, è necessario un approccio che tenga conto di queste complessità. Una metodologia efficace per formalizzare matematicamente tali sistemi dinamici è trattarli come processi generativi stocastici, i quali producono dati con dipendenze temporali, ovvero serie temporali.\nLa natura intrinsecamente non lineare della maggior parte dei sistemi complessi si riflette in queste serie temporali. Anziché mostrare semplici fluttuazioni attorno a una media stabile con varianza fissa, esse tendono a manifestarsi come random walk eterogenei, evidenziando la complessità sottostante.\nIn questo contesto, il Drift Diffusion Model (DDM) emerge come un’applicazione rilevante di questo quadro teorico (Myers et al., 2022). Originariamente sviluppato da Ratcliff nel 1978 e successivamente raffinato, il DDM si propone di descrivere il processo decisionale rapido tra due alternative di risposta (DDM; Ratcliff, 1978; Ratcliff e McKoon, 2008; Ratcliff et al., 2016). La sua crescente popolarità negli ultimi anni è attribuibile sia allo sviluppo di algoritmi che lo implementano, sia a una letteratura sempre più vasta che ne dimostra l’utilità nel comprendere processi cognitivi altrimenti difficili da descrivere con metodi tradizionali di analisi dei dati.\nIl processo decisionale, o decision making, rappresenta un campo di studio fondamentale nella psicologia cognitiva e nelle neuroscienze cognitive. Questo processo complesso comprende diversi stadi: dal riconoscimento delle caratteristiche della situazione, alla considerazione di molteplici alternative di risposta, fino alla selezione ed esecuzione di una risposta, all’osservazione dei risultati e all’adattamento del comportamento basato su questi esiti.\nL’importanza di studiare il decision making risiede nelle sue implicazioni pratiche. Qualsiasi compromissione in una delle fasi del processo decisionale può avere conseguenze significative nella vita quotidiana. Ad esempio, problemi nell’adattamento possono portare gli individui a privilegiare benefici a breve termine a discapito della salute a lungo termine, come nel caso di comportamenti additivi. Inoltre, alterazioni nel processo decisionale sono state associate a una vasta gamma di disturbi psicologici, dalla depressione e i disturbi d’ansia, ai disturbi di personalità borderline, fino alla suicidalità.\nIn conclusione, l’approccio del DDM offre un potente strumento per esplorare e comprendere i meccanismi cognitivi sottostanti al processo decisionale. La sua applicazione non solo arricchisce la nostra comprensione teorica, ma ha anche implicazioni pratiche significative per la diagnosi e il trattamento di vari disturbi psicologici.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#panoramica-del-modello-di-diffusione-del-drift-ddm",
    "href": "chapters/cognitive_models/01_ddm.html#panoramica-del-modello-di-diffusione-del-drift-ddm",
    "title": "111  Drift Diffusion Model",
    "section": "111.2 Panoramica del modello di diffusione del drift (DDM)",
    "text": "111.2 Panoramica del modello di diffusione del drift (DDM)\nNelle attività di decisione rapida in psicologia cognitiva, ai partecipanti viene richiesto di scegliere rapidamente tra due o più risposte in competizione. Esempi tipici includono il compito di decisione lessicale (dove si preme un tasto se lo stimolo è una parola e un altro se non lo è), il compito di Stroop (in cui si preme un tasto corrispondente al colore dell’inchiostro di una parola, ignorando il contenuto semantico della parola stessa) e il compito dei flanker saccadici (che richiede di muovere l’occhio nella direzione indicata da uno stimolo centrale, ignorando le direzioni dei flanker).\nIn questi compiti, anche partecipanti ben addestrati mostrano un compromesso tra velocità e accuratezza: essi possono incrementare l’accuratezza a scapito di tempi di risposta più lenti (e quindi maggiormente deliberati), oppure optare per decisioni rapide che risultano più suscettibili a errori (Schouten e Bekker, 1967; Wickelgren, 1977). Questo trade-off tra velocità e accuratezza sembra essere almeno parzialmente sotto il controllo conscio, poiché i partecipanti possono modulare le loro prestazioni in base alle istruzioni ricevute per enfatizzare la velocità o l’accuratezza (Ratcliff e Rouder, 1998; Voss et al., 2004; Milosavljevic et al., 2010; Katsimpokis et al., 2020). Questa flessibilità comportamentale complica l’interpretazione dei dati, poiché le differenze nei tempi di risposta tra gruppi possono riflettere meccanismi cognitivi sottostanti distinti (Voss et al., 2013). Ad esempio, due gruppi di pazienti potrebbero entrambi avere tempi di reazione medi più lenti rispetto a un gruppo di controllo sano, ma mentre in un gruppo ciò potrebbe riflettere una strategia decisionale più cauta, nell’altro potrebbe indicare un rallentamento dovuto alla patologia. È quindi fondamentale disporre di metodi di analisi che considerino non solo la velocità e l’accuratezza, ma anche l’interazione tra queste due variabili.\nPer affrontare queste complessità, un approccio complementare all’analisi dei dati comportamentali osservati è l’uso di modelli computazionali che mirano a inferire i parametri di modelli che descrivono processi cognitivi latenti. Questi parametri, quando combinati, sono in grado di riprodurre la distribuzione osservata dei tempi di reazione (RT) e delle accuratezze.\nIl modello di diffusione del drift (Drift Diffusion Model, DDM), descritto inizialmente da Ratcliff e colleghi (Ratcliff, 1978; Ratcliff e McKoon, 2008; Ratcliff et al., 2016), è un esempio prominente di una classe più ampia di modelli denominati “modelli di accumulazione dell’evidenza”. Tali modelli concettualizzano il processo decisionale come un accumulo di evidenza a favore di una delle risposte possibili, fino al raggiungimento di una soglia decisionale che innesca la risposta corrispondente. Questi modelli, noti anche come modelli di campionamento sequenziale, suggeriscono che il sistema nervoso acquisisca ripetutamente frammenti di informazione (campioni) dall’ambiente in modo sequenziale, fino a raggiungere una soglia di evidenza sufficiente per prendere una decisione. Il compromesso tra velocità e accuratezza rappresenta quindi un punto di equilibrio che determina quando interrompere il campionamento e agire sulla base delle informazioni accumulate.\nCome tutti i modelli computazionali, il DDM è formalizzato attraverso un insieme di equazioni matematiche che includono diversi parametri, ciascuno dei quali può essere assegnato a valori differenti. Un modo intuitivo di concepire i parametri è considerarli come regolatori (o sliders) di un sistema stereo, ognuno dei quali controlla un aspetto diverso del suono (ad esempio, alti, bassi, volume) e che possono essere regolati singolarmente per ottenere l’effetto desiderato complessivo. Analogamente, i parametri in un modello di accumulazione dell’evidenza regolano aspetti come la velocità di accumulazione dell’evidenza, un bias intrinseco verso una delle risposte, e la tendenza a privilegiare la velocità rispetto all’accuratezza. La regolazione di ciascuno di questi parametri influenza il comportamento del modello.\nNelle sezioni seguenti, descriveremo i passaggi principali nel processo di modellizzazione. Inizialmente, forniremo una descrizione generale del DDM, dei suoi parametri e del suo utilizzo in psicologia cognitiva. Successivamente, presenteremo un esempio concreto di applicazione del DDM in un semplice compito di decisione a due scelte, illustrando il processo di fitting del modello per stimare i valori dei parametri per un singolo partecipante, seguito dalla validazione del modello. Infine, discuteremo come riportare i risultati del modello e sottoporli ad analisi statistica.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#parametri-nel-modello-di-diffusione-del-drift-ddm",
    "href": "chapters/cognitive_models/01_ddm.html#parametri-nel-modello-di-diffusione-del-drift-ddm",
    "title": "111  Drift Diffusion Model",
    "section": "111.3 Parametri nel modello di diffusione del drift (DDM)",
    "text": "111.3 Parametri nel modello di diffusione del drift (DDM)\nIl modello di diffusione del drift (DDM) parte dall’assunto che il tempo di reazione (RT) in ogni prova, definito come il tempo che intercorre dall’inizio dello stimolo fino all’esecuzione della risposta motoria, possa essere scomposto in tre componenti: il tempo necessario per il sistema nervoso per rilevare o codificare lo stimolo (spesso indicato come Te), il tempo per raggiungere una decisione su come rispondere a quello stimolo (Td) e il tempo richiesto per eseguire la risposta motoria scelta (Tr). Pertanto, in una data prova, il tempo di reazione osservato è la somma di queste tre componenti: RT = Te + Td + Tr.\nSebbene in teoria sia possibile misurare separatamente Te e Tr, normalmente il tempo di codifica e di risposta vengono combinati in un unico parametro che rappresenta il tempo di non-decisione (Ter), ovvero la parte del RT che avviene indipendentemente dal processo decisionale Td. Con questa semplificazione, l’equazione diventa RT = Ter + Td. I valori tipici di Ter variano tra 0.1 e 0.5 secondi, in parte a seconda della complessità degli stimoli e delle risposte motorie specifiche coinvolte (ad esempio, le persone possono generalmente eseguire saccadi più velocemente rispetto alla pressione di un tasto). Si assume solitamente che Ter possa differire tra individui, ma rimanga relativamente costante tra le prove per un singolo individuo che esegue un determinato compito.\nL’altra componente del RT è il tempo di decisione (Td), che è il tempo necessario per prendere una decisione (dopo che lo stimolo è stato codificato, ma prima che venga eseguita la risposta scelta). In una singola prova, l’informazione rumorosa viene accumulata nel tempo mentre il processo si muove lungo un corridoio delimitato dalle due possibili risposte. Man mano che si accumulano maggiori informazioni, l’evidenza a favore di una risposta spinge il processo decisionale più vicino al confine corrispondente. Quando uno dei confini viene raggiunto, viene selezionata la risposta corrispondente, e il tempo per raggiungere quel confine definisce il tempo di decisione Td in quella prova.\n\n\n\nDrift Diffusion Model.\n\n\nIl modello DDM prevede che il processo decisionale inizi da un punto sulla y definito da un parametro che denota un punto di partenza relativo (z) che varia da 0 (asse inferiore) a 1 (asse superiore). Se z = 0.5, il punto di partenza è equidistante dai due confini. Tuttavia, se z si avvicina a 1 (o 0), il processo decisionale inizia vicino al confine superiore (o inferiore) in ogni prova, il che significa che è necessaria meno informazione per raggiungere quel confine e iniziare la risposta corrispondente. Il punto di partenza z riflette quindi un bias di risposta a favore di una o dell’altra risposta.\nIl processo decisionale nel DDM è considerato rumoroso, il che riflette la presenza di input sensoriali rumorosi, variazioni stocastiche nel tasso di scarica neuronale nei centri decisionali del cervello e anche fluttuazioni momentanee nell’attenzione. Questo rumore implica che lo stesso stimolo potrebbe non generare lo stesso tempo di decisione o addirittura la stessa risposta ogni volta che si verifica, portando a variazioni nel RT e nell’accuratezza delle risposte tra le prove.\nNel DDM, il tasso medio al quale l’evidenza si accumula verso il confine corretto è definito da un parametro che rappresenta il tasso di drift (drift rate) (d). Il tasso di drift è una misura della velocità di elaborazione delle informazioni, che può variare a seconda della difficoltà del compito. Per compiti facili con stimoli altamente discriminabili, ci dovrebbe essere un alto tasso di drift (pendenza ripida su o giù), e l’evidenza dovrebbe accumularsi rapidamente e in modo affidabile verso il confine corretto, risultando in tempi di reazione rapidi e alta accuratezza. Per compiti più difficili o stimoli più ambigui, il tasso di drift può essere più basso (meno ripido), il che significa che l’accumulo di evidenza è più lento e rumoroso, risultando in tempi di reazione più lenti e variabili.\nRiassumendo, i parametri del DDM si mappano su diversi processi cognitivi: impostazioni di velocità-accuratezza (separazione del confine \\(a\\)), bias di risposta (punto di partenza \\(z\\)), velocità di elaborazione delle informazioni (tasso di drift \\(d\\)) e tempo di non-decisione (\\(Ter\\)). Questi parametri sono talvolta chiamati “parametri liberi”, nel senso che possono assumere diversi valori liberamente, e proprio come le manopole di uno stereo, cambiare ciascun parametro influenza il comportamento del DDM.\nPer esempio, in un compito in cui il soggetto è istruito a eseguire una risposta r1 il più rapidamente possibile ogni volta che viene mostrato uno stimolo s1, ma una risposta diversa r2 ogni volta che viene mostrato uno stimolo s2, l’aumento del punto di partenza (\\(z\\)) avvicinerà il punto di partenza al confine superiore, rendendo più facile (e veloce) decidere a favore di r2 in ogni prova. Questo potrebbe creare un bias di risposta preponderante per r2 se, ad esempio, le risposte r2 sono molto più frequenti o altamente ricompensate nel compito.\nRiducendo la separazione del confine (\\(a\\)), entrambe le risposte diventerebbero più veloci, ma aumenterebbe anche il tasso di errore, perché il rumore potrebbe facilmente spingere il processo decisionale oltre uno dei confini. Una separazione del confine ridotta potrebbe verificarsi se, ad esempio, il soggetto fosse stato istruito a rispondere rapidamente, anche a scapito della precisione. Al contrario, aumentare a avrebbe l’effetto opposto, aumentando la cautela nelle risposte e producendo tempi di reazione più lenti.\nAumentare il tasso di drift per un tipo di stimolo comporterebbe un accumulo di evidenza più rapido in quelle prove, mentre diminuirlo comporterebbe un accumulo più lento. I tassi di drift sono tipicamente più lenti in condizioni di compiti più difficili, con minore discriminabilità degli stimoli o in presenza di stimoli distraenti.\nInfine, aumentare o diminuire il tempo di non-decisione Ter influenzerebbe il tempo di reazione complessivo, senza altrimenti influenzare il processo decisionale. Ad esempio, pazienti con disfunzioni motorie potrebbero avere un Ter aumentato (e un RT complessivo maggiore), indipendentemente dalle considerazioni decisionali.\nIn sintesi, i valori dei parametri del DDM Ter, \\(a\\), \\(z\\) e \\(d\\) interagiscono per influenzare le prestazioni complessive del compito, compresi sia l’accuratezza che il tempo di reazione.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#il-meccanismo-di-accumulo-dellevidenza",
    "href": "chapters/cognitive_models/01_ddm.html#il-meccanismo-di-accumulo-dellevidenza",
    "title": "111  Drift Diffusion Model",
    "section": "111.4 Il Meccanismo di Accumulo dell’Evidenza",
    "text": "111.4 Il Meccanismo di Accumulo dell’Evidenza\nDal punto di vista formale, il Drift Diffusion Model (DDM) è un modello matematico utilizzato per descrivere il processo decisionale in situazioni di scelta binaria. Questo modello rappresenta il processo decisionale attraverso il meccanismo di accumulo dell’evidenza \\(Z_t\\).\nNel DDM, l’accumulo dell’evidenza \\(Z_t\\) è modellato come un moto browniano con drift \\(\\delta\\) e volatilità \\(\\alpha\\). Matematicamente, è espresso dalla formula:\n\\[\nZ_t = \\delta t + \\alpha B_t,\n\\tag{111.1}\\]\ndove \\(B_t\\) è un moto browniano standard o processo di Wiener.\nCiascun termine di questa formula rappresenta un aspetto fondamentale del processo decisionale:\n\n\\(Z_t\\) - Processo di accumulo dell’evidenza:\n\\(Z_t\\) rappresenta l’evidenza accumulata fino al tempo \\(t\\) verso una delle due possibili decisioni. Quando \\(Z_t\\) raggiunge una delle soglie decisionali, viene presa una decisione.\n\\(\\delta\\) - Drift rate (tasso di drift):\n\\(\\delta\\) indica la velocità media di accumulo dell’evidenza. È un parametro deterministico che rappresenta la tendenza media dell’evidenza verso una decisione. Un \\(\\delta\\) positivo implica una tendenza verso una delle opzioni (ad esempio, quella “a favore”), mentre un \\(\\delta\\) negativo suggerisce una tendenza verso l’altra opzione (ad esempio, quella “contro”). Il drift rate determina quindi la direzione e la velocità media con cui l’evidenza si accumula.\n\\(t\\) - Tempo:\n\\(t\\) rappresenta il tempo trascorso dall’inizio del processo decisionale. Nel contesto della formula, \\(t\\) viene moltiplicato per il drift rate \\(\\delta\\), indicando come l’evidenza si accumula linearmente nel tempo in base alla velocità e direzione del drift.\n\\(\\alpha\\) - Volatilità:\n\\(\\alpha\\) rappresenta l’intensità delle fluttuazioni casuali nel processo di accumulo dell’evidenza. Questo parametro misura la quantità di variabilità o “rumore” nel processo decisionale. Un valore di \\(\\alpha\\) più elevato implica maggiori fluttuazioni casuali nel percorso dell’evidenza accumulata, rendendo il processo decisionale più imprevedibile.\n\\(B_t\\) - Moto browniano standard (processo di Wiener):\n\\(B_t\\) rappresenta un moto browniano standard, noto anche come processo di Wiener, che è un modello matematico per descrivere un movimento casuale nel tempo. È un processo stocastico con media zero e varianza proporzionale al tempo \\(t\\). Nel DDM, \\(B_t\\) rappresenta le fluttuazioni casuali dell’evidenza accumulata che si verificano mentre l’individuo elabora le informazioni per prendere una decisione.\n\nIn sintesi, la formula \\(Z_t = \\delta t + \\alpha B_t\\) descrive come l’evidenza accumulata (\\(Z_t\\)) si evolve nel tempo come somma di un componente deterministico (\\(\\delta t\\)), che rappresenta la tendenza media dell’accumulo di evidenza, e un componente stocastico (\\(\\alpha B_t\\)), che rappresenta la variabilità casuale o rumore nel processo decisionale. Questa combinazione di elementi permette al DDM di modellare accuratamente come le decisioni binarie vengono prese nel tempo in presenza di incertezza e variabilità.\nNel DDM, il processo di accumulo dell’evidenza si muove in modo casuale verso l’alto o verso il basso fino a raggiungere una delle soglie decisionali prestabilite. Queste soglie rappresentano i punti critici che determinano la decisione finale: quando l’evidenza accumulata \\(Z_t\\) raggiunge una soglia, viene presa una decisione a favore dell’alternativa associata a quella soglia. Generalmente, ci sono due soglie, una superiore e una inferiore, che corrispondono alle due possibili decisioni. La scelta finale è determinata dal raggiungimento di una di queste soglie, indicando la selezione dell’agente tra le due alternative disponibili.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#il-moto-browniano",
    "href": "chapters/cognitive_models/01_ddm.html#il-moto-browniano",
    "title": "111  Drift Diffusion Model",
    "section": "111.5 Il Moto Browniano",
    "text": "111.5 Il Moto Browniano\nPer comprendere meglio il funzionamento del DDM, è utile chiarire il concetto di moto browniano (ovvero, la componente \\(B_t\\) nell’Equazione 111.1), noto anche come processo di Wiener.\nIl moto browniano è un tipo di processo stocastico che descrive il comportamento casuale di una particella in movimento. È uno dei modelli più semplici e utilizzati per rappresentare l’evoluzione temporale di variabili che cambiano in modo incerto e imprevedibile nel tempo.\nIl processo di Wiener ha diverse proprietà che lo rendono utile per modellare fenomeni casuali:\n\nInizio a zero: Il processo inizia da un punto di partenza, spesso zero, cioè \\(W(0) = 0\\).\nIncrementi indipendenti: Gli incrementi del processo sono indipendenti tra loro. Ciò significa che il cambiamento del valore del processo in un intervallo di tempo non dipende dal cambiamento in un altro intervallo di tempo non sovrapposto.\nIncrementi normali: Gli incrementi del processo di Wiener su un intervallo di tempo \\(t\\) sono distribuiti normalmente (secondo una distribuzione gaussiana) con media 0 e varianza proporzionale a \\(t\\). Formalmente, se \\(t_2 &gt; t_1\\), allora \\(W(t_2) - W(t_1) \\sim N(0, t_2 - t_1)\\).\nContinuità: Il processo di Wiener è continuo, senza salti improvvisi, il che implica che il percorso del processo nel tempo è una funzione continua.\n\nNel contesto del Drift Diffusion Model (DDM), il processo di Wiener è utilizzato per rappresentare le fluttuazioni casuali nel processo di accumulo dell’evidenza verso una delle due possibili decisioni.\n\nEvidenza accumulata: Nel DDM, l’accumulo di evidenza per una decisione è considerato come un processo che si evolve nel tempo. Questo accumulo è influenzato da un termine deterministico (il drift rate, \\(v\\)) e da un termine stocastico (il rumore, modellato dal processo di Wiener).\nTermine deterministico (drift rate, \\(v\\)): Rappresenta la velocità media di accumulo dell’evidenza verso una delle decisioni. Un drift rate positivo indica una tendenza verso una decisione “a favore”, mentre un drift rate negativo indica una tendenza verso una decisione “contro”.\nTermine stocastico (rumore): Rappresenta la variabilità casuale nell’accumulo dell’evidenza. Questo rumore è modellato come un processo di Wiener, il che significa che l’evidenza può fluttuare casualmente mentre si accumula nel tempo.\n\n\n111.5.1 Simulazione di un Processo di Wiener\nPer simulare un processo di Wiener, possiamo utilizzare un semplice modello matematico che genera incrementi casuali normali a ogni passo temporale. Nel contesto del DDM, l’evidenza accumulata \\(Z(t)\\) a un tempo \\(t\\) può essere rappresentata come:\n\\[\nZ(t + \\Delta t) = Z(t) + v \\Delta t + s \\Delta W,\n\\]\ndove:\n\n\\(\\Delta t\\) è un piccolo intervallo di tempo.\n\\(v\\) è il drift rate, che rappresenta la velocità media con cui l’evidenza si accumula in una direzione preferita.\n\\(s\\) è la deviazione standard del rumore, che misura l’intensità delle fluttuazioni casuali nel processo di accumulo dell’evidenza.\n\\(\\Delta W \\sim N(0, \\Delta t)\\) è un incremento casuale del processo di Wiener, distribuito normalmente con media 0 e varianza \\(\\Delta t\\). Questo termine rappresenta il rumore stocastico che influenza il processo decisionale.\n\nUn esempio intuitivo per comprendere il funzionamento di questi elementi è il seguente: immagina di camminare su una linea dritta su una superficie ghiacciata. Se cammini dritto, il drift rate \\(v\\) rappresenta il tuo intento di muoverti verso una direzione specifica. Tuttavia, poiché la superficie è scivolosa, ogni passo che fai è influenzato dalla casualità (il processo di Wiener), facendoti scivolare in modo imprevedibile in diverse direzioni. La tua posizione finale dipenderà sia dalla tua intenzione di camminare dritto (drift rate) sia dalla casualità dei tuoi scivolamenti (rumore stocastico).\nIn conclusione, nel DDM, il processo di Wiener rappresenta la componente casuale del processo decisionale, mentre il drift rate rappresenta la componente sistematica o deterministica. Le soglie decisionali determinano i criteri per la decisione finale. Insieme, questi elementi permettono di modellare il processo di accumulazione dell’evidenza che porta alla decisione finale e determina il tempo di reazione in situazioni di scelta binaria.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#stima-dei-parametri",
    "href": "chapters/cognitive_models/01_ddm.html#stima-dei-parametri",
    "title": "111  Drift Diffusion Model",
    "section": "111.6 Stima dei Parametri",
    "text": "111.6 Stima dei Parametri\nSono stati proposti diversi metodi per stimare i parametri del DDM. Un approccio iniziale per la stima dei parametri del DDM è il metodo del χ² (ad esempio, Ratcliff e Tuerlinckx, 2002), che confronta un istogramma delle distribuzioni dei tempi di reazione (RT) nei dati empirici con quelli previsti dal modello sotto un dato insieme di valori dei parametri.\nI principali vantaggi del metodo χ² sono la velocità computazionale e la relativa robustezza agli RT anomali. Tuttavia, il metodo χ² richiede un gran numero di prove per produrre una stima affidabile (ad esempio, almeno 500 prove) e può risultare problematico se ci sono relativamente poche risposte errate (ad esempio, meno di 12 prove in qualsiasi intervallo quantile; Voss et al., 2015). Per queste ragioni, l’approccio del χ² per l’adattamento dei parametri è diventato meno utilizzato negli ultimi anni, poiché sono stati resi disponibili altri metodi e la potenza di calcolo è aumentata.\nUn metodo popolare per stimare i parametri del DDM utilizza la stima di massima verosimiglianza (MLE) per generare stime per ciascun parametro. Formalmente, la MLE cerca di trovare un insieme di valori dei parametri che, insieme, massimizzino la probabilità che il risultato del modello corrisponda ai dati empirici su tutte le prove. Gli approcci MLE sono stati utilizzati con successo in un gran numero di studi sul DDM e possono essere utilizzati anche quando sono disponibili relativamente poche prove (ad esempio, meno di 50) per ciascun partecipante (Lerche et al., 2017). Tuttavia, la MLE può essere molto sensibile agli RT anomali (soprattutto RT molto rapidi), quindi è necessario prestare molta attenzione alla pulizia dei dati. Inoltre, gli algoritmi MLE sono vulnerabili ai minimi locali, il che significa che possono convergere su un insieme di valori dei parametri in cui nessuna piccola perturbazione può migliorare ulteriormente la LLE, anche se questa potrebbe non essere la soluzione ottimale. Per questo motivo, i ricercatori che usano questo metodo eseguono la procedura MLE più volte, con diversi valori di partenza, per assicurarsi che la stessa soluzione venga trovata ogni volta.\nRecentemente, sono stati proposti diversi approcci bayesiani per stimare i valori dei parametri del DDM. Questi metodi, partono da stime iniziali (cioè “distribuzioni a priori”) su valori ragionevoli per ciascun parametro, e tali stime vengono aggiornate iterativamente per produrre le “distribuzioni posteriori” per quei parametri. Il calcolo delle distribuzioni posteriori è estremamente intensivo dal punto di vista computazionale e la soluzione diretta è generalmente intrattabile (non esiste un modo matematico noto per calcolare direttamente i posteriori dai priori e dai dati). Invece, si cercano soluzioni approssimate usando i metodi Markov Chain Monte Carlo (MCMC). Gli approcci bayesiani al DDM possono essere più robusti nel recupero dei parametri del modello rispetto ad altri metodi, come la MLE e il metodo χ², quando è disponibile un numero limitato di prove (Wiecki et al., 2013). Gli approcci bayesiani forniscono non solo stime dei parametri (media o mediana delle distribuzioni posteriori), ma quantificano anche l’incertezza in queste stime (deviazione standard o intervallo di confidenza al 95% delle distribuzioni posteriori).\nI metodi sopra descritti per stimare i parametri del DDM presuppongono che i parametri siano adattati ai dati di ciascun partecipante in modo indipendente. Un approccio alternativo è la modellizzazione gerarchica, che affronta le differenze individuali mentre raccoglie informazioni tra individui per generare stime dei parametri a livello di gruppo (Vandekerckhove et al., 2011; Wiecki et al., 2013; Johnson et al., 2017). Gli approcci gerarchici possono essere particolarmente utili quando la variabilità all’interno del gruppo è molto inferiore rispetto alla variabilità tra gruppi, o quando è disponibile solo un numero ridotto di prove per ciascun partecipante.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#simulazione",
    "href": "chapters/cognitive_models/01_ddm.html#simulazione",
    "title": "111  Drift Diffusion Model",
    "section": "111.7 Simulazione",
    "text": "111.7 Simulazione\nL’obiettivo di questa sezione è esaminare un campione di dati generato in conformità con il modello DDM. Nella simulazione, i parametri utilizzati per generare i dati secondo il DDM sono noti. Successivamente, ci proponiamo di inferire questi parametri a partire dai dati simulati. Per raggiungere questo scopo, utilizzeremo un approccio bayesiano implementato in Stan.\nIniziamo generando i dati secondo il DDM utilizzando i seguenti parametri:\n\nDrift rate: 2.0\nThreshold separation (separazione delle soglie): 1.0\nNon-decision time (tempo di non decisione): 0.3\nStarting point (punto di partenza) \\(z\\): 0.5\n\n\ndef simulate_ddm(v, a, t, z, n_trials):\n    \"\"\"\n    Simulate data from a simplified Drift Diffusion Model.\n\n    Parameters:\n    v (float): Drift rate\n    a (float): Boundary separation\n    t (float): Non-decision time\n    z (float): Starting point (a priori bias)\n    n_trials (int): Number of trials to simulate\n\n    Returns:\n    tuple: (RTs, responses)\n    \"\"\"\n    RTs = []\n    responses = []\n\n    for _ in range(n_trials):\n        x = z * a  # starting point\n        time = 0\n\n        while True:\n            x += v * 0.001 + np.random.normal(\n                0, np.sqrt(0.001)\n            )  # update every millisecond\n            time += 0.001\n\n            if x &lt;= 0 or x &gt;= a:\n                break\n\n        RT = time + t  # add non-decision time\n        response = 1 if x &gt;= a else 0\n\n        RTs.append(RT)\n        responses.append(response)\n\n    return np.array(RTs), np.array(responses)\n\n\n# Parameters\nv_true = 2.0\na_true = 1.0\nt_true = 0.3\nz_true = 0.5\nn_trials = 1000\n\nRTs, responses = simulate_ddm(v_true, a_true, t_true, z_true, n_trials)\n\nprint(f\"Mean RT: {np.mean(RTs):.3f}\")\nprint(f\"Proportion of upper boundary responses: {np.mean(responses):.3f}\")\n\nMean RT: 0.501\nProportion of upper boundary responses: 0.888\n\n\nCreiamo un istogramma dei tempi di reazione (RT).\n\nplt.hist(RTs, bins=30, edgecolor=\"black\")\nplt.title(\"Istogramma dei Tempi di Reazione (RT)\")\nplt.xlabel(\"Tempo di Reazione (secondi)\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\nImportiamo e compiliamo il codice Stan, che utilizzeremo per generare le distribuzioni a posteriori dei parametri del DDM, basandoci su distribuzioni a priori debolmente informative.\n\nstan_file = os.path.join(\n    project_directory, \"stan\", \"ddm_wiener_model.stan\"\n)\n\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\nfunctions {\n  real wiener_rng(real alpha, real tau, real beta, real delta) {\n    real dt = 0.0001;\n    real x = alpha * beta;\n    real t = 0;\n    while (x &gt; 0 && x &lt; alpha) {\n      x += delta * dt + sqrt(dt) * normal_rng(0, 1);\n      t += dt;\n    }\n    return t + tau;\n  }\n}\ndata {\n  int&lt;lower=1&gt; N; // number of trials\n  array[N] real&lt;lower=0&gt; rt; // response times\n  array[N] int&lt;lower=0, upper=1&gt; resp; // responses (0 or 1)\n}\nparameters {\n  real&lt;lower=0, upper=10&gt; v; // drift rate\n  real&lt;lower=0.1, upper=5&gt; a; // boundary separation\n  real&lt;lower=0.001, upper=min(rt)&gt; t; // non-decision time\n  real&lt;lower=0.1, upper=0.9&gt; z; // starting point\n}\nmodel {\n  // Priors\n  v ~ normal(2, 1) T[0, 10];\n  a ~ normal(1, 0.5) T[0.1, 5];\n  t ~ normal(0.3, 0.1) T[0.001, min(rt)];\n  z ~ beta(5, 5);\n  \n  // Likelihood\n  for (i in 1 : N) {\n    if (rt[i] &gt; t) {\n      if (resp[i] == 1) {\n        target += wiener_lpdf(rt[i] | a, t, z, v);\n      } else {\n        target += wiener_lpdf(rt[i] | a, t, 1 - z, -v);\n      }\n    } else {\n      target += -1e10; // Strongly penalize impossible RTs\n    }\n  }\n}\ngenerated quantities {\n  array[N] real log_lik;\n  array[N] real y_pred;\n  for (i in 1 : N) {\n    if (rt[i] &gt; t) {\n      if (resp[i] == 1) {\n        log_lik[i] = wiener_lpdf(rt[i] | a, t, z, v);\n        y_pred[i] = wiener_rng(a, t, z, v);\n      } else {\n        log_lik[i] = wiener_lpdf(rt[i] | a, t, 1 - z, -v);\n        y_pred[i] = wiener_rng(a, t, 1 - z, -v);\n      }\n    } else {\n      log_lik[i] = -1e10;\n      y_pred[i] = t; // Set to non-decision time for impossible RTs\n    }\n  }\n}\n\n\n\nLa likelihood (verosimiglianza) nel modello Stan specifica la probabilità dei dati osservati dato un insieme di parametri. Nel contesto del DDM, la likelihood è costruita sulla base della distribuzione di probabilità dei tempi di reazione (RT) per una risposta corretta o errata, dato un set di parametri del modello (drift rate \\(v\\), boundary separation \\(a\\), non-decision time \\(t\\), e starting point \\(z\\)).\nNel blocco model, la likelihood è costruita utilizzando un ciclo for per ogni trial (prova) nei dati. Per ogni prova, la likelihood tiene conto delle seguenti considerazioni:\n\nCondizioni su \\(\\text{rt}[i] &gt; t\\):\n\nPrima di tutto, il modello verifica se il tempo di reazione osservato (rt[i]) è maggiore del tempo di non-decisione (t). Questo perché il tempo di reazione non può essere inferiore al tempo di non-decisione: se lo fosse, sarebbe un tempo di reazione impossibile.\nSe \\(\\text{rt}[i] &gt; t\\), il codice procede a calcolare la verosimiglianza; altrimenti, impone una penalità molto forte (-1e10) per quei dati, indicando che tali osservazioni sono impossibili o estremamente improbabili. Questa penalità è così grande da garantire che tali eventi non contribuiscano alla log-verosimiglianza complessiva, influenzando negativamente l’adattamento del modello se venissero accettati.\n\nCalcolo della Likelihood per le Risposte:\n\nRisposte corrette (resp[i] == 1):\n\nSe la risposta è corretta (resp[i] == 1), viene utilizzata la distribuzione dei tempi di reazione del DDM per una risposta corretta, data dai parametri \\(a\\), \\(t\\), \\(z\\), e \\(v\\).\nLa funzione wiener_lpdf(rt[i] | a, t, z, v) calcola il log della densità di probabilità per il tempo di reazione osservato (rt[i]) sotto queste condizioni.\n\nRisposte errate (resp[i] == 0):\n\nSe la risposta è errata (resp[i] == 0), viene utilizzata la distribuzione dei tempi di reazione del DDM per una risposta errata. In questo caso, il modello inverte il drift rate a \\(-v\\) e considera la posizione di partenza opposta \\((1 - z)\\).\nLa funzione wiener_lpdf(rt[i] | a, t, 1 - z, -v) calcola il log della densità di probabilità per il tempo di reazione osservato (rt[i]) sotto queste condizioni.\n\n\n\nQuesto approccio consente di stimare i parametri del modello che meglio spiegano i dati osservati, tenendo conto delle distribuzioni stocastiche che descrivono il processo decisionale nel contesto di un compito di scelta binaria.\nNel blocco parameters e model del codice, vediamo le seguenti distribuzioni a priori.\n\nv ~ normal(2, 1) T[0, 10]: Il drift rate (v) ha una distribuzione a priori normale con media 2 e deviazione standard 1, troncata tra 0 e 10. Questo prior riflette l’assunzione che il drift rate tipico sia intorno a 2, con una moderata incertezza, ed è limitato a valori non negativi e ragionevolmente grandi (fino a 10) per rappresentare le condizioni realistiche di un processo decisionale umano.\na ~ normal(1, 0.5) T[0.1, 5]: La separazione delle soglie (a) ha una distribuzione a priori normale con media 1 e deviazione standard 0.5, troncata tra 0.1 e 5. Questo prior suggerisce che, normalmente, i confini sono vicini a 1, con una certa variazione consentita. La troncatura assicura che il parametro rimanga in un intervallo ragionevole, evitando valori troppo piccoli o troppo grandi che non sarebbero realistici nei modelli di decisione umana.\nt ~ normal(0.3, 0.1) T[0.001, min(rt)]: Il tempo di non-decisione (t) ha una distribuzione a priori normale con media 0.3 e deviazione standard 0.1, troncata tra 0.001 e il valore minimo dei tempi di reazione osservati min(rt). Questo prior riflette l’idea che il tempo di non-decisione (che rappresenta il tempo impiegato per percepire e avviare una risposta senza prendere una decisione) è solitamente intorno a 0.3 secondi, ma con una moderata variabilità. La troncatura inferiore (0.001) impedisce che il tempo di non-decisione diventi irrealisticamente piccolo, mentre la troncatura superiore (min(rt)) garantisce che (t) sia sempre inferiore a qualsiasi tempo di reazione registrato.\nz ~ beta(5, 5): Il punto di partenza (z) ha una distribuzione a priori beta con parametri 5 e 5, limitata tra 0.1 e 0.9. Questo prior beta è simmetrico intorno a 0.5, suggerendo una preferenza iniziale che il punto di partenza sia centrato tra le due soglie decisionali, ma con una certa variabilità consentita. La troncatura tra 0.1 e 0.9 evita punti di partenza troppo vicini alle soglie, il che rappresenterebbe un bias estremo non tipico nelle decisioni umane.\n\nIn sintesi, questi priors debolmente informativi assicurano che le stime dei parametri siano basate sui dati osservati, ma anche che rimangano in un intervallo realistico.\nCreiamo un dizionario con i dati nel formato richiesto da Stan.\n\n# Create the data dictionary for the Stan models\nstan_data = {\n    \"N\": len(RTs),  # Number of trials\n    \"rt\": RTs,  # Reaction times\n    \"resp\": responses,  # Accuracy\n}\n\nEseguiamo il campionamento.\n\nfit = model.sample(\n    data=stan_data,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n07:05:19 - cmdstanpy - INFO - CmdStan start processing\n07:05:19 - cmdstanpy - INFO - Chain [1] start processing\n07:05:19 - cmdstanpy - INFO - Chain [2] start processing\n07:05:19 - cmdstanpy - INFO - Chain [3] start processing\n07:05:19 - cmdstanpy - INFO - Chain [4] start processing\n07:06:15 - cmdstanpy - INFO - Chain [3] done processing\n07:06:16 - cmdstanpy - INFO - Chain [2] done processing\n07:06:17 - cmdstanpy - INFO - Chain [1] done processing\n07:06:18 - cmdstanpy - INFO - Chain [4] done processing\n\n\n\n# Run diagnostics and print results\ndiagnostic_info = fit.diagnose()\nprint(diagnostic_info)\n\nProcessing csv files: /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpeh6g91py/ddm_wiener_modelhxa8924m/ddm_wiener_model-20240829070519_1.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpeh6g91py/ddm_wiener_modelhxa8924m/ddm_wiener_model-20240829070519_2.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpeh6g91py/ddm_wiener_modelhxa8924m/ddm_wiener_model-20240829070519_3.csv, /var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/tmpeh6g91py/ddm_wiener_modelhxa8924m/ddm_wiener_model-20240829070519_4.csv\n\nChecking sampler transitions treedepth.\nTreedepth satisfactory for all transitions.\n\nChecking sampler transitions for divergences.\nNo divergent transitions found.\n\nChecking E-BFMI - sampler transitions HMC potential energy.\nE-BFMI satisfactory.\n\nEffective sample size satisfactory.\n\nSplit R-hat values satisfactory all parameters.\n\nProcessing complete, no problems detected.\n\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri del DDM.\n\nfit_az = az.from_cmdstanpy(posterior=fit)\naz.summary(fit_az, var_names=[\"v\", \"a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nv\n1.93\n0.10\n1.75\n2.11\n0.0\n0.0\n3858.53\n4325.16\n1.0\n\n\na\n1.03\n0.02\n0.99\n1.07\n0.0\n0.0\n4116.55\n5011.74\n1.0\n\n\nt\n0.30\n0.00\n0.30\n0.31\n0.0\n0.0\n3233.80\n4430.35\n1.0\n\n\nz\n0.52\n0.01\n0.49\n0.54\n0.0\n0.0\n3782.31\n4288.92\n1.0\n\n\n\n\n\n\n\nDa notare che l’approccio bayesiano è riuscito a fornire stime accurate dei parametri utilizzati per la simulazione dei dati, con un livello di incertezza relativamente basso. Questo è stato possibile grazie all’uso di un campione di dati piuttosto ampio (N = 1000), che rappresenta le prove di un singolo soggetto.\nAbbiamo utilizzato il metodo Leave-One-Out (LOO) cross-validation per valutare il modello. I valori k di Pareto sono stati calcolati per identificare eventuali influenze indebite di osservazioni anomale sui risultati:\n\nloo_results = az.loo(fit_az)\nprint(loo_results)\n\nComputed from 8000 posterior samples and 1000 observations log-likelihood matrix.\n\n         Estimate       SE\nelpd_loo   404.07    34.22\np_loo        3.79        -\n------\n\nPareto k diagnostic values:\n                         Count   Pct.\n(-Inf, 0.5]   (good)     1000  100.0%\n (0.5, 0.7]   (ok)          0    0.0%\n   (0.7, 1]   (bad)         0    0.0%\n   (1, Inf)   (very bad)    0    0.0%\n\n\n\nTutte le osservazioni hanno valori k di Pareto ben sotto la soglia di 0.5, il che significa che non ci sono prove di influenze indebite da parte di osservazioni anomale sui risultati. I risultati indicano dunque che non ci sono evidenze di influenze eccessive da parte di osservazioni anomale nel campione, confermando che il modello è stabile e le stime sono affidabili.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#linfluenza-delle-mascherine-sulle-valutazioni-delle-emozioni",
    "href": "chapters/cognitive_models/01_ddm.html#linfluenza-delle-mascherine-sulle-valutazioni-delle-emozioni",
    "title": "111  Drift Diffusion Model",
    "section": "111.8 L’influenza delle mascherine sulle valutazioni delle emozioni",
    "text": "111.8 L’influenza delle mascherine sulle valutazioni delle emozioni\nPer esercizio, esaminiamo lo studio di Williams et al. (2023), che ha analizzato l’influenza delle mascherine facciali sul riconoscimento delle emozioni. Sebbene sia noto che le mascherine rallentano la diffusione del SARS-CoV-2, non è ancora chiaro in che modo possano influenzare le interazioni sociali. Una possibile conseguenza è che le mascherine possano modificare il modo in cui le persone comunicano le emozioni attraverso le espressioni facciali. Nel loro studio, Williams et al. (2023) indagano in che misura e in che modo le mascherine influenzano la comunicazione delle emozioni facciali, utilizzando il modello di drift-diffusion (DDM).\n\n\n\nAi partecipanti venivano mostrate espressioni facciali che rappresentavano sei emozioni (rabbia, disgusto, paura, felicità, tristezza, sorpresa) con tre diversi tipi di “maschere facciali” (inferiore, nessuna, superiore) – figura tratta da Williams et al. (2023).\n\n\nI risultati evidenziano che, sebbene le persone siano ancora in grado di comunicare efficacemente le emozioni indossando mascherine, emergono anche delle difficoltà legate al riconoscimento delle emozioni stesse. Utilizzando il DDM, Williams et al. (2023) dimostrano che l’accumulo di evidenze, come meccanismo sottostante, può essere influenzato dall’uso delle mascherine, e che in situazioni in cui il tempo è un fattore critico, le mascherine potrebbero aumentare il rischio di incomprensioni.\nI risultati dello studio di Williams et al. (2023) mostrano che i partecipanti sono riusciti a identificare le espressioni facciali più frequentemente rispetto al caso anche con le mascherine. Tuttavia, i partecipanti erano meno propensi e più lenti a riconoscere correttamente le espressioni quando le mascherine coprivano parte del volto e accumulavano evidenze sulle emozioni in modo più lento rispetto a quando non indossavano le mascherine.\nPer gli scopi di questo tutorial, utilizzeremo il modello Stan descritto in precedenza per analizzare il riconoscimento di una specifica emozione, considerando se il volto è coperto o meno da una maschera visiva. L’emozione che prenderemo in esame è la rabbia. La maschera visiva, quando presente, copre la parte superiore del volto. In queste condizioni, Williams et al. (2023) hanno riscontrato un drift rate inferiore quando i partecipanti dovevano riconoscere l’emozione da stimoli parzialmente mascherati.\nNel loro studio originale, Williams et al. (2023) hanno coinvolto 228 soggetti. Per analizzare questi dati sarebbe quindi opportuno utilizzare un modello bayesiano gerarchico. Tuttavia, per semplicità, in questo tutorial utilizzeremo un sotto-campione casuale di 30 soggetti nelle due condizioni descritte. Inoltre, considereremo questi dati come provenienti da un unico “super-soggetto”, trascurando le differenze individuali.\nIniziamo importando i dati relativi alla condizione in cui il volto arrabbiato è parzialmente coperto da una maschera visiva.\n\ndf_angry_upper = pd.read_csv(\"../../data/williams_2023_angry_upper.csv\")\ndf_angry_upper.head()\n\n\n\n\n\n\n\n\nsubj_idx\ntrial\nresponse\nrt\nresp\n\n\n\n\n0\n2b3o5c2c6ntefnb\n35\n0\n1.720625\n1\n\n\n1\n2b3o5c2c6ntefnb\n65\n0\n2.227810\n1\n\n\n2\n2b3o5c2c6ntefnb\n69\n0\n0.584445\n1\n\n\n3\n2b3o5c2c6ntefnb\n73\n0\n0.805395\n1\n\n\n4\n2b3o5c2c6ntefnb\n91\n0\n1.181125\n1\n\n\n\n\n\n\n\nImportiamo i dati relativi alla condizione in cui il volto arrabbiato non è coperto da una maschera visiva.\n\ndf_angry_baseline = pd.read_csv(\"../../data/williams_2023_angry_baseline.csv\")\ndf_angry_baseline.head()\n\n\n\n\n\n\n\n\nsubj_idx\ntrial\nresponse\nrt\nresp\n\n\n\n\n0\n2b3o5c2c6ntefnb\n18\n0\n0.771650\n1\n\n\n1\n2b3o5c2c6ntefnb\n47\n0\n0.626895\n1\n\n\n2\n2b3o5c2c6ntefnb\n77\n0\n0.744640\n1\n\n\n3\n2b3o5c2c6ntefnb\n93\n0\n0.612550\n1\n\n\n4\n2b3o5c2c6ntefnb\n98\n0\n0.639810\n1\n\n\n\n\n\n\n\nGeneriamo un dizionario con i dati e eseguiamo il campionamento per i giudizi nei quali il volto arrabbiato non è coperto da una maschera visiva.\n\nstan_data_baseline = {\n    \"N\": len(df_angry_baseline[\"rt\"]),  # Number of trials\n    \"rt\": df_angry_baseline[\"rt\"],  # Reaction times\n    \"resp\": df_angry_baseline[\"resp\"],  # Accuracy\n}\n\n\nfit_baseline = model.sample(\n    data=stan_data_baseline,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n08:53:25 - cmdstanpy - INFO - CmdStan start processing\n08:53:25 - cmdstanpy - INFO - Chain [1] start processing\n08:53:25 - cmdstanpy - INFO - Chain [2] start processing\n08:53:25 - cmdstanpy - INFO - Chain [3] start processing\n08:53:25 - cmdstanpy - INFO - Chain [4] start processing\n08:55:13 - cmdstanpy - INFO - Chain [2] done processing\n08:55:13 - cmdstanpy - INFO - Chain [4] done processing\n08:55:13 - cmdstanpy - INFO - Chain [1] done processing\n08:55:15 - cmdstanpy - INFO - Chain [3] done processing\n\n\nEsaminiamo la distribuzione a posteriori dei parametri del DDM.\n\nfit_baseline_az = az.from_cmdstanpy(posterior=fit_baseline)\naz.summary(fit_baseline_az, var_names=[\"v\", \"a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nv\n0.58\n0.05\n0.48\n0.67\n0.0\n0.0\n4298.51\n4116.92\n1.0\n\n\na\n2.04\n0.04\n1.97\n2.11\n0.0\n0.0\n5596.90\n5367.25\n1.0\n\n\nt\n0.02\n0.01\n0.01\n0.04\n0.0\n0.0\n5183.94\n2552.18\n1.0\n\n\nz\n0.44\n0.01\n0.41\n0.46\n0.0\n0.0\n4684.97\n4835.42\n1.0\n\n\n\n\n\n\n\nGeneriamo un dizionario con i dati e eseguiamo il campionamento per i giudizi nei quali il volto arrabbiato è parzialmente coperto da una maschera visiva.\n\nstan_data_upper = {\n    \"N\": len(df_angry_upper[\"rt\"]),  # Number of trials\n    \"rt\": df_angry_upper[\"rt\"],  # Reaction times\n    \"resp\": df_angry_upper[\"resp\"],  # Accuracy\n}\n\n\nfit_upper = model.sample(\n    data=stan_data_upper,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n08:55:40 - cmdstanpy - INFO - CmdStan start processing\n08:55:40 - cmdstanpy - INFO - Chain [1] start processing\n08:55:40 - cmdstanpy - INFO - Chain [2] start processing\n08:55:40 - cmdstanpy - INFO - Chain [3] start processing\n08:55:40 - cmdstanpy - INFO - Chain [4] start processing\n08:57:22 - cmdstanpy - INFO - Chain [3] done processing\n08:57:22 - cmdstanpy - INFO - Chain [1] done processing\n08:57:23 - cmdstanpy - INFO - Chain [4] done processing\n08:57:24 - cmdstanpy - INFO - Chain [2] done processing\n\n\nEsaminiamo la distribuzione a posteriori dei parametri del DDM.\n\nfit_upper_az = az.from_cmdstanpy(posterior=fit_upper)\naz.summary(fit_upper_az, var_names=[\"v\", \"a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nv\n0.80\n0.05\n0.69\n0.90\n0.0\n0.0\n5111.57\n5265.06\n1.0\n\n\na\n2.03\n0.04\n1.96\n2.10\n0.0\n0.0\n5790.70\n5524.83\n1.0\n\n\nt\n0.03\n0.01\n0.02\n0.05\n0.0\n0.0\n5451.82\n4255.68\n1.0\n\n\nz\n0.41\n0.01\n0.38\n0.43\n0.0\n0.0\n5288.96\n5238.00\n1.0\n\n\n\n\n\n\n\nI risultati ottenuti mostrano che il drift rate è più alto nella condizione in cui il volto è parzialmente coperto. Con un sottocampione di 50 soggetti, questo risultato contraddice quanto riscontrato da Williams et al. (2023). L’obiettivo di questo esercizio era semplicemente verificare se il modello Stan descritto in precedenza potesse essere applicato a un campione di dati reali. Le due analisi effettuate confermano che ciò è possibile. Tuttavia, i risultati evidenziano anche i limiti del modello Stan utilizzato. È infatti fondamentale considerare le differenze individuali, cosa che non è stata fatta in questo caso, e disporre di un campione di grandi dimensioni per ottenere risultati affidabili.\nRiformuliamo dunque il modello Stan per rendere conto delle differenze individuali nei parametri del modello DDM. Nella versione qui considerata consentiremo a drift rate e boundary separation di assumere valori diversi tra i soggetti.\nCreaiamo il dizionario dei dati nel formato richiesto dal modello gerarchico.\n\n# Crea un indice unico per ogni soggetto\ndf_angry_baseline[\"subj_id\"] = (\n    df_angry_baseline[\"subj_idx\"].astype(\"category\").cat.codes + 1\n)\n\n# Crea il dizionario per Stan\nstan_data_baseline = {\n    \"N\": len(df_angry_baseline),  # numero totale di prove\n    \"S\": df_angry_baseline[\"subj_id\"].nunique(),  # numero totale di soggetti\n    \"subj\": df_angry_baseline[\"subj_id\"].values,  # array di ID soggetto per ogni prova\n    \"rt\": df_angry_baseline[\"rt\"].values,  # array di tempi di reazione\n    \"resp\": df_angry_baseline[\"resp\"].values,  # array di risposte\n}\n\n\n# Crea un indice unico per ogni soggetto\ndf_angry_upper[\"subj_id\"] = df_angry_upper[\"subj_idx\"].astype(\"category\").cat.codes + 1\n\n# Crea il dizionario per Stan\nstan_data_upper = {\n    \"N\": len(df_angry_upper),  # numero totale di prove\n    \"S\": df_angry_upper[\"subj_id\"].nunique(),  # numero totale di soggetti\n    \"subj\": df_angry_upper[\"subj_id\"].values,  # array di ID soggetto per ogni prova\n    \"rt\": df_angry_upper[\"rt\"].values,  # array di tempi di reazione\n    \"resp\": df_angry_upper[\"resp\"].values,  # array di risposte\n}\n\nCompiliamo e stampiamo il modello gerarchico. Si noti l’istruzione target += wiener_lpdf(rt[i] | a[subj[i]], t, 1 - z, -v[subj[i]]); che consente le differenze individuali nei due parametri indicati.\n\nstan_file = os.path.join(project_directory, \"stan\", \"ddm_h_wiener_model.stan\")\n\nmodel_h = CmdStanModel(stan_file=stan_file)\nprint(model_h.code())\n\n08:39:25 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/ddm_h_wiener_model.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/ddm_h_wiener_model\n08:39:41 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/ddm_h_wiener_model\n\n\nfunctions {\n  real wiener_rng(real alpha, real tau, real beta, real delta) {\n    real dt = 0.0001;\n    real x = alpha * beta;\n    real t = 0;\n    while (x &gt; 0 && x &lt; alpha) {\n      x += delta * dt + sqrt(dt) * normal_rng(0, 1);\n      t += dt;\n    }\n    return t + tau;\n  }\n}\ndata {\n  int&lt;lower=1&gt; N; // number of trials\n  int&lt;lower=1&gt; S; // number of subjects\n  array[N] int&lt;lower=1, upper=S&gt; subj; // subject IDs\n  array[N] real&lt;lower=0&gt; rt; // response times\n  array[N] int&lt;lower=0, upper=1&gt; resp; // responses (0 or 1)\n}\nparameters {\n  // Group-level parameters\n  real&lt;lower=0, upper=10&gt; mu_v; // group mean drift rate\n  real&lt;lower=0, upper=10&gt; sigma_v; // group std dev for drift rate\n  real&lt;lower=0.1, upper=5&gt; mu_a; // group mean boundary separation\n  real&lt;lower=0, upper=5&gt; sigma_a; // group std dev for boundary separation\n  real&lt;lower=0.001, upper=min(rt)&gt; t; // non-decision time\n  real&lt;lower=0.1, upper=0.9&gt; z; // starting point\n  \n  // Subject-level parameters\n  array[S] real&lt;lower=0, upper=10&gt; v; // drift rate for each subject\n  array[S] real&lt;lower=0.1, upper=5&gt; a; // boundary separation for each subject\n}\nmodel {\n  // Priors for group-level parameters\n  mu_v ~ normal(2, 1) T[0, 10];\n  sigma_v ~ normal(0, 1) T[0, 5];\n  mu_a ~ normal(1, 0.5) T[0.1, 5];\n  sigma_a ~ normal(0, 0.5) T[0, 5];\n  t ~ normal(0.3, 0.1) T[0.001, min(rt)];\n  z ~ beta(5, 5);\n  \n  // Priors for subject-level parameters\n  v ~ normal(mu_v, sigma_v) T[0, 10];\n  a ~ normal(mu_a, sigma_a) T[0.1, 5];\n  \n  // Likelihood\n  for (i in 1 : N) {\n    if (rt[i] &gt; t) {\n      if (resp[i] == 1) {\n        target += wiener_lpdf(rt[i] | a[subj[i]], t, z, v[subj[i]]);\n      } else {\n        target += wiener_lpdf(rt[i] | a[subj[i]], t, 1 - z, -v[subj[i]]);\n      }\n    } else {\n      target += -1e10; // Strongly penalize impossible RTs\n    }\n  }\n}\ngenerated quantities {\n  array[N] real log_lik;\n  array[N] real y_pred;\n  for (i in 1 : N) {\n    if (rt[i] &gt; t) {\n      if (resp[i] == 1) {\n        log_lik[i] = wiener_lpdf(rt[i] | a[subj[i]], t, z, v[subj[i]]);\n        y_pred[i] = wiener_rng(a[subj[i]], t, z, v[subj[i]]);\n      } else {\n        log_lik[i] = wiener_lpdf(rt[i] | a[subj[i]], t, 1 - z, -v[subj[i]]);\n        y_pred[i] = wiener_rng(a[subj[i]], t, 1 - z, -v[subj[i]]);\n      }\n    } else {\n      log_lik[i] = -1e10;\n      y_pred[i] = t; // Set to non-decision time for impossible RTs\n    }\n  }\n}\n\n\n\nEseguiamo il campionamento.\n\nfit_h_upper = model_h.sample(\n    data=stan_data_upper,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n08:40:51 - cmdstanpy - INFO - CmdStan start processing\n08:40:51 - cmdstanpy - INFO - Chain [1] start processing\n08:40:51 - cmdstanpy - INFO - Chain [2] start processing\n08:40:51 - cmdstanpy - INFO - Chain [3] start processing\n08:40:51 - cmdstanpy - INFO - Chain [4] start processing\n08:46:59 - cmdstanpy - INFO - Chain [2] done processing\n08:47:07 - cmdstanpy - INFO - Chain [4] done processing\n08:47:26 - cmdstanpy - INFO - Chain [1] done processing\n08:47:41 - cmdstanpy - INFO - Chain [3] done processing\n08:47:41 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_lpdf: Scale parameter is 0, but must be positive! (in 'ddm_h_wiener_model.stan', line 44, column 2 to column 38)\nConsider re-running with show_console=True if the above output is unclear!\n08:47:42 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 4 had 1 divergent transitions (0.1%)\n    Use the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n\n\n\nfit_h_upper_az = az.from_cmdstanpy(posterior=fit_h_upper)\naz.summary(fit_h_upper_az, var_names=[\"mu_v\", \"mu_a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_v\n0.57\n0.22\n0.12\n0.92\n0.0\n0.0\n3661.41\n2767.05\n1.0\n\n\nmu_a\n2.20\n0.10\n2.01\n2.38\n0.0\n0.0\n10142.31\n5346.70\n1.0\n\n\nt\n0.08\n0.00\n0.08\n0.09\n0.0\n0.0\n8233.31\n5854.03\n1.0\n\n\nz\n0.42\n0.01\n0.40\n0.44\n0.0\n0.0\n5464.86\n5489.24\n1.0\n\n\n\n\n\n\n\n\nfit_h_baseline = model_h.sample(\n    data=stan_data_baseline,\n    iter_warmup=2_000,\n    iter_sampling=2_000,\n    seed=42,\n    show_progress=False,\n    show_console=False,\n)\n\n08:49:25 - cmdstanpy - INFO - CmdStan start processing\n08:49:25 - cmdstanpy - INFO - Chain [1] start processing\n08:49:25 - cmdstanpy - INFO - Chain [2] start processing\n08:49:25 - cmdstanpy - INFO - Chain [3] start processing\n08:49:25 - cmdstanpy - INFO - Chain [4] start processing\n08:51:25 - cmdstanpy - INFO - Chain [1] done processing\n08:51:26 - cmdstanpy - INFO - Chain [4] done processing\n08:51:26 - cmdstanpy - INFO - Chain [2] done processing\n08:51:31 - cmdstanpy - INFO - Chain [3] done processing\n08:51:31 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: normal_lpdf: Scale parameter is 0, but must be positive! (in 'ddm_h_wiener_model.stan', line 44, column 2 to column 38)\nConsider re-running with show_console=True if the above output is unclear!\n08:51:32 - cmdstanpy - WARNING - Some chains may have failed to converge.\n    Chain 1 had 3 divergent transitions (0.1%)\n    Chain 3 had 2 divergent transitions (0.1%)\n    Use the \"diagnose()\" method on the CmdStanMCMC object to see further information.\n\n\n\nfit_h_baseline_az = az.from_cmdstanpy(posterior=fit_h_baseline)\naz.summary(fit_h_baseline_az, var_names=[\"mu_v\", \"mu_a\", \"t\", \"z\"], round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu_v\n0.61\n0.22\n0.14\n0.97\n0.0\n0.0\n5215.94\n3176.96\n1.0\n\n\nmu_a\n2.01\n0.12\n1.78\n2.21\n0.0\n0.0\n8588.11\n5230.70\n1.0\n\n\nt\n0.07\n0.01\n0.06\n0.08\n0.0\n0.0\n8776.01\n6180.00\n1.0\n\n\nz\n0.42\n0.01\n0.39\n0.45\n0.0\n0.0\n6994.74\n6781.55\n1.0\n\n\n\n\n\n\n\nNemmeno il modello gerarchico è riuscito a replicare i risultati riportati da Williams et al. (2023) utilizzando un sotto-campione di 30 soggetti. Tuttavia, in questo caso, abbiamo riscontrato che l’intervallo di credibilità al 94% per il parametro v è estremamente ampio, il che impedisce di differenziare chiaramente tra le due condizioni (maschera presente / assente). Pertanto, non giungiamo a una conclusione opposta a quella di Williams et al. (2023), ma dobbiamo ammettere che, con soli 30 soggetti, i dati non permettono di distinguere tra le due condizioni. Questo secondo esercizio dimostra che un modello gerarchico fornisce un risultato più ragionevole rispetto al modello precedente, che non considerava le differenze individuali. I risultati evidenziano anche che, per ottenere stime interpretabili e non eccessivamente rumorose, è necessario disporre di un campione di dimensioni adeguate: 30 soggetti non sono sufficienti. Williams et al. (2023) ne hanno utilizzati 228.\n\nEsempio 111.1 Simulare un singolo percorso del processo di Wiener e visualizzarlo.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\n\n# Simulazione del processo di Wiener\nW = np.zeros(N + 1)\nfor i in range(1, N + 1):\n    dW = np.random.normal(0, np.sqrt(dt))\n    W[i] = W[i - 1] + dW\n\n# Visualizzazione del percorso\nplt.plot(np.linspace(0, T, N + 1), W)\nplt.title(\"Percorso del Processo di Wiener\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 111.2 Simulare più percorsi del processo di Wiener e verificare che la distribuzione finale sia normale con media 0 e varianza \\(T\\).\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\nnum_simulations = 1000  # Numero di percorsi\n\n# Simulazione del processo di Wiener\nfinal_values = []\nfor _ in range(num_simulations):\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    final_values.append(W[-1])\n\n# Visualizzazione della distribuzione finale\nplt.hist(final_values, bins=50, density=True, alpha=0.75)\nplt.title(\"Distribuzione dei Valori Finali del Processo di Wiener\")\nplt.xlabel(\"Valore Finale\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 111.3 Studiare come cambia il percorso simulato del processo di Wiener al variare del passo temporale \\(dt\\).\n\n# Parametri\nT = 1.0  # Tempo totale\ndt_values = [0.1, 0.01, 0.001]  # Differenti passi temporali\n\nplt.figure(figsize=(10, 6))\n\nfor dt in dt_values:\n    N = int(T / dt)\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    plt.plot(np.linspace(0, T, N + 1), W, label=f\"dt = {dt}\")\n\nplt.title(\"Effetto del Passo Temporale sul Processo di Wiener\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 111.4 Calcolare le statistiche (media, varianza) del processo di Wiener in vari momenti temporali e confrontarle con le aspettative teoriche.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\nnum_simulations = 1000  # Numero di percorsi\ntimes = [0.2, 0.5, 1.0]  # Tempi da analizzare\n\n# Simulazione del processo di Wiener\nresults = {time: [] for time in times}\n\nfor _ in range(num_simulations):\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + dW\n    for time in times:\n        index = int(time / dt)\n        results[time].append(W[index])\n\n# Calcolo delle statistiche e confronto con la teoria\nfor time in times:\n    mean_empirical = np.mean(results[time])\n    var_empirical = np.var(results[time])\n    print(f\"Tempo: {time}\")\n    print(f\"Media empirica: {mean_empirical}, Media teorica: 0\")\n    print(f\"Varianza empirica: {var_empirical}, Varianza teorica: {time}\")\n    print(\"-\" * 40)\n\nTempo: 0.2\nMedia empirica: -0.01777872452188507, Media teorica: 0\nVarianza empirica: 0.2053824073161039, Varianza teorica: 0.2\n----------------------------------------\nTempo: 0.5\nMedia empirica: -0.005285999658711841, Media teorica: 0\nVarianza empirica: 0.5293344499462272, Varianza teorica: 0.5\n----------------------------------------\nTempo: 1.0\nMedia empirica: 0.008509695492746614, Media teorica: 0\nVarianza empirica: 0.999542671263401, Varianza teorica: 1.0\n----------------------------------------\n\n\n\n\nEsempio 111.5 Simulare un processo di Wiener con un drift costante (valore di tendenza \\(\\mu\\)) e osservare come il percorso viene influenzato.\n\n# Parametri\nT = 1.0  # Tempo totale\ndt = 0.01  # Passo temporale\nN = int(T / dt)  # Numero di passi\ndrift_values = [0.0, 0.5, 1.0]  # Differenti valori di drift\n\nplt.figure(figsize=(10, 6))\n\nfor drift in drift_values:\n    W = np.zeros(N + 1)\n    for i in range(1, N + 1):\n        dW = np.random.normal(0, np.sqrt(dt))\n        W[i] = W[i - 1] + drift * dt + dW\n    plt.plot(np.linspace(0, T, N + 1), W, label=f\"Drift = {drift}\")\n\nplt.title(\"Processo di Wiener con Drift\")\nplt.xlabel(\"Tempo\")\nplt.ylabel(\"W(t)\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#considerazioni-conclusive",
    "href": "chapters/cognitive_models/01_ddm.html#considerazioni-conclusive",
    "title": "111  Drift Diffusion Model",
    "section": "111.9 Considerazioni Conclusive",
    "text": "111.9 Considerazioni Conclusive\nUn modo per approfondire la comprensione della presa di decisione è attraverso l’utilizzo di modelli computazionali. Questi modelli cercano di dedurre informazioni sui processi cognitivi sottostanti a partire dai comportamenti osservabili durante il processo decisionale. Offrendo un quadro matematico per descrivere il comportamento, i modelli computazionali consentono ai ricercatori di svelare i meccanismi che guidano le azioni osservate. In questo capitolo, abbiamo esaminato il Drift Diffusion Model (DDM), che rappresenta l’accumulo di evidenze nel contesto di una decisione rapida tra due alternative, utilizzando quattro parametri: il drift rate, la threshold separation, il non-decision time e il starting point. Questi parametri sono considerati costanti nell’arco temporale in cui viene misurato il processo decisionale. Tuttavia, nelle versioni più recenti di questo modello (Schumacher et al., 2023), si ipotizza che anche questi parametri possano variare nel tempo.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/cognitive_models/01_ddm.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/cognitive_models/01_ddm.html#informazioni-sullambiente-di-sviluppo",
    "title": "111  Drift Diffusion Model",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m \n\nLast updated: Tue Aug 27 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nMyers, C. E., Interian, A., & Moustafa, A. A. (2022). A practical introduction to using the drift diffusion model of decision-making in cognitive psychology, neuroscience, and health sciences. Frontiers in Psychology, 13, 1039172.\n\n\nSchumacher, L., Bürkner, P.-C., Voss, A., Köthe, U., & Radev, S. T. (2023). Neural superstatistics for Bayesian estimation of dynamic cognitive models. Scientific Reports, 13(1), 13778.\n\n\nWilliams, W. C., Haque, E., Mai, B., & Venkatraman, V. (2023). Face masks influence emotion judgments of facial expressions: a drift–diffusion model. Scientific Reports, 13(1), 8842.",
    "crumbs": [
      "Modelli cognitivi",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Drift Diffusion Model</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "href": "chapters/frequentist_inference/introduction_frequentist_inference.html",
    "title": "Introduzione",
    "section": "",
    "text": "Nell’inferenza statistica esistono due approcci principali: la statistica frequentista e la statistica bayesiana. Entrambi i metodi permettono di trarre conclusioni sulla popolazione di interesse analizzando i dati, stimare quantità sconosciute, fare previsioni e testare ipotesi. Tuttavia, differiscono nell’interpretazione della probabilità e nell’integrazione di conoscenze precedenti ed evidenze.\nLa statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento. Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica utilizzando il teorema di Bayes. In questo contesto, il valore vero di un parametro della popolazione è trattato come una variabile casuale, che viene costantemente aggiornata man mano che nuovi dati vengono raccolti. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, utilizzabile per fare previsioni probabilistiche e quantificare l’incertezza associata.\nD’altra parte, la statistica frequentista interpreta la probabilità come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute dai dati osservati utilizzando varie tecniche statistiche e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nIn questa sezione della dispensa esamineremo i metodi frequentisti della stima puntuale, degli intervalli di confidenza e del test di ipotesi.",
    "crumbs": [
      "Frequentismo",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html",
    "title": "112  Introduzione all’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nCi sono due approcci principali per l’inferenza statistica: la statistica frequentista e la statistica bayesiana. Questi metodi consentono di fare conclusioni sulla popolazione di interesse attraverso l’analisi dei dati. Entrambi gli approcci sono usati per stimare quantità sconosciute, fare previsioni e testare ipotesi, ma differiscono nella loro interpretazione della probabilità e in come integrano le conoscenze precedenti ed evidenze.\nNella statistica frequentista, la probabilità viene interpretata come la frequenza relativa a lungo termine di un evento in un numero infinito di prove. Questo approccio si basa sull’idea che il vero valore di un parametro della popolazione sia fisso, ma sconosciuto e debba essere stimato dai dati. In questo contesto, le inferenze statistiche vengono ottenute a partire dai dati osservati, mediante l’utilizzo di tecniche come la stima puntuale, gli intervalli di confidenza e il test di ipotesi, e facendo alcune assunzioni riguardo al processo sottostante che genera i dati.\nD’altra parte, la statistica bayesiana interpreta la probabilità come una misura di convinzione o grado di certezza riguardo a un evento (Jaynes, 2003). Questo approccio consente di incorporare conoscenze pregresse ed evidenze nell’analisi statistica attraverso l’uso del teorema di Bayes. In questo contesto, il vero valore di un parametro della popolazione è trattato come una variabile casuale e viene continuamente aggiornato man mano che vengono raccolti nuovi dati. Ciò porta alla formazione di una distribuzione completa nello spazio dei parametri, nota come distribuzione a posteriori, che può essere utilizzata per fare previsioni probabilistiche e quantificare l’incertezza associata.\nIn questo capitolo, approfondiremo il concetto di distribuzione campionaria che costituisce uno dei pilastri dell’inferenza statistica frequentista. La distribuzione campionaria ci permette di comprendere come le stime dei parametri della popolazione, come la media o la varianza, cambiano da campione a campione. In particolare, la distribuzione campionaria ci consente di stabilire delle proprietà probabilistiche delle stime campionarie, come ad esempio la loro media e la loro varianza. Queste proprietà sono utili per costruire gli intervalli di fiducia e i test di ipotesi che costituiscono gli strumenti principali dell’inferenza statistica frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#i-frequentisti-sono-razzisti",
    "title": "112  Introduzione all’inferenza frequentista",
    "section": "112.1 I Frequentisti sono Razzisti?",
    "text": "112.1 I Frequentisti sono Razzisti?\nNel Capitolo 31, abbiamo esaminato le origini storiche e il contesto culturale che ha contribuito all’interpretazione applicativa del teorema di Bayes fornita da Richard Price. Queste origini sono legate alle idee alla base della rivoluzione americana, rappresentando quello che potremmo definire il “lato luminoso” del liberalismo moderno.\nLe origini culturali dell’approccio frequentista, invece, sono diametralmente opposte e strettamente connesse a quella che potremmo chiamare la “parte oscura” della modernità. Si potrebbe dire che l’avversione per la soggettività abbia guidato l’ascesa del frequentismo.\nFrancis Galton (1822-1911) fu un uomo straordinario sotto molti aspetti. Cugino di Charles Darwin e medico qualificato, ereditò una fortuna che gli permise di dedicarsi liberamente ai suoi interessi. Esplorò l’Africa, ricevendo una medaglia dalla Royal Geographical Society, e diede un importante contributo alla meteorologia, notando per primo il fenomeno degli “anticicloni”. Tuttavia, il suo contributo più significativo riguardò l’uso della statistica nello studio degli esseri umani, in particolare nell’analisi della trasmissione ereditaria del talento.\nGalton trascorse gran parte della sua carriera all’University College di Londra, dove fece numerose scoperte. Tra queste, un importante contributo riguardava la distribuzione normale. Fu anche il primo a spiegare il concetto che oggi conosciamo come “regressione verso la media”, da lui chiamato “regressione verso la mediocrità”.\nIl suo interesse per l’ereditarietà del talento lo portò a scrivere il libro “Hereditary Genius”, in cui esaminava come i pensatori brillanti spesso si concentrassero in determinate famiglie. Coniò l’espressione “nature and nurture” per riferirsi ai due fattori che influenzano lo sviluppo umano: l’ereditarietà (quello che oggi chiamiamo genetica) e l’ambiente.\nTuttavia, Galton non si limitò a osservare e documentare fatti sulla distribuzione dell’intelligenza. Il suo obiettivo era creare una scienza dell’allevamento umano, che egli denominò “eugenetica”. Egli sosteneva l’incoraggiamento della riproduzione tra le famiglie di maggior successo e lo scoraggiamento tra quelle meno fortunate.\nGalton era anche estremamente razzista. In una lettera al Times di Londra, definì gli africani “inferiori” e “selvaggi pigri e chiacchieroni”, descrisse gli arabi come “poco più che consumatori della produzione altrui” e sostenne che l’Africa orientale dovesse essere consegnata ai cinesi, poiché questi, nonostante fossero “inclini alla menzogna e alla servilità”, erano per natura “industriosi e amanti dell’ordine”. Per Galton, gli anglosassoni erano la migliore razza esistente, sebbene ritenesse che gli antichi ateniesi fossero stati i migliori di tutti i tempi.\nIl lavoro di Galton ispirò una generazione successiva di statistici, in particolare Karl Pearson (1857-1936) e Ronald Fisher (1890-1962). Come Galton, Fisher e Pearson erano brillanti, ma condividevano anche le sue idee razziste, considerate inaccettabili sia per gli standard attuali che per quelli del loro tempo.\nKarl Pearson, un poliedrico studioso, divenne professore di matematica applicata all’UCL nel 1885, seguendo le orme di Galton. Alla morte di quest’ultimo, ereditò la cattedra di eugenismo finanziata da Galton stesso. Pearson fondò la rivista di statistica “Biometrika” e sviluppò il test del chi quadrato, oltre a coniare il termine “deviazione standard”.\nRonald Fisher, più giovane, succedette a Pearson come professore di eugenismo all’UCL. Fisher è considerato un gigante della teoria statistica, avendo inventato o esteso numerosi strumenti statistici moderni, tra cui l’analisi della varianza (ANOVA), il concetto di “significatività statistica” e il metodo della massima verosimiglianza (MLE).\nTutti questi ricercatori cercarono di allontanare la statistica dall’approccio soggettivo di Laplace e Bayes. Come Galton, sia Pearson che Fisher erano convinti sostenitori dell’eugenismo.\nÈ interessante chiedersi se le idee di Galton, Pearson e Fisher sull’eugenismo abbiano influenzato le loro visioni scientifiche. Secondo alcuni studiosi, la storia della statistica e dell’eugenismo sono strettamente intrecciate. Fisher e, in misura minore, Pearson respingevano l’idea del bayesianesimo perché cercavano di assegnare un fondamento “oggettivo” alle loro idee eugenetiche. Se fosse stata la scienza a stabilire che alcune razze erano inferiori e altre superiori, o che si dovesse scoraggiare la riproduzione tra i poveri, allora queste idee sarebbero state incontestabili. Il bayesianesimo, con la sua intrinseca soggettività, minava questa pretesa di oggettività.\nQuanto di tutto ciò dobbiamo tenere a mente quando esaminiamo la statistica frequentista? Chivers (2024) risponde in questo modo. È certo che parte dell’ideologia razziale nazista può essere ricondotta senza troppe difficoltà a Galton. Tuttavia, questa considerazione, per quanto estremamente importante dal punto di vista storico ed etico, non è direttamente rilevante in ambito statistico. La domanda cruciale in termini statistici rimane: “Quale approccio è corretto?” o, più accuratamente, “Quale è più utile?”, piuttosto che “Quale ha avuto i sostenitori più disgustosi?”.\nD’altra parte, personalmente ritengo che la risposta di Chivers (2024) sia fondamentalmente inadeguata. Consideriamo uno scenario ipotetico: all’interno di una “torre d’avorio” - che sia la statistica, l’accademia o la scienza in generale - la teoria A si dimostra più efficace della teoria B. Tuttavia, al di fuori di questo ambito ristretto, la teoria A, a differenza della B, comporta implicazioni etiche inaccettabili.\nDobbiamo davvero accettare A solo perché funziona meglio all’interno di questo microcosmo artificiale? Assolutamente no.\nInnanzitutto, le cosiddette “torri d’avorio” sono mere costruzioni ideologiche. Non esiste una vera demarcazione tra “dentro” e “fuori” questi ambiti. La scienza e l’etica non operano in compartimenti stagni, ma si influenzano reciprocamente in un continuo dialogo.\nInoltre, nel caso specifico del frequentismo, è evidente - come dimostreremo in seguito - che questo metodo è intrinsecamente fallace, indipendentemente dal contesto in cui lo si applichi. La sua presunta efficacia all’interno di un ambito ristretto è illusoria e non giustifica in alcun modo le sue implicazioni problematiche. Non possiamo e non dobbiamo separare l’efficacia teorica dalle conseguenze pratiche ed etiche. Il frequentismo fallisce non solo sul piano morale, ma anche su quello scientifico, rendendo la sua difesa insostenibile su tutti i fronti.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#stime-stimatori-e-parametri",
    "title": "112  Introduzione all’inferenza frequentista",
    "section": "112.2 Stime, stimatori e parametri",
    "text": "112.2 Stime, stimatori e parametri\nSpostiamo ora il discorso da un piano culturale ad un piano strettamente statistico. Consideriamo il concetto di stima statistica.\nQuando si analizzano i dati, solitamente si è interessati a una quantità a livello di popolazione; tuttavia, di solito si ha accesso solo a un campione di osservazioni. La quantità sconosciuta di nostro interesse viene chiamata parametro. La statistica che calcoliamo utilizzando i dati del campione viene chiamata stima, e la formula che la produce viene chiamata stimatore. Formalmente, uno stimatore è una funzione dei dati osservati utilizzata per produrre una stima di un parametro.\nIn altre parole, quando analizziamo un campione di dati, vogliamo inferire alcune proprietà della popolazione di cui il campione è rappresentativo. Il parametro rappresenta la misura di tali proprietà, ma spesso non è possibile calcolarlo direttamente sulla popolazione. Pertanto, lo stimiamo utilizzando le osservazioni del campione. La stima è quindi l’approssimazione del valore del parametro che otteniamo dal nostro campione, mentre lo stimatore è la formula matematica utilizzata per calcolare questa stima.\nTuttavia, le stime non sono necessariamente identiche ai parametri di nostro interesse. Le stime presentano una certa incertezza dovuta alla variabilità del campionamento. In questo capitolo esamineremo come l’approccio frequentista quantifica l’incertezza nelle nostre stime, in modo da poter trarre conclusioni sul parametro.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzione-campionaria",
    "title": "112  Introduzione all’inferenza frequentista",
    "section": "112.3 Distribuzione campionaria",
    "text": "112.3 Distribuzione campionaria\nIn questo capitolo, affronteremo il problema dell’utilizzo della media di un campione casuale per stimare il parametro \\(\\mu\\) corrispondente alla media della popolazione da cui è stato estratto il campione. Per caratterizzare l’incertezza della stima di un parametro, l’approccio frequentista utilizza lo strumento statistico della distribuzione campionaria.\nPer comprendere il concetto di distribuzione campionaria, considereremo il caso di una popolazione finita di dimensioni ridotte. Tuttavia, le stesse proprietà che esamineremo si applicano alle popolazioni di qualsiasi dimensione.\nIn questa simulazione, ipotizziamo la seguente popolazione:\n\nx = np.array([2, 4.5, 5, 5.5])\nprint(x)\n\n[2.  4.5 5.  5.5]\n\n\nL’istogramma sottostante descrive la distribuzione di frequenza della popolazione.\n\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(\n    x,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nCalcoliamo la media e la varianza della popolazione.\n\n(np.mean(x), np.var(x, ddof=0))\n\n(4.25, 1.8125)\n\n\nPrendiamo ora in considerazione l’estrazione di tutti i campioni possibili di dimensione \\(n\\) = 2 dalla popolazione.\n\n# Create an array with all the pairs of possible values\nsamples = np.array(list(itertools.product(x, repeat=2)))\nprint(samples)\n\n[[2.  2. ]\n [2.  4.5]\n [2.  5. ]\n [2.  5.5]\n [4.5 2. ]\n [4.5 4.5]\n [4.5 5. ]\n [4.5 5.5]\n [5.  2. ]\n [5.  4.5]\n [5.  5. ]\n [5.  5.5]\n [5.5 2. ]\n [5.5 4.5]\n [5.5 5. ]\n [5.5 5.5]]\n\n\nPer ottenere un array con tutte le possibili coppie di valori estratti dall’array x, possiamo utilizzare la funzione product del modulo itertools. Impostiamo l’argomento repeat a 2 per indicare che vogliamo coppie di valori. Successivamente, convertiamo la lista di tuple risultante in un array NumPy utilizzando la funzione np.array, e infine stampiamo il risultato. L’output ottenuto sarà un array con 16 righe e 2 colonne, che rappresenta tutte le possibili coppie di valori che possono essere estratti dall’array x.\nCalcoliamo il numero totale di campioni di ampiezza \\(n\\) = 2.\n\nlen(list(itertools.product(x, x)))\n\n16\n\n\nOra procediamo al calcolo della media per ciascun campione. Questo insieme di valori rappresenta la distribuzione campionaria delle medie dei campioni con dimensione \\(n=2\\) che possono essere estratti dalla popolazione x.\n\n# Create an array with the mean of each sample\nmeans = np.mean(samples, axis=1)\nprint(means)\n\n[2.   3.25 3.5  3.75 3.25 4.5  4.75 5.   3.5  4.75 5.   5.25 3.75 5.\n 5.25 5.5 ]\n\n\nPer calcolare la media di ogni campione di ampiezza \\(n=2\\), utilizziamo la funzione mean del modulo NumPy e la applichiamo lungo l’asse delle colonne dell’array di coppie di valori. In questo modo otteniamo un array unidimensionale contenente la media di ciascuna coppia di valori.\nUna rappresentazione grafica della distribuzione campionaria dei campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x è fornita qui sotto.\n\nplt.hist(\n    means,\n    bins=5,\n    density=True,\n    color=color_fill,\n    edgecolor=color_edge,\n)\nplt.show()\n\n\n\n\n\n\n\n\nMostriamo qui nuovamente la lista di tutti i possibili campioni di ampiezza 2 insieme alla media di ciascun campione.\n\ndf = pd.DataFrame()\ndf[\"Samples\"] = list(itertools.product(x, x))\ndf[\"x_bar\"] = np.mean(list(itertools.product(x, x)), axis=1)\ndf\n\n\n\n\n\n\n\n\nSamples\nx_bar\n\n\n\n\n0\n(2.0, 2.0)\n2.00\n\n\n1\n(2.0, 4.5)\n3.25\n\n\n2\n(2.0, 5.0)\n3.50\n\n\n3\n(2.0, 5.5)\n3.75\n\n\n4\n(4.5, 2.0)\n3.25\n\n\n5\n(4.5, 4.5)\n4.50\n\n\n6\n(4.5, 5.0)\n4.75\n\n\n7\n(4.5, 5.5)\n5.00\n\n\n8\n(5.0, 2.0)\n3.50\n\n\n9\n(5.0, 4.5)\n4.75\n\n\n10\n(5.0, 5.0)\n5.00\n\n\n11\n(5.0, 5.5)\n5.25\n\n\n12\n(5.5, 2.0)\n3.75\n\n\n13\n(5.5, 4.5)\n5.00\n\n\n14\n(5.5, 5.0)\n5.25\n\n\n15\n(5.5, 5.5)\n5.50\n\n\n\n\n\n\n\nProcediamo ora al calcolo della media della distribuzione campionaria delle medie di campioni di ampiezza \\(n\\) = 2 che possono essere estratti dalla popolazione x. Sappiamo che, se la variabile aleatoria \\(X\\) è distribuita con media \\(\\mu\\) e varianza \\(\\sigma^2\\), allora la media della distribuzione dei campioni casuali indipendenti di ampiezza \\(n\\) = 2 sarà:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} n \\mu = \\mu.\n\\]\nVerifichiamo che ciò sia vero nel nostro caso specifico.\n\n(np.mean(x), np.mean(means))\n\n(4.25, 4.25)\n\n\nVerifichiamo che la varianza della distribuzione dei campioni casuali indipendenti di ampiezza \\(n=2\\) che possono essere estratti dalla popolazione \\(X\\) con varianza \\(\\sigma^2\\) sia \\(\\mathbb{V}(\\bar{X})=\\sigma^2/n\\).\nConsiderando la definizione di varianza, possiamo scrivere:\n\\[\n\\begin{aligned}\n\\mathbb{V}(\\bar{X}) &= \\mathbb{E}[(\\bar{X}-\\mu_{\\bar{X}})^2] \\\\\n&= \\mathbb{E}[(\\bar{X} - \\mu)^2] \\\\\n&= \\mathbb{E}[(X_1+X_2)/2 - \\mu)^2] \\\\\n&= \\mathbb{E}[((X_1 - \\mu) + (X_2 - \\mu))/2)^2] \\\\\n&= \\mathbb{E}[(X_1 - \\mu)^2/4 + (X_2 - \\mu)^2/4 + (X_1 - \\mu)(X_2 - \\mu)/2)] \\\\\n&= \\frac{1}{4}\\mathbb{E}[(X_1 - \\mu)^2] + \\frac{1}{4}\\mathbb{E}[(X_2 - \\mu)^2] + \\frac{1}{2}\\mathbb{E}[(X_1 - \\mu)(X_2 - \\mu)] \\\\\n&= \\frac{1}{4}\\mathbb{V}(X_1) + \\frac{1}{4}\\mathbb{V}(X_2) + \\frac{1}{2}\\mathbb{C}(X_1,X_2) \\\\\n&= \\frac{\\sigma^2}{4} + \\frac{\\sigma^2}{4} + 0 \\\\\n&= \\frac{\\sigma^2}{2}\n\\end{aligned}\n\\]\nDove \\(\\mu_{\\bar{X}}\\) è la media della distribuzione campionaria delle medie di campioni di ampiezza \\(n=2\\) e \\(\\mathbb{C}(X_1,X_2)\\) è la covarianza tra \\(X_1\\) e \\(X_2\\). In questo caso, dato che i campioni sono estratti in modo casuale e indipendente, la covarianza tra \\(X_1\\) e \\(X_2\\) è 0. Pertanto, abbiamo dimostrato che \\(\\mathbb{V}(\\bar{X})=\\sigma^2/n\\) per \\(n=2\\).\nIl valore teorico della varianza delle medie dei campioni è dunque pari a\n\nnp.var(x, ddof=0) / 2\n\n0.90625\n\n\nLo stesso risultato si ottiene facendo la media delle 16 medie che abbiamo trovato in precedenza.\n\nnp.var(means, ddof=0) \n\n0.90625\n\n\nConsideriamo ora un particolare campione. Per esempio\n\nobserved_sample = np.array([5, 5.5])\nprint(observed_sample)\n\n[5.  5.5]\n\n\nTroviamo la media del campione:\n\nsample_mean = np.mean(observed_sample)\nprint(sample_mean)\n\n5.25\n\n\nLa media del campione è diversa dalla media della popolazione (\\(\\mu\\) = 4.25).\nTroviamo la deviazione standard del campione:\n\nsample_sd = np.std(observed_sample, ddof=1)\nprint(sample_sd)\n\n0.3535533905932738\n\n\nLa deviazione standard del campione è diversa dalla deviazione standard della popolazione:\n\nnp.std(x, ddof=0)\n\n1.346291201783626\n\n\nIn conclusione, si presti attenzione a due aspetti importanti:\n\nla media della distribuzione delle medie campionarie è uguale alla media della popolazione,\nla varianza della distribuzione delle medie campionarie è minore della varianza della popolazione, ovvero è pari alla varianza della popolazione divisa per l’ampiezza campionaria.\n\nQuesti due risultati che abbiamo ottenuto empiricamente nella simulazione possono essere espressi in maniera formale dicendo che la media di campioni casuali estratti con ripetizione da una popolazione finita (oppure da una popolazione infinita) di media \\(\\mu\\) e varianza \\(\\sigma^2\\) ha valore atteso $ ({X}_n) = $ e varianza $ ({X}_n) = . $\nInoltre, se la popolazione segue una distribuzione normale, allora per le proprietà della distribuzione normale, anche la distribuzione delle medie dei campioni seguirà una distribuzione normale. Al contrario, se la popolazione non segue una distribuzione normale, il teorema del limite centrale garantisce che, all’aumentare delle dimensioni del campione, la distribuzione delle medie dei campioni tenderà a una distribuzione normale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#teorema-del-limite-centrale",
    "title": "112  Introduzione all’inferenza frequentista",
    "section": "112.4 Teorema del Limite Centrale",
    "text": "112.4 Teorema del Limite Centrale\nEsaminiamo ora più in dettaglio il Teorema del Limite Centrale (TLC). Nel 1812, Laplace dimostrò il TLC, che afferma che la somma di una sequenza di variabili casuali indipendenti tende a distribuirsi secondo una distribuzione Normale. Inoltre, il TLC stabilisce i parametri della distribuzione Normale risultante in base ai valori attesi e alle varianze delle variabili casuali sommate.\n\nTeorema 112.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. (variabili aleatorie identicamente distribuite e indipendenti) con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(SD(Y_i) = \\sigma\\). Si definisca una nuova variabile casuale come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tenderà a seguire una distribuzione Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard ridotta di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{\\sigma}{\\sqrt{n}} \\right).\n\\]\n\nIl TLC può essere generalizzato a variabili casuali che non sono identicamente distribuite, a condizione che siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l’altezza degli adulti, sono il risultato di una combinazione di effetti additivi relativamente piccoli. Questi effetti, indipendentemente dalla loro distribuzione individuale, tendono a portare alla normalità della distribuzione risultante. Questa è la ragione per cui la distribuzione normale fornisce una buona approssimazione per la distribuzione di molti fenomeni naturali.\nPer illustrare il TLC, utilizziamo una simulazione. Consideriamo una popolazione iniziale fortemente asimmetrica, come una distribuzione Beta(2, 1). Estraiamo da questa popolazione 50,000 campioni di ampiezza \\(n\\) e costruiamo la distribuzione campionaria di tali campioni.\n\n# parameters of the beta\na=2\nb=1\n\ndef plotSamples(n):\n    # create normal distribution with mean and standard deviation of the beta\n    mu = a / (a+b)\n    sigma = math.sqrt( a*b / (a+b)**2 / (a+b+1) )\n    x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n    y = stats.norm.pdf(x, mu, sigma/math.sqrt(n))\n\n    # find sample means from samples of \"ramped\" beta distribution\n    values = []\n    for i in range(n):\n        v = []\n        for j in range(50000):\n          v.append(np.random.beta(a,b))\n        values.append(v)\n    df = pd.DataFrame(values)\n    sample_means = df.mean(axis=0)\n\n    # plot a histogram of the distribution of sample means, together \n    # with the population distribution\n    fig, ax = plt.subplots(sharex=True)\n    sns.histplot(sample_means)\n    ax2 = ax.twinx()\n    sns.lineplot(x=x,y=y, ax=ax2, color='black')\n    ax.set(yticklabels=[])\n    ax2.set(yticklabels=[])\n    ax.set(ylabel=None)\n    ax2.set(ylabel=None)\n    ax.tick_params(left=False)\n    ax2.tick_params(right=False)\n    ax.set_title(\"Ampiezza campionaria = \" + str(n))\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n    ax2.spines['right'].set_visible(False)\n\nSe l’ampiezza campionaria è 1, allora la ditribuzione campionaria delle medie coincide con la popolazione.\n\nplotSamples(1)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 2, la distribuzione delle medie dei campioni non è certamente Normale, inizia ad avvicinarsi alla gaussianità.\n\nplotSamples(2)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 4 c’è ancora una grande differenza tra la distribuzione campionaria delle medie dei campioni e la distribuzione normale, ma l’approssimazione migliora.\n\nplotSamples(4)\n\n\n\n\n\n\n\n\nCon \\(n\\) = 30 la funzione \\(\\mathcal{N}(100, 15/\\sqrt{50})\\) fornisce una buona approssimazione alla distribuzione campionaria delle medie dei campioni.\n\nplotSamples(30)\n\n\n\n\n\n\n\n\nIn conclusione, il teorema del limite centrale (TLC) mostra che, salvo per campioni molto piccoli, la distribuzione campionaria della media dei campioni può essere ben approssimata dalla Normale, indipendentemente dalla forma della distribuzione della popolazione. Ciò significa che, per campioni sufficientemente grandi, il TLC ci fornisce una formula esplicita per la forma della distribuzione campionaria della media dei campioni, anche in assenza di conoscenze sulla popolazione di media \\(\\mu\\) e deviazione standard \\(\\sigma\\): \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\).\nIl risultato del TLC ha una grande utilità in molti ambiti. Infatti, ci aiuta a comprendere perché i risultati degli esperimenti con un grande numero di osservazioni sono più affidabili rispetto a quelli con un numero ridotto di osservazioni. Inoltre, il TLC ci fornisce una formula esplicita per l’errore standard (\\(\\sigma/\\sqrt{n}\\)), che ci consente di valutare l’affidabilità degli esperimenti al variare della dimensione del campione.\nNegli esperimenti psicologici, molti dei fenomeni che vogliamo misurare sono in realtà medie di molteplici variabili (ad esempio, l’intelligenza “generale” misurata dal QI è una media di un gran numero di abilità specifiche), e in questi casi la quantità media segue una distribuzione normale. Questa legge matematica ci permette di osservare spesso la distribuzione normale nei dati degli esperimenti psicologici e in molte altre discipline scientifiche.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#distribuzioni-campionarie-di-altre-statistiche",
    "title": "112  Introduzione all’inferenza frequentista",
    "section": "112.5 Distribuzioni campionarie di altre statistiche",
    "text": "112.5 Distribuzioni campionarie di altre statistiche\nIn precedenza abbiamo descritto la distribuzione campionaria della media dei campioni. Ma ovviamente è possibile costruire la distribuzione campionaria di altre statistiche campionarie. Ad esempio, la figura seguente mostra l’approssimazione empirica della distribuzione campionaria del valore massimo del campione. È chiaro che, se da ciascun campione estraiamo il valore massimo, il valore atteso della distribuzione campionaria di questa statistica sarà maggiore della media della popolazione.\n\n# define a normal distribution with a mean of 100 and a standard deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 100)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find the maximum score for each experiment\nsample_maxes = []\nfor i in range(1, 10000):\n    sample_max = max(np.random.normal(loc=100, scale=15, size=5).astype(int))\n    sample_maxes.append(sample_max)\n\n# plot a histogram of the distribution of sample maximums, together with the population distribution\nfig, ax = plt.subplots()\nsns.histplot(sample_maxes, ax=ax)\nax2 = ax.twinx()\n_ = sns.lineplot(x=x, y=y, ax=ax2, color=\"black\")\n\n\n\n\n\n\n\n\nLa distribuzione campionaria della varianza dei campioni è particolarmente interessante. Per calcolare la varianza, iniziamo usando la formula della statistica descrittiva, ovvero\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nCreiamo ora un grafico che rappresenta l’approssimazione empirica della distribuzione campionaria della varianza dei punteggi del quoziente di intelligenza, usando la procedura descritta in precedenza.\nSappiamo che la varianza della popolazione è uguale a \\(15^2 = 225\\). Tuttavia, calcolando la varianza con la formula della statistica descrittiva otteniamo, in media, un valore minore. Dunque, l’utilizzo della formula precedente conduce a una stima troppo piccola della varianza della popolazione. Gli statistici chiamano questa discrepanza distorsione, ovvero quando il valore atteso di uno stimatore non coincide con il parametro.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5))\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n176.76365773544788\n\n\n\n\n\n\n\n\n\nQuesta dimostrazione ci fa dunque capire come\n\\[\nS^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n}.\n\\]\nnon sia uno stimatore adeguato per la varianza della popolazione.\nAbbiamo già visto però che questo problema trova una semplice soluzione nel momento in cui usiamo usiamo il seguente stimatore per la varianza della popolazione:\n\\[\ns^2 = \\frac{\\sum_{i=1}^n (Y_i - \\bar{Y})^2}{n-1}.\n\\]\nVerifichiamo.\n\n# define a normal distribution with a mean of 100 and a standard \n# deviation of 15\nmu = 100\nsigma = 15\nx = np.linspace(0, 30)\ny = stats.norm.pdf(x, mu, sigma)\n\n# run 10000 simulated experiments with 5 subjects each, and find \n# the variance score for each experiment\nsample_vars = []\nfor i in range(1,10000):\n    sample_var = np.var(np.random.normal(loc=100,scale=15,size=5), ddof=1)\n    sample_vars.append(sample_var)\n\n# plot a histogram of the distribution of sample variance\nfig, ax = plt.subplots()\nsns.histplot(sample_vars, ax=ax)\n\nnp.mean(sample_vars)\n\n224.19924816630638\n\n\n\n\n\n\n\n\n\nLa discrepanza tra la stima di un parametro e il suo vero valore è definita come errore di stima. Uno stimatore è considerato non distorto (unbiased) se, in media, le sue stime su diversi campioni ipotetici coincidono con il valore del parametro che si intende stimare, ossia se l’errore medio di stima è nullo.\nNel corso di questo capitolo, abbiamo osservato che \\(\\frac{\\sum_{i=1}^n{X_i}}{n}\\) costituisce uno stimatore non distorto di \\(\\mu\\), mentre \\(\\frac{\\sum_{i=1}^n{(X_i - \\bar{X})^2}}{n-1}\\) è uno stimatore non distorto di \\(\\sigma^2\\). Questo implica che lo stimatore \\(\\frac{\\sum_{i=1}^n{(X_i - \\bar{X})^2}}{n-1}\\) presenta una distribuzione campionaria centrata sul vero valore del parametro \\(\\sigma^2\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#considerazioni-conclusive",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#considerazioni-conclusive",
    "title": "112  Introduzione all’inferenza frequentista",
    "section": "112.6 Considerazioni conclusive",
    "text": "112.6 Considerazioni conclusive\nIn generale, i parametri della popolazione sono sconosciuti, ma possiamo stimarli utilizzando le informazioni del campione. Di seguito viene presentata una tabella che riassume i simboli comuni utilizzati per indicare le quantità note e sconosciute nel contesto dell’inferenza statistica. Questo ci aiuterà a tenere traccia di ciò che sappiamo e ciò che non sappiamo.\n\n\n\n\n\n\n\n\nSimbolo\nNome\nÈ qualcosa che conosciamo?\n\n\n\n\n\\(s\\)\nDeviazione standard del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma\\)\nDeviazione standard della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}\\)\nStima della deviazione standard della popolazione\nSì, ma non è uguale a \\(\\sigma\\)\n\n\n\\(s^2\\)\nVarianza del campione\nSì, la calcoliamo dai dati grezzi\n\n\n\\(\\sigma^2\\)\nVarianza della popolazione\nNo, tranne in casi particolari o nelle simulazioni\n\n\n\\(\\hat{\\sigma}^2\\)\nStima della varianza della popolazione\nSì, ma non è uguale a \\(\\sigma^2\\)\n\n\n\nUtilizzando le informazioni di un campione casuale di ampiezza \\(n\\):\n\nLa stima migliore che possiamo ottenere per la media \\(\\mu\\) della popolazione è la media del campione \\(\\bar{Y}\\).\nLa stima migliore che possiamo ottenere per la varianza \\(\\sigma^2\\) della popolazione è:\n\n\\[\n\\hat{\\sigma}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2.\n\\]",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/01_intro_frequentist.html#informazioni-sullambiente-di-sviluppo",
    "title": "112  Introduzione all’inferenza frequentista",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv \n\nLast updated: Thu Jun 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.25.0\n\nseaborn   : 0.13.2\narviz     : 0.18.0\nnumpy     : 1.26.4\nmatplotlib: 3.8.4\npandas    : 2.2.2\nscipy     : 1.13.1\n\n\n\n\n\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>Introduzione all'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html",
    "href": "chapters/frequentist_inference/02_conf_interv.html",
    "title": "113  Intervallo di confidenza",
    "section": "",
    "text": "Introduzione\nGli intervalli di confidenza sono un pilastro nell’approccio frequentista all’inferenza statistica, fornendo un mezzo per gestire l’incertezza associata ai risultati delle analisi statistiche. Questo capitolo si propone di esplorare in profondità gli intervalli di confidenza, analizzandone il calcolo e la loro interpretazione dal punto di vista frequentista. Sarà messa in luce la sfida nell’interpretare correttamente tali intervalli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-lintervallo-di-confidenza",
    "href": "chapters/frequentist_inference/02_conf_interv.html#inferenza-statistica-frequentista-lintervallo-di-confidenza",
    "title": "113  Intervallo di confidenza",
    "section": "113.1 Inferenza Statistica Frequentista: L’Intervallo di Confidenza",
    "text": "113.1 Inferenza Statistica Frequentista: L’Intervallo di Confidenza\nL’intervallo di confidenza è un concetto fondamentale nell’approccio frequentista alla statistica. Questo strumento è impiegato per valutare la variabilità della stima di un parametro di interesse all’interno di una popolazione, partendo da un campione di essa.\nAl centro di questo metodo si trova l’errore standard, che misura la deviazione standard della distribuzione campionaria di uno stimatore. Questo indice quantifica quanto la stima del parametro si discosta, in media, dal valore effettivo del parametro nella popolazione. Gli statistici frequentisti sfruttano l’errore standard per definire l’intervallo di confidenza, che rappresenta un intervallo di valori entro cui si ritiene si trovi il vero valore del parametro, come ad esempio la media della popolazione.\nPer comprendere l’intervallo di confidenza da una prospettiva frequentista è essenziale il concetto di “procedura di stima”. In base a questo approccio, l’intervallo di confidenza viene costruito in modo che, se la medesima procedura fosse ripetuta su diversi campioni della stessa popolazione, una determinata percentuale degli intervalli di confidenza (ad esempio, il 95%) includerebbe il vero valore del parametro della popolazione.\nIn terminologia frequentista, quindi, non si afferma che un dato intervallo di confidenza possieda una probabilità del 95% di contenere il vero valore del parametro. Piuttosto, si sostiene che, seguendo lo stesso metodo di stima, il 95% degli intervalli di confidenza derivati da campioni differenti racchiuderebbe il vero valore del parametro.\nIn questo quadro, l’intervallo di confidenza non è una dichiarazione sulla probabilità che un particolare intervallo includa il valore del parametro, ma piuttosto un’affermazione sulla regolarità con cui gli intervalli calcolati in un determinato modo riescono a catturare il valore del parametro quando si ripete il medesimo processo su vari campioni. Questa distinzione è cruciale per una corretta comprensione dell’approccio frequentista all’inferenza statistica.\nMentre quest’interpretazione dell’intervallo di confidenza può apparire controintuitiva e talvolta poco pratica, riflette il contrasto con l’approccio bayesiano, il quale enfatizza l’aggiornamento delle probabilità sulla base di nuove informazioni, a differenza dell’approccio frequentista, che si basa sulla ripetizione degli esperimenti e sulla valutazione della variabilità campionaria.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#determinazione-dellintervallo-di-confidenza-per-una-media",
    "href": "chapters/frequentist_inference/02_conf_interv.html#determinazione-dellintervallo-di-confidenza-per-una-media",
    "title": "113  Intervallo di confidenza",
    "section": "113.2 Determinazione dell’intervallo di Confidenza per una Media",
    "text": "113.2 Determinazione dell’intervallo di Confidenza per una Media\nNei casi in cui la distribuzione delle statistiche campionarie si avvicina a una distribuzione Normale, l’intervallo di confidenza al 95% è calcolato come:\n\\[\n\\hat{\\theta} \\pm 1.96 \\cdot \\text{SE},\n\\]\ndove \\(\\hat{\\theta}\\) rappresenta la stima del parametro e SE l’errore standard.\n\n113.2.1 Derivazione dell’Intervallo di Confidenza per una Popolazione Normale con Varianza Nota\nConsideriamo una popolazione che segue una distribuzione normale con una media nota \\(\\mu\\) e varianza \\(\\sigma^2\\). Prendiamo un campione casuale di dimensione \\(n\\) da questa popolazione, indicato come \\(X_1, X_2, \\dots, X_n\\). Grazie alle proprietà delle distribuzioni normali, la media campionaria \\(\\bar{X}\\) segue anch’essa una distribuzione normale, nello specifico \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)\\).\n\n113.2.1.1 Passo 1: Standardizzazione della Media Campionaria\n\nPer standardizzare la media campionaria in una variabile distribuita normalmente standard, sottraiamo la media della popolazione \\(\\mu\\) e dividiamo per lo scarto standard della media campionaria \\(\\sigma/\\sqrt{n}\\). Ciò porta alla seguente trasformazione:\n\\[\nZ = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim \\mathcal{N}(0, 1).\n\\]\n\n\n\n113.2.1.2 Passo 2: Stabilire il Livello di Confidenza\n\nDefiniamo un livello di confidenza \\(\\gamma = 1 - \\alpha\\), ad esempio \\(\\gamma = 0.95\\) per un livello di confidenza del 95%.\nIdentifichiamo il valore critico \\(z\\), corrispondente al quantile \\((1 - \\alpha/2)\\) della distribuzione normale standard. Il valore \\(z\\) rappresenta il punto di taglio alle estremità della distribuzione:\n\\[\nP(-z \\leq Z \\leq z) = \\gamma.\n\\]\n\n\n\n113.2.1.3 Passo 3: Formulazione dell’Intervallo di Confidenza\n\nCon il valore \\(z\\) definito, formuliamo l’intervallo di confidenza per la media della popolazione:\n\\[\nP\\left(-z \\leq \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\leq z\\right) = \\gamma.\n\\]\n\n\n\n113.2.1.4 Passo 4: Manipolazione Algebrica per Definire i Limiti\n\nRielaboriamo la disuguaglianza per esporre i limiti dell’intervallo di confidenza:\n\\[\n\\begin{align}\nP\\bigg(-z \\leq &\\frac{ \\bar{X} - \\mu } {\\sigma} \\sqrt{n} \\leq z\\bigg) = \\gamma\\notag\\\\\nP\\bigg(-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq  &\\bar{X} - \\mu \\leq z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\nP\\bigg(-\\bar{X}-z {\\frac{\\sigma}{\\sqrt{n}}} \\leq &-\\mu \\leq -\\bar{X} + z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma\\notag\\\\\nP\\bigg(\\bar{X}+z \\frac{\\sigma}{\\sqrt{n}} \\geq &\\mu \\geq  \\bar{X} -z \\frac{\\sigma}{\\sqrt{n}}\\bigg) = \\gamma.\\notag\n\\end{align}\n\\]\n\n\n\n113.2.1.5 Passo 5: Specificazione dei Limiti dell’Intervallo\n\nDefiniamo i limiti dell’intervallo di confidenza, \\(\\hat{a}\\) e \\(\\hat{b}\\), come segue:\n\\[\n\\hat{a} = \\bar{X} - z \\frac{\\sigma}{\\sqrt{n}},\n\\quad \\hat{b} = \\bar{X} + z \\frac{\\sigma}{\\sqrt{n}},\n\\]\ncon \\(P(\\hat{a} \\leq \\mu \\leq \\hat{b}) = \\gamma\\).\n\n\n\n113.2.1.6 Conclusione:\n\nL’intervallo di confidenza \\((\\hat{a}, \\hat{b})\\) racchiude il vero valore della media della popolazione \\(\\mu\\) con una probabilità \\(\\gamma\\).\n\n\n\n\n113.2.2 Stima dell’Intervallo di Confidenza per Popolazioni Normali con Varianza Incognita\nIn contesti reali, quando si preleva un campione \\(X_1, \\dots, X_n\\) da una popolazione, la varianza \\(\\sigma^2\\) della popolazione è spesso incognita. Questo aggiunge incertezza riguardo alla media della popolazione \\(\\mu\\), che è il parametro di interesse. In questi casi, si adotta la distribuzione t di Student per la stima dell’intervallo di confidenza della media \\(\\mu\\), a causa della varianza incognita.\n\n113.2.2.1 Passo 1: Impiego della Distribuzione t di Student\n\nApplichiamo la formula seguente per calcolare l’intervallo:\n\\[\nP\\left(−t^{\\ast} \\leq \\frac{\\bar{X} - \\mu}{s/\\sqrt{n}} \\leq t^{\\ast}\\right) = \\gamma,\n\\]\ndove \\(\\gamma = 1 - \\alpha\\) è il livello di confidenza, \\(s\\) è la stima della deviazione standard \\(\\sigma\\) della popolazione, e \\(t^{\\ast}\\) è il quantile di ordine \\(1 - \\alpha/2\\) della distribuzione t con \\(n−1\\) gradi di libertà.\n\n\n\n113.2.2.2 Passo 2: Determinazione dei Limiti dell’Intervallo di Confidenza\n\nCalcoliamo i limiti inferiore \\(\\hat{a}\\) e superiore \\(\\hat{b}\\) dell’intervallo di confidenza così:\n\\[\n\\hat{a} = \\bar{X} - t^{\\ast} \\frac{s}{\\sqrt{n}},\n\\quad \\hat{b} = \\bar{X} + t^{\\ast} \\frac{s}{\\sqrt{n}}.\n\\]\n\nIn queste circostanze, si sostituisce la varianza sconosciuta \\(\\sigma^2\\) con la sua stima \\(s\\) e si utilizza la distribuzione t di Student invece della normale.\nApplicabilità e Limitazioni:\n\nIl metodo presuppone che la popolazione segua una distribuzione normale e è valido anche per campioni di piccole dimensioni (ad esempio, \\(n &lt; 30\\)) prelevati da tale popolazione.\nSe la popolazione non è normalmente distribuita e la dimensione del campione è ridotta, questo metodo potrebbe non essere idoneo.\nTuttavia, per campioni di grandi dimensioni (\\(n \\geq 30\\)), questo approccio rimane valido per la stima dell’intervallo di confidenza grazie al teorema del limite centrale, che si applica anche a popolazioni con distribuzioni non normali.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "href": "chapters/frequentist_inference/02_conf_interv.html#livello-di-copertura",
    "title": "113  Intervallo di confidenza",
    "section": "113.3 Livello di Copertura",
    "text": "113.3 Livello di Copertura\nPer interpretare correttamente gli intervalli di fiducia è fondamentale considerare il concetto di “livello di copertura”. Questo livello indica la frequenza con cui l’intervallo di fiducia include il valore reale del parametro della popolazione, in una serie di esperimenti ripetuti.\nEsempio di Livello di Copertura: - Se il livello di copertura è del 95%, significa che, nel lungo periodo, il 95% degli intervalli di fiducia costruiti conterrà il valore vero del parametro. - Importante: Questo non implica che ci sia una probabilità del 95% che il valore vero del parametro cada in un particolare intervallo di fiducia. Infatti, il parametro della popolazione è un valore fisso e non soggetto a probabilità; piuttosto, l’incertezza risiede nell’intervallo di fiducia stesso.\nCome Funziona la Copertura: - Nel contesto frequentista, la “probabilità” si riferisce alla frequenza a lungo termine di un certo evento in un gran numero di ripetizioni dell’esperimento. - Nel caso degli intervalli di fiducia, l’“esperimento” è l’estrazione di un campione dalla popolazione, e l’“evento” è la generazione di un intervallo di fiducia che contiene il valore vero del parametro. - Il livello di copertura, generalmente indicato come \\(1-\\alpha\\), rappresenta la probabilità a lungo termine che intervalli di fiducia costruiti con questa metodologia includano il vero valore del parametro.\n\n113.3.1 Simulazione\n\nPer illustrare questo concetto, eseguiamo una simulazione con la popolazione degli adulti maschi italiani, assunta come normalmente distribuita con media 175 cm e varianza 49 cm².\nEseguiamo 1000 ripetizioni di un esperimento, estraendo ogni volta un campione di 30 individui.\nPer ciascun campione, calcoliamo l’intervallo di fiducia al 95% usando la formula:\n\\[\n\\bar{X} \\pm t \\frac{s}{\\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(s\\) è la deviazione standard campionaria e \\(t\\) è il valore critico della distribuzione t-Student per \\(n-1\\) gradi di libertà al livello di significatività \\(\\alpha/2 = 0.025\\).\nRegistriamo i limiti di ciascun intervallo e controlliamo quanti di essi includono effettivamente il vero valore medio della popolazione.\n\nAttraverso questa simulazione, possiamo visualizzare concretamente il concetto di livello di copertura e la sua importanza nella statistica frequentista.\nIniziamo generando 1000 campioni casuali di dimensione \\(n=30\\) da una distribuzione normale con media \\(175\\) e deviazione standard \\(7\\).\n\nmu = 175\nsigma = 7\nn = 30\nn_samples = 1000\n\nsamples = np.stack([np.random.normal(loc=mu, scale=sigma, size=n) for i in range(n_samples)])\nsamples.shape\n\n(1000, 30)\n\n\nIl primo campione di ampiezza \\(n\\) = 30 che abbiamo ottenuto è il seguente.\n\nprint(samples[1, :])\n\n[164.73077142 178.36458698 178.37872685 174.13939428 171.93750167\n 183.62660835 166.47855379 166.14290722 190.11028319 178.59315899\n 171.1696638  173.70591366 170.78474733 175.70917764 168.69153018\n 177.18965061 184.68306022 180.57048893 182.54977759 179.74984648\n 167.07981468 185.24317632 176.86968895 177.70411011 171.09097822\n 166.88189761 176.52572538 175.31383448 173.88320882 169.05527411]\n\n\nStampiamo qui di seguito le medie dei primi dieci campioni.\n\nxbar = samples.mean(axis=1)\nprint(xbar[0:10])\n\n[176.37407572 175.23180193 174.58152045 176.40365999 176.74312635\n 174.17121749 174.48572499 174.18025492 175.07399899 176.36952714]\n\n\nTroviamo il valore critico della distribuzione \\(t\\) di Student con (30-1) gradi di libertà.\n\nalpha = 0.05\nt = st.t.ppf(1 - alpha/2, n-1)\nt\n\n2.0452296421327034\n\n\nUtilizzando le informazioni precedenti, calcoliamo 1000 intervalli di confidenza per la media della popolazione.\n\ninterval_width = t * samples.std(axis=1, ddof=1) / np.sqrt(n)\nCI_low = samples.mean(axis=1) - interval_width\nCI_high = samples.mean(axis=1) + interval_width\n\nTroviamo ora il livello di copertura, ovvero il numero di volte in cui l’intervallo di confidenza calcolato contiene il vero valore del parametro.\n\ncoverage_p = np.sum(np.logical_and(CI_low &lt; mu, mu &lt; CI_high)) / samples.shape[0]\ncoverage_p\n\n0.958\n\n\nIn conclusione, ripetendo la simulazione per 1000 volte, abbiamo ottenuto una proporzione di intervalli di confidenza del 95% che contengono il parametro (ovvero il livello di copertura) molto vicino al valore nominale di \\(1 - \\alpha = 0.95\\).\n\n\n113.3.2 Il Concetto di Livello di Confidenza\nGli intervalli di confidenza sono range di valori che, con una certa sicurezza statistica, si ritiene includano il parametro di interesse.\nSecondo l’approccio frequentista, l’intervallo di confidenza si deve considerare come una metodologia: - Se ripetiamo l’esperimento (estrarre un campione e calcolare l’intervallo di confidenza) molte volte, il metodo produce un intervallo che coprirà il valore vero del parametro nel 95% dei casi, assumendo un livello di confidenza del 95%.\n\n\n113.3.3 Un Malinteso Comune nell’Interpretazione degli Intervalli di Confidenza\nÈ inesatto affermare che un determinato intervallo di confidenza contenga il valore vero di un parametro con una probabilità del 95%. Questo è un errore diffuso, persino tra i ricercatori, che spesso interpretano l’intervallo di confidenza come indicativo della probabilità che il parametro (ad esempio, la media della popolazione \\(\\mu\\)) si trovi effettivamente all’interno di un dato intervallo (es. \\([\\hat{a}, \\hat{b}]\\)).\nLa descrizione corretta è la seguente: - “La metodologia impiegata per calcolare l’intervallo \\([\\hat{a}, \\hat{b}]\\) ha il 95% di probabilità di generare un intervallo che include il vero valore del parametro”. - Ciò significa che l’intervallo di confidenza non esprime una probabilità circa la posizione precisa del parametro, ma riflette la probabilità che la procedura adottata per determinarlo generi un intervallo che lo includa.\nIn conclusione, l’intervallo di confidenza ci fornisce una garanzia statistica riguardo alla affidabilità del metodo usato per la sua stima, piuttosto che sulla esatta ubicazione del parametro in questione.\n\n\n113.3.4 Fraintendimenti Comuni sugli Intervalli di Confidenza\nNel loro lavoro, {cite}hoekstra2014robust evidenziano come, nonostante l’ampio riconoscimento dei limiti dei test di ipotesi nulle, gli intervalli di confidenza siano spesso consigliati per l’inferenza statistica. Anche l’American Psychological Association (APA) suggerisce che gli intervalli di confidenza siano “in generale, la migliore strategia di reportistica”. Tuttavia, {cite}hoekstra2014robust sottolineano che queste raccomandazioni non considerano la difficoltà nel fornire una corretta interpretazione degli intervalli di confidenza.\nPer indagare l’interpretazione degli intervalli di confidenza, Hoekstra et al. hanno condotto uno studio con due domande principali:\n\nQuanto frequentemente intervalli di confidenza sono mal interpretati da studenti e ricercatori?\nL’esperienza nella ricerca riduce le interpretazioni errate degli intervalli di confidenza?\n\nPrima di presentare lo studio, {cite}hoekstra2014robust ricordano qual è l’interpretazione corretta degli intervalli di confidenza.\n\nA CI is a numerical interval constructed around the estimate of a parameter. Such an interval does not, however, directly indicate a property of the parameter; instead, it indicates a property of the procedure, as is typical for a frequentist technique. Specifically, we may find that a particular procedure, when used repeatedly across a series of hypothetical data sets (i.e., the sample space), yields intervals that contain the true parameter value in 95% of the cases. When such a procedure is applied to a particular data set, the resulting interval is said to be a 95% CI. The key point is that the CIs do not provide for a statement about the parameter as it relates to the particular sample at hand; instead, they provide for a statement about the performance of the procedure of drawing such intervals in repeated use. Hence, it is incorrect to interpret a CI as the probability that the true value is within the interval (e.g., Berger & Wolpert, 1988). As is the case with \\(p\\)-values, CIs do not allow one to make probability statements about parameters or hypotheses.\n\nNel loro studio, {cite:t}hoekstra2014robust hanno presentato un questionario a 596 partecipanti, tra cui studenti universitari e ricercatori, con le seguenti affermazioni riguardanti l’interpretazione degli intervalli di confidenza.\n\nProfessor Bumbledorf conducts an experiment, analyzes the data, and reports: “The 95% confidence interval for the mean ranges from 0.1 to 0.4.” Please mark each of the statements below as ‘true’ or ‘false’.\n\n\n\nThe probability that the true mean is greater than 0 is at least 95%.\nThe probability that the true mean equals 0 is smaller than 5%.\nThe “null hypothesis” that the true mean equals 0 is likely to be incorrect.\nThere is a 95% probability that the true mean lies between 0.1 and 0.4.\nWe can be 95% confident that the true mean lies between 0.1 and 0.4.\nIf we were to repeat the experiment over and over, then 95% of the time the true mean falls between 0.1 and 0.4.\n\n\nSorprendentemente, anche se tutte le sei affermazioni nel questionario sono errate, molti partecipanti hanno concordato con esse. I risultati mostrano che, in media, i partecipanti hanno concordato con circa 3.5 affermazioni errate su 6. Non è stata rilevata una differenza di rilievo nell’interpretazione degli intervalli di confidenza tra studenti e ricercatori, suggerendo che l’esperienza nella ricerca non migliora la comprensione di questo concetto.\nI risultati indicano che molte persone interpretano erroneamente gli intervalli di confidenza, e che anche l’esperienza nella ricerca non garantisce una migliore comprensione. Questo solleva dubbi sull’efficacia degli intervalli di confidenza frequentisti e suggerisce che gli “intervalli di credibilità” bayesiani possano rappresentare un’alternativa più vantaggiosa. Quest’ultimi tendono ad essere più intuitivi e di più facile interpretazione corretta.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "href": "chapters/frequentist_inference/02_conf_interv.html#confronto-tra-intervalli-frequentisti-e-bayesiani",
    "title": "113  Intervallo di confidenza",
    "section": "113.4 Confronto tra Intervalli Frequentisti e Bayesiani",
    "text": "113.4 Confronto tra Intervalli Frequentisti e Bayesiani\nConcludiamo questo capitolo esaminando le differenze tra l’intervallo di confidenza frequentista e l’intervallo di credibilità bayesiano, utilizzando lo stesso set di dati per entrambi i calcoli.\nImmaginiamo di avere un gruppo di 20 osservazioni relative alla performance in un test cognitivo. Il nostro obiettivo è stimare la media della popolazione da cui sono state tratte queste osservazioni. Per farlo, simuliamo 20 valori casuali da una popolazione che segue una distribuzione normale con media 50 e deviazione standard 10, rappresentata da \\(\\mathcal{N}(50, 10)\\).\n\nsample_size = 20\nmu = 50\nsigma = 10\nsample_data = np.random.normal(loc=mu, scale=sigma, size=n)\nprint(sample_data)\n\n[40.13038118 67.14138507 58.15372819 61.87080597 70.28823876 58.64307551\n 55.41941724 67.9643939  42.76867878 58.37573589 51.38804991 46.78454195\n 36.63322195 44.69934389 56.11884628 40.82879678 45.90438324 45.45382291\n 40.89898539 49.55213524 64.12932274 50.47661058 53.19291531 52.46171204\n 47.98108743 41.26631945 66.63886733 58.25433261 50.31265781 60.7856227 ]\n\n\n\n_ = plt.hist(sample_data, density=True)\n\n\n\n\n\n\n\n\n\n113.4.1 Intervallo di Confidenza Frequentista\nQuando ci si avvicina al problema di stimare la media della popolazione, \\(\\mu\\), attraverso un approccio frequentista, uno dei metodi più comuni è la stima puntuale. Questo metodo consiste nell’utilizzare un unico valore, solitamente la media del campione, per rappresentare il parametro della popolazione che non conosciamo.\nLa media campionaria, indicata come \\(\\hat{\\mu}\\), è una scelta frequente per la stima puntuale della media della popolazione, \\(\\mu\\). Si calcola sommando tutti i valori osservati nel campione, ovvero \\(X_1, X_2, ..., X_n\\), e dividendo questa somma per il numero totale di osservazioni nel campione, \\(n\\):\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n X_i.\n\\]\nApplicando questa formula ai dati del nostro esempio, otteniamo\n\nsample_mean = np.mean(sample_data)\nsample_mean\n\n52.81724720110726\n\n\nMentre le stime puntuali offrono un valore specifico per rappresentare il parametro della popolazione, non riescono da sole a descrivere completamente l’incertezza associata a questa stima. Per affrontare questa lacuna, l’approccio frequentista si avvale degli intervalli di confidenza. Un intervallo di confidenza fornisce una gamma di valori all’interno dei quali si presume che il vero parametro della popolazione cada, basandosi sui dati osservati. Questo intervallo viene definito aggiungendo e sottraendo un margine di errore alla stima puntuale:\n\\[\\hat{\\mu} \\pm m = [\\hat{\\mu} - m, \\hat{\\mu} + m].\\]\nIl margine di errore, che riflette la variabilità dei dati del campione, dipende sia dal livello di confidenza scelto, indicato come \\(1-\\alpha\\), sia dalla dimensione del campione, \\(n\\). Ad esempio, un intervallo di confidenza del 95% significa che ci si aspetta che l’intervallo includa il vero parametro della popolazione nel 95% delle applicazioni di questa procedura.\nIl margine di errore si calcola normalmente attraverso l’errore standard (SE) della stima puntuale, e viene definito da:\n\\[m = t_{1-\\frac{\\alpha}{2}, n-1} \\times SE,\\]\ndove \\(t_{1-\\frac{\\alpha}{2}, n-1}\\) rappresenta il valore critico dalla distribuzione t per il livello di confidenza desiderato e \\(n-1\\) gradi di libertà.\nL’errore standard della media campionaria si ottiene dividendo la deviazione standard del campione, \\(\\sigma\\), per la radice quadrata della dimensione del campione:\n\\[SE = \\frac{\\sigma}{\\sqrt{n}}.\\]\nApplicando questa formula ai dati del nostro esempio, la deviazione standard del campione risulta\n\nsample_stddev = np.std(sample_data, ddof=1)\nsample_stddev\n\n9.359341680068068\n\n\nL’errore standard della media è\n\nstandard_error = sample_stddev / np.sqrt(sample_size)\nprint(standard_error)\n\n2.092812422127929\n\n\nL’errore standard della media rappresenta una stima della deviazione standard della distribuzione delle medie campionarie per campioni di dimensione \\(n\\) (in questo caso, \\(n\\) = 20).\nSupponiamo di voler avere un livello di confidenza del 95%. Per trovare il valore critico della distribuzione \\(t\\) di Student, dobbiamo trovare il valore della statistica \\(T\\) che lascia il 2.5% dell’area sotto la coda a sinistra e il 2.5% dell’area sotto la coda a destra della distribuzione \\(t\\) di Student con 19 gradi di libertà.\n\ndegrees_of_freedom = sample_size - 1\nt_val = st.t.ppf(0.975, degrees_of_freedom)\nprint(t_val)\n\n2.093024054408263\n\n\nIl margine d’errore è uguale a\n\\[t \\cdot SE\\]\novvero\n\nmargin_of_error = t_val * standard_error\nprint(margin_of_error)\n\n4.380306740878175\n\n\nL’intervallo di confidenza frequentista è uguale a\n\\[\\text{stima del parametro} \\pm \\text{margine d'errore}\\]\novvero\n\\[\\bar{x} \\pm t_{\\text{critico}} \\frac{s}{\\sqrt{n}}.\\]\nPer i dati dell’esempio otteniamo\n\nconfidence_interval_lower = sample_mean - margin_of_error\nconfidence_interval_upper = sample_mean + margin_of_error\nconfidence_interval = [confidence_interval_lower, confidence_interval_upper]\nprint(confidence_interval)\n\n[48.43694046022908, 57.19755394198543]\n\n\nInterpretiamo questo risultato dicendo che la procedura utilizzata per calcolare l’intervallo \\([42.99, 53.23]\\) include \\(\\mu\\) nel 95% dei casi.\nLa figura successiva mostra la distribuzione dei dati, la stima di \\(\\mu\\) (ovvero, la media del campione) e l’intervalli di confidenza al 95%.\n\ndef visualize_output(sample_data, sample_mean, interval, type_interval):\n    plt.hist(sample_data, density=True, alpha=0.5)\n    plt.axvline(x=sample_mean, linestyle='dashed', linewidth=2)\n    plt.axvline(x=interval[0], linewidth=2)\n    plt.axvline(x=interval[1], linewidth=2)\n    plt.legend(['Sample Mean', f'{type_interval} interval'])\n\n\nvisualize_output(sample_data, sample_mean, confidence_interval, 'confidence')\n\n\n\n\n\n\n\n\n\n\n113.4.2 Intervallo di Credibilità Bayesiano\nPer determinare l’intervallo di credibilità bayesiano, impieghiamo un modello statistico basato sulla distribuzione Normale, integrando distribuzioni a priori che forniscono informazioni iniziali limitate sui parametri. Questa strategia ci consente di inserire delle conoscenze preliminari, pur essendo vaghe, nell’analisi statistica.\nDettagli sulle scelte delle distribuzioni a priori: - Per il parametro \\(\\mu\\), impostiamo una distribuzione a priori centrata intorno allo zero, con una deviazione standard piuttosto ampia. Come alternativa, si potrebbe considerare di centrare la distribuzione a priori sulla media campionaria. - Per il parametro \\(\\sigma\\), adottiamo una distribuzione Normale troncata, posizionata anch’essa intorno allo zero, ma con una deviazione standard notevolmente grande.\nLa scelta di centrare le distribuzioni a priori sullo zero è volta a evitare l’introduzione di bias nell’analisi, tendendo verso una stima conservativa, ossia una stima del parametro incline allo zero. La decisione di usare deviazioni standard molto ampie riflette la debolezza delle informazioni preliminari che abbiamo incorporato nel modello.\nCiò detto, abbiamo introdotto alcune conoscenze iniziali nell’analisi: in particolare, l’assunzione che valori eccessivamente elevati, sia positivi che negativi, per la media del campione siano improbabili. Questa considerazione riflette una cautela nell’estimare il parametro, evitando di considerare valori estremi come plausibili.\n\nmodel = pm.Model()\n\nwith model:\n    mu = pm.Normal(\"mu\", mu=0, sigma=200)\n    sigma = pm.HalfNormal(\"sigma\", 100)\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=sample_data)\n\n\nwith model:\n    idata = pm.sample(nuts_sampler=\"numpyro\")\n\n\naz.summary(idata, hdi_prob=0.95, round_to=2)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu\n52.89\n1.84\n49.26\n56.53\n0.04\n0.03\n2432.99\n2087.60\n1.0\n\n\nsigma\n9.77\n1.31\n7.47\n12.45\n0.03\n0.02\n2652.84\n2492.04\n1.0\n\n\n\n\n\n\n\nSi noti che, dati i dati specifici e la formulazione del modello bayesiano in uso, l’intervallo di credibilità ottenuto si mostra molto simile all’intervallo di confidenza calcolato secondo l’approccio frequentista. Tuttavia, l’interpretazione di questi due intervalli differisce in maniera sostanziale.\nNel caso dell’intervallo di credibilità bayesiano, possiamo affermare che, in base al nostro grado di credenza soggettiva del 95%, la media della popolazione si trova all’interno dell’intervallo specificato. Questo è un’affermazione diretta sulla probabilità che la media della popolazione rientri in un determinato intervallo, basata sulle informazioni priori e sui dati osservati.\nIn contrasto, l’intervallo di confidenza frequentista non permette un’interpretazione diretta riguardo alla probabilità della media della popolazione di cadere in un dato intervallo. Invece, l’interpretazione frequentista indica che, se ripetessimo il processo di campionamento molte volte, il 95% degli intervalli di confidenza calcolati conterrebbe la vera media della popolazione.\nQuindi, mentre l’intervallo di credibilità bayesiano fornisce una misura diretta della credenza nella posizione della media della popolazione, l’intervallo di confidenza frequentista fornisce una misura di affidabilità del processo di stima nel lungo termine.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "href": "chapters/frequentist_inference/02_conf_interv.html#riflessioni-conclusive",
    "title": "113  Intervallo di confidenza",
    "section": "113.5 Riflessioni Conclusive",
    "text": "113.5 Riflessioni Conclusive\nCome sottolineato da {cite:t}hoekstra2014robust, è comune riscontrare fraintendimenti riguardo agli intervalli di fiducia. Il “livello di confidenza del 95%” è da interpretarsi come la probabilità a lungo termine che, in una serie di intervalli di fiducia calcolati, il 95% di essi includa il vero valore del parametro sconosciuto. Tuttavia, per un singolo intervallo di fiducia, non è possibile dichiarare con sicurezza che questo contenga effettivamente il parametro di interesse. In altre parole, la certezza sulla presenza del parametro sconosciuto all’interno di un dato intervallo di fiducia non è garantita per ogni singolo caso analizzato.\nÈ inoltre inesatto presumere che esista un legame diretto tra la varianza e la media di un campione, ipotizzando che un intervallo di fiducia più ristretto implichi maggiore precisione. Nella prospettiva frequentista, la “precisione” è strettamente legata al livello di copertura a lungo termine assicurato dal metodo usato per creare gli intervalli di fiducia. Questo concetto non si applica al singolo intervallo di fiducia osservato. Dunque, un intervallo di fiducia che si presenta estremamente ristretto potrebbe in realtà essere significativamente lontano dal valore vero del parametro non noto.\nÈ importante sottolineare che l’approccio frequentista offre un metodo per calcolare gli intervalli di confidenza per una vasta gamma di statistiche. Questo include, ad esempio, la stima dell’intervallo di confidenza per la differenza tra due medie, per una proporzione o per la differenza tra due proporzioni. Ecco le formule per calcolare gli intervalli di confidenza per i casi menzionati:\n\nIntervallo di confidenza per la differenza tra due medie:\nSe abbiamo due campioni indipendenti di dimensione $ n_1 $ e $ n_2 $, con medie $ {x}_1 $ e $ {x}_2 $ e deviazioni standard $ s_1 $ e $ s_2 $, l’intervallo di confidenza per la differenza tra le medie è calcolato come:\n\\[\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n\\]\nDove $ t_{/2} $ è il valore critico della distribuzione t di Student con $ /2 $ di probabilità di coda e gradi di libertà $ df = n_1 + n_2 - 2 $.\nIntervallo di confidenza per una proporzione:\nPer stimare l’intervallo di confidenza per una proporzione $ p $ in un campione binomiale di dimensione $ n $, la formula è:\n\\[\n\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\nDove $ $ è la proporzione campionaria e $ z_{/2} $ è il valore critico della distribuzione normale standard con $ /2 $ di probabilità di coda.\nIntervallo di confidenza per la differenza tra due proporzioni:\nPer stimare l’intervallo di confidenza per la differenza tra due proporzioni $ p_1 $ e $ p_2 $ in due campioni binomiali di dimensioni $ n_1 $ e $ n_2 $, la formula è:\n\\[\n(\\hat{p}_1 - \\hat{p}_2) \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}}\n\\]\nDove $ _1 $ e $ 2 $ sono le proporzioni campionarie e $ z{/2} $ è il valore critico della distribuzione normale standard con $ /2 $ di probabilità di coda.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/02_conf_interv.html#informazioni-sullambiente-di-sviluppo",
    "title": "113  Intervallo di confidenza",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Sun May 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nseaborn   : 0.13.2\nmatplotlib: 3.8.4\narviz     : 0.18.0\nnumpy     : 1.26.4\nscipy     : 1.13.0\npandas    : 2.2.2\npymc      : 5.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>Intervallo di confidenza</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html",
    "title": "114  Significatività statistica",
    "section": "",
    "text": "Introduzione\nIl test di ipotesi è un metodo ampiamente utilizzato nella ricerca per fare inferenze sui parametri della popolazione basandosi sui dati campionari. Nel contesto della psicologia, questo metodo è spesso impiegato per valutare l’efficacia di interventi psicologici, confrontare diverse teorie o approcci, esplorare le influenze di variabili psicologiche su comportamenti e processi cognitivi, e comprendere meglio i meccanismi sottostanti a fenomeni psicologici complessi come l’apprendimento, la memoria e le emozioni.\nIn questo capitolo, ci concentreremo sul test di ipotesi frequentista, una procedura ancora comunemente utilizzata. Tuttavia, è fondamentale sottolineare che la comunità statistica sconsiglia l’uso esclusivo del test di ipotesi frequentista come criterio decisionale per stabilire la validità di un risultato sperimentale.\nTradizionalmente, un risultato è considerato “statisticamente significativo” se è improbabile che sia dovuto al caso, suggerendo che il risultato sia stabile o reale. Al contrario, i risultati “non significativi” vengono spesso etichettati come rumorosi e visti con scetticismo. Questa visione semplificata della significatività statistica può portare a fraintendimenti e conclusioni errate.\nAnalizzeremo come l’approccio frequentista, in pratica, non mantenga sempre la sua “promessa” e come l’uso della procedura della significatività statistica, nella pratica scientifica, possa spesso produrre risultati opposti a quelli desiderati. La significatività statistica dipende fortemente dalle dimensioni del campione e da altri fattori. Un risultato non significativo non implica necessariamente che l’effetto osservato sia nullo o irrilevante. Inoltre, la significatività statistica può essere influenzata dalla scelta dei livelli di confidenza e dai test statistici utilizzati, portando a interpretazioni soggettive dei risultati che possono essere fuorvianti.\nPertanto, anziché concentrarsi esclusivamente sulla significatività statistica, è preferibile valutare l’effetto osservato nel contesto scientifico più ampio e alla luce dei risultati di altre analisi, utilizzando un approccio più completo e critico.\nInfine, in questo capitolo esamineremo il caso specifico della media del campione come stimatore della media della popolazione, esplorando i suoi limiti e le sue applicazioni nella statistica inferenziale di tipo frequentista.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi",
    "title": "114  Significatività statistica",
    "section": "114.1 Il Test di Ipotesi",
    "text": "114.1 Il Test di Ipotesi\nIl test di ipotesi è un metodo statistico utilizzato per valutare se i dati sono coerenti con l’ipotesi nulla (\\(H_0\\)). L’ipotesi nulla solitamente afferma che non vi è alcun effetto o differenza significativa, mentre l’ipotesi alternativa (\\(H_1\\)) rappresenta l’affermazione che si desidera testare. I dati del campione vengono analizzati per determinare se forniscono prove sufficienti per rifiutare l’ipotesi nulla. Un passaggio cruciale consiste nel calcolare il value-p.\n\n114.1.1 La procedura di Test di Ipotesi\nPasso 1: Formulare l’ipotesi nulla (\\(H_0\\)) e l’ipotesi alternativa (\\(H_1\\)) basandosi sulla domanda di ricerca.\nNOTA: Decidiamo un’ipotesi non direzionale (nota anche come ipotesi bilaterale) quando testiamo effetti in entrambe le direzioni (la più comune), altrimenti un’ipotesi direzionale (nota anche come ipotesi unilaterale).\nPasso 2: Stabilire un livello di significatività, α (solitamente 0.05).\nPasso 3: Selezionare il Test Statistico appropriato, verificare eventuali assunzioni e calcolare il test statistico.\nNOTA: Esistono due tipi fondamentali di test statistici, parametrici e non parametrici. I test parametrici (ad esempio, t-test, ANOVA) dipendono da assunzioni sulla distribuzione del parametro studiato. I test non parametrici (ad esempio, test di Mann-Whitney U, test di Kruskal-Wallis) utilizzano un metodo di ordinamento delle misure e non richiedono tali assunzioni. Tuttavia, i test non parametrici sono tipicamente meno potenti dei test parametrici.\nPasso 4: Decidere se il risultato è “statisticamente significativo” secondo (a) la regione di rifiuto o (b) il valore-p.\n\nL’approccio della regione di rifiuto. Basandosi sulla distribuzione campionaria nota del test statistico, la regione di rifiuto è un insieme di valori per il test statistico per i quali l’ipotesi nulla viene rifiutata. Se il valore osservato del test statistico rientra nella regione di rifiuto, allora si rifiuta l’ipotesi nulla.\nL’approccio del valore-p. Il valore-p è la probabilità di ottenere i risultati osservati, o risultati ancora più estremi, se l’ipotesi nulla è vera.\n\nConfrontiamo il valore-p calcolato con il livello di significatività α:\n\nSe il valore-p &lt; α, si rifiuta l’ipotesi nulla (\\(H_0\\)).\nSe il valore-p ≥ α, non si rifiuta l’ipotesi nulla (\\(H_0\\)).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#il-test-di-ipotesi-nel-contesto-frequentista",
    "title": "114  Significatività statistica",
    "section": "114.2 Il Test di Ipotesi nel Contesto Frequentista",
    "text": "114.2 Il Test di Ipotesi nel Contesto Frequentista\nSi noti che i metodi bayesiani e frequentisti non sono semplicemente due approcci diversi per rispondere alla stessa domanda, ma formulano domande fondamentalmente diverse. Pertanto, per comprendere il test di ipotesi frequentista, è essenziale chiarire cosa si intende per valore-p.\nL’American Statistical Association (ASA) definisce il valore-p come:\n\nthe probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value (Wasserstein e Lazar 2016).\n\nQuesta definizione può risultare difficile da comprendere perché contiene concetti complessi come “probabilità” e “modello statistico specificato”. Per capire meglio cosa rappresenta un valore-p, è necessario esaminare attentamente entrambi questi concetti. Questo ci porterà anche a una comprensione più profonda di altri concetti fondamentali per l’inferenza frequentista e ci aiuterà a distinguere tra inferenza frequentista e inferenza bayesiana.\nUna distinzione fondamentale tra l’approccio frequentista e quello bayesiano riguarda l’interpretazione della probabilità: il primo si basa sulla frequenza relativa degli eventi nel lungo periodo, mentre il secondo si basa sulla “certezza soggettiva” o sul grado di fiducia che un individuo attribuisce a un evento specifico.\nChiarito che la probabilità assume significati diversi nei contesti frequentista e bayesiano, possiamo chiederci quale nozione di probabilità sia implicita nella definizione del valore-p fornita dall’ASA. La visione comune suggerisce che si riferisca alle frequenze relative. Ma frequenze relative di cosa e ripetizioni di cosa?\nPossiamo riformulare la definizione dell’ASA in questo modo:\n\nIl valore-p si riferisce alla frequenza relativa di ottenere un riassunto statistico dei dati grande quanto o più grande del valore osservato in ripetizioni ipotetiche di un esperimento descritto da un modello statistico specificato.\n\nQuindi, l’approccio frequentista può essere descritto come un metodo per stimare il valore di un parametro attraverso esperimenti ipotetici, confrontando i nostri dati con i risultati di tali esperimenti per giudicare se i nostri dati sono sorprendenti o meno.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#applicazione-alla-media-campionaria",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#applicazione-alla-media-campionaria",
    "title": "114  Significatività statistica",
    "section": "114.3 Applicazione alla Media Campionaria",
    "text": "114.3 Applicazione alla Media Campionaria\nIn questo capitolo, esploreremo come applicare il processo del test di ipotesi frequentista alla media campionaria. Analizzeremo come utilizzare la media di un campione per fare inferenze sulla media della popolazione, discutendo i limiti e le applicazioni di questo approccio nell’inferenza statistica frequentista.\nPer comprendere meglio il concetto di valori-p e l’applicazione della verifica del test di ipotesi, è utile ricorrere a delle simulazioni. Queste permettono di replicare condizioni sperimentali ipotetiche e osservare la variabilità dei risultati.\n\n114.3.1 La Distribuzione della Media Campionaria\nQuando consideriamo la media campionaria come stima della media di una popolazione, assumiamo che questa popolazione segua una distribuzione normale. Vogliamo quindi esplorare la distribuzione della media campionaria (\\(\\bar{X}\\)), che descrive la variazione di \\(\\bar{X}\\) attraverso infiniti campioni di dimensione \\(n\\). Abbiamo già dimostrato che, se la popolazione è normalmente distribuita, anche la distribuzione campionaria di \\(\\bar{X}\\) seguirà una distribuzione normale, con media \\(\\mu\\) (la media della popolazione) e deviazione standard \\(\\frac{\\sigma}{\\sqrt{n}}\\) (dove \\(\\sigma\\) è la deviazione standard della popolazione e \\(n\\) è la dimensione del campione).\n\n\n114.3.2 Test di Ipotesi sulla Media Campionaria\nSupponendo di conoscere \\(\\sigma\\) ma non \\(\\mu\\), utilizziamo i test di ipotesi per indagare quanto la media campionaria osservata si discosti da un valore ipotetico \\(\\mu_0\\), specificato dall’ipotesi nulla. Questo processo ci permette di valutare la plausibilità di \\(\\mu_0\\) come vera media della popolazione.\n\n\n114.3.3 Calcolo della Statistica del Test\nPer valutare quanto la media campionaria osservata si discosti dall’ipotesi nulla che propone \\(\\mu = \\mu_0\\), standardizziamo \\(\\bar{X}\\) usando la formula:\n\\[\nZ = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}\n\\]\nQuesta trasformazione produce una variabile \\(Z\\) che segue una distribuzione normale standard \\(\\mathcal{N}(0, 1)\\). Valori estremi di \\(Z\\) (sia molto grandi che molto piccoli) suggeriscono che la media campionaria osservata è incompatibile con \\(\\mu_0\\), portando al rigetto dell’ipotesi nulla.\n\n114.3.3.1 Simulazione\nPer illustrare quanto espresso sopra attraverso una simulazione, consideriamo un esempio numerico. Supponiamo che \\(\\mu_0 = 100\\), \\(\\sigma = 15\\) e \\(n = 30\\). Vogliamo calcolare il valore-p per l’evento \\(\\bar{X} &gt; 105\\).\nLa simulazione può essere eseguita come segue:\n\n# To make the simulation reproducible\nnp.random.seed(123)\n\nmu_0 = 100\nsigma = 15\nn = 30\nn_sim = 10000  # Number of simulations\n\n# Generate n_sim sample means from a N(mu_0, sigma/sqrt(n))\nsample_means = np.random.normal(loc=mu_0, scale=sigma / np.sqrt(n), size=n_sim)\n\n# Calculate the p-value as the proportion of sample means &gt; 105\np_value = np.sum(sample_means &gt; 105) / n_sim\n\n# Print the p-value\nprint(p_value)\n\n0.0348\n\n\nQuesto script simula la distribuzione campionaria di \\(\\bar{X}\\) sotto l’ipotesi nulla che \\(\\mu = \\mu_0\\) e calcola il valore-p per l’evento \\(\\bar{X} &gt; 105\\). Il valore-p indica la probabilità di osservare un valore di \\(\\bar{X}\\) così estremo (o più estremo) se l’ipotesi nulla fosse vera.\nIl risultato della simulazione può essere confrontato con il calcolo teorico del valore-p usando la distribuzione normale standard. Il valore \\(Z\\) per \\(\\bar{X} = 120\\) è calcolato come:\n\\[\nZ = \\frac{105 - 100}{15/\\sqrt{30}}\n\\]\nPossiamo usare la funzione stats.norm.sf() per trovare l’area sotto la curva normale standard a destra di questo valore \\(Z\\), che corrisponde al valore-p teorico.\n\nZ = (105 - 100) / (15 / np.sqrt(30))\nprint(Z)\n\n1.8257418583505538\n\n\n\n# Calculate the upper tail probability\nupper_tail_prob = stats.norm.sf(Z)\n\nprint(upper_tail_prob)\n\n0.033944577430914495\n\n\nOppure, in maniera equivalente\n\nupper_tail_prob = 1 - stats.norm.cdf(105, loc=100, scale=15 / np.sqrt(30))\nprint(upper_tail_prob)\n\n0.0339445774309145\n\n\nIl calcolo teorico mostra che il valore \\(Z\\) per una media campionaria di 105 è 1.82. Questo valore indica una deviazione sostanziale dalla media ipotizzata sotto l’ipotesi nulla (\\(\\mu_0 = 100\\)). Tale deviazione può essere quantificata dalla “sorpresa” indicata dal valore-p, dove valori-p piccoli rappresentano una maggiore sorpresa. Il valore-p ottenuto, pari a 0.0339, indica un elevato grado di sorpresa: come mostrato dalla simulazione, un valore di 105 o superiore si verifica solo nel 3.4% dei casi se l’esperimento viene ripetuto numerose volte sotto l’ipotesi nulla. Questo suggerisce che un risultato del genere è altamente improbabile se l’ipotesi nulla fosse vera.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#applicazioni-pratiche",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#applicazioni-pratiche",
    "title": "114  Significatività statistica",
    "section": "114.4 Applicazioni pratiche",
    "text": "114.4 Applicazioni pratiche\nNella precedente discussione, abbiamo supposto \\(\\sigma\\) nota. Tuttavia, poiché di solito non conosciamo il valore di \\(\\sigma\\) nella pratica, dobbiamo stimarlo utilizzando la deviazione standard campionaria \\(s\\). Pertanto, al posto di \\(\\sigma\\), possiamo utilizzare \\(s\\), ottenendo così la statistica:\n\\[\nT = \\frac{\\bar{X} - \\mu_0}{\\frac{s}{\\sqrt{n}}}.\n\\]\nSi può dimostrare che la statistica \\(T\\) segue una distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà se il campione casuale è stato estratto da una popolazione normale.\nA questo punto, possiamo applicare la stessa logica descritta in precedenza e possiamom basarci sulla statistica \\(T\\) per testare un’ipotesi sulla media della popolazione. Utilizzando il valore critico appropriato dalla distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà e un livello di significatività predefinito, possiamo determinare se i dati osservati supportano o respingono l’ipotesi nulla sulla media della popolazione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-statistiche",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-statistiche",
    "title": "114  Significatività statistica",
    "section": "114.5 Ipotesi statistiche",
    "text": "114.5 Ipotesi statistiche\nEsaminiamo in maggior dettaglio la procedura di test di ipotesi statistiche nel contesto frequentista. Definiamo innanzitutto l’ipotesi statistica come una dichiarazione riguardante la distribuzione di probabilità di una variabile casuale. Tale ipotesi può riguardare la forma funzionale della distribuzione o i parametri che la caratterizzano.\nIn particolare, l’ipotesi che riguarda i parametri di una o più popolazioni viene denominata ipotesi nulla e viene rappresentata come \\(H_0\\). Per un parametro sconosciuto \\(\\theta\\), l’ipotesi nulla viene formulata come:\n\\[\nH_0: \\theta \\in \\Theta_0 \\subset \\Theta,\n\\]\ndove \\(\\Theta_0\\) è un sottoinsieme del dominio \\(\\Theta\\), che rappresenta tutti i possibili valori del parametro \\(\\theta\\) coerenti con il modello statistico adottato. L’ipotesi nulla può essere semplice se \\(\\Theta_0\\) contiene un unico elemento, oppure composta se contiene più di un elemento.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#i-passi-di-un-test-di-ipotesi",
    "title": "114  Significatività statistica",
    "section": "114.6 I passi di un test di ipotesi",
    "text": "114.6 I passi di un test di ipotesi\nPer prendere una decisione tra accettare o respingere l’ipotesi nulla, i frequentisti utilizzano un test statistico. Un test statistico frequentista ci permette di valutare se i dati osservati forniscono prove sufficienti per respingere o accettare un’ipotesi riguardante una proprietà di una popolazione di interesse e si può descrivere nel modo seguente.\nIniziamo formulando l’ipotesi nulla \\(H_0\\), che rappresenta un’affermazione specifica sulla popolazione. L’ipotesi alternativa \\(H_1\\) viene formulata come l’evento complementare rispetto all’evento specificato dall’ipotesi nulla. Successivamente, definiamo una statistica campionaria \\(\\mathcal{G}_n(X_1, \\dots, X_n)\\) che viene calcolata a partire dai dati campionari e che ha una distribuzione nota quando l’ipotesi nulla è vera.\nSuccessivamente, suddividiamo l’insieme di tutte le possibili realizzazioni della statistica \\(\\mathcal{G}_n\\) in due insiemi disgiunti: la “regione di accettazione” \\(\\mathcal{A}\\) e la sua regione complementare, la “regione di rifiuto” \\(\\mathcal{R}\\). La regione di accettazione rappresenta l’insieme dei valori che la statistica può assumere sotto l’ipotesi nulla, mentre la regione di rifiuto rappresenta l’insieme dei valori che la statistica può assumere se l’ipotesi nulla è falsa.\nInfine, selezioniamo un livello di significatività \\(\\alpha\\), che rappresenta la massima probabilità di respingere erroneamente l’ipotesi nulla quando questa è vera. Se l’osservazione della statistica \\(\\mathcal{G}_n\\) rientra nella regione di accettazione, allora l’ipotesi nulla non viene respinta; altrimenti, viene respinta a favore dell’ipotesi alternativa.\nIn sintesi, il test statistico ci consente di stabilire se i dati osservati forniscono sufficienti evidenze per rifiutare l’ipotesi nulla a favore dell’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-alternativa",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-alternativa",
    "title": "114  Significatività statistica",
    "section": "114.7 Ipotesi alternativa",
    "text": "114.7 Ipotesi alternativa\nDurante un test di ipotesi, dopo aver definito l’ipotesi nulla \\(H_0\\), possono essere considerate diverse ipotesi alternative \\(H_1\\). Le ipotesi alternative più comuni si suddividono in tre tipi:\n\n\\(H_1: \\theta \\neq \\theta_0\\),\n\\(H_1: \\theta &gt; \\theta_0\\),\n\\(H_1: \\theta &lt; \\theta_0\\).\n\nQueste corrispondono rispettivamente a un test bidirezionale, un test unilaterale superiore (o destro) e un test unilaterale inferiore (o sinistro).\nLa scelta dell’ipotesi alternativa determina la definizione della regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla \\(H_0\\). La regione di rifiuto rappresenta i valori estremi della distribuzione, nella direzione dell’ipotesi alternativa \\(H_1\\). Nel caso di un test unilaterale inferiore, \\(\\mathcal{R}\\) si trova nella coda sinistra della distribuzione, nell’intervallo [\\(-\\infty\\), \\(\\theta_0\\)]. Nel caso di un test unilaterale superiore, \\(\\mathcal{R}\\) si trova nella coda destra della distribuzione, nell’intervallo [\\(\\theta_0\\), \\(\\infty\\)].\nI valori critici sono i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bidirezionale. Il risultato di un test viene considerato statisticamente significativo se il valore della statistica del test si trova nella regione di rifiuto \\(\\mathcal{R}\\).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#valore-p",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#valore-p",
    "title": "114  Significatività statistica",
    "section": "114.8 Valore-p",
    "text": "114.8 Valore-p\nIl valore-p è definito come la probabilità che la statistica del test assuma un valore uguale o più estremo di quello osservato, considerando la distribuzione campionaria costruita assumendo come vera l’ipotesi nulla. La significatività statistica viene convenzionalmente definita come un valore-p inferiore a 0.05, indicando che l’evidenza osservata è improbabile da ottenere se l’ipotesi nulla è vera. Se il risultato osservato non raggiunge la significatività statistica, significa che la stima non è statisticamente significativa e che il valore osservato può essere spiegato da una semplice variazione casuale.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#un-esempio-motivante",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#un-esempio-motivante",
    "title": "114  Significatività statistica",
    "section": "114.9 Un esempio motivante",
    "text": "114.9 Un esempio motivante\nPer esplorare il concetto di significatività statistica, possiamo prendere in considerazione uno studio svolto da Mehr et al. (2016) sul ruolo della musica nella trasmissione di messaggi sociali ai bambini. La musica è una forma d’arte presente in molte attività quotidiane e può trasmettere informazioni relative alla cultura e all’appartenenza sociale. Gli autori dello studio hanno voluto indagare se i bambini di soli 5 mesi avessero una preferenza per individui sconosciuti che cantavano loro una canzone familiare rispetto ad altri individui sconosciuti che cantavano una canzone simile, ma con una diversa melodia.\nDalle analisi condotte da Mehr et al. (2016) è emerso che la preferenza dei bambini si manifestava solo quando la canzone veniva cantata dai loro genitori durante la fase di familiarizzazione, ma non quando la stessa canzone veniva cantata da un estraneo. Secondo gli autori, questo dimostra che il significato sociale è un elemento chiave nella preferenza dei bambini, oltre alla familiarità con la canzone.\n\n114.9.1 Domanda della ricerca e ipotesi statistiche\nLa ricerca condotta da Mehr et al. (2016) si è concentrata sullo studio dell’influenza della musica sui messaggi sociali trasmessi ai bambini molto piccoli. Tuttavia, come molte altre ipotesi psicologiche, l’ipotesi principale non può essere valutata direttamente in termini quantitativi. Pertanto, i ricercatori devono formulare ipotesi statistiche, che, sebbene non coincidano con l’ipotesi della ricerca, possono essere esaminate in termini probabilistici.\nPer chiarire questo punto, consideriamo l’esperimento condotto sui bambini da Mehr et al. (2016). Dopo la fase di familiarizzazione con la canzone di prova, i bambini partecipanti sono stati sottoposti a un test in laboratorio, durante il quale sono stati mostrati due video. Nel primo video, un estraneo cantava la canzone di prova, mentre nel secondo video, un altro individuo cantava una canzone simile ma non familiare ai bambini. I ricercatori hanno misurato il tempo in cui i bambini fissavano ciascun video. Nel primo esperimento, la variabile dipendente era la media delle proporzioni di tempo che i bambini fissavano il video “familiare” rispetto al tempo di fissazione totale. Poiché l’ipotesi principale non può essere valutata direttamente, i ricercatori hanno formulato ipotesi statistiche che possono essere esaminate in termini probabilistici.\nPoiché nei tipici esperimenti psicologici, come nel caso della ricerca di Mehr et al. (2016), l’ipotesi della ricerca non può essere valutata direttamente, è necessario stabilire una connessione tra l’ipotesi della ricerca e l’ipotesi statistica. Nel caso specifico, ci sono tre possibili scenari da considerare:\n\nNel caso in cui i bambini non mostrino alcuna preferenza tra i due tipi di video-registrazione, la media delle proporzioni di tempo di fissazione per la popolazione sarà uguale a \\(\\mu = 0.5\\), in quanto i tempi di fissazione saranno uguali in media per le due video-registrazioni.\nSe invece gli autori della ricerca hanno ragione, i bambini mostreranno una preferenza per il video con la canzone familiare rispetto a quello con la canzone non familiare. In questo caso, l’ipotesi statistica sarà \\(\\mu &gt; 0.5\\), dove \\(\\mu = 0.5\\) rappresenta il livello di probabilità casuale.\nInfine, una terza possibilità è che i bambini siano maggiormente attratti da una melodia non familiare, contrariamente a quanto suggerito dagli autori della ricerca. In tal caso, l’ipotesi statistica diventa \\(\\mu &lt; 0.5\\).\n\nLe tre ipotesi precedenti sono esempi di ipotesi statistiche, che sono delle affermazioni riguardanti i valori di un parametro di un modello statistico. Nel caso dell’esperimento di Mehr et al. (2016), il modello statistico riguarda la distribuzione delle proporzioni dei tempi di fissazione di una popolazione virtuale di infiniti bambini di sei mesi di età. Ogni bambino avrà una proporzione di tempi di fissazione diversa dagli altri bambini. Il modello statistico descritto dai ricercatori rappresenta la distribuzione dei possibili valori della proporzione del tempo di fissazione nei confronti del video “familiare”. I dati raccolti dagli sperimentatori corrispondono alla media della proporzione del tempo di fissazione del video “familiare” e possono essere messi in relazione con il modello statistico.\n\n\n114.9.2 Domanda della ricerca e ipotesi statistiche\nLa distinzione tra l’ipotesi della ricerca e l’ipotesi statistica è cruciale durante il test delle ipotesi. L’ipotesi della ricerca riguarda l’affermazione che si intende testare sulla natura dei fenomeni psicologici, mentre l’ipotesi statistica riguarda il modello generativo dei dati, ovvero le proprietà della popolazione. Nel caso dell’esperimento condotto da Mehr e colleghi, l’ipotesi della ricerca afferma che la preferenza sociale dei bambini è influenzata dalla musica e, in particolare, dalla familiarità con i materiali musicali. L’ipotesi statistica, invece, sostiene che la media della proporzione del tempo di fissazione dei bambini sul video “familiare” sia maggiore di 0.5.\nI test di ipotesi vengono applicati alle ipotesi statistiche, non alle ipotesi della ricerca. Ciò significa che se l’esperimento non viene condotto nella maniera appropriata, il collegamento tra l’ipotesi statistica e la domanda della ricerca può essere spezzato. Ad esempio, se l’attore che canta la melodia familiare assomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un aspetto molto diverso, allora potrebbe essere facile trovare evidenze a supporto dell’ipotesi statistica secondo cui la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” è maggiore di 0.5, ma ciò non avrebbe nulla a che fare con la domanda della ricerca.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#ipotesi-nulla-e-ipotesi-alternativa",
    "title": "114  Significatività statistica",
    "section": "114.10 Ipotesi nulla e ipotesi alternativa",
    "text": "114.10 Ipotesi nulla e ipotesi alternativa\nFino a qui il ragionamento è stato semplice: il ricercatore ha un’ipotesi a proposito dei fenomeni psicologici e a tale ipotesi di ricerca corrisponde un’ipotesi statistica che riguarda il meccanismo generativo dei dati. Se il fenomeno psicologico possiede le proprietà suggerite dall’ipotesi della ricerca, allora il ricercatore può aspettarsi che i dati osservati abbiano alcune specifiche caratteristiche. A questo punto, però, il ragionamento diventa contro-intuitivo perché non è possibile verificare direttamente l’ipotesi statistica che corrisponde alla domanda della ricerca.\n\n114.10.1 Apagogia\nIn linea di principio, non è mai possibile dimostrare direttamente la verità di una proposizione. Tuttavia, possiamo dimostrare la sua verità in modo indiretto, ovvero provando la falsità della sua proposizione complementare.\nL’esempio classico è il seguente. Consideriamo la seguente proposizione: “Tutti i cigni sono bianchi” (questo è l’esempio ornitologico preferito da Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è sufficiente a dimostrare la verità di questa proposizione – infatti, ci potrebbe essere da qualche parte un cigno non bianco che non abbiamo osservato (e infatti c’è). D’altra parte, invece, l’osservazione di un solo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un cigno nero proveniente dall’Australia) può falsificare la proposizione considerata. Questa è la logica del falsificazionismo di Popper.\nQuesto modo di pensare è stato trasferito nella procedura di test di ipotesi di stampo frequentista. Dato che non possiamo dimostrare vera l’ipotesi statistica associata alla domanda della ricerca, seguiamo il percorso opposto. Ovvero, ci poniamo l’obiettivo di dimostrare falso l’evento complementare a quello specificato dall’ipotesi statistica associata alla domanda della ricerca. L’ipotesi statistica che vorremmo falsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel caso dell’esempio che stiamo discutendo, l’ipotesi nulla è: \\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili ipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e \\(\\mu &lt; 0.5\\)), ad eccezione di quella che è associata all’ipotesi della ricerca (ovvero, \\(\\mu &gt; 0.5\\)). Questo definisce, nel caso presente, un test unilaterale.\nIn pratica, ciò che stiamo facendo è dividere tutti i possibili valori di \\(\\mu\\) in due gruppi: quei valori che sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi alternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con l’ipotesi della ricerca (ovvero, i valori che specificano l’ipotesi nulla).\nAvendo detto questo, la cosa importante da riconoscere è che l’obiettivo di un test di ipotesi frequentista non è quello di dimostrare che l’ipotesi alternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi nulla è (probabilmente) falsa. La maggior parte delle persone ritiene che questo modo di ragionare sia piuttosto strano.\n\n\n114.10.2 La similitudine del processo penale\nUn test di ipotesi è spesso comparato ad un processo penale, dove l’ipotesi nulla rappresenta l’imputato, il ricercatore il pubblico ministero, e il test statistico il giudice. Così come in un processo penale, anche in un test di ipotesi c’è una presunzione di innocenza, dove l’ipotesi nulla viene considerata vera a meno che il ricercatore non dimostri, con evidenza al di là di ogni ragionevole dubbio, che è falsa. Il ricercatore progetta l’esperimento in modo da massimizzare la possibilità che i dati producano una condanna dell’ipotesi nulla. Il test statistico, rappresentato dal giudice in questa metafora, stabilisce le regole che devono essere seguite per giungere al verdetto e tali regole sono pensate per proteggere l’ipotesi nulla. In particolare, sono studiate per garantire che la probabilità di una condanna sia bassa se l’ipotesi nulla è effettivamente vera. È importante sottolineare che l’ipotesi nulla deve essere protetta, poiché il ricercatore sta cercando di dimostrare che essa è falsa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#due-tipi-di-errori",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#due-tipi-di-errori",
    "title": "114  Significatività statistica",
    "section": "114.11 Due tipi di errori",
    "text": "114.11 Due tipi di errori\nPrima di entrare nei dettagli su come viene costruito un test statistico è utile capire la logica su cui esso è basato. In precedenza abbiamo paragonato il test di ipotesi nulla ad un processo penale, ma ora dobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro test in modo da non commettere errori. Sfortunatamente, però, questo non è possibile: a volte il ricercatore è sfortunato e finisce per prendere la decisione sbagliata, anche se adotta un processo decisionale razionale. Ad esempio, può succedere che una moneta venga lanciata 10 volte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una prova molto forte del fatto che la moneta è sbilanciata, ma c’è una possibilità su 1024 che ciò accada anche se la moneta è equilibrata. In altre parole, nella vita reale dobbiamo sempre accettare la possibilità che le nostre scelte siano sbagliate, anche quando sembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi statistiche non è quello di eliminare completamente gli errori (questo è impossibile), ma di ridurre gli errori al minimo.\nA questo punto, dobbiamo precisare meglio cosa intendiamo per “errori”. Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre a rifiutare l’ipotesi nulla o a non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di commettere uno di due tipi di errore, come indicato nella figura seguente. L’errore di I tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera; l’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi alternativa.\n\n\n114.11.1 Errore di I tipo: la protezione dei diritti dell’imputato\nIn precedenza abbiamo paragonato il test statistico ad un processo penale. Infatti, un processo penale richiede che si stabilisca la colpevolezza dell’imputato “oltre ogni ragionevole dubbio”. Le regole del processo penale sono state progettate per garantire che non ci sia (quasi) nessuna possibilità di condannare ingiustamente un imputato innocente: il processo penale è progettato (almeno in teoria) per proteggere i diritti dell’imputato. Detto in altri termini, il processo penale non mette sullo stesso piano i due tipi di errore che si possono commettere: punire un innocente o assolvere un colpevole. L’errore che consiste nel punire un innocente viene considerato assai più grave di quello che porta ad assolvere un colpevole.\nUn test statistico fa praticamente la stessa cosa: i test di ipotesi statistiche sono costruiti in modo tale da controllare la probabilità di un errore di I tipo, con l’obiettivo di mantenerla al di sotto di una certa soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\), viene chiamata “livello di significatività del test”. Usando parole diverse, possiamo dire che un test di ipotesi ha un livello di significatività \\(\\alpha\\) se il tasso di errore di I tipo non è più grande di \\(\\alpha\\). Per convenzione, i ricercatori fanno uso di tre diversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.\n\n\n114.11.2 Errore di II tipo: l’asimmetria del giudizio\nChe dire del tasso di errore di II tipo? In realtà, vorremmo tenere anche quello sotto controllo e denotiamo la probabilità di un errore di II tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente discusso ed è molto più comune fare riferimento alla potenza del test, che è la probabilità dell’evento complementare, ovvero la probabilità con cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero \\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un piccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una piccola soglia di probabilità prefissata.\nSi noti l’asimmetria qui rivelata: i test di ipotesi sono progettati per garantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia prefissata, ma non esiste alcuna corrispondente garanzia a proposito di \\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia piccolo, e in generale i ricercatori cercano di progettare i loro esperimenti in maniera tale da avere una ragionevole potenza del test (\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione sufficientemente grande – ma nella logica della costruzione del test di ipotesi questo aspetto è secondario rispetto alla necessità di controllare il tasso di errore di I tipo.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#come-si-costruisce-un-test-di-ipotesi",
    "title": "114  Significatività statistica",
    "section": "114.12 Come si costruisce un test di ipotesi?",
    "text": "114.12 Come si costruisce un test di ipotesi?\nRitorniamo all’esempio relativo allo studio di Mehr et al. (2016). In questo caso, sulla base all’ipotesi della ricerca, l’ipotesi nulla può essere formulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini di età media pari a 5.6 mesi, Mehr et al. (2016) hanno scoperto che, in media, i bambini dirigevano lo sguardo verso il video “familiare” nel 56% del tempo totale di fissazione. Dunque, la media campionaria è \\(\\bar{X} = 0.56\\) Questo è il valore campionario rilevante per il test dell’ipotesi nulla.\nIngenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o meno, sia sufficiente confrontare la proporzione calcolata nel campione con il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente, l’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un intervallo di valori: \\([0, 0.5]\\). I dati campionari specificano un valore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso nell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece avessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe stato nient’altro da dire: se i dati osservati sono compatibili con \\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già trovato la risposta alla domanda della ricerca.\n\n114.12.1 La variabilità campionaria\nNel caso dell’esperimento di Mehr et al. (2016) che stiamo discutendo, \\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del valore osservato \\(\\bar{X} = 0.56\\) possiamo dunque concludere che \\(H_0\\) è falsa? Non così presto. Non è sufficiente trovare una differenza \\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso). È anche necessario tenere in considerazione il fenomeno della variabilità campionaria.\nInfatti, la media \\(\\bar{X}\\) osservata in ogni singolo campione di ampiezza \\(n=32\\) è una variabile aleatoria: in ciascun possibile campione di ampiezza 32 i bambini si comportano in maniera diversa e, di conseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione a campione. Le statistiche campionarie – nel nostro caso la media \\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò a cui noi siamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma sfortunatamente conosciamo solo una sua realizzazione campionaria, ovvero \\(\\bar{X}\\).\nRisulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può essere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti, è ragionevole pensare che, indipendentemente dal fatto che l’ipotesi nulla sia vera o meno, in alcuni campioni la differenza \\(\\bar{X} - \\mu\\) sarà positive mentre in altri campioni sarà negativa. Dobbiamo dunque trovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per effetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che considerare unicamente la differenza \\(\\bar{X} - \\mu\\).\n\n\n114.12.2 Le distribuzioni delle statistiche test\nIl metodo seguito dall’approccio frequentista per affrontare questo problema è quello di costruire la distribuzione della statistica test \\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera l’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la procedura di test di ipotesi dell’approccio frequentista. Esaminiamolo più in dettaglio.\nLo scopo della procedura di test statistici dell’approccio frequentista non è quello di verificare l’ipotesi alternativa: questo non è logicamente possibile. Invece, come suggerito dalla similitudine del processo penale all’ipotesi nulla, l’approccio frequentista si pone l’obiettivo di determinare se ci siano indizi sufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla. In questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\) corrisponde all’idea che dobbiamo assumere come vera l’ipotesi nulla fino a prova contraria.\nNell’esempio che stiamo discutendo, assumere come vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la media della popolazione) sia uguale a 0.5. Sulla base di questa assunzione, per i dati dell’esempio presente, è possibile costruire la distribuzione delle medie dei campioni di ampiezza 32. Standardizzando poi la media del campione, è possibile stabilire quanto sia “distante” dal valore atteso della distribuzione campionaria costruita assumento come vera \\(H_0\\).\nLa standardizzazione di \\(\\bar{X}\\) si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) è la media del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard del campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del campione (ovvero, \\(n\\) = 32). Per il caso presente otteniamo:\n\nT = (0.56 - 0.50) / (0.179 / np.sqrt(32))\nprint(T)\n\n1.8961522623996823\n\n\n\n\n114.12.3 Regioni di rifiuto e regioni di non rifiuto\nConoscendo la distribuzione dei valori della statistica test (distribuzione determinata assumendo come vera \\(H_0\\)) diventa poi possibile dividere l’insieme dei valori possibili di \\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica statistica test) in due regioni: i valori che ci portano a rigettare \\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare \\(H_0\\) (regione di non rifiuto).\nPer decidere quanto deve essere grande la regione di rifiuto di \\(H_0\\) è sufficiente collocare nella regione di rifiuto i valori estremi della statistica test \\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare se \\(H_0\\) fosse vera.\n\n\n114.12.4 Quando rifiutare l’ipotesi nulla\nSupponiamo che la figura seguente rappresenti la distribuzione campionaria della statistica test \\(\\mathcal{G}_n\\).\n\nSe i dati producono la statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi nulla \\(H_0\\). Se invece i dati producono \\(\\mathcal{G}_n^2\\) allora possiamo rifiutare l’ipotesi nulla in favore dell’ipotesi alternativa. Ci sono varie cose da notare.\n\nLa regione di rifiuto è costituita da valori lontani dal centro della distribuzione campionaria della statistica test, la quale è stata costruita assumendo come vera \\(H_0\\).\nLa regione di rifiuto è situata nelle code della distribuzione. Vedremo in seguito anche degli esempi di regioni di rifiuto unilaterali.\nIn questa discussione, l’ipotesi alternativa non è menzionata. Rifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla distribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla probabilità della statistica test condizionata all’ipotesi nulla \\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa in considerazione quando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\), ma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\n\n\n\n114.12.5 Specificazione delle regioni di rifiuto\nL’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce a specificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). La regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai valori collocati agli estremi della distribuzione secondo la direzione dell’ipotesi alternativa \\(H_1\\).\n\nSe l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove \\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore del parametro), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli intervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).\nSe l’ipotesi alternativa è \\(H_1: \\theta &lt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.\nSe l’ipotesi alternativa è \\(H_1: \\theta &gt; \\theta_0\\), allora le evidenze coerenti con l’ipotesi alternativa (e che portano al rigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di destra della distribuzione.\n\nSi chiamano valori critici i valori che delimitano la regione di rifiuto \\(\\mathcal{R}\\) in un test unilaterale e i valori che delimitano le regioni di rifiuto \\(\\mathcal{R}\\) in un test bilaterale. In un test bidirezionale, i valori critici lasciano in ciascuna delle due code della distribuzione della statistica test una probabilità pari a \\(\\alpha/2\\); in un test unidirezionale lasciano una probabilità pari ad \\(\\alpha\\) in una sola coda. Il risultato di un test si dice statisticamente significativo quando il valore della statistica test ricade nella regione di rifiuto \\(\\mathcal{R}\\).\n\n\n114.12.6 La decisione statistica\nIl processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:\n\nControllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente all’ipotesi assunta, respingiamo l’ipotesi. (p. 441)\n\nOvviamente l’ipotesi a cui von Mises fa riferimento è l’ipotesi nulla.\nIn pratica, possiamo decidere se rigettare o meno l’ipotesi nulla in due modi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno nella regione di rifiuto (come abbiamo descritto sopra) o confrontando il valore-\\(p\\) con \\(\\alpha\\) – i due metodi sono equivalenti.\nIl valore-p rappresenta la probabilità di osservare un valore della statistica test \\(\\mathcal{G}_n\\) pari a quello effettivamente osservato, o maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore del livello di significatività \\(\\alpha\\), allora la statistica test cade nella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi nulla. Tali concetti sono riassunti nella tabella seguente.\n\nPer l’esempio in discussione, la statistica \\(T\\) calcolata sopra si distribuisce come \\(t\\) di Student con \\(\\nu = 31\\) gradi di libertà. Il valore-p corrisponde dunque all’area sottesa ad una \\(t_{31}\\) nell’intervallo \\([1.896, +\\infty]\\) (test unidirezionale destro), ovvero\n\np = 1 - stats.t.cdf(T, 31)\nprint(p)\n\n0.033647093369739034\n\n\nDato che il valore-p è minore di \\(\\alpha = 0.05\\), Mehr et al. (2016) rifiutano \\(H_0\\) (cioè che la proporzione media del tempo di fissazione dei bambini nei confronti del video “familiare” sia 0.5, o minore) e concludono che i bambini mostrano una preferenza per il video familiare.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#potenza-del-test",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#potenza-del-test",
    "title": "114  Significatività statistica",
    "section": "114.13 Potenza del test",
    "text": "114.13 Potenza del test\nRitorniamo ora al concetto di potenza del test. Il livello di significatività e la potenza del test vengono usati per quantificare la qualità dell’inferenza statistica. Idealmente, la procedura di test di ipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non dovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\) in favore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due dei quattro esiti che, in principio, sono possibili, e corrispondono alle probabilità indicate di seguito.\n\nPossiamo pensare a \\(H_0\\) come all’ipotesi che descrive l’evento “nulla di interessante sta succedendo” – ad esempio, “la moneta è bilanciata”, “il trattamento non è migliore del placebo”, ecc. – e pensare ad \\(H_1\\) come al caso contrario, ovvero: “sta accadendo qualcosa di interessante”. Quindi la potenza del test, ovvero la probabilità \\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla probabilità di rilevare qualcosa di interessante, quando qualcosa di interessante è effettivamente successo, mentre il livello di significatività corrisponde alla probabilità di affermare che qualcosa di interessante si è verificato, quando in realtà non è successo nulla di interessante.\nIl calcolo della potenza di un test è spesso difficile, perché richiede la conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando è vera l’ipotesi alternativa \\(H_1\\). Tipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione in maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate a \\(H_0\\) e ad \\(H_1\\). In un disegno sperimentale è importante determinare in anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.\n\n114.13.1 Neyman e Fisher\nLa procedura di test di ipotesi statistiche descritta sopra combina due approcci teorici diversi, proposti da Sir Ronald Fisher e Jerzy Neyman. La storia di questi due approcci non è lineare, poiché Fisher e Neyman hanno modificato le loro opinioni nel tempo, senza mai fornire una “verità definitiva” su come interpretare il loro lavoro.\nIn sintesi, Fisher considerava che il ricercatore avesse un’unica ipotesi (quella nulla) e che lo scopo fosse verificare se i dati fossero coerenti o meno con essa. In questo senso, il valore-\\(p\\) rappresenta la probabilità di osservare, sotto l’ipotesi nulla, il risultato ottenuto o uno ancora più estremo. Se il valore-\\(p\\) è piccolo, Fisher rifiutava l’ipotesi nulla. Tuttavia, poiché non venivano formulate altre ipotesi, non c’era modo di “accettare l’alternativa”.\nAl contrario, Neyman adottava un approccio più formale rispetto a Fisher e pensava che lo scopo della verifica delle ipotesi fosse quello di prendere decisioni. Secondo Neyman, il problema era decidere se accettare l’ipotesi nulla o l’alternativa e il test serviva a stabilire quale supporto venisse fornito alle due alternative. Per questo motivo, era fondamentale specificare in modo preciso l’ipotesi alternativa. Nel suo approccio, il valore-\\(p\\) non misurava la probabilità del risultato del test o di uno più estremo sotto l’ipotesi nulla, ma forniva una descrizione astratta dei “possibili test” che portavano all’accettazione dell’ipotesi nulla o dell’alternativa.\nAttualmente ci troviamo in una situazione strana e ambigua, dove sono presenti elementi di entrambi gli approcci. La procedura di verifica di ipotesi statistiche distingue tra un’ipotesi nulla e un’ipotesi alternativa, seguendo la visione di Neyman, ma definisce il valore-\\(p\\) in termini di dati estremi, come avrebbe fatto Fisher, in confronto con un livello \\(\\alpha\\) stabilito da Neyman. Alcuni test statistici specificano in modo chiaro l’ipotesi alternativa, mentre altri sono più vaghi in merito, adottando l’approccio di Fisher. Inoltre, c’è disaccordo tra i ricercatori riguardo alla possibilità di “accettare l’alternativa”, a seconda che si segua Neyman o Fisher. Questa confusione costituisce il “peccato originale” della procedura di verifica di ipotesi statistiche. Tuttavia, ci sono motivi più specifici per cui questo approccio, noto come significatività statistica, viene criticato da molti ricercatori come una delle cause principali della crisi della replicabilità dei risultati della ricerca in psicologia e in altri campi. Nel capitolo Capitolo 119 esploreremo queste ragioni in dettaglio.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#la-storia-del-test-dellipotesi-nulla-di-fisher-e-le-sue-contraddizioni",
    "title": "114  Significatività statistica",
    "section": "114.14 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni",
    "text": "114.14 La Storia del Test dell’Ipotesi Nulla di Fisher e le Sue Contraddizioni\nConcludiamo l’analisi della procedura dei test di ipotesi statistici esaminando l’evento che ha ispirato Ronald A. Fisher a sviluppare la sua teoria dell’inferenza statistica, focalizzata sul test dell’ipotesi nulla. Questo episodio è descritto dettagliatamente da Etz et al. (2018). L’aneddoto riguarda un tè che Fisher aveva offerto alla sua collega, la Dott.ssa Muriel Bristol. Durante la preparazione della bevanda, la Dr.ssa Bristol contestò il metodo adottato da Fisher, asserendo che il tè avrebbe avuto un gusto migliore se il latte fosse stato versato prima dell’acqua bollente. Per verificare l’affermazione della Dr.ssa Bristol, Fisher ideò un esperimento di discriminazione sensoriale. Nei test condotti, la Dr.ssa Bristol fu in grado di individuare correttamente il processo di preparazione del tè in cinque occasioni su sei.\nQuesto risultato pose Fisher di fronte a un interrogativo: la sua collega stava semplicemente facendo una supposizione fortunata, oppure era effettivamente in grado di discernere tra le due diverse modalità di preparazione? Per risolvere questa questione, Fisher elaborò la sua metodologia per il test dell’ipotesi nulla. Utilizzò un valore-\\(p\\) calcolato sulla base della probabilità dell’evento osservato, nonché di qualsiasi altro evento più estremo che potrebbe verificarsi sotto l’ipotesi nulla.\nTuttavia, è stato fatto notare che l’approccio di Fisher al test dell’ipotesi nulla può essere insufficiente e portare a conclusioni errate (Etz et al., 2018). Una delle questioni fondamentali riguarda la definizione di un evento “più estremo” rispetto a quello osservato.\nSupponiamo che lo scopo dell’esperimento casuale sia di determinare l’accuratezza delle riposte della Dr.ssa Bristol in esattamente sei tentativi (e non di più). In tale caso, con 5 risposte corrette, il valore-\\(p\\) è pari a 0.109, che non è statisticamente significativo. In questo scenario, secondo la logica di Fisher, non si dovrebbe respingere l’ipotesi nulla che la Dr. Bristol stesse semplicemente indovinando.\nSupponiamo ora che lo scopo dell’esperimento casuale sia di continuare a servire tè fino a quando la Dr.ssa Bristol non abbia raggiunto cinque risposte corrette (un risultato che, per coincidenza, si è verificato dopo sei tentativi). Se analizziamo i dati in questo secondo scenario, il valore-\\(p\\) diventa pari a 0.031, che è statisticamente significativo. In quest’ultimo caso, l’ipotesi nulla verrebbe respinta.\nQuello che emerge è che, nonostante i dati osservati nei due scenari siano identici, giungiamo a conclusioni opposte come conseguenza delle diverse modalità di campionamento impiegate. Questa variabilità è problematica poiché il valore-\\(p\\), e quindi la nostra valutazione delle capacità discriminative della Dr.ssa Bristol, dipendono non solo dai dati effettivamente raccolti, ma anche dal disegno sperimentale adottato. Questa constatazione mette in discussione la robustezza del test dell’ipotesi nulla come strumento fondamentale per l’inferenza scientifica.\nPer illustrare il problema, svolgiamo i calcoli utilizzando le distribuzioni statistiche richieste per i due tipi di campionamento: la distribuzione binomiale e la distribuzione geometrica negativa.\n\n114.14.1 Distribuzione Binomiale\nLa distribuzione binomiale è la distribuzione da utilizzare quando il numero di tentativi è prefissato e conosciuto a priori. Nel contesto dell’esempio del tè, assumiamo che siano state servite esattamente sei tazze. La formula per determinare la probabilità di registrare esattamente \\(k\\) successi in \\(n\\) tentativi è la seguente:\n\\[\nP(X = k) = \\binom{n}{k} \\times p^k \\times (1-p)^{(n-k)}\n\\]\nQui, \\(\\binom{n}{k}\\) rappresenta il coefficiente binomiale, \\(p\\) è la probabilità di un singolo successo (ossia di indovinare correttamente la preparazione del tè), e \\((1-p)\\) è la probabilità di un singolo fallimento.\nPer calcolare il valore-\\(p\\) in questo specifico contesto, dobbiamo sommare le probabilità di ottenere un risultato di 5 o più estremo su un totale di 6 tentativi.\n\n# Parametri\nn_binomial = 6  # Numero fisso di tentativi per la distribuzione binomiale\nn_success = 5  # Numero di successi desiderato\np = 0.5  # Probabilità di successo (indovinare la tazza di tè)\n\n# Calcolo del p-value per la distribuzione binomiale\np_value_binomial = 1 - binom.cdf(n_success - 1, n_binomial, p)\n\np_value_binomial\n\n0.109375\n\n\n\n\n114.14.2 Distribuzione Geometrica Negativa\nNel contesto dell’esperimento del tè, quando il test continua fino al raggiungimento di un numero prefissato di successi (nel nostro caso, cinque identificazioni corrette), la distribuzione di riferimento appropriata è la distribuzione geometrica negativa.\nLa distribuzione geometrica negativa modella il numero di fallimenti \\(k\\) che si verificano prima di ottenere un numero prefissato \\(r\\) di successi in una sequenza di prove indipendenti di Bernoulli, dove ogni prova ha probabilità di successo \\(p\\).\nLa probabilità di osservare esattamente \\(k\\) fallimenti prima di ottenere \\(r\\) successi è data da:\n\\[\nP(X = k) = \\binom{k+r-1}{k} p^r (1-p)^k,\n\\]\ndove:\n\n\\(k\\) è il numero di fallimenti,\n\\(r\\) è il numero di successi desiderato,\n\\(p\\) è la probabilità di successo in ogni prova,\n\\(\\binom{k+r-1}{k}\\) è il coefficiente binomiale che rappresenta il numero di modi possibili in cui \\(k\\) fallimenti e \\(r\\) successi possono essere ordinati.\n\nNel nostro caso specifico:\n\n\\(r = 5\\) (successi desiderati),\n\\(p = 0.5\\) (probabilità di indovinare correttamente sotto l’ipotesi nulla),\n\\(k\\) varia da 0 a 1 (possibili fallimenti prima del quinto successo).\n\nIl valore-p si calcola sommando le probabilità per tutti i casi “più estremi” di quello osservato:\n\\[\n\\text{valore-p} = \\sum_{k=0}^{1} \\binom{k+5-1}{k} (0.5)^5 (0.5)^k.\n\\]\nImplementazione:\n\n# Parametri\nn_binomial = 6  # Numero fisso di tentativi per la distribuzione binomiale\nn_success = 5  # Numero di successi desiderato\np = 0.5  # Probabilità di successo (indovinare la tazza di tè)\n\n# Calcolo del p-value per la distribuzione geometrica negativa\np_value_geom_corrected = 0\nfor k in range(n_binomial - n_success):  # Numero di fallimenti prima del 5° successo\n    p_value_geom_corrected += (\n        comb(k + n_success - 1, k) * ((1 - p) ** k) * (p**n_success)\n    )\n\np_value_geom_corrected\n\n0.03125\n\n\nIn conclusione,\n\nper la distribuzione binomiale, il p-value è \\(0.109\\), che non è statisticamente significativo (dato che è maggiore di 0.05); quindi, secondo Fisher, in questo caso non dovremmo rigettare l’ipotesi nulla che Dr. Bristol stia indovinando.\nper la distribuzione geometrica negativa, il p-value è \\(0.031\\), che è statisticamente significativo (dato che è minore di 0.05); in questo caso, dovremmo rigettare l’ipotesi nulla, suggerendo che Dr. Bristol non sta semplicemente indovinando.\n\nLa presente discussione mostra che, in base alla procedura del test dell’ipotesi nulla, la stessa sequenza di eventi (5 successi su 6 tentativi) può portare a conclusioni opposte a seconda delle ipotesi sul processo di campionamento. Questo paradosso è uno dei motivi (per ulteriori critiche, si veda Wasserstein & Lazar (2016); Benjamin et al. (2018)) per cui l’inferenza bayesiana è diventata più popolare negli ultimi anni come quadro alternativo per il test delle ipotesi e la stima dei parametri.\n\n\n114.14.3 Approccio Bayesiano\nNel loro lavoro, Etz et al. (2018) propongono un’alternativa bayesiana per risolvere il problema esaminato da Fisher. Questa soluzione bayesiana evita le contraddizioni che emergono quando si cercano di definire “risultati più estremi” che non sono stati osservati. L’approccio bayesiano si focalizza esclusivamente sui dati effettivamente raccolti e utilizza queste osservazioni per aggiornare le probabilità iniziali (o “a priori”) associate a diverse ipotesi. Il processo si basa sulla regola di Bayes e si sviluppa in tre fasi principali:\n\nStabilire Probabilità a Priori: Iniziamo assegnando una distribuzione di probabilità a priori a tutti i possibili tassi di successo che la Dr. Bristol potrebbe avere. Questo include una probabilità specifica per l’ipotesi nulla, che suggerisce che la Dr. Bristol stia semplicemente indovinando (con un tasso di successo del 50%).\nAggiornare le Probabilità con Dati Osservati: Utilizziamo i dati raccolti nell’esperimento per aggiornare le nostre probabilità a priori. Questo aggiornamento è fatto utilizzando la regola di Bayes.\nCalcolare il Fattore di Bayes: Questa metrica ci dice quanto i dati osservati influenzano le probabilità delle diverse ipotesi. Un Fattore di Bayes molto maggiore di 1 indicherebbe un forte supporto per l’ipotesi alternativa rispetto all’ipotesi nulla.\n\nNel caso specifico, il Fattore di Bayes calcolato è risultato essere circa 147.33, un valore notevolmente alto. Questo suggerisce che i dati osservati sono molto più compatibili con l’ipotesi che la Dr.ssa Bristol possa effettivamente distinguere tra le diverse preparazioni del tè, piuttosto che con l’ipotesi che stia indovinando.\nEtz et al. (2018) concludono che l’approccio bayesiano offre un quadro più robusto e coerente per il test delle ipotesi. A differenza del metodo frequentista, esso non dipende dalla definizione di “risultati più estremi” non osservati e si concentra invece esclusivamente sui dati effettivamente raccolti. Questa focalizzazione, in generale, rende l’approccio bayesiano una soluzione più solida per valutare le ipotesi scientifiche. Per una rivisitazione bayesiana dell’esperimento “The Lady Tasting Tea”, si veda anche la discussione di Doorn et al. (2020).",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#malintesi-sul-valore-p",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#malintesi-sul-valore-p",
    "title": "114  Significatività statistica",
    "section": "114.15 Malintesi sul valore-p",
    "text": "114.15 Malintesi sul valore-p\nSono diffusi molti malintesi sul valore-p. Ne esaminiamo qui quelli più comuni.\nMalinteso 1: Un valore p non significativo significa che l’ipotesi nulla è vera.\nIl malinteso che un valore p non significativo (p &gt; 0.05) implichi l’assenza di effetto o la verità dell’ipotesi nulla è diffuso e porta a conclusioni errate. La chiave per evitare questo errore sta nel comprendere che i valori p riflettono la probabilità dei dati osservati sotto l’ipotesi nulla, e non la probabilità dell’ipotesi stessa. Un valore p elevato non dimostra che l’ipotesi nulla sia vera, ma indica semplicemente che i dati osservati non sono sufficientemente insoliti da rifiutare l’ipotesi nulla con un livello di confidenza predefinito.\nRisultati non significativi possono verificarsi anche quando esiste un effetto reale, ma i dati non sono abbastanza estremi da superare la soglia di significatività statistica.\nInvece di concludere affrettatamente l’assenza di effetto da un valore p non significativo, dovremmo riconoscere l’ambiguità e considerare altre possibilità. Dichiarazioni come “non c’era differenza” dovrebbero essere riformulate in termini di assenza di differenza statisticamente significativa, lasciando aperta la questione dell’esistenza di un effetto reale.\nL’approccio bayesiano offre una prospettiva diversa che può essere particolarmente utile per interpretare risultati non significativi. A differenza dei valori p, che si limitano a valutare la probabilità dei dati sotto l’ipotesi nulla, l’inferenza bayesiana permette di calcolare direttamente la probabilità delle ipotesi date i dati.\nL’approccio bayesiano, quindi, non si limita a rifiutare o non rifiutare l’ipotesi nulla, ma quantifica la forza dell’evidenza a favore di un’ipotesi rispetto all’altra, fornendo una conclusione più informativa rispetto al semplice “non posso rifiutare l’ipotesi nulla”.\nMalintesto 2: Un valore p significativo significa che l’ipotesi nulla è falsa.\nCome spiegato in precedenza, il valore-p quantifica la “sorpresa” suscitata dai dati, alla luce dell’ipotesi nulla. Non ci dice niente sull’ipotesi che abbiamo assunto per quantificare la “sorpresa”.\nMalinteso 3: Un valore p significativo significa che è stato scoperto un effetto importante.\nLa distinzione tra “significatività statistica” e “rilevanza pratica” è fondamentale: mentre la prima indica semplicemente che un risultato è improbabile sotto l’ipotesi nulla, la seconda valuta l’effetto nel contesto di applicazioni reali e le sue implicazioni.\nUn effetto statisticamente significativo non garantisce che l’effetto abbia un impatto pratico notevole o utile.\nInoltre, al di là della significatività pratica, l’abitudine di molti psicologi di escludere i predittori che non risultano “statisticamente significativi” è un grossolano errore: la significatività statistica non può essere usata come un metodo per la selezione di variabili in un modello statistico.\nUn p &lt; 0.05 indica che, se l’ipotesi nulla è vera, abbiamo osservato dati che dovrebbero essere considerati sorprendenti. Tuttavia, solo perché i dati sono sorprendenti, non significa che dobbiamo preoccuparcene. È principalmente l’etichetta verbale “significativo” che causa confusione qui: in un contesto frequentista, un effetto “significativo” è un effetto “sorprendente” alla luce di \\(H_0\\), non è necessariamente un effetto “importante”.\nMalinteso 4: Se avete osservato un risultato significativo, la probabilità che abbiate commesso un errore di Tipo 1 (un falso positivo) è del 5%.\nIl malinteso che la presenza di un risultato significativo (per esempio, p &lt; 0.05) indichi una probabilità del 5% di aver commesso un errore di Tipo 1 (falso positivo) riflette una comprensione errata della statistica frequentista. La probabilità del 5% si riferisce al tasso di errore di Tipo 1, che è la proporzione di volte che potremmo aspettarci di rifiutare erroneamente l’ipotesi nulla se questa fosse vera, su molteplici ripetizioni dell’esperimento sotto le stesse condizioni. In altre parole, se potessimo ripetere lo stesso studio infinite volte, osserveremmo risultati falsamente positivi nel 5% di questi studi, assumendo che l’ipotesi nulla sia effettivamente vera in ogni caso.\nTuttavia, una volta che abbiamo raccolto i dati e ottenuto un risultato significativo in un unico studio, non possiamo dire che “la probabilità che questo particolare risultato sia un errore di Tipo 1 è del 5%”. In realtà, in quel momento specifico, l’evento (commettere un errore di Tipo 1) è già accaduto o non è accaduto; la probabilità associata a quel singolo risultato non è più applicabile nel modo in cui potremmo aspettarci intuitivamente. Il risultato è, per così dire, una realtà fissa: o abbiamo rilevato un effetto che in realtà non esiste (errore di Tipo 1), oppure abbiamo correttamente identificato un effetto reale. Senza ulteriori esperimenti o dati, non possiamo determinare con certezza in quale di queste categorie cade il nostro risultato.\nIn breve, il tasso del 5% di errore di Tipo 1 non si applica retroattivamente a un singolo risultato ottenuto, ma piuttosto descrive il comportamento a lungo termine di un test statistico sotto ripetute campionature. Questa distinzione è cruciale per una corretta interpretazione dei risultati degli esperimenti e sottolinea l’importanza di non sovrastimare la certezza di un singolo risultato statistico significativo.\nMalinteso 5: Uno meno il valore p è la probabilità che l’effetto si replichi quando ripetuto.\nIl concetto che 1 meno il valore p rappresenti la probabilità di replicazione di un effetto è un malinteso diffuso. In realtà, la probabilità di replicazione di un effetto non può essere direttamente calcolata dal valore p di un singolo studio a causa della complessità dei fattori coinvolti, tra cui la vera differenza media tra i gruppi. La potenza statistica di un test, che dipende dalla dimensione dell’effetto, dalla dimensione del campione e dal livello di significatività α, fornisce una stima della probabilità di rilevare un effetto significativo se questo effetto esiste davvero. Tuttavia, osservare un effetto significativo in un unico studio (ad esempio, p = 0.03) non significa che vi sia una probabilità del 97% che tale effetto si replichi in studi futuri. La possibilità di replicare un risultato dipende dalla presenza di un vero effetto e dalla potenza statistica del test originale.\nIn sintesi, la replicabilità di un effetto è influenzata da molti fattori e non può essere inferita semplicemente dal valore p di un singolo risultato. La comprensione e l’interpretazione corrette della replicabilità richiedono un’analisi dettagliata della potenza statistica e della dimensione dell’effetto, oltre che della consistenza dei risultati attraverso studi multipli.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/03_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/03_test_ipotesi.html#informazioni-sullambiente-di-sviluppo",
    "title": "114  Significatività statistica",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon May 13 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.4.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nscipy : 1.13.0\nxarray: 2024.3.0\nnumpy : 1.26.4\narviz : 0.18.0\npymc  : 5.14.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., et al. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class demonstration of Bayesian inference. Psychology Learning & Teaching, 19(1), 36–45.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic bulletin & review, 25(1), 219–234.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old infants, melodies are social. Psychological Science, 27(4), 486–501.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>Significatività statistica</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html",
    "title": "115  Test t di Student per campioni indipendenti",
    "section": "",
    "text": "Introduzione\nIn questo capitolo, esamineremo il test \\(t\\) di Student per campioni indipendenti, uno dei test statistici frequentisti più ampiamente utilizzati nella pratica.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#applicazioni-del-test-t-di-student",
    "title": "115  Test t di Student per campioni indipendenti",
    "section": "115.1 Applicazioni del Test t di Student",
    "text": "115.1 Applicazioni del Test t di Student\nIl test t di Student per due campioni indipendenti è un metodo statistico utilizzato per determinare se le medie di due campioni indipendenti sono significativamente diverse. Questo test si applica quando i due campioni sono estratti da popolazioni diverse e non vi è alcuna correlazione tra le osservazioni di un campione e quelle dell’altro.\nPer condurre il test t di Student per due campioni indipendenti, calcoliamo la differenza tra le medie dei due campioni e le stime delle varianze campionarie delle rispettive popolazioni. L’ipotesi nulla del test è che le medie dei due campioni siano uguali, mentre l’ipotesi alternativa a due code è che le medie dei due campioni siano diverse. La statistica del test t viene calcolata come il rapporto tra la differenza delle medie campionarie e la deviazione standard media campionaria.\nSuccessivamente, confrontiamo la statistica t con la distribuzione t di Student con \\(n_1 + n_2 - 2\\) gradi di libertà, dove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni. Calcoliamo quindi il valore-p dalla distribuzione t per determinare la significatività del test.\nEsistono due approcci per stimare la varianza. Se assumiamo che le due popolazioni abbiano la stessa varianza (omoschedasticità), utilizziamo una stima pooled della varianza. Questo metodo è considerato efficiente quando l’omoschedasticità è verificata (argomento correction = False in pg.ttest()). Invece, se supponiamo che le due popolazioni abbiano varianze diverse, utilizziamo due stime separate delle varianze per i due campioni, chiamato test di Welch (argomento correction = True in pg.ttest()). Questo approccio è più robusto quando le varianze dei due gruppi sono significativamente diverse.\nLe principali assunzioni del test t di Student per due campioni indipendenti sono l’indipendenza dei due campioni e la normalità della distribuzione delle popolazioni da cui sono stati estratti i campioni.\nDi seguito è riportato il calcolo della stima della deviazione standard pooled, utilizzata per standardizzare la differenza tra le medie dei due campioni quando l’assunzione di omoschedasticità è verificata:\n\\[\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(s_p\\) è la deviazione standard pooled, \\(n\\) e \\(m\\) sono le dimensioni dei due campioni, \\(s^2_0\\) e \\(s^2_1\\) sono le varianze campionarie dei due gruppi.\nLa statistica del test t è quindi calcolata come:\n\\[\nt = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{1/n_1 + 1/n_2}},\n\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\) sono le medie campionarie dei due gruppi.\n\n115.1.1 Dimostrazione\nPer dimostrare come calcolare la varianza della differenza tra due medie campionarie, supponiamo di avere due campioni casuali indipendenti \\(X_1, X_2, \\dots, X_n\\) e \\(Y_1, Y_2, \\dots, Y_m\\) che sono estratti dalla stessa popolazione con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo \\(\\bar{X}\\) e \\(\\bar{Y}\\) come le medie campionarie di questi due campioni, rispettivamente.\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono date da: \\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n\\] \\[\n\\bar{Y} = \\frac{1}{m} \\sum_{j=1}^m Y_j\n\\]\nLe medie campionarie \\(\\bar{X}\\) e \\(\\bar{Y}\\) sono entrambe stimatori non distorti della media della popolazione \\(\\mu\\). Le loro varianze sono date da:\n\\[\n\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\n\\]\n\\[\n\\text{Var}(\\bar{Y}) = \\frac{\\sigma^2}{m}\n\\]\nSiamo interessati a calcolare la varianza della differenza \\(\\bar{X} - \\bar{Y}\\). Utilizzando le proprietà di varianza per combinazioni lineari di variabili aleatorie indipendenti, otteniamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y})\n\\]\ndato che i termini incrociati si annullano per l’indipendenza di \\(\\bar{X}\\) e \\(\\bar{Y}\\). Sostituendo le varianze di \\(\\bar{X}\\) e \\(\\bar{Y}\\) abbiamo:\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{m}\n\\]\n\\[\n\\text{Var}(\\bar{X} - \\bar{Y}) = \\sigma^2 \\left(\\frac{1}{n} + \\frac{1}{m}\\right)\n\\]\nQuindi, la varianza della differenza tra le due medie campionarie è una combinazione delle varianze delle singole medie, ponderate in base alle dimensioni dei campioni corrispondenti.\nPer giungere alla formula del test \\(t\\) di Student per due campioni indipendenti dobbiamo considerare l’incertezza aggiuntiva che deriva dal fatto che non conosciamo \\(\\sigma\\). Il modo migliore di stimare \\(\\sigma\\) è quello di utilizzare le due deviazioni standard dei campioni (calcolate come stimatori della varianza della popolazione) ponderate per i rispettivi gradi di libertà, come indicato in precedenza per la deviazione standard pooled:\n\\[\ns_p = \\sqrt{\\frac{(n - 1)s^2_x + (m - 1)s^2_y}{n + m - 2}},\n\\]\ndove \\(s_x\\) e \\(s_y\\) sono le deviazioni standard dei due campioni, e \\(n\\) e \\(m\\) sono le numerosità dei due campioni.\n\n\n115.1.2 Un esempio concreto\nEsaminiamo un esempio concreto. Supponiamo di disporre di nove misure del peso per un gruppo di donne e di nove misure di peso per un gruppo di uomini. Ci chiediamo se, nella popolazione, la media del peso dei due gruppi sia diversa.\nCreiamo due array con i dati e li inseriamo in un DataFrame.\n\nwomen_weight = np.array([38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5])\nmen_weight = np.array([67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4])\n\nweight = np.concatenate((women_weight, men_weight))\nprint(weight)\n\n[38.9 61.2 73.3 21.8 63.4 64.6 48.4 48.8 48.5 67.8 60.  63.4 76.  89.4\n 73.3 67.3 61.3 62.4]\n\n\nCreaiamo una variabile che specifica l’appartenenza al gruppo.\n\nis_female = np.repeat([1, 0], 9)\nis_female\n\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\n\n\ndf = pd.DataFrame({\"is_female\": is_female, \"weight\": weight})\ndf\n\n\n\n\n\n\n\n\nis_female\nweight\n\n\n\n\n0\n1\n38.9\n\n\n1\n1\n61.2\n\n\n2\n1\n73.3\n\n\n3\n1\n21.8\n\n\n4\n1\n63.4\n\n\n5\n1\n64.6\n\n\n6\n1\n48.4\n\n\n7\n1\n48.8\n\n\n8\n1\n48.5\n\n\n9\n0\n67.8\n\n\n10\n0\n60.0\n\n\n11\n0\n63.4\n\n\n12\n0\n76.0\n\n\n13\n0\n89.4\n\n\n14\n0\n73.3\n\n\n15\n0\n67.3\n\n\n16\n0\n61.3\n\n\n17\n0\n62.4\n\n\n\n\n\n\n\nQui sotto è riportato un KDE plot per i dati di tutto il campione.\n\ndensity = gaussian_kde(df[\"weight\"])\nx_vals = np.linspace(min(df[\"weight\"]), max(df[\"weight\"]), 1000)\ndensity = density.evaluate(x_vals)\n\nplt.plot(x_vals, density)\nplt.xlabel('Weight')\n_ = plt.ylabel('Density')\n\n\n\n\n\n\n\n\nDal DataFrame estraiamo due array contenenti i valori dei pesi dei due gruppi.\n\nweight_f = df.loc[df[\"is_female\"] == 1, \"weight\"]\nweight_m = df.loc[df[\"is_female\"] == 0, \"weight\"]\n\nCalcoliamo la deviazione standard pooled.\n\ns_pool_num = np.sum(\n    [\n        (len(weight_f) - 1) * np.std(weight_f, ddof=1) ** 2,\n        (len(weight_m) - 1) * np.std(weight_m, ddof=1) ** 2,\n    ]\n)\ns_pool_denom = len(weight_f) + len(weight_m) - 2\n\ns_pool = np.sqrt(np.divide(s_pool_num, s_pool_denom))\ns_pool\n\n12.86771368796942\n\n\nCalcoliamo la statistica test.\n\nt_num = np.mean(weight_f) - np.mean(weight_m)\nt_denom = s_pool * np.sqrt(1 / len(weight_f) + 1 / len(weight_m))\nT = np.divide(t_num, t_denom)\nT\n\n-2.7842353699254567\n\n\nI gradi di libertà sono:\n\nlen(weight_f) + len(weight_m) - 2\n\n16\n\n\nIl valore-p è uguale a\n\nstats.t.cdf(T, df=16) * 2\n\n0.013265602643801042\n\n\nRifacciamo ora i calcoli usando la funzione ttest del pacchatto pingouin. L’argomento paired = False specifica che i due campioni sono indipendenti; l’argomento correction=False specifica che non verrà usata la correzione di Welch per varianze separate.\n\nres = pg.ttest(weight_m, weight_f, paired=False, correction=False)\nprint(res)\n\n               T  dof alternative     p-val          CI95%   cohen-d   BF10  \\\nT-test  2.784235   16   two-sided  0.013266  [4.03, 29.75]  1.312501  4.251   \n\n           power  \nT-test  0.743519  \n\n\nIl risultato conferma quanto trovato in precedenza attraverso i calcoli effettuati. Il valore-\\(p\\) indica che possiamo rifiutare l’ipotesi nulla di uguaglianza delle medie delle due popolazioni. Quindi, possiamo concludere con un livello di confidenza del 95% che la media del peso dei maschi nella popolazione è superiore alla media del peso delle femmine nella popolazione.\nSe vogliamo un test più robusto, che non assume l’omogeneità delle varianze, usiamo la correzione di Welch:\n\nres = pg.ttest(weight_m, weight_f, paired=False, correction=True)\nprint(res)\n\n               T        dof alternative     p-val         CI95%   cohen-d  \\\nT-test  2.784235  13.113752   two-sided  0.015384  [3.8, 29.98]  1.312501   \n\n         BF10     power  \nT-test  4.251  0.743519  \n\n\nLa statistica test resta immutata. Quello che cambiano sono i gradi di libertà. Con questa correzione dei gradi di libertà, il p-valore diventa più grande.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#interpretazione-dei-risultati",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#interpretazione-dei-risultati",
    "title": "115  Test t di Student per campioni indipendenti",
    "section": "115.2 Interpretazione dei Risultati",
    "text": "115.2 Interpretazione dei Risultati\nIl test t di Student per campioni indipendenti ha generato un p-valore di 0.013, inferiore alla soglia di significatività di α = 0.05. Questo indica che la differenza osservata tra i gruppi è statisticamente significativa. Tuttavia, anziché limitarci a etichettare il risultato come “statisticamente significativo”, è importante considerare cosa implica questo esito nel contesto della ricerca.\nIn sostanza, il basso p-valore ci porta a rifiutare l’ipotesi nulla, suggerendo che è improbabile che le differenze osservate nei dati siano dovute al caso. Questo ci permette di concludere con una certa fiducia che esiste una differenza reale tra le medie delle popolazioni da cui i campioni sono stati estratti. Questa interpretazione apre la strada a ulteriori indagini sulle cause di tale differenza e sulle loro implicazioni teoriche o pratiche.\nSe il p-valore fosse stato superiore alla soglia di significatività α, avremmo interpretato il risultato in modo diverso. Un p-valore maggiore di α indica che i dati osservati non sono incompatibili con l’ipotesi nulla. In altre parole, non avremmo avuto motivi statistici sufficienti per rifiutare l’ipotesi nulla. Tuttavia, è importante sottolineare che questo non equivale a dimostrare che l’ipotesi nulla sia vera; piuttosto, i dati non forniscono evidenza sufficiente per confutarla.\nIn pratica, la non rifiutazione dell’ipotesi nulla significa che i dati sono compatibili sia con l’ipotesi nulla sia con altre possibili ipotesi sulle caratteristiche della popolazione. Di conseguenza, in assenza di evidenza contraria, ci asteniamo dal fare affermazioni conclusive e manteniamo una posizione di neutralità riguardo l’ipotesi nulla, rimanendo aperti alla possibilità di ulteriori indagini e dati futuri che potrebbero chiarire meglio la questione.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#riportare-i-risultati",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#riportare-i-risultati",
    "title": "115  Test t di Student per campioni indipendenti",
    "section": "115.3 Riportare i risultati",
    "text": "115.3 Riportare i risultati\nPer riportare i risultati si può usare un testo come quello seguente:\n\nAbbiamo condotto un test \\(t\\) di Student per campioni indipendenti per confrontare le medie dei due gruppi. I risultati indicano una differenza tra le medie dei gruppi (\\(t\\)(16) = 2.78, \\(p\\) = 0.013). L’intervallo di confidenza al 95% per la differenza delle medie è tra 4.03 e 29.75. L’ampiezza dell’effetto, misurata con Cohen’s \\(d\\), è stata di 1.31, indicando un effetto grande secondo le convenzioni comunemente accettate. La potenza statistica del test, calcolata post hoc, è stata del 74.4%, indicando una buona probabilità di rilevare un effetto, se presente.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#test-unidirezionali-e-bidirezionali",
    "title": "115  Test t di Student per campioni indipendenti",
    "section": "115.4 Test Unidirezionali e Bidirezionali",
    "text": "115.4 Test Unidirezionali e Bidirezionali\nIl criterio secondo il quale un p-valore inferiore a α indica una “significatività statistica” è comune sia nei test bidirezionali sia nei test unidirezionali, ma l’applicazione differisce a seconda della natura dell’ipotesi testata.\n\n115.4.1 Test Bidirezionale\nNel caso di un test bidirezionale, le ipotesi sono formulate come segue: - Ipotesi nulla (H₀): \\(\\mu_1 = \\mu_2\\) (cioè, \\(\\mu_1 - \\mu_2 = 0\\)); si assume uguaglianza delle varianze (\\(\\sigma^2_1 = \\sigma^2_2\\)). - Ipotesi alternativa (H₁): \\(\\mu_1 \\neq \\mu_2\\); ancora con uguaglianza delle varianze.\nLa statistica test è calcolata come $ {Y}_1 - {Y}_2 $, dove \\(\\bar{Y}_1\\) e \\(\\bar{Y}_2\\) sono le medie campionarie dei due gruppi. La regione di rifiuto dell’ipotesi nulla è equamente divisa tra le due code della distribuzione della statistica test, con α/2 per coda.\n\n\n115.4.2 Test Unidirezionale\nPer i test unidirezionali, la direzione della differenza che si sta testando è cruciale:\n\nQuando si testa se \\(\\mu_1\\) è minore di \\(\\mu_2\\):\n\nIpotesi nulla (H₀): \\(\\mu_1 \\geq \\mu_2\\);\nIpotesi alternativa (H₁): \\(\\mu_1 &lt; \\mu_2\\).\n\nLa statistica test è calcolata come $ {Y}_1 - {Y}_2 $. Se questa differenza è significativamente negativa (cioè cade nella coda sinistra oltre il valore critico), supporta H₁.\nQuando si testa se \\(\\mu_1\\) è maggiore di \\(\\mu_2\\):\n\nIpotesi nulla (H₀): \\(\\mu_1 \\leq \\mu_2\\);\nIpotesi alternativa (H₁): \\(\\mu_1 &gt; \\mu_2\\).\n\nAnche qui, la statistica test è $ {Y}_1 - {Y}_2 $. Un risultato che supera il valore critico nella coda destra indica supporto per H₁.\n\nIn ogni tipo di test unidirezionale, la regione di rifiuto occupa l’intero α dell’area sotto la curva di densità, ma è posizionata completamente nella coda specificata dall’ipotesi alternativa.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#considerazioni-sugli-errori-di-tipo-i-e-tipo-ii",
    "title": "115  Test t di Student per campioni indipendenti",
    "section": "115.5 Considerazioni sugli Errori di Tipo I e Tipo II",
    "text": "115.5 Considerazioni sugli Errori di Tipo I e Tipo II\nLa scelta di un livello di significatività \\(\\alpha = 0.05\\) implica che, nel contesto di un test d’ipotesi, esiste una probabilità del 5% di commettere un errore di Tipo I. Questo tipo di errore si verifica quando l’ipotesi nulla è vera ma, a causa della variabilità casuale nei dati del campione, otteniamo risultati abbastanza estremi da rifiutare erroneamente \\(H_0\\).\nUn errore di Tipo II, invece, si verifica quando l’ipotesi nulla è falsa, ma i dati del campione non sono sufficientemente estremi da giustificare il suo rifiuto. La probabilità di commettere un errore di Tipo II è spesso influenzata dalla dimensione del campione: campioni più piccoli tendono ad avere una potenza statistica inferiore, aumentando il rischio di non rifiutare \\(H_0\\) quando sarebbe appropriato farlo. La potenza statistica di un test, che rappresenta la probabilità di rifiutare correttamente l’ipotesi nulla quando è falsa, può essere stimata, ma questa stima può diventare complessa.\nPer i modelli statistici complessi, la stima della potenza può essere particolarmente difficile. Non solo i calcoli possono essere intricati, ma non esiste un metodo unico e standardizzato per effettuare tali stime, richiedendo l’introduzione di diverse assunzioni.\nLa funzione ttest del pacchetto pingouin offre un modo per calcolare la potenza di un test in contesti di test statistici relativamente semplici.",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/frequentist_inference/04_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/frequentist_inference/04_two_ind_samples.html#informazioni-sullambiente-di-sviluppo",
    "title": "115  Test t di Student per campioni indipendenti",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Tue Jul 30 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.6.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nnumpy     : 1.26.4\npingouin  : 0.5.4\npandas    : 2.2.2\nscipy     : 1.14.0\nseaborn   : 0.13.2\nmatplotlib: 3.9.1\narviz     : 0.18.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Frequentismo",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>Test t di Student per campioni indipendenti</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/introduction_replication_crisis.html",
    "href": "chapters/replication_crisis/introduction_replication_crisis.html",
    "title": "Introduzione",
    "section": "",
    "text": "In psicologia, nelle scienze sociali e in altre discipline è in corso una Riforma Metodologica, scaturita da una profonda crisi che ha colpito la scienza contemporanea: la crisi di replicazione dei risultati delle ricerche. Un esempio emblematico è rappresentato dal sito Retraction Watch, che monitora le ritrattazioni di studi scientifici. Questa crisi mina la credibilità della ricerca scientifica e ha spinto a una revisione radicale delle metodologie alla base delle scienze psicologiche e di altre discipline affini (Korbmacher et al., 2023). Le cause della crisi di replicazione sono molteplici: frodi, pratiche di ricerca scorrette e incentivi distorti offerti dal sistema accademico. Una delle cause più rilevanti per un corso sull’analisi dei dati psicologici è l’uso delle tecniche inferenziali di stampo frequentista, che ha contribuito alla proliferazione di pubblicazioni contenenti falsi positivi.\nUn articolo di Altmejd et al. (2019) identifica alcuni fattori semplici ma altamente predittivi della replicabilità degli studi: il campione era di dimensioni adeguate? I ricercatori hanno ottenuto un risultato appena sotto la soglia di significatività di p = 0.05? (Spesso un articolo può rivendicare un risultato “significativo” se questa soglia viene raggiunta, e molti utilizzano vari trucchi statistici per superare tale limite.) Lo studio ha rilevato un effetto sull’intera popolazione studiata o ha individuato un “effetto di interazione” (ad esempio, un effetto presente solo in un segmento più piccolo della popolazione), che è molto meno probabile che si riproduca?\nÈ emerso inoltre che prevedere la replicazione di uno studio è sorprendentemente semplice. Non è necessario un approfondimento della metodologia statistica né un esame rigoroso dei dati, né tantomeno una scrupolosa analisi delle teorie più esoteriche per individuare errori sottili: questi articoli presentano problemi evidenti, a livello superficiale. Uno studio pubblicato su Nature ha coinvolto scienziati in una scommessa su quali studi di scienze sociali sarebbero stati replicati. Camerer et al. (2018) ha scoperto che le previsioni degli scienziati in questo mercato delle scommesse erano estremamente accurate nel determinare quali articoli avrebbero avuto successo nella replicazione.\nUlteriori ricerche hanno dimostrato che non è nemmeno necessario consultare esperti del settore per indovinare quali studi resisteranno a un esame rigoroso. Uno studio di Hoogeveen et al. (2020) ha coinvolto partecipanti senza un background professionale nelle scienze sociali, chiedendo loro di leggere articoli di psicologia e prevedere se questi si sarebbero replicati. “I non-esperti senza una formazione professionale nelle scienze sociali sono in grado di prevedere la replicabilità degli studi con una precisione superiore al caso,” conclude lo studio, “basandosi esclusivamente su semplici descrizioni verbali degli studi.”\nSebbene i non esperti non siano stati altrettanto precisi nelle loro previsioni rispetto agli scienziati nello studio pubblicato su Nature, il fatto che siano comunque riusciti a individuare molte replicazioni fallite suggerisce che molti di questi studi presentano difetti evidenti, riconoscibili anche da chi non è un addetto ai lavori.\nLa pubblicazione di un articolo peer-reviewed non rappresenta l’ultimo passo del processo scientifico. Dopo la pubblicazione, altri studi potrebbero citare l’articolo originale, diffondendo eventuali errori o fraintendimenti. Uno studio di Yang et al. (2020) mostra che non esiste alcuna correlazione tra la replicabilità di uno studio e la sua frequenza di citazione. “Gli studi falliti si diffondono nella letteratura scientifica con la stessa rapidità degli studi replicabili,” affermano Yang et al. (2020). Questo solleva una domanda: se gli scienziati sono abbastanza bravi nel prevedere se uno studio si replicherà, perché sono altrettanto inclini a citare studi non replicabili quanto quelli validi?\nQueste considerazioni suggeriscono che la crisi di replicazione non richiede solo una revisione metodologica, ma è il sintomo di un sistema scientifico che necessita di un ripensamento più ampio. Le riviste scientifiche non sono sufficientemente responsabili per la pubblicazione di articoli discutibili, e il sistema accademico promuove incentivi distorti. In alcuni casi, la cultura accademica sembra addirittura incentivare la produzione di ricerche di bassa qualità. La pressione a pubblicare un elevato numero di articoli favorisce chi riesce a farlo rapidamente, spesso ricorrendo a “scorciatoie”. Di conseguenza, si è creato un sistema in cui gli incentivi continuano a promuovere la cattiva ricerca, nonostante si comprenda sempre meglio cosa costituisca una ricerca di qualità.\nIn questa sezione della dispensa, ci concentreremo su uno dei problemi che stanno alla base della crisi della riproducibilità dei risultati della ricerca, ovvero i limiti dell’inferenza frequentista (Baker, 2016). Analizzeremo gli errori di tipo S e di tipo M, concetti introdotti da Gelman & Carlin (2014), che hanno contribuito a migliorare la comprensione dei limiti della statistica frequentista. Inoltre, discuteremo alcuni possibili metodi per affrontare la crisi e le implicazioni che derivano dall’integrità della ricerca.\n\n\n\n\nAltmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson, M., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the replicability of social science lab experiments. PloS one, 14(12), e0225826.\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J., Johannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et al. (2018). Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015. Nature human behaviour, 2(9), 637–644.\n\n\nGelman, A., & Carlin, J. (2014). Beyond Power Calculations: Assessing Type S (Sign) and Type M (Magnitude) Errors. Perspectives on Psychological Science, 9(6), 641–651.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020). Laypeople can predict which social-science studies will be replicated successfully. Advances in Methods and Practices in Psychological Science, 3(3), 267–285.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep replicability of scientific findings using human and artificial intelligence. Proceedings of the National Academy of Sciences, 117(20), 10762–10768.",
    "crumbs": [
      "Crisi",
      "Introduzione"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html",
    "href": "chapters/replication_crisis/01_crisis.html",
    "title": "116  La Crisi della Replicazione",
    "section": "",
    "text": "Introduzione\nQuesto capitolo introduce la crisi di replicazione dei risultati della ricerca in psicologia, esplorando le cause principali di questo fenomeno e mettendo in evidenza il ruolo che l’approccio statistico frequentista ha avuto nel contribuire a questa crisi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#feeling-the-future",
    "href": "chapters/replication_crisis/01_crisis.html#feeling-the-future",
    "title": "116  La Crisi della Replicazione",
    "section": "116.1 Feeling the Future",
    "text": "116.1 Feeling the Future\nIl 2011 ha rappresentato un punto di svolta per la comunità scientifica, segnando l’inizio della cosiddetta “crisi della replicazione”. Questo fenomeno, pur non influenzando direttamente la vita quotidiana della maggior parte delle persone, inclusi molti psicologi, ha avuto profonde ripercussioni sul mondo della ricerca, specialmente in psicologia, il campo più colpito. Per coloro con una conoscenza anche solo basilare della statistica, e che erano più interessati alla ricerca della verità che all’accumulo di citazioni o all’avanzamento di carriera, il 2011 è stato percepito come un vero e proprio “Anno Zero”. Questo momento cruciale ha messo in luce problemi fondamentali nei metodi di ricerca e nell’interpretazione dei risultati, avviando un processo di ripensamento delle pratiche scientifiche che è ancora in corso.\n\n116.1.1 La Scoperta di Frodi e Risultati Controversi\n\n116.1.1.1 Il Caso Diederik Stapel\nUno dei primi segnali della crisi fu la scoperta della frode scientifica commessa da Diederik Stapel, una stella nascente della psicologia sociale e professore presso l’Università di Tilburg nei Paesi Bassi, aveva attirato l’attenzione con una serie di articoli sensazionali: uno suggeriva che mangiare carne rendeva le persone più antisociali; un altro sosteneva che le persone sono più inclini al razzismo se l’ambiente circostante è pieno di rifiuti. Tuttavia, si scoprì che per quegli studi, e molti altri, non aveva mai condotto gli esperimenti né raccolto i dati. Li aveva semplicemente inventati. A volte le frodi accadono. Stapel fu scoperto (alla fine), licenziato e decine dei suoi articoli furono ritirati.\n\n\n116.1.1.2 Lo Studio “Feeling the Future” di Daryl Bem\nNello stesso anno, Daryl Bem della Cornell University pubblicò uno studio intitolato “Feeling the Future” (Bem, 2011), che avrebbe scosso ulteriormente le fondamenta della psicologia sociale. Lo studio di Bem si inseriva nella tradizione degli esperimenti di “priming”, una tecnica ampiamente utilizzata in psicologia sociale dagli anni ’70. Gli esperimenti di priming tipicamente coinvolgevano studenti universitari, remunerati con modeste somme o crediti accademici. I partecipanti venivano esposti a determinati concetti per poi osservare come questi influenzassero il loro comportamento successivo. Un celebre esempio è lo studio di John Bargh del 1996, che dimostrò come l’esposizione a parole associate all’età avanzata inducesse i soggetti a camminare più lentamente (Bargh et al., 1996). Un altro studio del 2006 rivelò che il priming con concetti legati al denaro rendeva le persone meno propense ad aiutare gli altri. Questi studi sembravano dimostrare una straordinaria malleabilità della mente umana, suggerendo che il nostro comportamento potesse essere inconsciamente manipolato da sottili segnali ambientali. Tuttavia, lo studio di Bem introdusse un elemento nuovo in questo paradigma sperimentale.\nTra i vari esperimenti condotti da Bem, uno in particolare si distingueva. I soggetti venivano esposti a una parola con connotazione positiva o negativa e successivamente dovevano valutare rapidamente la piacevolezza di alcune immagini. Fin qui, nulla di insolito. La svolta radicale consisteva nel fatto che in metà delle prove, il priming avveniva dopo che i soggetti avevano già visto e valutato l’immagine (Bem, 2011).\nSorprendentemente, i risultati mostravano che il priming funzionava anche in queste condizioni: i partecipanti erano più veloci a giudicare piacevoli le immagini quando successivamente venivano esposti a una parola positiva. Questo effetto risultava statisticamente significativo, con un p-value di 0.01, sufficiente secondo gli standard correnti per rifiutare l’ipotesi nulla.\nBem interpretò questi risultati come prova della chiaroveggenza, una conclusione che suscitò notevoli controversie e ridicolizzò la psicologia. Gli altri otto esperimenti dello studio, tutti basati su classici paradigmi della psicologia sociale con l’ordine temporale invertito, mostrarono risultati altrettanto significativi.\nQuesti risultati ponevano la comunità scientifica di fronte a un dilemma: accettare l’esistenza di fenomeni paranormali o mettere in discussione le pratiche statistiche e metodologiche consolidate nella disciplina. Bem stesso continua a sostenere la validità dei suoi risultati come prova dell’esistenza di capacità precognitive.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#pratiche-di-ricerca-disoneste-e-loro-conseguenze",
    "href": "chapters/replication_crisis/01_crisis.html#pratiche-di-ricerca-disoneste-e-loro-conseguenze",
    "title": "116  La Crisi della Replicazione",
    "section": "116.2 Pratiche di Ricerca Disoneste e Loro Conseguenze",
    "text": "116.2 Pratiche di Ricerca Disoneste e Loro Conseguenze\nLo studio di Bem, che portava a conclusioni insensate, si rivelò un catalizzatore per un esame critico delle pratiche di ricerca in psicologia, innescando un dibattito che avrebbe avuto profonde ripercussioni sull’intera disciplina (Ritchie et al., 2012).\nGià nel 2005, John Ioannidis dell’Università di Stanford aveva previsto la crisi imminente nel suo articolo “Why Most Published Research Findings Are False” (Ioannidis, 2005). Il nucleo della critica di Ioannidis riguardava l’approccio interpretativo dei dati sperimentali. Secondo la sua analisi, il problema fondamentale risiedeva nel fatto che molti scienziati non valutavano correttamente la probabilità che la loro ipotesi fosse vera alla luce dei dati raccolti. Al contrario, seguendo l’approccio tradizionale ispirato ai lavori di Bernoulli e Fisher, si concentravano sulla probabilità di ottenere i dati osservati nell’ipotesi che la loro teoria fosse falsa.\n\n116.2.1 P-hacking e HARKing\nLa psicologia, come molte altre discipline scientifiche, si trova spesso a confrontarsi con le “questionable research practices” (pratiche di ricerca discutibili), ovvero quell’insieme di comportamenti o azioni adottate dai ricercatori durante il processo di conduzione e comunicazione della ricerca scientifica che possono compromettere l’integrità e l’affidabilità dei risultati ottenuti. Queste pratiche includono il “P-hacking”, in cui i ricercatori manipolano i dati o le analisi statistiche per ottenere risultati significativi; il “HARKing” (Hypothesizing After Results are Known), in cui le ipotesi vengono formulate retrospettivamente per adattarsi ai risultati ottenuti; e la “presentazione selettiva dei risultati”, dove vengono presentati solo i risultati che supportano le ipotesi, tralasciando quelli non significativi o contraddittori.\nLa pressione per ottenere risultati “statisticamente significativi”, insieme all’uso di campioni di piccole dimensioni, porta alla proliferazione di falsi positivi come conseguenza dell’adozione di pratiche di ricerca discutibili. Simmons, Nelson e Simonsohn hanno dimostrato come, attraverso l’impiego di tali pratiche, sia semplice ottenere risultati statisticamente significativi (Nelson et al., 2018).\nL’uso di queste pratiche è molto diffuso nella ricerca e l’approccio statistico frequentista è particolarmente vulnerabile a tali manipolazioni.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "href": "chapters/replication_crisis/01_crisis.html#la-cultura-della-frode-nel-sistema-accademico",
    "title": "116  La Crisi della Replicazione",
    "section": "116.3 La Cultura della Frode nel Sistema Accademico",
    "text": "116.3 La Cultura della Frode nel Sistema Accademico\nIl sistema accademico stesso, con i suoi incentivi alla pubblicazione e al finanziamento, incoraggia indirettamente queste pratiche.\n\n116.3.1 Il Caso Brian Wansink\nUn caso emblematico è quello di Brian Wansink, ex ricercatore di spicco alla Cornell University, che ricevette cospicui finanziamenti federali durante l’amministrazione Obama. I suoi studi sul comportamento alimentare, come quello sugli uomini che mangiano di più in presenza di donne o sull’effetto dei nomi “attraenti” dati alle verdure sul consumo da parte dei bambini, attirarono grande attenzione mediatica ma si rivelarono in seguito non replicabili. Le conseguenze per Wansink furono severe: diciotto suoi articoli furono ritirati, sette ricevettero “espressioni di preoccupazione”, e quindici furono corretti. Nel 2019, Wansink si dimise da Cornell dopo essere stato giudicato colpevole di cattiva condotta scientifica.\n\n\n116.3.2 Il Caso Sylvain Lesné\nUn altro esempio rilevante riguarda Sylvain Lesné e i suoi coautori che, nel 2006, pubblicarono su Nature un importante articolo sul morbo di Alzheimer. Questo lavoro era fondamentale per lo sviluppo dell’ipotesi amiloide, un meccanismo proposto per spiegare come la malattia affligge le sue vittime. La ricerca sulla malattia di Alzheimer, che colpisce oltre 50 milioni di persone nel mondo, ha ricevuto oltre un miliardo di dollari in finanziamenti governativi fino al 2022, incoraggiata da studi come quello di Lesné.\nNel 2022, il neuroscienziato Matthew Schrag scoprì immagini manipolate in questo e in molti altri articoli di Lesné, inclusi quelli che sostenevano l’ipotesi amiloide. Le immagini erano state manualmente modificate e accorpate per mostrare falsamente supporto alle ipotesi degli articoli. Queste frodi passarono inosservate attraverso i processi di peer review formali di Nature e di altre sei riviste accademiche, venendo infine scoperte solo tramite canali non ufficiali.\nLe conseguenze di queste scoperte furono lente e frammentarie. Gli altri coautori dell’articolo del 2006 alla fine accettarono di ritirarlo, ma non Lesné stesso. La lentezza della risposta a queste evidenze di frode, e il fatto che Lesné continui a essere finanziato dal National Institutes of Health e impiegato presso l’Università del Minnesota, dimostra un fallimento sistemico nell’affrontare la cattiva condotta scientifica.\n\n\n116.3.3 Altri Casi di Rilievo\nHo controllato il contenuto e ho notato che ci sono effettivamente alcune ripetizioni e inconsistenze. Hai ragione nel sospettare che i casi di Dan Ariely e Francesca Gino siano stati trattati separatamente, mentre in realtà sono parte dello stesso scandalo. Inoltre, il caso di Marc Tessier-Lavigne è menzionato due volte. Ecco una versione riscritta e migliorata del testo:\nNel mondo accademico, recenti scandali hanno messo in luce il problema della frode scientifica e le sue conseguenze spesso limitate per i responsabili. Ecco alcuni casi emblematici:\n\nMarc Tessier-Lavigne, ex presidente della Stanford University: Nel 2023, fu costretto a dimettersi dopo la rivelazione di dati falsificati in sue ricerche precedenti presso Genentech. Nonostante lo scandalo, Tessier-Lavigne ha subito conseguenze minime, diventando successivamente CEO di una nuova azienda di ricerca farmacologica. Lo scandalo fu portato alla luce grazie all’indagine condotta da Theo Baker, uno studente diciassettenne di Stanford.\nDan Ariely e Francesca Gino: Questi due rinomati psicologi, noti per le loro ricerche sulla disonestà e il comportamento non etico, sono stati coinvolti in uno scandalo di frode scientifica.\n\nDan Ariely, nel 2021, fu implicato nella fabbricazione di dati in un articolo del 2012 sulla disonestà.\nFrancesca Gino, docente presso la Harvard Business School, è stata accusata di aver presentato lavori contenenti risultati falsificati. Il sito del Dipartimento ora riporta che è in “administrative leave”.\n\n\nL’inefficacia delle istituzioni accademiche nel gestire la frode scientifica riflette una corruzione culturale sistemica. Gli incentivi attuali favoriscono la pubblicazione di risultati positivi e innovativi, spesso a scapito dell’integrità scientifica. Gli studiosi che resistono a queste pressioni rischiano di essere emarginati, mentre chi adotta pratiche discutibili per ottenere risultati desiderati viene spesso premiato con finanziamenti, promozioni e prestigio accademico. In sintesi, la crisi della riproducibilità e la cultura della frode sono problemi diffusi e profondamente radicati nel mondo accademico.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilità",
    "href": "chapters/replication_crisis/01_crisis.html#il-progetto-di-riproducibilità",
    "title": "116  La Crisi della Replicazione",
    "section": "116.4 Il Progetto di Riproducibilità",
    "text": "116.4 Il Progetto di Riproducibilità\n\n116.4.1 L’Iniziativa di Brian Nosek\nNel 2011, Brian Nosek dell’Università della Virginia avviò il Progetto di Riproducibilità (Collaboration, 2015), coinvolgendo 270 ricercatori nel tentativo di replicare cento studi di psicologia. L’obiettivo era ripetere gli esperimenti originali, utilizzando gli stessi metodi ma con nuovi campioni, per verificare la solidità e la replicabilità dei risultati precedentemente pubblicati.\nI risultati di questo imponente lavoro, pubblicati nel 2015, furono a dir poco sconvolgenti. Dei cento studi esaminati, ben novantasette avevano inizialmente riportato risultati statisticamente significativi. Tuttavia, il team di Nosek riuscì a replicare questi risultati solo in trentasei casi. Non solo: le dimensioni degli effetti nelle replicazioni risultarono, in media, dimezzate rispetto agli studi originali. Inoltre, più della metà di queste dimensioni degli effetti cadeva al di fuori degli intervalli di confidenza al 95% riportati nei lavori originali.\n\n\n116.4.2 Studi Successivi\nQuesti risultati sono stati ulteriormente corroborati da numerosi studi successivi, tra cui una ricerca più recente basata su tecniche di machine learning, che ha esaminato studi di psicologia pubblicati in sei importanti riviste nell’arco di vent’anni. Questa ricerca suggerisce che poco più della metà di questi articoli di psicologia non supererebbe i test di replicazione (Youyou et al., 2023). Discipline come la psicologia sociale sono state oggetto di particolare preoccupazione, con un tasso di replicazione del solo 25% riportato dal Progetto di Riproducibilità (Collaboration, 2015). Questo dato è in linea con il lavoro di Youyou et al. (2023), che ha mostrato come la replicabilità degli articoli di psicologia vari considerevolmente per sottocampo, con la psicologia sociale che mostra un tasso di replicazione stimato del 37%, un risultato leggermente più incoraggiante rispetto a quanto riportato in precedenza, ma ancora tra i più bassi dei sottocampi esaminati. Altri settori come la psicologia dello sviluppo, cognitiva e clinica hanno mostrato tassi di replicazione stimati rispettivamente del 36%, 42% e 44%, mentre aree come la psicologia delle organizzazioni e della personalità hanno mostrato tassi leggermente più incoraggianti (50% e 55%, rispettivamente). Complessivamente, le evidenze suggeriscono che le preoccupazioni diffuse sulla robustezza e replicabilità dei risultati della ricerca psicologica siano fondate. Sebbene il problema non sia limitato esclusivamente alla psicologia, le questioni rilevate in questo campo hanno ricevuto notevole attenzione a causa dell’apparente portata del fenomeno.\nQuesti risultati confermavano in modo drammatico le previsioni formulate anni prima da John Ioannidis e Dennis Lindley. Le loro avvertenze riguardo alla possibilità che una larga parte, se non la maggioranza, dei risultati scientifici pubblicati potesse essere falsa, si rivelavano ora profetiche.\nIl Progetto di Riproducibilità di Nosek ha segnato un punto di svolta nel dibattito sulla crisi della replicazione in psicologia e, più in generale, nelle scienze sociali e biomediche. Ha evidenziato non solo la fragilità di molti risultati ritenuti consolidati, ma anche la necessità di un riesame critico delle pratiche di ricerca e pubblicazione scientifica. Questo ripensamento delle metodologie scientifiche è ancora in atto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "href": "chapters/replication_crisis/01_crisis.html#cause-profonde-della-crisi-della-replicazione",
    "title": "116  La Crisi della Replicazione",
    "section": "116.5 Cause Profonde della Crisi della Replicazione",
    "text": "116.5 Cause Profonde della Crisi della Replicazione\nLa crisi della replicazione in psicologia e in altre scienze ha radici profonde e non può essere attribuita esclusivamente a pratiche di ricerca disoneste. Diverse cause immediate sono state identificate, tra cui:\n\nPressione a pubblicare (“publish or perish”): L’intensa pressione sui ricercatori a pubblicare prolificamente è un fattore importante che può contribuire a molti dei problemi legati alla crisi della replicazione. La cultura del “publish or perish” mette i ricercatori sotto stress continuo per produrre risultati significativi e pubblicarli rapidamente (Gopalakrishna et al., 2022; Grimes et al., 2018).\nRicerca della novità a ogni costo e incentivi accademici distorti: La ricerca di risultati innovativi e il valore eccessivo attribuito alle scoperte significative incentivano pratiche di ricerca distorte. Questo include la sovrarappresentazione dei risultati positivi e la mancanza di rigore metodologico (Ferguson & Heene, 2012; Ware & Munafò, 2015).\nBassa potenza statistica e scarsità di sforzi di replicazione: Molti studi soffrono di bassa potenza statistica, il che rende difficile ottenere risultati affidabili. Inoltre, la mancanza di sforzi di replicazione contribuisce a mantenere e diffondere risultati non replicabili.\nMancanza di trasparenza nella reportistica: La reportistica selettiva e la flessibilità non dichiarata nei metodi e nei dati sono pratiche comuni che compromettono l’integrità scientifica. Inoltre, la riluttanza a condividere dati e materiali e il bias di pubblicazione, per cui i risultati nulli hanno meno probabilità di essere pubblicati rispetto a quelli statisticamente significativi, aggravano il problema (Bruton et al., 2020; Nosek et al., 2012).\n\n\n116.5.1 La Probabilità Inversa\nOltre a questi fattori, alcuni studiosi sostengono che la radice della crisi della replicazione sia ancora più profonda e risieda nell’approccio statistico stesso, ampiamente adottato dalla comunità scientifica (Chivers, 2024; Gelman & Loken, 2014; Loken & Gelman, 2017). Questo punto di vista suggerisce che le difficoltà nella replicazione dei risultati non siano solo il prodotto di comportamenti individuali discutibili, ma derivino in larga parte da un’interpretazione e un’applicazione problematica dei metodi statistici.\nPer comprendere meglio questa questione, dobbiamo tornare alle basi della statistica inferenziale. L’approccio frequentista, dominante nella ricerca scientifica, si basa sulle probabilità di campionamento. Questo metodo, che risale a Jakob Bernoulli nel XVIII secolo, calcola la probabilità di osservare certi dati assumendo che una determinata ipotesi sia vera. Il famoso “p-value” è un esempio di questa logica: esso indica la probabilità di ottenere risultati estremi quanto o più estremi di quelli osservati, supponendo che l’ipotesi nulla sia vera.\nTuttavia, questo approccio ha un limite fondamentale: non ci dice direttamente quanto è probabile che la nostra ipotesi sia vera alla luce dei dati raccolti. In altre parole, non fornisce una “probabilità inferenziale”, cioè la probabilità che l’ipotesi sia corretta in base ai risultati ottenuti. Qui entra in gioco l’approccio bayesiano. Il teorema di Bayes offre un metodo per calcolare proprio questa probabilità inferenziale. L’approccio bayesiano tiene conto non solo dei dati osservati, ma anche delle conoscenze pregresse (le “prior”) relative all’ipotesi in esame.\nLa differenza tra questi due approcci è cruciale. Mentre il p-value ci dice quanto sono improbabili i nostri dati se l’ipotesi nulla è vera, l’approccio bayesiano ci fornisce la probabilità che la nostra ipotesi sia vera alla luce dei dati raccolti e delle conoscenze precedenti.\n\n\n116.5.2 Implicazioni per la Pratica Scientifica\nQuesta distinzione ha implicazioni profonde per la pratica scientifica. L’uso esclusivo dell’approccio frequentista può portare a sovrastimare la forza delle evidenze a favore di un’ipotesi, specialmente quando si lavora con campioni piccoli o si conducono molti test statistici, come spesso accade in psicologia.\nAlcune soluzioni proposte per affrontare la crisi della replicazione includono:\n\nAbbassare la soglia di significatività statistica, rendendo più difficile dichiarare un risultato “significativo”.\nRichiedere la preregistrazione delle ipotesi per prevenire l’HARKing (Hypothesizing After Results are Known).\nFar sì che le riviste accettino gli articoli basandosi sui metodi piuttosto che sui risultati, per evitare il bias verso la pubblicazione di risultati solo “positivi” o “nuovi”.\n\nTuttavia, queste soluzioni, pur utili, non affrontano il problema fondamentale dell’interpretazione delle evidenze statistiche. L’adozione di un approccio bayesiano offre una soluzione più radicale, fornendo un quadro più completo e realistico della forza delle evidenze a favore o contro un’ipotesi scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "href": "chapters/replication_crisis/01_crisis.html#guardare-i-dati",
    "title": "116  La Crisi della Replicazione",
    "section": "116.6 Guardare i Dati",
    "text": "116.6 Guardare i Dati\nConsideriamo una simulazione, ispirata da Lakens (2015), che illustra come una pratica apparentemente innocua, quella di osservare i risultati man mano che vengono raccolti all’interno dell’approccio frequentista, possa avere conseguenze enormi sulle conclusioni dello studio, in particolare sulla probabilità di ottenere un risultato statisticamente significativo. Nella simulazione seguente, due campioni casuali vengono estratti dalla stessa popolazione normale di partenza. Di conseguenza, l’“ipotesi nulla” è vera: non c’è differenza tra le medie delle popolazioni di partenza. Tuttavia, a causa della variabilità campionaria, si noterà come il p-valore sia fortemente influenzato da ogni singola osservazione aggiunta al campione.\n\ndef simulate_t_tests(seed, max_sample_size, mu=0, sigma=1):\n    # Imposta il seme per la riproducibilità\n    np.random.seed(seed)\n\n    # Intervallo di grandezza campionaria\n    sample_sizes = range(2, max_sample_size + 1, 2)\n    p_values = []\n\n    # Genera due campioni grandi iniziali da una distribuzione normale\n    full_sample1 = np.random.normal(mu, sigma, max_sample_size)\n    full_sample2 = np.random.normal(mu, sigma, max_sample_size)\n\n    # Simulazione\n    for n in sample_sizes:\n        # Estrai sottoinsiemi incrementali dai campioni completi\n        sample1 = full_sample1[:n]\n        sample2 = full_sample2[:n]\n\n        # Esegui il t-test per il confronto delle medie di due gruppi indipendenti\n        t_stat, p_value = ttest_ind(sample1, sample2)\n        p_values.append(p_value)\n\n    color_fill = \"#b97c7c\"\n    color_edge = \"#8f2727\"\n\n    # Crea il grafico del p-valore in funzione della grandezza campionaria\n    plt.plot(sample_sizes, p_values, marker=\"\", linestyle=\"-\", color=color_fill)\n    plt.axhline(y=0.05, color=color_edge, linestyle=\"--\", label=\"Significatività a 0.05\")\n    plt.xlabel(\"Grandezza Campionaria\")\n    plt.ylabel(\"P-valore\")\n    plt.title(\"P-valore in funzione della grandezza campionaria\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nNelle due simulazioni seguenti, osserviamo come il p-valore cambia progressivamente aumentando la dimensione dei campioni casuali da \\(n = 2\\) a \\(n = 300\\). È evidente come il p-valore vari drasticamente con l’aggiunta di nuove osservazioni ai campioni. Si noti inoltre che, per alcune configurazioni dei due campioni, il p-valore può scendere al di sotto della soglia critica di 0.05 per puro caso. Se un ricercatore interrompesse la raccolta dei dati in quel momento, otterrebbe un risultato “statisticamente significativo”. Tuttavia, questa simulazione non mostra altro che rumore: i due campioni sono stati estratti dalla stessa popolazione.\n\nsimulate_t_tests(seed=12, max_sample_size=300, mu=0, sigma=2)\n\n\n\n\n\n\n\n\n\nsimulate_t_tests(seed=42, max_sample_size=300, mu=0, sigma=2)\n\n\n\n\n\n\n\n\nLa simulazione evidenzia una limitazione fondamentale dell’approccio frequentista: ogni test statistico considera esclusivamente i dati del campione corrente, ignorando le conoscenze accumulate in precedenza. Questa pratica rende il processo decisionale estremamente volatile, poiché, teoricamente, ad ogni nuovo studio si “dimentica” tutta l’informazione derivante dagli studi precedenti.\n\n116.6.1 Analisi Bayesiana\nL’approccio bayesiano offre una soluzione elegante a questo problema. Nel framework bayesiano, la distribuzione a posteriori (cioè, la nostra convinzione aggiornata dopo aver osservato i dati) bilancia sempre l’informazione a priori (ciò che sapevamo prima dell’esperimento) con la verosimiglianza (ciò che i dati ci dicono). Questo equilibrio è particolarmente prezioso quando i dati sono deboli o contengono molto rumore, come nel caso dei dati della simulazione che stiamo discutendo. In tali situazioni, l’informazione a priori assume un ruolo più rilevante, impedendo conclusioni affrettate basate su dati poco informativi.\nPer illustrare questa differenza, consideriamo l’analisi bayesiana dei dati simulati in precedenza. Se questi dati vengono analizzati con l’approccio frequentista, forniscono un risultato “statisticamente significativo”, suggerendo una differenza tra i due gruppi.\nTuttavia, analizzando gli stessi dati con un approccio bayesiano, otteniamo un intervallo di credibilità al 95% compreso tra -0.52 e 1.12. Poiché questo intervallo include lo zero, possiamo affermare, con un livello di certezza soggettiva del 95%, che non c’è una differenza sostanziale tra le medie delle due popolazioni da cui sono stati estratti i campioni.\nQuesta discrepanza nei risultati evidenzia un punto cruciale: l’approccio bayesiano è più resistente ai falsi positivi in presenza di dati rumorosi o campioni piccoli. Invece di forzare una decisione binaria (significativo/non significativo) basata su una soglia arbitraria, l’analisi bayesiana fornisce una rappresentazione più sfumata e realistica dell’incertezza associata alle nostre conclusioni.\nInoltre, l’approccio bayesiano offre il vantaggio di essere cumulativo: ogni nuovo studio non parte da zero, ma incorpora naturalmente le conoscenze precedenti attraverso la distribuzione a priori.\n\nnp.random.seed(12)\nmu=0\nsigma=2\nmax_sample_size=50\nfull_sample1 = np.random.normal(mu, sigma, max_sample_size)\nfull_sample2 = np.random.normal(mu, sigma, max_sample_size)\n\n\nstan_data = {\n    \"N1\": len(full_sample1),\n    \"N2\": len(full_sample2),\n    \"y1\": full_sample1,\n    \"y2\": full_sample2,\n}\nstan_data\n\n{'N1': 50,\n 'N2': 50,\n 'y1': array([ 0.94597166, -1.36285176,  0.48487899, -3.40147127,  1.50628567,\n        -3.06944268,  0.01025416, -0.24045534, -1.61396376,  5.74363879,\n        -1.19564584,  0.94491399,  2.19191224, -2.4303376 ,  2.68471274,\n        -0.24429958,  2.02503095, -1.82773829, -2.05906041,  2.4195929 ,\n         1.00374461,  0.27769235,  1.28152223,  1.05466533, -2.30872047,\n        -4.42666696, -3.36351302, -3.5761885 , -4.43706989, -1.29486156,\n        -1.05680864, -0.07841835,  0.4299519 , -0.76871761, -0.50780816,\n         0.14650415, -1.99440767, -1.42771258,  0.07083269, -1.35589073,\n        -1.14376212, -0.21172463,  2.67166268,  0.63733058, -0.6751905 ,\n        -1.17053656, -0.22983988,  4.48363559, -6.29483304,  1.07027179]),\n 'y2': array([ 0.46498088,  1.7352239 , -2.29642543,  4.22868848,  2.00188552,\n        -0.10282999,  0.3195754 , -1.43252717,  0.10104565, -0.28667483,\n         1.88715078,  0.71528845, -0.16689841,  1.35561221,  1.11212075,\n         0.44543892, -3.05797096,  2.05842235, -2.33251752, -2.0191233 ,\n        -0.21053598,  1.02404432,  2.81545553, -3.37539266,  2.94246799,\n         3.27292581, -0.92278987, -0.40272454, -1.14363346, -1.20659823,\n        -2.67877844, -3.37930584, -0.39865468,  0.51554517,  3.65764143,\n        -2.00200309, -4.18338243,  0.29311941, -0.9327022 ,  0.71244601,\n        -0.79575947, -2.51844703, -1.37775738,  1.6052609 ,  0.54478208,\n        -1.938353  ,  1.74393624, -2.89271889, -1.07296253,  0.39584103])}\n\n\n\nstan_file = os.path.join(project_directory, \"stan\", \"two_means_diff.stan\")\nmodel = CmdStanModel(stan_file=stan_file)\nprint(model.code())\n\n13:52:36 - cmdstanpy - INFO - compiling stan file /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff.stan to exe file /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff\n13:52:47 - cmdstanpy - INFO - compiled model executable: /Users/corradocaudek/_repositories/psicometria/stan/two_means_diff\n\n\ndata {\n  int&lt;lower=0&gt; N1; // Numero di osservazioni nel gruppo 1\n  int&lt;lower=0&gt; N2; // Numero di osservazioni nel gruppo 2\n  vector[N1] y1; // Dati del gruppo 1\n  vector[N2] y2; // Dati del gruppo 2\n}\nparameters {\n  real mu1; // Media del gruppo 1\n  real delta; // Differenza tra le medie\n  real&lt;lower=0&gt; sigma; // Deviazione standard comune\n  real&lt;lower=0&gt; nu; // Gradi di libertà per la distribuzione t\n}\ntransformed parameters {\n  real mu2; // Media del gruppo 2\n  mu2 = mu1 + delta;\n}\nmodel {\n  // Priori\n  mu1 ~ normal(0, 5);\n  delta ~ normal(0, 2); // Priore su delta\n  sigma ~ cauchy(0, 5);\n  nu ~ gamma(2, 0.1); // Priore sulla t-student\n  \n  // Verosimiglianza\n  y1 ~ student_t(nu, mu1, sigma);\n  y2 ~ student_t(nu, mu2, sigma);\n}\ngenerated quantities {\n  real diff; // Differenza tra le medie (alias di delta per chiarezza)\n  diff = delta;\n}\n\n\n\n\nfit = model.sample(\n    data=stan_data,\n    seed=123,\n    chains=4,\n    iter_sampling=2_000,\n    iter_warmup=1_000,\n    show_progress=False,\n    show_console=False,\n)\n\n13:53:34 - cmdstanpy - INFO - CmdStan start processing\n13:53:34 - cmdstanpy - INFO - Chain [1] start processing\n13:53:34 - cmdstanpy - INFO - Chain [2] start processing\n13:53:34 - cmdstanpy - INFO - Chain [3] start processing\n13:53:34 - cmdstanpy - INFO - Chain [4] start processing\n13:53:34 - cmdstanpy - INFO - Chain [1] done processing\n13:53:34 - cmdstanpy - INFO - Chain [2] done processing\n13:53:34 - cmdstanpy - INFO - Chain [4] done processing\n13:53:34 - cmdstanpy - INFO - Chain [3] done processing\n13:53:34 - cmdstanpy - WARNING - Non-fatal error during sampling:\nException: gamma_lpdf: Random variable is inf, but must be positive finite! (in 'two_means_diff.stan', line 22, column 2 to column 21)\nException: gamma_lpdf: Random variable is inf, but must be positive finite! (in 'two_means_diff.stan', line 22, column 2 to column 21)\nConsider re-running with show_console=True if the above output is unclear!\n\n\n\naz.summary(\n    fit,\n    var_names=[\"mu1\", \"mu2\", \"delta\"],\n    round_to=2,\n    hdi_prob=0.95\n)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nmu1\n-0.43\n0.30\n-1.03\n0.15\n0.00\n0.0\n4961.74\n4696.27\n1.0\n\n\nmu2\n-0.15\n0.30\n-0.73\n0.42\n0.00\n0.0\n9396.35\n6530.40\n1.0\n\n\ndelta\n0.28\n0.42\n-0.52\n1.12\n0.01\n0.0\n4850.37\n5211.27\n1.0\n\n\n\n\n\n\n\n\n# Estrai i campioni di delta\ndelta_samples = fit.stan_variable(\"delta\")\n\n# Disegna la distribuzione a posteriori di delta\ncolor_fill = \"#b97c7c\"\ncolor_edge = \"#8f2727\"\nplt.hist(delta_samples, bins=30, density=True, alpha=0.75, color=color_fill)\nplt.axvline(\n    np.mean(delta_samples),\n    color=color_edge,\n    linestyle=\"--\",\n    label=f\"Mean: {np.mean(delta_samples):.2f}\",\n)\nplt.xlabel(\"delta\")\nplt.ylabel(\"Density\")\nplt.title(\"Posterior distribution of delta\")\nplt.legend()\nplt.show()",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "href": "chapters/replication_crisis/01_crisis.html#il-giardino-dei-sentieri-che-si-biforcano",
    "title": "116  La Crisi della Replicazione",
    "section": "116.7 Il Giardino dei Sentieri che si Biforcano",
    "text": "116.7 Il Giardino dei Sentieri che si Biforcano\nLo psicologo Paul Meehl condusse uno studio su un campione di cinquantasettamila studenti delle scuole superiori del Minnesota, indagando su variabili quali religione, abitudini nel tempo libero, ordine di nascita, numero di fratelli, piani post-diploma e numerosi altri aspetti (Meehl, 2012). Complessivamente, le diverse risposte dei partecipanti potevano essere combinate in 990 modi distinti, permettendo analisi del tipo: “Gli studenti appassionati di cucina hanno una maggiore probabilità di essere figli unici?” o “Gli studenti provenienti da famiglie battiste sono più inclini a partecipare a club politici scolastici?”. Meehl evidenziò che, analizzando i dati, il 92% di queste possibili combinazioni risultava in correlazioni statisticamente significative. Queste differenze, sebbene reali, presumibilmente derivano da cause multifattoriali e complesse.\nAndrew Gelman ha denominato questo fenomeno “Il Giardino dei Sentieri che si Biforcano” [Garden of Forking Paths; Gelman & Loken (2013)], riferendosi ai molteplici gradi di libertà a disposizione del ricercatore nell’analisi dei dati. Come nell’esempio di Meehl, è possibile esaminare le differenze intergruppo (se questo è l’oggetto di interesse) da molteplici prospettive. Con un campione sufficientemente ampio, alcune di queste differenze risulteranno “statisticamente significative”. Ciò indica che, in quello specifico campione, quel particolare aspetto dei dati è rilevante. Tuttavia, questa differenza “statisticamente significativa” non sarà necessariamente generalizzabile ad un altro campione, il quale presenterà le proprie idiosincrasie.\nIn altri termini, come sottolineato da Gelman, l’approccio basato sul test dell’ipotesi nulla si limita a “descrivere il rumore”. Da un punto di vista teorico, simili esercizi statistici risultano privi di valore euristico e non contribuiscono in nessun modo all’avanzamento delle conoscenze sul fenomeno oggetto di studio.\nIn un’ottica di inferenza statistica, questo problema è riconducibile al concetto di “p-hacking” o “data dredging”, dove l’esplorazione esaustiva di molteplici ipotesi statistiche su un singolo set di dati può portare a falsi positivi e a una sovrastima della significatività statistica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "href": "chapters/replication_crisis/01_crisis.html#garbage-in-garbage-out",
    "title": "116  La Crisi della Replicazione",
    "section": "116.8 Garbage In, Garbage Out",
    "text": "116.8 Garbage In, Garbage Out\nLa natura della statistica frequentista impone di prendere una decisione dicotomica: o si rifiuta l’ipotesi nulla o non la si rifiuta. Ciò implica che o esiste un effetto reale, oppure non esiste. Con un campione abbastanza grande, è inevitabile trovare qualche effetto, anche se di minima entità.\nUn approccio bayesiano, invece, permette di stimare la dimensione dell’effetto e di fornire una distribuzione di probabilità. Una distribuzione di probabilità è una rappresentazione grafica delle diverse possibilità che potrebbero verificarsi. In questo contesto, si tratta della “probabilità inversa”, ovvero della plausibilità dell’ipotesi alla luce dei dati osservati e delle conoscenze pregresse. Qui, il parametro \\(\\delta\\) rappresenta la differenza tra le due medie ed è il parametro di interesse. Le credenze precedenti su \\(\\delta\\) sono espresse tramite una distribuzione a priori: in questo caso, una distribuzione Normale centrata su 0 con una deviazione standard di 2. La distribuzione a posteriori rappresenta la nostra conoscenza aggiornata su \\(\\delta\\) dopo l’aggiornamento bayesiano. Il parametro \\(\\delta\\) è la nostra ipotesi sulla differenza tra le due medie, e l’inferenza bayesiana riguarda il cambiamento della nostra credenza dopo aver osservato i dati.\nL’approccio frequentista, al contrario, produce una decisione dicotomica che non modifica la nostra concezione dell’ipotesi dopo aver osservato i dati. Assume una determinata ipotesi come vera e verifica se i dati sono coerenti con essa. Tramite il concetto binario di “significatività statistica”, non si modificano le ipotesi di interesse, ma si accettano o si rifiutano le ipotesi nulle.\nSebbene l’approccio frequentista sia spesso considerato “ingenuo” da molti ricercatori, adottare l’approccio bayesiano non rappresenta una soluzione miracolosa ai problemi della scienza contemporanea. Risolve alcuni problemi, ma non altri. In particolare, non affronta la questione degli incentivi accademici che favoriscono la pubblicazione di un elevato numero di articoli, indipendentemente dalla loro qualità. Un principio fondamentale della ricerca è “Garbage in, garbage out”. Se i dati derivano da un disegno di ricerca fallace o poco creativo, se la ricerca non ha un solido fondamento teorico capace di avanzare le nostre conoscenze, o se la qualità delle misurazioni è insufficiente, i dati raccolti sono puro rumore. Nessun metodo statistico, nemmeno quello bayesiano, può trasformare la spazzatura in oro.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#esercizi",
    "href": "chapters/replication_crisis/01_crisis.html#esercizi",
    "title": "116  La Crisi della Replicazione",
    "section": "116.9 Esercizi",
    "text": "116.9 Esercizi\n\nEsercizio 116.1 Esistono numerosi esempi di ricerche che non riescono a essere replicate (posso citare anche uno studio di replicazione che ho condotto io stesso: Caudek et al. (2017)). Un recente caso emblematico è rappresentato dallo studio di Karataş & Cutright (2023) e dal successivo tentativo di replicazione condotto da Moore et al. (2024). Analizzando le quattro principali argomentazioni sollevate da Gelman & Brown (2024) per criticare lo studio di Aungle & Langer (2023), si offra un’interpretazione del perché lo studio di Karataş & Cutright (2023) non sia stato replicato con successo.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/01_crisis.html#informazioni-sullambiente-di-sviluppo",
    "title": "116  La Crisi della Replicazione",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Mon Jul 29 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\npandas    : 2.2.2\nnumpy     : 1.26.4\narviz     : 0.18.0\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of perceived time. Scientific Reports, 13(1), 22432.\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social behavior: Direct effects of trait construct and stereotype activation on action. Journal of personality and social psychology, 71(2), 230–244.\n\n\nBem, D. J. (2011). Feeling the future: experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100(3), 407–425.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020). Personal motivations and systemic incentives: Scientists on questionable research practices. Science and Engineering Ethics, 26(3), 1531–1547.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not reveal response inhibition in lying. Consciousness and Cognition, 55, 232–244.\n\n\nChivers, T. (2024). Everything is Predictable: How Bayesian Statistics Explain Our World. Simon; Schuster.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead theories: Publication bias and psychological science’s aversion to the null. Perspectives on Psychological Science, 7(6), 555–561.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no «fishing expedition» or «p-hacking» and the research hypothesis was posited ahead of time. Department of Statistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science. American scientist, 102(6), 460–465.\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M., & Bouter, L. M. (2022). Prevalence of questionable research practices, research misconduct and their potential explanatory factors: A survey among academic researchers in The Netherlands. PloS one, 17(2), e0263023.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling science trustworthiness under publish or perish pressure. Royal Society open science, 5(1), 171511.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false. PLoS medicine, 2(8), e124.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from p-values just below 0.05. PeerJ, 3, e1142.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories are often uninterpretable. In Improving inquiry in social science (pp. 13–59). Routledge.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E., & Simmons, J. P. (2024). Does thinking about God increase acceptance of artificial intelligence in decision-making? Proceedings of the National Academy of Sciences, 121(31), e2402315121.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia: II. Restructuring incentives and practices to promote truth over publishability. Perspectives on Psychological Science, 7(6), 615–631.\n\n\nRitchie, S. J., Wiseman, R., & French, C. C. (2012). Failing the future: Three unsuccessful attempts to replicate Bem’s ‘Retroactive Facilitation of Recall’Effect. PloS one, 7(3), e33423.\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in research practice: causes, consequences and possible solutions. Addiction, 110(1), 4–8.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide investigation of the replicability of Psychology papers over the past two decades. Proceedings of the National Academy of Sciences, 120(6), e2208863120.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>La Crisi della Replicazione</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html",
    "title": "117  Limiti dell’inferenza frequentista",
    "section": "",
    "text": "Introduzione\nIn questa sezione della dispensa abbiamo esaminato il metodo “tradizionale” per il test di significatività dell’ipotesi nulla (NHST). Comprendere la logica alla base dell’approccio NHST è essenziale poiché questo è stato l’approccio predominante alla statistica inferenziale fin dalla sua introduzione all’inizio del XX secolo e la maggior parte dei ricercatori ancora si affida a questa procedura per analizzare i dati. Tuttavia, recentemente, l’approccio NHST è stato oggetto di aspre critiche, poiché molti ricercatori hanno iniziato a pensare che questo approccio possa creare più problemi di quanti ne risolva. Pertanto, è importante conoscere le critiche mosse alla procedura inferenziale NHST all’interno della comunità scientifica. In questa sezione esamineremo alcuni dei dubbi sorti riguardo a questo approccio.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#luso-del-valore-p-nel-mondo-della-ricerca",
    "title": "117  Limiti dell’inferenza frequentista",
    "section": "117.1 L’uso del valore-\\(p\\) nel mondo della ricerca",
    "text": "117.1 L’uso del valore-\\(p\\) nel mondo della ricerca\nNel suo articolo “Statistical Errors” (2014), Nuzzo evidenzia i limiti dell’approccio NHST nella pratica scientifica Nuzzo (2014). Infatti, sebbene il valore-\\(p\\) sia stato introdotto da Ronald Fisher negli anni ’20, egli non lo ha mai concepito come un test formale. Invece, Fisher lo considerava uno strumento informale per valutare se l’evidenza empirica fosse significativa in un senso colloquiale, ovvero meritevole di attenzione. In pratica, Fisher suggeriva di assumere un’ipotesi nulla e di calcolare la probabilità di osservare un risultato altrettanto estremo o più estremo di quello trovato, se il risultato fosse completamente dovuto alla sola variabilità campionaria. Sebbene sia possibile calcolare il valore-\\(p\\) tramite una procedura matematica, per Fisher esso era solo uno strumento da utilizzare all’interno di un processo decisionale non numerico, in grado di combinare le evidenze empiriche attuali con le conoscenze pregresse del ricercatore. In altre parole, il valore-\\(p\\) rappresentava uno strumento da utilizzare all’interno del processo decisionale, non la conclusione del processo decisionale stesso.\nVerso la fine degli anni ’20, Jerzy Neyman e Egon Pearson, rivali di Fisher, formalizzarono le procedure di decisione statistica con l’obiettivo di renderle “rigorose e oggettive”. In particolare, introdussero i concetti di potere statistico e di falso positivo, ma non utilizzarono la nozione di valore-\\(p\\) come aveva fatto Fisher.\nLe divergenze tra i tre autori portarono a un acceso dibattito, in cui Neyman criticò il lavoro di Fisher come matematicamente “peggiore dell’inutilità”, mentre Fisher definì l’approccio di Neyman “infantile” e “orribile per la libertà intellettuale dell’occidente”.\nDurante questo dibattito, altri autori iniziarono a scrivere manuali di statistica per fornire uno strumento di lavoro ai ricercatori. Poiché molti di questi autori non erano statistici e avevano solo una comprensione superficiale della distinzione tra i vari approcci, crearono un sistema ibrido che utilizzava il valore-\\(p\\) proposto da Fisher all’interno del “sistema rigoroso” proposto da Neyman e Pearson. È in questo contesto che la soglia di un valore-\\(p\\) pari a 0.05 venne definita come “statisticamente significativa”.\nTuttavia, dal punto di vista storico, il valore-\\(p\\) proposto da Fisher aveva un significato molto diverso da quello che viene attribuito oggi nel mondo della ricerca. Come abbiamo visto, il valore-\\(p\\) era solo uno strumento informale utilizzato da Fisher all’interno di un processo decisionale più ampio, e il suo uso all’interno del sistema ibrido creato dai manuali di statistica era privo di giustificazione e fondamento.\nNel 2016 l’American Statistical Association ha pubblicato un articolo nel quale si esprime una grande preoccupazione per l’uso inappropriato che viene fatto del valore-\\(p\\) nella pratica scientifica odierna Wasserstein & Lazar (2016):\n\n\\(P\\)-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone. Researchers often wish to turn a \\(p\\)-value into a statement about the truth of a null hypothesis, or about the probability that random chance produced the observed data. The \\(p\\)-value is neither. It is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself.\n\nL’articolo prosegue affermando che:\n\nScientific conclusions and business or policy decisions should not be based only on whether a \\(p\\)-value passes a specific threshold. Practices that reduce data analysis or scientific inference to mechanical “bright-line” rules (such as “\\(p &lt; 0.05\\)”) for justifying scientific claims or conclusions can lead to erroneous beliefs and poor decision making. A conclusion does not immediately become ‘true’ on one side of the divide and ‘false’ on the other. Researchers should bring many contextual factors into play to derive scientific inferences, including the design of a study, the quality of the measurements, the external evidence for the phenomenon under study, and the validity of assumptions that underlie the data analysis. Pragmatic considerations often require binary, ‘yes-no’ decisions, but this does not mean that \\(p\\)-values alone can ensure that a decision is correct or incorrect. The widespread use of “statistical significance” (generally interpreted as ) as a license for making a claim of a scientific finding (or implied truth) leads to considerable distortion of the scientific process.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#p-hacking",
    "title": "117  Limiti dell’inferenza frequentista",
    "section": "117.2 \\(P\\)-hacking",
    "text": "117.2 \\(P\\)-hacking\nLa pratica del \\(P\\)-hacking rappresenta la principale fallacia associata all’utilizzo del valore-\\(p\\) ed è nota anche come “\\(P\\)-hacking”, “data-dredging”, “snooping”, “fishing”, “significance-chasing” o “double-dipping”. Secondo Uri Simonsohn, docente presso l’Università della Pennsylvania, il \\(P\\)-hacking consiste nel tentativo di provare diverse ipotesi finché non si ottiene il risultato desiderato. Ad esempio, si potrebbe dire: “Quel risultato sembra essere stato ottenuto attraverso il \\(p\\)-hacking, gli autori hanno eliminato una delle condizioni in modo che il valore-\\(p\\) complessivo fosse inferiore a 0.05” oppure “Lei è una \\(p\\)-hacker, controlla sempre i dati mentre vengono raccolti”.\nQuesta pratica ha l’effetto di trasformare uno studio esplorativo, che dovrebbe essere sempre interpretato con cautela, in uno studio (apparentemente) confermativo, il cui risultato appare “robusto”, ma che in realtà ha una probabilità pressoché nulla di essere replicato in studi successivi. Secondo le simulazioni di Simonsohn, il cambiamento di poche decisioni nel processo di analisi dei dati può aumentare fino al 60% il tasso di falsi positivi in un singolo studio.\nIl \\(P\\)-hacking è diffuso soprattutto negli studi che tentano di dimostrare piccoli effetti usando dati molto rumorosi. Un’analisi della letteratura psicologica ha mostrato che i valori-\\(p\\) riportati dagli psicologi tendono a concentrarsi su valori appena superiori alla soglia minima dello 0.05. Questo risultato può essere interpretato come conseguenza della pratica del \\(P\\)-hacking: i ricercatori eseguono molteplici test statistici fino a trovare uno che risulta “statisticamente significativo” e poi riportano solo quello. Come mostra la figura seguente, questa pratica non riguarda solo la psicologia, ma è diffusa in tutti i campi della ricerca scientifica.\n\n\n\nDistribuzione dei valori-\\(p\\) nelle pubblicazioni scientifiche di economia, psicologia e biologia.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#critiche-al-valore-p",
    "title": "117  Limiti dell’inferenza frequentista",
    "section": "117.3 Critiche al valore-\\(p\\)",
    "text": "117.3 Critiche al valore-\\(p\\)\nIl valore-\\(p\\) è stato paragonato a creature noiose e ostinate come le zanzare, ai vestiti nuovi dell’imperatore, ovvero alla tendenza di non voler riconoscere evidenti problemi, ma preferire di far finta di nulla, o ad un intellectual rake sterile, che non porta alcun frutto. Si è anche ironizzato sul fatto che la procedura di statistical hypothesis inference testing venga chiamata così solo per l’acronimo che produce.\nIl valore-\\(p\\) incoraggia un modo di pensare errato, spostando l’attenzione dal problema centrale della ricerca, ovvero la forza della manipolazione sperimentale, alla dimostrazione di una falsa ipotesi che si sa a priori essere falsa (l’ipotesi nulla). Ad esempio, uno studio con più di 19.000 individui ha dimostrato che coloro che incontrano il loro partner online hanno una probabilità minore di divorziare (\\(p &lt;\\) 0,002) e sono più soddisfatti della loro vita matrimoniale (\\(p &lt;\\) 0,001) rispetto a chi non si è conosciuto online. Questo può sembrare un risultato interessante, ma senza considerare la dimensione dell’effetto, ovvero il tasso di divorzio che scende dal 7.67% al 5.96% e l’aumento dell’indice di soddisfazione matrimoniale da 5.48 a 5.64 su una scala a sette punti, il risultato perde di interesse. In generale, la domanda cruciale non è “c’è un effetto o no?” ma piuttosto “qual è la dimensione dell’effetto?”.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#leffetto-sperimentale-è-esattamente-nullo",
    "title": "117  Limiti dell’inferenza frequentista",
    "section": "117.4 L’effetto sperimentale è esattamente nullo?",
    "text": "117.4 L’effetto sperimentale è esattamente nullo?\nUna delle critiche più frequenti alla logica di verifica delle ipotesi statistiche riguarda l’assunzione irrealistica che l’effetto della manipolazione sperimentale sia “esattamente” nullo. Ad esempio, la fisica ci insegna che lo spostamento di un grammo di massa in una stella distante qualche anno luce dalla Terra può influenzare il movimento delle molecole di un gas sulla Terra Borel (1914). Questo ci suggerisce che ogni manipolazione sperimentale produca, in qualche modo, un effetto. Pertanto, secondo Andrew Gelman, il problema non è dimostrare falsa l’ipotesi nulla, ovvero che la manipolazione sperimentale non produca alcun effetto, ma piuttosto valutare se la dimensione dell’effetto è sufficientemente grande da avere un impatto pratico e se l’effetto sia riproducibile. In questo senso, la logica di verifica dell’ipotesi nulla può essere problematica, soprattutto quando si lavora con piccoli campioni e piccoli effetti, come nella maggior parte degli studi in psicologia, poiché può portare ad una sovrastima della dimensione dell’effetto e ad una visione binaria del risultato (vero/falso), invece di concentrarsi sulla stima non distorta della dimensione effettiva dell’effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#attenti-al-valore-p",
    "title": "117  Limiti dell’inferenza frequentista",
    "section": "117.5 Attenti al valore-\\(p\\)!",
    "text": "117.5 Attenti al valore-\\(p\\)!\nConsideriamo il seguente problema. Eseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo a verifica l’ipotesi nulla dell’eguaglianza delle due medie. Sia \\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual è la probabilità che i due campioni siano tratti da distribuzioni con la stessa media?\n\n\\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d) \\(95/100; \\quad\\) (e) sconosciuta.\n\nLa risposta corretta è: (e) sconosciuta. La statistica frequentista definisce le probabilità dei dati condizionatamente alle ipotesi (assunte come vere). Non consente di stabilire la probabilità di un’ipotesi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#la-crisi-della-riprodicibilità-dei-risultati-della-ricerca",
    "title": "117  Limiti dell’inferenza frequentista",
    "section": "117.6 La crisi della riprodicibilità dei risultati della ricerca",
    "text": "117.6 La crisi della riprodicibilità dei risultati della ricerca\nNegli ultimi anni, la mancanza di replicabilità dei risultati della ricerca - inclusa la ricerca psicologica - è diventata un tema di grande rilevanza. In questo contesto, è stato evidenziato che alcuni aspetti del metodo scientifico, in particolare il concetto di valore-p e la pratica di verificare la significatività dell’ipotesi nulla (NHST, Null Hypothesis Significance Testing), potrebbero contribuire a questa “crisi della ricerca scientifica”. Un’analisi più approfondita di questo problema è stata fornita da Gelman (2016), il quale sostiene che la pratica della NHST sia intrinsecamente problematica. Infatti, essa incoraggia il ricercatore a cercare di rigettare un’ipotesi “fantoccio” (straw-man) che è certamente falsa a priori o, almeno, poco interessante dal punto di vista scientifico, a favore di un’ipotesi alternativa che il ricercatore preferisce. In generale, sembra più ragionevole affermare che la differenza tra due condizioni sia molto piccola, piuttosto che affermare che sia esattamente uguale a zero.\nSpesso nei libri di statistica viene trasmesso il messaggio che la NHST sia una forma di “alchimia” che cerca di trasformare la casualità in una sorta di certezza, con l’uso di termini come “confidenza” e “significatività” Gelman (2016). Il processo di raccolta dei dati, analisi e inferenza statistica che ne segue viene poi riassunto in una conclusione espressa in termini di valore-p e di intervallo di confidenza che escludono lo zero. Tuttavia, ciò può dare l’impressione errata che il ricercatore abbia una comprensione completa delle proprietà del fenomeno in questione. Il problema principale della NHST è che spesso produce risultati “statisticamente significativi” in situazioni in cui le caratteristiche del fenomeno non giustificano la conclusione a cui il ricercatore arriva. Questo può portare alla non replicabilità dei risultati della ricerca.\nLa comunità degli statistici ha evidenziato come la non replicabilità dei risultati delle ricerche sia particolarmente evidente quando i ricercatori, utilizzando la metodologia NHST, giungono a conclusioni errate basate sull’osservazione di piccoli campioni con effetti di dimensioni ridotte. Queste condizioni, insieme ad altre, rendono estremamente problematica l’applicazione della NHST. Purtroppo, queste situazioni descrivono molte delle ricerche recenti in psicologia.\nLa statistica è stata definita come un metodo per prendere decisioni razionali in situazioni di incertezza. Gli statistici consigliano ai ricercatori di non solo diventare esperti nelle tecniche statistiche, ma anche di imparare a convivere con l’incertezza, nonostante la sempre crescente sofisticazione delle tecniche disponibili. Convivere con l’incertezza implica evitare di pensare che ottenere un valore-\\(p\\) “statisticamente significativo” significhi risolvere un problema scientifico. Come possiamo allora avere fiducia in ciò che abbiamo appreso dai dati? Una possibile strategia è la replicazione e la convalida esterna, ma nella ricerca in psicologia e nelle scienze sociali, questo può spesso essere difficile da perseguire a causa degli oneri elevati che comporta. Il problema di quali strumenti metodologici e metodi statistici siano più appropriati per indagare sui fenomeni psicologici, senza essere ingannati, rimane dunque un problema aperto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/02_limits_stat_freq.html#commenti-e-considerazioni-finali",
    "title": "117  Limiti dell’inferenza frequentista",
    "section": "117.7 Commenti e considerazioni finali",
    "text": "117.7 Commenti e considerazioni finali\nNon possiamo concludere senza sottolineare la controversia che circonda la nozione di valore-\\(p\\). Pur essendo ancora ampiamente utilizzato e spesso interpretato erroneamente, il valore-\\(p\\) conferisce solo una patina di legittimità ai risultati di studi dubbi, incoraggia cattive pratiche di ricerca e promuove la produzione di falsi positivi. Inoltre, è difficile comprendere appieno il significato di questa nozione. Anche gli esperti, quando chiamati a fornire una definizione di valore-\\(p\\), spesso sbagliano la risposta. Ciò che i ricercatori vogliono sapere è se i risultati della ricerca sono corretti o meno, ma il valore-\\(p\\) non fornisce questa informazione. Non dice nulla sulla dimensione dell’effetto, sulla forza dell’evidenza o sulla probabilità che il risultato sia stato ottenuto casualmente. Quindi, qual è il suo significato? Stuart Buck risponde così:\n\nImagine that you have a coin that you suspect is weighted toward heads. (Your null hypothesis is then that the coin is fair.) You flip it 100 times and get more heads than tails. The \\(p\\)-value won’t tell you whether the coin is fair, but it will tell you the probability that you’d get at least as many heads as you did if the coin was fair. That’s it – nothing more.\n\nIn sintesi, possiamo concludere che il valore-\\(p\\) risponde a una domanda molto specifica che non ha alcuna rilevanza per la validità scientifica dei risultati della ricerca. In un’epoca in cui la crisi della riproducibilità dei risultati è sempre più evidente Baker (2016), il test dell’ipotesi nulla e gli intervalli di confidenza frequentisti sono stati identificati come una delle principali cause del problema, spingendo molti ricercatori a cercare soluzioni alternative.\n\n\n\n\nBaker, M. (2016). Reproducibility Crisis. Nature, 533(7604), 452–454.\n\n\nBorel, E. (1914). Introduction Géométrique. G. Villars, New York.\n\n\nGelman, A. (2016). Commentary on «Crisis in Science? Or Crisis in Statistics! Mixed Messages in Statistics with Impact on Science». Journal of Statistical Research, 48-50(1), 11–12.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian statistics for clinical research. The Lancet, 404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nNuzzo, R. (2014). Statistical Errors. Nature, 506(7487), 150–152.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s statement on p-values: context, process, and purpose. The American Statistician, 70(2), 129–133.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>Limiti dell'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html",
    "href": "chapters/replication_crisis/03_effect_size.html",
    "title": "118  La grandezza dell’effetto",
    "section": "",
    "text": "Introduzione\nLa dimensione dell’effetto (effect size) è un concetto fondamentale nella metodologia della ricerca, utilizzato per quantificare la forza della relazione statistica tra due variabili. Questa misura rappresenta l’entità dell’effetto di un intervento o di un trattamento in modo standardizzato, descrivendo in termini quantitativi l’importanza di un fenomeno osservato.\nÈ cruciale distinguere tra la dimensione dell’effetto e la significatività statistica. Un risultato può essere “statisticamente significativo” pur avendo un effetto di piccole dimensioni, e viceversa. La conoscenza di uno di questi concetti non fornisce automaticamente informazioni sull’altro, evidenziando la necessità di considerare entrambi gli aspetti nell’analisi dei dati.\nL’importanza della dimensione dell’effetto è ampiamente riconosciuta nel campo della ricerca scientifica. Il manuale dell’American Psychological Association (APA) del 2010 ne sottolinea la rilevanza, raccomandando di riportare questa misura negli studi pubblicati. Di conseguenza, la maggior parte degli articoli nelle riviste associate all’APA include la dimensione dell’effetto, generalmente indicata tra parentesi accanto al valore di p.\nNonostante la sua importanza e la prassi di riportarla, la psicologia scientifica spesso mostra una carenza nella corretta valutazione e interpretazione delle dimensioni dell’effetto. Molti ricercatori si limitano a comunicare questi valori senza esaminarli approfonditamente, portando a conclusioni che possono risultare superficiali, poco informative, fuorvianti o addirittura errate. Questa tendenza rivela una sottovalutazione sistematica e una diffusa incomprensione delle dimensioni dell’effetto, anche tra i professionisti della ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "href": "chapters/replication_crisis/03_effect_size.html#misurazione-delleffetto-approcci-e-applicazioni",
    "title": "118  La grandezza dell’effetto",
    "section": "118.1 Misurazione dell’Effetto: Approcci e Applicazioni",
    "text": "118.1 Misurazione dell’Effetto: Approcci e Applicazioni\nTra le metriche più adottate per quantificare la dimensione dell’effetto si annoverano il \\(d\\) di Cohen e l’\\(r\\) di Pearson. Il \\(d\\) di Cohen è prevalentemente impiegato per descrivere le differenze tra le medie di gruppi sperimentali, quantificando questa differenza in termini di una deviazione standard aggregata.\nLa differenza standardizzata delle medie tra due gruppi può essere calcolata con la seguente formula (equazione 5.1, Glass et al., 1981),\n\\[\nd_p = \\frac{M_1 - M_2}{S_p}.\n\\]\nUn valore positivo di \\(d_p\\) indica che la media del gruppo 1 è maggiore della media del gruppo 2. Dividere la differenza delle medie per la deviazione standard combinata, \\(S_p\\), è la formulazione classica del \\(d\\) di Cohen. La deviazione standard combinata, \\(S_p\\), può essere calcolata come la radice quadrata della varianza media (ponderata per i gradi di libertà, \\(df = n-1\\)) del gruppo 1 e del gruppo 2 (pp. 108, Glass et al., 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1 - 1) S_1^2 + (n_2 - 1) S_2^2}{n_1 + n_2 - 2}}.\n\\]\nSi noti che il termine varianza si riferisce al quadrato della deviazione standard (\\(S^2\\)). Il \\(d_p\\) di Cohen è correlato alla statistica t di un test t per campioni indipendenti. Infatti, possiamo calcolare il valore di \\(d_p\\) a partire dalla statistica \\(t\\) con la seguente formula (equazione 5.3, Glass et al., 1981):\n\\[\nd = t \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nL’errore standard corrispondente di \\(d_p\\) è,\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1 + n_2}{n_1 n_2} + \\frac{d_p^2}{2(n_1 + n_2)}}.\n\\]\nLa statistica \\(r\\) di Pearson, d’altro canto, viene utilizzato per esprimere il grado di previsione di una variabile attraverso un’altra, fornendo una misura della correlazione. È interessante notare come queste due misure possano essere convertite l’una nell’altra attraverso la relazione:\n\\[\nd = \\frac{2r}{\\sqrt{1-r^2}}.\n\\]",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "href": "chapters/replication_crisis/03_effect_size.html#interpretare-la-dimensione-delleffetto",
    "title": "118  La grandezza dell’effetto",
    "section": "118.2 Interpretare la Dimensione dell’Effetto",
    "text": "118.2 Interpretare la Dimensione dell’Effetto\nL’interpretazione delle dimensioni dell’effetto solitamente avviene in due modi comuni: uno è privo di significato e l’altro è seriamente fuorviante.\n\nGli Standard di Cohen. Funder (2019) affermano che l’interpretazione più ampiamente utilizzata ma priva di senso delle dimensioni dell’effetto richiama gli standard stabiliti da Jacob Cohen (1977, 1988). Cohen ha fissato i valori di r di .10, .30 e .50 come soglie per effetti piccoli, medi e grandi, rispettivamente. Tuttavia, Cohen stesso ha dichiarato che queste soglie dovrebbero essere utilizzate solo in assenza di una base migliore e in seguito ha espresso rammarico per averle proposte.\nI termini “piccolo”, “medio” e “grande” sono privi di significato senza un contesto di riferimento. È necessario rispondere a due domande fondamentali: (a) piccolo, medio o grande rispetto a cosa? e (b) piccolo, medio o grande a quale scopo?\nElevare al Quadrato la Correlazione. Secondo Funder & Ozer (2019), un altro metodo comune per valutare la dimensione dell’effetto è ancora più problematico: elevare al quadrato il valore di r. Ad esempio, un r di .30 elevato al quadrato produce .09, interpretato come “proporzione di varianza spiegata”. Questa conversione spesso viene riportata con la parola “solo”, come in “la correlazione di .30 ha spiegato solo il 9% della varianza”.\nNon esiste una giustificazione valida per considerare r² come una misura appropriata della dimensione dell’effetto. La statistica r corrisponde alla pendenza di regressione quando entrambe le variabili sono standardizzate, mentre r² è molto meno interpretabile perché riflette la proporzione di varianza in una variabile spiegata da un’altra.\nUn esempio illustrativo è fornito da Darlington (1990). Immaginiamo un gioco in cui si lanciano prima un nickel (5¢) e poi un dime (10¢), ricevendo un pagamento di 5¢ o 10¢ rispettivamente se la moneta mostra testa. Le correlazioni tra il valore del nickel e il pagamento (r = .4472) e tra il valore del dime e il pagamento (r = .8944) sono calcolate. Elevando al quadrato queste correlazioni, si ottiene che i nickel spiegano il 20% della varianza nel pagamento, mentre i dime spiegano l’80%. Tuttavia, interpretare questi valori come indicazione che i dime contano quattro volte tanto quanto i nickel è fuorviante. Le correlazioni originali (.8944 è esattamente il doppio di .4472) offrono un confronto più informativo. In conclusione, elevare al quadrato r per valutare la dimensione dell’effetto non solo è poco informativo, ma può anche essere fuorviante.\n\n\n118.2.1 Alternative migliori\nÈ cruciale interpretare le dimensioni degli effetti in modo che ne arricchisca il significato. Funder & Ozer (2019) propongono due strategie principali: l’adozione di benchmark (criteri di riferimento) e la valutazione delle implicazioni pratiche dei risultati.\n\nUtilizzare criteri di riferimento significa confrontare l’entità di un risultato con quella di risultati ben noti e ampiamente compresi. Simile al modo in cui giudichiamo l’altezza di una persona basandoci su confronti con altri, i ricercatori possono ottenere una percezione accurata dell’importanza di un risultato confrontandolo con la dimensione di effetti noti, sia quelli tipici del campo di studio sia quelli emersi da ricerche passate.\nUn approccio al benchmarking può includere l’analisi di risultati considerati “classici” nel campo di interesse o la considerazione di dimensioni dell’effetto per risultati che hanno ottenuto un solido consenso nella comunità psicologica.\nIn un’ottica più ampia, alcuni ricercatori hanno proposto benchmark per la dimensione dell’effetto calcolando medie su vasti corpi di letteratura. Ad esempio, uno studio di psicologia sociale ha esaminato 708 correlazioni ottenute meta-analiticamente, rivelando che la dimensione media dell’effetto \\(r\\) era di .19.\nLa conoscenza comune o i risultati di ricerche non psicologiche possono offrire benchmark per valutare la forza di una relazione tra variabili. Un esempio è l’efficacia degli antistaminici contro il comune raffreddore, che corrisponde a un \\(r\\) di .11, mentre l’effetto degli anti-infiammatori non steroidei (come l’ibuprofene) sul dolore è di \\(r = .14\\).\n\nTali confronti illustrano come l’interpretazione delle dimensioni dell’effetto possa essere notevolmente approfondita e resa più significativa attraverso il riferimento a benchmark consolidati o intuitivamente comprensibili, sia dentro che fuori il campo della psicologia. Questo metodo consente di inserire i risultati di nuove ricerche in un contesto più vasto, favorendo una valutazione più consapevole della loro rilevanza relativa.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "href": "chapters/replication_crisis/03_effect_size.html#raccomandazioni-per-la-pratica-di-ricerca",
    "title": "118  La grandezza dell’effetto",
    "section": "118.3 Raccomandazioni per la Pratica di Ricerca",
    "text": "118.3 Raccomandazioni per la Pratica di Ricerca\nFunder & Ozer (2019) concludono il loro articolo con una serie di raccomandazioni per migliorare la pratica di riportare le dimensioni degli effetti negli studi scientifici.\nRiportare sempre e in modo evidente le dimensioni degli effetti. Ogni studio dovrebbe evidenziare chiaramente le dimensioni degli effetti. Una conseguenza di questa raccomandazione è che la dimensione del campione di uno studio deve essere adeguata affinché la stima della dimensione dell’effetto sia affidabile.\nCondurre studi con campioni ampi. Studi con campioni ampi sono ideali. Sebbene questo non sia sempre fattibile con certi tipi di ricerca o popolazioni specifiche, dovrebbe essere una priorità aumentare il più possibile la dimensione del campione.\nRiportare le dimensioni degli effetti in termini utili nel contesto. Il coefficiente di correlazione \\(r\\) di Pearson, essendo una misura standardizzata della dimensione dell’effetto, non fornisce informazioni sulle unità di misura dello studio. Pertanto, è necessario utilizzare misure delle dimensioni degli effetti che siano utili nel contesto specifico dello studio, come differenze medie o coefficienti di regressione grezzi, accanto a misure standardizzate, quando possibile.\nEvitare terminologia vuota. Si dovrebbe smettere di elevare al quadrato i valori di \\(r\\) per minimizzare l’apparente piccola percentuale di varianza spiegata e di utilizzare senza riflettere le linee guida di J. Cohen (1977, 1988), che lo stesso Cohen ha successivamente disconosciuto. Idealmente, termini come “piccolo” e “grande” dovrebbero essere eliminati dal vocabolario delle dimensioni degli effetti, poiché sono etichette soggettive e spesso arbitrarie che non aggiungono informazioni utili ai risultati quantitativi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "href": "chapters/replication_crisis/03_effect_size.html#commenti-e-considerazioni-finali",
    "title": "118  La grandezza dell’effetto",
    "section": "118.4 Commenti e considerazioni finali",
    "text": "118.4 Commenti e considerazioni finali\nLa sovrastima della grandezza dell’effetto in psicologia costituisce un problema diffuso. Un principio fondamentale della psicologia sociale e dell’economia comportamentale, almeno come viene presentato nei media e insegnato in molte scuole di business, è che piccoli “nudge” o spinte gentili, spesso cose che potremmo pensare non ci influenzino affatto, possono avere grandi effetti sul comportamento. Questo ha portato a numerose affermazioni sensazionalistiche, come l’idea che le elezioni siano decise da partite di football, o che la presentazione subliminale di una faccina sorridente possa causare enormi cambiamenti negli atteggiamenti verso l’immigrazione.\nIl modello di mondo alla base di queste affermazioni non è solo “l’effetto farfalla”, ovvero che piccoli cambiamenti possono avere grandi effetti, ma piuttosto che piccoli cambiamenti possono avere effetti grandi e prevedibili. È quello che a volte viene chiamato il modello “a pulsante” delle scienze sociali: l’idea che se fai X, puoi aspettarti di vedere Y.\nTuttavia, questa visione presenta diversi problemi:\n\nSovrastima degli effetti: Molti studi riportano effetti sorprendentemente grandi per interventi minimi, che spesso non vengono replicati in studi successivi.\nMancanza di considerazione delle interazioni: Se esistessero molti effetti grandi e prevedibili sul comportamento, questi interferirebbero tra loro, rendendo difficile osservare effetti coerenti nei dati osservazionali.\nInstabilità: Un sistema sociale con molti effetti grandi e prevedibili sarebbe instabile e difficile da studiare.\nGeneralizzazione eccessiva: Spesso si tende a generalizzare risultati ottenuti in condizioni di laboratorio molto specifiche a contesti più ampi e complessi della vita reale.\nBias di pubblicazione: Gli studi che riportano effetti grandi e statisticamente significativi hanno maggiori probabilità di essere pubblicati, creando una rappresentazione distorta della realtà.\n\nÈ importante sottolineare che la psicologia descrive molti fenomeni robusti, per esempio nella psicologia clinica e nella psicologia della percezione. Tuttavia, è fondamentale adottare un approccio più cauto e sfumato nell’interpretazione e nella comunicazione dei risultati della ricerca psicologica. La consapevolezza di questo problema ha portato a una maggiore enfasi sulla replicabilità degli studi, sull’uso di campioni più ampi e su metodi statistici più robusti. Inoltre, sta emergendo un approccio più critico e riflessivo nella comunità scientifica, che riconosce la complessità dei fenomeni psicologici e la necessità di evitare semplificazioni eccessive.\nIn conclusione, mentre la psicologia offre preziose intuizioni sul comportamento umano, è essenziale mantenere un sano scetticismo verso affermazioni di effetti grandi e facilmente ottenibili. La realtà è spesso più complessa e sfumata di quanto suggerito da titoli sensazionalistici o da singoli studi.\n\n\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in psychological research: Sense and nonsense. Advances in Methods and Practices in Psychological Science, 2(2), 156–168.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in Social Research. Sage Publications.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>La grandezza dell'effetto</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html",
    "href": "chapters/replication_crisis/04_s_m_errors.html",
    "title": "119  Errori di segno e errori di grandezza",
    "section": "",
    "text": "Introduzione\nIn questo capitolo verrà esaminata la relazione tra la crisi della replicabilità e la procedura di decisione statistica dell’approccio frequentista. In particolare, verranno discussi gli errori di tipo M (magnitude) e di tipo S (sign) che sono stati discussi da Loken & Gelman (2017).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "href": "chapters/replication_crisis/04_s_m_errors.html#il-filtro-della-significatività-statistica",
    "title": "119  Errori di segno e errori di grandezza",
    "section": "119.1 Il Filtro della Significatività Statistica",
    "text": "119.1 Il Filtro della Significatività Statistica\nNel Capitolo 116 abbiamo esaminato come la pratica scientifica contemporanea sia spesso compromessa da casi di frode, principalmente a causa delle notevoli implicazioni economiche legate alla pubblicazione su riviste scientifiche prestigiose. Questo problema è frequentemente sottovalutato, poiché le riviste sono riluttanti ad ammettere la necessità di correzioni o ritrattazioni degli articoli già pubblicati.\nLa frode scientifica rappresenta una minaccia evidente alla riproducibilità dei risultati, pilastro fondamentale del metodo scientifico. Tuttavia, le difficoltà nel replicare i risultati pubblicati non sono attribuibili esclusivamente alla frode o a “pratiche di ricerca disoneste” (Nelson et al., 2018). Un problema intrinseco riguarda il metodo statistico ampiamente adottato dai ricercatori: l’approccio del test di ipotesi nulla e della significatività statistica di stampo fisheriano. Secondo questo metodo, i risultati che non raggiungono la “significatività statistica” dovrebbero essere scartati, mentre quelli che la superano possono essere considerati credibili, basandosi unicamente su questo criterio (Wagenmakers et al., 2008).\nTuttavia, l’idea che la significatività statistica sia un filtro affidabile per distinguere i risultati di ricerca “validi” da quelli “non validi” è fondamentalmente errata. Numerose evidenze dimostrano la fallacia di questo approccio. Per approfondire questo aspetto, esamineremo lo studio di Loken & Gelman (2017), che mette in luce la relazione tra la crisi della replicabilità e la procedura di decisione statistica dell’approccio frequentista.\nUno dei principali problemi evidenziati dallo studio di Loken & Gelman (2017) è che, in contesti di ricerca complessi, la significatività statistica fornisce prove molto deboli riguardo al segno o all’entità di eventuali effetti sottostanti. In altre parole, il raggiungimento della significatività statistica non garantisce né la rilevanza né la consistenza dei risultati ottenuti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "href": "chapters/replication_crisis/04_s_m_errors.html#errori-di-tipo-m-e-s",
    "title": "119  Errori di segno e errori di grandezza",
    "section": "119.2 Errori di tipo M e S",
    "text": "119.2 Errori di tipo M e S\nPer evidenziare le implicazioni del processo decisionale basato sulla significatività statistica, gli autori di Loken & Gelman (2017) hanno condotto una simulazione. In questa simulazione, hanno immaginato una ricerca ipotetica in cui un effetto reale, seppur molto debole, era presente, ma difficilmente individuabile senza una grande quantità di dati. I ricercatori hanno quindi cercato di rilevare questo effetto utilizzando l’approccio frequentista e valutando la significatività statistica.\nI risultati della simulazione hanno rivelato che, anche quando un effetto reale ma debole era presente, l’approccio frequentista tendeva a individuare un effetto significativo solo in una piccola percentuale dei casi. Inoltre, quando veniva individuato un effetto significativo, la sua stima di grandezza risultava molto imprecisa e instabile.\nIn altre parole, la significatività statistica fornisce solo un’indicazione generale sulla presenza o assenza di un effetto, ma non offre informazioni precise sulla sua dimensione o replicabilità. Questo problema diventa ancora più evidente quando si considera che molte ricerche in psicologia e scienze sociali utilizzano campioni relativamente piccoli, e gli effetti osservati in tali studi tendono ad essere molto modesti. In tali contesti, l’approccio frequentista rischia di fornire prove molto deboli e instabili riguardo alla presenza o assenza di un effetto, mettendo a rischio la replicabilità e l’affidabilità dei risultati della ricerca.\nRiproduciamo qui, in maniera semplificata, la simulazione condotta da Loken & Gelman (2017). Iniziamo ad importare le librerie necessarie.\nSupponiamo di considerare due campioni casuali indipendenti di dimensioni \\(n_1 = 20\\) e \\(n_2 = 25\\), estratti dalle distribuzioni normali \\(\\mathcal{N}(102, 10)\\) e \\(\\mathcal{N}(100, 10)\\) rispettivamente. La dimensione effettiva dell’effetto per la differenza tra le medie di questi due campioni è rappresentata da \\(d\\), calcolato attraverso la formula:\n\\[\nd = \\frac{\\bar{y}_1 - \\bar{y}_2}{s_p},\n\\]\ndove \\(\\bar{y}_1\\) e \\(\\bar{y}_2\\) sono le medie campionarie dei due gruppi, mentre \\(s_p\\) è la deviazione standard combinata definita come:\n\\[\ns_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ncon \\(s_1\\) e \\(s_2\\) rappresentanti le deviazioni standard campionarie dei due gruppi.\nNel caso specifico preso in esame, la dimensione effettiva dell’effetto è molto piccola, indicando che la differenza osservata tra le medie manca di significatività pratica. Questo suggerisce che la distinzione tra i due gruppi non ha un impatto sostanziale nella pratica.\n\nmu_1 = 102\nmu_2 = 100\nsigma = 10\nn1 = 20\nn2 = 25\n\n\nmean_difference = abs(mu_1 - mu_2)\npooled_sd = np.sqrt(((n1 - 1) * sigma**2 + (n2 - 1) * sigma**2) / (n1 + n2 - 2))\ncohen_d = mean_difference / pooled_sd\n\nprint(\"Cohen's d effect size:\", cohen_d)\n\nCohen's d effect size: 0.2\n\n\nEsaminiamo ora quali sarebbero le conclusioni derivanti dall’approccio frequentista mediante la procedura di decisione statistica in queste circostanze. Consideriamo una simulazione in cui vengono estratti due campioni: uno composto da 20 osservazioni dalla prima popolazione e l’altro da 25 osservazioni dalla seconda popolazione. Successivamente, viene eseguito il test \\(t\\) di Student.\nNell’approccio frequentista, se il valore-\\(p\\) risulta essere superiore a 0.05, i risultati vengono considerati non significativi e quindi scartati. Al contrario, se il valore-\\(p\\) è inferiore a 0.05, il risultato è considerato “pubblicabile” e si conclude che esiste una differenza significativa tra i due gruppi.\nPer comprendere appieno le conclusioni ottenute mediante la procedura frequentista in questa situazione, è necessario ripetere il processo sopra descritto per un ampio numero di iterazioni, ad esempio 50,000 volte. Questo implica che il processo di estrazione dei campioni e il calcolo dei valori-\\(p\\) vengono ripetuti numerose volte al fine di ottenere una visione completa delle possibili distribuzioni dei risultati.\n\nn_samples = 50000\n\nres = []\n\nfor i in range(n_samples):\n    # Get random samples \n    y1 = np.random.normal(loc=mu_1, scale=sigma, size=n1)\n    y2 = np.random.normal(loc=mu_2, scale=sigma, size=n2)\n    # Compute effect size\n    y1bar = y1.mean()\n    y2bar = y2.mean()\n    v1 = np.var(y1, ddof=1)\n    v2 = np.var(y2, ddof=1)\n    s = np.sqrt(((n1-1)*v1 + (n2-1)*v2) / (n1 + n2 - 2))\n    efsize = (y1bar - y2bar) / s\n    # Compute p-value\n    out = stats.ttest_ind(a=y1, b=y2, equal_var=True)\n    # Save effect size only for 'statistically significant' results\n    if out.pvalue &lt; 0.05:\n        res.append(efsize)\n\nEsaminiamo un istogramma dei casi nei quali il valore-\\(p\\) è stato &lt; 0.05.\n\nplt.hist(res, bins=20)\nplt.axvline(\n    x=0.2, color=\"red\", linestyle=\"dashed\", linewidth=2, label=\"True Effect Size\"\n)\nplt.xlabel(\"Effect Size\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Histogram of Effect Sizes for 'Statistically Significant' Results\")\nplt.legend()\n_ = plt.show()\n\n\n\n\n\n\n\n\nCome sottolineato da Loken & Gelman (2017), l’utilizzo dell’approccio frequentista nella procedura di decisione statistica può portare a due tipi di errori significativi. Il primo errore, noto come “magnitude”, si manifesta nel fatto che i risultati pubblicati tendono a sovrastimare la vera grandezza dell’effetto. Nella simulazione effettuata, sebbene la vera grandezza dell’effetto fosse modesta (0.2), la media della grandezza dell’effetto per i risultati dichiarati “statisticamente significativi” era di circa 0.8, indicando una grandezza dell’effetto “ampia”.\nIl secondo errore, denominato “segno”, si verifica in alcune situazioni in cui, a causa della variabilità campionaria, viene commesso un errore nella direzione dell’effetto. In tali circostanze, il ricercatore potrebbe erroneamente concludere che \\(\\mu_2 &gt; \\mu_1\\), quando in realtà non è così. È importante notare che, anche in questi casi, la grandezza dell’effetto viene sovrastimata in termini assoluti.\nÈ interessante notare che le stesse conclusioni si applicherebbero anche se avessimo considerato l’intervallo di confidenza per la differenza tra le medie. In sintesi, l’approccio frequentista introduce un errore sistematico nella stima della grandezza dell’effetto, che è la quantità più importante che il ricercatore deve stimare. In alcune situazioni, può persino causare errori nella stima della direzione dell’effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#considerazioni-conclusive",
    "href": "chapters/replication_crisis/04_s_m_errors.html#considerazioni-conclusive",
    "title": "119  Errori di segno e errori di grandezza",
    "section": "119.3 Considerazioni conclusive",
    "text": "119.3 Considerazioni conclusive\nIn conclusione, l’approccio frequentista non fornisce un metodo affidabile per valutare i risultati della ricerca e determinare la loro attendibilità o la necessità di scartarli [gelman2014beyond; Loken & Gelman (2017)]. Questa mancanza di affidabilità deriva dall’introduzione di errori sistematici nella stima delle dimensioni dell’effetto, che può anche portare a errori nella direzione dell’effetto in alcune circostanze. Di conseguenza, non sembra esserci motivo valido per continuare a impiegare questo approccio.\nAl contrario, l’adozione dell’approccio bayesiano sembra offrire risultati più precisi e affidabili nella valutazione dei dati di ricerca. Tale approccio considera la probabilità delle ipotesi alla luce dei dati osservati, evitando gli errori intrinseci dell’approccio frequentista e fornendo una base più solida per le decisioni sulla validità dei risultati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "href": "chapters/replication_crisis/04_s_m_errors.html#esercizi",
    "title": "119  Errori di segno e errori di grandezza",
    "section": "119.4 Esercizi",
    "text": "119.4 Esercizi\n\nEsercizio 119.1 Esegui una simulazione con 10.000 ripetizioni (nrep = 10000) in cui vengono estratti due campioni casuali dalla stessa popolazione normale con media 0 e deviazione standard 10. Per ogni simulazione, esegui un t-test per confrontare le medie di due gruppi indipendenti.\n\nProporzione di risultati statisticamente significativi: Calcola la proporzione di risultati in cui si ottiene un risultato statisticamente significativo (p &lt; 0.05) in questa condizione in cui i campioni provengono dalla stessa popolazione, e quindi non c’è una differenza reale tra i gruppi. Questo ti darà un’idea della frequenza dei falsi positivi.\nGrandezza dell’effetto media: Calcola la grandezza dell’effetto (d di Cohen) media, considerando solo quei test in cui si è ottenuta una differenza statisticamente significativa. Questo valore ti mostrerà quanto grande appare l’effetto quando il risultato è significativo, nonostante la realtà sia priva di un effetto reale.\nRipetizione della simulazione con diverse grandezze campionarie: Ripeti la simulazione usando due diverse dimensioni campionarie: 20 osservazioni per gruppo e 200 osservazioni per gruppo. Confronta i risultati per capire come la dimensione del campione influenzi la proporzione di falsi positivi e la grandezza dell’effetto media.\nInterpretazione dei risultati: Interpreta i risultati alla luce del concetto del “filtro della significatività statistica”. Questo concetto suggerisce che tra tutti gli studi effettuati, tendono ad essere pubblicati e riportati solo quelli che ottengono risultati statisticamente significativi. Di conseguenza, i risultati significativi pubblicati possono sovrastimare la vera grandezza dell’effetto o indicare erroneamente che un effetto esiste quando in realtà non c’è. Questa simulazione dovrebbe mostrare come, anche in assenza di una differenza reale tra gruppi, si possano ottenere risultati apparentemente significativi con una certa frequenza, soprattutto quando la dimensione campionaria è piccola.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/04_s_m_errors.html#informazioni-sullambiente-di-sviluppo",
    "title": "119  Errori di segno e errori di grandezza",
    "section": "119.5 Informazioni sull’Ambiente di Sviluppo",
    "text": "119.5 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Sun May 12 2024\n\nPython implementation: CPython\nPython version       : 3.12.3\nIPython version      : 8.22.2\n\narviz     : 0.18.0\nscipy     : 1.13.0\nmatplotlib: 3.8.4\nseaborn   : 0.13.2\nnumpy     : 1.26.4\n\nWatermark: 2.4.3\n\n\n\n\n\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s renaissance. Annual review of psychology, 69(1), 511–534.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008). Bayesian versus frequentist inference. Bayesian evaluation of informative hypotheses, 181–207.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>Errori di segno e errori di grandezza</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html",
    "href": "chapters/replication_crisis/05_p_values.html",
    "title": "120  La fragilità del p-valore",
    "section": "",
    "text": "120.1 Introduzione\nIl codice seguente è ispirato da un post sul blog di Andrew Gelman.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>120</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#simulazione",
    "href": "chapters/replication_crisis/05_p_values.html#simulazione",
    "title": "120  La fragilità del p-valore",
    "section": "120.2 Simulazione",
    "text": "120.2 Simulazione\nLa seguente simulazione ha l’obiettivo di mostrare quanto i p-valori possano essere “fragili” e variare notevolmente da campione a campione, anche quando i dati provengono da una distribuzione con parametri molto simili. Questo serve a dimostrare che il p-valore, spesso usato per determinare la significatività statistica di un effetto, può essere influenzato pesantemente dalla variabilità campionaria, soprattutto in campioni di piccole dimensioni o con effetti deboli. Gelman esprime questo concetto dicendo che\n\nthe difference between “significant” and “not significant” is not itself statistically significant.\n\n\n120.2.1 Logica della Simulazione\n\nObiettivo:\n\nDimostrare la variabilità dei p-valori calcolati per diversi campioni estratti da una popolazione con una media molto vicina a zero.\nMostrare come, nonostante l’effetto vero sia piccolo, i p-valori possano essere significativamente diversi tra loro, a seconda della variabilità e delle dimensioni del campione.\n\nSetup della Simulazione:\n\nGeneriamo \\(J = 10\\) campioni indipendenti, ognuno con un numero ridotto di osservazioni (\\(n = 10\\)), per massimizzare la variabilità dei risultati.\nOgni campione è generato da una distribuzione normale con una media vera di \\(\\mu = 0.05\\) e una deviazione standard di \\(\\sigma = 0.1\\). Questi parametri sono scelti per rendere la media dei campioni vicina a zero e, al tempo stesso, abbastanza variabile.\n\nCalcolo della media campionaria:\n\nPer ciascun campione, calcoliamo la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nLa media del campione (\\(\\hat{\\mu}\\)) è utilizzata come stima del parametro.\n\nCalcolo del p-valore:\n\nApplichiamo un t-test per ciascun campione per verificare l’ipotesi nulla (\\(H_0\\)) che la media del campione sia zero.\nIl p-valore viene calcolato utilizzando la formula classica del t-test: [ t = ] dove:\n\n\\(\\hat{\\mu}\\) è la media del campione,\n\\(\\hat{\\sigma}\\) è la deviazione standard del campione,\n\\(n\\) è il numero di osservazioni per campione.\n\nSuccessivamente, il p-valore è calcolato come: [ = 2 (1 - (|t|)) ] dove \\(\\text{CDF}\\) è la funzione cumulativa della distribuzione t con \\(n-1\\) gradi di libertà.\n\n\n\n\n120.2.2 Descrizione della Sintassi\nIl codice Python è strutturato come segue:\n\nImportazione delle librerie:\n\nUsiamo numpy per generare i campioni casuali e calcolare le medie e le deviazioni standard.\nscipy.stats fornisce la distribuzione t per calcolare il p-valore.\n\nGenerazione dei campioni:\nsamples = [np.random.normal(true_mean, se, n) for _ in range(J)]\n\nCreiamo una lista di campioni (10 campioni in totale), ognuno con 10 osservazioni, utilizzando la distribuzione normale con media 0.05 e deviazione standard 0.1.\n\nCalcolo delle medie e dei p-valori:\n\nIteriamo su ciascun campione per calcolare la media (\\(\\hat{\\mu}\\)) e la deviazione standard (\\(\\hat{\\sigma}\\)).\nCalcoliamo il valore statistico \\(t\\) e il corrispondente p-valore utilizzando la distribuzione t.\n\nStampa dei risultati:\n\nI p-valori vengono arrotondati e stampati per osservare quanto siano variabili.\n\n\n\n# Imposta il seme per la riproducibilità\nnp.random.seed(1234)\n\n# Parametri della simulazione\nJ = 10  # Numero di campioni\nn = 10  # Numero di osservazioni per campione\ntrue_mean = 0.05  # Media vera vicina a zero\nse = 0.1  # Deviazione standard\n\n# Genera i campioni casuali\nsamples = [np.random.normal(true_mean, se, n) for _ in range(J)]\n\n# Calcola la media di ciascun campione e i p-valori usando il t-test\np_values = []\nfor sample in samples:\n    sample_mean = np.mean(sample)  # Media campionaria\n    sample_std = np.std(sample, ddof=1)  # Deviazione standard campionaria\n    t_statistic = sample_mean / (sample_std / np.sqrt(n))  # Calcolo della statistica t\n    p_value = 2 * (1 - stats.t.cdf(np.abs(t_statistic), df=n - 1))  # Calcolo del p-valore\n    p_values.append(p_value)\n\n# Stampa i p-valori arrotondati a 3 cifre decimali\nprint(np.round(p_values, 3))\n\n[0.336 0.118 0.094 0.003 0.311 0.153 0.282 0.05  0.181 0.245]\n\n\nImmagina che questo fosse un esperimento reale. Alcuni campioni mostrano risultati che potrebbero essere compatibili con puro rumore, alcuni sembrano fornire prove deboli contro l’ipotesi nulla, e altri mostrano risultati altamente significativi dal punto di vista statistico. Sarebbe naturale cercare di categorizzare questi risultati in qualche modo. Certo, la differenza tra “significativo” e “non significativo” non è di per sé statisticamente significativa, ma un p-valore di 0.336 in un caso e di 0.003 in un altro… sicuramente deve essere rilevante, giusto? No.\nQuesto è un caso estremo, in quanto non c’è una variazione sottostante reale; infatti, se si adatta un modello multilivello, si potrebbe vedere la mancanza di evidenza di una variazione effettiva sottostante.\nI punti principali sono:\n\nIl p-valore è una dichiarazione relativa all’ipotesi nulla di assenza di effetto. Non ha molto significato rispetto a un effetto reale, anche se piccolo.\nIl p-valore è estremamente variabile. È una trasformazione non lineare e strana dello z-score (che invece ha un’interpretazione più chiara) e può comportarsi in modi non intuitivi.\n\nE inoltre:\n\nSi può imparare molto da una simulazione. Anche un esperimento semplice come questo può essere estremamente istruttivo!\n\nSi noti che anche le inferenze bayesiane sono altamente variabili. Qualsiasi sintesi dei dati presenterà variabilità! Il problema non è tanto con i p-valori, quanto con il loro utilizzo scorretto (come nel punto 1) e quando vengono presi come una dichiarazione forte sulla realtà (come nel punto 2), invece di essere visti come un riassunto rumoroso di un esperimento specifico. Se si fraintendono e si sovrainterpretano le inferenze bayesiane—ad esempio, adattando un modello con prior non informativi, prendendo la probabilità posteriore che il parametro sia maggiore di zero e poi decidendo sulla base di una soglia arbitraria—ci si ritrova in una situazione altrettanto problematica.\n\n\n120.2.3 Conclusioni\nLa simulazione mostra che, nonostante le medie dei campioni siano generate con una distribuzione simile, i p-valori possono variare drasticamente. Questo effetto è amplificato dalla scelta di campioni piccoli e di una media vera molto vicina all’ipotesi nulla (zero). Dimostra quanto il p-valore possa essere influenzato da piccole variazioni nei dati e perché non sia sempre un indicatore affidabile per valutare l’efficacia o la presenza di un effetto.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>120</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/replication_crisis/05_p_values.html#informazioni-sullambiente-di-sviluppo",
    "title": "120  La fragilità del p-valore",
    "section": "120.3 Informazioni sull’Ambiente di Sviluppo",
    "text": "120.3 Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w\n\nLast updated: Wed Oct 09 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nmatplotlib: 3.9.1\nseaborn   : 0.13.2\nnumpy     : 1.26.4\narviz     : 0.18.0\nscipy     : 1.14.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>120</span>  <span class='chapter-title'>La fragilità del *p*-valore</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html",
    "href": "chapters/replication_crisis/06_changes.html",
    "title": "121  Proposte di cambiamento",
    "section": "",
    "text": "121.1 Introduzione\nLa crisi della riproducibilità ha portato a una profonda riflessione sullo stato della ricerca nelle scienze comportamentali, cognitive e sociali. La scoperta che molti studi pubblicati non erano replicabili ha scosso la fiducia nella ricerca scientifica e ha messo in evidenza le carenze metodologiche e strutturali che affliggono il sistema accademico. Di fronte a questa crisi, sono state avanzate diverse proposte di riforma volte a migliorare la qualità e l’affidabilità della ricerca scientifica.\nSecondo Korbmacher et al. (2023) sono neccessarie riforme strutturali, cambiamenti procedurali e cambiamenti nella comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "href": "chapters/replication_crisis/06_changes.html#riforme-strutturali",
    "title": "121  Proposte di cambiamento",
    "section": "121.2 Riforme Strutturali",
    "text": "121.2 Riforme Strutturali\n\n121.2.1 Integrazione della Riproducibilità nei Curriculum Educativi\nUna delle principali proposte per affrontare la crisi della riproducibilità è l’integrazione delle pratiche di riproducibilità nei curriculum educativi delle scienze psicologiche e affini. Attualmente, molti programmi di formazione non pongono sufficiente enfasi sull’importanza della replicabilità e della trasparenza nella ricerca. Incorporare queste tematiche nei corsi di metodologia della ricerca può sensibilizzare le nuove generazioni di ricercatori alla necessità di adottare pratiche più rigorose e trasparenti. Ad esempio, alcuni programmi universitari hanno iniziato a includere repliche di studi famosi come parte del percorso formativo degli studenti, offrendo loro l’opportunità di comprendere meglio i limiti e le potenzialità del processo scientifico.\n\n\n121.2.2 Incentivi per la Scienza Aperta\nOltre alla formazione, un altro aspetto cruciale è la riforma dei sistemi di incentivazione accademica. Tradizionalmente, il sistema accademico ha privilegiato la quantità di pubblicazioni e la novità dei risultati, piuttosto che la loro qualità e replicabilità. Per promuovere pratiche di scienza aperta, come la preregistrazione degli studi e la condivisione aperta dei dati, si propone l’introduzione di riconoscimenti ufficiali, come badge di “open science” o crediti accademici per la pubblicazione di rapporti registrati. Questi cambiamenti potrebbero favorire una maggiore adozione di pratiche che promuovono la trasparenza e rafforzano la fiducia nella ricerca scientifica.\nA tal proposito, è interessante considerare uno studio di Scheel et al. (2021). Gli autori hanno confrontato i risultati di rapporti registrati pubblicati (N = 71) con un campione casuale di studi ipotetico-deduttivi della letteratura standard (N = 152) in psicologia. Analizzando la prima ipotesi di ciascun articolo, hanno riscontrato che il 96% dei risultati nei rapporti standard erano positivi, contro solo il 44% nei rapporti registrati.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-procedurali",
    "title": "121  Proposte di cambiamento",
    "section": "121.3 Cambiamenti Procedurali",
    "text": "121.3 Cambiamenti Procedurali\n\n121.3.1 Mercati di Previsione per la Credibilità della Ricerca\nI mercati di previsione sono stati proposti come uno strumento innovativo per valutare la credibilità della ricerca. In questi mercati, esperti e non esperti scommettono sulla probabilità che i risultati di determinati studi siano replicabili. Questo approccio ha dimostrato di avere un’elevata accuratezza nella classificazione della replicabilità degli studi, offrendo un metodo alternativo e complementare alla replicazione diretta. I mercati di previsione potrebbero essere particolarmente utili in contesti in cui la raccolta dati è costosa o difficile da realizzare, fornendo una prima indicazione sulla solidità dei risultati di ricerca.\n\n\n121.3.2 Strumenti di Valutazione Statistica\nUn’altra proposta riguarda l’adozione di nuovi strumenti di valutazione statistica per identificare e correggere il bias di pubblicazione e migliorare la potenza degli studi. Strumenti come la curva-p e la curva-z sono stati sviluppati per analizzare la distribuzione dei valori p e identificare eventuali distorsioni nei risultati pubblicati. Inoltre, alcuni studiosi hanno suggerito di abbassare il livello di significatività statistica standard da 0,05 a 0,005 per ridurre il tasso di falsi positivi e aumentare la robustezza dei risultati. Queste proposte, sebbene non risolutive, rappresentano passi importanti verso una maggiore precisione nelle analisi statistiche.\n\n\n121.3.3 Analisi Multiverso\nL’analisi multiverso è un’altra proposta innovativa che mira a gestire la molteplicità di scelte analitiche possibili in un singolo studio. Questa tecnica prevede l’esecuzione di molteplici analisi su uno stesso dataset, variando i parametri e le scelte metodologiche, per testare la stabilità dei risultati. L’adozione di questo approccio permette di evidenziare quanto i risultati siano sensibili alle scelte analitiche, contribuendo a una maggiore trasparenza e affidabilità nelle conclusioni tratte dagli studi.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "href": "chapters/replication_crisis/06_changes.html#cambiamenti-nella-comunità",
    "title": "121  Proposte di cambiamento",
    "section": "121.4 Cambiamenti nella Comunità",
    "text": "121.4 Cambiamenti nella Comunità\n\n121.4.1 Big Team Science\nIl concetto di “Big Team Science” rappresenta un cambiamento significativo nella modalità di condurre ricerca. Questo approccio prevede la collaborazione su larga scala tra scienziati di diversi paesi e discipline, con l’obiettivo di replicare studi, raccogliere grandi campioni e condividere risorse. Questo modello di lavoro collettivo non solo aumenta l’efficienza della ricerca, ma promuove anche una maggiore diversità nei campioni e nei team di ricerca. Tuttavia, esistono anche criticità, come la possibilità di perpetuare disuguaglianze tra ricercatori di paesi sviluppati e in via di sviluppo, e la difficoltà nel riconoscere adeguatamente i contributi individuali all’interno di grandi consorzi.\n\n\n121.4.2 Collaborazioni Avversariali\nLe collaborazioni avversariali rappresentano un altro approccio interessante per migliorare la qualità della ricerca. In queste collaborazioni, ricercatori con visioni teoriche contrastanti lavorano insieme per progettare e condurre studi che testino le loro ipotesi in modo rigoroso. Questo tipo di collaborazione può ridurre i bias personali e promuovere un confronto costruttivo, portando a conclusioni più solide e condivise all’interno della comunità scientifica.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "href": "chapters/replication_crisis/06_changes.html#crisi-della-generalizzabilità",
    "title": "121  Proposte di cambiamento",
    "section": "121.5 Crisi della generalizzabilità",
    "text": "121.5 Crisi della generalizzabilità\nYarkoni (2022) affronta la questione critica della scarsa validità delle inferenze quantitative presenti nella letteratura psicologica pubblicata proponendo tre strategie principali che, se adottate, potrebbero migliorare significativamente la qualità della ricerca in psicologia.\n\n121.5.1 Do Something Else\nIl primo suggerimento dell’autore è quello di considerare la possibilità di abbandonare la ricerca psicologica quantitativa laddove risulti troppo difficile estrarre conclusioni significative e generalizzabili da effetti complessi e variabili. L’autore critica la tendenza nella psicologia (e in altre discipline) di concludere ogni contributo di ricerca con una nota positiva o “costruttiva”, indipendentemente dalla realtà delle evidenze raccolte. Secondo l’autore, non è realistico pensare che ogni domanda di ricerca meriti una risposta empirica, soprattutto quando le risorse necessarie per ottenere risultati minimamente informativi superano di gran lunga gli standard convenzionali. In queste circostanze, potrebbe essere più saggio riconoscere i limiti della ricerca e, in alcuni casi, scegliere percorsi di carriera alternativi, specialmente per i ricercatori alle prime armi, che potrebbero trovare prospettive di carriera migliori al di fuori dell’accademia.\n\n\n121.5.2 Abbracciare l’Analisi Qualitativa\nLa seconda opzione proposta è continuare a fare ricerca psicologica, ma abbandonando in gran parte i metodi statistici inferenziali a favore di metodi qualitativi. L’autore sostiene che gran parte di ciò che attualmente passa per scienza quantitativa in psicologia sia in realtà un’analisi qualitativa mascherata. Alcune teorie psicologiche, secondo l’autore, non traggono beneficio da un’analisi quantitativa poiché sono o troppo vaghe o troppo ovvie per essere falsificabili attraverso procedure statistiche. L’autore suggerisce che in molti casi l’analisi qualitativa potrebbe fornire risposte più profonde e significative rispetto a un approccio quantitativo superficiale, evitando così l’illusione di una precisione scientifica inesistente.\nIn un approccio qualitativo, i ricercatori potrebbero concentrarsi sulla descrizione e sull’esplorazione delle relazioni tra variabili senza cercare di trarre conclusioni causali definitive. L’autore menziona l’esempio della rivista Basic and Applied Social Psychology, che ha bandito l’uso dei p-value, come un esempio di come l’abbandono della statistica inferenziale possa essere gestito in modo costruttivo. Sebbene questa mossa sia stata accolta con scetticismo, l’autore suggerisce che, se affrontata correttamente, potrebbe essere un passo positivo verso una maggiore integrità nella ricerca psicologica.\n\n\n121.5.3 Adottare Standard Migliori\nLa terza e ultima strategia consiste nel migliorare gli standard della ricerca quantitativa in psicologia per renderla più rigorosa e affidabile. L’autore propone diverse pratiche che, se implementate, potrebbero migliorare la qualità e la validità delle inferenze psicologiche:\n\nInferenze più conservative: I ricercatori dovrebbero evitare di fare generalizzazioni ampie basate su dati limitati e dovrebbero esplicitamente indicare quando stanno speculando al di là dei dati disponibili. La formulazione di titoli di articoli e affermazioni dovrebbe riflettere in modo più accurato la portata dei risultati ottenuti.\nRicerca descrittiva: L’autore esorta a prendere più seriamente la ricerca descrittiva, che si concentra sulla caratterizzazione delle relazioni tra variabili senza ricorrere a spiegazioni causali. Questo tipo di ricerca può fornire un’importante base empirica che è spesso trascurata a favore di teorie semplificate e sovrastimate.\nModelli statistici più espansivi: I ricercatori dovrebbero abituarsi a utilizzare modelli statistici che considerino una più ampia gamma di variabili e fattori, oltre a includere effetti random per elementi come stimoli, compiti e siti di ricerca. Questo approccio richiede l’uso di modelli misti che permettano di gestire la complessità della realtà psicologica in modo più adeguato.\nProgettare con la variazione in mente: Yarkoni (2022) sostiene l’importanza di progettare studi che abbraccino la variabilità naturale delle condizioni sperimentali, piuttosto che cercare di controllare rigidamente ogni variabile. Questo approccio, sebbene più costoso in termini di risorse, permetterebbe di ottenere risultati più generalizzabili e utili.\nStime della varianza: Un maggiore enfasi dovrebbe essere posta sull’analisi dele componenti della varianza piuttosto che sulle stime puntuali. Questo permetterebbe di comprendere meglio l’importanza relativa delle diverse fonti di variazione nei dati e di pianificare studi futuri in modo più informato.\nPredizioni più rischiose: Yarkoni (2022) incoraggia i ricercatori a formulare predizioni teoriche che comportino un alto grado di rischio. Predizioni più precise e rischiose ridurrebbero le preoccupazioni sulla generalizzabilità, poiché solo modelli teorici accurati sarebbero in grado di fare previsioni con tale precisione.\nUtilità predittiva pratica: Infine, Yarkoni (2022) suggerisce un approccio più pragmatico che si concentri sull’utilità pratica delle predizioni piuttosto che su considerazione puramente teoriche. Invece di chiedersi se un fenomeno esiste, dovremmo chiederci se possiamo costruire modelli che predicano efficacemente comportamenti rilevanti in situazioni specifiche.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "href": "chapters/replication_crisis/06_changes.html#sviluppare-teorie-formali",
    "title": "121  Proposte di cambiamento",
    "section": "121.6 Sviluppare teorie formali",
    "text": "121.6 Sviluppare teorie formali\nOltre alle carenze metodologiche o statistiche, è stato spesso sottolineato che la crisi di replicabilità che affligge le scienze psicologiche trova le sue radici nella mancanza di un quadro teorico cumulativo. Senza un quadro teorico generale che generi ipotesi in diversi ambiti, i programmi empirici si sviluppano a partire da intuizioni personali e teorie popolari influenzate culturalmente. Fornendo strumenti per formulare previsioni chiare, anche attraverso l’uso di modelli formali, i quadri teorici stabiliscono aspettative che permettono di determinare se un nuovo risultato conferma le ricerche esistenti, integrandosi con esse, oppure se è inaspettato e, pertanto, richiede ulteriori verifiche e approfondimenti (Muthukrishna & Henrich, 2019).",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/06_changes.html#considerazioni-conclusive",
    "href": "chapters/replication_crisis/06_changes.html#considerazioni-conclusive",
    "title": "121  Proposte di cambiamento",
    "section": "121.7 Considerazioni Conclusive",
    "text": "121.7 Considerazioni Conclusive\nL’ampio utilizzo dei test statistici frequentisti in psicologia risulta spesso fuorviante, poiché attribuisce un’apparenza di rigore scientifico a inferenze che, in realtà, sono principalmente qualitative. Si rende quindi necessaria una profonda riforma delle pratiche di ricerca, volta a promuovere una maggiore trasparenza e precisione, oltre a incoraggiare la disponibilità a mettere in discussione e abbandonare approcci metodologici che non superano una rigorosa analisi critica (Yarkoni, 2022).\nLa crisi di replicabilità ha spinto verso una serie di riforme con il potenziale di trasformare positivamente la ricerca psicologica. Tra queste iniziative vi sono la promozione della scienza aperta, l’adozione di standard metodologici più rigorosi e una maggiore attenzione a pratiche di ricerca che privilegiano la qualità e la replicabilità dei risultati rispetto alla loro quantità e novità. Sebbene questi cambiamenti possano sembrare meno spettacolari rispetto ai metodi attualmente utilizzati, essi rappresentano un percorso fondamentale per garantire la credibilità e la sostenibilità a lungo termine della disciplina.\nAffinché queste riforme abbiano un impatto duraturo, è essenziale un cambiamento strutturale a tutti i livelli della comunità scientifica:\n\nI ricercatori devono impegnarsi ad adottare pratiche più rigorose e trasparenti, privilegiando la solidità metodologica e la replicabilità dei loro studi.\nGli enti finanziatori devono incentivare la qualità e la replicabilità degli studi, piuttosto che premiare esclusivamente la produzione di risultati innovativi o appariscenti.\nLe istituzioni accademiche devono rivedere i criteri di valutazione del merito scientifico, dando maggior peso all’impatto a lungo termine delle ricerche e alla loro solidità metodologica.\nLe riviste scientifiche devono assicurarsi che i risultati pubblicati siano realmente robusti e generalizzabili, anziché limitarsi a privilegiare i risultati nuovi o sorprendenti.\n\nQuesti cambiamenti, sebbene complessi e talvolta impopolari, sono fondamentali per ristabilire la fiducia nel processo scientifico e per garantire che la ricerca psicologica continui a offrire contributi utili e affidabili nella comprensione della mente umana e del comportamento.\nIn conclusione, la sfida posta dalla crisi di replicabilità offre un’opportunità unica per ridefinire e rafforzare le fondamenta metodologiche della ricerca psicologica. Abbracciando questi cambiamenti, la psicologia può emergere come una disciplina più robusta, trasparente e affidabile, capace di fornire intuizioni utili e durature sul funzionamento della mente e del comportamento umano.\n\n\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221–229.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of positive results: Comparing the standard psychology literature with registered reports. Advances in Methods and Practices in Psychological Science, 4(2), 25152459211007467.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>Proposte di cambiamento</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html",
    "href": "chapters/replication_crisis/07_integrity.html",
    "title": "122  Integrità della ricerca",
    "section": "",
    "text": "Introduzione\nL’integrità della ricerca si basa su principi e standard professionali che mirano a garantire l’affidabilità e la qualità della ricerca, distinguendosi dall’etica della ricerca, che si focalizza su principi morali. La condivisione dei dati, il consenso informato, e la trasparenza nelle pratiche di ricerca sono elementi chiave. I codici di condotta sono essenziali per orientare i comportamenti etici, tanto dei ricercatori quanto delle istituzioni. Le pratiche di ricerca discutibili, la fabbricazione e falsificazione dei dati, il plagio, e la gestione dei conflitti di interesse sono sfide da affrontare per mantenere l’integrità della ricerca. È fondamentale promuovere una cultura di ricerca che privilegi l’onestà, la trasparenza e il rispetto dei principi etici.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>122</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "href": "chapters/replication_crisis/07_integrity.html#standard-professionali-nei-codici-di-condotta-per-lintegrità-della-ricerca",
    "title": "122  Integrità della ricerca",
    "section": "122.1 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca",
    "text": "122.1 Standard Professionali nei Codici di Condotta per l’Integrità della Ricerca\nNel campo della ricerca, è essenziale aderire a principi di condotta responsabile. Questi principi, comunemente definiti come buone pratiche di ricerca, stabiliscono gli standard professionali che mirano a ottimizzare qualità e affidabilità degli studi condotti. Se è vero che le idee di base su cosa costituisca una buona pratica di ricerca rimangono relativamente stabili nel tempo, la loro applicazione pratica si evolve in risposta ai cambiamenti sociali, politici e tecnologici. Un esempio lampante di questo adattamento è la crescente enfasi sulla condivisione dei dati di ricerca, facilitata oggi dall’esistenza di repository online gratuiti, che ha portato a un’aspettativa diffusa di massima trasparenza e accessibilità dei dati raccolti. Molto incoraggiata è anche la “buona pratica” corrispondente alla condivisione del codice utilizzato dai ricercatori per analizzare i dati raccolti.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>122</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html#differenziazione-tra-integrità-e-etica-della-ricerca",
    "href": "chapters/replication_crisis/07_integrity.html#differenziazione-tra-integrità-e-etica-della-ricerca",
    "title": "122  Integrità della ricerca",
    "section": "122.2 Differenziazione tra Integrità e Etica della Ricerca",
    "text": "122.2 Differenziazione tra Integrità e Etica della Ricerca\nL’integrità della ricerca si fonda su standard professionali e si distingue nettamente dall’etica della ricerca, che si basa su principi morali quali l’autonomia, la beneficenza, la non-maleficenza e la giustizia. Questi ultimi si traducono in pratiche specifiche, come il consenso informato e la garanzia di verità e confidenzialità nei confronti dei partecipanti. L’adozione di tali principi etici implica l’obbligo per i ricercatori di evitare studi che possano arrecare danno o risultare eccessivamente onerosi per i soggetti coinvolti.\nI codici di condotta per l’integrità della ricerca variano leggermente tra le diverse fonti. Ad esempio, Il codice di condotta europeo per l’integrità della ricerca enfatizza l’importanza di principi come l’onestà, la trasparenza, l’accuratezza, la responsabilità, l’affidabilità, il rispetto e l’indipendenza. Questi principi sono interpretati in termini di comportamenti specifici attesi sia dai ricercatori sia dalle istituzioni di ricerca, come la condivisione dei dati di ricerca nel rispetto delle normative sulla protezione dei dati, come il GDPR europeo.\nUn esempio pratico della variazione degli standard nei codici di condotta è rappresentato dall’evoluzione della condivisione dei dati di ricerca. In precedenza, la condivisione dei dati poteva essere limitata dalla mancanza di infrastrutture adeguate. Oggi, l’accesso facilitato attraverso i repository online e la pressione esercitata dalle riviste scientifiche e dai finanziatori della ricerca hanno reso la condivisione dei dati una pratica standard, riflettendo un cambiamento verso una maggiore apertura e trasparenza nella ricerca.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>122</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/replication_crisis/07_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "href": "chapters/replication_crisis/07_integrity.html#pressioni-e-sfide-nelladesione-ai-codici-di-condotta",
    "title": "122  Integrità della ricerca",
    "section": "122.3 Pressioni e Sfide nell’Adesione ai Codici di Condotta",
    "text": "122.3 Pressioni e Sfide nell’Adesione ai Codici di Condotta\nNonostante l’esistenza di questi codici, i ricercatori, specialmente quelli in fase iniziale della loro carriera, possono trovarsi sotto pressione da parte dei supervisori per adottare comportamenti che si discostano dagli standard stabiliti, spesso a causa della competitività nel campo scientifico e del sistema di valutazione basato sul numero di pubblicazioni. Queste dinamiche possono indurre a pratiche di ricerca discutibili (PRD), che includono la pubblicazione selettiva dei risultati e l’uso di analisi dei dati flessibili per aumentare artificialmente la probabilità di ottenere risultati statisticamente significativi.\nPer mantenere l’integrità della ricerca, è fondamentale creare un ambiente di lavoro che valorizzi l’apertura, l’inclusività e la discussione franca delle pressioni e delle sfide etiche. Questo implica non solo l’adesione ai codici di condotta esistenti ma anche l’impegno attivo delle istituzioni di ricerca nel promuovere la formazione etica e l’integrità tra i ricercatori. Attraverso un tale approccio, la comunità scientifica può aspirare a una ricerca di alta qualità che sia sia eticamente responsabile sia metodologicamente solida.\nÈ degno di nota che Nature, una delle riviste scientifiche più prestigiose al mondo, abbia recentemente promosso il gioco da tavolo Publish or Perish. La descrizione del gioco è particolarmente provocatoria:\n\n“Falsificare dati, screditare altri scienziati, pubblicare una montagna di articoli che ricevono una torre di citazioni: i cinici potrebbero descrivere questi come passi necessari per raggiungere il successo accademico.”\n\nQuesta mossa solleva importanti questioni sullo stato attuale della ricerca scientifica. Non solo il mondo accademico sembra fornire inventivi distorti, ma anche il sistema economico delle riviste scientifiche presenta una componente di monetizzazione che appare in conflitto con gli obiettivi fondamentali della ricerca scientifica. Questo porta all’accettazione di pratiche disoneste, perché funzionali allo status quo.\nIn questo panorama complesso, emergono voci di dissenso che auspicano e si impegnano per una riforma del mondo pragmatico della scienza (McElreath, 2020; Smaldino & McElreath, 2016). Questa situazione invita a una riflessione profonda sulla necessità di bilanciare la produttività accademica con l’etica e la qualità della ricerca, nonché sul ruolo delle riviste scientifiche nel plasmare il panorama della ricerca contemporanea.\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of bad science. Royal Society open science, 3(9), 160384.",
    "crumbs": [
      "Crisi",
      "<span class='chapter-number'>122</span>  <span class='chapter-title'>Integrità della ricerca</span>"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html",
    "href": "chapters/epiloque/epiloque.html",
    "title": "Considerazioni Conclusive",
    "section": "",
    "text": "Limiti dell’Inferenza Frequentista\nNel corso di questa trattazione, abbiamo esaminato i limiti dell’inferenza frequentista, in particolare quando viene impiegata come “filtro” per distinguere i risultati scientifici rilevanti da quelli trascurabili. L’eccessiva dipendenza dai valori-p è stata oggetto di critiche per la sua associazione con inferenze inadeguate; gli effetti possono essere notevolmente sovrastimati, talvolta persino nella direzione errata, quando la stima è vincolata alla significatività statistica in presenza di dati altamente variabili (Loken & Gelman, 2017).\nLa persistenza e la resistenza del valore-p come indicatore di significatività sono sorprendenti, nonostante le critiche di lunga data e i dibattiti sul suo uso improprio e sulla sua errata interpretazione (Gardner e Altman, 1986; Cohen, 1994; Anderson et al., 2000; Fidler et al., 2004; Finch et al., 2004). Il continuo uso di questa tenacia può offrire spunti su come tali indici, insieme alle euristiche utilizzate per interpretarli (ad esempio, l’assegnazione di soglie come 0.05, 0.01 e 0.001 per determinati livelli di significatività), siano adottati dai ricercatori per ottenere una comprensione intuitiva, sebbene eccessivamente semplificata, della struttura dei loro dati. Inoltre, l’uso di un simile indice risulta particolarmente rilevante in contesti che richiedono decisioni e relative giustificazioni (ad esempio, in ambito medico).\nPurtroppo, queste euristiche sono diventate estremamente rigide, e il raggiungimento della significatività si è trasformato in un obiettivo fine a se stesso, piuttosto che in uno strumento per comprendere i dati (Cohen, 1994; Kirk, 1996). Ciò è particolarmente problematico considerando che i valori-p possono essere utilizzati solo per rifiutare l’ipotesi nulla e non per accettarla come vera, poiché un risultato statisticamente non significativo non implica l’assenza di differenze tra gruppi o l’assenza di un effetto di un trattamento (Wagenmakers, 2007; Amrhein et al., 2019).\nI fraintendimenti e l’uso improprio dei valori-p, il cosiddetto “p-hacking” (Simmons et al., 2011), hanno incentivato pratiche scientifiche discutibili, contribuendo in modo rilevante alla crisi di riproducibilità nella scienza psicologica (Chambers et al., 2014; Szucs e Ioannidis, 2016).",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "href": "chapters/epiloque/epiloque.html#la-crisi-della-replicabilità",
    "title": "Considerazioni Conclusive",
    "section": "La Crisi della Replicabilità",
    "text": "La Crisi della Replicabilità\nLa crisi della replicabilità rappresenta una sfida non solo per la ricerca psicologica, ma anche per l’applicazione pratica delle sue teorie. Quando i risultati degli studi non possono essere replicati in contesti diversi, si mette in dubbio la validità e l’affidabilità delle teorie psicologiche su cui si basano gli interventi clinici e le politiche pubbliche. Questo non solo mina la fiducia nella scienza psicologica, ma limita anche la capacità dei professionisti di sviluppare trattamenti efficaci e basati sull’evidenza. Pertanto, è fondamentale che la comunità scientifica adotti pratiche di ricerca rigorose e trasparenti per garantire che le scoperte siano replicabili e applicabili nel mondo reale.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#come-uscirne",
    "href": "chapters/epiloque/epiloque.html#come-uscirne",
    "title": "Considerazioni Conclusive",
    "section": "Come uscirne?",
    "text": "Come uscirne?\nL’abbandono dell’inferenza frequentista a favore dei metodi bayesiani, per ragioni quali la maggiore flessibilità, una migliore accuratezza in presenza di dati rumorosi e campioni piccoli, una minore predisposizione agli errori di tipo I, la possibilità di incorporare conoscenze pregresse nell’analisi e la chiarezza e facilità di interpretazione dei risultati (Kruschke, 2010; Kruschke et al., 2012; Etz e Vandekerckhove, 2016; Wagenmakers et al., 2016, 2018; Dienes e Mclatchie, 2018), è una delle strategie proposte per affrontare la crisi della replicabilità nella ricerca psicologica. Tuttavia, sebbene questo cambiamento sia rilevante, non è sufficiente da solo. I problemi più profondi derivano anche da un sistema accademico caratterizzato da incentivi distorti, come la pressione a pubblicare risultati significativi, e dalla riluttanza delle riviste scientifiche a riconoscere e affrontare casi di frode o a ritirare articoli quando necessario.\nUna proposta su cui insiste molto McElreath (2020) è quella di passare da un approccio descrittivo della relazione tra variabili — tipico dei modelli lineari e dei modelli lineari generalizzati — a una prospettiva che miri a descrivere formalmente il meccanismo generatore dei dati sottostante al fenomeno in esame. In questo contesto, il ricercatore dovrebbe formulare ipotesi esplicite sul processo che genera i dati e fornire un test quantitativo di tali ipotesi. Questo approccio porta naturalmente alla pratica del confronto tra modelli, un metodo che abbiamo discusso in diversi capitoli di questo testo. Tale confronto può essere effettuato utilizzando tecniche come la validazione incrociata bayesiana Leave-One-Out (LOO), che permette di valutare la robustezza dei modelli e la loro capacità di generalizzare a nuovi dati. Ma si tengano anche a mente i limiti di tale approccio (Navarro, 2019).\nUn altro approccio attuale per superare la cosiddetta “junk science” (Calin-Jageman & Caldwell, 2014; Gelman & Weakliem, 2009; Jung et al., 2014), che troppo spesso affligge la psicologia e non solo, è la “rivoluzione causale”. Questo movimento si concentra sul tentativo di comprendere e identificare le relazioni causali in contesti naturali, superando l’arbitrarietà e l’artificialità degli esperimenti di laboratorio tradizionali. La “rivoluzione causale” ha molto in comune con l’approccio di McElreath (2020), poiché anche qui si richiede ai ricercatori di formulare ipotesi causali in maniera esplicita e di confrontare modelli alternativi che rappresentano diverse ipotesi sui rapporti causali. Questo approccio non solo migliora la comprensione dei fenomeni studiati, ma aumenta anche la credibilità e la replicabilità dei risultati scientifici.\nQuesti cambiamenti prevedono anche una profonda revisione dei metodi didattici e dei programmi dei corsi, in cui si insegna agli studenti come formulare inferenze basate sui dati empirici raccolti in psicologia. Questo tema è stato approfondito da studiosi come Mine Dogucu [Johnson et al. (2022); dogucu2022current; rosenberg2022making; dogucu2021web]. Come dovrebbe ormai essere evidente al lettore, il presente testo ha accettato questa sfida.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/epiloque/epiloque.html#conclusioni",
    "href": "chapters/epiloque/epiloque.html#conclusioni",
    "title": "Considerazioni Conclusive",
    "section": "Conclusioni",
    "text": "Conclusioni\nL’approccio bayesiano rappresenta una risorsa fondamentale per l’analisi dei dati psicologici, offrendo strumenti avanzati per gestire l’incertezza, integrare conoscenze pregresse e adattarsi a modelli complessi. La sua capacità di fornire previsioni robuste e aggiornare continuamente le ipotesi alla luce di nuovi dati lo rende particolarmente adatto per esplorare e comprendere la mente umana e il comportamento in tutte le loro sfaccettature.\nTuttavia, per affrontare la crisi della replicabilità e migliorare la qualità della ricerca scientifica in psicologia, non è sufficiente adottare esclusivamente metodi bayesiani. È essenziale combinare questi metodi con altre pratiche rigorose e principi metodologici solidi. Tra queste pratiche, la formalizzazione dei modelli generativi consente di descrivere chiaramente i processi sottostanti che generano i dati, migliorando la trasparenza e la validità delle inferenze. Inoltre, il confronto rigoroso tra modelli, ad esempio tramite tecniche di validazione incrociata, aiuta a determinare quale modello meglio rappresenta i dati e a evitare interpretazioni errate.\nInfine, l’adozione di una prospettiva causale esplicita è cruciale per identificare correttamente le relazioni di causa-effetto, evitando l’arbitrarietà e l’artificialità degli esperimenti tradizionali. Solo attraverso un approccio integrato, che combini l’inferenza bayesiana con queste pratiche metodologiche avanzate, sarà possibile progredire verso una scienza psicologica più affidabile e riproducibile, capace di fornire una comprensione più profonda e accurata del comportamento umano.\n\n\n\n\nCalin-Jageman, R. J., & Caldwell, T. L. (2014). Replication of the superstition and performance study by Damisch, Stoberock, and Mussweiler (2010). Social Psychology.\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power: Too little attention has been paid to the statistical challenges in estimating small effects. American Scientist, 97(4), 310–316.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nJung, K., Shavitt, S., Viswanathan, M., & Hilbe, J. M. (2014). Female hurricanes are deadlier than male hurricanes. Proceedings of the National Academy of Sciences, 111(24), 8782–8787.\n\n\nLoken, E., & Gelman, A. (2017). Measurement Error and the Replication Crisis. Science, 355(6325), 584–585.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28–34.",
    "crumbs": [
      "Epilogo",
      "Considerazioni Conclusive"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html",
    "href": "chapters/appendix/a00_installation.html",
    "title": "Appendice A — Ambiente di lavoro",
    "section": "",
    "text": "A.1 Guida all’Installazione Locale dei Jupyter Notebook\nPer facilitare l’apprendimento e l’applicazione delle tecniche di analisi dei dati discusse in questo corso, utilizzeremo i Jupyter Notebook come strumento principale. I Jupyter Notebook sono documenti interattivi che consentono di combinare codice, testo narrativo, visualizzazioni grafiche e altri elementi multimediali, rendendoli ideali per documentare e condividere analisi di dati in modo trasparente e riproducibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "href": "chapters/appendix/a00_installation.html#guida-allinstallazione-locale-dei-jupyter-notebook",
    "title": "Appendice A — Ambiente di lavoro",
    "section": "",
    "text": "A.1.1 Prerequisiti per l’Uso dei Jupyter Notebook\nPer utilizzare i Jupyter Notebook, è necessario soddisfare alcuni prerequisiti:\n\nInstallare Python: È il linguaggio di programmazione fondamentale per il nostro corso e deve essere installato sul vostro computer.\nGestione degli Ambienti Virtuali con conda: Utilizzeremo conda per creare e gestire ambienti virtuali, che permettono di isolare e gestire le dipendenze del progetto.\nInstallazione dei Pacchetti Python Necessari: Dovrete installare specifici pacchetti Python, inclusi PyMC per l’analisi bayesiana, e altri pacchetti utili, all’interno dell’ambiente virtuale creato per questo corso.\nInterfaccia per l’Uso dei Jupyter Notebook: Avrete bisogno di un IDE (Integrated Development Environment) che supporti i Jupyter Notebook, come Visual Studio Code, per scrivere e eseguire i vostri notebook.\n\n\n\nA.1.2 Installazione di Anaconda\nLa maggior parte dei requisiti elencati può essere agevolmente soddisfatta tramite l’installazione di Anaconda, una distribuzione di Python che include conda e facilita la gestione degli ambienti virtuali e l’installazione dei pacchetti.\n\n\n\n\n\n\nSe Anaconda è già stata installata, potrebbero sorgere problemi dopo l’aggiornamento del sistema operativo. In tal caso, sarà indispensabile procedere con una nuova installazione di Anaconda.\n\n\n\n\nA.1.2.1 Per Utenti macOS\nSe lavorate su macOS, potreste trovare più pratico utilizzare conda direttamente dal Terminale o da un’applicazione terminale moderna come Warp, piuttosto che attraverso Anaconda Navigator. In questo caso, potete optare per installare una versione di Visual Studio Code indipendente da quella fornita con Anaconda, per un maggiore controllo e flessibilità.\n\n\nA.1.2.2 Per Utenti Windows\nPer coloro che utilizzano Windows, l’uso di Jupyter Notebook tramite Anaconda Navigator potrebbe risultare la scelta più semplice e diretta, grazie all’integrazione e alla facilità d’uso fornite da Anaconda in ambienti Windows.\n\n\n\nA.1.3 Creazione e Configurazione dell’Ambiente Virtuale\nIndipendentemente dal sistema operativo, è fondamentale installare e configurare conda, che vi permetterà di creare {ref}appendix-virtual-env dedicati. All’interno di questi ambienti, installerete cmdstanpy (o PyMC) e gli altri pacchetti richiesti per il corso. La strada più semplice per soddisfare questi requisiti è attraverso l’installazione di Anaconda, che semplifica notevolmente il processo di configurazione iniziale e gestione degli ambienti virtuali.\nQuesta guida all’installazione locale mira a fornirvi tutti gli strumenti necessari per iniziare a utilizzare i Jupyter Notebook nel contesto del nostro corso, facilitando un apprendimento efficiente e la condivisione dei risultati delle vostre analisi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#guida-allinstallazione-di-anaconda",
    "href": "chapters/appendix/a00_installation.html#guida-allinstallazione-di-anaconda",
    "title": "Appendice A — Ambiente di lavoro",
    "section": "A.2 Guida all’Installazione di Anaconda",
    "text": "A.2 Guida all’Installazione di Anaconda\nAnaconda è una distribuzione popolare per la programmazione in Python. Ecco una guida passo-passo per l’installazione:\n\nScaricare Anaconda:\n\nVisitate il sito ufficiale di Anaconda: https://www.anaconda.com/.\nScegliete la versione adatta al vostro sistema operativo (Windows, macOS o Linux).\nOptate per il download dell’ultima versione disponibile, che include l’ultima versione di Python.\n\nInstallare Anaconda:\n\nEseguite il file di installazione scaricato.\nSeguite le istruzioni visualizzate, mantenendo le impostazioni predefinite, a meno che non abbiate esigenze specifiche.\n\nAggiungere Anaconda al ‘PATH’ del Sistema:\n\nDurante l’installazione, vi sarà chiesto se desiderate aggiungere Anaconda al ‘PATH’ del sistema. Questo passaggio è cruciale poiché consente di utilizzare Python da qualunque parte del computer.\nVi consiglio di selezionare questa opzione (altri metodi sono possibili, ma questo ha dimostrato di funzionare senza problemi).\n\nConfermare l’Installazione:\n\nAl termine dell’installazione, aprite PowerShell all’interno di Anaconda Navigagor (Windows) o il terminale (macOS/Linux) e digitate python --version per verificare se l’installazione è riuscita. Se compare la versione di Python, tutto è andato a buon fine.\n\n\nAnaconda include il Navigator, un’interfaccia utente grafica per gestire ambienti di sviluppo, installare librerie aggiuntive e lanciare strumenti come Jupyter Notebook, che consente (in alternativa a VS Code) di scrivere ed eseguire codice Python.\n\n\n\n\n\n\nIstruzioni Specifiche per Utenti Windows:\n\nScaricare Anaconda:\n\nScaricate la versione “64-Bit Graphical Installer” dal sito di Anaconda.\n\nInstallare Anaconda:\n\nAvviate l’installer scaricato e seguite le istruzioni visualizzate.\nDurante l’installazione, selezionate “Just Me” (solo per l’utente corrente).\nMantenete il percorso di installazione predefinito.\n\nIncludere Anaconda nel ‘PATH’:\n\nIMPORTANTE: Selezionate l’opzione per aggiungere Anaconda al PATH e impostarlo come installazione di Python di default. Di default, questa opzione è deselezionata.\n\nVerifica dell’Installazione:\n\nCercate “Anaconda Navigator” nel menu Start. Se si apre correttamente, l’installazione è riuscita.\nAprite “Anaconda Prompt” (o “PowerShell”) dal menu Start di Anaconda Navigator e digitate conda --version per confermare l’installazione di conda.\n\n\nSeguite attentamente queste istruzioni per garantire un’installazione senza problemi.\nPer maggiori dettagli, consultate il tutorial su come installare Anaconda su Windows: Tutorial Installazione di Anaconda su Windows. Questo tutorial offre spiegazioni dettagliate e una guida passo-passo.\n\n\n\nUna volta installato Anaconda, potrete utilizzare Anaconda Navigator per gestire progetti Python, installare librerie necessarie e avviare strumenti come Jupyter Notebook.\n\n\n\n\n\n\nÈ necessario comprendere la differenza tra applicazione (App) e installer.\nCos’è un’Applicazione (App)\nUn’applicazione, comunemente chiamata “app”, è un software che funziona sul vostro computer o dispositivo mobile per uno scopo specifico, come navigare in internet, inviare messaggi, elaborare testi o fare calcoli. Esempi includono browser web come Google Chrome, programmi di elaborazione testi come Microsoft Word, o sistemi come Anaconda Navigator.\nCos’è un Installer\nUn installer è un software che installa un’applicazione sul vostro computer. Tipicamente, quando scaricate un’applicazione da internet, scaricate in realtà l’installer. L’installer ha il compito di: - Copiare i file dell’app nella corretta cartella del computer. - Creare scorciatoie per l’app, come icone sul desktop o voci nel menu Start. - Configurare impostazioni iniziali per il corretto funzionamento dell’app.\nDopo l’Installazione\nDopo che l’installer ha completato il suo lavoro, l’applicazione sarà pronta all’uso e l’installer può essere eliminato.\nIn sintesi, l’applicazione è il software che userete per svolgere compiti specifici, mentre l’installer è lo strumento temporaneo per installare l’applicazione sul vostro computer. Capire questa distinzione è fondamentale nel mondo dell’informatica.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#sec-virtual-environment",
    "href": "chapters/appendix/a00_installation.html#sec-virtual-environment",
    "title": "Appendice A — Ambiente di lavoro",
    "section": "A.3 L’Ambiente Virtuale in Python",
    "text": "A.3 L’Ambiente Virtuale in Python\nDopo aver installato Python tramite Anaconda, un aspetto fondamentale da considerare è la creazione di un ambiente virtuale. Un ambiente virtuale rappresenta uno spazio dedicato sul vostro computer, dove è possibile installare e gestire le librerie Python necessarie per il corso, inclusi quelle per l’analisi statistica. La creazione di un ambiente virtuale è estremamente vantaggiosa poiché contribuisce all’organizzazione del lavoro e previene possibili conflitti tra diverse librerie. Le istruzioni dettagliate per la configurazione di un ambiente virtuale sono disponibili nel Appendice E`.\nL’esecuzione delle fasi precedentemente delineate, ossia l’installazione di Anaconda, la configurazione di Visual Studio Code e la creazione di un ambiente virtuale, assicurerà la completa preparazione di un ambiente di sviluppo locale ottimizzato per l’utilizzo dei Jupyter Notebook nelle vostre attività legate alla data science all’interno di questo corso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#la-shell",
    "href": "chapters/appendix/a00_installation.html#la-shell",
    "title": "Appendice A — Ambiente di lavoro",
    "section": "A.4 La Shell",
    "text": "A.4 La Shell\nPer la creazione e la gestione dell’ambiente di calcolo, l’uso di una shell è indispensabile. Questa può essere approfondita nella sezione {ref}appendix-shell. La shell permette di interagire con il sistema operativo attraverso l’uso di comandi in un terminale. Diverse soluzioni software sono disponibili per facilitare questa interazione.\n\nA.4.1 Unix (MacOS, Linux)\nIn ambienti Unix come MacOS e Linux, ci sono diverse shell tra cui scegliere. Una scelta popolare è Bash, che è comunemente preinstallata su molti sistemi Unix. Un’altra opzione moderna è Zsh, nota per la sua facilità di personalizzazione e funzionalità avanzate. Per un’esperienza di terminale migliorata, warp è un’opzione innovativa che offre un’interfaccia utente ricca di funzionalità e supporto per i comandi intelligenti.\n\n\nA.4.2 Windows\nSu Windows, la shell predefinita è il Prompt dei Comandi, ma non è così potente o flessibile come le shell disponibili su Unix. PowerShell è un’opzione più avanzata disponibile su Windows, che combina la gestione della configurazione e l’automazione delle attività con un linguaggio di scripting.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#lavorare-con-visual-studio-code",
    "href": "chapters/appendix/a00_installation.html#lavorare-con-visual-studio-code",
    "title": "Appendice A — Ambiente di lavoro",
    "section": "A.5 Lavorare con Visual Studio Code",
    "text": "A.5 Lavorare con Visual Studio Code\nPer utilizzare Visual Studio Code con Python e Jupyter Notebook, è essenziale installare le relative estensioni. Per fare ciò, è sufficiente seguire alcuni semplici passaggi:\n\nAvvia Visual Studio Code sul tuo computer.\nNella barra laterale sinistra, trova e clicca sull’icona con quattro quadrati, di cui uno disallineato. Questo è il menu delle estensioni.\nNella barra di ricerca all’interno del menu delle estensioni, digita “Python” e premi Invio. Troverai diverse estensioni relative a Python.\nTrova l’estensione ufficiale di Python sviluppata da Microsoft e installala cliccando sul pulsante “Installa”.\nSuccessivamente, cerca “Jupyter” nella barra di ricerca delle estensioni e premi Invio.\nTrova l’estensione “Jupyter” nell’elenco dei risultati e installala cliccando sul pulsante “Installa”.\n\nUna volta completati questi passaggi, avrai installato con successo le componenti aggiuntive necessarie per lavorare con Python e Jupyter Notebook all’interno di Visual Studio Code. Potrai quindi iniziare a scrivere, eseguire e testare il tuo codice Python e i tuoi notebook Jupyter direttamente nell’ambiente di sviluppo di Visual Studio Code.\nQuando apri un file con estensione .ipynb in Visual Studio Code ricorda di selezionare l’ambiente virtuale che desiderate utilizzare. Puoi farlo tramite la “Command Palette” (⇧⌘P), utilizzando l’istruzione Python: Select Interpreter. In alternativa, puoi fare clic sull’icona Select kernel di Visual Studio Code, che si trova nell’angolo in alto a destra, sotto l’icona degli ingranaggi (⚙️).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#google-colab",
    "href": "chapters/appendix/a00_installation.html#google-colab",
    "title": "Appendice A — Ambiente di lavoro",
    "section": "A.6 Google Colab",
    "text": "A.6 Google Colab\nUtilizzando il link è possibile accedere a Google Colab e iniziare a scrivere codice Python direttamente dal proprio browser, senza dover effettuare alcuna installazione. Basta selezionare l’opzione “Nuovo notebook” per creare un nuovo ambiente di lavoro. Per avere un’introduzione completa sulle funzionalità di Colab, si può consultare la guida disponibile al seguente link. È possibile salvare ogni notebook nella propria cartella di Google Drive per una facile gestione e condivisione dei file.\n\nA.6.1 Uso dei Comandi Speciali in Colab\nNell’ambiente Google Colab, è possibile utilizzare il comando\n!pip list -v\nper visualizzare un elenco dettagliato di tutte le librerie preinstallate. Questo comando fornisce informazioni utili per comprendere quali strumenti sono immediatamente disponibili per l’uso, comprese le versioni delle librerie e i percorsi di installazione.\nIl prefisso ! indica un comando speciale, noto anche come comando “shell”, che consente di interagire con il sistema sottostante di Colab direttamente dalla cella del notebook, eseguendo operazioni al di fuori dell’ambiente Python standard.\n\n\nA.6.2 Installazione di Librerie Supplementari\nSe necessario aggiungere ulteriori librerie all’ambiente Colab, come pymc, bambi, e arviz, è possibile farlo facilmente mediante l’uso dei comandi pip. Ad esempio, per installare queste tre librerie, si possono eseguire i seguenti comandi uno dopo l’altro:\n!pip install bambi\n!pip install pymc\n!pip install arviz\nQuesti comandi non solo installeranno le librerie specificate ma gestiranno anche automaticamente l’installazione delle dipendenze necessarie, tra cui numpy, pandas, matplotlib, seaborn, scipy, e statsmodels, assicurando così che tutto l’ambiente di lavoro sia pronto per l’uso.\n\n\nA.6.3 Google Drive\n\nA.6.3.1 Collegare Google Drive a Colab\nPer accedere alla propria cartella di Google Drive durante l’utilizzo di Colab, è possibile seguire i seguenti passaggi:\n\nDalla pagina iniziale, fare clic sull’icona a forma di cartella (Files) situata nel menu in alto a sinistra.\n\n\n\nSi aprirà un menu con diverse opzioni.\n\n\n\nSelezionare la terza icona tra le quattro disposte orizzontalmente. Apparirà l’istruzione “Run this cell to mount your Google Drive”. Fare clic sull’icona del triangolo contenuta in un cerchio grigio.\nA questo punto, fare clic sull’icona “drive” e successivamente su “MyDrive” per accedere alle cartelle e ai file salvati sul proprio Google Drive.\n\nÈ importante tenere presente che la versione gratuita del runtime di Google Colaboratory non salva le informazioni in modo permanente, il che significa che tutto il lavoro svolto verrà eliminato una volta terminata la sessione. Pertanto, è necessario reinstallare le librerie utilizzate in precedenza ogni volta che ci si connette a Colab. Al contrario, i Jupyter Notebook possono essere salvati nella propria cartella di Google Drive.\nPer salvare un Jupyter Notebook su Google Drive utilizzando Colab, è possibile seguire i seguenti passaggi:\n\nFare clic su File nella barra del menu di Colab.\nSelezionare Save a copy in Drive. Di default, Colab salverà il Notebook nella cartella Colab Notebooks/.ipynb_checkpoints con un nome simile a Untitled7.ipynb.\nDopo aver salvato il Notebook, è consigliabile rinominarlo facendo clic con il pulsante destro del mouse sul file nella cartella di Google Drive e selezionando Rename. In questo modo sarà possibile assegnare un nome più significativo al Notebook.\nPer organizzare i file, è possibile trascinare il Notebook nella cartella desiderata all’interno di Google Drive.\n\nSeguendo questi passaggi, sarà possibile salvare e organizzare i Jupyter Notebook nella propria cartella di Google Drive, consentendo di accedervi facilmente e mantenerli in modo permanente anche dopo la sessione di Colab.\n\n\n\n\n\n\nÈ possibile accedere a un breve tutorial video su come utilizzare Colab e come leggere i dati da un file esterno in un Notebook di Jupyter in Colab. Il video tutorial può essere trovato seguendo il link fornito.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a00_installation.html#stan-playground",
    "href": "chapters/appendix/a00_installation.html#stan-playground",
    "title": "Appendice A — Ambiente di lavoro",
    "section": "A.7 Stan Playground",
    "text": "A.7 Stan Playground\nÈ possibile utilizzare Stan direttamente dal browser tramite il seguente link:\nhttps://stan-playground.flatironinstitute.org\nIl sito consente di caricare un modello Stan e i dati in formato JSON. È possibile compilare il modello, eseguire il campionamento e analizzare le stime a posteriori. La piattaforma supporta anche l’analisi in R o Python, permettendo così di integrare facilmente i risultati nel proprio workflow.\nÈ disponibile una presentazione su Stan Playground dalla conferenza StanCon Oxford 2024 a questo link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Ambiente di lavoro</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html",
    "href": "chapters/appendix/a01_markdown.html",
    "title": "Appendice B — Jupyter Notebook",
    "section": "",
    "text": "B.1 Configurazione Locale per Jupyter Notebook\nPer iniziare a lavorare con i Jupyter Notebook nel proprio ambiente di sviluppo locale, è necessario completare alcuni passaggi preliminari che assicurano una configurazione ottimale:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "href": "chapters/appendix/a01_markdown.html#configurazione-locale-per-jupyter-notebook",
    "title": "Appendice B — Jupyter Notebook",
    "section": "",
    "text": "Installazione di Python tramite Anaconda: Anaconda è una distribuzione di Python che include già Jupyter e altre librerie utili per la data science e l’analisi di dati. Seguendo le istruzioni dettagliate disponibili sul sito di Anaconda (e fornite in precedenza in questa dispensa), si può facilmente installare Python e Jupyter sul proprio sistema.\nSelezione di un Ambiente di Sviluppo Integrato (IDE): Visual Studio Code (VS Code) rappresenta una scelta eccellente per chi cerca un IDE versatile e gratuito. Disponibile al download dal sito ufficiale, VS Code supporta Python tramite l’installazione di una specifica estensione. Dopo aver installato VS Code, è possibile aggiungere il supporto per Python e per i Jupyter Notebook installando l’estensione “Python” disponibile nella sezione “Extensions”, identificabile dall’icona dei quattro quadrati. Per una completa integrazione dei notebook Jupyter, potrebbe essere necessario installare anche la libreria ipykernel.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#celle",
    "href": "chapters/appendix/a01_markdown.html#celle",
    "title": "Appendice B — Jupyter Notebook",
    "section": "B.2 Celle",
    "text": "B.2 Celle\nI Jupyter Notebook sono organizzati in celle, elementi discreti che possono contenere codice o testo (markdown). La possibilità di cambiare il tipo di una cella tramite il menu “Cell” o la barra degli strumenti, selezionando “Code” per codice Python o “Markdown” per annotazioni testuali, rende i notebook estremamente versatili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#formattazione-del-testo-con-markdown",
    "href": "chapters/appendix/a01_markdown.html#formattazione-del-testo-con-markdown",
    "title": "Appendice B — Jupyter Notebook",
    "section": "B.3 Formattazione del Testo con Markdown",
    "text": "B.3 Formattazione del Testo con Markdown\nMarkdown permette di arricchire le celle di testo con formattazioni varie, creando un documento strutturato e leggibile. Ecco alcuni esempi:\n\nTitoli: # Titolo per un titolo di primo livello, ## Sottotitolo per un secondo livello, e così via.\nElenchi: - Elemento per elenchi puntati, 1. Elemento per elenchi numerati.\nCollegamenti: [Testo del link](URL) per inserire un link.\nEnfasi: **grassetto** per il testo in grassetto, *corsivo* per il corsivo.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "href": "chapters/appendix/a01_markdown.html#comandi-magici-in-jupyter-notebook",
    "title": "Appendice B — Jupyter Notebook",
    "section": "B.4 Comandi Magici in Jupyter Notebook",
    "text": "B.4 Comandi Magici in Jupyter Notebook\nI Jupyter Notebook supportano i “comandi magici”, comandi speciali che iniziano con % (per comandi su una singola riga) o %% (per comandi che occupano un’intera cella). Questi comandi offrono funzionalità avanzate come:\n\n%run: esegue un file Python esterno.\n%timeit: valuta il tempo di esecuzione di una singola riga di codice.\n%matplotlib inline: integra grafici Matplotlib direttamente nel notebook.\n%load: carica il codice da un file esterno in una cella.\n%reset: cancella tutte le variabili definite nel notebook.\n%pwd e %cd: gestiscono il percorso della directory di lavoro.\n\nDigitando %lsmagic in una cella, si può accedere all’elenco completo dei comandi magici disponibili, esplorando così ulteriori strumenti e funzionalità offerte da Jupyter Notebook.\nIn conclusione, i Jupyter Notebook rappresentano uno strumento indispensabile per chi lavora nel campo della programmazione e dell’analisi dati, grazie alla loro capacità di unire codice, visualizzazione dei dati, e annotazioni testuali in un unico documento interattivo e facilmente condivisibile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Jupyter Notebook</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html",
    "href": "chapters/appendix/a02_shell.html",
    "title": "Appendice C — La Shell",
    "section": "",
    "text": "C.1 Che cos’è una Shell?\nUna shell è un programma che riceve comandi dall’utente tramite tastiera (o da file) e li passa al sistema operativo per l’esecuzione. Può essere accessibile tramite un terminale (o un emulatore di terminale).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a02_shell.html#che-cosè-una-shell",
    "href": "chapters/appendix/a02_shell.html#che-cosè-una-shell",
    "title": "Appendice C — La Shell",
    "section": "",
    "text": "C.1.1 Breve Storia della Shell\n\n1971: Ken Thompson di Bell Labs sviluppa la shell per UNIX.\n1977: Stephen Bourne introduce la Bourne shell (sh).\nDopo il 1977: Viene sviluppata la C shell (csh) e tcsh.\nBash: Sviluppata da Brian Fox come sostituto migliorato della Bourne shell.\n1990: Paul Falsted sviluppa Zsh, che diventa la shell predefinita per macOS dal 2019.\n\n\n\nC.1.2 Windows vs macOS/Linux\n\nWindows 10: È possibile utilizzare Bash attivando il Windows Subsystem for Linux. Tuttavia, l’ambiente preferito è solitamente PowerShell.\nmacOS/Linux: Zsh è la shell predefinita in entrambi i sistemi. È consigliabile sfruttare l’applicazione warp per un’esperienza utente moderna e ottimizzata.\n\n\n\nC.1.3 Comandi di Base Unix\n\npwd: Mostra il percorso della directory corrente.\nls: Elenca file e cartelle nella directory corrente.\ncd: Cambia directory. Senza argomenti, ti porta alla directory home.\nmkdir: Crea una nuova directory.\nrmdir: Rimuove una directory vuota.\nImportante: Evitare spazi nei nomi di file e cartelle.\n\n\nC.1.3.1 Gestione File\n\nmv: Rinomina o sposta file (usa \\ o '' per i nomi di file con spazi).\ncp: Copia file o cartelle (usa -r per le cartelle).\nrm: Rimuove file o cartelle (usa -i per confermare prima di eliminare).\n\n\n\nC.1.3.2 Visualizzazione e Manipolazione Contenuti dei File\n\nless/more: Visualizza il contenuto dei file con possibilità di navigazione.\ncat: Mostra l’intero contenuto di un file.\nhead: Mostra le prime righe di un file.\ntail: Mostra le ultime righe di un file.\n\n\n\n\nC.1.4 Comandi di Base PowerShell\nPer adattare i comandi Unix per l’utilizzo in PowerShell di Windows, molti dei comandi rimangono simili grazie alla natura cross-platform di PowerShell e alla sua flessibilità nel gestire sia gli stili di comando Unix che quelli tradizionali di Windows. Ecco come si traducono i comandi:\n\nGet-Location o semplicemente pwd: Mostra il percorso della directory corrente, simile a pwd in Unix.\nGet-ChildItem o semplicemente ls: Elenca file e cartelle nella directory corrente, equivalente a ls in Unix.\nSet-Location o semplicemente cd: Cambia directory. cd senza argomenti ti porta alla directory home in PowerShell con cd ~.\nNew-Item -ItemType Directory -Name 'nomeDirectory': Crea una nuova directory, simile a mkdir in Unix.\nRemove-Item -Path 'nomeDirectory' -Force: Rimuove una directory, anche se non vuota. Equivalente a rmdir in Unix, ma più potente perché può rimuovere anche directory con contenuti utilizzando il parametro -Force.\n\n\nC.1.4.1 Gestione File\n\nMove-Item -Path 'origine' -Destination 'destinazione': Rinomina o sposta file, equivalente a mv in Unix.\nCopy-Item -Path 'origine' -Destination 'destinazione': Copia file o cartelle, simile a cp in Unix. Usa -Recurse per copiare cartelle.\nRemove-Item -Path 'file' -Force: Rimuove file o cartelle, simile a rm in Unix. Usa -Force per rimuovere senza conferme e -Recurse per rimuovere cartelle con contenuti.\n\n\n\nC.1.4.2 Visualizzazione e Manipolazione Contenuti dei File\n\nGet-Content 'file' | More: Visualizza il contenuto dei file con possibilità di navigazione, simile a less/more in Unix.\nGet-Content 'file': Mostra l’intero contenuto di un file, equivalente a cat in Unix.\nGet-Content 'file' -Head &lt;numero&gt;: Mostra le prime righe di un file, simile a head in Unix.\nGet-Content 'file' -Tail &lt;numero&gt;: Mostra le ultime righe di un file, equivalente a tail in Unix.\n\n\n\n\n\n\n\nÈ cruciale familiarizzarsi con l’utilizzo dei percorsi relativi per semplificare gli spostamenti tra le diverse directory. L’impiego dei percorsi relativi rende il processo di navigazione più intuitivo e meno incline agli errori.\n\nNomi Chiari e Concisi: Evitate di includere spazi nei nomi dei file e delle cartelle. Preferite l’utilizzo di trattini bassi (_) per separare le parole e mantenere una struttura leggibile e facilmente comprensibile.\nEvitare Caratteri Speciali: È importante evitare l’inserimento di caratteri speciali come asterischi (*), dollari ($), slash (/, ), punti (.), virgole (,), punti e virgole (;), parentesi (()), parentesi quadre ([]), parentesi graffe ({}), ampersand (&), barre verticali (|), punti esclamativi (!), punti interrogativi (?) nei nomi dei file e delle cartelle. Talvolta, anche l’uso del trattino (-) può causare problemi; quindi è consigliabile evitarlo. Questi caratteri possono generare problemi di compatibilità con alcuni sistemi operativi o applicazioni, rendendo più complessa la gestione dei file.\nDifferenziazione tra Maiuscole e Minuscole: Unix distingue tra maiuscole e minuscole (tratta le lettere come oggetti distinti), mentre Windows non lo fa. Per evitare confusioni, è consigliabile adottare una politica conservativa: considerate i nomi che differiscono solo per la case delle lettere come distinti.\n\nSeguendo questi consigli, è possibile ottimizzare notevolmente l’organizzazione e la gestione dei propri file, migliorando l’efficienza del lavoro e riducendo il rischio di errori.\n\n\n\nCon la pratica, la riga di comando diventa uno strumento molto efficiente. Questa breve guida fornisce le basi per iniziare a esplorare e gestire i file dal terminale, offrendo una base di partenza per ulteriori apprendimenti. La familiarità con la shell è fondamentale nella data science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>La Shell</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_colab_tutorial.html",
    "href": "chapters/appendix/a03_colab_tutorial.html",
    "title": "Appendice D — Colab: un breve tutorial",
    "section": "",
    "text": "D.1 Preparazione su Google Drive\nPer iniziare, è necessario effettuare alcune operazioni preliminari su Google Drive:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a03_colab_tutorial.html#preparazione-su-google-drive",
    "href": "chapters/appendix/a03_colab_tutorial.html#preparazione-su-google-drive",
    "title": "Appendice D — Colab: un breve tutorial",
    "section": "",
    "text": "Salvataggio dei file necessari: Accedi al tuo account Google Drive e salva i file di interesse, come un dataset e un Jupyter Notebook. Per esempio, potresti creare un Jupyter Notebook con Visual Studio Code e salvarlo con l’estensione .ipynb. In questo esempio, il file STAR.csv è stato salvato nella cartella drive/MyDrive/teaching/psicometria/2024.\nPosizionamento dei file: Assicurati di conoscere con precisione il percorso della cartella in cui hai salvato i tuoi file. È possibile salvare il notebook in qualsiasi cartella, ma è importante ricordare dove si trova. Nel nostro esempio, anche il notebook import_data.ipynb è stato salvato nella stessa cartella del dataset.\n\n\nD.1.1 Collegamento a Google Colab\nPer collegare il tuo Google Drive a Colab, inserisci il seguente codice nella prima cella del tuo Jupyter Notebook su Colab:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nEsegui questa cella per iniziare il processo di autenticazione. Ti verrà richiesto di inserire le tue credenziali (si consiglia di utilizzare l’account istituzionale) e di concedere i permessi necessari a Colab per accedere al tuo Drive.\n\n\nD.1.2 Verifica del file\nPrima di procedere, è utile verificare che il file desiderato si trovi effettivamente nel percorso specificato. Usa un comando simile al seguente per elencare i file presenti nella cartella:\n!ls drive/MyDrive/teaching/psicometria/2024\nSe il comando mostra il file STAR.csv, significa che è presente nella cartella e pronto per essere utilizzato.\n\n\nD.1.3 Importazione dei pacchetti e del dataset\nPrima di importare i dati, importa i pacchetti Python necessari per la tua analisi:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nSuccessivamente, puoi importare i dati direttamente dal file CSV specificando il percorso completo:\ndf = pd.read_csv(\"drive/MyDrive/teaching/psicometria/2024/STAR.csv\")\nÈ fondamentale usare il percorso completo dal punto di montaggio drive fino al nome del file. Il percorso varierà a seconda dell’utente e della struttura del suo Drive.\n\n\nD.1.4 Visualizzazione dei dati\nCon i dati ora disponibili in df, puoi procedere con l’analisi. Per esempio, per creare un istogramma della variabile reading, puoi usare il seguente codice:\n_ = sns.histplot(data=df, x=\"reading\", stat='density')\nQuesto ti permetterà di visualizzare la distribuzione dei dati relativi alla lettura nel dataset STAR.csv.\nSeguendo questi passaggi, puoi facilmente lavorare con i file salvati su Google Drive direttamente all’interno di un Jupyter Notebook su Google Colab.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Colab: un breve tutorial</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html",
    "href": "chapters/appendix/a04_virtual_env.html",
    "title": "Appendice E — Ambienti virtuali",
    "section": "",
    "text": "E.1 Concetto di Ambiente Virtuale\nUn ambiente virtuale è uno spazio di lavoro isolato sul vostro computer, dove potete installare e utilizzare librerie Python senza interferire con il sistema principale. Questo isolamento consente di gestire le versioni delle librerie in modo efficiente, mantenendo il sistema organizzato e sicuro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "href": "chapters/appendix/a04_virtual_env.html#vantaggi-delluso-degli-ambienti-virtuali",
    "title": "Appendice E — Ambienti virtuali",
    "section": "E.2 Vantaggi dell’Uso degli Ambienti Virtuali",
    "text": "E.2 Vantaggi dell’Uso degli Ambienti Virtuali\n\nIsolamento: Permette di selezionare e mantenere versioni specifiche di Python e delle librerie, garantendo la compatibilità e la stabilità del progetto.\nOrdine e Sicurezza: Mantiene separato l’ambiente virtuale dal sistema principale, evitando conflitti e assicurando che le modifiche non influenzino altri programmi.\nRiproducibilità del Codice: Consente di condividere il codice in modo che funzioni correttamente su altri computer, garantendo coerenza e riproducibilità del lavoro.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "href": "chapters/appendix/a04_virtual_env.html#procedura-per-la-creazione-di-un-ambiente-virtuale-con-conda",
    "title": "Appendice E — Ambienti virtuali",
    "section": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda",
    "text": "E.3 Procedura per la Creazione di un Ambiente Virtuale con Conda\nPer creare e gestire ambienti virtuali, è possibile utilizzare conda, uno strumento incluso in Anaconda. Seguire i seguenti passaggi:\n\nAssicurarsi di avere Anaconda correttamente installato sul sistema.\nUtilizzare il terminale su macOS/Linux o PowerShell su Windows.\nEvitare di installare pacchetti direttamente nell’ambiente base di Conda.\nCreare un nuovo ambiente virtuale usando il comando conda create.\nAttivare l’ambiente virtuale appena creato utilizzando conda activate.\nInstallare i pacchetti necessari all’interno dell’ambiente virtuale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "href": "chapters/appendix/a04_virtual_env.html#gestione-dellambiente-virtuale",
    "title": "Appendice E — Ambienti virtuali",
    "section": "E.4 Gestione dell’Ambiente Virtuale",
    "text": "E.4 Gestione dell’Ambiente Virtuale\nPer una gestione più efficiente degli ambienti virtuali, è consigliabile utilizzare la linea di comando anziché l’interfaccia grafica di Anaconda. Questo offre maggiore controllo e flessibilità nel processo di creazione e gestione degli ambienti.\nSeguendo correttamente questi passaggi, è possibile sfruttare appieno i vantaggi degli ambienti virtuali, garantendo un ambiente di sviluppo Python pulito e ben organizzato.\n\n\n\n\n\n\nÈ fondamentale evitare l’installazione diretta di pacchetti nell’ambiente base di Conda. Assicuratevi sempre di seguire attentamente i seguenti passaggi:\n\nDisattivate l’ambiente base.\nCreate un nuovo ambiente virtuale.\nAttivate il nuovo ambiente appena creato.\n\nSolo dopo aver completato questi passaggi, è sicuro procedere con l’installazione dei pacchetti necessari. È possibile verificare l’ambiente attivo osservando il nome visualizzato all’inizio del prompt nel terminale.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "href": "chapters/appendix/a04_virtual_env.html#gestione-degli-ambienti-virtuali-passaggi-essenziali",
    "title": "Appendice E — Ambienti virtuali",
    "section": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali",
    "text": "E.5 Gestione degli Ambienti Virtuali: Passaggi Essenziali\n\nDisattivare l’Ambiente Virtuale Corrente: Se siete in un ambiente virtuale e desiderate uscirne, utilizzate il comando:\nconda deactivate\nSe non siete in un ambiente virtuale, potete procedere al passaggio successivo.\nCreare un Nuovo Ambiente Virtuale: Per utilizzare il campionatore CmdStan e il linguaggio di programmazione probabilistica Stan, adottate l’ambiente virtuale cmdstan_env. Se si utilizza conda, è possibile installare CmdStanPy e i componenti sottostanti di CmdStan dal repository conda-forge tramite la seguente procedura:\nconda create -n cmdstan_env -c conda-forge cmdstanpy\nConda richiederà la conferma digitando y. Questo passaggio crea l’ambiente e installa cmdstanpy insieme alle dipendenze necessarie.\nAttivare il Nuovo Ambiente: Per utilizzare l’ambiente appena creato, attivatelo tramite:\nconda activate cmdstan_env\nInstallare le Librerie Richieste: All’interno dell’ambiente, installate altre librerie necessarie. Ecco come installare le librerie che utilizzeremo:\nconda install -c conda-forge jax numpyro bambi arviz seaborn jupyter-book ipywidgets watermark pingouin networkx -y \nNota: Gli utenti Windows potrebbero dover utilizzare nutpie come alternativa a jax.\nComandi Utili per Gestire Ambienti e Librerie:\n\nElencare gli ambienti virtuali disponibili e verificare quello attivo:\nconda env list\nRimuovere un ambiente virtuale specifico, ad esempio my_env:\nconda env remove -n my_env\nRimuovere una libreria da un ambiente specifico, ad esempio package_name:\nconda remove -n nome_ambiente package_name\n\n\nSeguendo attentamente questi passaggi e utilizzando i comandi di gestione, sarete in grado di creare e gestire efficacemente gli ambienti virtuali con Conda, garantendo una gestione pulita e ordinata delle dipendenze dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#conda-forge",
    "href": "chapters/appendix/a04_virtual_env.html#conda-forge",
    "title": "Appendice E — Ambienti virtuali",
    "section": "E.6 Conda Forge",
    "text": "E.6 Conda Forge\nÈ consigliato aggiungere Conda Forge come canale aggiuntivo da cui Conda può cercare e installare i pacchetti. Conda Forge è una collezione di pacchetti gestita dalla community.\n\nE.6.1 Aggiungere Conda Forge\nPer aggiungere Conda Forge come canale, eseguire i seguenti comandi:\nconda config --add channels conda-forge\nconda config --set channel_priority strict\n\nconda config --add channels conda-forge: Aggiunge Conda Forge come canale aggiuntivo per la ricerca e l’installazione dei pacchetti.\nconda config --set channel_priority strict: Imposta la priorità dei canali su “strict”, dando priorità ai pacchetti trovati nei canali elencati per primi nel file di configurazione .condarc.\n\n\n\nE.6.2 Vantaggi dell’Uso di Conda Forge\n\nAmpia Disponibilità di Pacchetti: Conda Forge offre un numero maggiore di pacchetti rispetto al canale predefinito di Conda, aumentando le possibilità di trovare il pacchetto necessario senza ricorrere ad altre soluzioni.\nAggiornamenti Frequenti: I pacchetti su Conda Forge vengono aggiornati più frequentemente, rendendo più probabile trovare le versioni più recenti.\nCoerenza e Compatibilità: Utilizzando la priorità “strict” e Conda Forge, si aumenta la coerenza e la compatibilità tra i pacchetti, riducendo il rischio di conflitti tra dipendenze.\n\nAggiungere Conda Forge come canale e impostare la priorità dei canali su “strict” sono pratiche consigliate per migliorare la gestione dei pacchetti con Conda. Questo approccio aiuta a mantenere l’ambiente stabile, aggiornato e compatibile con le ultime versioni dei pacchetti disponibili.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "href": "chapters/appendix/a04_virtual_env.html#utilizzo-di-graphviz-opzionale",
    "title": "Appendice E — Ambienti virtuali",
    "section": "E.7 Utilizzo di Graphviz (Opzionale)",
    "text": "E.7 Utilizzo di Graphviz (Opzionale)\nPer utilizzare il pacchetto Python graphviz, è necessario installare prima Graphviz sul vostro computer. Le istruzioni specifiche per l’installazione variano a seconda del sistema operativo e sono disponibili sul sito ufficiale di Graphviz.\n\nE.7.1 Installazione di Graphviz\n\nInstallazione di Graphviz: Seguire le istruzioni sul sito di Graphviz per installare il software sul vostro sistema operativo (Windows, macOS, Linux).\nVerifica dell’Installazione: Dopo l’installazione, assicuratevi che Graphviz sia correttamente installato eseguendo il seguente comando nel terminale:\ndot -V\nQuesto comando dovrebbe restituire la versione di Graphviz installata.\n\n\n\nE.7.2 Installazione del Pacchetto Python graphviz\nDopo aver installato Graphviz, potete procedere con l’installazione del pacchetto Python graphviz nel vostro ambiente virtuale. Seguite questi passaggi:\n\nAttivare l’Ambiente Virtuale: Attivate l’ambiente virtuale in cui avete installato pymc (ad esempio, pymc_env) nella vostra console:\nconda activate pymc_env\nInstallare il Pacchetto Python graphviz: Eseguite il seguente comando per installare il pacchetto graphviz tramite Conda Forge:\nconda install -c conda-forge graphviz\n\n\n\nE.7.3 Vantaggi dell’Utilizzo di Graphviz\nL’installazione di Graphviz e del relativo pacchetto Python consente di creare e visualizzare grafici e diagrammi all’interno del vostro ambiente Python. Questo può essere particolarmente utile per visualizzare strutture di dati complesse, flussi di lavoro o grafi probabilistici.\nSeguendo questi passaggi, sarete in grado di utilizzare le funzionalità di Graphviz nel vostro ambiente Python, migliorando le capacità di visualizzazione e analisi dei vostri progetti.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Ambienti virtuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a10_math_symbols.html",
    "href": "chapters/appendix/a10_math_symbols.html",
    "title": "Appendice F — Simbologia di base",
    "section": "",
    "text": "Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.\n\n\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire “per ogni.”\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) è un elemento dell’insieme \\(A\\).\nL’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\).\nL’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge “tale che.”\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge “proporzionale a.”\nIl simbolo \\(\\approx\\) si legge “circa.”\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.”\nIl simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.”\nIl simbolo \\(\\#\\) indica la cardinalità di un insieme.\nIl simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l’insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) è l’insieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore più alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densità di probabilità.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilità o densità di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) è una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilità di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilità di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Simbologia di base</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html",
    "href": "chapters/appendix/a11_numbers.html",
    "title": "Appendice G — Numeri e intervalli",
    "section": "",
    "text": "G.1 Numeri binari\nI numeri binari costituiscono la forma più fondamentale di sistema numerico in informatica, essendo composto esclusivamente da due simboli, ovvero 0 e 1. Questo sistema è frequentemente impiegato per rappresentare dualità logiche, come vero/falso o presenza/assenza, in virtù della sua innata semplicità binaria. La sua applicazione è particolarmente efficace nell’elaborazione di dati per generare statistiche sintetiche in modo efficiente e rapido.\nImmaginiamo di porre la seguente domanda a 10 studenti: “Ti piacciono i mirtilli?” Le risposte potrebbero essere le seguenti:\nopinion = (True, False, True, True, True, False, True, True, True, False)\nopinion\n\n(True, False, True, True, True, False, True, True, True, False)\nIn questo caso, abbiamo utilizzato i numeri binari 0 e 1 per rappresentare risposte diverse, dove False indica “No” e True indica “Si”. Questa rappresentazione binaria ci consente di ottenere facilmente una panoramica delle preferenze degli studenti riguardo i mirtilli.\nIn Python True equivale a 1 e False a zero. Possiamo dunque calcolare la proporzione di risposte positive nel modo seguente:\nsum(opinion) / len(opinion)\n\n0.7",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-interi",
    "href": "chapters/appendix/a11_numbers.html#numeri-interi",
    "title": "Appendice G — Numeri e intervalli",
    "section": "G.2 Numeri interi",
    "text": "G.2 Numeri interi\nI numeri interi sono numeri privi di decimali e comprendono sia i numeri naturali utilizzati per il conteggio, come 1, 2, …, sia i numeri con il segno, necessari per rappresentare grandezze negative. L’insieme dei numeri naturali è indicato con il simbolo \\(\\mathbb{N}\\). L’insieme numerico dei numeri interi relativi si rappresenta come \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-razionali",
    "title": "Appendice G — Numeri e intervalli",
    "section": "G.3 Numeri razionali",
    "text": "G.3 Numeri razionali\nI numeri razionali sono numeri frazionari rappresentabili come \\(m/n\\), dove \\(m\\) e \\(n\\) sono numeri interi e \\(n\\) è diverso da zero. Gli elementi dell’insieme dei numeri razionali sono quindi dati da \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). È importante notare che l’insieme dei numeri naturali è incluso in quello dei numeri interi, che a sua volta è incluso in quello dei numeri razionali, ovvero \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Per rappresentare solo i numeri razionali non negativi, utilizziamo il simbolo \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "href": "chapters/appendix/a11_numbers.html#numeri-irrazionali",
    "title": "Appendice G — Numeri e intervalli",
    "section": "G.4 Numeri irrazionali",
    "text": "G.4 Numeri irrazionali\nTuttavia, alcune grandezze non possono essere esprimibili come numeri interi o razionali. Questi numeri sono noti come numeri irrazionali e sono rappresentati dall’insieme \\(\\mathbb{R}\\). Essi comprendono numeri illimitati e non periodici, che non possono essere scritti come frazioni. Ad esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\(\\pi = 3.141592\\ldots\\) sono esempi di numeri irrazionali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#numeri-reali",
    "href": "chapters/appendix/a11_numbers.html#numeri-reali",
    "title": "Appendice G — Numeri e intervalli",
    "section": "G.5 Numeri reali",
    "text": "G.5 Numeri reali\nI numeri razionali rappresentano solo una parte dei punti sulla retta \\(r\\). Per rappresentare ogni possibile punto sulla retta, è necessario introdurre i numeri reali. L’insieme dei numeri reali comprende numeri positivi, negativi e nulli, e contiene come casi particolari i numeri interi, razionali e irrazionali. In statistica, il numero di decimali spesso indica il grado di precisione della misurazione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a11_numbers.html#intervalli",
    "href": "chapters/appendix/a11_numbers.html#intervalli",
    "title": "Appendice G — Numeri e intervalli",
    "section": "G.6 Intervalli",
    "text": "G.6 Intervalli\nQuesto ci porta a esplorare gli intervalli, una struttura matematica che ci aiuta a definire sottoinsiemi specifici sulla retta numerica. Gli intervalli aperti, che escludono i punti di inizio e fine. D’altro canto, gli intervalli chiusi includono sia il punto di inizio che quello di fine, fornendo una copertura di valori senza tralasciare i confini. Le caratteristiche degli intervalli sono riportate nella tabella seguente.\n\n\n\nIntervallo\n\n\n\n\n\n\nchiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\naperto\n\\((a, b)\\)\n\\(a &lt; x &lt; b\\)\n\n\nchiuso a sinistra e aperto a destra\n\\([a, b)\\)\n\\(a \\leq x &lt; b\\)\n\n\naperto a sinistra e chiuso a destra\n\\((a, b]\\)\n\\(a &lt; x \\leq b\\)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Numeri e intervalli</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html",
    "href": "chapters/appendix/a12_sum_notation.html",
    "title": "Appendice H — Sommatorie",
    "section": "",
    "text": "H.1 Manipolazione di somme\nÈ conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l’operatore della sommatoria.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "href": "chapters/appendix/a12_sum_notation.html#manipolazione-di-somme",
    "title": "Appendice H — Sommatorie",
    "section": "",
    "text": "H.1.1 Proprietà 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) è pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\n\nH.1.2 Proprietà 2 (proprietà distributiva)\nNel caso in cui l’argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\nè possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\n\nH.1.3 Proprietà 3 (proprietà associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\nÈ dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\n\nH.1.4 Proprietà 4\nSe deve essere eseguita un’operazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull’argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\n\nH.1.5 Proprietà 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "href": "chapters/appendix/a12_sum_notation.html#doppia-sommatoria",
    "title": "Appendice H — Sommatorie",
    "section": "H.2 Doppia sommatoria",
    "text": "H.2 Doppia sommatoria\nÈ possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell’indice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria è il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi può osservare che nella sommatoria interna (quella che dipende dall’indice \\(j\\)), la quantità \\(x_i\\) è costante, ovvero non dipende dall’indice (che è \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall’operatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si può osservare che nell’argomento della sommatoria esterna la quantità costituita dalla sommatoria in \\(j\\) non dipende dall’indice \\(i\\) e quindi questa quantità può essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n} x_i \\sum_{j=1}^{n} y_j.\n\\]\nFacciamo un esercizio. Verifichiamo quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto così ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\n\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\n\\]\novvero\n\\[\n(2 + 3 + 1) \\times (1+4+9) = 84.\n\\]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>Sommatorie</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html",
    "href": "chapters/appendix/a13_sets.html",
    "title": "Appendice I — Insiemi",
    "section": "",
    "text": "I.1 Diagrammi di Eulero-Venn\nI diagrammi di Venn sono uno strumento grafico molto utile per rappresentare gli insiemi e per verificare le proprietà delle operazioni tra di essi. Questi diagrammi prendono il nome dal matematico inglese del 19° secolo John Venn, anche se rappresentazioni simili erano già state utilizzate in precedenza da Leibniz e Eulero.\nI diagrammi di Venn rappresentano gli insiemi come regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare alcuni elementi di un insieme tramite punti, e in alcuni casi possono essere evidenziati tutti gli elementi degli insiemi considerati.\nIn sostanza, questi diagrammi sono un modo visuale per rappresentare le proprietà degli insiemi e delle operazioni tra di essi. Sono uno strumento molto utile per visualizzare la relazione tra gli insiemi e per capire meglio come si combinano gli elementi all’interno di essi.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "href": "chapters/appendix/a13_sets.html#appartenenza-ad-un-insieme",
    "title": "Appendice I — Insiemi",
    "section": "I.2 Appartenenza ad un insieme",
    "text": "I.2 Appartenenza ad un insieme\nUsiamo ora Python.\n\nSet1 = {1, 2}\nprint(Set1)\nprint(type(Set1))\n\n{1, 2}\n&lt;class 'set'&gt;\n\n\n\nmy_list = [1, 2, 3, 4]\nmy_set_from_list = set(my_list)\nprint(my_set_from_list)\n\n{1, 2, 3, 4}\n\n\nL’appartenenza ad un insieme si verifica con in e not in.\n\nmy_set = set([1, 3, 5])\nprint(\"Ecco il mio insieme:\", my_set)\nprint(\"1 appartiene all'insieme:\", 1 in my_set)\nprint(\"2 non appartiene all'insieme:\", 2 in my_set)\nprint(\"4 NON appartiene all'insieme:\", 4 not in my_set)\n\nEcco il mio insieme: {1, 3, 5}\n1 appartiene all'insieme: True\n2 non appartiene all'insieme: False\n4 NON appartiene all'insieme: True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#relazioni-tra-insiemi",
    "title": "Appendice I — Insiemi",
    "section": "I.3 Relazioni tra insiemi",
    "text": "I.3 Relazioni tra insiemi\nEsaminiamo le funzioni Python per descrivere le relazioni tra insiemi. In particolare, dopo avere definito l’insieme universo e l’insieme vuoto, considereremo la relazione di inclusione che conduce al concetto di sottoinsieme. Analogamente si definisce il concetto di sovrainsieme. Mostreremo anche come valutare se due insiemi sono disgiunti (si dicono disgiunti gli insiemi con intersezione vuota).\n\nUniv = set([x for x in range(11)])\nSuper = set([x for x in range(11) if x % 2 == 0])\nDisj = set([x for x in range(11) if x % 2 == 1])\nSub = set([4, 6])\nNull = set([x for x in range(11) if x &gt; 10])\n\n\nprint(\"Insieme Universo (tutti gli interi positivi fino a 10):\", Univ)\nprint(\"Tutti gli interi positivi pari fino a 10:\", Super)\nprint(\"Tutti gli interi positivi dispari fino a 10:\", Disj)\nprint(\"Insieme di due elementi, 4 e 6:\", Sub)\nprint(\"Un isieme vuoto:\", Null)\n\nInsieme Universo (tutti gli interi positivi fino a 10): {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\nTutti gli interi positivi pari fino a 10: {0, 2, 4, 6, 8, 10}\nTutti gli interi positivi dispari fino a 10: {1, 3, 5, 7, 9}\nInsieme di due elementi, 4 e 6: {4, 6}\nUn isieme vuoto: set()\n\n\n\nprint('È \"Super\" un sovrainsieme di \"Sub\"?', Super.issuperset(Sub))\nprint('È \"Super\" un sottoinsieme di \"Univ\"?', Super.issubset(Univ))\nprint('È \"Sub\" un sovrainsieme di \"Super\"?', Sub.issuperset(Super))\nprint('Sono \"Super\" e \"Disj\" insiemi disgiunti?', Sub.isdisjoint(Disj))\n\nÈ \"Super\" un sovrainsieme di \"Sub\"? True\nÈ \"Super\" un sottoinsieme di \"Univ\"? True\nÈ \"Sub\" un sovrainsieme di \"Super\"? False\nSono \"Super\" e \"Disj\" insiemi disgiunti? True",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "href": "chapters/appendix/a13_sets.html#operazioni-tra-insiemi",
    "title": "Appendice I — Insiemi",
    "section": "I.4 Operazioni tra insiemi",
    "text": "I.4 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con } i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:\n\\[\n(A \\cup B)^c = A^c \\cap B^c,\n\\]\n\\[\n(A \\cap B)^c = A^c \\cup B^c.\n\\]\nIn tutte le seguenti figure, \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\n\n\n\nDiagrammi di Venn\n\n\nI diagrammi di Eulero-Venn che illustrano le leggi di DeMorgan sono forniti nella figura seguente.\n\n\n\nLeggi di DeMorgan\n\n\nVediamo ora come si eseguono le operazioni tra insiemi con Python.\nEguaglianza e differenza.\n\nS1 = {1, 2}\nS2 = {2, 2, 1, 1, 2}\nprint(\n    \"S1 e S2 sono uguali perché l'ordine o la ripetizione di elementi non importano per gli insiemi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 sono uguali perché l'ordine o la ripetizione di elementi non importano per gli insiemi\nS1==S2: True\n\n\n\nS1 = {1, 2, 3, 4, 5, 6}\nS2 = {1, 2, 3, 4, 0, 6}\nprint(\n    \"S1 e S2 NON sono uguali perché si differenziano per almeno uno dei loro elementi\\nS1==S2:\",\n    S1 == S2,\n)\n\nS1 e S2 NON sono uguali perché si differenziano per almeno uno dei loro elementi\nS1==S2: False\n\n\nIntersezione. Si noti che il connettivo logico & corrisponde all’intersezione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\n\nS1: {9, 3, 6}\n\n\n\nS2 = set([x for x in range(1, 7)])\nprint(\"S2:\", S2)\n\nS2: {1, 2, 3, 4, 5, 6}\n\n\n\nS_intersection = S1.intersection(S2)\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nS_intersection = S1 & S2\nprint(\"Intersezione di S1 e S2:\", S_intersection)\n\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\nIntersezione di S1 e S2: {1, 2, 3, 4, 6}\n\n\n\nS3 = set([x for x in range(6, 10)])\nprint(\"S3:\", S3)\nS1_S2_S3 = S1.intersection(S2).intersection(S3)\nprint(\"Intersection of S1, S2, and S3:\", S1_S2_S3)\n\nS3: {8, 9, 6, 7}\nIntersection of S1, S2, and S3: {6}\n\n\nUnione. Si noti che il connettivo logico | corrisponde all’unione.\n\nS1 = set([x for x in range(1, 11) if x % 3 == 0])\nprint(\"S1:\", S1)\nS2 = set([x for x in range(1, 5)])\nprint(\"S2:\", S2)\n\nS_union = S1.union(S2)\nprint(\"Unione di S1 e S2:\", S_union)\nS_union = S1 | S2\nprint(\"Unione di S1 e S2:\", S_union)\n\nS1: {9, 3, 6}\nS2: {1, 2, 3, 4}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\nUnione di S1 e S2: {1, 2, 3, 4, 6, 9}\n\n\nInsieme complementare.\n\nS = set([x for x in range(21) if x % 2 == 0])\nprint(\"S è l'insieme dei numeri interi pari tra 0 e 20:\", S)\n\nS è l'insieme dei numeri interi pari tra 0 e 20: {0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20}\n\n\n\nS_complement = set([x for x in range(21) if x % 2 != 0])\nprint(\"S_complement è l'insieme dei numeri interi dispari tra 0 e 20:\", S_complement)\n\nS_complement è l'insieme dei numeri interi dispari tra 0 e 20: {1, 3, 5, 7, 9, 11, 13, 15, 17, 19}\n\n\n\nprint(\n    \"È l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20?\",\n    S.union(S_complement) == set([x for x in range(21)]),\n)\n\nÈ l'unione di S e S_complement uguale a tutti i numeri interi tra 0 e 20? True\n\n\nDifferenza tra insiemi.\n\nS1 = set([x for x in range(31) if x % 3 == 0])\nprint(\"Set S1:\", S1)\n\nSet S1: {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\n\n\n\nS2 = set([x for x in range(31) if x % 5 == 0])\nprint(\"Set S2:\", S2)\n\nSet S2: {0, 5, 10, 15, 20, 25, 30}\n\n\n\nS_difference = S2 - S1\nprint(\"Differenza tra S2 e S1, i.e. S2\\S1:\", S_difference)\n\nS_difference = S1.difference(S2)\nprint(\"Differenza tra S1 e S2, i.e. S1\\S2:\", S_difference)\n\nDifferenza tra S1 e S2 i.e. S2\\S1: {25, 10, 20, 5}\nDifferenza tra S2 e S1 i.e. S1\\S2: {3, 6, 9, 12, 18, 21, 24, 27}\n\n\nDifferenza simmetrica. La differenza simmetrica, indicata con il simbolo Δ, è un’operazione insiemistica definita come unione tra la differenza tra il primo e il secondo insieme e la differenza tra il secondo e il primo insieme. In modo equivalente, la differenza simmetrica equivale all’unione tra i due insiemi meno la loro intersezione.\n\nprint(\"S1\", S1)\nprint(\"S2\", S2)\nprint(\"Differenza simmetrica\", S1 ^ S2)\nprint(\"Differenza simmetrica\", S2.symmetric_difference(S1))\n\nS1 {0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30}\nS2 {0, 5, 10, 15, 20, 25, 30}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}\nDifferenza simmetrica {3, 5, 6, 9, 10, 12, 18, 20, 21, 24, 25, 27}",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "chapters/appendix/a13_sets.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendice I — Insiemi",
    "section": "I.5 Coppie ordinate e prodotto cartesiano",
    "text": "I.5 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata) e \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]\nPiù in generale, un prodotto cartesiano di \\(n\\) insiemi può essere rappresentato da un array di \\(n\\) dimensioni, dove ogni elemento è una ennupla o tupla ordinata (ovvero, una collezione o un elenco ordinato di \\(n\\) oggetti). Una n-pla ordinata si distingue da un insieme di \\(n\\) elementi in quanto fra gli elementi di un insieme non è dato alcun ordine. Inoltre gli elementi di una ennupla possono anche essere ripetuti. Essendo la n-pla un elenco ordinato, in generale di ogni suo elemento è possibile dire se sia il primo, il secondo, il terzo, eccetera, fino all’n-esimo. Il prodotto cartesiano prende il nome da René Descartes la cui formulazione della geometria analitica ha dato origine al concetto.\n\nA = set([\"a\", \"b\", \"c\"])\nS = {1, 2, 3}\n\n\ndef cartesian_product(S1, S2):\n    result = set()\n    for i in S1:\n        for j in S2:\n            result.add(tuple([i, j]))\n    return result\n\n\nC = cartesian_product(A, S)\nprint(f\"Prodotto cartesiano di A e S\\n{A} x {S} = {C}\")\n\nProdotto cartesiano di A e S\n{'Head', 'Tail'} x {1, 2, 3} = {('Tail', 1), ('Head', 2), ('Head', 1), ('Tail', 3), ('Tail', 2), ('Head', 3)}\n\n\nSi definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\).\n\nprint(\"La cardinalità dell'insieme prodotto cartesiano è:\", len(C))\n\nLa cardinalità dell'insieme prodotto cartesiano è: 9\n\n\nInvece di scrivere funzioni noi stessi, è possibile usare la libreria itertools di Python. Si ricordi di trasformare l’oggetto risultante in una lista per la visualizzazione e la successiva elaborazione.\n\nfrom itertools import product as prod\n\n\nA = set([x for x in range(1, 7)])\nB = set([x for x in range(1, 7)])\np = list(prod(A, B))\n\nprint(\"A è l'insieme di tutti i possibili lanci di un dado:\", A)\nprint(\"B è l'insieme di tutti i possibili lanci di un dado:\", B)\nprint(\n    \"\\nIl prodotto di A e B è l'insieme dei risultati che si possono ottenere lanciando due dadi:\\n\",\n    p,\n)\n\nA è l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\nB è l'insieme di tutti i possibili lanci di un dado: {1, 2, 3, 4, 5, 6}\n\nIl prodotto di A e B è l'insieme dei risultati che si possono ottenere lanciando due dadi:\n [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)]\n\n\nLa cardinalità (cioè il numero di elementi) del prodotto cartesiano tra due o più insiemi è uguale al prodotto delle cardinalità degli insiemi considerati: card(A × B) = card(A) · card(B).\nUsando itertools è facile calcolare la cardinalità del prodotto cartesiano di un insieme per se stesso. Consideriamo il quadrato dell’insieme costituito dai risultati del lancio di una moneta. L’insieme risultante avrà cardinalità \\(2 \\cdot 2 = 4\\).\n\nA = {\"Head\", \"Tail\"} \np2 = list(prod(A, repeat=2))  \nprint(f\"Il quadrato dell'insieme A è un insieme che contiene {len(p2)} elementi: {p2}\")\n\nIl quadrato dell'insieme A è un insieme che contiene 4 elementi: [('Head', 'Head'), ('Head', 'Tail'), ('Tail', 'Head'), ('Tail', 'Tail')]\n\n\nL’insieme \\(A\\) elevato alla terza potenza produce un insieme la cui cardinalità è\n\np3 = list(prod(A, repeat=3))  \nprint(f\"L'insieme A elevato alla terza potenza è costituito da {len(p3)} elementi: {p3}\")\n\nL'insieme A elevato alla terza potenza è costituito da 8 elementi: [('Head', 'Head', 'Head'), ('Head', 'Head', 'Tail'), ('Head', 'Tail', 'Head'), ('Head', 'Tail', 'Tail'), ('Tail', 'Head', 'Head'), ('Tail', 'Head', 'Tail'), ('Tail', 'Tail', 'Head'), ('Tail', 'Tail', 'Tail')]",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>I</span>  <span class='chapter-title'>Insiemi</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html",
    "href": "chapters/appendix/a14_combinatorics.html",
    "title": "Appendice J — Calcolo combinatorio",
    "section": "",
    "text": "J.1 Principio del prodotto\nI metodi di base del calcolo combinatorio applicano due principi: la regola del prodotto e la regola della somma. Consideriamo il principio del prodotto.\nIn generale, una scelta può essere effettuata in più fasi, ad esempio \\(k\\). Supponiamo che per ogni \\(i = 1, \\dots, k\\) la scelta da compiere al \\(i\\)-esimo stadio possa essere effettuata in \\(n_i\\) modi. Secondo il principio del prodotto, il numero totale di possibili scelte è dato dal prodotto dei singoli numeri, ovvero:\n\\[\nn_{\\text{tot}} = n_1 \\cdot  n_2 \\cdots n_{k-1} \\cdot n_k.\n\\]\nEsempio 1. Ho a disposizione 2 paia di scarpe, 3 paia di pantaloni e 5 magliette. In quanti modi diversi mi posso vestire?\n\\[\n2 \\cdot 3 \\cdot 5 = 30\n\\]\nEsempio 2. In Minnesota le targhe delle automobili sono costituite da tre lettere (da A a Z) seguite da tre numeri (da 0 a 9). Qual è la proporzione di targhe che iniziano con GZN?\nLa soluzione è data dal numero di targhe che iniziano con GZN diviso per il numero totale di targhe possibili.\nIl numero totale di targe è \\(26 \\cdot 26 \\cdot 26 \\cdot 10 \\cdot 10 \\cdot 10 = 17,576,000\\). Per calcolare il numero di targhe che iniziano con GZN, consideriamo le targhe che hanno la forma GZN _ _ _. Per i tre simboli mancanti ci sono \\(10 \\cdot 10 \\cdot 10\\) possibilità. Dunque la proporzione cercata è\n\\[\n10^3/(26^3 \\cdot 10^3) = 1/26^3 = 0.0000569.\n\\]\n10**3 / (26**3 * 10**3)\n\n5.689576695493855e-05",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "href": "chapters/appendix/a14_combinatorics.html#principio-della-somma",
    "title": "Appendice J — Calcolo combinatorio",
    "section": "J.2 Principio della somma",
    "text": "J.2 Principio della somma\nIl principio della somma afferma che se un insieme può essere suddiviso in due o più sottoinsiemi disgiunti, allora il numero totale di elementi nell’insieme è dato dalla somma dei numeri di elementi in ciascun sottoinsieme.\nIn altre parole, se si vuole determinare il numero totale di modi in cui è possibile realizzare un certo evento, e questo evento può essere realizzato in modo esclusivo in modo A oppure B, allora il numero totale di modi in cui è possibile realizzare l’evento è dato dalla somma dei modi in cui può essere realizzato in modo A e dei modi in cui può essere realizzato in modo B.\nAd esempio, se si vuole determinare il numero totale di modi in cui è possibile scegliere un dolce da una tavola con due tipi di dolci (ad esempio torta e biscotti), il principio della somma afferma che il numero totale di modi è dato dalla somma del numero di modi in cui è possibile scegliere la torta e del numero di modi in cui è possibile scegliere i biscotti.\nEsempio 3. L’urna \\(A\\) contiene \\(5\\) palline numerate da \\(1\\) a \\(5\\), l’urna \\(B\\) contiene \\(6\\) palline numerate da \\(6\\) a \\(11\\), l’urna \\(C\\) contiene \\(3\\) palline numerate da \\(12\\) a \\(14\\) e l’urna \\(D\\) contiene \\(2\\) palline numerate \\(15\\) e \\(16\\). Quanti insiemi composti da due palline, ciascuna estratta da un’urna differente, si possono formare?\nIl numero di insiemi di tipo \\(AB\\) è dato dal prodotto delle palline che possono essere estratte dall’urna \\(A\\) (5) e da quelle che possono essere estratte dall’urna \\(B\\) (6), ovvero \\(5 \\cdot 6 = 30\\). In modo analogo, si ottengono 15 insiemi di tipo \\(AC\\), 10 di tipo \\(AD\\), 18 di tipo \\(BC\\), 12 di tipo \\(BD\\), 6 di tipo \\(CD\\). Quindi, per la regola della somma, il numero totale di insiemi distinti che si possono formare con due palline provenienti dalle quattro urne è dato dalla somma di questi valori, ovvero \\(30 + 15 + 10 + 18 + 12 + 6 = 91\\). Pertanto, ci sono 91 insiemi composti da due palline, ciascuna estratta da un’urna differente, che si possono formare.\nIn conclusione, il principio del prodotto e il principio della somma sono due concetti fondamentali del calcolo combinatorio. In generale, il principio del prodotto si applica quando si tratta di eventi indipendenti che si verificano in successione, mentre il principio della somma si applica quando si tratta di eventi mutuamente esclusivi (cioè non possono accadere contemporaneamente) e si cerca di calcolare il numero totale di possibili risultati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna",
    "href": "chapters/appendix/a14_combinatorics.html#il-modello-dellurna",
    "title": "Appendice J — Calcolo combinatorio",
    "section": "J.3 Il modello dell’urna",
    "text": "J.3 Il modello dell’urna\nI problemi di combinatoria spesso coinvolgono l’estrazione di palline da urne, le quali rappresentano dei modelli delle corrispondenti situazioni considerate. Una procedura comune per rappresentare queste situazioni è il modello dell’urna, che consiste nell’estrazione di \\(k\\) palline da un’urna contenente \\(n\\) palline. Le palline possono essere tutte diverse, oppure alcune palline possono essere indistinguibili tra loro. Tra le possibili modalità di estrazione, sono particolarmente importanti:\n\nL’estrazione Bernoulliana di \\(k\\) palline, che si ottiene estraendo una pallina alla volta e rimettendola nell’urna dopo ogni estrazione;\nL’estrazione senza ripetizione di \\(k\\) palline, che si ottiene estraendo una pallina alla volta senza rimetterla nell’urna dopo l’estrazione;\nL’estrazione in blocco di \\(k\\) palline, che si ottiene estraendo \\(k\\) palline contemporaneamente.\n\nPer esempio, nel caso di campioni di ampiezza 2 estratti da un’urna con tre elementi \\(\\{1, 2, 3\\}\\), abbiamo i seguenti quattro casi:\n\ncampionamento con reimmissione tenendo conto dell’ordine di estrazione: \\(\\{1,  1\\}, \\{2,  1\\}, \\{3,  1\\}, \\{1,  2\\}, \\{2,  2\\}, \\{3,  2\\}, \\{1,  3\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento con reimmissione senza tenere conto dell’ordine di estrazione: \\(\\{1,  1\\}, \\{1,  2\\}, \\{1,  3\\}, \\{2,  2\\}, \\{2,  3\\}, \\{3,  3\\}\\);\ncampionamento senza reimmissione tenendo conto dell’ordine di estrazione: \\(\\{1,  2\\}, \\{2,  1\\}, \\{1,  3\\}, \\{3,  1\\}, \\{2,  3\\}, \\{3,  2\\}\\);\ncampionamento senza reimmissione e senza tenere conto dell’ordine di estrazione: \\(\\{1 , 2\\}, \\{1,  3\\}, \\{2, 3\\}\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#permutazioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#permutazioni-semplici",
    "title": "Appendice J — Calcolo combinatorio",
    "section": "J.4 Permutazioni semplici",
    "text": "J.4 Permutazioni semplici\nLe permutazioni semplici sono il risultato di uno scambio dell’ordine degli elementi di un insieme che contiene elementi distinti tra loro. Queste permutazioni sono indicate con il simbolo \\(P_n\\), e il numero di permutazioni semplici di \\(n\\) elementi distinti è pari al fattoriale di \\(n\\), cioè \\(n!\\), come espresso dall’eq. {eq}eq-permsem:\n\\[\nP_n = n!\n\\] (eq-permsem)\ndove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed è uguale al prodotto di \\(n\\) numeri interi decrescenti da \\(n\\) fino a 1. Per definizione, il fattoriale di 0 è 1.\nIl numero di permutazioni di \\(n\\) elementi distinti può essere visto come l’estrazione senza rimessa di \\(n\\) elementi diversi da un’urna contenente gli \\(n\\) oggetti. Questo ci consente di applicare il principio del prodotto, il quale afferma che il numero di modi in cui è possibile combinare o disporre un insieme di oggetti è dato dal prodotto del numero di scelte possibili per ciascuna categoria di oggetti. Nel caso delle permutazioni, il principio del prodotto si applica nel seguente modo: se abbiamo \\(n\\) oggetti distinti da disporre in un ordine particolare, il numero di permutazioni possibili è dato dal prodotto del numero di scelte possibili per la prima posizione, per la seconda posizione, per la terza posizione, e così via, fino alla \\(n\\)-esima posizione.\nPer esempio, consideriamo il caso di disporre tre oggetti, A, B e C. Ci sono tre modi per scegliere il primo oggetto: A, B o C. Una volta scelto il primo oggetto, ci sono due modi per scegliere il secondo oggetto. Infine, rimane un solo modo per scegliere l’ultimo oggetto. Possiamo concettualizzare questo processo come un albero, dove il numero totale di foglie è uguale al numero di permutazioni. Per calcolare il numero di foglie, basta moltiplicare sequenzialmente il numero di rami a ogni livello, cioè \\(3 \\times 2 \\times 1\\).\nEsempio 4. Consideriamo l’insieme: \\(A = \\{a, b, c\\}\\). Calcoliamo il numero di permutazioni semplici.\nLe permutazioni semplici di \\(A\\) sono: \\(\\{a, b, c\\}\\), \\(\\{a, c, b\\}\\), \\(\\{b, c, a\\}\\), \\(\\{b, a, c\\}\\), \\(\\{c, a, b\\}\\), \\(\\{c, b, a\\}\\), ovvero 6. Applichiamo l’eq. {ref}eq-permsem:\n\\[\nP_n = P_3 = 3! = 3 \\cdot 2 \\cdot 1 = 6.\n\\]\nLo strumento principale che usiamo in Python per trovare le permutazioni di un insieme è una libreria specificamente progettata per iterare sugli oggetti in modi diversi, ovvero itertools. Con itertools.permutations() generiamo le permutazioni.\n\nA = {\"A\", \"B\", \"C\"}\nprint(A)\n\n{'A', 'B', 'C'}\n\n\n\npermutations = it.permutations(A)\n\nPer visualizzare il risultato dobbiamo trasformarlo in una tupla:\n\ntuple(permutations)\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nLo stesso risultato si ottiene con\n\npermutations = it.permutations(\"ABC\")\npermutations = tuple(permutations)\npermutations\n\n(('A', 'B', 'C'),\n ('A', 'C', 'B'),\n ('B', 'A', 'C'),\n ('B', 'C', 'A'),\n ('C', 'A', 'B'),\n ('C', 'B', 'A'))\n\n\nPossiamo ora contare quanti elementi ci sono nella tupla usando la funzione len():\n\nlen(permutations)\n\n6\n\n\nOppure, possiamo appliare la formula {eq}eq-permsem mediante la funzione factorial() contenuta nella libreria math di Numpy:\n\nmath.factorial(3)\n\n6\n\n\nEsempio 5. Gli anagrammi sono le permutazioni che si ottengono da una parola variando l’ordine delle lettere. Le permutazioni semplici si applicano al caso di parole costituite da lettere tutte diverse tra loro. Ad esempio, con la parola NUMERO si ottengono \\(P_6 = 6! = 6\\cdot5\\cdot4\\cdot3\\cdot2\\cdot1 = 720\\) anagrammi.\n\npermutations = it.permutations(\"NUMERO\")\npermutations = tuple(permutations)\npermutations[1:10]\n\n(('N', 'U', 'M', 'E', 'O', 'R'),\n ('N', 'U', 'M', 'R', 'E', 'O'),\n ('N', 'U', 'M', 'R', 'O', 'E'),\n ('N', 'U', 'M', 'O', 'E', 'R'),\n ('N', 'U', 'M', 'O', 'R', 'E'),\n ('N', 'U', 'E', 'M', 'R', 'O'),\n ('N', 'U', 'E', 'M', 'O', 'R'),\n ('N', 'U', 'E', 'R', 'M', 'O'),\n ('N', 'U', 'E', 'R', 'O', 'M'))\n\n\n\nlen(permutations)\n\n720\n\n\n\nmath.factorial(6)\n\n720\n\n\nEsempio 6. Un altro esempio riguarda i giochi di carte. Ci sono 52! \\(\\approx 8 \\times 10^{67}\\) modi di ordinare un mazzo di carte da poker; questo numero è “quasi” grande come il numero di atomi dell’universo che si stima essere uguale a circa \\(10^{80}\\).\n\nmath.factorial(52)\n\n80658175170943878571660636856403766975289505440883277824000000000000\n\n\n\nprint(\"{:.2e}\".format(math.factorial(52)))\n\n8.07e+67\n\n\nEsempio 7. Le cifre 1, 2, 3, 4 e 5 sono disposte in ordine casuale per formare un numero di cinque cifre.\n\nQuanti diversi numeri di cinque cifre possono essere formati?\nQuanti diversi numeri di cinque cifre sono dispari?\n\nIniziamo a creare una tupla con le cinque cifre:\n\ntuple(range(1, 6))\n\n(1, 2, 3, 4, 5)\n\n\nCome in precedenza, possiamo usare it.permutations():\n\npermutations = it.permutations(range(1, 6))\npermutations = tuple(permutations)\npermutations[1:10]\n\n((1, 2, 3, 5, 4),\n (1, 2, 4, 3, 5),\n (1, 2, 4, 5, 3),\n (1, 2, 5, 3, 4),\n (1, 2, 5, 4, 3),\n (1, 3, 2, 4, 5),\n (1, 3, 2, 5, 4),\n (1, 3, 4, 2, 5),\n (1, 3, 4, 5, 2))\n\n\nCi sono 120 permutazioni.\n\nlen(permutations)\n\n120\n\n\nPer trovare i numeri dispari tra queste 120 permutazioni utilizziamo la funzione sum() in Python abbinato alle espressioni for e in. Accediamo al quinto elemento di una permutazione utilizzando la notazione [4] (il primo elemento è indicato con 0, quindi il quinto è 4):\n\nsum(permutation[4] % 2 for permutation in permutations)\n\n72\n\n\nPossiamo controllare questo teoricamente: nel caso presente, ci sono tre possibili cifre dispari per l’ultima posizione di un numero di cinque cifre: 1, 3 e 5. Dopo aver scelto una di queste, le cifre rimanenti nelle prime quattro posizioni possono essere formate in 4! modi. Pertanto:\n\nmath.factorial(4) * 3\n\n72",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#disposizioni-semplici",
    "href": "chapters/appendix/a14_combinatorics.html#disposizioni-semplici",
    "title": "Appendice J — Calcolo combinatorio",
    "section": "J.5 Disposizioni semplici",
    "text": "J.5 Disposizioni semplici\nLe disposizioni semplici rappresentano tutti i modi in cui un insieme di oggetti può essere disposto in sequenza, tenendo conto dell’ordine in cui gli oggetti vengono scelti e senza permettere la scelta di un oggetto più di una volta.\nQuindi, se abbiamo un insieme di \\(n\\) oggetti distinti e vogliamo selezionarne \\(k\\) per formare una sequenza, le disposizioni semplici rappresentano tutti i sottoinsiemi di \\(k\\) oggetti distinti che possono essere selezionati dall’insieme di \\(n\\) oggetti distinti in modo tale che l’ordine in cui vengono selezionati sia importante.\nAd esempio, se abbiamo l’insieme di oggetti \\({a,b,c}\\) e vogliamo selezionare due oggetti per formare una sequenza, le disposizioni semplici sarebbero: \\(ab\\), \\(ba\\), \\(ac\\), \\(ca\\), \\(bc\\), \\(cb\\). Nota che, in questo caso, l’ordine in cui gli oggetti vengono scelti è importante e ogni oggetto viene scelto una sola volta.\nIl numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) è indicato con \\(D_{n,k}\\) e può essere calcolato dividendo il numero di permutazioni di \\(n\\) oggetti distinti per il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti, poiché ogni disposizione semplice può essere ottenuta come una permutazione di un sottoinsieme di \\(k\\) oggetti distinti.\nQuindi, il numero di disposizioni semplici di \\(n\\) elementi distinti della classe \\(k\\) è dato da\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!},\n\\] (eq_disp_simple)\ndove \\(n!\\) rappresenta il numero di permutazioni di \\(n\\) oggetti distinti e \\((n-k)!\\) rappresenta il numero di permutazioni dei restanti \\(n-k\\) oggetti distinti.\nEsempio 8. Consideriamo l’insieme: \\(A = \\{a, b, c\\}\\). Qual è il numero di disposizioni semplici di classe 2? Come abbiamo visto sopra, le disposizioni semplici di classe 2 sono \\(\\{a, b\\}\\), \\(\\{b, a\\}\\), \\(\\{a, c\\}\\), \\(\\{c, a\\}\\), \\(\\{b, c\\}\\), \\(\\{c, b\\}\\), ovvero 6.\nApplichiamo l’eq. {eq}eq_disp_simple:\n\\[\nD_{n,k} = \\frac{n!}{(n-k)!} = 3 \\cdot 2 = 6.\n\\]\nIn maniera equivalente possiamo trovare il risultato usando itertools.permutations(iterable, k). Tale istruzione ci consente di trovare il numero di permutazioni possibili di tutti i sottoinsiemi di \\(k\\) elementi distinti, ovvero il numero di diverse sequenze ordinate che possiamo ottenere scegliendo \\(k\\) oggetti dall’insieme.\n\ntuple(it.permutations(\"ABC\", 2))\n\n(('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B'))\n\n\n\nres = tuple(it.permutations(\"ABC\", 2))\nlen(res)\n\n6\n\n\nOppure possiamo implementare l’eq. {eq}eq_disp_simple:\n\ndef simple_disp(n, k):\n    return math.factorial(n) / math.factorial(n - k)\n\n\nsimple_disp(3, 2)\n\n6.0",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a14_combinatorics.html#sec-combinazione-semplice",
    "href": "chapters/appendix/a14_combinatorics.html#sec-combinazione-semplice",
    "title": "Appendice J — Calcolo combinatorio",
    "section": "J.6 Combinazioni semplici",
    "text": "J.6 Combinazioni semplici\nLe combinazioni sono simili alle permutazioni, ma ignorano l’ordine degli elementi. In altre parole, le combinazioni rappresentano i modi di scegliere \\(k\\) elementi distinti da\\(n\\)elementi senza considerare l’ordine. Ad esempio, scegliendo 2 elementi da 3 (A, B e C), le permutazioni sono 6 (AB, BA, AC, CA, BC, CB), mentre le combinazioni sono 3 (AB, AC, BC).\nPer calcolare le combinazioni, prima calcoliamo le permutazioni \\(D_{n,k}\\) e poi dividiamo per \\(k!\\). Questo perché ci sono \\(k!\\) modi per disporre \\(k\\) elementi in ordine diverso, ma tutte queste disposizioni contano come una singola combinazione. La formula generale per le combinazioni è:\n\\[\nC_{n,k} = \\binom{n}{k} = \\frac{D_{n,k}}{P_k} = \\frac{n!}{k!(n-k)!},\n\\] (eq_combsemp)\nche è spesso indicata con il simbolo \\(\\binom{n}{k}\\) e viene chiamato “coefficiente binomiale”. In sintesi, le combinazioni semplici rappresentano il numero di sottoinsiemi di \\(k\\) elementi distinti scelti da un insieme di \\(n\\) elementi distinti senza considerare l’ordine di estrazione.\nEsempio 9. Per l’insieme \\(A = \\{a, b, c\\}\\) si trovino le combinazioni semplici di classe 2.\nLe combinazioni semplici dell’insieme \\(A\\) sono \\(\\{a, b\\}\\), \\(\\{a, c\\}\\), \\(\\{b, c\\}\\), ovvero 3. Applichiamo l’eq. {eq}eq_combsemp:\n\\[\nC_{n,k} = \\binom{n}{k} = \\binom{3}{2} = 3.\n\\]\nUsiamo itertools:\n\nc_nk = tuple(it.combinations(\"ABC\", 2))\nc_nk\n\n(('A', 'B'), ('A', 'C'), ('B', 'C'))\n\n\n\nlen(c_nk)\n\n3\n\n\nLa soluzione si trova anche usando la funzione comb() della libreria math.\n\nmath.comb(3, 2)\n\n3\n\n\nOppure usando la funzione comb() della libreria scipy.special.\n\nimport scipy.special as sp\n\nsp.comb(3, 2)\n\n3.0\n\n\nEsempio 10. Quanti gruppi di 2 si possono formare con 5 individui?\n\nc_nk = tuple(it.combinations(range(5), 2))\nc_nk\n\n((0, 1),\n (0, 2),\n (0, 3),\n (0, 4),\n (1, 2),\n (1, 3),\n (1, 4),\n (2, 3),\n (2, 4),\n (3, 4))\n\n\n\nlen(c_nk)\n\n10\n\n\novvero\n\nmath.comb(5, 2)\n\n10\n\n\nEsempio 11. Ho un’associazione con 50 soci. Devo scegliere 5 membri che compongano il comitato direttivo. Quante possibili scelte?\n\nmath.comb(50, 5)\n\n2118760\n\n\nEsempio 12. Una gelateria offre 15 gusti di gelato differenti. Quante coppe diverse posso formare se ognuna contiene 3 gusti di gelato differenti tra loro?\n\nmath.comb(15, 3)\n\n455\n\n\nEsempio 13. Uno studente deve rispondere a 5 domande su 10. Solo 5 su 10. Quante possibili scelte ha?\n\nmath.comb(10, 5)\n\n252\n\n\nEsempio 14. Consideriamo un incidente del 2009 quando il Governatore della California Arnold Schwarzenegger inviò un messaggio all’assemblea statale riguardo il veto al disegno di legge 1176. Questo messaggio formava un acrostico volgare con le prime lettere di ogni riga.\n\n\n\n\n\n\nFigura J.1\n\n\n\nCi possiamo chiedere quale sia la probabilità che questo acrostico sia stato casuale. Per rispondere a questa domanda, calcoliamo le combinazioni di due diversi eventi.\nIl messaggio di Arnold Schwarzenegger è composto da 85 parole. Supponiamo che il messaggio sia stato diviso in 7 righe in modo casuale. Per creare 7 righe, dobbiamo inserire 6 interruzioni di riga. Queste interruzioni di riga possono essere inserite in qualsiasi posizione tra le parole.\nPoiché ci sono 85 parole, ci sono 84 spazi tra le parole (prima della seconda parola, terza parola, e così via). Il numero di modi in cui possiamo inserire 6 interruzioni di riga in 84 spazi è dato dalla combinazione:\n\\[\n\\binom{84}{6} = \\frac{84!}{6!(78!)} \\approx 406,481,544.\n\\]\nCalcoliamo ora il numero di modi in cui questo particolare acrostico può essere ottenuto.\nSupponiamo che l’acrostico “FUCKYOU” possa essere formato solo in un numero limitato di combinazioni specifiche. Per calcolare queste combinazioni, dobbiamo considerare le parole che iniziano con ciascuna delle lettere dell’acrostico e le posizioni in cui possono essere inserite le interruzioni di riga.\n\nIdentificazione delle parole chiave:\n\nF: “For”\nU: “unnecessary”\nC: “conversation”\nK: “keeping”\nY: “you”\nO: “over”\nU: “until”\n\nDeterminazione delle possibili interruzioni di riga: Per formare l’acrostico, dobbiamo posizionare le interruzioni di riga in modo che le parole chiave siano all’inizio delle righe. Le interruzioni possono essere inserite tra le parole chiave, con un certo numero di parole tra di esse.\nConteggio delle combinazioni:\n\nTra “For” e “unnecessary”: 11 possibilità\nTra “unnecessary” e “conversation”: 3 possibilità\nTra “conversation” e “keeping”: 9 possibilità\nTra “keeping” e “you”: 2 possibilità\nTra “you” e “over”: 2 possibilità\nTra “over” e “until”: 1 possibilità\n\nQuindi, il numero totale di combinazioni è:\n\\[\n11 \\times 3 \\times 9 \\times 2 \\times 2 \\times 1 = 1,188.\n\\]\n\nIn conclusione, la probabilità che l’acrostico volgare si verifichi casualmente è data dal rapporto tra il numero di combinazioni specifiche che formano l’acrostico (1,188) e il numero totale di modi per inserire 6 interruzioni di riga in 84 spazi (406,481,544):\n\\[\n\\frac{1,188}{406,481,544} \\approx 2.92 \\times 10^{-6} \\approx 1 \\text{ su } 342,000.\n\\]\nQuesta analisi ci mostra che è estremamente improbabile che l’acrostico volgare sia stato il risultato di una divisione casuale delle righe del messaggio. In altre parole, la probabilità che questo acrostico sia stato generato casualmente è trascurabile.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>J</span>  <span class='chapter-title'>Calcolo combinatorio</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html",
    "href": "chapters/appendix/a15_calculus.html",
    "title": "Appendice K — Per liberarvi dai terrori preliminari",
    "section": "",
    "text": "K.1 Introduzione ai logaritmi\nAggiungo alcune nozioni di base sui logaritmi. Il logaritmo è una funzione matematica che risponde alla domanda: “quante volte devo moltiplicare un certo numero (chiamato”base”) per ottenere un altro numero?” Matematicamente, questo è espresso come:\n\\[\n\\log_b(a) = x \\iff b^x = a\n\\]\nAd esempio, \\(\\log_2(8) = 3\\) perché \\(2^3 = 8\\).\nNel contesto dei logaritmi, i valori molto piccoli (compresi tra 0 e 1) diventano più grandi (in termini assoluti) e negativi quando applichiamo una funzione logaritmica. Questo è utile per stabilizzare i calcoli, specialmente quando lavoriamo con prodotti di numeri molto piccoli che potrebbero portare a problemi di underflow.\nPer esempio: - \\(\\log(1) = 0\\) - \\(\\log(0.1) = -1\\) - \\(\\log(0.01) = -2\\) - \\(\\log(0.001) = -3\\)\nCome si può vedere, i valori assoluti dei logaritmi crescono man mano che il numero originale si avvicina a zero.\nUna delle proprietà più utili dei logaritmi è che consentono di trasformare un prodotto in una somma:\n\\[\n\\log_b(a \\times c) = \\log_b(a) + \\log_b(c)\n\\]\nQuesta proprietà è estremamente utile in calcoli complessi, come nella statistica bayesiana, dove il prodotto di molte probabilità potrebbe diventare un numero molto piccolo e causare problemi numerici.\nUn’altra proprietà utile dei logaritmi è che un rapporto tra due numeri diventa la differenza dei loro logaritmi:\n\\[\n\\log_b\\left(\\frac{a}{c}\\right) = \\log_b(a) - \\log_b(c)\n\\]\nAnche questa proprietà è molto utilizzata in matematica, specialmente in situazioni in cui è necessario normalizzare i dati.\nIn sintesi, i logaritmi sono strumenti potenti per semplificare e stabilizzare i calcoli matematici. Essi consentono di lavorare più agevolmente con numeri molto grandi o molto piccoli e di trasformare operazioni complesse come prodotti e divisioni in somme e differenze, rendendo i calcoli più gestibili e meno inclini a errori numerici.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a15_calculus.html#watermark",
    "href": "chapters/appendix/a15_calculus.html#watermark",
    "title": "Appendice K — Per liberarvi dai terrori preliminari",
    "section": "K.2 Watermark",
    "text": "K.2 Watermark\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Thu Feb 29 2024\n\nPython implementation: CPython\nPython version       : 3.11.8\nIPython version      : 8.22.1\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.3.0\nMachine     : x86_64\nProcessor   : i386\nCPU cores   : 8\nArchitecture: 64bit\n\nmatplotlib: 3.8.3\nseaborn   : 0.13.2\nnumpy     : 1.26.4\narviz     : 0.17.0\nscipy     : 1.12.0\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>K</span>  <span class='chapter-title'>Per liberarvi dai terrori preliminari</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a20_kde_plot.html",
    "href": "chapters/appendix/a20_kde_plot.html",
    "title": "Appendice L — Kernel Density Estimation",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport scipy.stats as st\nfrom scipy.constants import golden\nimport arviz as az\n\n\n%config InlineBackend.figure_format = 'retina'\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\naz.style.use(\"arviz-darkgrid\")\nsns.set_theme(palette=\"colorblind\")\n\nConsideriamo in maggiore dettaglio la procedura di costruzione di un Kernel Density plot.\nUn istogramma divide i dati in intervalli discreti, conta il numero di punti che rientrano in ciascun intervallo e visualizza i risultati in un modo intuitivo. Nell’istruzione seguente, se specifichiamo il parametro density=True, l’area totale delle barre dell’istogramma diventa uguale a 1.\nPer fare un esempio, definisco una funzione che simula dei dati estratti da una distribuzione bimodale.\n\ndef make_data(N, f=0.3, rseed=1):\n    rand = np.random.RandomState(rseed)\n    x = rand.randn(N)\n    x[int(f * N) :] += 5\n    return x\n\n\nx = make_data(1000)\nhist = plt.hist(x, bins=30, density=True)\n\n\n\n\n\n\n\n\nGenero ora un numero più piccolo di dati.\n\nx = make_data(20, f=0.3, rseed=10)\nx\n\narray([ 1.3315865 ,  0.71527897, -1.54540029, -0.00838385,  0.62133597,\n       -0.72008556,  5.26551159,  5.10854853,  5.00429143,  4.82539979,\n        5.43302619,  6.20303737,  4.03493433,  6.02827408,  5.22863013,\n        5.44513761,  3.86339779,  5.13513688,  6.484537  ,  3.92019511])\n\n\nIl primo dei due istrogrammi seguenti chiarisce che si tratta di una distribuzione bimodale. Quello successivo, invece, mostra una distribuzione unimodale con una lunga coda. Senza vedere il codice, probabilmente non ci verrebbe in mente che questi due istogrammi sono stati costruiti dagli stessi dati. Il problema degli istogrammi, infatti, è che, a seconda della scelta dell’ampiezza degli intervalli, il profilo dell’istogramma può cambiare anche in maniera drastica. La domanda è: come possiamo ottenere un risultato migliore?\n\nhist = plt.hist(x, bins=12, density=True)\nplt.plot(x, np.full_like(x, -0.01), \"|k\", markeredgewidth=1);\n\n\n\n\n\n\n\n\n\nhist = plt.hist(x, bins=4, density=True)\nplt.plot(x, np.full_like(x, -0.01), \"|k\", markeredgewidth=1);\n\n\n\n\n\n\n\n\nL’istogramma conta quante osservazioni sono contenute in ciascun intervallo. Il Kernel Density Plot (KDE) fa una cosa simile, ma sostituisce alle frequenze assolute (o relative) un metodo diverso. Immaginiamo di posizionare la curva densità di una distribuzione gaussiana (con un’opportuna deviazione standard) in corrispondenza di ciascun punto della distribuzione. I punti sono rappresentati, nelle figure precedenti dai “ticks” evidenziati sotto l’istogramma. Per ciascun valore dell’asse \\(X\\), le ordinate di queste funzioni di densità vengono sommate. I punti così ottenuti sono congiunti da una curva. Il processo è descritto nella cella seguente.\n\nx_d = np.linspace(-4, 8, 1000)\ndensity = sum(st.norm(xi).pdf(x_d) for xi in x)\ndensity[0:10]\n\narray([0.02160887, 0.02227584, 0.02296033, 0.02366267, 0.02438324,\n       0.02512238, 0.02588048, 0.02665789, 0.02745499, 0.02827215])\n\n\nIl risultato è il cosiddetto KDE plot, ovvero un istogramma “lisciato”.\n\nplt.fill_between(x_d, density, alpha=0.5)\nplt.plot(x, np.full_like(x, -0.1), \"|k\", markeredgewidth=1)\n\nplt.axis([-4, 8, -0.2, 5]);\n\n\n\n\n\n\n\n\nUn risultato equivalente si ottiene con la funzione kdeplot() di seaborn. Si noti l’argomento bw_adjust che determina la deviazione standard delle gaussiane che vengono sommate.\n\n_ = sns.kdeplot(x, bw_adjust=0.6);\n\n\n\n\n\n\n\n\nIn generale, questo tipo di rappresentazione di una distribuzione empirica di frequenza è più informativa di un istogramma.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>L</span>  <span class='chapter-title'>Kernel Density Estimation</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a30_prob_tutorial.html",
    "href": "chapters/appendix/a30_prob_tutorial.html",
    "title": "Appendice M — Esercizi di probabilità discreta",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport math\nimport seaborn as sns\nfrom collections import defaultdict\nimport arviz as az\n\n\n%config InlineBackend.figure_format = 'retina'\nRANDOM_SEED = 42\nrng = np.random.default_rng(RANDOM_SEED)\naz.style.use(\"arviz-viridish\")\n\nConsidereremo qui alcuni esempi che illustrano come, generando delle liste che corrispondono a spazi campione ed eventi, sia possibile calcolare la probabilità associata agli eventi definiti sullo spazio campione di un esperimento casuale. In questo capitolo ci focalizzeremo su tre esperimenti casuali che producono uno spazio campione discreto: lancio di monete, lancio di dadi, estrazione di carte da un mazzo ben mescolato. Inizieremo ad esaminare il caso del lancio di uno o più dadi e i giochi di carte. In seguito esamineremo delle funzioni specializzate che possono essere usate per modellare l’esperimento casuale corrispondene ad una serie di lanci di una moneta. Prima di fare questo, però, esamineremo alcune funzioni Python utili per il calcolo delle probabilità.\nProbabilità di ottenere un numero minore di 4 dal lancio di un dado\nAbbiamo già visto in precedenza come generare lo spazio campione dell’esperimento aleatorio che corrisponde al lancio di un dado equilibrato a 6 facce.\n\nsample = [dice1 for dice1 in range(1, 7)]\nlist(sample)\n\n[1, 2, 3, 4, 5, 6]\n\n\nSu tale spazio campione definiamo un evento.\n\nevent = [roll for roll in sample if roll &lt; 4]\nprint(list(event))\n\n[1, 2, 3]\n\n\nCalcoliamo la probabilità di osservare l’evento che abbiamo definito.\n\nprint(f\"La probabilità dell'evento è {len(event)}/{len(sample)}.\")\n\nLa probabilità dell'evento è 3/6.\n\n\nLa probabilità di ottenere almeno un 6 dal lancio di due dadi\nConsideriamo un caso un po’ più complesso, ma che abbiamo già incontrato in precedenza. Iniziamo nuovamente a definire lo spazio campione dell’esperimento casuale. Si noti la sintassi della list comprehension.\n\nsample = [(dice1, dice2) for dice1 in range(1, 7) for dice2 in range(1, 7)]\nsample\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (2, 6),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (4, 6),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\nL’evento definito dal problema si verifica se è vera la condizione roll[0] == 6 (si ottiene un 6 con il primo dado) oppure se si verifica la condizione roll[1] (si ottiene un 6 con il secondo dado), oppure se si verificano entrambe. Si noti il connettivo logico or.\n\nevent = [roll for roll in sample if roll[0] == 6 or roll[1] == 6]\nevent\n\n[(1, 6),\n (2, 6),\n (3, 6),\n (4, 6),\n (5, 6),\n (6, 1),\n (6, 2),\n (6, 3),\n (6, 4),\n (6, 5),\n (6, 6)]\n\n\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n11 / 36\n\n\nLa probabilità di non ottenere neppure un 6 dal lancio di due dadi\nLa soluzione di questo problema richiede che si neghino le due condizioni definite in precedenza.\n\nevent = [roll for roll in sample if roll[0] != 6 and roll[1] != 6]\nevent\n\n[(1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (2, 1),\n (2, 2),\n (2, 3),\n (2, 4),\n (2, 5),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (4, 1),\n (4, 2),\n (4, 3),\n (4, 4),\n (4, 5),\n (5, 1),\n (5, 2),\n (5, 3),\n (5, 4),\n (5, 5)]\n\n\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n25 / 36\n\n\nIn maniera equivalente, la soluzione è data dalla probabilità dell’evento complementare a quello definito dal problema precedente: 1 - 11/36.\nLa probabilità che lanciando contemporaneamente due dadi a 6 facce la somma faccia 4\nIn questo caso la condizione logica che viene definita nella list comprehension è if sum(roll) == 4.\n\nevent = [roll for roll in sample if sum(roll) == 4]\nevent\n\n[(1, 3), (2, 2), (3, 1)]\n\n\nTroviamo la probabilità.\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n3 / 36\n\n\nLa probabilità che lanciando contemporaneamente tre dadi a 6 facce la somma faccia 10\nQuesto problema è solo una variante del problema precedente. L’unica differenza di rilievo è che dobbiamo costruire uno spazio campione corrispondente al prodotto cartesiano dell’insieme dei punti di un dado elevato alla terza potenza.\n\nr = range(1, 7)\nsample = [(i, j, k) for i in r for j in r for k in r]\nevent = [roll for roll in sample if sum(roll) == 10]\nprint(event)\nprint(f\"{len(event)} / {len(sample)}\")\n\n[(1, 3, 6), (1, 4, 5), (1, 5, 4), (1, 6, 3), (2, 2, 6), (2, 3, 5), (2, 4, 4), (2, 5, 3), (2, 6, 2), (3, 1, 6), (3, 2, 5), (3, 3, 4), (3, 4, 3), (3, 5, 2), (3, 6, 1), (4, 1, 5), (4, 2, 4), (4, 3, 3), (4, 4, 2), (4, 5, 1), (5, 1, 4), (5, 2, 3), (5, 3, 2), (5, 4, 1), (6, 1, 3), (6, 2, 2), (6, 3, 1)]\n27 / 216\n\n\nLa probabilità che lanciando contemporaneamente quattro dadi a 6 facce la somma faccia 13\nLa struttura logica è identica alla precedente, aumenta solo la dimensione dello spazio campione.\n\nr = range(1, 7)\nsample = [(i, j, k, l) for i in r for j in r for k in r for l in r]\nevent = [roll for roll in sample if sum(roll) == 13]\nprint(f\"{len(event)} / {len(sample)}\")\n\n140 / 1296\n\n\nLa probabilità di ottenere un 6 e un altro numero (diverso da 6) nel lancio di due dadi a 6 facce\nQuesto problema introduce un nuovo modo per valutare una condizione logica in riferimento allo spazio campione. Il problema dice che dobbiamo ottenere solo un 6, con il primo o con il secondo dado, ma non con entrambi. Dobbiamo dunque esaminare ciascun punto dello spazio campione (una tupla di due elementi) e verificare se contiene un solo 6. Per fare questo definiamo la funzione numsix() che prende come argomento una tupla e ritorna il numero di 6 che ha trovato. Avendo definito questa funzione, la applichiamo a tutti i punti dello spazio campione e estraiamo gli elementi nei quali la funzione ritorna 1 (ovvero, i punti campione nei quali c’è un solo 6).\n\nsample = [(i, j) for i in r for j in r]\n\n\ndef numsix(roll):\n    return len([dice for dice in roll if dice == 6])\n\n\nevent = [roll for roll in sample if numsix(roll) == 1]\nprint(event)\n\n[(1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n\n\nLa probabilità cercata è dunque 10/36.\n\nprint(f\"{len(event)} / {len(sample)}\")\n\n10 / 36\n\n\nLa probabilità di ottenere un 6 e un altro numero (diverso da 6) nel lancio di quattro dadi a 6 facce\nQuesto problema è simile al precedente, ma considera uno spazio campione più grande.\n\nsample = [(i, j, k, l) for i in r for j in r for k in r for l in r]\n\nevent = [roll for roll in sample if numsix(roll) == 1]\nprint(f\"{len(event)} / {len(sample)}\")\n\n500 / 1296\n\n\nLa probabilità di ottenere tre 6 e un altro numero (diverso da 6) nel lancio di quattro dadi a 6 facce\nQui cambia solo la quantificazione della condizione logica usata prima.\n\nevent = [roll for roll in sample if numsix(roll)==3]\nprint(f\"{len(event)} / {len(sample)}\")\n\n20 / 1296\n\n\nEsaminiamo ora alcuni esempio relativi ai giochi di carte. Per questi scopi abbiamo bisogno di generare degli spazi campione che corrispondono a selezioni di elementi nelle quali l’ordine non conta e gli elementi non possono essere ripetuti. Questa è la definizione di una combinazione semplice – si veda la sezione {ref}combinazione-semplice-section. Importiamo la funzione combinations da itertools.\n\nfrom itertools import combinations, product\n\nPer chiarire la procedura, iniziamo a considerare un mazzo di carte molto piccolo, in cui abbiamo solo due semi e tre numeri. Generiamo il mazzo di carte.\n\ncards = list(product(range(1,3), range(1,4)))\ncards\n\n[(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3)]\n\n\nDiciamo che il primo valore di ciascuna delle precedenti coppie di numeri corrisponde al seme e il secondo valore corrisponde al numero. Se vogliamo, possiamo immaginare cuori e picche con i numeri 1, 2, 3.\nIniziamo a chiederci quante mani di due carte siano possibili per questo mazzo di carte. Ci sono 15 possibilità. Usiamo la formula delle combinazioni semplici.\n\nmath.comb(6, 2)\n\n15\n\n\nElenchiamo tutte le possibili combinazioni semplici.\n\nsample = list(combinations(cards, 2))\nsample\n\n[((1, 1), (1, 2)),\n ((1, 1), (1, 3)),\n ((1, 1), (2, 1)),\n ((1, 1), (2, 2)),\n ((1, 1), (2, 3)),\n ((1, 2), (1, 3)),\n ((1, 2), (2, 1)),\n ((1, 2), (2, 2)),\n ((1, 2), (2, 3)),\n ((1, 3), (2, 1)),\n ((1, 3), (2, 2)),\n ((1, 3), (2, 3)),\n ((2, 1), (2, 2)),\n ((2, 1), (2, 3)),\n ((2, 2), (2, 3))]\n\n\n\nlen(sample)\n\n15\n\n\nChiediamoci ora quale sia la probabilità di una coppia di assi. Ovviamente nello spazio campione precedente c’è solo un modo di ottenere una coppia di assi: ((1, 1), (2, 1)). Ma poniamoci il problema di trovare questa soluzione in maniera algoritmica.\n\ndef numval(hand, val):\n    return len([card for card in hand if card[1] == val])\n\n\ndef numace(hand):\n    return numval(hand, 1)\n\n\nevent = [hand for hand in sample if numace(hand) == 2]\nprint(f\"{len(event)} / {len(sample)}\")\n\n1 / 15\n\n\nLa probabilità di un pocker d’assi\nOra che abbiamo capito come fare, possiamo usare la procedura descritta sopra per calcolare un evento più interessante, ovvero la probabilità di ottenere un pocker d’assi in un regolare mazzo da pocker di 52 carte. Iniziamo trovando il numero di possibili di mani di 5 carte:\n\ncards = list(product(range(1,5), range(1,14)))\nsample = list(combinations(cards, 5))\nlen(sample)\n\n2598960\n\n\nTroviamo ora la probabilità di un pocker d’assi.\n\nevent = [hand for hand in sample if numace(hand) == 4]\nprint(f\"{len(event)} / {len(sample)}\")\n\n48 / 2598960\n\n\nLa probabilità di una coppia d’assi e una coppia di Jack\nIn una variante di questo problema, troviamo la probabilità di una coppia d’assi e una coppia di Jack:\n\ndef numjack(hand):\n    return numval(hand, 11)\n\n\nevent = [hand for hand in sample if numace(hand) == 2 and numjack(hand) == 2]\nprint(f\"{len(event)} / {len(sample)}\")\n\n1584 / 2598960\n\n\nConcludiamo con alcuni esempi discussi nel secondo capitolo del testo di {cite:t}unpingco2022python.\nConsideriamo nuovamente l’esperimento casuale corrispondente al lancio di due dati equilibrati. Sia \\(X\\) la v.c. corrispondente alla somma dei punti prodotti dai due lanci. Poniamoci il problema di trovare la distribuzione di massa di probabilità di \\(X\\) e la probabilità associata a diversi eventi. Vedremo qui una procedura alternativa per risolvere questo problema rispetto quella discussa in precedenza.\nPer affrontare questo problema, {cite:t}unpingco2022python inizia a costruire un dizionario Python i cui elementi sono i punti del prodotto cartesiano i cui elementi sono della forma (a,b), dove \\(a\\) appartiene ad \\(A\\) = {1, 2, 3, 4, 5, 6} (punti del primo dado) e \\(b\\) appartiene a \\(B\\) = {1, 2, 3, 4, 5, 6} (punti del secondo dado).\n\nd = {(i, j): i + j for i in range(1, 7) for j in range(1, 7)}\nd\n\n{(1, 1): 2,\n (1, 2): 3,\n (1, 3): 4,\n (1, 4): 5,\n (1, 5): 6,\n (1, 6): 7,\n (2, 1): 3,\n (2, 2): 4,\n (2, 3): 5,\n (2, 4): 6,\n (2, 5): 7,\n (2, 6): 8,\n (3, 1): 4,\n (3, 2): 5,\n (3, 3): 6,\n (3, 4): 7,\n (3, 5): 8,\n (3, 6): 9,\n (4, 1): 5,\n (4, 2): 6,\n (4, 3): 7,\n (4, 4): 8,\n (4, 5): 9,\n (4, 6): 10,\n (5, 1): 6,\n (5, 2): 7,\n (5, 3): 8,\n (5, 4): 9,\n (5, 5): 10,\n (5, 6): 11,\n (6, 1): 7,\n (6, 2): 8,\n (6, 3): 9,\n (6, 4): 10,\n (6, 5): 11,\n (6, 6): 12}\n\n\nIl passo successivo è quello di raccogliere tutte le coppie (a,b) la cui somma corrisponde a ciascuno dei possibili valori da 2 a 12. Per fare questo, {cite:t}unpingco2022python utilizza la funzione defaultdict():\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\ndinv\n\ndefaultdict(list,\n            {2: [(1, 1)],\n             3: [(1, 2), (2, 1)],\n             4: [(1, 3), (2, 2), (3, 1)],\n             5: [(1, 4), (2, 3), (3, 2), (4, 1)],\n             6: [(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)],\n             7: [(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)],\n             8: [(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)],\n             9: [(3, 6), (4, 5), (5, 4), (6, 3)],\n             10: [(4, 6), (5, 5), (6, 4)],\n             11: [(5, 6), (6, 5)],\n             12: [(6, 6)]})\n\n\nA questo punto è possibile ottenere una lista di tutte le coppie la cui somma è 7, per esempio:\n\ndinv[7]\n\n[(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)]\n\n\nIl passo successivo consiste nel calcolare la probabilità misurata per ciascun elemento di dinv. Utilizzando l’ipotesi di indipendenza, ciò significa che dobbiamo calcolare la somma dei prodotti delle probabilità dei singoli elementi in dinv. Poiché sappiamo che ogni risultato è ugualmente probabile, la probabilità di ogni termine nella somma è uguale a 1/36. Pertanto, tutto ciò che dobbiamo fare è contare il numero di elementi nell’elenco corrispondente per ogni key in dinv e dividere per 36. Ad esempio, dinv[11] contiene [(5, 6), (6, 5)]. La probabilità di 5+6=6+5=11 è la probabilità di questo insieme, che è composto dalla somma delle probabilità dei singoli elementi {(5,6),(6,5)}. In questo caso, abbiamo P(11) = P({(5, 6)}) + P({(6, 5)}) = 1/36 + 1/36 = 2/36. Ripetendo questa procedura per tutti gli elementi, deriviamo la funzione di massa di probabilità come mostrato di seguito:\n\nX = {i: len(j) / 36.0 for i, j in dinv.items()}\nX\n\n{2: 0.027777777777777776,\n 3: 0.05555555555555555,\n 4: 0.08333333333333333,\n 5: 0.1111111111111111,\n 6: 0.1388888888888889,\n 7: 0.16666666666666666,\n 8: 0.1388888888888889,\n 9: 0.1111111111111111,\n 10: 0.08333333333333333,\n 11: 0.05555555555555555,\n 12: 0.027777777777777776}\n\n\n{cite:t}unpingco2022python afferma che questo esempio mostra quali sono gli elementi della teoria della probabilità che sono in gioco in questo semplice problema, sopprimendo deliberatamente alcuni dei dettagli tecnici più fastidiosi.\nEsaminiamo con più attenzione la funzione defaultdict(). Si noti che, nell’esempio sopra, essa prende come argomento list. Consideriamo con il seguente problema. Vogliamo contare quante volte ciascuna parola compare in un testo. Un primo modo per affrontare il problema è il seguente: creiamo un dizionario a cui aggiungiamo come key ciascuna parola (se non è già presente nel dizionario) e, come valore, il numero di occorrenze:\n\ntext = \"Suppose I need to count the number of word occurrences in a text. How could I do that? Python provides us with multiple ways to do this same thing.\"\nword_count_dict = {}\nfor w in text.split(\" \"):\n    if w in word_count_dict:\n        word_count_dict[w]+=1\n    else:\n        word_count_dict[w]=1\n\nword_count_dict\n\n{'Suppose': 1,\n 'I': 2,\n 'need': 1,\n 'to': 2,\n 'count': 1,\n 'the': 1,\n 'number': 1,\n 'of': 1,\n 'word': 1,\n 'occurrences': 1,\n 'in': 1,\n 'a': 1,\n 'text.': 1,\n 'How': 1,\n 'could': 1,\n 'do': 2,\n 'that?': 1,\n 'Python': 1,\n 'provides': 1,\n 'us': 1,\n 'with': 1,\n 'multiple': 1,\n 'ways': 1,\n 'this': 1,\n 'same': 1,\n 'thing.': 1}\n\n\nLo stesso risultato si ottiene con defaultdict(). In questo caso\n\nword_count_dict = defaultdict(int)\nfor w in text.split(\" \"):\n    word_count_dict[w] += 1\n\nword_count_dict\n\ndefaultdict(int,\n            {'Suppose': 1,\n             'I': 2,\n             'need': 1,\n             'to': 2,\n             'count': 1,\n             'the': 1,\n             'number': 1,\n             'of': 1,\n             'word': 1,\n             'occurrences': 1,\n             'in': 1,\n             'a': 1,\n             'text.': 1,\n             'How': 1,\n             'could': 1,\n             'do': 2,\n             'that?': 1,\n             'Python': 1,\n             'provides': 1,\n             'us': 1,\n             'with': 1,\n             'multiple': 1,\n             'ways': 1,\n             'this': 1,\n             'same': 1,\n             'thing.': 1})\n\n\nCiò rende chiaro che, in questo caso, defaultdict() viene usato per creare un dizionario dove associamo a ciascuna key la frequenza con la quale essa è presente nell’oggetto text. In questo secondo esempio, defaultdict() prende come argomento int perché ritornerà un integer.\nNel caso del lancio dei due dadi, invece, l’argomento di defaultdict() è list, perché a ciascuna key verrà associata una lista. d.items() sono i dict_items.\n\nd.items()\n\ndict_items([((1, 1), 2), ((1, 2), 3), ((1, 3), 4), ((1, 4), 5), ((1, 5), 6), ((1, 6), 7), ((2, 1), 3), ((2, 2), 4), ((2, 3), 5), ((2, 4), 6), ((2, 5), 7), ((2, 6), 8), ((3, 1), 4), ((3, 2), 5), ((3, 3), 6), ((3, 4), 7), ((3, 5), 8), ((3, 6), 9), ((4, 1), 5), ((4, 2), 6), ((4, 3), 7), ((4, 4), 8), ((4, 5), 9), ((4, 6), 10), ((5, 1), 6), ((5, 2), 7), ((5, 3), 8), ((5, 4), 9), ((5, 5), 10), ((5, 6), 11), ((6, 1), 7), ((6, 2), 8), ((6, 3), 9), ((6, 4), 10), ((6, 5), 11), ((6, 6), 12)])\n\n\nIl ciclo for i, j in d.items(): fa riferimento a ciascuno degli elementi del dizionario d.\n\nfor i, j in d.items():\n    print(i,j)\n\n(1, 1) 2\n(1, 2) 3\n(1, 3) 4\n(1, 4) 5\n(1, 5) 6\n(1, 6) 7\n(2, 1) 3\n(2, 2) 4\n(2, 3) 5\n(2, 4) 6\n(2, 5) 7\n(2, 6) 8\n(3, 1) 4\n(3, 2) 5\n(3, 3) 6\n(3, 4) 7\n(3, 5) 8\n(3, 6) 9\n(4, 1) 5\n(4, 2) 6\n(4, 3) 7\n(4, 4) 8\n(4, 5) 9\n(4, 6) 10\n(5, 1) 6\n(5, 2) 7\n(5, 3) 8\n(5, 4) 9\n(5, 5) 10\n(5, 6) 11\n(6, 1) 7\n(6, 2) 8\n(6, 3) 9\n(6, 4) 10\n(6, 5) 11\n(6, 6) 12\n\n\nL’indice i indica le coppie\n\nfor i, j in d.items():\n    print(i)\n\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n(2, 1)\n(2, 2)\n(2, 3)\n(2, 4)\n(2, 5)\n(2, 6)\n(3, 1)\n(3, 2)\n(3, 3)\n(3, 4)\n(3, 5)\n(3, 6)\n(4, 1)\n(4, 2)\n(4, 3)\n(4, 4)\n(4, 5)\n(4, 6)\n(5, 1)\n(5, 2)\n(5, 3)\n(5, 4)\n(5, 5)\n(5, 6)\n(6, 1)\n(6, 2)\n(6, 3)\n(6, 4)\n(6, 5)\n(6, 6)\n\n\nMentre j fa riferimento alla somma\n\nfor i, j in d.items():\n    print(j)\n\n2\n3\n4\n5\n6\n7\n3\n4\n5\n6\n7\n8\n4\n5\n6\n7\n8\n9\n5\n6\n7\n8\n9\n10\n6\n7\n8\n9\n10\n11\n7\n8\n9\n10\n11\n12\n\n\nOra possiamo usare defaultdict(list). Per ciascun valore della somma (j), appendiamo alla lista ad esso associata gli elementi (i) che producono tale somma:\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\nAvendo ottenuto il risultato riportato sopra, {cite:t}unpingco2022python si pone un altra domanda: qual è la probabilità che la metà del prodotto dei punti prodotti da tre dadi superi la loro somma? Possiamo risolverlo usando lo stesso metodo del seguente. Innanzitutto, si crea lo spazio campione dell’esperimento casuale, ovvero un dizionario a cui, per ciascun punto dello spazio campione si aggiunge una variabile booleana che è True se la condizione specificata è soddisfatta ed è False altrimenti.\n\nd = {\n    (i, j, k): ((i * j * k) / 2 &gt; i + j + k)\n    for i in range(1, 7)\n    for j in range(1, 7)\n    for k in range(1, 7)\n}\nd\n\n{(1, 1, 1): False,\n (1, 1, 2): False,\n (1, 1, 3): False,\n (1, 1, 4): False,\n (1, 1, 5): False,\n (1, 1, 6): False,\n (1, 2, 1): False,\n (1, 2, 2): False,\n (1, 2, 3): False,\n (1, 2, 4): False,\n (1, 2, 5): False,\n (1, 2, 6): False,\n (1, 3, 1): False,\n (1, 3, 2): False,\n (1, 3, 3): False,\n (1, 3, 4): False,\n (1, 3, 5): False,\n (1, 3, 6): False,\n (1, 4, 1): False,\n (1, 4, 2): False,\n (1, 4, 3): False,\n (1, 4, 4): False,\n (1, 4, 5): False,\n (1, 4, 6): True,\n (1, 5, 1): False,\n (1, 5, 2): False,\n (1, 5, 3): False,\n (1, 5, 4): False,\n (1, 5, 5): True,\n (1, 5, 6): True,\n (1, 6, 1): False,\n (1, 6, 2): False,\n (1, 6, 3): False,\n (1, 6, 4): True,\n (1, 6, 5): True,\n (1, 6, 6): True,\n (2, 1, 1): False,\n (2, 1, 2): False,\n (2, 1, 3): False,\n (2, 1, 4): False,\n (2, 1, 5): False,\n (2, 1, 6): False,\n (2, 2, 1): False,\n (2, 2, 2): False,\n (2, 2, 3): False,\n (2, 2, 4): False,\n (2, 2, 5): True,\n (2, 2, 6): True,\n (2, 3, 1): False,\n (2, 3, 2): False,\n (2, 3, 3): True,\n (2, 3, 4): True,\n (2, 3, 5): True,\n (2, 3, 6): True,\n (2, 4, 1): False,\n (2, 4, 2): False,\n (2, 4, 3): True,\n (2, 4, 4): True,\n (2, 4, 5): True,\n (2, 4, 6): True,\n (2, 5, 1): False,\n (2, 5, 2): True,\n (2, 5, 3): True,\n (2, 5, 4): True,\n (2, 5, 5): True,\n (2, 5, 6): True,\n (2, 6, 1): False,\n (2, 6, 2): True,\n (2, 6, 3): True,\n (2, 6, 4): True,\n (2, 6, 5): True,\n (2, 6, 6): True,\n (3, 1, 1): False,\n (3, 1, 2): False,\n (3, 1, 3): False,\n (3, 1, 4): False,\n (3, 1, 5): False,\n (3, 1, 6): False,\n (3, 2, 1): False,\n (3, 2, 2): False,\n (3, 2, 3): True,\n (3, 2, 4): True,\n (3, 2, 5): True,\n (3, 2, 6): True,\n (3, 3, 1): False,\n (3, 3, 2): True,\n (3, 3, 3): True,\n (3, 3, 4): True,\n (3, 3, 5): True,\n (3, 3, 6): True,\n (3, 4, 1): False,\n (3, 4, 2): True,\n (3, 4, 3): True,\n (3, 4, 4): True,\n (3, 4, 5): True,\n (3, 4, 6): True,\n (3, 5, 1): False,\n (3, 5, 2): True,\n (3, 5, 3): True,\n (3, 5, 4): True,\n (3, 5, 5): True,\n (3, 5, 6): True,\n (3, 6, 1): False,\n (3, 6, 2): True,\n (3, 6, 3): True,\n (3, 6, 4): True,\n (3, 6, 5): True,\n (3, 6, 6): True,\n (4, 1, 1): False,\n (4, 1, 2): False,\n (4, 1, 3): False,\n (4, 1, 4): False,\n (4, 1, 5): False,\n (4, 1, 6): True,\n (4, 2, 1): False,\n (4, 2, 2): False,\n (4, 2, 3): True,\n (4, 2, 4): True,\n (4, 2, 5): True,\n (4, 2, 6): True,\n (4, 3, 1): False,\n (4, 3, 2): True,\n (4, 3, 3): True,\n (4, 3, 4): True,\n (4, 3, 5): True,\n (4, 3, 6): True,\n (4, 4, 1): False,\n (4, 4, 2): True,\n (4, 4, 3): True,\n (4, 4, 4): True,\n (4, 4, 5): True,\n (4, 4, 6): True,\n (4, 5, 1): False,\n (4, 5, 2): True,\n (4, 5, 3): True,\n (4, 5, 4): True,\n (4, 5, 5): True,\n (4, 5, 6): True,\n (4, 6, 1): True,\n (4, 6, 2): True,\n (4, 6, 3): True,\n (4, 6, 4): True,\n (4, 6, 5): True,\n (4, 6, 6): True,\n (5, 1, 1): False,\n (5, 1, 2): False,\n (5, 1, 3): False,\n (5, 1, 4): False,\n (5, 1, 5): True,\n (5, 1, 6): True,\n (5, 2, 1): False,\n (5, 2, 2): True,\n (5, 2, 3): True,\n (5, 2, 4): True,\n (5, 2, 5): True,\n (5, 2, 6): True,\n (5, 3, 1): False,\n (5, 3, 2): True,\n (5, 3, 3): True,\n (5, 3, 4): True,\n (5, 3, 5): True,\n (5, 3, 6): True,\n (5, 4, 1): False,\n (5, 4, 2): True,\n (5, 4, 3): True,\n (5, 4, 4): True,\n (5, 4, 5): True,\n (5, 4, 6): True,\n (5, 5, 1): True,\n (5, 5, 2): True,\n (5, 5, 3): True,\n (5, 5, 4): True,\n (5, 5, 5): True,\n (5, 5, 6): True,\n (5, 6, 1): True,\n (5, 6, 2): True,\n (5, 6, 3): True,\n (5, 6, 4): True,\n (5, 6, 5): True,\n (5, 6, 6): True,\n (6, 1, 1): False,\n (6, 1, 2): False,\n (6, 1, 3): False,\n (6, 1, 4): True,\n (6, 1, 5): True,\n (6, 1, 6): True,\n (6, 2, 1): False,\n (6, 2, 2): True,\n (6, 2, 3): True,\n (6, 2, 4): True,\n (6, 2, 5): True,\n (6, 2, 6): True,\n (6, 3, 1): False,\n (6, 3, 2): True,\n (6, 3, 3): True,\n (6, 3, 4): True,\n (6, 3, 5): True,\n (6, 3, 6): True,\n (6, 4, 1): True,\n (6, 4, 2): True,\n (6, 4, 3): True,\n (6, 4, 4): True,\n (6, 4, 5): True,\n (6, 4, 6): True,\n (6, 5, 1): True,\n (6, 5, 2): True,\n (6, 5, 3): True,\n (6, 5, 4): True,\n (6, 5, 5): True,\n (6, 5, 6): True,\n (6, 6, 1): True,\n (6, 6, 2): True,\n (6, 6, 3): True,\n (6, 6, 4): True,\n (6, 6, 5): True,\n (6, 6, 6): True}\n\n\n\ndinv = defaultdict(list)\nfor i, j in d.items():\n    dinv[j].append(i)\n\ndinv\n\ndefaultdict(list,\n            {False: [(1, 1, 1),\n              (1, 1, 2),\n              (1, 1, 3),\n              (1, 1, 4),\n              (1, 1, 5),\n              (1, 1, 6),\n              (1, 2, 1),\n              (1, 2, 2),\n              (1, 2, 3),\n              (1, 2, 4),\n              (1, 2, 5),\n              (1, 2, 6),\n              (1, 3, 1),\n              (1, 3, 2),\n              (1, 3, 3),\n              (1, 3, 4),\n              (1, 3, 5),\n              (1, 3, 6),\n              (1, 4, 1),\n              (1, 4, 2),\n              (1, 4, 3),\n              (1, 4, 4),\n              (1, 4, 5),\n              (1, 5, 1),\n              (1, 5, 2),\n              (1, 5, 3),\n              (1, 5, 4),\n              (1, 6, 1),\n              (1, 6, 2),\n              (1, 6, 3),\n              (2, 1, 1),\n              (2, 1, 2),\n              (2, 1, 3),\n              (2, 1, 4),\n              (2, 1, 5),\n              (2, 1, 6),\n              (2, 2, 1),\n              (2, 2, 2),\n              (2, 2, 3),\n              (2, 2, 4),\n              (2, 3, 1),\n              (2, 3, 2),\n              (2, 4, 1),\n              (2, 4, 2),\n              (2, 5, 1),\n              (2, 6, 1),\n              (3, 1, 1),\n              (3, 1, 2),\n              (3, 1, 3),\n              (3, 1, 4),\n              (3, 1, 5),\n              (3, 1, 6),\n              (3, 2, 1),\n              (3, 2, 2),\n              (3, 3, 1),\n              (3, 4, 1),\n              (3, 5, 1),\n              (3, 6, 1),\n              (4, 1, 1),\n              (4, 1, 2),\n              (4, 1, 3),\n              (4, 1, 4),\n              (4, 1, 5),\n              (4, 2, 1),\n              (4, 2, 2),\n              (4, 3, 1),\n              (4, 4, 1),\n              (4, 5, 1),\n              (5, 1, 1),\n              (5, 1, 2),\n              (5, 1, 3),\n              (5, 1, 4),\n              (5, 2, 1),\n              (5, 3, 1),\n              (5, 4, 1),\n              (6, 1, 1),\n              (6, 1, 2),\n              (6, 1, 3),\n              (6, 2, 1),\n              (6, 3, 1)],\n             True: [(1, 4, 6),\n              (1, 5, 5),\n              (1, 5, 6),\n              (1, 6, 4),\n              (1, 6, 5),\n              (1, 6, 6),\n              (2, 2, 5),\n              (2, 2, 6),\n              (2, 3, 3),\n              (2, 3, 4),\n              (2, 3, 5),\n              (2, 3, 6),\n              (2, 4, 3),\n              (2, 4, 4),\n              (2, 4, 5),\n              (2, 4, 6),\n              (2, 5, 2),\n              (2, 5, 3),\n              (2, 5, 4),\n              (2, 5, 5),\n              (2, 5, 6),\n              (2, 6, 2),\n              (2, 6, 3),\n              (2, 6, 4),\n              (2, 6, 5),\n              (2, 6, 6),\n              (3, 2, 3),\n              (3, 2, 4),\n              (3, 2, 5),\n              (3, 2, 6),\n              (3, 3, 2),\n              (3, 3, 3),\n              (3, 3, 4),\n              (3, 3, 5),\n              (3, 3, 6),\n              (3, 4, 2),\n              (3, 4, 3),\n              (3, 4, 4),\n              (3, 4, 5),\n              (3, 4, 6),\n              (3, 5, 2),\n              (3, 5, 3),\n              (3, 5, 4),\n              (3, 5, 5),\n              (3, 5, 6),\n              (3, 6, 2),\n              (3, 6, 3),\n              (3, 6, 4),\n              (3, 6, 5),\n              (3, 6, 6),\n              (4, 1, 6),\n              (4, 2, 3),\n              (4, 2, 4),\n              (4, 2, 5),\n              (4, 2, 6),\n              (4, 3, 2),\n              (4, 3, 3),\n              (4, 3, 4),\n              (4, 3, 5),\n              (4, 3, 6),\n              (4, 4, 2),\n              (4, 4, 3),\n              (4, 4, 4),\n              (4, 4, 5),\n              (4, 4, 6),\n              (4, 5, 2),\n              (4, 5, 3),\n              (4, 5, 4),\n              (4, 5, 5),\n              (4, 5, 6),\n              (4, 6, 1),\n              (4, 6, 2),\n              (4, 6, 3),\n              (4, 6, 4),\n              (4, 6, 5),\n              (4, 6, 6),\n              (5, 1, 5),\n              (5, 1, 6),\n              (5, 2, 2),\n              (5, 2, 3),\n              (5, 2, 4),\n              (5, 2, 5),\n              (5, 2, 6),\n              (5, 3, 2),\n              (5, 3, 3),\n              (5, 3, 4),\n              (5, 3, 5),\n              (5, 3, 6),\n              (5, 4, 2),\n              (5, 4, 3),\n              (5, 4, 4),\n              (5, 4, 5),\n              (5, 4, 6),\n              (5, 5, 1),\n              (5, 5, 2),\n              (5, 5, 3),\n              (5, 5, 4),\n              (5, 5, 5),\n              (5, 5, 6),\n              (5, 6, 1),\n              (5, 6, 2),\n              (5, 6, 3),\n              (5, 6, 4),\n              (5, 6, 5),\n              (5, 6, 6),\n              (6, 1, 4),\n              (6, 1, 5),\n              (6, 1, 6),\n              (6, 2, 2),\n              (6, 2, 3),\n              (6, 2, 4),\n              (6, 2, 5),\n              (6, 2, 6),\n              (6, 3, 2),\n              (6, 3, 3),\n              (6, 3, 4),\n              (6, 3, 5),\n              (6, 3, 6),\n              (6, 4, 1),\n              (6, 4, 2),\n              (6, 4, 3),\n              (6, 4, 4),\n              (6, 4, 5),\n              (6, 4, 6),\n              (6, 5, 1),\n              (6, 5, 2),\n              (6, 5, 3),\n              (6, 5, 4),\n              (6, 5, 5),\n              (6, 5, 6),\n              (6, 6, 1),\n              (6, 6, 2),\n              (6, 6, 3),\n              (6, 6, 4),\n              (6, 6, 5),\n              (6, 6, 6)]})\n\n\n\nX = {i: len(j) / 6.0**3 for i, j in dinv.items()}\nprint(X)\n\n{False: 0.37037037037037035, True: 0.6296296296296297}\n\n\n\nd = pd.DataFrame(\n    index=[(i, j) for i in range(1, 7) for j in range(1, 7)],\n    columns=[\"sm\", \"d1\", \"d2\", \"pd1\", \"pd2\", \"p\"],\n)\nd\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(1, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(2, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(3, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(4, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(5, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 1)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 2)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 3)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 4)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 5)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n(6, 6)\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nd.d1 = [i[0] for i in d.index]\nd.d2 = [i[1] for i in d.index]\n\nd.head(), d.tail()\n\n(         sm  d1  d2  pd1  pd2    p\n (1, 1)  NaN   1   1  NaN  NaN  NaN\n (1, 2)  NaN   1   2  NaN  NaN  NaN\n (1, 3)  NaN   1   3  NaN  NaN  NaN\n (1, 4)  NaN   1   4  NaN  NaN  NaN\n (1, 5)  NaN   1   5  NaN  NaN  NaN,\n          sm  d1  d2  pd1  pd2    p\n (6, 2)  NaN   6   2  NaN  NaN  NaN\n (6, 3)  NaN   6   3  NaN  NaN  NaN\n (6, 4)  NaN   6   4  NaN  NaN  NaN\n (6, 5)  NaN   6   5  NaN  NaN  NaN\n (6, 6)  NaN   6   6  NaN  NaN  NaN)\n\n\n\nd[\"sm\"] = d[\"d1\"] + d[\"d2\"]\nd.head()\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\n2\n1\n1\nNaN\nNaN\nNaN\n\n\n(1, 2)\n3\n1\n2\nNaN\nNaN\nNaN\n\n\n(1, 3)\n4\n1\n3\nNaN\nNaN\nNaN\n\n\n(1, 4)\n5\n1\n4\nNaN\nNaN\nNaN\n\n\n(1, 5)\n6\n1\n5\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nd[\"pd1\"] = 1/6\nd[\"pd2\"] = 1/6\nd[\"p\"] = d[\"pd1\"] * d[\"pd2\"]\nd.head()\n\n\n\n\n\n\n\n\nsm\nd1\nd2\npd1\npd2\np\n\n\n\n\n(1, 1)\n2\n1\n1\n0.166667\n0.166667\n0.027778\n\n\n(1, 2)\n3\n1\n2\n0.166667\n0.166667\n0.027778\n\n\n(1, 3)\n4\n1\n3\n0.166667\n0.166667\n0.027778\n\n\n(1, 4)\n5\n1\n4\n0.166667\n0.166667\n0.027778\n\n\n(1, 5)\n6\n1\n5\n0.166667\n0.166667\n0.027778\n\n\n\n\n\n\n\n\nd[\"p\"].sum()\n\n1.0\n\n\n\nd.groupby('sm')['p'].sum()\n\nsm\n2     0.027778\n3     0.055556\n4     0.083333\n5     0.111111\n6     0.138889\n7     0.166667\n8     0.138889\n9     0.111111\n10    0.083333\n11    0.055556\n12    0.027778\nName: p, dtype: float64",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>M</span>  <span class='chapter-title'>Esercizi di probabilità discreta</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html",
    "href": "chapters/appendix/a40_rng.html",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "",
    "text": "N.0.1 Numeri casuali\nCosa intendiamo per numeri casuali? Sono sequenze di numeri generati secondo una distribuzione di probabilità specificata. Questa distribuzione definisce la probabilità con cui ciascun valore può essere estratto. Ad esempio, nella distribuzione uniforme, tutti i valori hanno la stessa probabilità di apparire. Un esempio concreto è il lancio di un dado perfetto: ogni faccia ha una probabilità su sei di uscire, rappresentando una distribuzione uniforme discreta.\nTuttavia, la casualità non si limita ai dadi o ai numeri interi. Possiamo generare numeri casuali che possono assumere qualsiasi valore all’interno di un intervallo, come ad esempio tra 0 e 1. Questi numeri sono detti uniformi, poiché ogni valore ha la stessa probabilità di essere estratto.\nMa la casualità può assumere molte altre forme. Possiamo generare numeri che seguono altre leggi di probabilità, come la distribuzione normale (a forma di campana), la distribuzione beta o la distribuzione gamma. La scelta della distribuzione dipende dal problema specifico che vogliamo affrontare.\nIl computer, essendo una macchina che segue regole precise, non può generare numeri veramente casuali, ma può produrre sequenze di numeri che appaiono casuali a tutti gli effetti. Questi numeri sono chiamati pseudo-casuali.\nCome fanno i computer a simulare la casualità? Utilizzano degli algoritmi, ovvero delle procedure ben precise, che a partire da un valore iniziale, chiamato “seed”, generano una sequenza di numeri. Questo seed è spesso ottenuto da eventi esterni al computer, come ad esempio il tempo di sistema, rendendo così la sequenza generata diversa ad ogni esecuzione. Per molti scopi pratici, come le simulazioni statistiche, non è necessario distinguere tra numeri veramente casuali e pseudo-casuali.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#generazione-di-numeri-casuali",
    "href": "chapters/appendix/a40_rng.html#generazione-di-numeri-casuali",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.1 Generazione di Numeri Casuali",
    "text": "N.1 Generazione di Numeri Casuali\nLa generazione di numeri casuali (RNG) è il processo mediante il quale si estrae una sequenza di numeri che, in realtà, non sono completamente casuali per varie ragioni.\nEssi vengono estratti da una distribuzione di probabilità, con la più comune che è la distribuzione uniforme nel dominio 0≤𝑥&lt;1, ovvero numeri casuali compresi tra zero e uno.\nNella maggior parte delle applicazioni informatiche, comprese quelle utilizzate in questo insegnamento, i numeri casuali sono in realtà pseudocasuali. Questo significa che dipendono completamente da un valore iniziale chiamato “seed” e vengono generati da un algoritmo deterministico basato su quel seed. Questo diventa evidente quando notiamo che otteniamo sempre la stessa sequenza di numeri casuali quando utilizziamo lo stesso seme, sia su diverse macchine che in diverse ripetizioni sulla stessa macchina.\nPer ottenere numeri veramente casuali sui nostri computer, sarebbe necessario acquisire dati casuali da una fonte esterna, come sequenze di tasti, movimenti del mouse, dati di rete, e così via. La necessità di numeri veramente casuali sorge principalmente in contesti legati alla sicurezza, come la crittografia. Tuttavia, per gli scopi della data science, i numeri pseudocasuali generati dal computer tramite algoritmi come quelli offerti da NumPy in Python sono sufficienti.\nIl generatore rng fornito da NumPy offre una serie di metodi per generare numeri casuali estratti da diverse distribuzioni di probabilità. Oltre agli argomenti specifici della distribuzione, ciascun metodo accetta un argomento size, il cui valore predefinito è None. Se size è impostato su None, verrà generato e restituito un singolo valore casuale. Se, invece, size è un numero intero, verrà restituito un array 1-D contenente i valori generati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-uniforme",
    "href": "chapters/appendix/a40_rng.html#distribuzione-uniforme",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.2 Distribuzione uniforme",
    "text": "N.2 Distribuzione uniforme\nConsideriamo la distribuzione uniforme: rng.uniform([low, high, size]). Genero un singolo valore:\nLo genero una seconda volta:\n\nrng.uniform(0, 1, size=1)\n\narray([0.77395605])\n\n\nGenero 20 valori:\n\nrng.uniform(0, 1, size=20)\n\narray([0.43887844, 0.85859792, 0.69736803, 0.09417735, 0.97562235,\n       0.7611397 , 0.78606431, 0.12811363, 0.45038594, 0.37079802,\n       0.92676499, 0.64386512, 0.82276161, 0.4434142 , 0.22723872,\n       0.55458479, 0.06381726, 0.82763117, 0.6316644 , 0.75808774])\n\n\nCreo un istogramma.\n\nn_samples = 1000000\n_ = plt.hist(rng.uniform(0, 1, size=n_samples), bins=50, density=True)",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-normale",
    "href": "chapters/appendix/a40_rng.html#distribuzione-normale",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.3 Distribuzione normale",
    "text": "N.3 Distribuzione normale\nEstraiamo ora dei campioni casuali dalla distribuzione Gaussiana, rng.normal([loc, scale, size]). Per esempio, generiamo 10 valori dalla distribuzione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\):\n\nx = rng.normal(loc=100, scale=15, size=10)\nprint(x)\n\n[ 88.39130723 106.85972149 112.68284617  98.40757644  59.28402571\n  83.63194152 127.29102032  91.32585446 109.21359401 103.23261596]\n\n\nOra generiamo un grande numero (1000000) di valori casuali dalla \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\). Con questi valori creiamo un istogramma e a tale istogramma sovrapponiamo la funzione di densità \\(\\mathcal{N}(\\mu = 100, \\sigma = 15)\\). In questo modo possiamo accertarci che i numeri casuali che abbiamo ottenuto si riferiscano veramente alla densità desiderata. Per trovare la densità della distribuzione normale, uso norm.pdf da scipy.stats.\n\nn_samples = 1000000\nmu = 100\nsigma = 15\n# create x's\nxs = np.linspace(55, 145, n_samples)\ny_pdf = stats.norm.pdf(xs, mu, sigma)\n# create random samples\nsamps = rng.normal(loc=mu, scale=sigma, size=n_samples)\n# plot them\nplt.plot(xs, y_pdf)\nplt.hist(samps, bins=50, density=True)\nplt.title(\"Distribuzione Normale $\\mathcal{N}(\\mu=100, \\sigma=15)$\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xlim(40, 160);\n\n\n\n\n\n\n\n\nLa stessa procedura può essere usata per tutte le distribuzioni implementate da NumPy. Esaminiamo alcuni esempi qui sotto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-beta",
    "href": "chapters/appendix/a40_rng.html#distribuzione-beta",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.4 Distribuzione Beta",
    "text": "N.4 Distribuzione Beta\nPer estrarre dei campioni casuali dalla distribuzione Beta usiamo il generatore rng.beta(a, b[, size]); per la densità Beta usiamo stats.beta.pdf(x, a, b).\n\n# Definisci il numero di campioni\nn_samples = 1000000\na = 3\nb = 9\n\n# Crea un array di valori x\nxs = np.linspace(0, 1, n_samples)\n\n# Calcola la densità di probabilità (PDF) della distribuzione Beta\ny_pdf = stats.beta.pdf(xs, a, b)\n\n# Genera i campioni casuali\nsamps = rng.beta(a, b, size=n_samples)\n\n# Traccia il grafico\nplt.plot(xs, y_pdf, label=\"Densità Beta(3,9)\")\nplt.hist(samps, bins=50, density=True, label=\"Campioni\")\nplt.title(\"Confronto tra la Distribuzione Beta(3,9) e Campioni Casuali\")\nplt.ylabel(\"Densità\")\nplt.xlabel(\"Valore\")\n_ = plt.legend()",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-binomiale",
    "href": "chapters/appendix/a40_rng.html#distribuzione-binomiale",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.5 Distribuzione binomiale",
    "text": "N.5 Distribuzione binomiale\nPer estrarre dei campioni casuali dalla distribuzione Binomiale usiamo rng.binomial(n, p[, size]); per la distribuzione di massa Binomiale usiamo stats.binom.pmf(r, n, p).\n\nn_samples = 1000000\n\nn = 10\np = 0.3\n# create r values\nr_values = list(range(n + 1))\n# pmf\ny_pmf = [stats.binom.pmf(r, n, p) for r in r_values]\n# create random samples\nr_samps = rng.binomial(n=n, p=p, size=n_samples)\nplt.plot(r_values, y_pmf, \"x\")\nplt.hist(r_samps, bins=np.arange(-0.5, 11.5, 1), density=True)\nplt.title(\"Distribuzione Binomiale($n$=10, $p$=0.3)\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\");",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-t-di-student",
    "href": "chapters/appendix/a40_rng.html#distribuzione-t-di-student",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.6 Distribuzione \\(t\\) di Student",
    "text": "N.6 Distribuzione \\(t\\) di Student\nPer estrarre dei campioni casuali dalla distribuzione \\(t\\) di Student uso il generatore rng con standard_t(df, size=None); per la densità \\(t\\) di Student uso t.pdf da scipy.stats.\n\nn_samples = 100000\ndf = 4\n# create x's\nxs = np.linspace(-4, 4, n_samples)\ny_pdf = stats.t.pdf(xs, df=df)\n# create random samples\nsamps = rng.standard_t(df=df, size=n_samples)\n# plot them\nfig, ax = plt.subplots()\nplt.plot(xs, y_pdf)\nplt.hist(samps, bins=400, density=True)\nplt.title(\"Distribuzione $t(\\\\nu=4)$\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xlim(-4, 4);",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#distribuzione-arbitraria-di-una-variabile-casuale-distreta",
    "href": "chapters/appendix/a40_rng.html#distribuzione-arbitraria-di-una-variabile-casuale-distreta",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.7 Distribuzione arbitraria di una variabile casuale distreta",
    "text": "N.7 Distribuzione arbitraria di una variabile casuale distreta\nCon la funzione random.choices è possible specificare i valori di una variabile casuale discreta con una distribuzione di massa di probabilità arbitraria.\n\n# Define the set of values\nx_rv = [1, 2, 3, 4]\n# Define the weights for each value\nweights = [0.1, 0.1, 0.3, 0.5]\n\nx_sample = rng.choice(x_rv, size=100, p=weights)\nprint(f\"Random Sample: {x_sample}\")\n\nRandom Sample: [1 1 4 3 1 4 1 4 3 3 4 4 1 4 4 4 4 2 4 2 1 4 4 2 1 3 2 4 1 4 4 3 4 2 4 4 1\n 4 3 4 4 4 4 3 1 4 3 3 2 4 3 4 4 3 3 4 4 1 3 4 4 4 3 2 1 4 4 4 4 4 3 4 3 2\n 3 4 4 3 3 4 4 3 4 2 4 3 4 3 1 2 4 4 1 1 4 3 1 4 4 4]\n\n\nNell’esempio, i pesi weights indicano che, nella distribuzione, il valore 4 è presente con una frequenza di cinque volte maggiore dei valori 1 e 2.\nSe aggiungiamo l’argomento k possiamo definire i pesi (indirettamente, le probabilità) dei diversi valori della variabile casuale che sono stati specificati. Nell’esempio, i pesi [1, 1, 3, 6] indicano che, nella distribuzione, il valore 4 è presente con una frequenza di sei volte maggiore dei valori 1 e 2.\n\nn_samples = 100000\nx = rng.choice(x_rv, size=n_samples, p=weights)\nbins = plt.hist(x, density=True)\nplt.title(\"Distribuzione arbitraria di massa di probabilità\")\nplt.ylabel(\"$f(X)$\")\nplt.xlabel(\"Valore della variabile casuale $X$\")\nplt.xticks(x_rv);\n\n\n\n\n\n\n\n\n\nrng.binomial(10, .1, size=4)\n\narray([3, 0, 3, 1])",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#la-tecnica-dellinversione",
    "href": "chapters/appendix/a40_rng.html#la-tecnica-dellinversione",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.8 La Tecnica dell’Inversione",
    "text": "N.8 La Tecnica dell’Inversione\nLa tecnica dell’inversione per la simulazione, introdotta nel 1947 da John Von Neumann (Roger, 1987), permette di generare campioni casuali da una distribuzione data sfruttando una variabile casuale uniforme. Questo metodo consente di trasformare una variabile casuale uniforme in una variabile casuale con la distribuzione desiderata, permettendo così di ottenere un campione casuale da qualsiasi distribuzione specifica a partire da un campione di variabili casuali uniformi.\n\nN.8.1 Intuizione di Base\nImmaginiamo di avere una variabile casuale \\(X\\) con una funzione di distribuzione cumulativa \\(F(x)\\), che è una funzione che mappa i valori di \\(X\\) nell’intervallo \\([0, 1]\\). La tecnica dell’inversione sfrutta il fatto che possiamo invertire questa mappatura per ottenere i valori di \\(X\\) a partire da una variabile casuale uniforme \\(U\\) su \\([0, 1]\\).\n\nN.8.1.1 Passi Fondamentali:\n\nSi genera una variabile casuale \\(U\\) che è uniformemente distribuita nell’intervallo \\([0, 1]\\).\nSi applica l’inversa della funzione di distribuzione cumulativa \\(F^{-1}(u)\\) per ottenere il valore corrispondente di \\(X\\).\n\nVediamo come implementare questa tecnica utilizzando una distribuzione Gaussiana (Normale) con media \\(\\mu\\) e deviazione standard \\(\\sigma\\).\n\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n# Parametri della distribuzione normale\nmu = 0    # Media\nsigma = 1 # Deviazione standard\n\n# Generazione di 10000 variabili casuali uniformi\nu = np.random.uniform(0, 1, 10000)\n\n# Applicazione dell'inversa della funzione di distribuzione cumulativa normale\nx = stats.norm.ppf(u, loc=mu, scale=sigma)\n\n# Visualizzazione dell'istogramma dei campioni generati\nplt.hist(x, bins=50, density=True, alpha=0.6, color='g')\n\n# Sovrapposizione della funzione di densità di probabilità teorica\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\n\np = stats.norm.pdf(x, mu, sigma)\nplt.plot(x, p, 'k', linewidth=2)\ntitle = \"Istogramma dei campioni generati con la tecnica dell'inversione\"\nplt.title(title)\nplt.show()\n\n\n\n\n\n\n\n\nQuesto esempio illustra l’utilizzo della tecnica dell’inversione per generare campioni da una distribuzione normale utilizzando variabili casuali uniformi. Il processo è suddiviso in quattro passaggi:\n\nDefinizione della media μ e della deviazione standard σ della distribuzione normale desiderata.\nGenerazione di 10.000 numeri casuali uniformemente distribuiti nell’intervallo [0, 1].\nApplicazione dell’inversa della funzione di distribuzione cumulativa normale (tramite stats.norm.ppf) per trasformare i numeri casuali uniformi in campioni dalla distribuzione normale.\nCreazione di un istogramma dei campioni generati e confronto con la funzione di densità di probabilità teorica della distribuzione normale.\n\nQuesta tecnica dimostra come sia possibile generare campioni da una distribuzione specifica a partire da variabili casuali uniformi. La stessa metodologia può essere applicata ad altre distribuzioni, semplicemente modificando la funzione di distribuzione cumulativa e la sua inversa.\nSebbene siano disponibili funzioni di alto livello, come np.random.normal() in NumPy, che ottengono lo stesso risultato in modo più semplice (si veda sotto), la tecnica dell’inversione fornisce una comprensione più approfondita del processo matematico sottostante. Questa conoscenza può essere utile per estendere il metodo ad altre distribuzioni non supportate direttamente dalle librerie esistenti.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generazione di 10000 numeri casuali da una distribuzione normale\nmu = 0    # Media\nsigma = 1 # Deviazione standard\nsamples = np.random.normal(mu, sigma, 10000)\n\n\n# Visualizzazione dell'istogramma dei campioni generati\nplt.hist(samples, bins=50, density=True, alpha=0.6, color='g')\n\n# Sovrapposizione della funzione di densità di probabilità teorica\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = (1/(np.sqrt(2*np.pi*sigma**2))) * np.exp(-(x-mu)**2/(2*sigma**2))\nplt.plot(x, p, 'k', linewidth=2)\ntitle = \"Istogramma dei campioni generati con np.random.normal()\"\nplt.title(title)\nplt.show()",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a40_rng.html#commenti-e-considerazioni-finali",
    "href": "chapters/appendix/a40_rng.html#commenti-e-considerazioni-finali",
    "title": "Appendice N — Generazione di numeri casuali",
    "section": "N.9 Commenti e Considerazioni Finali",
    "text": "N.9 Commenti e Considerazioni Finali\nIn questo capitolo, abbiamo esaminato l’utilizzo della funzione rng = np.random.default_rng() per generare un campione di numeri pseudo-casuali da una distribuzione. Dopo aver inizializzato rng con rng = np.random.default_rng(RANDOM_SEED), possiamo generare campioni casuali da diverse distribuzioni di massa e di densità di probabilità:\n\nDistribuzione uniforme: rng.uniform(min, max, size)\nDistribuzione normale: rng.normal(loc, scale, size)\nDistribuzione t di Student: rng.standard_t(df, size)\nDistribuzione beta: rng.beta(alpha, beta, size)\nDistribuzione binomiale: rng.binomial(n, p, size)\n\nNei capitoli precedenti, nello specifico nei notebook {ref}discr_distr_notebook e {ref}cont-rv-distr-notebook, abbiamo invece approfondito l’utilizzo di varie funzioni della libreria scipy.stats per manipolare le distribuzioni di probabilità. In particolare, abbiamo illustrato come sia possibile utilizzare:\n\n.pdf per ottenere i valori della funzione di densità di probabilità o .pmf per ottenere i valori della distribuzione di massa di probabilità.\n.ppf per calcolare i quantili della distribuzione.\n.cdf per calcolare la probabilità associata a un valore specifico. Nel caso di una variabile casuale continua, questo corrisponde al valore della funzione di ripartizione, che rappresenta l’area sotto la curva di densità nella coda sinistra. Nel caso di una variabile casuale discreta, corrisponde alla somma delle probabilità dalla distribuzione di massa di probabilità dal valore minimo fino al valore specificato (incluso).\n\n\n\n\n\nRoger, E. (1987). Stan Ulam, John Von Neumann, and the Monte Carlo Method. Los Alamos Science, 15, 131–137.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>N</span>  <span class='chapter-title'>Generazione di numeri casuali</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html",
    "href": "chapters/appendix/a44_montecarlo.html",
    "title": "Appendice O — Simulazione Monte Carlo",
    "section": "",
    "text": "O.1 Il Metodo di Monte Carlo\nIl Metodo di Monte Carlo è una tecnica computazionale che utilizza la casualità per risolvere problemi complessi, evitando calcoli formali particolarmente complicati, come l’integrazione numerica o la soluzione di equazioni differenziali. Nato durante il Progetto Manhattan negli anni ’40, questo metodo prende il nome dal celebre casinò di Monte Carlo, in quanto basato su eventi casuali ripetuti. L’idea fu originariamente concepita da Stanislaw Ulam e sviluppata insieme a John von Neumann, come un modo per simulare problemi matematici complessi attraverso l’uso di numeri casuali.\nL’essenza del metodo risiede nella simulazione ripetuta di un fenomeno per ottenere informazioni quantitative su un sistema. Per esempio, se volessimo stimare l’area di una forma irregolare, potremmo inscriverla in un quadrato, lanciare un gran numero di puntine casualmente all’interno del quadrato e contare quante cadono all’interno della forma. Il rapporto tra il numero di puntine all’interno della forma e il totale ci fornisce una stima dell’area. Questo concetto riflette la semplicità del metodo Monte Carlo: utilizzare ripetizioni casuali per ottenere stime statistiche di un fenomeno.\nLa procedura del Metodo Monte Carlo può essere descritta nel modo seguente.\nIl metodo Monte Carlo ha molteplici applicazioni. Uno degli utilizzi più comuni del metodo Monte Carlo è l’approssimazione dell’integrale di una funzione, come nell’esempio dell’approssimazione dell’area di un cerchio inscrivendolo in un quadrato. Anche in ambiti come la teoria delle probabilità, il metodo si è dimostrato efficace, come mostrato nel celebre problema di Monty Hall. In questo contesto, la simulazione permette di stimare parametri come la media e la varianza di variabili casuali, aumentando la precisione con il crescere del numero di simulazioni, secondo la legge dei grandi numeri.\nConsideriamo ora una distribuzione continua \\(p(\\theta \\mid y)\\) con media \\(\\mu\\). Se possiamo generare campioni \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\) indipendenti da \\(p(\\theta \\mid y)\\), possiamo stimare il valore atteso teorico di \\(\\theta\\) attraverso la media campionaria \\(\\frac{1}{T} \\sum_{i=1}^T \\theta^{(t)}\\). Più è elevato il numero di campioni \\(T\\), maggiore sarà la precisione dell’approssimazione grazie alla Legge Forte dei Grandi Numeri. Allo stesso modo, possiamo stimare la probabilità che una variabile casuale \\(\\theta\\) cada in un intervallo specifico \\((l, u)\\) utilizzando la funzione indicatrice \\(I(l &lt; \\theta &lt; u)\\) e calcolando la proporzione di campioni che soddisfano questa condizione.\nSebbene il metodo Monte Carlo sia molto versatile e applicabile a una vasta gamma di problemi, presenta alcuni limiti. In particolare, la generazione di un numero sufficiente di campioni per ottenere stime accurate può richiedere un significativo sforzo computazionale, soprattutto in spazi ad alta dimensionalità. Inoltre, i risultati del metodo sono sempre affetti da un certo grado di incertezza, a causa della natura stessa della casualità.\nUn passo avanti per superare alcune di queste limitazioni è rappresentato dai metodi Markov Chain Monte Carlo (MCMC), che migliorano l’efficienza del campionamento da distribuzioni complesse e ad alta dimensionalità. Questi metodi, infatti, forniscono un framework per simulare da una vasta gamma di distribuzioni, anche quelle irregolari o multimodali, rendendo il campionamento Monte Carlo più praticabile in molte applicazioni avanzate.\nIn conclusione, il Metodo di Monte Carlo rappresenta una potente tecnica per la risoluzione di problemi complessi tramite simulazione casuale. Sebbene possa essere computazionalmente costoso e richieda molte simulazioni per ottenere risultati accurati, la sua flessibilità e applicabilità lo rendono uno strumento essenziale in molte discipline, inclusa la psicologia e la teoria delle probabilità. Con l’avvento di metodi come l’MCMC, le potenzialità del Monte Carlo continuano a crescere, rendendolo un pilastro della moderna analisi quantitativa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#il-metodo-di-monte-carlo",
    "href": "chapters/appendix/a44_montecarlo.html#il-metodo-di-monte-carlo",
    "title": "Appendice O — Simulazione Monte Carlo",
    "section": "",
    "text": "Definizione del problema: Il primo passo consiste nel formulare il problema in termini di un esperimento probabilistico. Ad esempio, per simulare il lancio di un dado, il problema diventa la generazione di un numero casuale compreso tra 1 e 6.\nGenerazione di numeri casuali: Sebbene i computer non possano generare numeri completamente casuali, utilizzano algoritmi che producono numeri pseudo-casuali, sufficientemente casuali per la maggior parte delle applicazioni pratiche.\nSimulazione: L’esperimento probabilistico viene ripetuto molte volte. Ogni ripetizione rappresenta una simulazione indipendente.\nAnalisi dei risultati: Una volta completate le simulazioni, si raccolgono i dati e si procede all’analisi statistica, calcolando medie, varianze e altre statistiche per ottenere stime del risultato cercato.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#stimare-π-con-il-metodo-monte-carlo",
    "href": "chapters/appendix/a44_montecarlo.html#stimare-π-con-il-metodo-monte-carlo",
    "title": "Appendice O — Simulazione Monte Carlo",
    "section": "O.2 Stimare π con il Metodo Monte Carlo",
    "text": "O.2 Stimare π con il Metodo Monte Carlo\nPer fare un esempio pratico del metodo Monte Carlo, immaginiamo di volere calcolare l’area di un cerchio. È un problema che ha una soluzione esatta, ma vediamo come possiamo risolverlo in modo approssimato usando il metodo Monte Carlo.\n\ndef in_circle(x, y, r):\n    \"\"\"\n    Checks if a point (x, y) is within a circle of radius r.\n    \"\"\"\n    distance = (x**2 + y**2) ** 0.5\n    return distance &lt;= r\n\n\ndef approx_pi(r, n):\n    \"\"\"\n    Approximates Pi using the Monte Carlo method.\n\n    Args:\n        r: Radius of the circle.\n        n: Number of points to simulate.\n\n    Returns:\n        Approximated value of Pi.\n    \"\"\"\n    xs, ys, cols = [], [], []\n    count = 0\n\n    for _ in range(n):\n        x = random.uniform(0, r)\n        y = random.uniform(0, r)\n        xs.append(x)\n        ys.append(y)\n\n        if in_circle(x, y, r):\n            count += 1\n            cols.append(\"orangered\")\n        else:\n            cols.append(\"teal\")\n\n    # Moltiplicando per 4, \"scaliamo\" la nostra stima da un quarto del cerchio\n    # a tutto il cerchio, permettendoci così di stimare il valore di π.\n    pi_appr = round(4 * count / n, 3)\n\n    # Plot the points\n    plt.figure(figsize=(6, 4))\n    plt.scatter(xs, ys, c=cols, s=20, alpha=0.5)\n    plt.title(\"Monte Carlo approximation of π = \" + str(pi_appr))\n    plt.annotate(\n        f\"Points inside circle: {count}/{n}\",\n        xy=(0.5, 0.9),\n        xycoords=\"axes fraction\",\n        ha=\"center\",\n    )\n    plt.annotate(\n        f\"Approximated π ≈ {pi_appr}\",\n        xy=(0.5, 0.85),\n        xycoords=\"axes fraction\",\n        ha=\"center\",\n    )\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n    plt.grid(True)\n    plt.axis(\"equal\")\n    plt.show()\n\n    return pi_appr\n\nL’algoritmo può essere compreso in modo intuitivo mediante l’analogia del bersaglio. Immagina di avere un bersaglio circolare su un quadrato. Vuoi stimare l’area del cerchio, ma non conosci la formula precisa. Come potresti fare?\nUn modo è lanciare dei dardi a caso sul quadrato. Alcuni dardi cadranno all’interno del cerchio, altri all’esterno. Se lanci molti dardi, il rapporto tra quelli che cadono all’interno del cerchio e il numero totale di dardi lanciati ti darà una stima del rapporto tra l’area del cerchio e l’area del quadrato.\nL’algoritmo in Python simula proprio questo processo:\n\nDefinizione del problema: Il cerchio è inscritto in un quadrato. Il raggio del cerchio è r.\nGenerazione di punti casuali: L’algoritmo genera un gran numero di punti all’interno del quadrato, in posizioni casuali. Ogni punto ha una coordinata x e una coordinata y.\nVerifica se il punto è all’interno del cerchio: Per ogni punto generato, viene calcolata la distanza dall’origine (il centro del cerchio). Se questa distanza è minore o uguale al raggio, il punto è all’interno del cerchio.\nConteggio dei punti: Viene contato il numero di punti che cadono all’interno del cerchio.\nCalcolo di Pi greco: Abbiamo calcolato la proporzione di punti che cadono all’interno di un quarto di cerchio rispetto all’area totale di un quarto di quadrato. Per ottenere l’area totale del cerchio rispetto all’area totale del quadrato, moltiplichiamo questa proporzione per 4. Sapendo che l’area di un cerchio è πr² e che l’area del quadrato è 4r², possiamo eguagliare le due proporzioni e ricavare: π ≈ 4 * (numero di punti nel cerchio) / (numero totale di punti).\nVisualizzazione: I punti vengono rappresentati graficamente per mostrare visivamente la distribuzione e l’approssimazione di π.\n\n\n# Example usage\nradius = 1\nnum_points = 50\nestimated_pi = approx_pi(radius, num_points)\nprint(f\"Estimated value of Pi with {num_points} points: {estimated_pi}\")\n\n\n\n\n\n\n\n\nEstimated value of Pi with 50 points: 3.68\n\n\n\n# Example usage\nnum_points = 500\nestimated_pi = approx_pi(radius, num_points)\nprint(f\"Estimated value of Pi with {num_points} points: {estimated_pi}\")\n\n\n\n\n\n\n\n\nEstimated value of Pi with 500 points: 3.136\n\n\n\n# Example usage\nnum_points = 5000\nestimated_pi = approx_pi(radius, num_points)\nprint(f\"Estimated value of Pi with {num_points} points: {estimated_pi}\")\n\n\n\n\n\n\n\n\nEstimated value of Pi with 5000 points: 3.142\n\n\nIl metodo Monte Carlo sfrutta la legge dei grandi numeri. La legge dei grandi numeri ci dice che, all’aumentare del numero di lanci (o di punti generati nel nostro caso), la proporzione di dardi che cadono nel cerchio si avvicina sempre di più alla proporzione tra le aree. Quindi, più punti generiamo, più precisa sarà la nostra stima di π.\nIn conclusione, abbiamo visto come, simulando un esperimento casuale, possiamo ottenere una stima approssimata di un valore preciso come π. Questo è solo un esempio delle potenzialità del metodo Monte Carlo, che trova applicazione in molti campi della scienza, inclusa la psicologia.\n\nO.2.1 Codice Stan\nEseguiamo ora la simulazione usando Stan.\ngenerated quantities {\n  real&lt;lower=-1, upper=1&gt; x = uniform_rng(-1, 1);\n  real&lt;lower=-1, upper=1&gt; y = uniform_rng(-1, 1);\n  int&lt;lower=0, upper=1&gt; inside = x^2 + y^2 &lt; 1;\n  real&lt;lower=0, upper=4&gt; pi = 4 * inside;\n}\n\nVariabili x e y:\n\nVengono generate casualmente e uniformemente nell’intervallo \\((-1, 1)\\). Questo significa che stiamo campionando punti all’interno di un quadrato di lato 2 centrato sull’origine.\n\nVariabile inside:\n\nÈ un indicatore che verifica se il punto \\((x, y)\\) cade all’interno del cerchio unitario. La condizione \\(x^2 + y^2 &lt; 1\\) è vera se il punto \\((x, y)\\) è all’interno del cerchio di raggio 1 centrato sull’origine, e falsa altrimenti.\nSe la condizione è vera, inside è impostato a 1, altrimenti a 0.\n\nVariabile pi:\n\npi viene calcolata come 4 volte il valore di inside.\n\n\nIl programma Stan genera punti casuali, verifica se cadono all’interno del cerchio e usa la proporzione di punti che cadono all’interno del cerchio per stimare \\(\\pi\\). Moltiplicando il valore indicatore per 4, otteniamo una stima di \\(\\pi\\) basata su ciascun punto generato. La stima finale di \\(\\pi\\) sarà la media di queste stime su molti punti campionati.\n\n\nO.2.2 Media Campionaria dell’Indicatore\nDopo aver generato un numero sufficiente di punti casuali e aver verificato quanti di essi cadono all’interno del cerchio, calcoliamo la media campionaria dell’indicatore inside. Questo indicatore è uguale a 1 se il punto è dentro il cerchio e a 0 se è fuori. La media di questi valori ci dà la proporzione dei punti che cadono dentro il cerchio.\nQuesta proporzione è una stima della probabilità che un punto casuale sia all’interno del cerchio. Moltiplicando questa proporzione per 4, otteniamo una stima di \\(\\pi\\).\nMatematicamente, possiamo scrivere questo processo come segue:\n\\[\n\\mathbb{E}[4 \\cdot \\textrm{I}(\\sqrt{X^2 + Y^2} \\leq 1)] = \\int_{-1}^1 \\int_{-1}^1 4 \\cdot \\textrm{I}(x^2 + y^2 &lt; 1) \\, \\textrm{d}x \\, \\textrm{d}y = \\pi,\n\\]\ndove \\(\\textrm{I}()\\) è l’indicatore che ritorna 1 se il suo argomento è vero e 0 altrimenti.\nIn altre parole, stiamo calcolando l’aspettativa di 4 volte l’indicatore che un punto casuale \\((x, y)\\) cade dentro il cerchio unitario. Questo valore atteso è uguale a \\(\\pi\\), il che ci permette di stimare \\(\\pi\\) usando i metodi Monte Carlo.\n\n\nO.2.3 Compilazione e Campionamento\nCompiliamo e poi campioniamo dal modello, prendendo un campione di dimensione \\(M = 10,000\\) estrazioni.\n\nM = 10_000\nmodel = CmdStanModel(stan_file=\"../../stan/monte-carlo-pi.stan\")\n\nsample = model.sample(\n    chains=1,\n    iter_warmup=1,\n    iter_sampling=M,\n    show_progress=False,\n    show_console=False,\n    seed=123,\n)\n\nx_draws = sample.stan_variable(\"x\")\ny_draws = sample.stan_variable(\"y\")\ninside_draws = sample.stan_variable(\"inside\")\npi_draws = sample.stan_variable(\"pi\")\n\ndf = pd.DataFrame({\"N\": 1000, \"x\": x_draws, \"y\": y_draws, \"inside\": inside_draws})\n\nplt.figure(figsize=(5, 5))\nplt.scatter(df[\"x\"], df[\"y\"], c=df[\"inside\"], cmap=\"coolwarm\", s=1)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.title(\"Monte Carlo Simulation of Pi Estimation\")\nplt.gca().set_aspect(\"equal\", adjustable=\"box\")\nplt.show()\n\n\n\n\n\n\n\n\nSuccessivamente, calcoliamo la media campionaria dell’indicatore dentro-il-cerchio, che produce una stima della probabilità che un punto sia dentro il cerchio:\n\nPr_is_inside = np.mean(inside_draws)\npi_hat = np.mean(pi_draws)\nprint(f\"Pr[Y is inside circle] = {Pr_is_inside:.3f};\")\nprint(f\"estimate for pi = {pi_hat:.3f}\")\n\nPr[Y is inside circle] = 0.786;\nestimate for pi = 3.144\n\n\nIl valore esatto di \\(\\pi\\) fino a tre cifre decimali è \\(3.142\\). Con il nostro metodo, ci avviciniamo a questo valore, ma non lo raggiungiamo esattamente, il che è tipico dei metodi Monte Carlo. Aumentando il numero di estrazioni, l’errore diminuisce. Teoricamente, con un numero sufficiente di estrazioni, possiamo ottenere qualsiasi precisione desiderata; tuttavia, in pratica, dobbiamo accontentarci di pochi decimali di accuratezza nelle nostre stime Monte Carlo. Questo di solito non è un problema, poiché l’incertezza statistica tende a dominare rispetto all’imprecisione numerica nella maggior parte delle applicazioni.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#integrazione-di-monte-carlo",
    "href": "chapters/appendix/a44_montecarlo.html#integrazione-di-monte-carlo",
    "title": "Appendice O — Simulazione Monte Carlo",
    "section": "O.3 Integrazione di Monte Carlo",
    "text": "O.3 Integrazione di Monte Carlo\nImmaginiamo di voler calcolare il valore atteso (la media) di una quantità che dipende da un parametro incerto, come la media di una popolazione. Se la distribuzione di probabilità di questo parametro è complessa o non ha una forma analitica semplice, calcolare l’integrale necessario per ottenere il valore atteso può essere molto difficile, se non impossibile.\nL’integrazione di Monte Carlo offre un’alternativa elegante a questo problema. Invece di calcolare l’integrale analiticamente, generiamo un gran numero di campioni casuali dal parametro di interesse, ognuno dei quali rappresenta una possibile realizzazione del parametro. Quindi, calcoliamo la media di questi campioni per ottenere una stima del valore atteso.\nFormalmente, supponiamo di voler calcolare il valore atteso posteriore di un parametro \\(\\theta\\) dato i dati osservati \\(x\\):\n\\[\n\\mathbb{E}(\\theta |x) = \\int \\theta p(\\theta|x)d\\theta ,\n\\]\ndove \\(p(\\theta \\mid x)\\) è la distribuzione di probabilità posteriore di \\(\\theta\\).\nL’integrazione di Monte Carlo ci permette di stimare questo valore atteso come:\n\\[\n\\hat{\\mathbb{E}} (\\theta |x) = \\frac{1}{M} \\sum_{m=1}^M \\theta^{(m)}, \\quad \\theta^{(m)} \\sim p(\\theta|x).\n\\]\nIn altre parole, generiamo \\(M\\) campioni \\(\\theta^{(1)}, ..., \\theta^{(M)}\\) dalla distribuzione posteriore e calcoliamo la media aritmetica di questi campioni.\nL’integrazione di Monte Carlo non si limita al calcolo del valore atteso. Possiamo utilizzarla per calcolare il valore atteso di qualsiasi funzione \\(g(\\theta)\\):\n\\[\n\\hat{\\mathbb{E}} (g(\\theta |x)) = \\frac{1}{M} \\sum_{m=1}^M g(\\theta^{(m)}), \\quad \\theta^{(m)} \\sim p(\\theta \\mid x).\n\\]\nLa funzione \\(g(\\theta)\\) è detta ordinabile perché possiamo calcolare il suo valore per ogni campione \\(\\theta^{(m)}\\) e poi ordinare i risultati.\nAd esempio, supponiamo di voler stimare la varianza posteriore di \\(\\theta\\). La varianza è definita come:\nVar(\\theta|x) = E[(\\theta - E[\\theta|x])^2 | x]\nPossiamo riscrivere questa espressione come:\nVar(\\theta|x) = E[g(\\theta) | x]\ndove \\(g(\\theta) = (\\theta - E[\\theta|x])^2\\). La funzione \\(g(\\theta)\\) è ordinabile: possiamo calcolare \\(g(\\theta^{(1)})\\), \\(g(\\theta^{(2)})\\), …, \\(g(\\theta^{(M)})\\) e poi calcolarne la media per ottenere una stima della varianza.\nPerché è utile?\nL’integrazione di Monte Carlo è uno strumento estremamente versatile perché ci permette di:\n\nCalcolare valori attesi: Di qualsiasi funzione della variabile casuale di interesse.\nStimare quantili: Come la mediana, i quartili, ecc.\nCalcolare probabilità: Ad esempio, la probabilità che un parametro cada in un certo intervallo.\n\nIn sintesi, l’integrazione di Monte Carlo è un metodo numerico potente per affrontare problemi di inferenza bayesiana quando le soluzioni analitiche sono difficili da ottenere. Grazie alla sua flessibilità, è ampiamente utilizzata in molti campi, inclusa la psicologia.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a44_montecarlo.html#importance-sampling",
    "href": "chapters/appendix/a44_montecarlo.html#importance-sampling",
    "title": "Appendice O — Simulazione Monte Carlo",
    "section": "O.4 Importance Sampling",
    "text": "O.4 Importance Sampling\nIl metodo che abbiamo discusso in precedenza si chiama naive Monte Carlo. Produce la risposta corretta, ma è molto inefficiente. Il metodo naive Monte Carlo genera punti casuali uniformemente all’interno di una regione. Tuttavia, in molti casi, siamo interessati a stimare grandezze relative a regioni dello spazio dei parametri dove la densità di probabilità è bassa. In queste situazioni, generando punti uniformemente, molti di essi cadranno in regioni che non ci interessano, riducendo l’efficienza della stima.\nL’importance sampling è una tecnica che permette di concentrare i campioni nelle regioni dello spazio dei parametri che sono più rilevanti per la stima che vogliamo ottenere. Invece di campionare da una distribuzione uniforme, si campiona da una distribuzione proposta, che dovrebbe essere scelta in modo da assegnare una probabilità maggiore alle regioni di interesse.\n\nO.4.1 Come Dunziona in Pratica?\n\nScegli una distribuzione proposta: Questa distribuzione dovrebbe essere simile alla distribuzione della quantità che si vuole stimare, ma più facile da campionare.\nCampiona: Genera punti casuali dalla distribuzione proposta.\nCorreggi il peso: Ogni punto campionato viene pesato in base al rapporto tra la densità della distribuzione target (quella che vogliamo stimare) e la densità della distribuzione proposta nel punto campionato.\nCalcola la stima: La stima finale viene ottenuta come media pesata dei valori della funzione da stimare nei punti campionati.\n\nVantaggi dell’importance sampling:\n\nMaggiore efficienza: Concentrando i campioni nelle regioni importanti, si riducono le varianze delle stime e si ottengono risultati più accurati con un numero minore di simulazioni.\nFlessibilità: Può essere applicato a una vasta gamma di problemi.\nAdattabilità: La distribuzione proposta può essere adattata durante la simulazione per migliorare ulteriormente l’efficienza.\n\nSvantaggi dell’importance sampling:\n\nScelta della distribuzione proposta: Una cattiva scelta della distribuzione proposta può portare a una stima peggiore.\nCalcolo dei pesi: Il calcolo dei pesi può essere computazionalmente costoso.\n\nIn conclusione, l’importance sampling è una tecnica usata per migliorare l’efficienza delle simulazioni Monte Carlo.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>O</span>  <span class='chapter-title'>Simulazione Monte Carlo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html",
    "href": "chapters/appendix/a46_stan.html",
    "title": "Appendice P — Linguaggio Stan",
    "section": "",
    "text": "P.1 Interfacce e pacchetti\nÈ possibile accedere al linguaggio Stan tramite diverse interfacce:\nInoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, sia in Python che in Linguaggio \\(\\mathsf{R}\\):",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#interfacce-e-pacchetti",
    "href": "chapters/appendix/a46_stan.html#interfacce-e-pacchetti",
    "title": "Appendice P — Linguaggio Stan",
    "section": "",
    "text": "CmdStanPy - integrazione con il linguaggio di programmazione Python;\nPyStan - integrazione con il linguaggio di programmazione Python;\nCmdStan - eseguibile da riga di comando,\nRStan - integrazione con il linguaggio \\(\\mathsf{R}\\);\nMatlabStan - integrazione con MATLAB;\nStan.jl - integrazione con il linguaggio di programmazione Julia;\nStataStan - integrazione con Stata.\nScalaStan - integrazione con Scala.\n\n\n\nArviz - ArviZ è una libreria Python per l’analisi esplorativa dei modelli bayesiani. Essa funge da strumento indipendente dal backend per diagnosticare e visualizzare l’inferenza bayesiana.\nshinystan - interfaccia grafica interattiva per l’analisi della distribuzione a posteriori e le diagnostiche MCMC in \\(\\mathsf{R}\\);\nbayesplot - insieme di funzioni utilizzabili per creare grafici relativi all’analisi della distribuzione a posteriori, ai test del modello e alle diagnostiche MCMC in \\(\\mathsf{R}\\);\nbrms - fornisce un’ampia gamma di modelli lineari e non lineari specificando i modelli statistici mediante la sintassi usata in \\(\\mathsf{R}\\);\nrstanarm - fornisce un sostituto per i modelli frequentisti forniti da base \\(\\mathsf{R}\\) e lme4 utilizzando la sintassi usata in \\(\\mathsf{R}\\) per la specificazione dei modelli statistici;\ncmdstanr - un’interfaccia \\(\\mathsf{R}\\) per CmdStan.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#interfaccia-cmdstanpy",
    "href": "chapters/appendix/a46_stan.html#interfaccia-cmdstanpy",
    "title": "Appendice P — Linguaggio Stan",
    "section": "P.2 Interfaccia cmdstanpy",
    "text": "P.2 Interfaccia cmdstanpy\nNegli esempi di questa dispensa verrà utilizzata l’interfaccia cmdstanpy. CmdStanPy è una interfaccia di Stan per gli utenti Python, che fornisce gli oggetti e le funzioni necessarie per condurre l’inferenza bayesiana su un modello di probabilità e dei dati. Essa racchiude l’interfaccia a riga di comando di CmdStan in un piccolo insieme di classi Python, le quali offrono metodi per analizzare e gestire l’insieme risultante di modello, dati e stime a posteriori.\nPer l’installazione di CmdStanPy, si segua il link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a46_stan.html#codice-stan",
    "href": "chapters/appendix/a46_stan.html#codice-stan",
    "title": "Appendice P — Linguaggio Stan",
    "section": "P.3 Codice Stan",
    "text": "P.3 Codice Stan\nStan consente agli utenti di definire un modello bayesiano attraverso il linguaggio Stan. Questo modello, di solito, viene salvato in un file di testo con estensione .stan.\nIl codice Stan deve poi essere compilato. Il processo di compilazione di un modello in Stan avviene in due fasi: innanzitutto, Stan traduce il modello dal formato .stan in codice C++, il quale viene successivamente compilato in codice macchina.\nDopo la compilazione del modello (ovvero, dopo che il codice macchina è stato generato), l’utente può utilizzare l’interfaccia prescelta (per esempio, CmdStan) per campionare la distribuzione definita dal modello e per eseguire altri calcoli correlati al modello stesso.\nIl codice Stan è costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono:\nfunctions {\n  // ... function declarations and definitions ...\n}\ndata {\n  // ... declarations ...\n}\ntransformed data {\n   // ... declarations ... statements ...\n}\nparameters {\n   // ... declarations ...\n}\ntransformed parameters {\n   // ... declarations ... statements ...\n}\nmodel {\n   // ... declarations ... statements ...\n}\ngenerated quantities {\n   // ... declarations ... statements ...\n}\nQuesti blocchi devono sempre essere in questo ordine, ma non tutti i programmi Stan richiedono tutti i blocchi.\n\nP.3.1 Blocco data\nNel blocco data vengono specificate le variabili di input utilizzate nel modello Stan. Per ogni variabile, è necessario definire il tipo di dato, le dimensioni e, se necessario, applicare vincoli sui valori che tali variabili possono assumere.\nEsempio di blocco data:\ndata {\n  int&lt;lower=0&gt; ntrials; // Numero di prove\n  int&lt;lower=0&gt; y;       // Successi osservati\n  real&lt;lower=0&gt; alpha_prior; // Parametro alpha per il prior Beta\n  real&lt;lower=0&gt; beta_prior;  // Parametro beta per il prior Beta\n}\nStan offre diversi tipi di dati per le variabili, tra cui:\n\nint: Rappresenta numeri interi senza parte decimale. Esempio: int N = 10;.\nreal: Rappresenta numeri reali, inclusi i decimali. Esempio: real pi = 3.14159;.\nvector: Un vettore unidimensionale di numeri reali. Esempio: vector[3] y;.\nmatrix: Una matrice bidimensionale di numeri reali. Esempio: matrix[2,3] A;.\narray: Tipo generico per contenere elementi di qualsiasi tipo, incluso array di array. Esempio: array[3] int my_array;.\n\n\nP.3.1.1 Dichiarazione di dimensioni e applicazione di vincoli\nQuando si dichiara una variabile, è essenziale specificarne le dimensioni e, se appropriato, applicare vincoli sui valori che può assumere. I vincoli più comuni sono:\n\nlower: Specifica il valore minimo.\nupper: Specifica il valore massimo.\n\nEsempio di variabile reale compresa tra 0 e 1:\nreal&lt;lower=0, upper=1&gt; x;\n\n\n\nP.3.2 Tipi di Dati in Stan\n\nP.3.2.1 Interi\nLe variabili intere vengono dichiarate con la parola chiave int. Per dichiarare un intero positivo, si aggiunge un vincolo inferiore:\nint&lt;lower=1&gt; N;\n\n\nP.3.2.2 Reali\nLe variabili reali, dichiarate con real, possono essere vincolate allo stesso modo degli interi:\nreal&lt;lower=0&gt; sigma;\n\n\nP.3.2.3 Tipi di Dati Vettoriali e Matriciali\n\nVector: Rappresenta una sequenza unidimensionale di numeri reali. Esempio: vector[3] u;.\nMatrix: Una matrice bidimensionale di numeri reali. Esempio: matrix[3, 3] A;.\n\nLe variabili vettoriali e matriciali possono contenere solo valori reali, non interi, e sono trattate come strutture dati distinte dagli array.\n\nP.3.2.3.1 Vettori\nI vettori in Stan sono vettori colonna. Esempio di vettore reale di lunghezza 3:\nvector[3] u;\n\n\nP.3.2.3.2 Matrici\nLe matrici vengono dichiarate specificando il numero di righe e colonne:\nmatrix[3, 3] A;\nmatrix[M, N] B;\nLe dimensioni devono essere definite come variabili intere nel blocco dati.\n\n\n\nP.3.2.4 Array\nGli array possono contenere variabili di qualsiasi tipo (inclusi array di array). Ad esempio, un array di interi:\narray[5] int n;\nGli array multidimensionali sono array di array. Un array bidimensionale di interi si dichiara così:\narray[3, 4] int a;\n\n\n\nP.3.3 Indicizzazione e Miscelazione dei Tipi\n\nStan indicizza vettori, matrici e array a partire da 1.\nNon è possibile assegnare tra loro variabili di tipo array, vettore o matrice, anche se hanno le stesse dimensioni.\n\n\n\nP.3.4 Dizionari in CmdStanPy\nQuando si forniscono i dati a Stan tramite CmdStanPy, questi devono essere organizzati in un dizionario Python. Ogni chiave del dizionario corrisponde a una variabile del blocco data di Stan e il valore associato rappresenta i dati reali.\nEsempio di dizionario:\ndata = {\n  \"ntrials\": 100,\n  \"y\": 45,\n  \"alpha_prior\": 2.0,\n  \"beta_prior\": 5.0\n}\nIn questo modo, i dati sono mappati correttamente alle variabili del modello Stan.\nIn sintesi, in Stan ogni variabile deve avere un tipo di dato ben definito e, ove appropriato, è possibile applicare vincoli per garantire la validità e l’efficienza del modello. I tipi di dati principali sono interi, reali, vettori, matrici e array, ciascuno con caratteristiche specifiche per il tipo di dati e le operazioni consentite.\n\n\nP.3.5 Blocco parameters\nI parametri da stimare sono definiti all’interno del blocco parameters.\nAd esempio, consideriamo il seguente codice, dove viene dichiarata la variabile theta per rappresentare una probabilità. Si notino i vincoli che specificano che i valori possibili per theta devono essere contenuti nell’intervallo [0, 1].\nparameters {\n  real&lt;lower=0, upper=1&gt; theta; // Parametro stimato, limitato tra 0 e 1\n}\n\n\nP.3.6 Blocco model\nLa sezione model è il cuore di un modello Stan, dove si specificano le relazioni statistiche tra i dati osservati e i parametri incogniti. In questa sezione, si definisce la verosimiglianza, ovvero la distribuzione di probabilità dei dati condizionata dai parametri, e si assegnano le distribuzioni a priori ai parametri stessi.\n\nLa verosimiglianza modella il processo generativo dei dati. Essa descrive come i dati osservati si sarebbero potuti generare a partire da specifici valori dei parametri. In Stan, la verosimiglianza viene specificata utilizzando il simbolo ~ (tilde).\nLe distribuzioni a priori riflettono le nostre conoscenze o credenze a priori sui parametri prima di osservare i dati. Esse agiscono come regolarizzatori, prevenendo sovrastima o sottostima dei parametri.\n\nAd esempio, nel codice seguente\nmodel {\n  // Modello Beta-Binomiale\n  theta ~ beta(alpha_prior, beta_prior); // Distribuzione a priori di theta\n  y ~ binomial(ntrials, theta); // Verosimiglianza binomiale\n}\n\ntheta ~ beta(alpha_prior, beta_prior);: Questa riga assegna una distribuzione a priori Beta al parametro theta, con parametri di forma alpha_prior e beta_prior.\ny ~ binomial(ntrials, theta);: Questa riga specifica che i dati osservati y seguono una distribuzione binomiale con ntrials prove e probabilità di successo theta.\n\nIn generale, possiamo leggere il simbolo ~ come “è distribuito come”. Pertanto, l’esempio sopra può essere scritto anche come:\n\\[\np(\\theta \\mid \\alpha_p, \\beta_p) = \\text{Beta}(\\alpha_p, \\beta_p)\n\\]\ne\n\\[\np(y \\mid \\theta) = \\text{Binomiale}(y \\mid n, \\theta).\n\\]\nLa notazione compatta usata da Stan facilita la definizione delle relazioni probabilistiche nel modello.\nIn assenza di specifiche, Stan assume una distribuzione non informativa, ovvero una distribuzione a priori uniforme tra meno infinito e più infinito. Per ulteriori raccomandazioni sulle scelte delle distribuzioni a priori, è possibile consultare questo link.\nIn sintesi, la sezione model definisce il modello statistico completo, combinando la nostra conoscenza a priori sui parametri (attraverso le distribuzioni a priori) con le informazioni contenute nei dati (attraverso la verosimiglianza). Stan utilizza poi tecniche di inferenza Bayesiana per stimare i valori più probabili dei parametri alla luce dei dati osservati.\n\n\nP.3.7 Blocchi opzionali\nCi sono inoltre tre blocchi opzionali:\n\nIl blocco transformed data consente il pre-processing dei dati. È possibile trasformare i parametri del modello; solitamente ciò viene fatto nel caso dei modelli più avanzati per consentire un campionamento MCMC più efficiente.\nIl blocco transformed parameters consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.\nIl blocco generated quantities consente il post-processing riguardante qualsiasi quantità che non fa parte del modello ma può essere calcolata a partire dai parametri del modello, per ogni iterazione dell’algoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.\n\n\n\nP.3.8 Sintassi\nIl codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo data e lo si assegni a qualcos’altro. I punti e virgola non sono invece richiesti all’inizio di un ciclo o di un’istruzione condizionale, dove non viene assegnato nulla.\nIn Stan, qualsiasi stringa che segue il marcatore // denota un commento e viene ignorata dal programma. Una descrizione dettagliata della sintassi del linguaggio Stan è disponibile al seguente link.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>P</span>  <span class='chapter-title'>Linguaggio Stan</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html",
    "href": "chapters/appendix/a47_first_order_markov.html",
    "title": "Appendice Q — Catene di Markov",
    "section": "",
    "text": "Q.1 Classificazione degli Stati\nConsideriamo ora la terminologia usata per descrivere le varie caratteristiche di una catena di Markov.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "href": "chapters/appendix/a47_first_order_markov.html#classificazione-degli-stati",
    "title": "Appendice Q — Catene di Markov",
    "section": "",
    "text": "Q.1.1 Catene di Markov Irriducibili\nUna catena di Markov è detta irriducibile se, per qualsiasi coppia di stati \\(i\\) e \\(j\\), esiste una probabilità positiva di passare dallo stato \\(i\\) allo stato \\(j\\) in un numero finito di passi. In altre parole, una catena irriducibile non ha stati isolati: ogni stato è raggiungibile da qualsiasi altro stato.\n\n\nQ.1.2 Stati Ricorrenti\nUno stato \\(i\\) di una catena di Markov si dice ricorrente se, partendo da \\(i\\), la probabilità di ritornarvi è uguale a 1. Questo implica che una volta raggiunto lo stato \\(i\\), è garantito che la catena tornerà in \\(i\\) prima o poi. Gli stati ricorrenti possono essere ulteriormente classificati come:\n\nPositivamente ricorrenti: uno stato è positivamente ricorrente se il tempo medio atteso per ritornare in quello stato, partendo da esso, è finito.\nNullamente ricorrenti: uno stato è nullamente ricorrente se il tempo medio atteso per ritornare in quello stato è infinito.\nRicorrenti di Harris: sono stati ricorrenti che vengono visitati infinite volte quando il tempo tende all’infinito, garantendo una certa frequenza di visita.\n\n\n\nQ.1.3 Aperiodicità\nUno stato \\(i\\) si dice aperiodico se il massimo comun divisore dei tempi di ritorno in \\(i\\) è 1. In altre parole, uno stato è aperiodico se non esiste un ciclo deterministico che vincola i tempi in cui la catena può ritornare in quello stato. Una catena di Markov è aperiodica se tutti i suoi stati sono aperiodici. L’aperiodicità evita che la catena rimanga bloccata in una sequenza ciclica fissa, permettendo un comportamento più variegato nel tempo.\n\n\nQ.1.4 Stazionarietà\nNella teoria delle catene di Markov, una distribuzione stazionaria \\(\\pi\\) è una distribuzione di probabilità sugli stati tale che, se la catena parte con questa distribuzione iniziale, la distribuzione delle probabilità rimane invariata nel tempo. Matematicamente, se \\(\\pi\\) è la distribuzione stazionaria, allora \\(\\pi P = \\pi\\), dove \\(P\\) è la matrice di transizione della catena di Markov. La stazionarietà è fondamentale per analizzare il comportamento a lungo termine della catena, poiché una volta raggiunta, la distribuzione di probabilità sugli stati rimane costante.\n\n\nQ.1.5 Ergodicità\nUna catena di Markov si dice ergodica se è irriducibile e aperiodica, e tutti i suoi stati sono positivamente ricorrenti. Questo implica che la catena, nel lungo termine, visita tutti gli stati secondo una distribuzione di probabilità che diventa stabile (stazionaria) e non dipende dallo stato iniziale. La proprietà di ergodicità è cruciale in quanto garantisce che le medie temporali di una funzione sugli stati della catena convergono alle medie rispetto alla distribuzione stazionaria.\n\n\nQ.1.6 Convergenza\nLa convergenza di una catena di Markov si riferisce al processo mediante il quale la distribuzione di probabilità degli stati si avvicina alla distribuzione stazionaria \\(\\pi\\) man mano che il numero di passi \\(n\\) tende all’infinito. In altre parole, indipendentemente dalla distribuzione iniziale degli stati, la distribuzione della catena dopo un lungo periodo di tempo sarà vicina a \\(\\pi\\). Questo concetto è strettamente legato alla stazionarietà, poiché la convergenza descrive il percorso verso l’equilibrio, mentre la stazionarietà rappresenta lo stato di equilibrio raggiunto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a47_first_order_markov.html#estensioni-del-modello-di-markov",
    "href": "chapters/appendix/a47_first_order_markov.html#estensioni-del-modello-di-markov",
    "title": "Appendice Q — Catene di Markov",
    "section": "Q.2 Estensioni del modello di Markov",
    "text": "Q.2 Estensioni del modello di Markov\nOltre al modello di base, esistono diverse estensioni del processo di Markov che aumentano la sua capacità di rappresentare situazioni più complesse.\n\nQ.2.1 Modello di Markov misto\nUn’estensione comune del modello di Markov è il modello di Markov misto (Mixture Markov model, MMM), che considera la possibilità che una popolazione sia composta da sottogruppi distinti (cluster) con proprie probabilità di transizione. Ad esempio, possiamo immaginare di dividere una popolazione studentesca in due gruppi: quelli con alte prestazioni e quelli con basse prestazioni. Ogni gruppo ha una propria matrice di transizione che descrive la probabilità di rimanere o cambiare stato. Questo approccio permette di identificare sottogruppi latenti all’interno della popolazione e può essere utilizzato per raggruppare dati sequenziali in base a modelli di comportamento simili.\n\n\nQ.2.2 Modello di Markov nascosto\nUn’altra estensione utile è il modello di Markov nascosto (Hidden Markov model, HMM), utilizzato quando lo stato di interesse non può essere osservato direttamente o quando vi è un errore di misurazione nelle osservazioni. In un HMM, la catena di Markov opera a livello di stati nascosti, che generano o emettono stati osservati con diverse probabilità. Ad esempio, consideriamo l’abilità di uno studente come uno stato nascosto e il suo successo scolastico come uno stato osservato. Non possiamo misurare direttamente la vera abilità dello studente, ma possiamo stimarla dai punteggi dei test, che rappresentano le emissioni del loro stato di abilità. Questi modelli, noti come modelli di Markov nascosti misti (Mixture hidden Markov models, MHMM), combinano l’idea di cluster tempo-costanti con stati nascosti variabili nel tempo, permettendo di modellare popolazioni complesse con sottogruppi che si comportano in modo diverso nel tempo.\n\n\nQ.2.3 Sommario\nUna catena di Markov è una sequenza di variabili aleatorie \\(X_0, X_1, X_2, \\ldots\\) che soddisfa la cosiddetta proprietà di Markov. Questa proprietà stabilisce che, dato lo stato attuale della catena, il futuro è indipendente dal passato. Formalmente, questa proprietà si esprime come:\n\\[\nP(X_{n+1} = j \\mid X_n = i, X_{n-1} = i_{n-1}, \\ldots, X_0 = i_0) = P(X_{n+1} = j \\mid X_n = i) = q_{ij},\n\\]\ndove \\(q_{ij}\\) rappresenta la probabilità di passare dallo stato \\(i\\) allo stato \\(j\\) in un singolo passo. Queste probabilità di transizione sono organizzate in una matrice di transizione \\(Q = (q_{ij})\\), in cui ogni riga corrisponde a una distribuzione di probabilità condizionata sui possibili stati futuri dato l’attuale stato della catena.\nLa distribuzione di probabilità degli stati della catena dopo \\(n\\) passi può essere calcolata moltiplicando la matrice di transizione \\(Q\\) elevata alla potenza \\(n\\) per il vettore di probabilità iniziale \\(s\\), che descrive la distribuzione di probabilità degli stati al tempo \\(0\\). In simboli, questo è rappresentato da \\(sQ^n\\), che fornisce la distribuzione di probabilità marginale degli stati dopo \\(n\\) passi.\nGli stati di una catena di Markov possono essere classificati come ricorrenti o transitori. Uno stato è ricorrente se la catena torna a questo stato ripetutamente nel tempo; è transitorio se la catena potrebbe lasciare questo stato per non ritornarvi mai più. Gli stati possono anche avere un periodo associato, definito come il massimo comun divisore dei numeri di passi necessari per ritornare allo stato stesso. Una catena di Markov è detta irriducibile se è possibile raggiungere qualsiasi stato da qualsiasi altro stato in un numero finito di passi, ed è aperiodica se ogni stato ha periodo 1.\nUna distribuzione stazionaria di una catena di Markov è una distribuzione di probabilità che rimane invariata nel tempo. Se la catena inizia con questa distribuzione, continuerà a mantenerla in ogni passo successivo. Questa condizione si esprime matematicamente come \\(sQ = s\\), dove \\(s\\) è il vettore di probabilità stazionaria e \\(Q\\) è la matrice di transizione. Per una catena di Markov finita che è irriducibile e aperiodica, esiste una distribuzione stazionaria unica verso la quale la catena converge indipendentemente dalla distribuzione iniziale.\nUn concetto importante nelle catene di Markov è quello di reversibilità. Una catena di Markov è detta reversibile se esiste una distribuzione di probabilità \\(s\\) tale che, per ogni coppia di stati \\(i\\) e \\(j\\), la condizione di reversibilità \\(s_i q_{ij} = s_j q_{ji}\\) sia soddisfatta. Questa condizione garantisce che \\(s\\) sia una distribuzione stazionaria per la catena. Le catene di Markov reversibili sono particolarmente utili in applicazioni pratiche come gli algoritmi di simulazione Monte Carlo, ad esempio l’algoritmo di Metropolis-Hastings, poiché permettono di progettare catene che convergono rapidamente alla distribuzione di probabilità desiderata.\n\n\nQ.2.4 Letteratura\nI metodi markoviani sono stati ampiamente utilizzati in vari ambiti della psicologia e dell’educazione. Una delle applicazioni più comuni di questi metodi è il clustering dei dati sequenziali (Törmänen et al. (2022); Törmänen et al. (2023); Fincham et al. (2018)). Ad esempio, i modelli nascosti di Markov (HMM) sono stati utilizzati per raggruppare le sequenze di dati tracciati da sistemi di gestione dell’apprendimento (LMS) degli studenti, al fine di identificare i loro schemi di attività, ovvero le tattiche e strategie di apprendimento (Fincham et al. (2018)). Un uso molto diffuso dei modelli di Markov di primo ordine è quello di mappare le transizioni degli studenti tra diverse attività di apprendimento. Per esempio, Matcha et al. (2020) ha utilizzato modelli di Markov di primo ordine per studiare i processi di transizione degli studenti tra diverse strategie di apprendimento. Altri usi includono lo studio delle transizioni tra diverse strategie di scrittura accademica (Peeters et al. (2020)), tra eventi di apprendimento autoregolato (Lim et al. (2023)), o all’interno di contesti di apprendimento collaborativo (Saqr & López-Pernas (2023)). Esempi più specifici nell’ambito psicologico comprendono lo studio delle influenze reciproche tra stati affettivi (Cipresso et al. (2023)) e l’analisi degli effetti psicologici che dipendono dal tempo nelle sequenze di decision-making (Gunawan et al. (2022)).\n\n\nQ.2.5 Stima dei Parametri del Modello\nI parametri di un modello di Markov, come le probabilità iniziali degli stati e le probabilità di transizione tra stati, possono essere stimati a partire dai dati utilizzando diversi metodi statistici. In questo corso, ci concentreremo sulla stima bayesiana utilizzando il software Stan, che offre una grande flessibilità nella definizione dei modelli e permette di ottenere stime precise.\nPer chiarire meglio, consideriamo l’esempio di un processo di Markov di primo ordine implementato in Stan. Immaginiamo di voler modellare un sistema meteorologico, come abbiamo discusso in precedenza. In questo contesto, potremmo voler stimare le probabilità iniziali di condizioni meteorologiche specifiche e le probabilità di transizione che descrivono come il tempo potrebbe cambiare da un giorno all’altro.\ndata {\n  int&lt;lower=1&gt; N;           // Numero di osservazioni\n  int&lt;lower=1&gt; K;           // Numero di stati possibili (3 per Soleggiato, Piovoso, Nebbioso)\n  int&lt;lower=1, upper=K&gt; y[N]; // Sequenza di osservazioni (stati)\n}\n\nparameters {\n  simplex[K] P[K]; // Matrice di transizione delle probabilità\n}\n\nmodel {\n  for (n in 2:N) {\n    y[n] ~ categorical(P[y[n-1]]);\n  }\n}\nIn questo modello, usiamo la distribuzione categorical() per modellare le transizioni tra i tre stati meteorologici possibili.\nConsideriamo ora una situazione ancora più semplice, come quella discussa nel Capitolo 104. In questo secondo caso, abbiamo una sequenza di prove con solo due stati: prova prova corretta (0) e prova sbagliata (1). Il nostro interesse è la prestazione post-errore. Questo scenario si presta naturalmente all’uso della distribuzione bernoulli().\ndata {\n  int&lt;lower=1&gt; N;           // Numero di prove\n  int&lt;lower=0, upper=1&gt; y[N]; // Sequenza di risultati (0 = corretto, 1 = errore)\n}\n\nparameters {\n  real&lt;lower=0, upper=1&gt; p_error_given_correct;\n  real&lt;lower=0, upper=1&gt; p_error_given_error;\n}\n\nmodel {\n  for (n in 2:N) {\n    if (y[n - 1] == 1) {\n      y[n] ~ bernoulli(p_error_given_error);\n    } else {\n      y[n] ~ bernoulli(p_error_given_correct);\n    }\n  }\n}\nIn questo modello:\n\np_error_given_correct rappresenta la probabilità di errore dopo una prova corretta.\np_error_given_error rappresenta la probabilità di errore dopo un errore precedente.\n\nMentre nel modello Meteo avevamo tre stati (Soleggiato, Piovoso, Nebbioso), nel caso del modello Post-Errore abbiamo solo due stati (Corretto, Errore). Ciò porta ad una differenza tra le funzioni di verosimiglianza che vengono utilizzate:\n\nModello Meteo: categorical();\nModello Post-Errore: bernoulli().\n\nDi conseguenza, la parametrizzazione dei modelli cambia:\n\nModello Meteo: Matrice di transizione completa (simplex[K] P[K]);\nModello Post-Errore: Due probabilità di transizione (p_error_given_correct, p_error_given_error)\n\nIn conclusione, il processo di Markov di primo ordine è uno strumento potente per modellare sequenze di eventi con memoria limitata. L’implementazione in Stan permette di effettuare inferenze su questi modelli, sia in contesti con molteplici stati (come le previsioni meteo) sia in scenari binari (come l’analisi della prestazione post-errore).\n\n\n\n\nCipresso, P., Borghesi, F., & Chirico, A. (2023). Affects affect affects: A Markov chain. Frontiers in Psychology, 14, 1162655.\n\n\nFincham, E., Gašević, D., Jovanović, J., & Pardo, A. (2018). From study tactics to learning strategies: An analytical method for extracting interpretable representations. IEEE Transactions on Learning Technologies, 12(1), 59–72.\n\n\nGunawan, D., Hawkins, G. E., Kohn, R., Tran, M.-N., & Brown, S. D. (2022). Time-evolving psychological processes over repeated decisions. Psychological Review, 129(3), 438–456.\n\n\nLim, L., Bannert, M., Graaf, J. van der, Singh, S., Fan, Y., Surendrannair, S., Rakovic, M., Molenaar, I., Moore, J., & Gašević, D. (2023). Effects of real-time analytics-based personalized scaffolds on students’ self-regulated learning. Computers in Human Behavior, 139, 107547.\n\n\nMatcha, W., Gasevic, D., Jovanovic, J., Pardo, A., Lim, L., Maldonado-Mahauad, J., Gentili, S., Pérez-Sanagustı́n, M., Tsai, Y.-S., et al. (2020). Analytics of Learning Strategies: Role of Course Design and Delivery Modality Authors. Journal of Learning Analytics, 7(2), 45–71.\n\n\nPeeters, W., Saqr, M., & Viberg, O. (2020). Applying learning analytics to map students’ self-regulated learning tactics in an academic writing course. Proceedings of the 28th International Conference on Computers in Education, 1, 245–254.\n\n\nSaqr, M., & López-Pernas, S. (2023). The temporal dynamics of online problem-based learning: Why and when sequence matters. International Journal of Computer-Supported Collaborative Learning, 18(1), 11–37.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2022). A person-centered approach to study students’ socio-emotional interaction profiles and regulation of collaborative learning. Frontiers in Education, 7, 866612.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S. (2023). Affective states and regulation of learning during socio-emotional interactions in secondary school collaborative groups. British Journal of Educational Psychology, 93, 48–70.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>Q</span>  <span class='chapter-title'>Catene di Markov</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a48_hidden_markov_processes.html",
    "href": "chapters/appendix/a48_hidden_markov_processes.html",
    "title": "Appendice R — Processi di Markov Nascosti",
    "section": "",
    "text": "R.1 Introduzione\nMentre i processi di Markov di primo ordine forniscono un potente strumento per modellare fenomeni in cui il futuro dipende solo dal presente e non dal passato, ci sono situazioni in cui lo stato del sistema non è direttamente osservabile. In tali casi, possiamo utilizzare un’estensione del modello di Markov nota come modello di Markov nascosto o Hidden Markov Model (HMM).\nUn HMM è un modello statistico in cui il sistema è rappresentato da una sequenza di stati nascosti che seguono un processo di Markov di primo ordine. A differenza dei modelli di Markov tradizionali, però, gli stati stessi non sono osservabili direttamente. Invece, ad ogni stato nascosto corrisponde una variabile osservata, o “emissione”, che è una manifestazione indiretta dello stato nascosto.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>  <span class='chapter-title'>Processi di Markov Nascosti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a48_hidden_markov_processes.html#introduzione",
    "href": "chapters/appendix/a48_hidden_markov_processes.html#introduzione",
    "title": "Appendice R — Processi di Markov Nascosti",
    "section": "",
    "text": "R.1.1 Definizione Formale degli HMM\nConsideriamo gli stati latenti, che rappresentano gli stati dell’umore che possono essere inferiti dai pattern di risposta dei pazienti con disturbo bipolare attraverso item maniacali e depressivi. Un modello di Markov nascosto può essere formalmente definito dai seguenti componenti:\n\nStati Nascosti (\\(S\\)): Un insieme di stati nascosti \\(S = \\{\\text{neutro}, \\text{elevato}, \\text{misto}, \\text{abbassato}\\}\\), dove ogni stato rappresenta una condizione latente del sistema, che non è direttamente osservabile. Questi stati latenti corrispondono a diverse configurazioni dell’umore dei pazienti.\nOsservazioni (\\(O\\)): Un insieme di osservazioni \\(O = \\{O_1, O_2, ..., O_M\\}\\), in cui ogni osservazione \\(O_j\\) rappresenta un evento misurabile o un dato osservabile, che viene generato in base allo stato nascosto del sistema. Le osservazioni sono correlate agli item maniacali e depressivi riportati dai pazienti.\nProbabilità di Transizione (\\(A\\)): Una matrice di probabilità di transizione \\(A = [a_{ij}]\\), in cui ogni elemento \\(a_{ij} = P(S_{t+1} = j \\mid S_t = i)\\) rappresenta la probabilità di passare dallo stato nascosto \\(S_i\\) allo stato nascosto \\(S_j\\) in un singolo passo temporale. Questa matrice descrive la dinamica del cambiamento tra stati dell’umore.\nProbabilità di Emissione (\\(B\\)): Una matrice di probabilità di emissione \\(B = [b_j(k)]\\), in cui ogni elemento \\(b_j(k) = P(O_t = k \\mid S_t = j)\\) rappresenta la probabilità che l’osservazione \\(O_k\\) venga generata quando il sistema è nello stato nascosto \\(S_j\\). Questa matrice connette gli stati latenti con le osservazioni osservabili, modellando come gli stati nascosti influenzano i dati misurati.\nProbabilità Iniziale (\\(\\pi\\)): Un vettore di probabilità iniziali \\(\\pi = [\\pi_i]\\), dove ogni elemento \\(\\pi_i = P(S_1 = i)\\) rappresenta la probabilità che il sistema inizi nello stato nascosto \\(S_i\\). Questo vettore definisce la distribuzione di probabilità sugli stati nascosti all’inizio del processo di Markov.\n\n\n\nR.1.2 Applicazione degli HMM ai Disturbi Bipolari\nPer continuare l’esempio precedente del disturbo bipolare, un HMM può essere utilizzato per modellare le fluttuazioni dell’umore dei pazienti nel tempo. Consideriamo lo studio di Mildiner Moraga et al. (2024) che esplora l’uso di un HMM per identificare quattro stati dell’umore nei pazienti con disturbo bipolare: neutro, elevato, misto e abbassato. Questi stati sono derivati dai dati raccolti attraverso valutazioni momentanee ecologiche (EMA) intensivi, effettuate più volte al giorno.\n\nStato Neutro: Caratterizzato da punteggi bassi sia sugli item maniacali che depressivi del questionario EMA, rappresentando uno stato di equilibrio emotivo.\nStato Elevato: Definito da punteggi alti sugli item maniacali e bassi sugli item depressivi, riflettendo un umore elevato o maniacale.\nStato Misto: Presenta una combinazione di sintomi maniacali e depressivi, con punteggi variabili su entrambi i tipi di item.\nStato Abbassato: Contraddistinto da punteggi alti sugli item depressivi e bassi su quelli maniacali, indicativo di un umore depresso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>  <span class='chapter-title'>Processi di Markov Nascosti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a48_hidden_markov_processes.html#proprietà-fondamentali-degli-hmm",
    "href": "chapters/appendix/a48_hidden_markov_processes.html#proprietà-fondamentali-degli-hmm",
    "title": "Appendice R — Processi di Markov Nascosti",
    "section": "R.2 Proprietà Fondamentali degli HMM",
    "text": "R.2 Proprietà Fondamentali degli HMM\nGli HMM sono utili per modellare situazioni in cui gli stati del sistema non sono direttamente osservabili ma possono essere inferiti attraverso dati osservabili, come nel caso degli stati dell’umore nei disturbi bipolari. Le proprietà fondamentali degli HMM includono:\n\nProcesso Markoviano degli Stati Nascosti: Gli stati nascosti seguono un processo di Markov di primo ordine, il che significa che la probabilità di transizione a uno stato successivo dipende solo dallo stato attuale e non dagli stati precedenti.\nIndipendenza delle Emissioni: La probabilità di osservare una determinata emissione dipende solo dallo stato nascosto corrente.\nOmogeneità Temporale: Le probabilità di transizione e di emissione rimangono costanti nel tempo, implicando che il comportamento del sistema non cambia lungo il tempo.\n\n\nR.2.1 Applicazione e Analisi degli HMM\nL’uso degli HMM per modellare i dati dei disturbi bipolari permette di identificare pattern di instabilità dell’umore e la durata dei diversi stati. Questo tipo di analisi è utile per comprendere meglio le dinamiche del disturbo bipolare e migliorare le strategie di trattamento. Ad esempio, l’HMM applicato ai dati EMA nel documento ha rivelato che i pazienti con disturbo bipolare sperimentano frequenti cambiamenti tra gli stati dell’umore e che gli stati misti spesso mediano le transizioni tra stati elevati e abbassati. Questi risultati suggeriscono che l’instabilità dell’umore è una caratteristica chiave del disturbo bipolare, anche durante periodi relativamente stabili.\n\n\n\n\nMildiner Moraga, S., Bos, F. M., Doornbos, B., Bruggeman, R., Krieke, L. van der, Snippe, E., & Aarts, E. (2024). Evidence for mood instability in patients with bipolar disorder: Applying multilevel hidden Markov modeling to intensive longitudinal ecological momentary assessment data. Journal of Psychopathology and Clinical Science.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>R</span>  <span class='chapter-title'>Processi di Markov Nascosti</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a50_lin_fun.html",
    "href": "chapters/appendix/a50_lin_fun.html",
    "title": "Appendice S — La funzione lineare",
    "section": "",
    "text": "La funzione lineare è definita come:\n\\[\nf(x) = a + b x,\n\\]\ndove \\(a\\) e \\(b\\) sono costanti. Il grafico di questa funzione è una retta, dove il parametro \\(b\\) rappresenta il coefficiente angolare e il parametro \\(a\\) rappresenta l’intercetta con l’asse delle \\(y\\). In altre parole, la retta interseca l’asse \\(y\\) nel punto \\((0,a)\\) se \\(b \\neq 0\\).\nPossiamo dare un’interpretazione geometrica alle costanti \\(a\\) e \\(b\\) considerando la funzione:\n\\[\ny = b x.\n\\]\nQuesta funzione rappresenta un caso speciale, la proporzionalità diretta tra \\(x\\) e \\(y\\). Nel caso generale della funzione lineare:\n\\[\ny = a + b x,\n\\]\naggiungiamo una costante \\(a\\) a ciascun valore \\(y = b x\\). Nella funzione lineare, se il coefficiente \\(b\\) è positivo, il valore di \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) è negativo, il valore di \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\), la retta è orizzontale e il valore di \\(y\\) non varia al variare di \\(x\\).\nConsideriamo ora il coefficiente \\(b\\) in modo più dettagliato. Prendiamo un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\), come mostrato nella figura. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono chiamate “incrementi” di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) è definito come il rapporto\n\\[\nb = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\]\nindipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Per dare un’interpretazione geometrica al coefficiente angolare (o pendenza) della retta, possiamo semplificare assumendo \\(\\Delta x = 1\\). In questo caso, \\(b\\) è uguale a \\(\\Delta y\\).\n\n\n\n\n\n\nFigura S.1: La funzione lineare \\(y = a + bx\\).\n\n\n\nPossiamo dunque dire che la pendenza \\(b\\) di un retta è uguale all’incremento \\(\\Delta y\\) associato ad un incremento unitario nella \\(x\\).",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>S</span>  <span class='chapter-title'>La funzione lineare</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a51_r_squared.html",
    "href": "chapters/appendix/a51_r_squared.html",
    "title": "Appendice T — Teorema della scomposizione della devianza",
    "section": "",
    "text": "T.1 Formulazione del Teorema\nDato un set di dati \\(y_1, y_2, \\dots, y_n\\), dove \\(y_i\\) rappresenta l’i-esimo valore della variabile dipendente, e \\(\\bar{y}\\) è la media campionaria di \\(y\\), la devianza totale (o variazione totale) dei dati può essere scomposta nel seguente modo:",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>  <span class='chapter-title'>Teorema della scomposizione della devianza</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a51_r_squared.html#formulazione-del-teorema",
    "href": "chapters/appendix/a51_r_squared.html#formulazione-del-teorema",
    "title": "Appendice T — Teorema della scomposizione della devianza",
    "section": "",
    "text": "Devianza Totale (VT): Misura la dispersione totale dei dati intorno alla loro media. \\[\nDT = \\sum_{i=1}^n (y_i - \\bar{y})^2\n\\]\nDevianza Spiegata (VS): Misura quanto della variazione totale è spiegata dal modello di regressione.\n\\[\nDS = \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2\n\\]\ndove \\(\\hat{y}_i\\) è il valore predetto dalla regressione per l’i-esimo osservazione.\nDevianza Residua (VR): Misura la variazione dei dati che il modello non riesce a spiegare. \\[\nDR = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n\\]\n\n\nT.1.1 Teorema di Scomposizione della Devianza\nIl teorema afferma che la variazione totale \\(DT\\) è uguale alla somma della variazione spiegata \\(DS\\) e della variazione residua \\(DR\\):\n\\[\nDT = DS + DR\n\\]\n\n\nT.1.2 Dimostrazione\nLa dimostrazione di questa identità si basa sul principio di ortogonalità dei residui e delle stime. I residui \\(y_i - \\hat{y}_i\\) sono ortogonali alle predizioni \\(\\hat{y}_i - \\bar{y}\\) nel contesto della regressione lineare. Matematicamente, ciò è espresso da:\n\\[\n\\sum_{i=1}^n (\\hat{y}_i - \\bar{y})(y_i - \\hat{y}_i) = 0\n\\]\nUtilizzando l’ortogonalità, possiamo scrivere la variazione totale come segue:\n\\[\n\\begin{align*}\nDT &= \\sum_{i=1}^n (y_i - \\bar{y})^2 \\\\\n   &= \\sum_{i=1}^n [(y_i - \\hat{y}_i) + (\\hat{y}_i - \\bar{y})]^2 \\\\\n   &= \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + 2\\sum_{i=1}^n (y_i - \\hat{y}_i)(\\hat{y}_i - \\bar{y}) + \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2 \\\\\n   &= DR + 2 \\cdot 0 + DS \\\\\n   &= DR + DS\n\\end{align*}\n\\]\nQuesta dimostrazione chiarisce che la variazione totale è esattamente uguale alla somma della devianza spiegata dal modello e quella non spiegata (residua).\n\n\nT.1.3 Applicazione\nApplichiamo ora il teorema di scomposizione della devianza ai dati in esame. Usando pg.linear_regression(x, y) calcoliamo il coefficiente di determinazione.\nConsideriamo i dati forniti dal dataset kidiq.\n\nkidiq = pd.read_stata(\"../../data/kidiq.dta\")\nkidiq.head()\n\n\n\n\n\n\n\n\nkid_score\nmom_hs\nmom_iq\nmom_work\nmom_age\n\n\n\n\n0\n65\n1.0\n121.117529\n4\n27\n\n\n1\n98\n1.0\n89.361882\n4\n25\n\n\n2\n85\n1.0\n115.443165\n4\n27\n\n\n3\n83\n1.0\n99.449639\n3\n25\n\n\n4\n115\n1.0\n92.745710\n4\n27\n\n\n\n\n\n\n\nCi concentreremo sulla relazione lineare tra l’intelligenza del bambino e l’intelligenza della madre.\nRinominiamo le due variabili di interesse.\n\nx = kidiq[\"mom_iq\"]\ny = kidiq[\"kid_score\"]\n\nUn diagramma a dispersione evidenzia un’associazione tra le due variabili in esame, che può essere ragionevolmente approssimata da una retta. Tuttavia, il grafico suggerisce anche che la relazione tra le variabili non sia particolarmente forte.\nIn questo contesto, ci poniamo il duplice obiettivo di individuare la retta che meglio si adatta ai dati del diagramma e di quantificare la bontà di questo adattamento. In altre parole, vogliamo valutare quanto, in media, i punti del diagramma si discostano dalla retta individuata.\n\nplt.plot(x, y, \"x\")\nplt.xlabel(\"Intelligenza della madre\")\n_ = plt.ylabel(\"Intelligenza del bambino\")\n\n\n\n\n\n\n\n\nCalcoliamo i coefficienti del modello\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + e_i\n\\]\ncon il metodo della massima verosimiglianza. A questo scopo usiamo la funzione linear_regression() del pacchetto pingouin.\n\nlm = pg.linear_regression(x, y)\nlm.round(2)\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n25.80\n5.92\n4.36\n0.0\n0.2\n0.2\n14.17\n37.43\n\n\n1\nmom_iq\n0.61\n0.06\n10.42\n0.0\n0.2\n0.2\n0.49\n0.72\n\n\n\n\n\n\n\n\nr_squared = lm[\"r2\"][0] # R-squared del modello\nprint(r_squared)\n\n0.20095123075855126\n\n\nCalcoliamo la devianza totale.\n\nDT = np.sum((y - np.mean(y))**2)\nprint(DT)\n\n180386.15668202768\n\n\nCalcoliamo la devianza spiegata.\n\nDS = np.sum((yhat - np.mean(y)) ** 2)\nprint(DS)\n\n36248.82019705826\n\n\nCalcoliamo la devianza residua.\n\nDR = np.sum((y - yhat) ** 2)\nprint(DR)\n\n144137.33648496936\n\n\nLa devianza totale è la somma della devianza spiegata e della devianza residua.\n\nDS + DR\n\n180386.15668202762\n\n\nIl coefficiente di determinazione è il rapporto tra la devianza spiegata e la devianza totale.\n\nRsq = DS / DT\nprint(Rsq)\n\n0.2009512307585509\n\n\nCiò significa che solo il 20% della devianza totale del QI dei bambini può essere predetta dal QI delle madri in base ad un modello lineare in questo campione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>T</span>  <span class='chapter-title'>Teorema della scomposizione della devianza</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a53_entropy_rv_cont.html",
    "href": "chapters/appendix/a53_entropy_rv_cont.html",
    "title": "Appendice U — Entropia di una variabile casuale continua",
    "section": "",
    "text": "U.1 Calcolo dell’Entropia per una Distribuzione Uniforme\nIl caso più semplice riguarda una distribuzione uniforme continua. Consideriamo una variabile casuale X uniformemente distribuita nell’intervallo (a, b). Per questa distribuzione:\nL’entropia H(X) di una variabile casuale continua è definita come:\n\\[\nH(X) = -\\int_{\\text{Im}(X)} f(x) \\log_2(f(x)) \\, dx.\n\\]\nPer la nostra distribuzione uniforme, possiamo calcolarla come segue. Calcoliamo prima \\(h(f(x)) = -\\log_2(f(x))\\):\n\\[\n\\begin{align*}\nh(f(x)) &= -\\log_2(f(x)) \\\\\n&= -\\log_2\\left(\\frac{1}{b - a}\\right) \\\\\n&= \\log_2(b - a).\n\\end{align*}\n\\]\nOra possiamo scrivere l’espressione per l’entropia:\n\\[\nH(X) = \\int_a^b f(x) \\cdot h(f(x)) \\, dx = \\int_a^b \\frac{1}{b - a} \\cdot \\log_2(b - a) \\, dx.\n\\]\nOsserviamo che all’interno dell’integrale abbiamo due termini costanti rispetto a x:\nGrazie alla proprietà delle costanti negli integrali, possiamo estrarre questi termini costanti dall’integrale:\n\\[\nH(X) = \\frac{1}{b - a} \\cdot \\log_2(b - a) \\cdot \\int_a^b \\, dx.\n\\]\nCalcoliamo l’integrale rimanente:\n\\[\n\\int_a^b \\, dx = [x]_a^b = b - a.\n\\]\nSostituiamo questo risultato nell’equazione:\n\\[\nH(X) = \\frac{1}{b - a} \\cdot \\log_2(b - a) \\cdot (b - a).\n\\]\nI termini \\((b - a)\\) si annullano:\n\\[\nH(X) = \\log_2(b - a) \\cdot \\frac{(b - a)}{(b - a)} = \\log_2(b - a) \\cdot 1 = \\log_2(b - a).\n\\]\nIn conclusione, l’entropia di una variabile casuale X uniformemente distribuita nell’intervallo (a, b) è:\n\\[\nH(X) = \\log_2(b - a).\n\\]\nQuesta formula mostra che l’entropia di una distribuzione uniforme:\nAd esempio, calcoliamo l’entropia di una distribuzione uniforme di supporto [-4, 4].\n# Definisco i limiti dell'intervallo\na = -4\nb = 4\n\n# Calcolo l'entropia\nentropy_uniform = np.log2(b - a)\nprint(entropy_uniform)\n\n3.0",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>  <span class='chapter-title'>Entropia di una variabile casuale continua</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a53_entropy_rv_cont.html#calcolo-dellentropia-per-una-distribuzione-uniforme",
    "href": "chapters/appendix/a53_entropy_rv_cont.html#calcolo-dellentropia-per-una-distribuzione-uniforme",
    "title": "Appendice U — Entropia di una variabile casuale continua",
    "section": "",
    "text": "L’insieme dei valori possibili per X, detto immagine di X e indicato con Im(X), è l’intervallo (a, b):\n\\[\n\\text{Im}(X) = (a, b).\n\\]\nLa funzione di densità di probabilità f(x) è definita come:\n\\[\nf(x) = \\begin{cases}\n\\frac{1}{b - a}, & \\text{per } x \\in (a, b) \\\\\n0, & \\text{altrimenti}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\n\n\\(\\frac{1}{b - a}\\) è costante perché b e a sono i limiti dell’intervallo.\n\\(\\log_2(b - a)\\) è anche costante per lo stesso motivo.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDipende solo dall’ampiezza dell’intervallo (b - a) e non dalla sua posizione specifica sull’asse reale.\nÈ espressa in bit, dato l’uso del logaritmo in base 2.\nAumenta al crescere dell’ampiezza dell’intervallo, riflettendo una maggiore incertezza sulla posizione esatta della variabile casuale all’interno di un intervallo più ampio.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>  <span class='chapter-title'>Entropia di una variabile casuale continua</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a53_entropy_rv_cont.html#calcolo-dellentropia-per-una-distribuzione-gaussiana-standardizzata",
    "href": "chapters/appendix/a53_entropy_rv_cont.html#calcolo-dellentropia-per-una-distribuzione-gaussiana-standardizzata",
    "title": "Appendice U — Entropia di una variabile casuale continua",
    "section": "U.2 Calcolo dell’Entropia per una Distribuzione Gaussiana Standardizzata",
    "text": "U.2 Calcolo dell’Entropia per una Distribuzione Gaussiana Standardizzata\nCalcoliamo ora l’entropia di una gaussiana standardizzata. Cominciamo dalla funzione di densità di probabilità per una variabile casuale gaussiana con media \\(\\mu\\) e varianza \\(\\sigma^2\\):\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right).\n\\]\nPer una gaussiana standardizzata, ovvero una distribuzione normale con \\(\\mu = 0\\) e \\(\\sigma^2 = 1\\), la funzione di densità diventa:\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right).\n\\]\nL’entropia per una variabile casuale continua \\(X\\) con densità \\(f(x)\\) è data da:\n\\[\nH(X) = - \\int_{-\\infty}^{+\\infty} f(x) \\log_2(f(x)) \\, dx.\n\\]\nInseriamo la densità della distribuzione normale standardizzata:\n\\[\nH(X) = - \\int_{-\\infty}^{+\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) \\log_2\\left(\\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)\\right) dx.\n\\]\nSepariamo il logaritmo dei prodotti in due parti:\n\\[\n\\log_2\\left(\\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)\\right) = \\log_2\\left(\\frac{1}{\\sqrt{2\\pi}}\\right) + \\log_2\\left(\\exp\\left(-\\frac{x^2}{2}\\right)\\right).\n\\]\nSappiamo che \\(\\log_2\\left(\\exp(x)\\right) = \\frac{x}{\\ln(2)}\\), quindi possiamo riscrivere il logaritmo della seconda parte:\n\\[\n\\log_2\\left(\\exp\\left(-\\frac{x^2}{2}\\right)\\right) = -\\frac{x^2}{2} \\log_2(e).\n\\]\nOra possiamo riscrivere l’entropia come somma di due termini:\n\\[\nH(X) = - \\int_{-\\infty}^{+\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) \\left[ \\log_2\\left(\\frac{1}{\\sqrt{2\\pi}}\\right) + \\left(-\\frac{x^2}{2} \\log_2(e)\\right) \\right] dx.\n\\]\nIl primo termine del logaritmo è costante rispetto a \\(x\\), quindi possiamo separarlo dall’integrale:\n\\[\nH(X) = - \\log_2\\left(\\frac{1}{\\sqrt{2\\pi}}\\right) \\int_{-\\infty}^{+\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) dx.\n\\]\nL’integrale è semplicemente \\(1\\) (poiché la funzione densità di probabilità di una gaussiana standardizzata è normalizzata), quindi abbiamo:\n\\[\nH(X) = - \\log_2\\left(\\frac{1}{\\sqrt{2\\pi}}\\right).\n\\]\nSemplifichiamo:\n\\[\n\\log_2\\left(\\frac{1}{\\sqrt{2\\pi}}\\right) = -\\frac{1}{2} \\log_2(2\\pi).\n\\]\nQuindi il primo termine contribuisce con:\n\\[\nH(X) = \\frac{1}{2} \\log_2(2\\pi).\n\\]\nOra consideriamo il secondo termine dell’integrale:\n\\[\n- \\log_2(e) \\int_{-\\infty}^{+\\infty} \\frac{x^2}{2\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) dx.\n\\]\nQuesto è l’integrale della varianza della distribuzione normale, che sappiamo valere \\(\\sigma^2 = 1\\). Pertanto, l’integrale diventa:\n\\[\n\\frac{1}{2} \\log_2(e).\n\\]\nOra sommiamo i due contributi:\n\\[\nH(X) = \\frac{1}{2} \\log_2(2\\pi) + \\frac{1}{2} \\log_2(e).\n\\]\nSappiamo che \\(\\log_2(e) \\approx 1.4427\\), quindi l’entropia complessiva è:\n\\[\nH(X) = \\frac{1}{2} \\log_2(2\\pi e) \\approx 2.05.\n\\]\nL’entropia di una variabile casuale con distribuzione gaussiana standard è dunque circa 2.05 bit.\nPer verificare il risultato, calcoliamo l’entropia della gaussiana standard usando le funzioni di scipy.\n\nentropy_gaussian = stats.norm.entropy()\n\n# Convertiamo l'entropia in bit (dato che scipy la fornisce in nats)\nentropy_gaussian_bits = entropy_gaussian / np.log(2)\n\nentropy_gaussian_bits\n\n2.047095585180641\n\n\nConfrontiamo il risultato ottenuto per la distribuzione gaussiana standardizzata con il caso precedente della distribuzione uniforme sull’intervallo \\([-4, 4]\\). Sebbene gran parte della massa della distribuzione gaussiana sia concentrata all’interno dello stesso intervallo, l’entropia della gaussiana risulta inferiore rispetto a quella della distribuzione uniforme. Questo è coerente con le nostre aspettative, poiché la distribuzione uniforme ha una maggiore incertezza: ogni valore all’interno dell’intervallo ha la stessa probabilità di verificarsi, mentre nella distribuzione gaussiana la probabilità si concentra attorno alla media, riducendo l’incertezza complessiva.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>U</span>  <span class='chapter-title'>Entropia di una variabile casuale continua</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a55_rescorla_wagner.html",
    "href": "chapters/appendix/a55_rescorla_wagner.html",
    "title": "Appendice V — Apprendimento per rinforzo",
    "section": "",
    "text": "V.1 Simulare l’Apprendimento\nIniziamo con il simulare il processo decisionale di un partecipante che sceglie tra due slot machine utilizzando il modello di apprendimento di Rescorla-Wagner.\nConfigurazione della simulazione:\nLa simulazione dei dati segue la procedura discussa nel Capitolo 106.\ndef simulate_RescorlaWagner(params, T, mu, noisy_choice=True):\n\n    alpha, theta = params\n    \n    # Un array di zeri di lunghezza T\n    c = np.zeros((T), dtype=int)\n    r = np.zeros((T), dtype=int)\n\n    # Un array multidimensionale di zeri di dimensione 2xT\n    Q_stored = np.zeros((2, T), dtype=float)\n    \n    # Inizializza Q per t == 0\n    Q = [0.5, 0.5]\n\n    for t in range(T):\n\n        # Salva i valori Q per Q_{t+1}\n        Q_stored[:, t] = Q\n\n        # Calcola le probabilità di scelta\n        p0 = np.exp(theta*Q[0]) / (np.exp(theta*Q[0]) + np.exp(theta*Q[1]))\n        p1 = 1 - p0\n        \n        # Se noisy_choice è vero, viene simulato un comportamento di scelta rumoroso in \n        # cui l'opzione 0 è scelta con probabilità p0, mentre l'opzione 1 è scelta con \n        # probabilità 1-p0.\n        if noisy_choice:\n            if np.random.random_sample(1) &lt; p0:\n                c[t] = 0\n            else:\n                c[t] = 1\n        else:  # la scelta viene effettuata senza rumore\n            c[t] = np.argmax([p0, p1])\n\n        # Genera la ricompensa sulla base delle probabilità di ricompensa\n        r[t] = np.random.rand() &lt; mu[c[t]]\n\n        # Aggiorna le aspettative di valore\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    return c, r, Q_stored\nSimuliamo T = 100 prove utilizzando il modello generativo dei dati definito in precedenza.\nT = 100\nK = 2\nmu = [0.2, 0.8]\nc, r, Q = simulate_RescorlaWagner([.1, 2.5], T=T, mu=mu)\nRappresentiamo graficamente i risultati ottenuti dalla simulazione – i dati sono identici a quelli del Capitolo 106.\nplt.plot(range(T), r, 'r--', alpha=.6)\nplt.plot(range(T), c, '+', label='scelta')\nplt.xlabel('Prove')\nplt.ylabel('Feedback (1=Ricompensa,\\n 0=Nessuna ricompensa)')\nplt.title(f'Apprendimento di Rescorla-Wagner')\nplt.show()\nIl grafico successivo mostra le aspettative di valore \\(Q\\) delle due slot machine nel corso delle prove.\nplt.plot(range(T), Q[1, :], 'r--', alpha=.6, label='80% machine')\nplt.plot(range(T), Q[0, :], 'm-', alpha=.6, label='20% machine')\nplt.plot(range(T), c, 'b+', label='choice')\nplt.xlabel('trials')\nplt.ylabel('value')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a55_rescorla_wagner.html#simulare-lapprendimento",
    "href": "chapters/appendix/a55_rescorla_wagner.html#simulare-lapprendimento",
    "title": "Appendice V — Apprendimento per rinforzo",
    "section": "",
    "text": "Numero di tentativi: \\(T = 100\\). Significa che il partecipante farà 100 scelte consecutive.\nNumero di slot machine: \\(K = 2\\). Il partecipante sceglierà tra due slot machine ad ogni tentativo.\nProbabilità di ricompensa: \\(\\mu = [0.2, 0.8]\\). Ciò significa che la Slot machine 1 ha una probabilità pari a 0.2 di offrire una ricompensa, mentre la Slot machine 2 ha una probabilità pari a 0.8 di offrire una ricompensa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a55_rescorla_wagner.html#la-massima-verosimiglianza",
    "href": "chapters/appendix/a55_rescorla_wagner.html#la-massima-verosimiglianza",
    "title": "Appendice V — Apprendimento per rinforzo",
    "section": "V.2 La Massima Verosimiglianza",
    "text": "V.2 La Massima Verosimiglianza\nIl passo successivo è stimare i parametri del modello a partire dai dati osservati. Esistono diversi metodi per stimare i parametri, ma in questa appendice ci concentreremo sull’approccio della Massima Verosimiglianza.\nL’approccio della massima verosimiglianza cerca di trovare i valori dei parametri del modello che massimizzano la probabilità dei dati osservati. In altre parole, vogliamo trovare i parametri \\((\\alpha, \\theta)\\) che rendono i dati osservati \\(d_{1:T}\\) più probabili secondo il modello Rescorla-Wagner.\n\nV.2.1 Calcolo del Logaritmo della Verosimiglianza\nMassimizzare la verosimiglianza è spesso più facile se si lavora con il logaritmo della verosimiglianza, perché le moltiplicazioni di probabilità diventano somme. La log-verosimiglianza può essere espressa come:\n\\[\n\\log \\mathcal{L} = \\log p(d_{1:T} | (\\alpha, \\theta)_m, m) = \\sum_{t=1}^T \\log p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\n\\]\nIn questa equazione:\n\n\\(\\log \\mathcal{L}\\) è il logaritmo della verosimiglianza.\n\\(p(d_{1:T} | (\\alpha, \\theta)_m, m)\\) è la probabilità dei dati osservati dato il modello e i parametri.\n\\(p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\\) è la probabilità di ogni singola scelta \\(c_t\\) data la storia delle scelte e dei feedback fino al tempo \\(t\\) e i parametri del modello.\n\n\n\nV.2.2 Minimizzazione del Logaritmo Negativo della Verosimiglianza\nIn pratica, massimizzare la log-verosimiglianza è equivalente a minimizzare il logaritmo negativo della verosimiglianza. Questo ci porta alla seguente equazione:\n\\[\n-\\log \\mathcal{L} = -\\sum_{t=1}^T \\log p(c_t | d_{1:t-1}, s_t, (\\alpha, \\theta)_m, m)\n\\]\nPer applicare questa procedura al modello di Rescorla-Wagner, dobbiamo definire la funzione di log-verosimiglianza negativa specifica per il nostro modello. Questa funzione ci permette di calcolare quanto bene i parametri \\(\\alpha\\) e \\(\\theta\\) spiegano i dati osservati. Durante il processo di stima, l’obiettivo è minimizzare questa funzione per trovare i valori ottimali dei parametri.\n\n\nV.2.3 Esempio Pratico\nImmaginiamo di avere dati osservati da un esperimento in cui un partecipante ha fatto 100 scelte tra due slot machine. Il nostro obiettivo è stimare i parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\theta\\) (temperatura) che meglio spiegano queste scelte. Per fare ciò, utilizziamo il metodo della massima verosimiglianza.\nLa seguente funzione negll_RescorlaWagner calcola il negativo della log-verosimiglianza per il modello di apprendimento di Rescorla-Wagner. Questo ci permette di capire quanto bene i parametri del modello (\\(\\alpha\\) e \\(\\theta\\)) spiegano le scelte osservate. Ecco una spiegazione passo passo per capire come funziona questa funzione.\nI parametri della Funzione sono:\n\nparams: una lista che contiene i valori dei parametri \\(\\alpha\\) (tasso di apprendimento) e \\(\\theta\\) (temperatura).\nc: un array che contiene le scelte effettuate dal partecipante (0 o 1).\nr: un array che contiene le ricompense ricevute dopo ogni scelta (1 per ricompensa, 0 per nessuna ricompensa).\n\nEsaminiamo ora il corpo della funzione.\n\nInizializzazione dei Parametri\nalpha, theta = params\nQ = [0.5, 0.5]\nT = len(c)\nchoiceProb = np.zeros((T), dtype=float)\n\nalpha e theta sono estratti dalla lista params.\nQ è una lista che tiene traccia delle aspettative di valore per le due slot machine, inizializzate a 0.5.\nT è il numero di scelte effettuate.\nchoiceProb è un array che memorizza la probabilità di ogni scelta effettuata.\n\nCalcolo delle Probabilità di Scelta e Aggiornamento dei Valori\nfor t in range(T):\n    p0 = np.exp(theta * Q[0]) / (np.exp(theta * Q[0]) + np.exp(theta * Q[1]))\n    p = [p0, 1 - p0]\n    choiceProb[t] = p[c[t]]\n    delta = r[t] - Q[c[t]]\n    Q[c[t]] = Q[c[t]] + alpha * delta\n\nCalcolo delle Probabilità di Scelta:\n\np0 è la probabilità di scegliere la prima slot machine.\np è una lista delle probabilità di scegliere ciascuna delle due slot machine.\nchoiceProb[t] memorizza la probabilità della scelta effettivamente fatta al tempo \\(t\\).\n\nAggiornamento delle Aspettative di Valore:\n\ndelta è la differenza tra la ricompensa effettiva r[t] e l’aspettativa di valore Q[c[t]] per la scelta fatta.\nQ[c[t]] viene aggiornata secondo la regola di Rescorla-Wagner: il nuovo valore atteso è il vecchio valore atteso più una frazione (determinata da \\(\\alpha\\)) dell’errore di previsione.\n\n\nCalcolo del Negativo della Log-Verosimiglianza\nnegLL = -np.sum(np.log(choiceProb))\nreturn negLL\n\nLog-Verosimiglianza:\n\nnp.log(choiceProb) calcola il logaritmo delle probabilità di scelta.\nnp.sum(np.log(choiceProb)) somma questi logaritmi.\n\nNegativo della Log-Verosimiglianza:\n\nIl risultato è moltiplicato per -1 per ottenere il negativo della log-verosimiglianza, poiché nella stima dei parametri cerchiamo di minimizzare questa funzione.\n\n\n\nIn sintesi, la funzione negll_RescorlaWagner:\n\nCalcola le probabilità di scelta basate sui parametri \\(\\alpha\\) e \\(\\theta\\).\nAggiorna le aspettative di valore in base alle scelte e alle ricompense osservate.\nCalcola il negativo della log-verosimiglianza per valutare quanto bene i parametri spiegano i dati osservati.\n\nEcco la funzione completa con commenti per facilitarne la comprensione:\n\ndef negll_RescorlaWagner(params, c, r):\n    alpha, theta = params\n    Q = [0.5, 0.5]\n    T = len(c)\n    choiceProb = np.zeros((T), dtype=float)\n\n    for t in range(T):\n        # Calcola le probabilità di scelta per k = 2\n        p0 = np.exp(theta * Q[0]) / (np.exp(theta * Q[0]) + np.exp(theta * Q[1]))\n        # \"p\" è una lista di probabilità di scelta per le due opzioni disponibili\n        p = [p0, 1 - p0]\n\n        # Memorizza la probabilità della scelta effettuata\n        choiceProb[t] = p[c[t]]\n\n        # Aggiorna le aspettative di valore secondo la regola di Rescorla-Wagner\n        delta = r[t] - Q[c[t]]\n        Q[c[t]] = Q[c[t]] + alpha * delta\n\n    # Calcola il negativo della log-verosimiglianza\n    negLL = -np.sum(np.log(choiceProb))\n\n    return negLL\n\nSimuliamo ora un set di dati.\n\n# simulate choices from RW Model\nalpha = .2\ntheta = 1.5\nc, r, Q2 = simulate_RescorlaWagner([alpha, theta], T=T, mu=[.2, .8])\n\nPer fare un esempio, valutiamo la log-verosimiglianza negativa per i dati simulati in corrispondenza dei valori alpha e theta indicati di seguito.\n\nalpha_hat = 0.3\ntheta_hat = 2.5\nnegLL = negll_RescorlaWagner([alpha_hat, theta_hat], c, r)\nprint(alpha_hat, theta_hat, negLL)\n\n0.3 2.5 67.02432583559954\n\n\n\nalpha_hat = 0.2\ntheta_hat = 1.5\nnegLL = negll_RescorlaWagner([alpha_hat, theta_hat], c, r)\nprint(alpha_hat, theta_hat, negLL)\n\n0.2 1.5 62.40238018291291\n\n\nUn metodo per trovare i parametri di massima verosimiglianza è effettuare una ricerca esaustiva su tutto lo spazio dei parametri. Questo significa selezionare i valori di alpha e theta per i quali la funzione negLL assume il valore più basso.\nPer illustrare questo metodo, applichiamolo a un set di dati simulato. Per semplicità, assumiamo di conoscere il valore di \\(\\theta\\) e di dover trovare solo il valore di \\(\\alpha\\).\n\nnLL = []\nalpha_vals = np.linspace(0, 0.5, 1000)\nfor alpha_val in alpha_vals:\n    nLL.append(negll_RescorlaWagner([alpha_val, theta], c, r))\n\nplt.figure()\nplt.plot(alpha_vals, nLL, '-')\nplt.plot(\n    alpha_vals[np.argmin(nLL)], nLL[np.argmin(nLL)],\n    'X', label=r'optimal $\\hat \\alpha$'\n)\nplt.ylabel('negative log likelihood')\nplt.xlabel(fr'learning rate, $\\hat \\alpha$')\nplt.title(f'Rescorla-Wagner Learning')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nV.2.4 Validazione\nUna volta stabilito un metodo per stimare i parametri del modello dai dati, dobbiamo valutare quanto accuratamente queste stime riflettano i veri valori dei parametri del modello. Per rispondere a questa domanda, possiamo condurre uno studio di simulazione.\nI parametri della simulazione sono i seguenti.\n\nT = 250\nmu = [0.2, 0.8]\nnum_subjects = 20\n\nCalcolimo i valori di massima verosimiglianza dei parametri alpha e theta usando la funzione minimize per minimizzare la funzione di log-verosimiglianza. Simuliamo i dati di un soggetto.\nSpecifichiamo poi le stime iniziali per i valori dei parametri e i valori margine delle possibili soluzioni. I risultati saranno salvati nell’oggetto result. Le stime dei due parametri si estraggono con result.x.\n\nc, r, Q = simulate_RescorlaWagner([0.15, 1.5], T=T, mu=mu)\n\ninit_guess = (0.1, 0.1)\n\n# minimize neg LL\nresult = minimize(\n    negll_RescorlaWagner,\n    init_guess,\n    (c, r),\n    bounds=((0, 1), (0, 10)),\n)\nprint(result.x)\n\n[0.1093135  1.27704408]\n\n\nSimuliamo i dati per 500 soggetti, con 250 osservazioni ciascuno, utilizzando valori casuali di alpha e theta. Successivamente, eseguiamo la stima di massima verosimiglianza per i dati di ogni soggetto, inizializzando casualmente i parametri per ciascuno di essi. Infine, salviamo i risultati ottenuti nel DataFrame df. Ecco il codice corrispondente:\n\nNREP = 500\ndf = pd.DataFrame(\n    index=range(0, NREP), columns=[\"true_alpha\", \"alpha\", \"true_theta\", \"theta\"]\n)\n\n# loop through subjects\nfor index in range(NREP):\n\n    true_alpha = 0.95 * np.random.random()\n    true_theta = 4.0 * np.random.random()\n\n    c, r, Q = simulate_RescorlaWagner([true_alpha, true_theta], T=250, mu=mu)\n\n    init_guess = (0.2 * np.random.random(), 1.0 * np.random.random())\n    # minimize neg LL\n    param_fits = minimize(\n        negll_RescorlaWagner,\n        init_guess,\n        (c, r),\n        bounds=((0, 1), (0, 10)),\n    )\n\n    # store in dataframe\n    df.at[index, \"true_alpha\"] = true_alpha\n    df.at[index, \"true_theta\"] = true_theta\n    df.at[index, \"alpha\"] = param_fits.x[0]\n    df.at[index, \"theta\"] = param_fits.x[1]\n\nLa figura successiva mostra una corrispondenza tra i valori stimati di alpha e i valori veri. È importante notare che la corrispondenza non è perfetta a causa della presenza di una componente di casualità nei dati. Inoltre, in alcuni casi si possono osservare valori stimati di alpha pari a 0 o 1, che corrispondono a risultati spurii dell’algoritmo. Il numero di risultati spurii aumenta con il diminuire del numero di osservazioni per ciascun soggetto.\n\nplt.plot(df.true_alpha, df.alpha, 'ob', alpha=.4)\nplt.xlabel('True alpha')\nplt.ylabel('Estimated alpha')\nplt.title(f'ML estimation')\nplt.show()\n\n\n\n\n\n\n\n\nUn discorso analogo si può fare per theta, anche se in questo caso vi è una migliore corrispondenza tra i valori stimati e i valori veri.\n\nplt.plot(df.true_theta, df.theta, 'or', alpha=.4)\nplt.xlabel('True theta')\nplt.ylabel('Estimated theta')\nplt.title(f'ML estimation')\nplt.show()\n\n\n\n\n\n\n\n\nIn sintesi, possiamo affermare che il metodo della massima verosimiglianza è in grado di recuperare i valori simulati dei parametri \\(\\alpha\\) e \\(\\theta\\) del modello di Rescorla-Wagner, ma solo quando il numero di osservazioni per soggetto è considerevole. Tuttavia, è importante notare che questo metodo può produrre risultati imprecisi in determinate circostanze.\nEsistono altri metodi di stima che offrono risultati migliori anche con un numero inferiore di osservazioni per soggetto. Tra questi, il metodo gerarchico bayesiano è ampiamente utilizzato nella pratica. Va precisato che l’obiettivo di questo tutorial era principalmente illustrare in modo semplice come sia possibile ottenere con buona accuratezza i parametri del modello di Rescorla-Wagner dai dati generati da una simulazione, considerando condizioni ottimali in cui i valori dei parametri del modello sono noti.\nÈ importante sottolineare che, nella pratica, la stima dei parametri può essere un processo complesso e che l’accuratezza delle stime dipende da molteplici fattori, come la dimensione del campione e la natura dei dati osservati. Pertanto, è sempre consigliabile valutare attentamente i risultati e considerare l’utilizzo di approcci più sofisticati, come il metodo gerarchico bayesiano, per ottenere stime più affidabili dei parametri del modello.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a55_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/appendix/a55_rescorla_wagner.html#informazioni-sullambiente-di-sviluppo",
    "title": "Appendice V — Apprendimento per rinforzo",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\n%load_ext watermark\n%watermark -n -u -v -iv -w -m\n\nLast updated: Fri Jul 26 2024\n\nPython implementation: CPython\nPython version       : 3.12.4\nIPython version      : 8.26.0\n\nCompiler    : Clang 16.0.6 \nOS          : Darwin\nRelease     : 23.5.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 8\nArchitecture: 64bit\n\narviz     : 0.18.0\nscipy     : 1.14.0\npandas    : 2.2.2\nmatplotlib: 3.9.1\nnumpy     : 1.26.4\nseaborn   : 0.13.2\n\nWatermark: 2.4.3",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>V</span>  <span class='chapter-title'>Apprendimento per rinforzo</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html",
    "href": "chapters/appendix/a60_ttest_exercises.html",
    "title": "Appendice W — Esercizi sull’inferenza frequentista",
    "section": "",
    "text": "W.1 Inferenza statistica su una singola media",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>  <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#inferenza-statistica-su-una-singola-media",
    "href": "chapters/appendix/a60_ttest_exercises.html#inferenza-statistica-su-una-singola-media",
    "title": "Appendice W — Esercizi sull’inferenza frequentista",
    "section": "",
    "text": "W.1.1 Test \\(t\\) di Student a un campione\nPer descrivere l’inferenza su una singola media consideriamo il seguente esempio. È stato condotto uno studio di ricerca al fine di esaminare le differenze tra gli adulti anziani e quelli giovani sulla percezione della soddisfazione nella vita. Per testare questa ipotesi, è stato effettuato uno studio pilota su dati ipotetici. Il test è stato somministrato a dieci adulti anziani (oltre i 70 anni) e dieci adulti giovani (tra i 20 e i 30 anni). La scala di valutazione utilizzata ha un range di punteggi da 0 a 60, dove punteggi elevati indicano una maggiore soddisfazione nella vita e punteggi bassi indicano una minore soddisfazione. È stata scelta una scala con elevata affidabilità e validità. I dati (fittizi) raccolti sono riportati di seguito.\n\nyounger = np.array([45, 38, 52, 48, 25, 39, 51, 46, 55, 46])\nolder = np.array([34, 33, 36, 38, 37, 40, 42, 43, 32, 36])\n\nPer ora, esaminiamo soltanto il gruppo degli adulti più anziani. Si suppponga che studi precedenti indichino che, per questo gruppo d’età, la soddisfazione della vita misurata con questo test sia pari a 60. Svolgiamo il test t di Student usando l’ipotesi nulla che nella popolazione la media sia effettivamente uguale a 40.\nInziamo a svolgere l’esercizio applicando la funzione ttest del modulo pingouin. Per l’esempio presente, poniamo \\(\\mu_0\\), la media dell’ipotesi nulla, uguale a 40. Svolgiamo l’esercizio con ttest.\n\nres = pg.ttest(older, 40)\n\nEsaminiamo il risultato.\n\nprint(res)\n\n               T  dof alternative     p-val           CI95%   cohen-d   BF10  \\\nT-test -2.481666    9   two-sided  0.034896  [34.46, 39.74]  0.784772  2.319   \n\n           power  \nT-test  0.599895  \n\n\nInterpretazione. Dato che il valore-p è minore di \\(\\alpha\\) = 0.05, ovvero in modo equivalente, dato che la statistica test cade nella regione di rifiuto, rifiutiamo \\(H_0: \\mu = 40\\).\nProcediamo ora con i calcoli passo-passo utilizzando la formula del test t di Student. La statistica \\(T\\) calcolata dal test è definita come:\n\\[\nT = \\frac{\\bar{X} - \\mathbb{E}(\\bar{X})}{s / \\sqrt{n}} = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}},\n\\]\ndove \\(\\bar{X}\\) è la media campionaria, \\(\\mu_0\\) è l’ipotesi nulla sulla media della popolazione, \\(s\\) è la deviazione standard campionaria e \\(n\\) è la dimensione del campione. Tale statistica ha una semplice interpretazione: essa corrisponde alla standardizzazione della media del campione all’interno della distribuzione campionaria delle medie di ampiezza \\(n\\) = 10. La distribuzione campionaria delle medie di ampiezza \\(n\\) = 10 ha media \\(\\mu_{\\bar{X}} = \\mu\\) e varianza \\(\\sigma^2_{\\bar{X}} = \\frac{\\sigma^2}{n}\\), dove \\(\\mu\\) è la media della popolazione e \\(\\sigma^2\\) è la varianza della popolazione da cui il campione è stato estratto. Tuttavia, poiché i parametri della popolazione sono sconosciuti, l’approccio frequentista utilizza la media \\(\\mu_0\\) ipotizzata dall’ipotesi nulla \\(H_0\\) al posto della media sconosciuta della popolazione e stima il parametro sconosciuto \\(\\sigma\\) con la deviazione standard \\(s\\) del campione. In queste circostanze, la statistica \\(T\\) segue la distribuzione \\(t\\) di Student con \\(n-1\\) gradi di libertà se il campione è stato estratto da una popolazione normale.\nSvolgiamo i calcoli con Python.\n\nT = (np.mean(older) - 40) / (np.std(older, ddof=1) / np.sqrt(len(older)))\nT\n\n-2.481665888425312\n\n\nI gradi di libertà sono \\(n-1\\).\n\ndf = len(older) - 1\nprint(df)\n\n9\n\n\nTroviamo il valore-p, ovvero l’area sottesa alla distribuzione t di Student con 9 gradi di libertà nei due intervalli \\([-\\infty, -T]\\) e \\([T, +\\infty]\\).\n\n# Set up the x-axis values for the t-distribution plot\nx = np.linspace(st.t.ppf(0.001, df), st.t.ppf(0.999, df), 1000)\n\n# Set up the y-axis values for the t-distribution plot\ny = st.t.pdf(x, df)\n\n# Create the t-distribution plot\nplt.plot(x, y, label=\"t-distribution\")\n\n# Shade the areas [-infinity, -T] and [T, +infinity]\nplt.fill_between(x[x &lt;= -T], y[x &lt;= -T], color=\"red\", alpha=0.2)\nplt.fill_between(x[x &gt;= T], y[x &gt;= T], color=\"red\", alpha=0.2)\n\n# Add vertical lines for T and -T\nplt.axvline(x=T, color=\"black\", linestyle=\"--\")\nplt.axvline(x=-T, color=\"black\", linestyle=\"--\")\n\n\n# Set the plot title and axis labels\nplt.title(f\"Distribuzione t di Student con {df} gradi di libertà\")\nplt.xlabel(\"Valore t\")\nplt.ylabel(\"Densità di probabilità\")\nplt.show()\n\n\n\n\n\n\n\n\n\nst.t.cdf(T, df=len(older) - 1) * 2\n\n0.03489593108658913\n\n\n\n\nW.1.2 Intervallo di confidenza per una media\nCalcoliamo ora l’intervallo di confidenza al livello di fiducia del 95%. Come visto in precedenza, la procedura ttest ha calcolato l’intervallo di confidenza del 95% per la media della popolazione che va da 34.46 a 39.74. Questo intervallo può essere interpretato come segue: se la stessa procedura venisse applicata molte volte, in circa il 95% dei casi l’intervallo ottenuto conterrà il vero valore della media della popolazione.\nIniziamo a trovare il valore critico della distribuzione \\(t\\) di Student che lascia \\(\\alpha/2\\) in ciascuna coda.\n\nalpha = 0.05\ndf # 9\nt_c = st.t.ppf(1 - alpha / 2, df)\nt_c\n\n2.262157162854099\n\n\nL’intervallo di confidenza è dato da\n\\[\n\\bar{X} \\pm t_{n-1} \\frac{s}{\\sqrt{n}}.\n\\]\nSvolgiamo i calcoli.\n\nci_lower = np.mean(older) - t_c * np.std(older, ddof=1) / np.sqrt(len(older))\nci_upper = np.mean(older) + t_c * np.std(older, ddof=1) / np.sqrt(len(older))\nprint(\"L'intervallo di confidenza al 95% per la media della popolazione è: [{:.2f}, {:.2f}].\".format(ci_lower, ci_upper))\n\nL'intervallo di confidenza al 95% per la media della popolazione è: [34.46, 39.74].",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>  <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#confronto-tra-medie-per-campioni-indipendenti",
    "href": "chapters/appendix/a60_ttest_exercises.html#confronto-tra-medie-per-campioni-indipendenti",
    "title": "Appendice W — Esercizi sull’inferenza frequentista",
    "section": "W.2 Confronto tra medie per campioni indipendenti",
    "text": "W.2 Confronto tra medie per campioni indipendenti\n\nW.2.1 Test \\(t\\) di Student per campioni indipendenti\nPer eseguire il test t di Student per due campioni indipendenti, iniziamo svolgendo i calcoli con la funzione ttest del modulo pingouin. L’ipotesi nulla è che la differenza tra le medie delle due popolazioni sia uguale a 0: \\(\\mu_1 - \\mu_2 = 0\\). La funzione ttest implementa la seguente formula:\n\\[\nT = \\frac{(\\bar{x}_1 - \\bar{x}_2) - 0}{\\sqrt{\n    \\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}.\n}},\n\\]\n\nres = pg.ttest(younger, older, paired=False)\nprint(res)\n\n               T  dof alternative    p-val          CI95%  cohen-d   BF10  \\\nT-test  2.479867   18   two-sided  0.02326  [1.13, 13.67]  1.10903  2.849   \n\n           power  \nT-test  0.650317  \n\n\nSvolgiamo i calcoli passo-passo.\n\nt_num = np.mean(younger) - np.mean(older)\nt_denom = np.sqrt(np.var(younger, ddof=1) / len(younger) + np.var(older, ddof=1) / len(older))\nT = np.divide(t_num, t_denom)\nT\n\n2.479866520313643\n\n\nLa statistica \\(T\\) calcolata sopra si distribuisce con \\((n_1 - 1) + (n_2 - 1)\\), ovvero \\(n_1 + n_2 - 2\\), gradi di libertà.\n\ndf = len(younger) + len(older) - 2\nprint(df)\n\n18\n\n\nIl valore-p è uguale all’area sottesa alla funzione t di Student con \\(n_1 + n_2 - 2\\) negli intervalli \\([-\\infty, -T]\\) e \\([T, +\\infty]\\). Nel caso presente abbiamo\n\n(1 - st.t.cdf(T, df=df)) * 2\n\n0.023260241301116924\n\n\n\n\nW.2.2 Intervallo di confidenza per la differenza tra due medie\nCalcoliamo ora l’intervallo di confidenza al livello di fiducia del 95% per la differenza tra le due medie. Iniziamo a calcolare il valore critico \\(t\\).\n\nalpha = 0.05\nt_c = st.t.ppf(1 - alpha / 2, df)\nt_c\n\n2.10092204024096\n\n\nTroviamo l’errore standard della differenza tra le due medie.\n\nse_diff = np.sqrt(np.var(younger, ddof=1) / len(younger) + np.var(older, ddof=1) / len(older))\nse_diff\n\n2.9840315756446754\n\n\nTroviamo i limiti inferiore e superiore dell’intervallo di confidenza al 95%.\n\nci_lower = (np.mean(younger) - np.mean(older)) - (t_c * se_diff)\nci_upper = (np.mean(younger) - np.mean(older)) + (t_c * se_diff)\nprint(\"L'intervallo di confidenza al 95% per la differenza tra le due medie è: [{:.2f}, {:.2f}].\".format(ci_lower, ci_upper))\n\nL'intervallo di confidenza al 95% per la differenza tra le due medie è: [1.13, 13.67].\n\n\nSi noti che i gradi di libertà sono \\(n_1+n_2-2\\) quando le varianze delle due popolazioni sono uguali. La formula di Welch-Satterthwaite viene usata per approssimare i gradi di libertà quando le due varianze non sono uguali:\n\\[\n\\nu \\approx \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{(s_1^2/n_1)^2}{n_1 - 1} + \\frac{(s_2^2/n_2)^2}{n_2 - 1}}\n\\]\ndove \\(\\nu\\) rappresenta i gradi di libertà approssimati, \\(s_1^2\\) e \\(s_2^2\\) sono le varianze campionarie delle due popolazioni, \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni.\nNel caso di varianze diverse, l’argomento correction=True produce una correzione dei gradi di liberta con l’approssimazione di Welch-Satterthwaite e il corrispondente valore-p.\n\nres1 = pg.ttest(younger, older, paired=False, correction=True)\nprint(res1)\n\n               T        dof alternative     p-val          CI95%  cohen-d  \\\nT-test  2.479867  12.156852   two-sided  0.028738  [0.91, 13.89]  1.10903   \n\n         BF10     power  \nT-test  2.849  0.650317  \n\n\nConsideriamo ora la statistica \\(d\\) di Cohen. Il \\(d\\) di Cohen è una misura di effetto comunemente utilizzata per valutare la differenza tra le medie di due gruppi indipendenti. La formula del \\(d\\) di Cohen per la differenza di due medie indipendenti è la seguente:\n\\[\nd = \\frac{\\bar{X}_1 - \\bar{X}_2}{s},\n\\]\ndove \\(\\bar{X}_1\\) e \\(\\bar{X}_2\\) sono le medie dei due gruppi, e \\(s\\) è la deviazione standard raggruppata (pooled standard deviation), definita come:\n\\[\ns = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}},\n\\]\ndove \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due gruppi e \\(s_1\\) e \\(s_2\\) sono le deviazioni standard dei due gruppi. Il \\(d\\) di Cohen può essere interpretato come la differenza tra le medie dei due gruppi in unità di deviazioni standard raggruppate. Un valore di \\(d\\) di Cohen di 0.2 è considerato un effetto piccolo, un valore di 0.5 è considerato un effetto medio e un valore di 0.8 o superiore è considerato un effetto grande.\nLa funzione ttest ha trovato un valore di 1.10903. Svolgiamo i calcoli passo-passo.\nIniziamo a calcolare la deviazione standard raggruppata (pooled standard deviation).\n\ns_pool_num = np.sum(\n    [\n        (len(younger) - 1) * np.std(younger, ddof=1) ** 2,\n        (len(older) - 1) * np.std(older, ddof=1) ** 2,\n    ]\n)\ns_pool_denom = len(younger) + len(older) - 2\n\ns_pool = np.sqrt(np.divide(s_pool_num, s_pool_denom))\ns_pool\n\n6.672497450147301\n\n\nTroviamo ora il \\(d\\) di Cohen.\n\nd = (np.mean(younger) - np.mean(older)) / s_pool\nprint(d)\n\n1.1090300229094336\n\n\nInterpretazione. Il risultato dell’analisi suggerisce che la differenza nella soddisfazione nella vita tra i due gruppi di età, misurata tramite l’indice \\(d\\) di Cohen, è considerevole in termini di dimensione dell’effetto.\n\n\nW.2.3 PyMC\nSvolgiamo ora lo stesso esercizio usando l’inferenza Bayesiana. Utilizzeremo distribuzioni a priori ampie per garantire un risultato simile all’analisi frequentista. Inseriamo i dati in un DataFrame.\n\ny = np.concatenate((younger, older))\nx = np.concatenate((np.repeat(1, len(younger)), np.repeat(0, len(older))))\ndf = pd.DataFrame({\"y\": y, \"x\": x})\ndf.head()\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n0\n45\n1\n\n\n1\n38\n1\n\n\n2\n52\n1\n\n\n3\n48\n1\n\n\n4\n25\n1\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\ny\nx\n\n\n\n\n15\n40\n0\n\n\n16\n42\n0\n\n\n17\n43\n0\n\n\n18\n32\n0\n\n\n19\n36\n0\n\n\n\n\n\n\n\n\nsns.scatterplot(x=df[\"x\"], y=df[\"y\"])\nsns.regplot(x=df[\"x\"], y=df[\"y\"], ci=False)\n\n\n\n\n\n\n\n\nCreaimo il modello statistico corrispondente ad un modello di regressione con un predittore dicotomico codificato con 0 per il primo gruppo e con 1 per il secondo gruppo. Iniziamo con l’analisi predittiva a priori per determinare se le distribuzioni a priori sono adeguate.\n\nwith Model() as model_p:\n\n    # Priors\n    alpha = Normal(\"alpha\", mu=0, sigma=50)\n    beta = Normal(\"beta\", mu=0, sigma=100)\n    sigma = pm.HalfNormal(\"sigma\", sigma=50)\n\n    # Expected value of outcome\n    mu = alpha + beta * x\n\n    # Likelihood of observations\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n\n    # Sampling\n    idata_p = pm.sample_prior_predictive(samples=50)\n\nSampling: [Y_obs, alpha, beta, sigma]\n\n\nUtilizzo lo script fornito dal sito di PyMC per generare casualmente un campione di rette di regressione dal modello utilizzando le distribuzioni a priori specificate.\n\n_, ax = plt.subplots()\n\nxp = xr.DataArray(np.linspace(0, 1, 11), dims=[\"plot_dim\"])\nprior = idata_p.prior\nyp = prior[\"alpha\"] + prior[\"beta\"] * xp\n\nax.plot(xp, yp.stack(sample=(\"chain\", \"draw\")), c=\"k\", alpha=0.4)\n\nax.set_ylabel(\"Soddisfazione della vita\")\nax.set_xlabel(\"Gruppo (codificato con 0 e 1)\")\nax.set_title(\"Distribuzione predittiva a priori\");\n\n\n\n\n\n\n\n\nSi noti che prior[\"alpha\"] è un array che contiene 50 valori generati casualmente dal modello per il parametro alpha.\n\nprior[\"alpha\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'alpha' (chain: 1, draw: 50)&gt; Size: 400B\narray([[ 27.91316336,  -9.761233  ,  21.89391528, -14.56856298,\n         68.39580771, -37.42800408, -52.79004685,  90.34566945,\n        -53.22280112, -83.55364275,  -5.15598452, -15.56387412,\n         35.18040675,  45.55683681,  44.74212001,  52.60001141,\n          4.91303814, -13.8408394 , -29.8977839 ,   3.06879684,\n         50.20452599,  39.56802222,  28.65514305,  -7.73157439,\n        -18.9430296 ,  -4.08430141, -48.42185103, -36.97779067,\n         34.10768708, -51.30605918,  -4.31841036, -30.40509399,\n        -36.26374915,  36.98455803, -45.12949691, -37.09592811,\n        -35.53336193, -54.06503347, -75.56008329,   6.52612528,\n        -73.64141351,  28.0803143 ,  60.28700248, 108.42906955,\n        -51.10481884, -74.83993705, -16.03126424,  -8.95153788,\n        -12.08582618,   0.62408476]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49xarray.DataArray'alpha'chain: 1draw: 5027.91 -9.761 21.89 -14.57 68.4 ... -74.84 -16.03 -8.952 -12.09 0.6241array([[ 27.91316336,  -9.761233  ,  21.89391528, -14.56856298,\n         68.39580771, -37.42800408, -52.79004685,  90.34566945,\n        -53.22280112, -83.55364275,  -5.15598452, -15.56387412,\n         35.18040675,  45.55683681,  44.74212001,  52.60001141,\n          4.91303814, -13.8408394 , -29.8977839 ,   3.06879684,\n         50.20452599,  39.56802222,  28.65514305,  -7.73157439,\n        -18.9430296 ,  -4.08430141, -48.42185103, -36.97779067,\n         34.10768708, -51.30605918,  -4.31841036, -30.40509399,\n        -36.26374915,  36.98455803, -45.12949691, -37.09592811,\n        -35.53336193, -54.06503347, -75.56008329,   6.52612528,\n        -73.64141351,  28.0803143 ,  60.28700248, 108.42906955,\n        -51.10481884, -74.83993705, -16.03126424,  -8.95153788,\n        -12.08582618,   0.62408476]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nLo stesso si può dire per beta.\n\nprior[\"beta\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'beta' (chain: 1, draw: 50)&gt; Size: 400B\narray([[  36.25169578,   -7.92409658,   78.11662091,  -77.30445403,\n          -2.91861005,   63.14901963, -120.4458863 , -122.9803336 ,\n         -29.99397584,  -79.06934517,  196.1112678 ,  -47.14082206,\n         -80.37696349, -105.18911559,   55.41040452,   81.30111272,\n          82.17672831,    5.54854267,   87.26233082,   80.28598144,\n        -143.41337086,  129.64063429,  -71.67569728,   -7.63877719,\n         103.65954504,  133.47888441, -179.02868192,  -69.95843954,\n         -93.39842188, -104.65997079,   21.09319786,  -73.99700599,\n          92.13556843,   44.7699911 ,  -23.466116  ,  115.23595245,\n         109.53955429, -106.70959991,   -3.47936206, -107.42657989,\n        -194.18473598, -113.7431577 ,    6.26294595,   13.49018829,\n           9.02114705,  -61.35179689, -116.75047565,  -28.45809619,\n          82.9444729 ,    6.62830301]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49xarray.DataArray'beta'chain: 1draw: 5036.25 -7.924 78.12 -77.3 -2.919 ... -61.35 -116.8 -28.46 82.94 6.628array([[  36.25169578,   -7.92409658,   78.11662091,  -77.30445403,\n          -2.91861005,   63.14901963, -120.4458863 , -122.9803336 ,\n         -29.99397584,  -79.06934517,  196.1112678 ,  -47.14082206,\n         -80.37696349, -105.18911559,   55.41040452,   81.30111272,\n          82.17672831,    5.54854267,   87.26233082,   80.28598144,\n        -143.41337086,  129.64063429,  -71.67569728,   -7.63877719,\n         103.65954504,  133.47888441, -179.02868192,  -69.95843954,\n         -93.39842188, -104.65997079,   21.09319786,  -73.99700599,\n          92.13556843,   44.7699911 ,  -23.466116  ,  115.23595245,\n         109.53955429, -106.70959991,   -3.47936206, -107.42657989,\n        -194.18473598, -113.7431577 ,    6.26294595,   13.49018829,\n           9.02114705,  -61.35179689, -116.75047565,  -28.45809619,\n          82.9444729 ,    6.62830301]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nL’array xp è un vettore unidimensionale di 11 elementi compresi tra 0 e 1.\n\nxp.shape\n\n(11,)\n\n\n\nxp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (plot_dim: 11)&gt; Size: 88B\narray([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])\nDimensions without coordinates: plot_dimxarray.DataArrayplot_dim: 110.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nSi noti che l’xarray yp ha coordinate chain e draw.\n\nyp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (chain: 1, draw: 50, plot_dim: 11)&gt; Size: 4kB\narray([[[ 2.79131634e+01,  3.15383329e+01,  3.51635025e+01,\n          3.87886721e+01,  4.24138417e+01,  4.60390112e+01,\n          4.96641808e+01,  5.32893504e+01,  5.69145200e+01,\n          6.05396896e+01,  6.41648591e+01],\n        [-9.76123300e+00, -1.05536427e+01, -1.13460523e+01,\n         -1.21384620e+01, -1.29308716e+01, -1.37232813e+01,\n         -1.45156910e+01, -1.53081006e+01, -1.61005103e+01,\n         -1.68929199e+01, -1.76853296e+01],\n        [ 2.18939153e+01,  2.97055774e+01,  3.75172395e+01,\n          4.53289016e+01,  5.31405636e+01,  6.09522257e+01,\n          6.87638878e+01,  7.65755499e+01,  8.43872120e+01,\n          9.21988741e+01,  1.00010536e+02],\n        [-1.45685630e+01, -2.22990084e+01, -3.00294538e+01,\n         -3.77598992e+01, -4.54903446e+01, -5.32207900e+01,\n         -6.09512354e+01, -6.86816808e+01, -7.64121262e+01,\n         -8.41425716e+01, -9.18730170e+01],\n        [ 6.83958077e+01,  6.81039467e+01,  6.78120857e+01,\n          6.75202247e+01,  6.72283637e+01,  6.69365027e+01,\n          6.66446417e+01,  6.63527807e+01,  6.60609197e+01,\n          6.57690587e+01,  6.54771977e+01],\n...\n        [-7.48399371e+01, -8.09751167e+01, -8.71102964e+01,\n         -9.32454761e+01, -9.93806558e+01, -1.05515835e+02,\n         -1.11651015e+02, -1.17786195e+02, -1.23921375e+02,\n         -1.30056554e+02, -1.36191734e+02],\n        [-1.60312642e+01, -2.77063118e+01, -3.93813594e+01,\n         -5.10564069e+01, -6.27314545e+01, -7.44065021e+01,\n         -8.60815496e+01, -9.77565972e+01, -1.09431645e+02,\n         -1.21106692e+02, -1.32781740e+02],\n        [-8.95153788e+00, -1.17973475e+01, -1.46431571e+01,\n         -1.74889667e+01, -2.03347764e+01, -2.31805860e+01,\n         -2.60263956e+01, -2.88722052e+01, -3.17180148e+01,\n         -3.45638245e+01, -3.74096341e+01],\n        [-1.20858262e+01, -3.79137889e+00,  4.50306840e+00,\n          1.27975157e+01,  2.10919630e+01,  2.93864103e+01,\n          3.76808576e+01,  4.59753048e+01,  5.42697521e+01,\n          6.25641994e+01,  7.08586467e+01],\n        [ 6.24084763e-01,  1.28691506e+00,  1.94974537e+00,\n          2.61257567e+00,  3.27540597e+00,  3.93823627e+00,\n          4.60106657e+00,  5.26389687e+00,  5.92672717e+00,\n          6.58955747e+00,  7.25238777e+00]]])\nCoordinates:\n  * chain    (chain) int64 8B 0\n  * draw     (draw) int64 400B 0 1 2 3 4 5 6 7 8 ... 41 42 43 44 45 46 47 48 49\nDimensions without coordinates: plot_dimxarray.DataArraychain: 1draw: 50plot_dim: 1127.91 31.54 35.16 38.79 42.41 46.04 ... 4.601 5.264 5.927 6.59 7.252array([[[ 2.79131634e+01,  3.15383329e+01,  3.51635025e+01,\n          3.87886721e+01,  4.24138417e+01,  4.60390112e+01,\n          4.96641808e+01,  5.32893504e+01,  5.69145200e+01,\n          6.05396896e+01,  6.41648591e+01],\n        [-9.76123300e+00, -1.05536427e+01, -1.13460523e+01,\n         -1.21384620e+01, -1.29308716e+01, -1.37232813e+01,\n         -1.45156910e+01, -1.53081006e+01, -1.61005103e+01,\n         -1.68929199e+01, -1.76853296e+01],\n        [ 2.18939153e+01,  2.97055774e+01,  3.75172395e+01,\n          4.53289016e+01,  5.31405636e+01,  6.09522257e+01,\n          6.87638878e+01,  7.65755499e+01,  8.43872120e+01,\n          9.21988741e+01,  1.00010536e+02],\n        [-1.45685630e+01, -2.22990084e+01, -3.00294538e+01,\n         -3.77598992e+01, -4.54903446e+01, -5.32207900e+01,\n         -6.09512354e+01, -6.86816808e+01, -7.64121262e+01,\n         -8.41425716e+01, -9.18730170e+01],\n        [ 6.83958077e+01,  6.81039467e+01,  6.78120857e+01,\n          6.75202247e+01,  6.72283637e+01,  6.69365027e+01,\n          6.66446417e+01,  6.63527807e+01,  6.60609197e+01,\n          6.57690587e+01,  6.54771977e+01],\n...\n        [-7.48399371e+01, -8.09751167e+01, -8.71102964e+01,\n         -9.32454761e+01, -9.93806558e+01, -1.05515835e+02,\n         -1.11651015e+02, -1.17786195e+02, -1.23921375e+02,\n         -1.30056554e+02, -1.36191734e+02],\n        [-1.60312642e+01, -2.77063118e+01, -3.93813594e+01,\n         -5.10564069e+01, -6.27314545e+01, -7.44065021e+01,\n         -8.60815496e+01, -9.77565972e+01, -1.09431645e+02,\n         -1.21106692e+02, -1.32781740e+02],\n        [-8.95153788e+00, -1.17973475e+01, -1.46431571e+01,\n         -1.74889667e+01, -2.03347764e+01, -2.31805860e+01,\n         -2.60263956e+01, -2.88722052e+01, -3.17180148e+01,\n         -3.45638245e+01, -3.74096341e+01],\n        [-1.20858262e+01, -3.79137889e+00,  4.50306840e+00,\n          1.27975157e+01,  2.10919630e+01,  2.93864103e+01,\n          3.76808576e+01,  4.59753048e+01,  5.42697521e+01,\n          6.25641994e+01,  7.08586467e+01],\n        [ 6.24084763e-01,  1.28691506e+00,  1.94974537e+00,\n          2.61257567e+00,  3.27540597e+00,  3.93823627e+00,\n          4.60106657e+00,  5.26389687e+00,  5.92672717e+00,\n          6.58955747e+00,  7.25238777e+00]]])Coordinates: (2)chain(chain)int640array([0])draw(draw)int640 1 2 3 4 5 6 ... 44 45 46 47 48 49array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])Indexes: (2)chainPandasIndexPandasIndex(Index([0], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n      dtype='int64', name='draw'))Attributes: (0)\n\n\nL’istruzione yp = prior[\"alpha\"] + prior[\"beta\"] * xp genera i valori y per una serie di rette con coefficienti prior[\"alpha\"] e prior[\"beta\"]. Nel nostro caso, stiamo generando 50 rette perché abbiamo selezionato 50 valori di alpha e 50 valori di beta dalle distribuzioni a posteriori.\nNel contesto della modellazione bayesiana, il termine “chain” si riferisce alla catena di campionamento di Markov Monte Carlo (MCMC). Durante il processo di campionamento, vengono eseguiti diversi passaggi successivi per ottenere campioni indipendenti dalla distribuzione a posteriori. Ogni passaggio viene chiamato “draw” o “sample”. Pertanto, “chain” rappresenta le catene di campionamento e “draw” rappresenta i singoli campioni all’interno di ciascuna catena.\nL’istruzione yp.stack(sample=(\"chain\", \"draw\")) viene utilizzata per combinare le dimensioni “chain” e “draw” al fine di ottenere un array multidimensionale che rappresenta i campioni di parametri estratti dalla distribuzione a posteriori. Ciò facilita la visualizzazione e l’analisi dei campioni.\nNotiamo che le pendenze delle rette di regressione generate casualmente dal modello, utilizzando le distribuzioni a priori specificate, presentano un intervallo più ampio rispetto alle pendenze trovate nel campione osservato. Inoltre, il valore medio della variabile dipendente \\(y\\) nel campione è incluso nella distribuzione a priori. Questo suggerisce che le scelte delle distribuzioni a priori siano appropriate per il modello.\nAvendo determinato le distribuzioni a priori, eseguiamo il campionamento MCMC.\n\nwith Model() as model:\n\n    # Priors\n    alpha = Normal(\"alpha\", mu=0, sigma=50)\n    beta = Normal(\"beta\", mu=0, sigma=50)\n    sigma = pm.HalfNormal(\"sigma\", sigma=50)\n\n    # Expected value of outcome\n    mu = alpha + beta * x\n\n    # Likelihood of observations\n    Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n\n    # Sampling\n    idata = pm.sample()\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, beta, sigma]\n\n\n\n\n\n\n\n\n\n\n\nSampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 16 seconds.\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri.\n\n_ = az.plot_trace(idata, combined=True)\nplt.tight_layout()\n\n\n\n\n\n\n\n\nNel contesto di un modello di regressione in cui i gruppi “older” e “younger” sono codificati rispettivamente come 0 e 1, la media del gruppo “older” può essere interpretata come il valore di riferimento o l’intercetta del modello. In termini matematici, la media del gruppo “older” corrisponde al coefficiente α (alpha) del modello di regressione. La differenza tra le medie dei due gruppi è invece uguale al coefficiente beta.\nPer verificare, troviamo la media del gruppo “older” (codificato con x = 0).\n\nnp.mean(older)\n\n37.1\n\n\nCalcoliamo la differenza tra le medie dei due campioni.\n\nnp.mean(younger) - np.mean(older)\n\n7.399999999999999\n\n\nEsaminiamo ora le stime a posteriori dei due coefficienti del modello e gli intervalli di credibilità al 95%.\n\naz.summary(idata, hdi_prob=0.95)\n\n\n\n\n\n\n\n\nmean\nsd\nhdi_2.5%\nhdi_97.5%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nalpha\n37.067\n2.260\n32.572\n41.284\n0.048\n0.034\n2210.0\n2191.0\n1.0\n\n\nbeta\n7.406\n3.250\n1.230\n14.012\n0.070\n0.050\n2142.0\n2151.0\n1.0\n\n\nsigma\n7.178\n1.278\n4.916\n9.771\n0.028\n0.020\n2183.0\n2007.0\n1.0\n\n\n\n\n\n\n\nI coefficienti alpha e beta nel modello di regressione assumono i valori previsti. L’intervallo di credibilità per il coefficiente beta può essere interpretato nel seguente modo: si può affermare con una certezza soggettiva del 95% che il gruppo “younger” tende ad avere una soddisfazione della vita che è almeno 1.1 punti superiore e non più di 14.1 punti superiore rispetto al gruppo “older”.\nUsiamo ora la funzione dedicata di PyMC per campionare le distribuzioni a posteriori per generare il posterior predictive check. La funzione sample_posterior_predictive estrarrà casualmente 40000 campioni dei parametri del modello dalla traccia MCMC. Successivamente, per ogni campione, verranno estratti 100 numeri casuali da una distribuzione normale specificata dai valori di mu e sigma in quel campione:\n\nwith model:\n    pm.sample_posterior_predictive(idata, extend_inferencedata=True, random_seed=rng)\n\nSampling: [Y_obs]\n\n\n\n\n\n\n\n\n\n\n\nL’oggetto xarray “posterior_predictive” in “idata” conterrà ora 40000 insiemi di dati (ciascuno contenente 100 valori), i quali sono stati generati utilizzando una diversa configurazione dei parametri dalle distribuzioni a posteriori di alpha e beta:\n\nidata.posterior_predictive\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 648kB\nDimensions:      (chain: 4, draw: 1000, Y_obs_dim_2: 20)\nCoordinates:\n  * chain        (chain) int64 32B 0 1 2 3\n  * draw         (draw) int64 8kB 0 1 2 3 4 5 6 ... 993 994 995 996 997 998 999\n  * Y_obs_dim_2  (Y_obs_dim_2) int64 160B 0 1 2 3 4 5 6 ... 13 14 15 16 17 18 19\nData variables:\n    Y_obs        (chain, draw, Y_obs_dim_2) float64 640kB 56.93 45.38 ... 29.89\nAttributes:\n    created_at:                 2024-05-07T04:19:22.885544+00:00\n    arviz_version:              0.18.0\n    inference_library:          pymc\n    inference_library_version:  5.14.0xarray.DatasetDimensions:chain: 4draw: 1000Y_obs_dim_2: 20Coordinates: (3)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 5 ... 995 996 997 998 999array([  0,   1,   2, ..., 997, 998, 999])Y_obs_dim_2(Y_obs_dim_2)int640 1 2 3 4 5 6 ... 14 15 16 17 18 19array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19])Data variables: (1)Y_obs(chain, draw, Y_obs_dim_2)float6456.93 45.38 44.72 ... 47.46 29.89array([[[56.93119105, 45.38112552, 44.71705033, ..., 36.6533742 ,\n         26.7945236 , 43.70073916],\n        [48.59795404, 49.14921972, 36.26414691, ..., 33.9800401 ,\n         43.64123915, 27.04789784],\n        [46.20305509, 37.31314497, 24.9156855 , ..., 34.63748569,\n         43.68189988, 25.00128306],\n        ...,\n        [41.88456655, 46.6706999 , 42.15297999, ..., 33.78602401,\n         45.84205574, 30.18639455],\n        [42.50078136, 51.06733118, 58.90315575, ..., 25.58896962,\n         23.22293853, 36.39028755],\n        [37.25135731, 33.72155053, 49.35109368, ..., 38.50069572,\n         43.37827239, 40.12896516]],\n\n       [[69.89704936, 44.89150638, 35.56737805, ..., 40.56827667,\n         24.40992124, 38.77930154],\n        [41.05292868, 34.71488032, 44.81629245, ..., 42.46278301,\n         44.84971018, 50.22855624],\n        [47.57661051, 44.39864842, 34.75311598, ..., 37.36811349,\n         52.05518433, 60.44519465],\n...\n        [46.36530415, 46.82141194, 43.99908701, ..., 33.36542914,\n         38.30912878, 24.24702688],\n        [58.0412549 , 40.54760807, 44.01622446, ..., 17.3388618 ,\n         29.39961152, 36.3022488 ],\n        [45.5066708 , 40.26978451, 45.96019551, ..., 27.45048685,\n         31.34425973, 27.56274796]],\n\n       [[49.10864016, 50.6347884 , 33.25334531, ..., 41.79996363,\n         56.15275593, 32.58161595],\n        [61.01484177, 45.19326455, 47.63829417, ..., 48.95528758,\n         33.60197361, 36.22097782],\n        [46.69327667, 52.18230406, 43.11523761, ..., 27.3596807 ,\n         41.88385917, 38.33724321],\n        ...,\n        [44.95070411, 36.79029201, 46.02741174, ..., 24.30896316,\n         21.17478346, 30.58681844],\n        [44.15401203, 43.59896216, 50.40780036, ..., 45.82617659,\n         29.65260042, 20.27135168],\n        [40.78029668, 41.79302778, 37.94651275, ..., 30.31091397,\n         47.45717734, 29.89154143]]])Indexes: (3)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n       ...\n       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n      dtype='int64', name='draw', length=1000))Y_obs_dim_2PandasIndexPandasIndex(Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype='int64', name='Y_obs_dim_2'))Attributes: (4)created_at :2024-05-07T04:19:22.885544+00:00arviz_version :0.18.0inference_library :pymcinference_library_version :5.14.0\n\n\nPossiamo utilizzare questi dati per verificare se il modello è in grado di riprodurre le caratteristiche osservate nel campione. Per fare ciò, possiamo utilizzare la funzione plot_ppc fornita da ArviZ:\n\naz.plot_ppc(idata, num_pp_samples=200);\n\n\n\n\n\n\n\n\nOsserviamo che i dati generati dal modello seguono l’andamento dei dati osservati, indicando che il modello è adeguato per i dati considerati. Inoltre, notiamo che il modello produce campioni di dati molto diversi tra loro. Questa variazione è coerente considerando che il campione osservato era di dimensioni ridotte e quindi vi è un’ampia incertezza associata alle caratteristiche dei campioni futuri.\nEseguiamo ora l’analisi di regressione sugli stessi dati usando il metodo dei minimi quadrati. A questo fine usiamo la funzione linear_regression del modulo pingouin.\n\npg.linear_regression(df['x'], df['y'])\n\n\n\n\n\n\n\n\nnames\ncoef\nse\nT\npval\nr2\nadj_r2\nCI[2.5%]\nCI[97.5%]\n\n\n\n\n0\nIntercept\n37.1\n2.110029\n17.582697\n8.790692e-13\n0.25465\n0.213242\n32.666994\n41.533006\n\n\n1\nx\n7.4\n2.984032\n2.479867\n2.326024e-02\n0.25465\n0.213242\n1.130782\n13.669218\n\n\n\n\n\n\n\nLa stima dei coefficienti è altamente coerente con quella ottenuta utilizzando PyMC. L’intervallo di fiducia per il coefficiente b, che rappresenta la differenza tra le medie dei due gruppi, presenta una somiglianza notevole con l’intervallo di credibilità bayesiano.\nTuttavia, è importante sottolineare che, anche se in questo caso specifico l’approccio frequentista produce risultati simili all’approccio bayesiano, non è possibile generalizzare questa conclusione a tutti i casi. Le differenze tra i due approcci possono emergere in scenari diversi e richiedono un’analisi caso per caso.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>  <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#project-star",
    "href": "chapters/appendix/a60_ttest_exercises.html#project-star",
    "title": "Appendice W — Esercizi sull’inferenza frequentista",
    "section": "W.3 Project Star",
    "text": "W.3 Project Star\nSvolgiamo ora un altro esercizio usando dei dati reali relativi al progetto Star. Il Project STAR (Student-Teacher Achievement Ratio) è stato un grande esperimento educativo condotto negli Stati Uniti tra il 1985 e il 1990. L’obiettivo era quello di esaminare l’effetto della dimensione delle classi sulla performance degli studenti. In particolare, gli studenti venivano assegnati in modo casuale a classi di piccole dimensioni (13-17 studenti) o grandi dimensioni (22-25 studenti).\nIl progetto coinvolse più di 6.000 studenti e 1.000 insegnanti in 79 scuole elementari in Tennessee. I risultati dello studio indicarono che gli studenti assegnati a classi più piccole hanno ottenuto risultati migliori in termini di performance accademica, partecipazione in classe, comportamento e assenze rispetto agli studenti assegnati a classi più grandi.\nIn questo capitolo, analizziamo una parte dei dati del Project STAR. Come variabili abbiamo i punteggi ottenuti dagli studenti ai test standardizzati di lettura e matematica alla fine del terzo anno, insieme alla percentuale di studenti che hanno completato gli studi superiori.\nL’obiettivo dell’esercizio è calcolare la media dell’effetto causale della frequenza delle classi piccole rispetto alle classi di dimensioni standard sui punteggi dei test di lettura di terza elementare per tutta la popolazione target di studenti.\nLeggiamo i dati dal file STAR.csv.\n\ndf_star = pd.read_csv(\"../data/STAR.csv\")\ndf_star.head()\n\n\n\n\n\n\n\n\nclasstype\nreading\nmath\ngraduated\n\n\n\n\n0\nsmall\n578\n610\n1\n\n\n1\nregular\n612\n612\n1\n\n\n2\nregular\n583\n606\n1\n\n\n3\nsmall\n661\n648\n1\n\n\n4\nsmall\n614\n636\n1\n\n\n\n\n\n\n\nLe medie dei due gruppi sono le seguenti.\n\ngroup_means = df_star.groupby('classtype')[\"reading\"].mean()\nprint(group_means)\n\nclasstype\nregular    625.492017\nsmall      632.702564\nName: reading, dtype: float64\n\n\nGeneriamo un violin plot per i punteggi nel test di lettura di terza elementare per i due gruppi.\n\nsns.violinplot(x=\"classtype\", y=\"reading\", data=df_star)\n\n\n\n\n\n\n\n\nL’ipotesi nulla è che i dati provengono da due popolazioni aventi la stessa media: \\(H_0: \\mu_1 - \\mu_2 = 0\\). Useremo un test bilaterale, ovvero rifiuteremo \\(H_0\\) sia quando il valore \\(T\\) cade nella regione di rifiuto perché \\(\\mu_1 &gt; \\mu_2 = 0\\), sia quando cade nella regione di rifiuto perché \\(\\mu_1 &lt; \\mu_2 = 0\\).\nPer semplicità, credo due DataFrame, uno per ciascun gruppo.\n\ndf_small = df_star[df_star['classtype'] == 'small']\ndf_regular = df_star[df_star['classtype'] == 'regular']\n\nSvolgo il test \\(t\\) di Student per due gruppi indipendenti con la funzione ttest.\n\nres = pg.ttest(df_small[\"reading\"], df_regular[\"reading\"], paired=False)\nprint(res)\n\n               T          dof alternative    p-val          CI95%   cohen-d  \\\nT-test  3.495654  1220.993525   two-sided  0.00049  [3.16, 11.26]  0.197183   \n\n          BF10     power  \nT-test  25.771  0.938789  \n\n\nInterpretazione. Avendo ottenuto un valore-p minore di \\(\\alpha\\), si conclude rifiutando l’ipotesi nulla di uguaglianza delle due medie. Si presti però attenzione al \\(d\\) di Cohen: \\(d\\) = 0.20. Ciò significa che la dimensione dell’effetto è piccola.\nSvolgiamo ora i calcoli passo-passo. Calcoliamo la differenza tra le medie dei due gruppi.\n\nmean_diff = np.mean(df_small[\"reading\"]) - np.mean(df_regular[\"reading\"])\nmean_diff\n\n7.210546686018347\n\n\nTroviamo i gradi di libertà per la differenza tra due medie indipendenti.\n\nnum_rows = df_star.shape[0]\nnum_rows\n\n1274\n\n\n\ndof = 2 * num_rows - 2\ndof\n\n2546\n\n\nTroviamo il valore critico per un test bilaterale.\n\nt_c = st.t.ppf(0.975, dof)\nt_c\n\n1.9608961841574426\n\n\nSe non assumiamo che le due varianze siano uguali, allora l’errore standard per la differenza tra le medie di due gruppi indipendenti è\n\\[\n\\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}.\n\\]\n\nse_diff = np.sqrt(\n    np.var(df_small[\"reading\"], ddof=1) / len(df_small[\"reading\"]) +\n    np.var(df_regular[\"reading\"], ddof=1) / len(df_regular[\"reading\"])\n    )\nse_diff\n\n2.0627173626882493\n\n\nTroviamo il valore della statistica \\(T\\).\n\nT = mean_diff / se_diff\nprint(T)\n\n3.4956542357413216\n\n\nTroviamo il valore-p.\n\n(1 - st.t.cdf(T, df=dof)) * 2\n\n0.0004809856733483109\n\n\nCalcoliamo ora l’intervallo di fiducia al 95% per la differenza tra le medie dei due gruppi:\n\\[\n(\\bar{X}_1 - \\bar{X}_2) \\pm t_{n_1 + n_2 - 2} \\cdot \\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}.\n\\]\n\npm = np.array([-1, +1])\nci = mean_diff + pm * (t_c * se_diff)\nprint(ci)\n\n[ 3.16577208 11.25532129]\n\n\nInterpretazione. Dai risultati ottenuti, si può concludere che l’effetto causale medio di frequentare una classe piccola sui punteggi dei test di lettura di terza elementare, per tutti gli studenti della popolazione target, è probabilmente un aumento compreso tra 3.17 e 11.25 punti.\n\nW.3.1 Margine d’errore\nEsiste un modo alternativo di esprimere gli intervalli di confidenza, che è popolare nel mondo dei sondaggi. Coinvolge l’uso di ciò che è noto come “margine di errore”, definito come la metà della larghezza dell’intervallo di confidenza. Utilizzando questo termine, possiamo esprimere l’intervallo di confidenza come:\n\\[\n\\text{stimatore} \\pm \\text{margine di errore.}\n\\]\nPer i dati presenti, possiamo dire che frequentare una classe piccola produce un incremento atteso di 7.21 ± 4.04 punti sui punteggi dei test di lettura di terza elementare. L’ampiezza dell’intervallo di confidenza è qui di 8.08 punti, quindi il margine di errore è di 4.04 punti.\nSi deve notare la differenza concettuale tra il risultato espresso in termini di intervallo di confidenza o margine d’errore, che rappresenta una differenza assoluta tra le medie dei due gruppi, e l’indice \\(d\\) di Cohen, il quale rappresenta una differenza relativa tra le medie dei due gruppi, ponderata in base all’incertezza della stima. In altre parole, mentre il margine d’errore esprime la precisione della stima assoluta della differenza tra le medie, l’indice \\(d\\) di Cohen esprime la dimensione dell’effetto relativo tra i due gruppi, tenendo conto della variazione naturale dei dati.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>  <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a60_ttest_exercises.html#inferenza-su-una-proporzione",
    "href": "chapters/appendix/a60_ttest_exercises.html#inferenza-su-una-proporzione",
    "title": "Appendice W — Esercizi sull’inferenza frequentista",
    "section": "W.4 Inferenza su una proporzione",
    "text": "W.4 Inferenza su una proporzione\nOccupiamoci ora dell’inferenza sulla proporzione di una popolazione. La teoria delle probabilità ci dice che il valore atteso della proporzione campionaria \\(\\hat{p}\\) è la proporzione \\(p\\) della popolazione e che la deviazione standard della proporzione campionaria è la deviazione standard della variabile casuale binomiale \\(Y\\) divisa per \\(n\\):\n\\[\\begin{align}\n\\mu_{\\hat p}&=\\frac{\\mu_Y}{n} = p \\\\\n\\sigma_{\\hat p} &=\\frac{\\sigma_Y}{n} = \\frac{\\sqrt{n \\cdot p \\cdot (1-p)}}{n} = \\sqrt{\\frac{p \\cdot (1-p)}{n}}\n\\end{align}\\]\nQuesto punto può essere chiarito da una simulazione. Supponiamo di esaminare 10000 campioni casuali di ampiezza 10 estratti da una popolazione nella quale la probabilità di “successo” è 0.6.\n\np = 0.6\nn = 10\nX = st.bernoulli(p)\nY = [X.rvs(n) for i in range(10000)]\n\nI primi 5 campioni sono i seguenti.\n\nY[0:5]\n\n[array([0, 0, 1, 1, 0, 1, 0, 1, 0, 1]),\n array([0, 0, 0, 1, 1, 1, 1, 0, 0, 1]),\n array([0, 1, 1, 1, 0, 1, 1, 0, 0, 1]),\n array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1]),\n array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0])]\n\n\n\n_ = plt.hist(np.sum(Y, axis=1), density=True)\n\n\n\n\n\n\n\n\nL’istogramma precedente è un’approssimazione empirica della distribuzione delle proporzioni campionarie di ampiezza 10 estratte da una popolazione con probabilità di successo uguale a 0.6.\n\nprint('Media empirica della distribuzione campionaria: {}'.format(np.mean(np.mean(Y, axis=1))))\nprint('Valore teorico atteso: {}'.format(p))\n\nMedia empirica della distribuzione campionaria: 0.5986799999999999\nValore teorico atteso: 0.6\n\n\n\nprint('Stima empirica della deviazione standard: {}'.format(np.std(np.mean(Y, axis=1))))\nprint('Deviazione standard teorica: {}'.format(np.sqrt(p*(1-p)/n)))\n\nStima empirica della deviazione standard: 0.154939528849161\nDeviazione standard teorica: 0.15491933384829668\n\n\nMan mano che aumenta il numero di campioni estratti dalla popolazione, i due valori diventano sempre più simili.\nPer quel che riguarda la forma della distribuzione, come conseguenza del TLC possiamo dire che la distribuzione delle proporzioni campionarie tende sempre più ad assumere una forma normale all’aumentare della dimensione dei campioni.\nPer mettere alla prova il TLC, consideriamo un caso estremo, ovvero una popolazione nella quale la probabilità di successo è 0.03. Supponiamo che la numerosità campionaria sia uguale a 400.\n\np = 0.03\nn = 400\nX = st.bernoulli(p)\nY = [X.rvs(n) for i in range(10000)]\n\n\nprint('Media empirica della distribuzione campionaria: {}'.format(np.mean(np.mean(Y, axis=1))))\nprint('Valore teorico atteso: {}'.format(p))\n\nMedia empirica della distribuzione campionaria: 0.029917250000000003\nValore teorico atteso: 0.03\n\n\n\nprint('Stima empirica della deviazione standard: {}'.format(np.std(np.mean(Y, axis=1))))\nprint('Deviazione standard teorica: {}'.format(np.sqrt(p*(1-p)/n)))\n\nStima empirica della deviazione standard: 0.008587201373992577\nDeviazione standard teorica: 0.00852936105461599\n\n\n\nnp.mean(Y, axis=1)\n\narray([0.03  , 0.04  , 0.0275, ..., 0.045 , 0.0325, 0.035 ])\n\n\n\ny = np.mean(Y, axis=1)\nsns.distplot(y, bins=10, hist=True, kde=False, norm_hist=True, hist_kws={'edgecolor':'black'})\nx = np.linspace(0, 0.1, 1000)\ny = st.norm.pdf(x, np.mean(y), np.std(y))  # Normal density values\nplt.plot(x, y, 'r-', label='Normal Density')\n\n\n\n\n\n\n\n\n\nW.4.1 Brexit\nPrendiamo in considerazione un ulteriore relativo all’indagine BES condotta prima del referendum sulla Brexit del 2016 al fine di valutare l’opinione pubblica dell’intera popolazione del Regno Unito. Importiamo i dati.\n\nbes = pd.read_csv(\"../data/BES.csv\")\nbes.head()\n\n\n\n\n\n\n\n\nvote\nleave\neducation\nage\n\n\n\n\n0\nleave\n1.0\n3.0\n60\n\n\n1\nleave\n1.0\nNaN\n56\n\n\n2\nstay\n0.0\n5.0\n73\n\n\n3\nleave\n1.0\n4.0\n64\n\n\n4\ndon't know\nNaN\n2.0\n68\n\n\n\n\n\n\n\n\nbes.shape\n\n(30895, 4)\n\n\nEliminiamo le righe del DataFrame che contengono dati mancanti.\n\nbes_cleaned = bes.dropna()\nbes_cleaned.shape\n\n(25097, 4)\n\n\nCalcoliamo la proporzione di risposte “leave”.\n\nbes_cleaned[\"leave\"].mean()\n\n0.47188907040682154\n\n\nL’output del sondaggio BES indica che il 47.19% dei partecipanti era a favore della Brexit. Tuttavia, non possiamo inferire da questo risultato che circa il 47% di tutti gli elettori del Regno Unito era a favore della Brexit, poiché si tratta di un risultato a livello di campione. Per generalizzare a livello di popolazione, dobbiamo considerare la variabilità campionaria che introduce rumore nei nostri risultati.\nAbbiamo visto sopra che la distribuzione campionaria di una proporzione presenta le seguenti caratteristiche:\n\nLa media della distribuzione campionaria di una proporzione è uguale alla proporzione della popolazione. Ciò significa che in media, la proporzione dei valori del campione è uguale alla proporzione della popolazione.\nLa deviazione standard della distribuzione campionaria di una proporzione è calcolata come \\(\\sqrt{\\pi (1-\\pi) / n}\\), dove \\(\\pi\\) rappresenta la proporzione della popolazione e \\(n\\) è la dimensione del campione. La deviazione standard rappresenta la dispersione dei valori del campione intorno alla proporzione della popolazione. Possiamo stimare l’errore standard sostituendo \\(\\pi\\) con \\(p\\), la proporzione campionaria.\nLa distribuzione campionaria di una proporzione tende alla normale se la dimensione del campione è grande.\n\nPer fare inferenze sul parametro \\(\\pi\\) della popolazione (la proporzione di elettori del Regno Unito a favore della Brexit nel 2016), possiamo costruire un intervallo di confidenza al 95% per la proporzione nella popolazione.\nPer iniziare il calcolo dell’intervallo di confidenza, dobbiamo prima determinare la dimensione del campione.\n\nn = bes_cleaned.shape[0]\nn\n\n25097\n\n\nPossiamo stimare l’errore standard di una proporzione con la formula $ SE = . $\n\np = bes_cleaned[\"leave\"].mean()\nse = np.sqrt(p * (1 - p) / n)\nprint(se)\n\n0.0031511685382488307\n\n\nTroviamo il limite inferiore e il limite superiore dell’intervallo di fiducia al 95%.\n\npm = np.array([-1, +1])\nci = np.mean(bes_cleaned[\"leave\"]) + pm * st.norm.ppf(0.975) * se\nprint(f\"L'intervallo di fiducia al 95% è [{ci[0]:.4f}, {ci[1]:.4f}].\")\n\nL'intervallo di fiducia al 95% è [0.4657, 0.4781].\n\n\nSecondo l’approccio frequentista, è possibile affermare che la proporzione di sostegno per la Brexit tra tutti gli elettori del Regno Unito nel 2016 era compresa con una probabilità del 95% tra il 46.57% e il 47.81%. Questo intervallo di confidenza è stato ottenuto mediante una procedura di stima con un livello di confidenza del 95%, il quale indica la probabilità che l’intervallo contenga il vero valore del parametro.\nInoltre, il margine di errore, che rappresenta la metà della larghezza dell’intervallo di confidenza, è di 0.62 punti percentuali. Ciò significa che la proporzione di sostegno per la Brexit tra tutti gli elettori del Regno Unito nel 2016 era probabilmente del 47.19%, con un margine di errore di 0.62 punti percentuali.\nSi noti che il margine di errore dipende dalla dimensione del campione. Nel caso del sondaggio BES, che ha una grande dimensione del campione di 25097 osservazioni, il margine di errore è relativamente piccolo. Tuttavia, per la maggior parte dei sondaggi che hanno una dimensione del campione molto più piccola, di circa 1000 osservazioni, il margine di errore sarà molto più grande. In generale, all’aumentare della dimensione del campione, la larghezza dell’intervallo di confidenza diminuisce, e viceversa.\n\n\nW.4.2 Supporto per la Brexit ed età\nCon i dati del sondaggio BES facciamo un altro esempio relativo al confronto tra due medie indipendenti. Nello specifico, esamineremo la differenza d’età tra gli elettori che hanno espresso supporto per la Brexit e quelli che invece hanno sostenuto la posizione “stay”.\n\nsns.violinplot(x=\"leave\", y=\"age\", data=bes)\n\n\n\n\n\n\n\n\nIl violin plot rivela che l’età media dei sostenitory della posizione “leave” è più alta dell’età media del gruppo “stay”. Si noti però che le due distribuzioni non sembrano gaussiane.\nPer verificare l’ipotesi di gaussianità dei dati, usiamo un QQ-plot (Quantile-Quantile plot). Un QQ-plot è uno strumento grafico utilizzato per verificare se una distribuzione di dati segue o meno una distribuzione teorica, come ad esempio una distribuzione normale. In pratica, un QQ-plot confronta i quantili di una distribuzione di dati con quelli di una distribuzione teorica, disegnando un grafico dei quantili teorici lungo l’asse x e dei quantili dei dati lungo l’asse y. Se i dati seguono la distribuzione teorica, allora i punti nel QQ-plot si distribuiranno lungo una linea retta. Se invece ci sono deviazioni dalla distribuzione teorica, i punti nel QQ-plot si discosteranno dalla retta e si potrà individuare in che punto si verificano le maggiori deviazioni.\n\nax = pg.qqplot(bes[\"age\"], dist=\"norm\")\n\n\n\n\n\n\n\n\nSi può osservare dal QQ-plot che i valori di età estremi della distribuzione differiscono marcatamente dalle corrispondenti aspettative teoriche. Solo per fare un esecizio, proseguiamo comunque con l’analisi dei dati e applichiamo il test t di Student ai due gruppi d’età. Si noti però che, per dati non normali, una tale procedura di analisi statistica è inappropriata.\nPossiamo anche visualizzare i dati dei due gruppi tramite un KDE plot (da notare che questa rappresentazione è già inclusa nel violin plot precedente).\n\nsns.kdeplot(data=bes, x=\"age\", hue=\"leave\")\n\n\n\n\n\n\n\n\nPer agevolare il test t di Student, dividiamo il DataFrame originale in due DataFrame distinti.\n\nleave_df = bes[bes[\"leave\"] == 1]\nstay_df = bes[bes[\"leave\"] == 0]\n\nL’ipotesi nulla che viene sottoposta a verifica con il test t di Student è l’uguaglianza delle medie dei valori dell’età nelle due popolazioni da cui i campioni sono stati estratti: \\(H_0: \\mu_{\\text{leave}} = \\mu_{\\text{stay}}\\). Il test t di Student può essere facilmente eseguito utilizzando la funzione ttest del pacchetto pingouin.\n\nres = pg.ttest(leave_df[\"age\"], stay_df[\"age\"], paired=False)\nprint(res)\n\n                T           dof alternative  p-val         CI95%   cohen-d  \\\nT-test  41.588603  27738.840259   two-sided    0.0  [7.63, 8.38]  0.495062   \n\n       BF10  power  \nT-test  inf    1.0  \n\n\nSvolgiamo ora i calcoli applicando la formula del test t di Student. La statistica \\(t\\) di Student per la differenza tra le medie di due campioni indipendenti è\n\\[T = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}},\\]\ndove \\(\\bar{x}_1\\) e \\(\\bar{x}2\\) sono le medie dei due campioni, \\(s^2_1\\) e \\(s^2_2\\) sono le varianze dei due campioni e \\(n_1\\) e \\(n_2\\) sono le dimensioni dei due campioni.\n\nn_l = leave_df.shape[0]\nn_l\n\n13692\n\n\n\nn_s = stay_df.shape[0]\nn_s\n\n14352\n\n\n\nn_l + n_s - 2\n\n28042\n\n\nCalcoliamo l’errore standard della differenza delle medie di due campioni indipendenti.\n\nse = np.sqrt(\n    (np.var(leave_df[\"age\"], ddof=1) / n_l) + \n    (np.var(stay_df[\"age\"], ddof=1) / n_s)\n) \nse\n\n0.19250126816432642\n\n\nTroviamo la statistica t di Student.\n\nT = (np.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])) / se\n\nTroviamo il valore-p con la funzione t.sf che calcola l’area sottesa alla funzione \\(t\\) nella coda di destra. È importante notare che le funzioni Python che abbiamo utilizzato in precedenza calcolano i gradi di libertà in modo diverso rispetto alla formula \\(n_1+n_2-2\\). Infatti, il numero di gradi di libertà calcolato come \\(n_1+n_2-2\\) è appropriato solo quando le varianze delle due popolazioni sono uguali. Se le varianze sono diverse, è necessario introdurre un fattore di correzione, che viene calcolato mediante software. Tuttavia, per questo esercizio, procederemo con \\(n_1+n_2-2\\), poiché per un valore \\(t\\) così estremo non fa alcuna differenza.\n\n2 * st.t.sf(T, df = n_l + n_s - 2)\n\n0.0\n\n\nPoniamoci ora l’obiettivo di trovare l’intervallo di fiducia per la differenza tra le due medie. Iniziamo a trovare il valore critico della distribuzione \\(t\\) corrispondente al livello di significatività scelto.\n\nt_c = st.t.ppf(0.975, df=n_l + n_s - 2)\nt_c\n\n1.9600485852064147\n\n\nPossiamo ora trovare l’intervallo di fiducia.\n\npm = np.array([-1, +1])\nci = (np.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])) + pm * t_c * se\nprint(f\"L'intervallo di fiducia al 95% è [{ci[0]:.2f}, {ci[1]:.2f}].\")\n\nL'intervallo di fiducia al 95% è [7.63, 8.38].\n\n\nIn conclusione, l’intervallo di confidenza al 95% per la differenza di età media tra i sostenitori della Brexit e coloro che sostenevano la posizione ‘stay’ è [7.63, 8.38]. Ciò significa che, utilizzando una procedura di stima corretta nel 95% dei casi, ci si aspetta che l’età media dei sostenitori della Brexit sia 8 anni superiore a quella dei sostenitori della posizione ‘stay’, con un’incertezza di +/- 0.375 anni.\n\nnp.mean(leave_df[\"age\"]) - np.mean(stay_df[\"age\"])\n\n8.00585876624487\n\n\n\n(8.38 - 7.63) / 2\n\n0.37500000000000044",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>W</span>  <span class='chapter-title'>Esercizi sull'inferenza frequentista</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html",
    "href": "chapters/appendix/a70_predict_counts.html",
    "title": "Appendice X — La predizione delle frequenze",
    "section": "",
    "text": "X.1 La ricerca sul trauma\nPer fare un esempio di questo approccio, in questo capitolo faremo riferimento alla ricerca sul trauma. In questo campo di ricerca, come in altri, il risultato di interesse può essere rappresentato dalla frequenza del numero di episodi che si verificano in un dato periodo di tempo. Nel caso della ricerca sulla violenza domestica, ad esempio, potremmo esaminare il tasso di atti aggressivi durante l’intervallo tra un momento temporale di baseline e un’intervista di follow-up. Altri esempi di risultati esprimibili in termini di frequenze nalla ricerca post-traumatica includono la frequenza dell’abuso di sostanze durante un periodo di osservazione o il numero di interventi della polizia durante un dato periodo.\nNell’esempio seguente esamineremo l’uso della predizione bayesiana per predire il numero di aggressioni nei confronti del partner nelle relazioni di coppia. I dati presentati sono tratti da uno studio che esamina la frequenza di episodi di aggressione messi in atto da pazienti di sesso maschile che avevano recentemente iniziato un programma di trattamento dell’alcol nei confronti del loro partner di sesso femminile.\nLa frequenza degli episodi di violenza, così come altri fenomeni quantificabili in termini di frequenze assolute, può essere modellata da un processo di Poisson, che si basa sul presupposto che gli eventi siano casuali e abbiano la stessa probabilità di verificarsi in qualsiasi momento. Naturalmente, questa ipotesi non è sempre valida, ma spesso è sufficiente per la modellazione.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>X</span>  <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-priori",
    "href": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-priori",
    "title": "Appendice X — La predizione delle frequenze",
    "section": "X.2 La distribuzione a priori",
    "text": "X.2 La distribuzione a priori\nIn una ricerca sui pazienti che avevano recentemente iniziato un programma di trattamento per l’abuso o la dipendenza da alcol, {cite:t}gagnon2008poisson hanno trovato che, in un periodo di 6 mesi, il numero di assalti fisici da parte dei pazienti di genere maschile nei confronti del loro partner femminile è uguale, in media, a 11.46 (\\(SD\\) = 25.79; \\(n\\) = 114).\nPer questi dati, è dunque sensato pensare che la distribuzione del numero di episodi di aggressione fisica può essere rappresentata dalla distribuzione esponenziale.\nDal punto di vista statistico, ricordiamo che la distribuzione esponenziale modella il numero di eventi che si verificano in un intervallo di tempo quando questi eventi si verificano raramente e indipendentemente l’uno dall’altro.\nLa funzione di densità di probabilità della distribuzione esponenziale è data da:\n\\[\nf(x) = λe^{(-λx)}\n\\]\ndove λ è il parametro della distribuzione e rappresenta il tasso medio di occorrenza degli eventi. La media e la varianza della distribuzione esponenziale sono entrambe uguali a 1/λ.\nPoniamoci dunque il problema di rappresentare le nostre credenze a priori relative al numero di episodi di aggressione fisica mediante una distribuzione esponenziale.\nDalla ricerca di {cite:t}gagnon2008poisson sappiamo che, in un periodo di 6 mesi, il numero di assalti fisici nei confronti del partner femminile, in questa popolazione, è uguale a 11.46.\nConsidereremo una distribuzione esponenziale per rappresentare le nostre credenze a priori circa la frequenza media \\(\\mu\\) degli episodi di aggressione nei confronti del partner per questa popolazione, in un periodo di 6 mesi. In Python, scipy.stats.expon è un modulo che fornisce funzioni per lavorare con la distribuzione esponenziale. In particolare, la funzione pdf (probability density function) calcola la funzione di densità di probabilità della distribuzione esponenziale per un dato valore di x.\nLa sintassi per utilizzare questa funzione è la seguente:\nscipy.stats.expon.pdf(x, loc=0, scale=1)\ndove x è il valore per il quale si vuole calcolare la funzione di densità di probabilità. Il parametro loc(opzionale) e scale specificano rispettivamente la posizione e la scala della distribuzione. La posizione (loc) di solito è impostata a 0, mentre la scala (scale) è l’inverso del parametro λ della distribuzione esponenziale. In altre parole, la scala è uguale alla media della distribuzione esponenziale.\nPer il caso presente, dunque, se vogliamo che la distribuzione esponenziale abbia una media di 11.46, procediamo come indicato sotto\n\nx = np.linspace (0, 50, 100) \ny = st.expon.pdf(x, 0, 11.46)\nplt.plot(x, y);\n\n\n\n\n\n\n\n\nPer verificare che abbiamo implementato correttamente la funzione esponenziale con il parametro voluto, estraiamo un grande numero di realizzazioni della v.c. e calcoliamo la media.\n\nr = st.expon.rvs(0, 11.46, size=100000)\nr.mean()\n\n11.438957034038369",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>X</span>  <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#inferenza-bayesiana",
    "href": "chapters/appendix/a70_predict_counts.html#inferenza-bayesiana",
    "title": "Appendice X — La predizione delle frequenze",
    "section": "X.3 Inferenza bayesiana",
    "text": "X.3 Inferenza bayesiana\nUna volta capito come descrivere le nostre credenze a priori, poniamoci il problema di usare PyMC per l’inferenza Bayesiana.\nConsideriamo un singlo individuo di genere maschile appartenente a questa popolazione. Se, in media, in 6 mesi ci aspettiamo un numero di episodi di violenza pari a 11.46, possiamo descrivere il numero di episodi di violenza per un singolo individuo con la seguente distribuzione esponenziale. Si noti che, in questo caso, la funzione pm.Exponential è parametrizzata usando il parametro l che è uguale a \\(\\lambda = 1/ \\mu\\).\n\nl = 1/11.46\n\nwith pm.Model() as model:\n    mu = pm.Exponential(\"mu\", l)\n    idata = pm.sample_prior_predictive(samples=10000, random_seed=rng)\n\nSampling: [mu]\n\n\nEsaminiamo 10000 campioni casuali estratti dalla distribuzione a priori. Il risultato è simile alla distribuzione di densità teorica rappresentata nel grafico precedente.\n\n_ = az.plot_posterior(idata.prior.mu);\n\n\n\n\n\n\n\n\nSi noti che, in questo caso, stiamo usando una distribuzione a priori informativa.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>X</span>  <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-verosimiglianza",
    "href": "chapters/appendix/a70_predict_counts.html#la-verosimiglianza",
    "title": "Appendice X — La predizione delle frequenze",
    "section": "X.4 La verosimiglianza",
    "text": "X.4 La verosimiglianza\nAdesso inseriamo nel modello PyMC la verosimiglianza.\nIn questo caso, usiamo quale modello generativo dei dati una distribuzione di Poisson.\nLe distribuzioni di Poisson sono usate per modellare il numero di eventi rari che si verificano in un intervallo di tempo fisso. Ad esempio, il numero di episodi di comportamento inappropriato per settimana in individui con disturbi alimentari, nascite in un giorno o incidenti in una settimana.\nLa verosimiglianza di Poisson è simile a quella binomiale, ma non ha un limite superiore al numero di successi.\nPer esempio, consideriamo un paziente chiamato Mario. Usando gli item della sottoscala relativa agli episodi di violenza fisica della Conflict Tactics Scales-2, troviamo che Mario ha avuto 8 episodi violenti nei confronti del partner negli ultimi 6 mesi.\nInseriamo questa informazione nel modello bayesiano usando 8 come dato che specifica una verosimiglianza di Poisson con parametro sconosciuto mu, a cui abbiamo attribuito una distribuzione a priori esponenziale ed eseguiamo il campionamento.\n\nwith pm.Model() as model:\n    mu = pm.Exponential(\"mu\", l)\n    episodes = pm.Poisson(\"episodes\", mu, observed=8)\n    idata2 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:11&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 11 seconds.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>X</span>  <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-posteriori",
    "href": "chapters/appendix/a70_predict_counts.html#la-distribuzione-a-posteriori",
    "title": "Appendice X — La predizione delle frequenze",
    "section": "X.5 La distribuzione a posteriori",
    "text": "X.5 La distribuzione a posteriori\nEstraiamo dall’oggetto idata2 i campioni della distribuzione a posteriori del parametro mu (media del numero di episodi di violenza negli ultimi 6 mesi).\n\nsample_posterior = idata2.posterior['mu']\n\nGeneriamo un grafico della distribuzione a posteriori del parametro mu.\n\naz.plot_posterior(sample_posterior)\n\n\n\n\n\n\n\n\nPossiamo dunque concludere, con un livello di certezza soggettiva del 94%, che per Mario, il numero di episodi di violenza nei confronti del partner varierà da un minimo di 3.5 ad un massimo di 13, in un periodo di 6 mesi, con una media di 8.2.\nSupponiamo ora di volere confrontare due individui, Mario e Paolo. Di Mario abbiamo osservato 8 episodi di violenza in 6 mesi; di Paolo abbiamo osservato 12 episodi di violenza negli ultimi 6 mesi. Possiamo dire che Paolo è più violento di Mario? Oppure dobbiamo pensare che la differenza tra i due sia solo una fluttuazione casuale?\nScriviamo il modello bayesiano nel modo seguente, usando sempre la distribuzione a priori che abbiamo definito in precedenza.\n\nwith pm.Model() as model3:\n    mu_A = pm.Exponential(\"mu_A\", l)\n    mu_B = pm.Exponential(\"mu_B\", l)\n    episodes_A = pm.Poisson(\"episodes_A\", mu_A, observed=[8])\n    episodes_B = pm.Poisson(\"episodes_B\", mu_B, observed=[12])\n    idata3 = pm.sample(2000)\n\nAuto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [mu_A, mu_B]\n\n\n\n\n\n\n\n    \n      \n      100.00% [12000/12000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n    \n    \n\n\nSampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 36 seconds.\n\n\nEsaminiamo le distribuzioni a posteriori dei parametri mu_A e mu_B che rappresentano la media del numero di episodi di violenza per i due individui.\n\nwith model3:\n    az.plot_trace(idata3, kind=\"rank_bars\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nEstraiamo le distribuzioni a posteriori dei due parametri da idata3.\n\nmu_A = idata3.posterior['mu_A']\nmu_B = idata3.posterior['mu_B']\nmu_B.mean(), mu_A.mean()\n\n(&lt;xarray.DataArray 'mu_B' ()&gt;\n array(11.98949309),\n &lt;xarray.DataArray 'mu_A' ()&gt;\n array(8.26997179))\n\n\nRappresentiamo graficamente le due distribuzioni a posteriori.\n\naz.plot_posterior(mu_A)\naz.plot_posterior(mu_B);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVogliamo eseguire un test di ipotesi bayesiano per determinare la probabilità che la media del numero di episodi di violenza di Mario sia maggiore di quella di Paolo. Per fare ciò, calcoliamo quante volte mu_B è maggiore di mu_A nelle due distribuzioni a posteriori.\n\n(mu_B &gt; mu_A).mean()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray ()&gt;\narray(0.808)xarray.DataArray0.808array(0.808)Coordinates: (0)Indexes: (0)Attributes: (0)\n\n\nPossiamo dunque dire che, se confrontiamo i valori dei parametri delle due distribuzioni a posteriori, nell’81% di casi risulta che Paolo è più violento di Mario.\nIl grafico seguente mostra le stime degli intervalli di credibilità del 94% per ciascuna delle 4 catene, pe i due parametri.\n\n_ = az.plot_forest(idata3, var_names=[\"mu_A\", \"mu_B\"])\n\n\n\n\n\n\n\n\nDato che gli intervalli di credibilità sono sovrapposti, concludiamo che non ci sono evidenze credibili di una differenza. Ovvero, sulla base delle nostre credenze a priori e sulla base dei dati osservati, ad un livello di certezza soggettiva del 94%, non possiamo concludere che Paolo sia più violento di Mario.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>X</span>  <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/a70_predict_counts.html#la-predizione-di-episodi-di-violenza-futuri",
    "href": "chapters/appendix/a70_predict_counts.html#la-predizione-di-episodi-di-violenza-futuri",
    "title": "Appendice X — La predizione delle frequenze",
    "section": "X.6 La predizione di episodi di violenza futuri",
    "text": "X.6 La predizione di episodi di violenza futuri\nConsideriamo ora il problema della predizione di dati futuri. Utilizziamo nuovamente il modello che abbiamo già usato in precedenza, ovvero model3.\nCreiamo la distribuzione predittiva a posteriori per il parametro mu_A, ovvero la media del numero di eventi di violenza attesi in futuro per Mario.\n\nwith model3:\n    post_pred = pm.sample_posterior_predictive(idata3)\n\nSampling: [episodes_A, episodes_B]\n\n\n\n\n\n\n\n    \n      \n      100.00% [8000/8000 00:00&lt;00:00]\n    \n    \n\n\n\npost_pred\n\n\n            \n              \n                arviz.InferenceData\n              \n              \n              \n            \n                  \n                  posterior_predictive\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (chain: 4, draw: 2000, episodes_A_dim_2: 1,\n                       episodes_B_dim_2: 1)\nCoordinates:\n  * chain             (chain) int64 0 1 2 3\n  * draw              (draw) int64 0 1 2 3 4 5 ... 1994 1995 1996 1997 1998 1999\n  * episodes_A_dim_2  (episodes_A_dim_2) int64 0\n  * episodes_B_dim_2  (episodes_B_dim_2) int64 0\nData variables:\n    episodes_A        (chain, draw, episodes_A_dim_2) int64 1 4 12 ... 6 10 11\n    episodes_B        (chain, draw, episodes_B_dim_2) int64 18 13 4 ... 14 14 17\nAttributes:\n    created_at:                 2023-10-27T04:56:02.607337\n    arviz_version:              0.16.1\n    inference_library:          pymc\n    inference_library_version:  5.9.1xarray.DatasetDimensions:chain: 4draw: 2000episodes_A_dim_2: 1episodes_B_dim_2: 1Coordinates: (4)chain(chain)int640 1 2 3array([0, 1, 2, 3])draw(draw)int640 1 2 3 4 ... 1996 1997 1998 1999array([   0,    1,    2, ..., 1997, 1998, 1999])episodes_A_dim_2(episodes_A_dim_2)int640array([0])episodes_B_dim_2(episodes_B_dim_2)int640array([0])Data variables: (2)episodes_A(chain, draw, episodes_A_dim_2)int641 4 12 14 7 4 1 ... 9 13 11 6 10 11array([[[ 1],\n        [ 4],\n        [12],\n        ...,\n        [ 6],\n        [13],\n        [ 7]],\n\n       [[12],\n        [12],\n        [ 4],\n        ...,\n        [ 4],\n        [ 6],\n        [15]],\n\n       [[ 9],\n        [ 4],\n        [ 8],\n        ...,\n        [ 9],\n        [ 5],\n        [12]],\n\n       [[22],\n        [ 3],\n        [ 7],\n        ...,\n        [ 6],\n        [10],\n        [11]]])episodes_B(chain, draw, episodes_B_dim_2)int6418 13 4 6 10 8 ... 9 22 7 14 14 17array([[[18],\n        [13],\n        [ 4],\n        ...,\n        [13],\n        [10],\n        [18]],\n\n       [[ 7],\n        [11],\n        [ 6],\n        ...,\n        [ 5],\n        [13],\n        [ 4]],\n\n       [[ 8],\n        [ 5],\n        [22],\n        ...,\n        [16],\n        [11],\n        [14]],\n\n       [[20],\n        [10],\n        [12],\n        ...,\n        [14],\n        [14],\n        [17]]])Indexes: (4)chainPandasIndexPandasIndex(Index([0, 1, 2, 3], dtype='int64', name='chain'))drawPandasIndexPandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n       ...\n       1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999],\n      dtype='int64', name='draw', length=2000))episodes_A_dim_2PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_A_dim_2'))episodes_B_dim_2PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_B_dim_2'))Attributes: (4)created_at :2023-10-27T04:56:02.607337arviz_version :0.16.1inference_library :pymcinference_library_version :5.9.1\n                      \n                  \n            \n            \n            \n                  \n                  observed_data\n                  \n                  \n                      \n                          \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:           (episodes_A_dim_0: 1, episodes_B_dim_0: 1)\nCoordinates:\n  * episodes_A_dim_0  (episodes_A_dim_0) int64 0\n  * episodes_B_dim_0  (episodes_B_dim_0) int64 0\nData variables:\n    episodes_A        (episodes_A_dim_0) int64 8\n    episodes_B        (episodes_B_dim_0) int64 12\nAttributes:\n    created_at:                 2023-10-27T04:56:02.610237\n    arviz_version:              0.16.1\n    inference_library:          pymc\n    inference_library_version:  5.9.1xarray.DatasetDimensions:episodes_A_dim_0: 1episodes_B_dim_0: 1Coordinates: (2)episodes_A_dim_0(episodes_A_dim_0)int640array([0])episodes_B_dim_0(episodes_B_dim_0)int640array([0])Data variables: (2)episodes_A(episodes_A_dim_0)int648array([8])episodes_B(episodes_B_dim_0)int6412array([12])Indexes: (2)episodes_A_dim_0PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_A_dim_0'))episodes_B_dim_0PandasIndexPandasIndex(Index([0], dtype='int64', name='episodes_B_dim_0'))Attributes: (4)created_at :2023-10-27T04:56:02.610237arviz_version :0.16.1inference_library :pymcinference_library_version :5.9.1\n                      \n                  \n            \n            \n              \n            \n            \n\n\nRappresentiamo la distribuzione predittiva a posteriori di mu_A con un istogramma.\n\n_ = az.plot_posterior(post_pred.posterior_predictive.episodes_A, hdi_prob=0.94)\n\n\n\n\n\n\n\n\nFacciamo la stessa cosa per Paolo.\n\n_ = az.plot_posterior(post_pred.posterior_predictive.episodes_B, hdi_prob=0.94)\n\n\n\n\n\n\n\n\nIn base alle nostre credenze precedenti e ai dati osservati negli ultimi 6 mesi, possiamo aspettarci con una certezza soggettiva del 94% che nei prossimi 6 mesi Mario avrà tra 1 e 15 episodi di violenza, mentre Paolo ne avrà tra 3 e 20.",
    "crumbs": [
      "Appendici",
      "<span class='chapter-number'>X</span>  <span class='chapter-title'>La predizione delle frequenze</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_probability.html",
    "href": "chapters/appendix/solutions_probability.html",
    "title": "Appendice Y — Probabilità",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nimport math\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 27\nEsercizio 27.1\nPer calcolare questa probabilità in maniera analitica, utilizziamo la seguente uguaglianza:\n\\[\nP(\\text{almeno 2 psicologi clinici}) = 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}).\n\\]\nIl numero totale di modi per selezionare 5 persone dal gruppo di 20 è dato da:\n\\[\n\\binom{20}{5} = \\frac{20!}{5!(15!)} = 15,504.\n\\]\nIl numero di modi per avere nessun psicologo clinico nella commissione (ovvero, selezionare solo psicologi del lavoro) è:\n\\[\n\\binom{10}{0} \\times \\binom{10}{5} = 1 \\times 252 = 252.\n\\]\nQuindi, la probabilità di avere nessun psicologo clinico è:\n\\[\nP(\\text{nessun psicologo clinico}) = \\frac{252}{15,504} \\approx 0.016.\n\\]\nIl numero di modi per avere esattamente 1 psicologo clinico nella commissione è:\n\\[\n\\binom{10}{1} \\times \\binom{10}{4} = 10 \\times 210 = 2,100.\n\\]\nQuindi, la probabilità di avere esattamente 1 psicologo clinico è:\n\\[\nP(\\text{1 psicologo clinico}) = \\frac{2,100}{15,504} \\approx 0.135.\n\\]\nLa probabilità di avere almeno 2 psicologi clinici nella commissione è quindi:\n\\[\n\\begin{align}\nP(\\text{almeno 2 psicologi clinici}) &= 1 - P(\\text{nessun psicologo clinico}) - P(\\text{1 psicologo clinico}) \\notag\\\\\n&= 1 - 0.016 - 0.135 \\notag\\\\\n&= 0.848.\\notag\n\\end{align}\n\\]\nQuindi, la probabilità che almeno 2 psicologi clinici siano nella commissione è circa 0.848.\n\n# Funzione per calcolare le combinazioni\ndef nCk(n, k):\n    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n\n\n# Calcolo delle probabilità per il problema della commissione\ntotal_ways = nCk(20, 5)\nno_clinical = nCk(10, 0) * nCk(10, 5)\none_clinical = nCk(10, 1) * nCk(10, 4)\n\np_no_clinical = no_clinical / total_ways\np_one_clinical = one_clinical / total_ways\n\np_at_least_two_clinical = 1 - p_no_clinical - p_one_clinical\n\nprint(f\"Probabilità di almeno 2 psicologi clinici: {p_at_least_two_clinical:.3f}\")\n\nProbabilità di almeno 2 psicologi clinici: 0.848\n\n\nIn maniera più intuitiva, possiamo risolvere il problema con una simulazione Monte Carlo.\n\nimport random\n\n# Numero di simulazioni\nsimulations = 1000000\n\n# Numero di successi (almeno 2 psicologi clinici nella commissione)\nsuccess_count = 0\n\n# Creiamo una lista che rappresenta il gruppo di 20 persone\n# 1 rappresenta un psicologo clinico, 0 rappresenta un psicologo del lavoro\ngroup = [1] * 10 + [0] * 10\n\n# Simulazione Monte Carlo\nfor _ in range(simulations):\n    # Estrai casualmente 5 persone dal gruppo\n    committee = random.sample(group, 5)\n\n    # Conta quanti psicologi clinici ci sono nella commissione\n    num_clinical_psychologists = sum(committee)\n\n    # Verifica se ci sono almeno 2 psicologi clinici\n    if num_clinical_psychologists &gt;= 2:\n        success_count += 1\n\n# Calcola la probabilità\nprobability = success_count / simulations\n\n# Mostra il risultato\nprint(\n    f\"La probabilità che almeno 2 psicologi clinici siano nella commissione è: {probability:.4f}\"\n)\n\nLa probabilità che almeno 2 psicologi clinici siano nella commissione è: 0.8482\n\n\n\n\nCapitolo 39\nEsercizio 39.1\nPer calcolare le deviazioni standard delle distribuzioni gaussiane date le percentuali di studenti che ottengono meno di 18, possiamo utilizzare le proprietà della distribuzione normale e i quantili della distribuzione normale standard (distribuzione normale con media 0 e deviazione standard 1).\nLe distribuzioni normali hanno la proprietà che possiamo trasformare qualsiasi valore \\(X\\) della distribuzione \\(N(\\mu, \\sigma)\\) nella distribuzione normale standard \\(N(0, 1)\\) tramite la formula:\n\\[ Z = \\frac{X - \\mu}{\\sigma}, \\]\ndove \\(Z\\) è il quantile standardizzato.\nPer trovare il valore di \\(\\sigma\\) dato un certo percentile, utilizziamo l’inverso della funzione di distribuzione cumulativa (CDF) della distribuzione normale standard. Per un dato percentile \\(p\\), \\(z_p\\) è tale che:\n\\[ p = P(Z \\leq z_p) \\]\nQuindi possiamo trovare \\(\\sigma\\) risolvendo per \\(\\sigma\\) nella formula:\n\\[ z_p = \\frac{X - \\mu}{\\sigma}, \\]\n\\[ \\sigma = \\frac{X - \\mu}{z_p}, \\]\ndove:\n\n\\(X\\) è il punteggio di soglia (18 in questo caso).\n\\(\\mu\\) è la media della distribuzione.\n\\(z_p\\) è il quantile della distribuzione normale standard per il percentile \\(p\\).\n\nI quantili della distribuzione normale standard per i percentili desiderati sono:\n\nPer il 15%, il quantile è \\(z_{0.15} \\approx -1.036\\).\nPer il 10%, il quantile è \\(z_{0.10} \\approx -1.281\\).\nPer il 5%, il quantile è \\(z_{0.05} \\approx -1.645\\).\n\nPrima Prova\n\nMedia: \\(\\mu = 24\\)\nPercentuale che ottiene meno di 18: 15%\nQuantile: \\(z_{0.15} = -1.036\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_1 = \\frac{24 - 18}{1.036} \\approx 5.79 \\]\nSeconda Prova\n\nMedia: \\(\\mu = 25\\)\nPercentuale che ottiene meno di 18: 10%\nQuantile: \\(z_{0.10} = -1.281\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_2 = \\frac{25 - 18}{1.281} \\approx 5.46 \\]\nTerza Prova\n\nMedia: \\(\\mu = 26\\)\nPercentuale che ottiene meno di 18: 5%\nQuantile: \\(z_{0.05} = -1.645\\)\nSoglia: \\(X = 18\\)\n\n\\[ \\sigma_3 = \\frac{26 - 18}{1.645} \\approx 4.86 \\]\n\n# Funzione per calcolare la deviazione standard data la media, la soglia e il quantile\ndef calculate_std(mean, threshold, quantile):\n    return abs((mean - threshold) / quantile)\n\n\n# Parametri delle distribuzioni gaussiane per le tre prove\nmean_test1 = 24\nstd_test1 = calculate_std(mean_test1, 18, -1.036)\nmean_test2 = 25\nstd_test2 = calculate_std(mean_test2, 18, -1.281)\nmean_test3 = 26\nstd_test3 = calculate_std(mean_test3, 18, -1.645)\n\n# Numero di studenti\nn_students = 220\n\n# Percentuale di studenti che non fa le prove\ndrop_test1 = 0.10\ndrop_test2 = 0.05\n\n# Seed per il generatore di numeri casuali basato sulla stringa \"simulation\"\nseed = sum(map(ord, \"simulation\"))\nrng = np.random.default_rng(seed=seed)\n\n# Generazione dei voti per le tre prove\n# Genera i voti solo per gli studenti che partecipano alla prova\ntest1_scores = np.where(\n    rng.random(n_students) &gt; drop_test1,\n    rng.normal(mean_test1, std_test1, n_students),\n    np.nan,\n)\ntest2_scores = np.where(\n    rng.random(n_students) &gt; drop_test2,\n    rng.normal(mean_test2, std_test2, n_students),\n    np.nan,\n)\ntest3_scores = rng.normal(mean_test3, std_test3, n_students)\n\n# Calcola il voto finale solo per gli studenti che hanno partecipato a tutte e tre le prove\nfinal_scores = np.nanmean(\n    np.column_stack((test1_scores, test2_scores, test3_scores)), axis=1\n)\n\n# Filtra gli studenti che non hanno partecipato a tutte e tre le prove\nvalid_final_scores = final_scores[~np.isnan(final_scores)]\n\n# Visualizzazione della distribuzione finale dei voti\nplt.hist(valid_final_scores, bins=30, edgecolor=\"black\")\nplt.title(\"Distribuzione dei voti finali\")\nplt.xlabel(\"Voto finale\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n# Statistiche descrittive dei voti finali\nmean_final_score = np.mean(valid_final_scores)\nmedian_final_score = np.median(valid_final_scores)\nstd_final_score = np.std(valid_final_scores)\n\nprint(f\"Media dei voti finali: {mean_final_score:.2f}\")\nprint(f\"Mediana dei voti finali: {median_final_score:.2f}\")\nprint(f\"Deviazione standard dei voti finali: {std_final_score:.2f}\")",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>Y</span>  <span class='chapter-title'>Probabilità</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_bayesian_inference.html",
    "href": "chapters/appendix/solutions_bayesian_inference.html",
    "title": "Appendice Z — Inferenza bayesiana",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n\nCapitolo 42\nEsercizio 42.1\nimport numpy as np\nfrom scipy.stats import binom\n\n# Definire i parametri del problema\nn = 100  # numero di studi\nk = 20   # numero di studi che hanno condiviso i materiali\n\n# Discretizzazione della probabilità theta\ntheta_grid = np.array([0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95])\n\n# Distribuzione a priori\nprior_probs = np.array([0.05, 0.20, 0.30, 0.15, 0.10, 0.08, 0.05, 0.03, 0.02, 0.02])\n\n# Calcolo della verosimiglianza per ciascuna theta\nlikelihood = binom.pmf(k, n, theta_grid)\n\n# Distribuzione a posteriori (non normalizzata)\nposterior_unnorm = likelihood * prior_probs\n\n# Normalizzazione della distribuzione a posteriori\nposterior_probs = posterior_unnorm / np.sum(posterior_unnorm)\n\n# Calcolo della media a posteriori\nposterior_mean = np.sum(posterior_probs * theta_grid)\n\n# Estrazione di un campione casuale dalla distribuzione a posteriori\nnp.random.seed(42)  # per la riproducibilità\nposterior_sample = np.random.choice(theta_grid, size=10000, p=posterior_probs)\n\n# Calcolo dell'intervallo di credibilità al 89%\ncred_interval = np.percentile(posterior_sample, [5.5, 94.5])\n\nposterior_mean, cred_interval\nLa soluzione dell’esercizio basato sul metodo della griglia fornisce i seguenti risultati:\n\nMedia della distribuzione a posteriori: 0.2152\nIntervallo di credibilità al 89%: [0.15, 0.25]\n\nQuesti risultati indicano che, dopo aver osservato i dati e aver considerato la distribuzione a priori, la probabilità stimata che uno studio condivida i materiali di ricerca è circa il 21.5%, con un intervallo di credibilità all’89% che va dal 15% al 25%.\n\n\nCapitolo 44\nEsercizio 44.1\nimport scipy.stats as stats\nimport numpy as np\n\n# Dati forniti\nalpha_prior = 31.91\nbeta_prior = 100 - 31.91  # 100 - successo = insuccesso\n\n# Parametri per la distribuzione a priori\na_prior = alpha_prior\nb_prior = beta_prior\n\n# Parametri per il calcolo della distribuzione a posteriori\nn_observations = 152\n\n# Scenario (a): tasso di successo del 60%\nsuccesses_a = 0.60 * n_observations\n\n# Scenario (b): tasso di successo del 96%\nsuccesses_b = 0.96 * n_observations\n\n# Calcolo della distribuzione a posteriori\na_posterior_a = a_prior + successes_a\nb_posterior_a = b_prior + (n_observations - successes_a)\n\na_posterior_b = a_prior + successes_b\nb_posterior_b = b_prior + (n_observations - successes_b)\n\n# Distribuzioni beta a posteriori\nx = np.linspace(0, 1, 1000)\nposterior_a = stats.beta.pdf(x, a_posterior_a, b_posterior_a)\nposterior_b = stats.beta.pdf(x, a_posterior_b, b_posterior_b)\n\na_posterior_a, b_posterior_a, a_posterior_b, b_posterior_b\nLa risoluzione del problema ha portato al calcolo delle distribuzioni a posteriori nei due scenari specificati, utilizzando il metodo delle famiglie coniugate.\nScenario (a): Tasso di successo del 60%\n\nParametri della distribuzione a posteriori:\n\n\\(\\alpha_{\\text{post}} = 123.11\\)\n\\(\\beta_{\\text{post}} = 128.89\\)\n\n\nScenario (b): Tasso di successo del 96%\n\nParametri della distribuzione a posteriori:\n\n\\(\\alpha_{\\text{post}} = 177.83\\)\n\\(\\beta_{\\text{post}} = 74.17\\)\n\n\nIn entrambi gli scenari, i parametri \\(\\alpha_{\\text{post}}\\) e \\(\\beta_{\\text{post}}\\) determinano le forme delle distribuzioni a posteriori, che ci forniscono informazioni aggiornate su \\(\\theta\\) (il tasso di successo) dopo aver osservato i dati.\nCommento sui Risultati\n\nScenario (a): Con un tasso di successo osservato del 60%, la distribuzione a posteriori riflette una moderata concentrazione attorno a \\(\\theta = 0.49\\), suggerendo una certa incertezza nella stima del vero tasso di successo, ma comunque compatibile con la distribuzione a priori basata sugli studi preregistrati.\nScenario (b): Con un tasso di successo osservato del 96%, la distribuzione a posteriori è fortemente concentrata verso l’alto, con un valore medio di \\(\\theta\\) che si avvicina a 0.71. Questo scenario riflette una maggiore confidenza in un tasso di successo elevato, pur risultando in una distribuzione molto diversa rispetto alla distribuzione a priori.\n\nQuesti risultati mostrano come i dati osservati influenzino la nostra stima del tasso di successo, con la distribuzione a priori che viene “aggiornata” in base alle osservazioni fatte. In particolare, lo scenario con il 96% di successo evidenzia una netta discrepanza rispetto alla distribuzione a priori, suggerendo che i risultati ottenuti potrebbero essere molto più ottimistici rispetto alla base di riferimento data dagli studi preregistrati.\nEsercizio 44.2\nSia \\(\\theta\\) la probabilità di nascita di una femmina dato il caso di placenta previa. Se utilizziamo una distribuzione a priori uniforme per \\(\\theta\\) (Beta(1, 1)), allora il problema si riduce a trovare la distribuzione a posteriori per \\(\\theta\\) nel contesto di un modello beta-binomiale. La distribuzione a posteriori risulta essere una Beta(y + \\(\\alpha_{\\text{prior}}\\), N - y + \\(\\beta_{\\text{prior}}\\)), ovvero una Beta(438, 544). Possiamo calcolare la media a posteriori di \\(\\theta\\) nel modo seguente:\n\nbirths = 987\nfem_births = 437\nstats.beta.mean(fem_births + 1, births - fem_births + 1).round(3)\n\n0.443\n\n\nPossiamo anche simulare un campione dalla distribuzione a posteriori per fare inferenze.\n\nposterior_sample = stats.beta.rvs(size=10000, a=fem_births + 1, b=births - fem_births + 1)\n\nsns.histplot(posterior_sample, alpha=0.5, stat=\"density\")\n_ = plt.xlabel(r\"$\\theta$\")\nplt.axvline(0.485, color=\"gray\", linestyle=\"--\")\n\nplt.annotate(\n    \"Proporzione di nascite femminili\\nnella popolazione generale\",\n    xy=(0.485, 20),  # Posizione dell'annotazione (x, y)\n    xytext=(0.5, 0.95),  # Posizione del testo dell'annotazione\n    textcoords=\"axes fraction\",\n    arrowprops=dict(facecolor=\"black\", arrowstyle=\"-&gt;\"),\n    horizontalalignment=\"left\",\n)\n\nText(0.5, 0.95, 'Proporzione di nascite femminili\\nnella popolazione generale')\n\n\n\n\n\n\n\n\n\n\nnp.quantile(posterior_sample, [0.025, 0.975]).round(3)\n\narray([0.411, 0.473])\n\n\nRiassunti precisi della distribuzione a posteriori possono essere ottenuti dalle proprietà della distribuzione beta. I quantili esatti della distribuzione a posteriori possono essere calcolati tramite integrazione numerica della densità beta; la mediana risulta essere 0.446 e l’intervallo centrale di credibilità al 95% è [0.415, 0.477].\nIn conclusione, possiamo affermare con un livello di certezza soggettiva del 95% che la proporzione di nascite femminili nella popolazione con placenta previa è inferiore alla proporzione di nascite femminili nella popolazione generale.\nEsercizio 44.3\n\n# Parametri della distribuzione Beta\nalpha_prior = 48.5\nbeta_prior = 51.5\n\n# Creazione dei valori x su cui valutare la distribuzione Beta\nx = np.linspace(0, 1, 1000)\n\n# Valutazione della densità di probabilità Beta su x\ny = stats.beta.pdf(x, alpha_prior, beta_prior)\n\n# Creazione del grafico\nplt.plot(x, y, color=\"rebeccapurple\")\nplt.fill_between(x, y, alpha=0.3)\nplt.xlim(0, 1)\nplt.ylim(0, max(y) + 0.05)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribuzione Beta(48.5, 51.5)\")\nplt.legend()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_10074/1642415141.py:19: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend()\n\n\n\n\n\n\n\n\n\n\nbirths = 987\nfem_births = 437\n\nposterior_sample = stats.beta.rvs(\n    size=10000, a=fem_births + alpha_prior, b=births - fem_births + beta_prior\n)\n\nsns.histplot(posterior_sample, alpha=0.5, stat=\"density\")\n_ = plt.xlabel(r\"$\\theta$\")\nplt.axvline(0.485, color=\"gray\", linestyle=\"--\")\n\nplt.annotate(\n    \"Proporzione di nascite femminili\\nnella popolazione generale\",\n    xy=(0.485, 20),  # Posizione dell'annotazione (x, y)\n    xytext=(0.5, 0.95),  # Posizione del testo dell'annotazione\n    textcoords=\"axes fraction\",\n    arrowprops=dict(facecolor=\"black\", arrowstyle=\"-&gt;\"),\n    horizontalalignment=\"left\",\n)\n\nText(0.5, 0.95, 'Proporzione di nascite femminili\\nnella popolazione generale')\n\n\n\n\n\n\n\n\n\n\nnp.quantile(posterior_sample, [0.025, 0.975]).round(3)\n\narray([0.417, 0.476])\n\n\nI risultati replicano sostanzialmente quelli ottenuti nell’Esercizio 44.2.\nEsercizio 44.4\nPer risolvere il problema utilizzando il modello beta-binomiale e calcolare la distribuzione a posteriori, seguiamo i seguenti passaggi.\n\nAbbiamo un campione di 202 soggetti adulti italiani, e 6.4% di questi sono mancini. Ciò significa che il numero di mancini osservati è \\(y = 0.064 \\times 202 = 12.928\\), che approssimiamo a \\(y = 13\\).\nLa prior informativa basata sullo studio di Papadatou-Pastou et al. (2020) è espressa come una distribuzione Beta(8, 60).\n\nNel modello beta-binomiale, se abbiamo una prior \\(\\text{Beta}(\\alpha_{\\text{prior}}, \\beta_{\\text{prior}})\\), e osserviamo \\(y\\) successi su \\(N\\) tentativi, la distribuzione a posteriori sarà:\n\\[\n\\text{Beta}(\\alpha_{\\text{post}} = \\alpha_{\\text{prior}} + y, \\, \\beta_{\\text{post}} = \\beta_{\\text{prior}} + N - y)\n\\]\nIn questo caso:\n\n\\(\\alpha_{\\text{prior}} = 8\\)\n\\(\\beta_{\\text{prior}} = 60\\)\n\\(y = 13\\)\n\\(N = 202\\)\n\nQuindi i parametri della distribuzione a posteriori saranno:\n\\[\n\\alpha_{\\text{post}} = 8 + 13 = 21\n\\]\n\\[\n\\beta_{\\text{post}} = 60 + 202 - 13 = 249\n\\]\nLa distribuzione a posteriori è dunque una Beta(21, 249).\nQuesta distribuzione a posteriori riflette la nostra credenza aggiornata sulla proporzione di mancini nella popolazione italiana, tenendo conto sia delle evidenze dello studio di Gori et al. (2024) che delle informazioni pregresse della meta-analisi di Papadatou-Pastou et al. (2020).\nPer visualizzare questa distribuzione a posteriori, possiamo utilizzare Python:\n\n# Parametri della distribuzione Beta a posteriori\nalpha_post = 21\nbeta_post = 249\n\n# Creazione dei valori x su cui valutare la distribuzione Beta\nx = np.linspace(\n    0, 0.2, 1000\n)  # Si concentra la visualizzazione nell'intervallo plausibile\n\n# Valutazione della densità di probabilità Beta su x\ny = stats.beta.pdf(x, alpha_post, beta_post)\n\n# Creazione del grafico\nplt.plot(x, y)\nplt.fill_between(x, y, alpha=0.3)\nplt.xlim(0, 0.2)\nplt.ylim(0, max(y) + 0.5)\nplt.xlabel(r\"$\\theta$\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribuzione a Posteriori Beta(21, 249)\")\nplt.legend()\nplt.show()\n\n/var/folders/s7/z86r4t9j6yx376cm120nln6w0000gn/T/ipykernel_10074/519876995.py:21: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n  plt.legend()\n\n\n\n\n\n\n\n\n\nPossiamo anche calcolare la media e la varianza della distribuzione a posteriori:\n\nMedia a posteriori:\n\n\\[\n\\mu_{\\text{post}} = \\frac{\\alpha_{\\text{post}}}{\\alpha_{\\text{post}} + \\beta_{\\text{post}}} = \\frac{21}{21 + 249} = 0.077\n\\]\n\nVarianza a posteriori:\n\n\\[\n\\text{Var}_{\\text{post}} = \\frac{\\alpha_{\\text{post}} \\beta_{\\text{post}}}{(\\alpha_{\\text{post}} + \\beta_{\\text{post}})^2 (\\alpha_{\\text{post}} + \\beta_{\\text{post}} + 1)} \\approx 0.00026\n\\]\nLa distribuzione a posteriori Beta(21, 249) suggerisce che la proporzione di mancini nella popolazione italiana è molto probabilmente vicina al 7.7%, con un intervallo di incertezza che riflette sia i dati attuali che le informazioni pregresse.\n\n\nCapitolo 48\nEsercizio 48.1\nNel caso del modello Gamma-Poisson, la distribuzione Gamma è la coniugata naturale della distribuzione di Poisson. Questo significa che se usiamo una priori Gamma per il tasso λ e una verosimiglianza Poisson, la distribuzione a posteriori sarà ancora una Gamma.\nEcco la soluzione analitica per l’esercizio:\n\nPriori: λ ~ Gamma(α, β) dove α è il parametro di forma e β è il parametro di tasso (inverso del parametro di scala)\nVerosimiglianza: y_i | λ ~ Poisson(λ) per i = 1, …, n osservazioni\nPosteriori: λ | y ~ Gamma(α_post, β_post)\ndove: α_post = α + Σy_i β_post = β + n\nΣy_i è la somma di tutte le osservazioni n è il numero di osservazioni\n\nNel nostro caso specifico:\n\nPriori: abbiamo usato α = 1.0 e β = 1 / 1.52 ≈ 0.658\nDati: y = [2, 0, 1, 3], quindi Σy_i = 6 e n = 4\n\nCalcoliamo i parametri della posteriori:\nα_post = 1.0 + 6 = 7.0 β_post = 0.658 + 4 = 4.658\nQuindi, la distribuzione a posteriori è:\nλ | y ~ Gamma(7.0, 4.658)\nDa questa distribuzione a posteriori, possiamo calcolare direttamente:\n\nMedia a posteriori: E[λ | y] = α_post / β_post ≈ 1.503\nModa a posteriori: (α_post - 1) / β_post ≈ 1.288 (solo per α_post &gt; 1)\nVarianza a posteriori: Var[λ | y] = α_post / (β_post)^2 ≈ 0.323\nIntervallo di credibilità al 95%: Possiamo usare la funzione di punto percentuale inversa della distribuzione Gamma. In Python, potremmo calcolarla così:\nfrom scipy import stats\n\nlower_ci = stats.gamma.ppf(0.025, a=7.0, scale=1/4.658)\nupper_ci = stats.gamma.ppf(0.975, a=7.0, scale=1/4.658)\n\n\n\n(sec_stan?)\n?exr-stan-beta-binomial-1\nLaplace adottò la seguente distribuzione campionaria per modellare il numero di maschi nati su un totale di \\(N\\) nascite:\n\\[\ny \\sim \\text{binomiale}(N, \\theta),\n\\]\ndove \\(N\\) è il numero totale di nascite, \\(\\theta\\) è la probabilità di nascita di un maschio e \\(y\\) è il numero di nascite maschili.\nLaplace utilizzò la seguente distribuzione a priori per \\(\\theta\\):\n\\[\n\\theta \\sim \\text{beta}(1, 1),\n\\]\ndove la distribuzione \\(\\text{beta}(1, 1)\\) è uniforme sull’intervallo \\(\\theta \\in (0, 1)\\).\nEcco come possiamo specificare il modello Stan:\n\nstan_file = os.path.join(project_directory, \"stan\", \"sex-ratio.stan\")\n\nwith open(stan_file, \"r\") as f:\n    print(f.read())\n\ndata {\n  int&lt;lower = 0&gt; N;\n  int&lt;lower = 0, upper = N&gt; y;\n  int&lt;lower = 0&gt; alpha_prior;\n  int&lt;lower = 0&gt; beta_prior;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; theta;\n}\nmodel {\n  theta ~ beta(alpha_prior, beta_prior);\n  y ~ binomial(N, theta);\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; boys_gt_girls = theta &gt; 0.5;\n}\n\n\n\nIn questo programma Stan, vediamo che sia il numero totale di nascite (\\(N\\)) sia il numero di nascite maschili (\\(y\\)) sono forniti come dati. Poi ci sono due blocchi aggiuntivi: un blocco dei parametri, usato per dichiarare valori sconosciuti (qui, solo il tasso di nascite maschili \\(\\theta\\)), e un blocco del modello, dove specifichiamo la distribuzione a priori e la verosimiglianza. La distribuzione a posteriori viene calcolata da Stan combinando queste due componenti. Inoltre, c’è un blocco delle quantità generate dove viene calcolata una variabile booleana che indica se la probabilità di nascita dei maschi \\(\\theta\\) è maggiore di 0.5.\nIl modello di Laplace ci consente di calcolare non solo la probabilità di nascita di un maschio, ma anche la probabilità che nascano più maschi che femmine.\n\nmodel = CmdStanModel(stan_file=stan_file)\n\n\nboys = 110312\ngirls = 105287\n\ndata = {\"N\": boys + girls, \"y\": boys, \"alpha_prior\": 1, \"beta_prior\": 1}\n\n\nsample = model.sample(\n    data=data,\n    iter_warmup=1000,\n    iter_sampling=10_000,\n    seed=123,\n    show_progress=False,\n    show_console=False,\n)\n\n11:19:03 - cmdstanpy - INFO - CmdStan start processing\n11:19:03 - cmdstanpy - INFO - Chain [1] start processing\n11:19:03 - cmdstanpy - INFO - Chain [2] start processing\n11:19:03 - cmdstanpy - INFO - Chain [3] start processing\n11:19:03 - cmdstanpy - INFO - Chain [4] start processing\n11:19:03 - cmdstanpy - INFO - Chain [1] done processing\n11:19:03 - cmdstanpy - INFO - Chain [2] done processing\n11:19:03 - cmdstanpy - INFO - Chain [3] done processing\n11:19:03 - cmdstanpy - INFO - Chain [4] done processing\n\n\nProcediamo quindi a estrarre i campioni a posteriori per le variabili theta e boys_gt_girls.\n\ntheta_draws = sample.stan_variable(\"theta\")\nboys_gt_girls_draws = sample.stan_variable(\"boys_gt_girls\")\n\n\nplt.hist(\n    theta_draws,\n    bins=30,\n    alpha=0.5,\n    density=True,\n)\nplt.title(\"Istogramma della distribizione a posteriori di theta\")\nplt.xlabel(\"Valori\")\nplt.ylabel(\"Frequenza\")\nplt.show()\n\n\n\n\n\n\n\n\nPer il modello di Laplace, la stima per il tasso di nascite maschili \\(\\theta\\) condizionata sui dati di nascita \\(y\\) è calcolata come la media campionaria delle estrazioni per theta.\n\ntheta_hat = np.mean(theta_draws)\nprint(f\"estimated theta = {theta_hat:.3f}\")\n\nestimated theta = 0.512\n\n\n\nquantile_05 = np.quantile(theta_draws, 0.05)\nquantile_95 = np.quantile(theta_draws, 0.95)\nprint(\n    f\"\"\"0.05 quantile = {quantile_05:.3f};\n0.95 quantile = {quantile_95:.3f}\"\"\"\n)\n\n0.05 quantile = 0.510;\n0.95 quantile = 0.513\n\n\n\nPr_boy_gt_girl = np.mean(boys_gt_girls_draws)\nprint(f\"estimated Pr[boy more likely] = {Pr_boy_gt_girl:.15f}\")\n\nestimated Pr[boy more likely] = 1.000000000000000\n\n\nCome possiamo vedere di seguito, tutti i nostri campioni per \\(\\theta\\) sono maggiori di \\(\\frac{1}{2}\\), ovvero boys_gt_girls_draws è sempre uguale a 1:\n\nnp.unique(boys_gt_girls_draws)\n\narray([1.])\n\n\nIl valore 1 restituito come stima solleva l’importante problema della precisione numerica. Laplace calcolò il risultato analiticamente, che è\n\\[\n\\Pr\\!\\left[\\Theta &gt; \\frac{1}{2} \\ \\bigg| \\ N, y\\right] \\approx 1 - 10^{-27}.\n\\]\nQuindi avremmo bisogno di un numero astronomico di campioni a posteriori prima di generare un valore di \\(\\theta\\) inferiore a \\(\\frac{1}{2}\\). La risposta di 1.0 trovata da Stan è molto vicina alla risposta vera e ben entro l’errore Monte Carlo atteso.\n\nsample.summary(sig_figs=3)\n\n\n\n\n\n\n\n\nMean\nMCSE\nStdDev\n5%\n50%\n95%\nN_Eff\nN_Eff/s\nR_hat\n\n\n\n\nlp__\n-149000.000\n0.004770\n6.720000e-01\n-149000.00\n-149000.000\n-149000.000\n19800.0\n39900.0\n1.0\n\n\ntheta\n0.512\n0.000009\n1.090000e-03\n0.51\n0.512\n0.513\n13700.0\n27600.0\n1.0\n\n\nboys_gt_girls\n1.000\nNaN\n9.380000e-14\n1.00\n1.000\n1.000\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nCapitolo 50\nEsercizio 50.1\nPer risolvere questo problema, calcoleremo la distribuzione predittiva a posteriori per il prossimo lancio utilizzando un nuovo set di dati: tre “testa” seguite da una “croce”. Procederemo passo dopo passo:\nPasso 1: Definire il Problema e i Dati\nAbbiamo tre tipi di monete nel sacchetto:\n\nMoneta di Tipo 0: Dà sempre “croce” (probabilità di “testa” = 0).\nMoneta di Tipo 1: È una moneta equa (probabilità di “testa” = 0.5).\nMoneta di Tipo 2: Dà sempre “testa” (probabilità di “testa” = 1).\n\nSupponiamo di avere un nuovo set di dati composto da tre “testa” seguite da una “croce”. Indichiamo questo set di dati come \\(D' = (\\text{\"testa\"}, \\text{\"testa\"}, \\text{\"testa\"}, \\text{\"croce\"})\\).\nPasso 2: Calcolare le Probabilità a Posteriori\nPrima di calcolare la distribuzione predittiva a posteriori, dobbiamo aggiornare le probabilità a posteriori per ciascun tipo di moneta utilizzando il nuovo set di dati \\(D'\\).\nPrima di osservare i dati, le probabilità iniziali (priori) per ciascun tipo di moneta sono uguali:\n\\[\nP(X = 0) = \\frac{1}{3}, \\quad P(X = 1) = \\frac{1}{3}, \\quad P(X = 2) = \\frac{1}{3}.\n\\]\nOra calcoliamo la verosimiglianza di ottenere il set di dati \\(D'\\) per ciascun tipo di moneta:\n\nMoneta di Tipo 0 (X = 0):\nProbabilità di ottenere “testa” = 0, quindi ottenere tre “testa” seguite da una “croce” è impossibile:\n\\[\nP(D' | X = 0) = 0.\n\\]\nMoneta di Tipo 1 (X = 1):\nProbabilità di ottenere “testa” o “croce” = 0.5. La probabilità di ottenere tre “testa” seguite da una “croce” è:\n\\[\nP(D' | X = 1) = 0.5^3 \\times 0.5 = 0.5^4 = 0.0625.\n\\]\nMoneta di Tipo 2 (X = 2):\nProbabilità di ottenere “testa” = 1, quindi ottenere tre “testa” seguite da una “croce” è impossibile:\n\\[\nP(D' | X = 2) = 0.\n\\]\n\nLe probabilità a posteriori sono calcolate usando la formula di Bayes:\n\\[\nP(X = i | D') = \\frac{P(D' | X = i) \\times P(X = i)}{P(D')},\n\\]\ndove \\(P(D')\\) è la probabilità totale di osservare il set di dati \\(D'\\), calcolata come:\n\\[\nP(D') = P(D' | X = 0) \\times P(X = 0) + P(D' | X = 1) \\times P(X = 1) + P(D' | X = 2) \\times P(X = 2).\n\\]\nSostituendo i valori:\n\\[\nP(D') = 0 \\times \\frac{1}{3} + 0.0625 \\times \\frac{1}{3} + 0 \\times \\frac{1}{3} = \\frac{0.0625}{3} = 0.020833.\n\\]\nOra possiamo calcolare le probabilità a posteriori:\n\nPer la Moneta di Tipo 0 (X = 0): \\[\nP(X = 0 | D') = \\frac{0 \\times \\frac{1}{3}}{0.020833} = 0.\n\\]\nPer la Moneta di Tipo 1 (X = 1): \\[\nP(X = 1 | D') = \\frac{0.0625 \\times \\frac{1}{3}}{0.020833} = \\frac{0.020833}{0.020833} = 1.\n\\]\nPer la Moneta di Tipo 2 (X = 2): \\[\nP(X = 2 | D') = \\frac{0 \\times \\frac{1}{3}}{0.020833} = 0.\n\\]\n\nPasso 3: Calcolare la Distribuzione Predittiva a Posteriori\nLa distribuzione predittiva a posteriori per il prossimo lancio è data dalla combinazione delle probabilità a posteriori con le probabilità di ottenere “croce” con ciascun tipo di moneta:\n\\[\nP(\\text{croce nel prossimo lancio} | D') = P(X = 0 | D') \\times 0 + P(X = 1 | D') \\times 0.5 + P(X = 2 | D') \\times 0.\n\\]\nSostituendo i valori calcolati:\n\\[\nP(\\text{croce nel prossimo lancio} | D') = 0 \\times 0 + 1 \\times 0.5 + 0 \\times 0 = 0.5.\n\\]\nLa distribuzione predittiva a posteriori per il prossimo lancio, dato che abbiamo osservato tre “testa” seguite da una “croce”, è 0.5.\nEsercizio 50.2\nPasso 1: Prior.\nLe probabilità preliminari sono:\n\\[\nP(X = 0) = 0.5, \\quad P(X = 1) = 0.25, \\quad P(X = 2) = 0.25.\n\\]\nPasso 2: Verosimiglianza.\n\nMoneta di Tipo 0 (X = 0): \\(P(D | X = 0) = 0.\\)\nMoneta di Tipo 1 (X = 1): \\(P(D | X = 1) = 0.3 \\times 0.7 \\times 0.3 = 0.063.\\)\nMoneta di Tipo 2 (X = 2): \\(P(D | X = 2) = 0.\\)\n\nPasso 3: Calcolo delle Probabilità a Posteriori.\n\\[\nP(D) = 0 \\times 0.5 + 0.063 \\times 0.25 + 0 \\times 0.25 = 0.01575.\n\\]\n\\[\nP(X = 0 | D) = 0, \\quad P(X = 1 | D) = 1, \\quad P(X = 2 | D) = 0.\n\\]\nPasso 4: Distribuzione Predittiva a Posteriori.\n\\[\n\\begin{align}\nP(\\text{croce nel quarto lancio} | D) &= P(X = 0 | D) \\times 1 + P(X = 1 | D) \\times 0.3 + P(X = 2 | D) \\times 0\\notag\\\\\n&= 0 \\times 1 + 1 \\times 0.3 + 0 \\times 0\\notag\\\\\n&= 0.3.\\notag\n\\end{align}\n\\]\nIn conclusione, la probabilità di ottenere “croce” al quarto lancio, dopo aver osservato la sequenza croce, testa, croce, è 0.3.\n\n\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The Italian version of Edinburgh Handedness Inventory: Translation, transcultural adaptation, and validation in healthy subjects. Laterality, 29(2), 151–168.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M. R., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A meta-analysis. Psychological bulletin, 146(6), 481–524.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>Z</span>  <span class='chapter-title'>Inferenza bayesiana</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_mult_regr.html",
    "href": "chapters/appendix/solutions_mult_regr.html",
    "title": "[Appendice — Regressione multipla",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 78\nEsercizio 78.1\n\nDeterminazione delle Matrici.\n\nLe variabili indipendenti (\\(x_1\\), \\(x_2\\) e \\(x_3\\)) sono date, e possiamo creare la matrice delle variabili indipendenti \\(\\mathbf{X}\\). Aggiungiamo una colonna di 1 per il termine costante \\(\\beta_0\\):\n\\[\n\\mathbf{X} = \\begin{pmatrix}\n1 & 2 & 11 & 12 \\\\\n1 & 1 & 9 & 9 \\\\\n1 & 3 & 12 & 7 \\\\\n1 & 4 & 10 & 8 \\\\\n1 & 5 & 11 & 6\n\\end{pmatrix}\n\\]\nLa matrice dei coefficienti \\(\\boldsymbol{\\beta}\\) è data come:\n\\[\n\\boldsymbol{\\beta} = \\begin{pmatrix}\n-1.402020 \\\\\n0.183838 \\\\\n1.405051 \\\\\n-0.664646\n\\end{pmatrix}\n\\]\nLa matrice degli errori \\(\\boldsymbol{\\epsilon}\\) non è fornita, ma la rappresentiamo comunque:\n\\[\n\\boldsymbol{\\epsilon} = \\begin{pmatrix}\n\\epsilon_1 \\\\\n\\epsilon_2 \\\\\n\\epsilon_3 \\\\\n\\epsilon_4 \\\\\n\\epsilon_5\n\\end{pmatrix}\n\\]\nL’equazione del modello lineare in forma matriciale è:\n\\[\n\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\n\\]\n\nEspansione del Modello.\n\nEspandiamo il modello per ottenere le cinque equazioni esplicite utilizzando i valori forniti. Il modello per ogni osservazione \\(i\\) è:\n\\[\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\epsilon_i\n\\]\nCalcoliamo le cinque equazioni:\n\\[\n\\begin{aligned}\ny_1 &= -1.402020 + 0.183838 \\cdot 2 + 1.405051 \\cdot 11 - 0.664646 \\cdot 12 + \\epsilon_1 \\\\\ny_2 &= -1.402020 + 0.183838 \\cdot 1 + 1.405051 \\cdot 9 - 0.664646 \\cdot 9 + \\epsilon_2 \\\\\ny_3 &= -1.402020 + 0.183838 \\cdot 3 + 1.405051 \\cdot 12 - 0.664646 \\cdot 7 + \\epsilon_3 \\\\\ny_4 &= -1.402020 + 0.183838 \\cdot 4 + 1.405051 \\cdot 10 - 0.664646 \\cdot 8 + \\epsilon_4 \\\\\ny_5 &= -1.402020 + 0.183838 \\cdot 5 + 1.405051 \\cdot 11 - 0.664646 \\cdot 6 + \\epsilon_5 \\\\\n\\end{aligned}\n\\]\n\nCalcolo dei Valori Predetti (\\(\\hat{y}_i\\)).\n\nCalcoliamo i valori predetti \\(\\hat{y}_i\\) sostituendo \\(\\epsilon_i\\) con 0:\n\\[\n\\begin{aligned}\n\\hat{y}_1 &= -1.402020 + 0.183838 \\cdot 2 + 1.405051 \\cdot 11 - 0.664646 \\cdot 12 \\\\\n\\hat{y}_2 &= -1.402020 + 0.183838 \\cdot 1 + 1.405051 \\cdot 9 - 0.664646 \\cdot 9 \\\\\n\\hat{y}_3 &= -1.402020 + 0.183838 \\cdot 3 + 1.405051 \\cdot 12 - 0.664646 \\cdot 7 \\\\\n\\hat{y}_4 &= -1.402020 + 0.183838 \\cdot 4 + 1.405051 \\cdot 10 - 0.664646 \\cdot 8 \\\\\n\\hat{y}_5 &= -1.402020 + 0.183838 \\cdot 5 + 1.405051 \\cdot 11 - 0.664646 \\cdot 6 \\\\\n\\end{aligned}\n\\]\nCalcoliamo i valori numerici:\n\\[\n\\begin{aligned}\n\\hat{y}_1 &= -1.402020 + 0.367676 + 15.455561 - 7.975752 \\approx 6.445465 \\\\\n\\hat{y}_2 &= -1.402020 + 0.183838 + 12.645459 - 5.981814 \\approx 5.445463 \\\\\n\\hat{y}_3 &= -1.402020 + 0.551514 + 16.860612 - 4.652522 \\approx 11.357584 \\\\\n\\hat{y}_4 &= -1.402020 + 0.735352 + 14.05051 - 5.317168 \\approx 8.066674 \\\\\n\\hat{y}_5 &= -1.402020 + 0.91919 + 15.455561 - 3.987876 \\approx 10.985855 \\\\\n\\end{aligned}\n\\]\nI valori predetti sono quindi:\n\\[\n\\begin{aligned}\n\\hat{y}_1 &\\approx 6.445 \\\\\n\\hat{y}_2 &\\approx 5.445 \\\\\n\\hat{y}_3 &\\approx 11.358 \\\\\n\\hat{y}_4 &\\approx 8.067 \\\\\n\\hat{y}_5 &\\approx 10.986 \\\\\n\\end{aligned}\n\\]\n\nCalcolo degli errori casuali (\\(\\boldsymbol{\\epsilon}\\)).\n\nGli errori casuali (\\(\\epsilon_i\\)) si ottengono sottraendo i valori predetti (\\(\\hat{y}_i\\)) dai valori osservati (\\(y_i\\)). Per ciascun \\(i\\):\n\\[\n\\epsilon_i = y_i - \\hat{y}_i\n\\]\nCalcoliamo gli errori casuali per ciascuna osservazione:\n\\[\n\\begin{aligned}\n\\epsilon_1 &= 5.7 - 6.445 \\approx -0.745 \\\\\n\\epsilon_2 &= 4.7 - 5.445 \\approx -0.745 \\\\\n\\epsilon_3 &= 12.6 - 11.358 \\approx 1.242 \\\\\n\\epsilon_4 &= 10.8 - 8.067 \\approx 2.733 \\\\\n\\epsilon_5 &= 8.5 - 10.986 \\approx -2.486 \\\\\n\\end{aligned}\n\\]\nQuindi, la matrice degli errori \\(\\boldsymbol{\\epsilon}\\) è:\n\\[\n\\boldsymbol{\\epsilon} = \\begin{pmatrix}\n-0.745 \\\\\n-0.745 \\\\\n1.242 \\\\\n2.733 \\\\\n-2.486\n\\end{pmatrix}\n\\]\nEsercizio 78.2\nEcco come implementare la formula dei minimi quadrati in Python utilizzando la libreria numpy e come verificare il risultato usando pingouin.linear_regression.\n\nimport numpy as np\nimport pandas as pd\nimport pingouin as pg\n\n# Definizione della matrice X e del vettore y\nX = np.array([[2, 11, 12], [1, 9, 9], [3, 12, 7], [4, 10, 8], [5, 11, 6]])\ny = np.array([5.7, 4.7, 12.6, 10.8, 8.5])\n\n# Implementazione con NumPy\nX_numpy = np.hstack([np.ones((X.shape[0], 1)), X])\nbeta_numpy = np.linalg.inv(X_numpy.T @ X_numpy) @ X_numpy.T @ y\nprint(\"I coefficienti beta calcolati con NumPy sono:\", beta_numpy)\n\n# Implementazione con Pingouin\ndata = pd.DataFrame(X, columns=[\"x1\", \"x2\", \"x3\"])\ndata[\"y\"] = y\nmodel_pingouin = pg.linear_regression(\n    data[[\"x1\", \"x2\", \"x3\"]], data[\"y\"], add_intercept=True\n)\nprint(\"\\nI coefficienti beta calcolati con Pingouin sono:\")\nprint(model_pingouin)\n\n# Confronto dei risultati\nprint(\"\\nConfrontiamo i coefficienti:\")\nprint(\"NumPy:   \", beta_numpy)\nprint(\"Pingouin:\", model_pingouin[\"coef\"].values)\n\nI coefficienti beta calcolati con NumPy sono: [-1.4020202   0.18383838  1.40505051 -0.66464646]\n\nI coefficienti beta calcolati con Pingouin sono:\n       names      coef         se         T      pval        r2   adj_r2  \\\n0  Intercept -1.402020  22.592392 -0.062057  0.960544  0.632638 -0.46945   \n1         x1  0.183838   1.901446  0.096683  0.938640  0.632638 -0.46945   \n2         x2  1.405051   1.960075  0.716835  0.604064  0.632638 -0.46945   \n3         x3 -0.664646   1.214501 -0.547259  0.681221  0.632638 -0.46945   \n\n     CI[2.5%]   CI[97.5%]  \n0 -288.465573  285.661533  \n1  -23.976322   24.343999  \n2  -23.500063   26.310164  \n3  -16.096345   14.767052  \n\nConfrontiamo i coefficienti:\nNumPy:    [-1.4020202   0.18383838  1.40505051 -0.66464646]\nPingouin: [-1.4020202   0.18383838  1.40505051 -0.66464646]\n\n\nCapitolo 79\nEsercizio 79.1\nimport os\nimport pandas as pd\nimport bambi as bmb\nimport arviz as az\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\ndata_path = os.path.join(project_directory, \"data\", \"Aungle_Langer_2023.csv\")\nd = pd.read_csv(data_path)\nd[\"Condition\"] = d[\"Condition\"].astype(\"category\")\nd.head()\n\n# Define and fit the basic mixed-effects model\nmodel = bmb.Model(\n    \"Healing ~ Condition + (1|Subject) + (1|ResponseId)\",\n    data=d\n)\n\nidata = model.fit(nuts_sampler=\"numpyro\")\naz.summary(idata, round_to=2, var_names=\"Condition\")\n\nmodel_varying_slopes = bmb.Model(\n    \"Healing ~ Condition + (1 + Condition|Subject) + (1 + Condition|ResponseId)\",\n    data=d,\n)\nidata_varying_slopes = model_varying_slopes.fit(nuts_sampler=\"numpyro\")\naz.summary(idata_varying_slopes, round_to=2, var_names=\"Condition\")\nGelman & Brown (2024) hanno replicato l’analisi degli autori originali utilizzando un modello a effetti misti con pendenze casuali. Questa nuova analisi ha prodotto risultati sostanzialmente diversi. Nel nuovo modello statistico, i t-score sono stati notevolmente ridotti: da 10.7 a 3.0 per il confronto tra la condizione di 56 minuti e quella di 14 minuti, e da 2.5 a 0.7 per il confronto tra la condizione di 28 minuti e quella di 14 minuti. Inoltre, l’effetto della manipolazione sulla guarigione è stato stimato come altamente variabile tra i singoli soggetti, risultando a volte positivo e a volte negativo.\nGelman & Brown (2024) esprimono scetticismo riguardo alla capacità di questo studio di rivelare effetti reali del tempo percepito sulla guarigione fisica, basandosi su quattro argomentazioni principali.\n\nSelezione dei risultati: Il risultato statisticamente significativo emerso è solo uno dei molti confronti possibili. Lo studio ha raccolto dati su diverse variabili (ansia, stress, depressione, mindfulness, umore e tratti della personalità), aprendo la possibilità a numerose altre analisi. In assenza di una preregistrazione dello studio, non è possibile determinare quali analisi sarebbero state condotte se i dati fossero stati diversi.\nVariabilità tra i soggetti: La grande variazione stimata nell’effetto tra i soggetti suggerisce che qualsiasi effetto medio stimato sarebbe altamente dipendente dal campione specifico di partecipanti. Non vi è motivo di ritenere che i 33 partecipanti siano rappresentativi di una popolazione più ampia di interesse.\nVariabilità situazionale: Ci si aspetterebbe che l’effetto vari non solo tra le persone, ma anche tra le situazioni, sollevando preoccupazioni sulla stabilità e sulla generalizzabilità dei risultati. Inoltre, l’esperimento ha coinvolto solo contusioni molto lievi, non vere e proprie malattie o lesioni. Dunque, è difficile concludere, come fanno gli autori, che la tecnica del cupping abbia delle vere e propri proprietà curative.\nMancanza di un meccanismo chiaro: Non è chiaro come la percezione del tempo possa influenzare la guarigione della pelle in questo contesto. Gli autori fanno riferimento a concetti generali come “l’unità mente-corpo”, ma non sono stati esaminati meccanismi specifici. Attribuire le differenze osservate al “tempo percepito” piuttosto che ad altri fattori che variavano tra le condizioni sembra essere una conclusione azzardata.\n\nIn conclusione, Gelman & Brown (2024) suggeriscono che, data la molteplicità di variabili in gioco nell’esperimento, potrebbe essere più plausibile interpretare i risultati come un esempio della capacità dei ricercatori di trovare pattern nel rumore in studi non adeguatamente controllati, piuttosto che come una prova dell’effetto del tempo percepito sulla guarigione fisica.\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>[</span>  <span class='chapter-title'>Regressione multipla</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_rescorla_wagner.html",
    "href": "chapters/appendix/solutions_rescorla_wagner.html",
    "title": "Appendice  — Modello Rescorla-Wagner",
    "section": "",
    "text": "Capitolo 106\nEsercizio 106.1\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef softmax(Q, theta):\n    \"\"\"\n    Calcola le probabilità di selezione delle azioni utilizzando la regola softmax.\n\n    Args:\n        Q (numpy array): Array di valori attesi per ciascuna azione.\n        theta (float): Parametro di temperatura.\n\n    Returns:\n        numpy array: Array di probabilità di selezione delle azioni.\n    \"\"\"\n    # Calcola le probabilità softmax\n    exp_values = np.exp(theta * Q)\n    probabilities = exp_values / np.sum(exp_values)\n    return probabilities\n\n\n# Esempio di utilizzo della funzione softmax\nQ = np.array([0.25, 0.75])\ntheta_values = [0.1, 1, 2, 5]\n\n# Visualizziamo le probabilità per diversi valori di theta\nfor theta in theta_values:\n    probabilities = softmax(Q, theta)\n    print(f\"Theta = {theta}: Probabilità = {probabilities}\")\n\n# Tracciare il grafico delle probabilità al variare di theta\ntheta_range = np.linspace(0, 5, 100)\nprobabilities_list = [softmax(Q, theta) for theta in theta_range]\nprobabilities_array = np.array(probabilities_list).T\n\nplt.figure()\nplt.plot(theta_range, probabilities_array[0], label=\"Opzione 1: Q = 0.25\")\nplt.plot(theta_range, probabilities_array[1], label=\"Opzione 2: Q = 0.75\")\nplt.xlabel(\"Theta\")\nplt.ylabel(\"Probabilità\")\nplt.title(\"Funzione Softmax - Modello Rescorla-Wagner\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\nTheta = 0.1: Probabilità = [0.4875026 0.5124974]\nTheta = 1: Probabilità = [0.37754067 0.62245933]\nTheta = 2: Probabilità = [0.26894142 0.73105858]\nTheta = 5: Probabilità = [0.07585818 0.92414182]\n\n\n\n\n\n\n\n\n\nEsercizio 106.2\n\nimport numpy as np\n\n\ndef update_value(Q, R, alpha):\n    \"\"\"\n    Aggiorna il valore atteso utilizzando il modello di Rescorla-Wagner.\n\n    Args:\n        Q (float): Valore atteso attuale.\n        R (float): Ricompensa ricevuta.\n        alpha (float): Tasso di apprendimento.\n\n    Returns:\n        float: Nuovo valore atteso.\n        float: Errore di previsione.\n    \"\"\"\n    # Calcola l'errore di previsione\n    prediction_error = R - Q\n    # Aggiorna il valore atteso\n    Q_new = Q + alpha * prediction_error\n    return Q_new, prediction_error\n\n\n# Esempio di utilizzo della funzione update_value\nQ = 0.5  # Valore atteso iniziale\nR_values = [1, 0, 1, 1, 0]  # Sequenza di ricompense ricevute\nalpha = 0.1  # Tasso di apprendimento\n\n# Inizializza una lista per tracciare i valori attesi e gli errori di previsione\nQ_values = [Q]\nprediction_errors = []\n\n# Aggiorna il valore atteso per ciascuna ricompensa ricevuta\nfor R in R_values:\n    Q, error = update_value(Q, R, alpha)\n    Q_values.append(Q)\n    prediction_errors.append(error)\n    print(\n        f\"Ricompensa: {R}, Errore di Previsione: {error:.2f}, Nuovo Valore Atteso: {Q:.2f}\"\n    )\n\n# Visualizziamo i risultati\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(Q_values, label=\"Valore Atteso\")\nplt.plot(\n    range(1, len(prediction_errors) + 1),\n    prediction_errors,\n    label=\"Errore di Previsione\",\n    linestyle=\"--\",\n)\nplt.xlabel(\"Prove\")\nplt.ylabel(\"Valore\")\nplt.title(\n    \"Aggiornamento del Valore Atteso e dell'Errore di Previsione nel Modello di Rescorla-Wagner\"\n)\nplt.legend()\nplt.grid(True)\nplt.show()\n\nRicompensa: 1, Errore di Previsione: 0.50, Nuovo Valore Atteso: 0.55\nRicompensa: 0, Errore di Previsione: -0.55, Nuovo Valore Atteso: 0.50\nRicompensa: 1, Errore di Previsione: 0.50, Nuovo Valore Atteso: 0.55\nRicompensa: 1, Errore di Previsione: 0.45, Nuovo Valore Atteso: 0.59\nRicompensa: 0, Errore di Previsione: -0.59, Nuovo Valore Atteso: 0.53\n\n\n\n\n\n\n\n\n\nEsercizio 106.3\n\nScenario 1: Apprendimento Rapido in un Ambiente Stabile\n\nTasso di Apprendimento (alpha): In questo scenario, un tasso di apprendimento elevato (ad esempio, alpha = 0.8) sarebbe vantaggioso perché l’ambiente è stabile e la ricompensa è consistente. Un alto tasso di apprendimento permetterà al cane di aggiornare rapidamente le sue aspettative e imparare il trucco più velocemente.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso potrebbe essere basso (ad esempio, Q_0 = 0.1), riflettendo la mancanza di conoscenza iniziale del cane sul trucco e la ricompensa associata.\n\nScenario 2: Apprendimento Lento in un Ambiente Stabile\n\nTasso di Apprendimento (alpha): Qui, un tasso di apprendimento più basso (ad esempio, alpha = 0.2) sarebbe più appropriato. Anche se l’ambiente è stabile, un apprendimento più lento potrebbe essere sufficiente poiché il bambino potrebbe non essere costantemente focalizzato sui puzzle e può imparare gradualmente.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso potrebbe essere moderato (ad esempio, Q_0 = 0.3), considerando che il bambino potrebbe avere un’idea preliminare che risolvere puzzle porta a una ricompensa, ma non è ancora certo dell’entità della ricompensa.\n\nScenario 3: Apprendimento in un Ambiente Variabile\n\nTasso di Apprendimento (alpha): In un ambiente variabile, un tasso di apprendimento moderato (ad esempio, alpha = 0.5) potrebbe essere utile. Questo permetterebbe al giocatore di aggiornare rapidamente le aspettative senza essere troppo influenzato dalle variazioni casuali delle ricompense.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso potrebbe essere neutro (ad esempio, Q_0 = 0.5), poiché il giocatore non ha informazioni iniziali solide su quale arma sia la migliore e dovrebbe esplorare per raccogliere dati.\n\nScenario 4: Apprendimento con Informazioni Iniziali Parziali\n\nTasso di Apprendimento (alpha): Un tasso di apprendimento moderato (ad esempio, alpha = 0.4) potrebbe essere adeguato. Il ricercatore dovrebbe essere in grado di aggiornare le sue aspettative basandosi su nuovi dati, ma non dovrebbe ignorare completamente le informazioni preliminari.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso dovrebbe essere relativamente alto (ad esempio, Q_0 = 0.7), riflettendo la conoscenza preliminare del ricercatore che un certo farmaco potrebbe essere efficace.\n\n\nIn conclusione\n\nTasso di Apprendimento (alpha): Un tasso di apprendimento elevato è utile in ambienti stabili dove le informazioni raccolte sono affidabili, mentre un tasso più basso è preferibile in contesti dove l’apprendimento deve essere graduale o l’ambiente è meno prevedibile.\nValore Iniziale Atteso (Q_0): Il valore iniziale atteso riflette la conoscenza preliminare dell’agente. Un valore basso indica poca conoscenza iniziale, mentre un valore alto indica una forte aspettativa basata su informazioni preliminari.\n\nQuesto esercizio ti aiuta a comprendere come i parametri del modello di Rescorla-Wagner influenzano il processo di apprendimento e come adattare questi parametri in base al contesto specifico.\nEsercizio 106.4\n\nContesto 1: Addestramento di un Animale Domestico\n\nErrore di Previsione: Quando il cane esegue correttamente il comando e riceve una ricompensa, l’errore di previsione sarà positivo, indicando che il risultato è migliore di quanto atteso. Questo rinforza il comportamento corretto.\nAggiornamento del Valore Atteso: Il valore atteso per eseguire il comando “seduto” aumenterà, portando il cane a eseguire il comando più frequentemente in futuro.\nLimitazioni del Modello RW: Il modello potrebbe non catturare la variabilità individuale del cane, come il suo livello di motivazione o distrazione, che possono influenzare l’apprendimento.\n\nContesto 2: Apprendimento Scolastico\n\nErrore di Previsione: Se lo studente riceve un voto migliore del previsto, l’errore di previsione sarà positivo, motivando lo studente a continuare ad impegnarsi. Un voto peggiore del previsto porterà a un errore di previsione negativo.\nAggiornamento del Valore Atteso: Il valore atteso per lo studio e l’impegno nella materia aumenterà con feedback positivi e diminuirà con feedback negativi.\nLimitazioni del Modello RW: Il modello potrebbe non considerare fattori esterni come il supporto familiare, lo stress o le risorse disponibili per lo studente, che influenzano l’apprendimento.\n\nContesto 3: Terapia Comportamentale\n\nErrore di Previsione: Quando il paziente affronta la situazione temuta con successo e riceve un rinforzo positivo, l’errore di previsione sarà positivo, riducendo gradualmente l’ansia associata.\nAggiornamento del Valore Atteso: Il valore atteso per affrontare la situazione temuta senza evitare aumenterà, incoraggiando il paziente a continuare ad esporsi.\nLimitazioni del Modello RW: Il modello potrebbe non catturare l’importanza del contesto terapeutico e del rapporto di fiducia tra paziente e terapeuta, che sono cruciali per il successo della terapia.\n\nContesto 4: Apprendimento nelle Organizzazioni\n\nErrore di Previsione: I dipendenti che ricevono premi o riconoscimenti migliori del previsto avranno un errore di previsione positivo, aumentando la loro motivazione e impegno.\nAggiornamento del Valore Atteso: Il valore atteso per raggiungere gli obiettivi di performance aumenterà con i premi, incoraggiando i dipendenti a mantenere o migliorare le loro prestazioni.\nLimitazioni del Modello RW: Il modello potrebbe non tenere conto di fattori come la cultura aziendale, la collaborazione tra colleghi e l’equilibrio tra vita lavorativa e personale, che possono influenzare le performance dei dipendenti.\n\n\nIn conclusione,\n\nErrore di Previsione: Gioca un ruolo cruciale nell’apprendimento, influenzando il grado di aggiornamento delle aspettative in base ai risultati osservati.\nAggiornamento del Valore Atteso: Determina la probabilità che un comportamento venga ripetuto in futuro, basato sull’esperienza passata.\nLimitazioni del Modello RW: Sebbene il modello di Rescorla-Wagner fornisca un framework utile per comprendere l’apprendimento basato sul rinforzo, potrebbe non catturare tutte le sfaccettature dei contesti di apprendimento reali, inclusi fattori individuali, sociali e ambientali.\n\nQuesto esercizio ti aiuta a riflettere su come i concetti teorici del modello di Rescorla-Wagner si applicano a diversi contesti pratici di apprendimento e a riconoscere le potenziali limitazioni del modello.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>\\</span>  <span class='chapter-title'>Modello Rescorla-Wagner</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_entropia.html",
    "href": "chapters/appendix/solutions_entropia.html",
    "title": "[Appendice ] — Entropia]{#sec-solutions-entropia .quarto-section-identifier}",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 97\nEsercizio 98.1\n\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.1, 0.2, 0.7])\n\n\n# Calcoliamo l'entropia di $p$.\nh_p = -np.sum(p * np.log(p))\nprint(\"Entropia di p: \", h_p)\n\nEntropia di p:  1.0296530140645737\n\n\n\n# Calcoliamo l'entropia incrociata tra $p$ e $q$.\nh_pq = -np.sum(p * np.log(q))\nprint(\"Entropia incrociata tra p e q: \", h_pq)\n\nEntropia incrociata tra p e q:  1.372238457997479\n\n\n\n# Calcoliamo la divergenza di Kullback-Leibler da $p$ a $q$.\nkl_pq = h_pq - h_p\nprint(\"Divergenza KL da p a q: \", kl_pq)\n\nDivergenza KL da p a q:  0.34258544393290524\n\n\n\n# Lo stesso risultato si ottiene applicando la formula della Divergenza $\\mathbb{KL}$.\nnp.sum(p * (np.log(p) - np.log(q)))\n\n0.3425854439329054\n\n\n\n# Se invece $q$ è molto simile a $p$, la differenza $\\mathbb{KL}$ è molto minore.\np = np.array([0.2, 0.5, 0.3])\nq = np.array([0.2, 0.55, 0.25])\nnp.sum(p * (np.log(p) - np.log(q)))\n\n0.007041377136023895\n\n\nEsercizio 98.2\n\n# Define the parameters\nn = 4\np = 0.2\n\n# Compute the probability mass function\ntrue_py = stats.binom.pmf(range(n + 1), n, p)\nprint(true_py)\n\n[0.4096 0.4096 0.1536 0.0256 0.0016]\n\n\n\nq1 = np.array([0.46, 0.42, 0.10, 0.01, 0.01])\nprint(q1)\n\n[0.46 0.42 0.1  0.01 0.01]\n\n\n\nq2 = [0.2] * 5\nprint(q2)\n\n[0.2, 0.2, 0.2, 0.2, 0.2]\n\n\n\n# La divergenza $\\mathbb{KL}$ di $q_1$ da $p$ è\nkl_pq1 = np.sum(true_py * (np.log(true_py) - np.log(q1)))\nprint(\"Divergenza KL di q1 da p: \", kl_pq1)\n\nDivergenza KL di q1 da p:  0.02925199033345882\n\n\n\n# La divergenza $\\mathbb{KL}$ di $q_2$ da $p$ è:\nkl_pq2 = np.sum(true_py * (np.log(true_py) - np.log(q2)))\nprint(\"Divergenza KL di q2 da p: \", kl_pq2)\n\nDivergenza KL di q2 da p:  0.48635777871415425\n\n\nÈ chiaro che perdiamo una quantità maggiore di informazioni se, per descrivere la distribuzione binomiale \\(p\\), usiamo la distribuzione uniforme \\(q_2\\) anziché \\(q_1\\).\nEsercizio 98.3\n\n# Definire le distribuzioni p e q\np = np.array([0.01, 0.99])\nq = np.array([0.7, 0.3])\n\n# Calcolo dell'entropia di p\nh_p = -np.sum(p * np.log(p))\n\n# Calcolo dell'entropia incrociata da p a q\nh_pq = -np.sum(p * np.log(q))\n\n# Calcolo della divergenza KL da p a q\nkl_pq = h_pq - h_p\n\n# Calcolo dell'entropia di q\nh_q = -np.sum(q * np.log(q))\n\n# Calcolo dell'entropia incrociata da q a p\nh_qp = -np.sum(q * np.log(p))\n\n# Calcolo della divergenza KL da q a p\nkl_qp = h_qp - h_q\n\nprint(f\"Entropia di p: {h_p}\")\nprint(f\"Entropia incrociata da p a q: {h_pq}\")\nprint(f\"Divergenza KL da p a q: {kl_pq}\")\n\nprint(f\"\\nEntropia di q: {h_q}\")\nprint(f\"Entropia incrociata da q a p: {h_qp}\")\nprint(f\"Divergenza KL da q a p: {kl_qp}\")\n\nEntropia di p: 0.056001534354847345\nEntropia incrociata da p a q: 1.1954998257220641\nDivergenza KL da p a q: 1.1394982913672167\n\nEntropia di q: 0.6108643020548935\nEntropia incrociata da q a p: 3.226634230947714\nDivergenza KL da q a p: 2.6157699288928207",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>]</span>  <span class='chapter-title'>Entropia</span>"
    ]
  },
  {
    "objectID": "chapters/appendix/solutions_replication_crisis.html",
    "href": "chapters/appendix/solutions_replication_crisis.html",
    "title": "Appendice ^ — Crisi della replicazione",
    "section": "",
    "text": "# Standard library imports\nimport os\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport arviz as az\nimport scipy.stats as stats\nfrom scipy.special import expit  # Funzione logistica\nfrom cmdstanpy import cmdstan_path, CmdStanModel\n\n# Configuration\nseed = sum(map(ord, \"stan_poisson_regression\"))\nrng = np.random.default_rng(seed=seed)\naz.style.use(\"arviz-darkgrid\")\n%config InlineBackend.figure_format = \"retina\"\n\n# Define directories\nhome_directory = os.path.expanduser(\"~\")\nproject_directory = f\"{home_directory}/_repositories/psicometria\"\n\n# Print project directory to verify\nprint(f\"Project directory: {project_directory}\")\n\nProject directory: /Users/corradocaudek/_repositories/psicometria\n\n\n\nCapitolo 116\nEsercizio 116.1\nLe argomentazioni di Gelman & Brown (2024) mettono in luce fattori come la selezione dei confronti, la variabilità degli effetti tra i soggetti, l’influenza delle condizioni sperimentali, e l’assenza di un chiaro meccanismo d’azione. Questi stessi fattori potrebbero essere stati determinanti nella mancata replicazione dello studio di Karataş & Cutright (2023). La combinazione di una possibile sovrainterpretazione dei dati iniziali, la presenza di variabili non controllate, e la mancanza di un chiaro modello teorico per spiegare i risultati originali potrebbe aver portato a risultati che non si sono confermati in studi successivi.\n\n\nCapitolo 119\nEsercizio 119.1\nIl seguente codice è scritto in R. Può essere facilmente convertito in Python.\nset.seed(42)  # Imposta un seed per la riproducibilità\n\nn_sim &lt;- 10000  # Numero di simulazioni\nn_per_group &lt;- 20  # Campioni per gruppo\nsd_max_fp &lt;- 10  # Deviazione standard scelta per massimizzare i falsi positivi\n\n# Vettori per conservare i risultati\nsignificant_results &lt;- numeric()\neffect_sizes &lt;- numeric()\n\nfor (i in 1:n_sim) {\n  # Genera due gruppi con media 0 e sd massimizzata\n  group1 &lt;- rnorm(n_per_group, mean = 0, sd = sd_max_fp)\n  group2 &lt;- rnorm(n_per_group, mean = 0, sd = sd_max_fp)\n  \n  # Esegui il t-test\n  t_test &lt;- t.test(group1, group2)\n  \n  # Calcola l'effect size (d di Cohen)\n  pooled_sd &lt;- sqrt(((n_per_group - 1) * var(group1) + (n_per_group - 1) * var(group2)) / \n                      (2 * n_per_group - 2))\n  cohen_d &lt;- abs(mean(group1) - mean(group2)) / pooled_sd\n  \n  # Conserva i risultati solo se significativi\n  if (t_test$p.value &lt; 0.05) {\n    significant_results &lt;- c(significant_results, t_test$p.value)\n    effect_sizes &lt;- c(effect_sizes, cohen_d)\n  }\n}\n\n# Calcola la proporzione di risultati significativi\nproportion_significant &lt;- length(significant_results) / n_sim\n\n# Calcola l'effect size medio dei risultati significativi\nmean_effect_size_significant &lt;- mean(effect_sizes)\n\n# Stampa i risultati\ncat(\"Proporzione di risultati statisticamente significativi:\", proportion_significant, \"\\n\")\ncat(\"Effect size medio dei risultati significativi:\", mean_effect_size_significant, \"\\n\")\n\n\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges and misreadings of the literature combine to produce unreplicable science: An example from psychology.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about God increases acceptance of artificial intelligence in decision-making. Proceedings of the National Academy of Sciences, 120(33), e2218961120.",
    "crumbs": [
      "Appendici",
      "Soluzioni degli esercizi",
      "<span class='chapter-number'>^</span>  <span class='chapter-title'>Crisi della replicazione</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psicometria",
    "section": "",
    "text": "Benvenuti\nBenvenuti nel sito web dell’insegnamento di Psicometria, parte del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#descrizione",
    "href": "index.html#descrizione",
    "title": "Psicometria",
    "section": "Descrizione",
    "text": "Descrizione\nL’insegnamento offre una formazione teorico-pratica nell’ambito dell’inferenza statistica, con un focus particolare sulle applicazioni in campo psicologico. Attraverso esercitazioni pratiche in Python e R, gli studenti acquisiranno competenze nell’analisi di dati e nell’uso di modelli statistici avanzati.\n\n\nAnno Accademico: 2024-2025\n\nCodice Insegnamento: B000286\n\nOrario e Luogo: Lunedì e Martedì (8:30-10:30), Giovedì (11:30-13:30), Plesso didattico La Torretta.\n\n\n\n\n\n\n\nQuesto sito web è la fonte ufficiale per il programma dell’insegnamento B000286 - Psicometria e le modalità d’esame.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#struttura-dellinsegnamento",
    "href": "index.html#struttura-dellinsegnamento",
    "title": "Psicometria",
    "section": "Struttura dell’Insegnamento",
    "text": "Struttura dell’Insegnamento\nL’insegnamento è organizzato in diverse sezioni, ciascuna dedicata a uno specifico argomento chiave.\n\n\nFondamenti: Introduzione ai concetti statistici di base.\n\nInferenza Bayesiana: Applicazioni avanzate dell’inferenza causale.\n\nProgrammazione in Python e R: Utilizzo pratico per l’analisi dati.\n\nVisualizzazione dei Dati: Tecniche per interpretare e comunicare risultati.\n\nConsulta il syllabus completo per ulteriori dettagli.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "index.html#materiale-didattico",
    "href": "index.html#materiale-didattico",
    "title": "Psicometria",
    "section": "Materiale Didattico",
    "text": "Materiale Didattico\nIl presente sito web ospita la dispensa ufficiale del corso, contenente tutte le note e i materiali relativi alle lezioni. Per quanto riguarda le esercitazioni pratiche e gli esempi applicativi, è possibile accedere al sito dedicato, disponibile al seguente indirizzo: Psicometria Esercizi. Entrambi i materiali sono forniti gratuitamente agli studenti, senza necessità di ulteriori acquisti.",
    "crumbs": [
      "Benvenuti"
    ]
  },
  {
    "objectID": "prefazione.html",
    "href": "prefazione.html",
    "title": "Prefazione",
    "section": "",
    "text": "Come possiamo migliorare l’analisi dei dati psicologici per renderla più affidabile e robusta? È possibile affrontare questa sfida semplicemente applicando una serie di algoritmi o procedure standard? L’analisi dei dati in psicologia può davvero essere ridotta a un insieme di “ricette” preconfezionate (McElreath, 2020)?\nQueste domande ci portano a riflettere sulla natura stessa dell’analisi dei dati psicologici. A differenza di ciò che suggerisce l’approccio frequentista del test dell’ipotesi nulla, l’analisi dei dati non è una disciplina che si esaurisce con l’applicazione meccanica di metodi predefiniti. Anzi, considerare l’analisi dei dati come un insieme di procedure automatiche contribuisce a uno dei problemi più gravi della psicologia contemporanea: la crisi della replicabilità dei risultati (Korbmacher et al., 2023).\nMa perché la replicabilità è così cruciale? Se i risultati delle ricerche psicologiche non sono replicabili, significa che la nostra comprensione dei fenomeni psicologici è superficiale e inaffidabile. Questo non è solo un problema teorico o accademico; ha implicazioni dirette sulle applicazioni pratiche della psicologia. Se le basi scientifiche sono incerte, anche le strategie di intervento psicologico rischiano di essere inefficaci o addirittura dannose (Funder et al., 2014; Ioannidis, 2019; Shrout & Rodgers, 2018; Tackett et al., 2019).\nPerché le pratiche di analisi dei dati derivanti dal frequentismo potrebbero contribuire a questa crisi? In che modo gli incentivi accademici influenzano la qualità della ricerca psicologica? E, soprattutto, quali alternative abbiamo per migliorare l’affidabilità e la validità delle nostre conclusioni?\nL’analisi bayesiana emerge come una delle proposte per superare i limiti dell’approccio frequentista (Gelman et al., 1995). Tuttavia, è sufficiente abbandonare l’inferenza frequentista per risolvere i problemi della psicologia? Come possiamo integrare metodi robusti e flessibili, come quelli bayesiani, con una comprensione più approfondita e trasparente dei fenomeni psicologici?\nIn questo corso, esploreremo queste domande, cercando di identificare le “buone pratiche” dell’analisi dei dati psicologici. Discuteremo i limiti delle metodologie attuali, esamineremo le cause sottostanti della crisi della replicabilità e valuteremo come l’adozione di metodi avanzati, come l’inferenza bayesiana e la modellazione causale, possa offrire soluzioni efficaci (Oberauer & Lewandowsky, 2019; Wagenmakers et al., 2018; Yarkoni, 2022). Il nostro obiettivo è fornire una visione critica e costruttiva, che non solo identifichi le sfide della ricerca psicologica, ma proponga anche percorsi concreti per migliorare la qualità e l’affidabilità della scienza psicologica.\n\n\n\n\nFunder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C., Vazire, S., & West, S. G. (2014). Improving the dependability of research in personality and social psychology: Recommendations for research and educational practice. Personality and Social Psychology Review, 18(1), 3–12.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of scientific papers with P values? The American Statistician, 73(sup1), 20–25.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall, M., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze, T., et al. (2023). The replication crisis has led to positive structural, procedural, and community changes. Communications Psychology, 1(1), 3.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis in psychology. Psychonomic Bulletin & Review, 26, 1596–1618.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019). Psychology’s replication crisis and clinical psychological science. Annual Review of Clinical Psychology, 15(1), 579–604.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love, J., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018). Bayesian inference for psychology. Part I: Theoretical advantages and practical ramifications. Psychonomic Bulletin & Review, 25, 35–57.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and Brain Sciences, 45, e1.",
    "crumbs": [
      "Prefazione"
    ]
  },
  {
    "objectID": "programmazione2024.html",
    "href": "programmazione2024.html",
    "title": "1  Calendario delle lezioni",
    "section": "",
    "text": "1.1 Calendario delle relazioni in itinere\nLe relazioni di avanzamento del progetto di gruppo dovranno essere consegnate entro le scadenze stabilite. Ogni gruppo dovrà presentare un unico elaborato.\nOgni relazione rappresenta una tappa del progetto di gruppo, che culminerà nella presentazione finale durante gli ultimi incontri del corso.",
    "crumbs": [
      "Programmazione",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Calendario delle lezioni</span>"
    ]
  },
  {
    "objectID": "programmazione2024.html#calendario-delle-relazioni-in-itinere",
    "href": "programmazione2024.html#calendario-delle-relazioni-in-itinere",
    "title": "1  Calendario delle lezioni",
    "section": "",
    "text": "Data di Scadenza\nContenuto della Relazione\n\n\n\n\n18 marzo\nRelazione 1: Importazione dei dati, data wrangling, data tidying, dizionario dei dati, statistiche descrittive\n\n\n25 marzo\nRelazione 2: Priori coniugati e metodo basato su griglia\n\n\n31 marzo\nRelazione 3: Metodi Monte Carlo e algoritmi MCMC\n\n\n7 aprile\nRelazione 4: Regressione lineare\n\n\n8 maggio\nRelazione 5: Confronto di modelli\n\n\n18 maggio\nRelazione 6: Analisi frequentista; limiti dell’approccio frequentista",
    "crumbs": [
      "Programmazione",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Calendario delle lezioni</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html",
    "href": "chapters/eda/03_dplyr.html",
    "title": "17  Data tidying",
    "section": "",
    "text": "17.1 Introduzione\nSebbene Python sia generalmente considerato un linguaggio di programmazione più elegante e intuitivo rispetto a R, quest’ultimo è stato sviluppato appositamente per l’analisi dei dati. Grazie a questa specializzazione, molte operazioni di analisi, in particolare nelle fasi iniziali di preprocessing e pulizia dei dati, possono essere eseguite in modo più semplice ed efficiente con R rispetto a Python.\nL’obiettivo di questo capitolo è fornire un’introduzione alle funzioni principali del linguaggio R per le operazioni di data wrangling, cioè per il preprocessing e la pulizia dei dati. In R, queste operazioni sono strettamente legate al concetto di “data tidying”, che si riferisce all’organizzazione sistematica dei dati per facilitare l’analisi.\nPer comprendere meglio il concetto di “data tidying”, possiamo rifarci a una citazione tratta dal testo di riferimento R for Data Science (2e):\nL’essenza del “data tidying” è organizzare i dati in un formato che sia facile da gestire e analizzare. Anche se gli stessi dati possono essere rappresentati in vari modi, non tutte le rappresentazioni sono ugualmente efficienti o facili da usare. Un dataset “tidy” segue tre principi fondamentali che lo rendono particolarmente pratico:\nI pacchetti R come dplyr, ggplot2 e gli altri pacchetti del tidyverse sono progettati specificamente per lavorare con dati in formato “tidy”, permettendo agli utenti di eseguire operazioni di manipolazione e visualizzazione in modo più intuitivo ed efficiente.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#introduzione",
    "href": "chapters/eda/03_dplyr.html#introduzione",
    "title": "17  Data tidying",
    "section": "",
    "text": "“Happy families are all alike; every unhappy family is unhappy in its own way.”\n— Leo Tolstoy\n\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.”\n— Hadley Wickham\n\n\n\n\nOgni variabile è una colonna: ogni colonna nel dataset rappresenta una singola variabile.\n\nOgni osservazione è una riga: ogni riga nel dataset rappresenta un’unica osservazione.\n\nOgni valore è una cella: ogni cella del dataset contiene un singolo valore.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#pipe",
    "href": "chapters/eda/03_dplyr.html#pipe",
    "title": "17  Data tidying",
    "section": "\n17.2 Pipe",
    "text": "17.2 Pipe\nSia il pacchetto tidyr che il pacchetto dplyr utilizzano l’operatore pipe, |&gt;. La pipe è uno strumento potente che permette di concatenare in modo efficiente una serie di operazioni. Utilizzando la pipe, l’output di un’istruzione viene automaticamente passato come input all’istruzione successiva.\nQuesto metodo di concatenazione rende il codice più leggibile e conciso, permettendo di applicare una serie di trasformazioni o manipolazioni sui dati senza dover creare variabili intermedie o scrivere codice ridondante. In pratica, ogni funzione applicata con la pipe riceve l’output della funzione precedente come suo primo argomento, rendendo il flusso di operazioni lineare e facile da seguire.\nAd esempio, in una sequenza di operazioni di pulizia dati, si può utilizzare la pipe per filtrare i dati, selezionare solo alcune colonne, e riordinare le righe, tutto in un’unica catena di comandi. Questo approccio non solo semplifica la sintassi del codice, ma migliora anche la sua leggibilità, rendendo più chiaro quale operazione viene eseguita e in quale ordine.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#verbi",
    "href": "chapters/eda/03_dplyr.html#verbi",
    "title": "17  Data tidying",
    "section": "\n17.3 Verbi",
    "text": "17.3 Verbi\nLe funzioni principali (“verbi) di dplyr sono le seguenti:\n\n\n\n\n\n\nVerbo dplyr\nDescrizione\n\n\n\nselect()\nSeleziona colonne\n\n\nfilter()\nFiltra righe\n\n\narrange()\nRiordina o organizza le righe\n\n\nmutate()\nCrea nuove colonne\n\n\nsummarise()\nRiassume i valori\n\n\ngroup_by()\nConsente di eseguire operazioni di gruppo seguendo il concetto di “dividi-applica-combina”\n\n\n\nI verbi di dplyr sono suddivisi in quattro gruppi, in base all’elemento su cui operano: righe, colonne, gruppi o tabelle.\nInoltre, le diverse funzioni bind_ e _joins permettono di combinare più tibbles (ovvero, data frame) in uno solo.\nPer introdurre il processo di “data tidying”, in questo tutorial utilizzeremo il dataset msleep.\n\ndata(msleep)\ndim(msleep)\n\n[1] 83 11\n\n\n\nglimpse(msleep)\n\nRows: 83\nColumns: 11\n$ name         &lt;chr&gt; \"Cheetah\", \"Owl monkey\", \"Mountain beaver\", \"Greater shor…\n$ genus        &lt;chr&gt; \"Acinonyx\", \"Aotus\", \"Aplodontia\", \"Blarina\", \"Bos\", \"Bra…\n$ vore         &lt;chr&gt; \"carni\", \"omni\", \"herbi\", \"omni\", \"herbi\", \"herbi\", \"carn…\n$ order        &lt;chr&gt; \"Carnivora\", \"Primates\", \"Rodentia\", \"Soricomorpha\", \"Art…\n$ conservation &lt;chr&gt; \"lc\", NA, \"nt\", \"lc\", \"domesticated\", NA, \"vu\", NA, \"dome…\n$ sleep_total  &lt;dbl&gt; 12.1, 17.0, 14.4, 14.9, 4.0, 14.4, 8.7, 7.0, 10.1, 3.0, 5…\n$ sleep_rem    &lt;dbl&gt; NA, 1.8, 2.4, 2.3, 0.7, 2.2, 1.4, NA, 2.9, NA, 0.6, 0.8, …\n$ sleep_cycle  &lt;dbl&gt; NA, NA, NA, 0.1333333, 0.6666667, 0.7666667, 0.3833333, N…\n$ awake        &lt;dbl&gt; 11.9, 7.0, 9.6, 9.1, 20.0, 9.6, 15.3, 17.0, 13.9, 21.0, 1…\n$ brainwt      &lt;dbl&gt; NA, 0.01550, NA, 0.00029, 0.42300, NA, NA, NA, 0.07000, 0…\n$ bodywt       &lt;dbl&gt; 50.000, 0.480, 1.350, 0.019, 600.000, 3.850, 20.490, 0.04…\n\n\nLe colonne, nell’ordine, corrispondono a quanto segue:\n\n\nNome colonna\nDescrizione\n\n\n\nname\nNome comune\n\n\ngenus\nRango tassonomico\n\n\nvore\nCarnivoro, onnivoro o erbivoro?\n\n\norder\nRango tassonomico\n\n\nconservation\nStato di conservazione del mammifero\n\n\nsleep_total\nQuantità totale di sonno, in ore\n\n\nsleep_rem\nSonno REM, in ore\n\n\nsleep_cycle\nDurata del ciclo di sonno, in ore\n\n\nawake\nQuantità di tempo trascorso sveglio, in ore\n\n\nbrainwt\nPeso del cervello, in chilogrammi\n\n\nbodywt\nPeso corporeo, in chilogrammi",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#righe",
    "href": "chapters/eda/03_dplyr.html#righe",
    "title": "17  Data tidying",
    "section": "\n17.4 Righe",
    "text": "17.4 Righe\nI verbi più importanti che operano sulle righe di un dataset sono filter(), che seleziona le righe da includere senza modificarne l’ordine, e arrange(), che cambia l’ordine delle righe senza alterare la selezione delle righe presenti.\n\nmsleep |&gt;\n    filter(sleep_total &lt; 4) |&gt;\n    arrange(sleep_total)\n\n# A tibble: 9 × 11\n  name    genus vore  order conservation sleep_total sleep_rem sleep_cycle awake\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Giraffe Gira… herbi Arti… cd                   1.9       0.4          NA  22.1\n2 Pilot … Glob… carni Ceta… cd                   2.7       0.1          NA  21.4\n3 Horse   Equus herbi Peri… domesticated         2.9       0.6           1  21.1\n4 Roe de… Capr… herbi Arti… lc                   3        NA            NA  21  \n5 Donkey  Equus herbi Peri… domesticated         3.1       0.4          NA  20.9\n6 Africa… Loxo… herbi Prob… vu                   3.3      NA            NA  20.7\n7 Caspia… Phoca carni Carn… vu                   3.5       0.4          NA  20.5\n8 Sheep   Ovis  herbi Arti… domesticated         3.8       0.6          NA  20.2\n9 Asian … Elep… herbi Prob… en                   3.9      NA            NA  20.1\n# ℹ 2 more variables: brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;\n\n\nPossiamo usare filter() speficicano più di una condizione logica.\n\nmsleep |&gt;\n    filter((sleep_total &lt; 4 & bodywt &gt; 100) | brainwt &gt; 1) |&gt;\n    arrange(sleep_total)\n\n# A tibble: 7 × 11\n  name    genus vore  order conservation sleep_total sleep_rem sleep_cycle awake\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Giraffe Gira… herbi Arti… cd                   1.9       0.4        NA    22.1\n2 Pilot … Glob… carni Ceta… cd                   2.7       0.1        NA    21.4\n3 Horse   Equus herbi Peri… domesticated         2.9       0.6         1    21.1\n4 Donkey  Equus herbi Peri… domesticated         3.1       0.4        NA    20.9\n5 Africa… Loxo… herbi Prob… vu                   3.3      NA          NA    20.7\n6 Asian … Elep… herbi Prob… en                   3.9      NA          NA    20.1\n7 Human   Homo  omni  Prim… &lt;NA&gt;                 8         1.9         1.5  16  \n# ℹ 2 more variables: brainwt &lt;dbl&gt;, bodywt &lt;dbl&gt;",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#colonne",
    "href": "chapters/eda/03_dplyr.html#colonne",
    "title": "17  Data tidying",
    "section": "\n17.5 Colonne",
    "text": "17.5 Colonne\nEsistono quattro verbi principali che modificano le colonne di un dataset senza cambiare le righe:\n\n\nrelocate() cambia la posizione delle colonne;\n\nrename() modifica i nomi delle colonne;\n\nselect() seleziona le colonne da includere o escludere;\n\nmutate() crea nuove colonne a partire da quelle esistenti.\n\n\nmsleep2 &lt;- msleep |&gt;\n    mutate(\n        rem_prop = sleep_rem / sleep_total * 100\n    ) |&gt;\n    dplyr::select(name, vore, rem_prop, sleep_total) |&gt;\n    arrange(desc(rem_prop))\n\nglimpse(msleep2)\n\nRows: 83\nColumns: 4\n$ name        &lt;chr&gt; \"European hedgehog\", \"Thick-tailed opposum\", \"Giant armadi…\n$ vore        &lt;chr&gt; \"omni\", \"carni\", \"insecti\", \"omni\", \"carni\", \"omni\", \"omni…\n$ rem_prop    &lt;dbl&gt; 34.65347, 34.02062, 33.70166, 29.21348, 28.71287, 27.22222…\n$ sleep_total &lt;dbl&gt; 10.1, 19.4, 18.1, 8.9, 10.1, 18.0, 9.1, 10.3, 12.5, 8.4, 1…\n\n\nIn questo esempio, utilizziamo mutate() per creare una nuova colonna rem_prop che rappresenta la percentuale di sonno REM sul totale del sonno. Successivamente, select() viene utilizzato per scegliere solo alcune colonne del dataset, e infine desc(rem_prop) ordina i valori di rem_prop in ordine decrescente, dal valore maggiore a quello minore.\nPer cambiare il nome di una colonna possiamo usare rename(). Inoltre, possiamo cambiare l’ordine delle variabili con relocate().\n\nmsleep2 |&gt;\n    rename(rem_perc = rem_prop) |&gt;\n    relocate(rem_perc, .before = name)\n\n# A tibble: 83 × 4\n   rem_perc name                   vore    sleep_total\n      &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;         &lt;dbl&gt;\n 1     34.7 European hedgehog      omni           10.1\n 2     34.0 Thick-tailed opposum   carni          19.4\n 3     33.7 Giant armadillo        insecti        18.1\n 4     29.2 Tree shrew             omni            8.9\n 5     28.7 Dog                    carni          10.1\n 6     27.2 North American Opossum omni           18  \n 7     26.4 Pig                    omni            9.1\n 8     26.2 Desert hedgehog        &lt;NA&gt;           10.3\n 9     25.6 Domestic cat           carni          12.5\n10     25   Eastern american mole  insecti         8.4\n# ℹ 73 more rows",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#gruppi",
    "href": "chapters/eda/03_dplyr.html#gruppi",
    "title": "17  Data tidying",
    "section": "\n17.6 Gruppi",
    "text": "17.6 Gruppi\nIl verbo group_by() viene utilizzato per suddividere un dataset in gruppi, in base a una o più variabili, che siano rilevanti per l’analisi. Questo permette di eseguire operazioni di sintesi su ciascun gruppo separatamente, ottenendo informazioni aggregate.\nAd esempio, nel codice seguente:\n\nmsleep |&gt;\n    group_by(order) |&gt;\n    summarise(\n        avg_sleep = mean(sleep_total),\n        min_sleep = min(sleep_total),\n        max_sleep = max(sleep_total),\n        total = n()\n    ) |&gt;\n    arrange(desc(avg_sleep))\n\n# A tibble: 19 × 5\n   order           avg_sleep min_sleep max_sleep total\n   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;\n 1 Chiroptera          19.8       19.7      19.9     2\n 2 Didelphimorphia     18.7       18        19.4     2\n 3 Cingulata           17.8       17.4      18.1     2\n 4 Afrosoricida        15.6       15.6      15.6     1\n 5 Pilosa              14.4       14.4      14.4     1\n 6 Rodentia            12.5        7        16.6    22\n 7 Diprotodontia       12.4       11.1      13.7     2\n 8 Soricomorpha        11.1        8.4      14.9     5\n 9 Primates            10.5        8        17      12\n10 Erinaceomorpha      10.2       10.1      10.3     2\n11 Carnivora           10.1        3.5      15.8    12\n12 Scandentia           8.9        8.9       8.9     1\n13 Monotremata          8.6        8.6       8.6     1\n14 Lagomorpha           8.4        8.4       8.4     1\n15 Hyracoidea           5.67       5.3       6.3     3\n16 Artiodactyla         4.52       1.9       9.1     6\n17 Cetacea              4.5        2.7       5.6     3\n18 Proboscidea          3.6        3.3       3.9     2\n19 Perissodactyla       3.47       2.9       4.4     3\n\n\n\ngroup_by(order) suddivide il dataset msleep in gruppi, ciascuno corrispondente a un valore distinto della variabile order.\n\nSuccessivamente, summarise() calcola diverse statistiche per ogni gruppo:\n\n\navg_sleep è la media del totale del sonno (sleep_total) all’interno di ciascun gruppo.\n\nmin_sleep è il valore minimo di sleep_total in ogni gruppo.\n\nmax_sleep è il valore massimo di sleep_total in ogni gruppo.\n\ntotal è il numero di osservazioni (o righe) per ciascun gruppo, calcolato con la funzione n().\n\n\nInfine, arrange(desc(avg_sleep)) ordina i risultati in ordine decrescente in base alla media del sonno totale (avg_sleep), mostrando prima i gruppi con la media di sonno più alta.\n\nQuesto tipo di approccio è utile quando si vuole analizzare come cambiano le caratteristiche dei dati a seconda dei gruppi specifici, fornendo una visione più dettagliata e significativa.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#dati-mancanti",
    "href": "chapters/eda/03_dplyr.html#dati-mancanti",
    "title": "17  Data tidying",
    "section": "\n17.7 Dati mancanti",
    "text": "17.7 Dati mancanti\nNel dataset ci sono celle che contengono valori mancanti, indicati come NA. Questi rappresentano misurazioni per le quali i dati non sono stati registrati.\nPer ottenere una panoramica dei dati, inclusi i valori mancanti, possiamo utilizzare il comando:\n\nsummary(msleep)\n\n     name              genus               vore              order          \n Length:83          Length:83          Length:83          Length:83         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n conservation        sleep_total      sleep_rem      sleep_cycle    \n Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n Class :character   1st Qu.: 7.85   1st Qu.:0.900   1st Qu.:0.1833  \n Mode  :character   Median :10.10   Median :1.500   Median :0.3333  \n                    Mean   :10.43   Mean   :1.875   Mean   :0.4396  \n                    3rd Qu.:13.75   3rd Qu.:2.400   3rd Qu.:0.5792  \n                    Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n                                    NA's   :22      NA's   :51      \n     awake          brainwt            bodywt        \n Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n 1st Qu.:10.25   1st Qu.:0.00290   1st Qu.:   0.174  \n Median :13.90   Median :0.01240   Median :   1.670  \n Mean   :13.57   Mean   :0.28158   Mean   : 166.136  \n 3rd Qu.:16.15   3rd Qu.:0.12550   3rd Qu.:  41.750  \n Max.   :22.10   Max.   :5.71200   Max.   :6654.000  \n                 NA's   :27                          \n\n\nPer visualizzare il pattern di dati mancanti, ovvero come la mancanza di una variabile possa influenzare la mancanza di altre, si può usare:\n\nmd.pattern(msleep, rotate.names = TRUE)\n\n\n\n\n\n\n\n   name genus order sleep_total awake bodywt vore sleep_rem brainwt\n20    1     1     1           1     1      1    1         1       1\n9     1     1     1           1     1      1    1         1       1\n9     1     1     1           1     1      1    1         1       1\n5     1     1     1           1     1      1    1         1       1\n1     1     1     1           1     1      1    1         1       0\n10    1     1     1           1     1      1    1         1       0\n1     1     1     1           1     1      1    1         1       0\n1     1     1     1           1     1      1    1         1       0\n5     1     1     1           1     1      1    1         0       1\n3     1     1     1           1     1      1    1         0       1\n7     1     1     1           1     1      1    1         0       0\n5     1     1     1           1     1      1    1         0       0\n2     1     1     1           1     1      1    0         1       1\n1     1     1     1           1     1      1    0         1       1\n2     1     1     1           1     1      1    0         1       1\n2     1     1     1           1     1      1    0         0       0\n      0     0     0           0     0      0    7        22      27\n   conservation sleep_cycle    \n20            1           1   0\n9             1           0   1\n9             0           1   1\n5             0           0   2\n1             1           1   1\n10            1           0   2\n1             0           1   2\n1             0           0   3\n5             1           0   2\n3             0           0   3\n7             1           0   3\n5             0           0   4\n2             1           0   2\n1             0           1   2\n2             0           0   3\n2             0           0   5\n             29          51 136\n\n\nIl modo più semplice per gestire i valori mancanti è l’analisi dei casi completi (complete case analysis), che esclude dall’analisi le osservazioni con valori mancanti e utilizza solo quelle con tutte le variabili registrate. Questo approccio può essere implementato come segue:\n\nmsleep_comp &lt;- msleep |&gt;\n    drop_na()\ndim(msleep_comp)\n\n[1] 20 11\n\n\nTuttavia, per il dataset in questione, questa strategia non è adeguata, poiché si passa da 83 osservazioni iniziali a solo 20 righe dopo aver eliminato i dati mancanti.\nUn approccio più utile è l’utilizzo di metodi di imputazione (imputation methods). Uno di questi è l’imputazione semplice (single imputation, SI), dove il valore mancante viene sostituito dalla media della variabile corrispondente. Questo tipo di imputazione può essere eseguito come segue:\n\nimp &lt;- mice(msleep, method = \"mean\", m = 1, maxit = 1, print = FALSE)\n\nWarning: Number of logged events: 6\n\ncomplete(imp) |&gt;\n    summary()\n\n     name              genus               vore              order          \n Length:83          Length:83          Length:83          Length:83         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n conservation        sleep_total      sleep_rem      sleep_cycle    \n Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n Class :character   1st Qu.: 7.85   1st Qu.:1.150   1st Qu.:0.4167  \n Mode  :character   Median :10.10   Median :1.875   Median :0.4396  \n                    Mean   :10.43   Mean   :1.875   Mean   :0.4396  \n                    3rd Qu.:13.75   3rd Qu.:2.200   3rd Qu.:0.4396  \n                    Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n     awake          brainwt            bodywt        \n Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n 1st Qu.:10.25   1st Qu.:0.00635   1st Qu.:   0.174  \n Median :13.90   Median :0.11500   Median :   1.670  \n Mean   :13.57   Mean   :0.28158   Mean   : 166.136  \n 3rd Qu.:16.15   3rd Qu.:0.28158   3rd Qu.:  41.750  \n Max.   :22.10   Max.   :5.71200   Max.   :6654.000  \n\n\nTuttavia, uno dei problemi dell’imputazione media è che tende a ridurre la varianza e a rendere le stime dell’errore standard meno accurate, generando bias verso il basso.\nUn metodo più sofisticato è l’imputazione multipla (multiple imputation, MI). Questa tecnica genera più imputazioni, creando diversi dataset completi. Per ciascuno di questi dataset, è possibile effettuare l’analisi desiderata e, al termine, combinare i risultati ottenuti dai vari dataset imputati per ottenere un risultato finale più robusto. Un esempio di questa tecnica utilizza il metodo di predictive mean matching (metodo = “pmm”), che sfrutta i valori vicini nei dati come imputazioni:\n\nimp2 &lt;- mice(msleep, method = \"pmm\", m = 1, maxit = 100, print = FALSE)\n\nWarning: Number of logged events: 6\n\ncomplete(imp2) |&gt;\n    summary()\n\n     name              genus               vore              order          \n Length:83          Length:83          Length:83          Length:83         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n conservation        sleep_total      sleep_rem      sleep_cycle    \n Length:83          Min.   : 1.90   Min.   :0.100   Min.   :0.1167  \n Class :character   1st Qu.: 7.85   1st Qu.:0.900   1st Qu.:0.1833  \n Mode  :character   Median :10.10   Median :1.500   Median :0.3333  \n                    Mean   :10.43   Mean   :1.843   Mean   :0.4502  \n                    3rd Qu.:13.75   3rd Qu.:2.400   3rd Qu.:0.6667  \n                    Max.   :19.90   Max.   :6.600   Max.   :1.5000  \n     awake          brainwt            bodywt        \n Min.   : 4.10   Min.   :0.00014   Min.   :   0.005  \n 1st Qu.:10.25   1st Qu.:0.00260   1st Qu.:   0.174  \n Median :13.90   Median :0.01210   Median :   1.670  \n Mean   :13.57   Mean   :0.23634   Mean   : 166.136  \n 3rd Qu.:16.15   3rd Qu.:0.13600   3rd Qu.:  41.750  \n Max.   :22.10   Max.   :5.71200   Max.   :6654.000  \n\n\nL’imputazione multipla, grazie alla sua capacità di considerare la variabilità tra le diverse imputazioni, fornisce stime più accurate rispetto all’imputazione media semplice, riducendo il rischio di bias e fornendo risultati più affidabili.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#considerazioni-conclusive",
    "href": "chapters/eda/03_dplyr.html#considerazioni-conclusive",
    "title": "17  Data tidying",
    "section": "\n17.8 Considerazioni Conclusive",
    "text": "17.8 Considerazioni Conclusive\nIl data wrangling è una delle fasi più importanti in qualsiasi pipeline di analisi dei dati. In questo capitolo abbiamo introdotto l’uso del pacchetto tidyverse di R per la manipolazione dei dati e il suo utilizzo in scenari di base. Tuttavia, il tidyverse è un ecosistema ampio e qui abbiamo trattato solo gli elementi fondamentali. Per approfondire, si consiglia di consultare ulteriori risorse come quelle disponibili sul sito web del tidyverse e il libro R for Data Science (2e), di cui esiste anche una traduzione italiana.",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/eda/03_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/eda/03_dplyr.html#informazioni-sullambiente-di-sviluppo",
    "title": "17  Data tidying",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n\nR version 4.4.2 (2024-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C/UTF-8/C/C/C/C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] mice_3.16.0     lubridate_1.9.3 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1    \n [9] tibble_3.2.1    ggplot2_3.5.1   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.4        generics_0.1.3    shape_1.4.6.1     stringi_1.8.4    \n [5] lattice_0.22-6    lme4_1.1-35.5     mitml_0.4-5       hms_1.1.3        \n [9] digest_0.6.37     magrittr_2.0.3    evaluate_1.0.1    grid_4.4.2       \n[13] timechange_0.3.0  iterators_1.0.14  fastmap_1.2.0     jomo_2.7-6       \n[17] foreach_1.5.2     jsonlite_1.8.9    glmnet_4.1-8      Matrix_1.7-1     \n[21] nnet_7.3-19       backports_1.5.0   survival_3.7-0    fansi_1.0.6      \n[25] scales_1.3.0      codetools_0.2-20  cli_3.6.3         rlang_1.1.4      \n[29] splines_4.4.2     munsell_0.5.1     withr_3.0.2       pan_1.9          \n[33] tools_4.4.2       tzdb_0.4.0        nloptr_2.1.1      minqa_1.2.8      \n[37] colorspace_2.1-1  boot_1.3-31       broom_1.0.7       rpart_4.1.23     \n[41] vctrs_0.6.5       R6_2.5.1          lifecycle_1.0.4   htmlwidgets_1.6.4\n[45] MASS_7.3-61       pkgconfig_2.0.3   pillar_1.9.0      gtable_0.3.6     \n[49] glue_1.8.0        Rcpp_1.0.13-1     xfun_0.49         tidyselect_1.2.1 \n[53] knitr_1.49        nlme_3.1-166      htmltools_0.5.8.1 rmarkdown_2.29   \n[57] compiler_4.4.2",
    "crumbs": [
      "EDA",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Data tidying</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html",
    "href": "chapters/mcmc/18_cmdstanr_intro.html",
    "title": "68  Introduzione a CmdStanR",
    "section": "",
    "text": "68.1 Introduzione\nRiprendiamo l’analisi dei dati fittizi di un compito Go/No-go, in cui sono state registrate 6 risposte corrette su 9 prove, già discussa in precedenza. In questa sezione, utilizzeremo il pacchetto cmdstanr in R, invece di cmdstanpy in Python, per eseguire l’analisi. L’obiettivo di questo capitolo è mostrare come utilizzare CmdStan attraverso il linguaggio R, offrendo un’alternativa all’uso di Python.\nIn R, i dati vengono salvati in una lista, che equivale a un dizionario in Python.\ndata_list &lt;- list(\n    \"N\" = 9,\n    \"y\" = 6\n)\nSuccessivamente, specifichiamo il percorso del file contenente lo script Stan. È importante notare che lo script Stan rimane identico indipendentemente dall’interfaccia utilizzata, sia essa R o Python.\nfile &lt;- file.path(here::here(\"stan\", \"go_nogo_model.stan\"))\nfile\n\n[1] \"/Users/corradocaudek/_repositories/psicometria/stan/go_nogo_model.stan\"",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#compilazione-del-modello",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#compilazione-del-modello",
    "title": "68  Introduzione a CmdStanR",
    "section": "\n68.2 Compilazione del modello",
    "text": "68.2 Compilazione del modello\nPer compilare il modello, utilizziamo la funzione cmdstan_model(), che crea un nuovo oggetto CmdStanModel a partire da un file contenente un programma Stan.\n\nmod &lt;- cmdstan_model(file)\n\nDopo aver compilato il modello, possiamo stamparne le informazioni.\n\nmod$print()\n\ndata {\n  int&lt;lower=1&gt; N;\n  int&lt;lower=0&gt; y;\n}\nparameters {\n  real&lt;lower=0, upper=1&gt; p;\n}\nmodel {\n  y ~ binomial(N, p); // Likelihood\n  p ~ beta(1, 1); // Prior\n}\ngenerated quantities {\n  int&lt;lower=0, upper=1&gt; p_gt_chance = p &gt; 0.5;\n}",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#esecuzione-dellalgoritmo-mcmc",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#esecuzione-dellalgoritmo-mcmc",
    "title": "68  Introduzione a CmdStanR",
    "section": "\n68.3 Esecuzione dell’algoritmo MCMC",
    "text": "68.3 Esecuzione dell’algoritmo MCMC\nIl metodo $sample() sugli oggetti CmdStanModel esegue l’algoritmo MCMC predefinito di Stan. L’argomento data accetta una lista di oggetti R con nomi specificati.\n\nfit &lt;- mod$sample(\n    data = data_list,\n    seed = 123,\n    chains = 4,\n    parallel_chains = 4\n)",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#statistiche-riassuntive-del-posterior",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#statistiche-riassuntive-del-posterior",
    "title": "68  Introduzione a CmdStanR",
    "section": "\n68.4 Statistiche riassuntive del posterior",
    "text": "68.4 Statistiche riassuntive del posterior\nIl metodo $summary() chiama la funzione summarise_draws() dal pacchetto posterior. Il primo argomento specifica le variabili da riassumere, e gli argomenti successivi sono passati a posterior::summarise_draws() per specificare quali statistiche calcolare, l’uso di più core, ecc.\n\nfit$summary(variables = c(\"p\"))\n\n# A tibble: 1 × 10\n  variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 p        0.636  0.647 0.141 0.148 0.389 0.854  1.00    1372.    1351.\n\n\nÈ possibile utilizzare una formula per riassumere funzioni arbitrarie, come ad esempio la probabilità che \\(p\\) sia minore o uguale a 0.5.\n\nfit$summary(\"p\", pr_lt_half = ~ mean(. &lt;= 0.5))\n\n# A tibble: 1 × 2\n  variable pr_lt_half\n  &lt;chr&gt;         &lt;dbl&gt;\n1 p             0.176",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#estrazione-dei-campioni-posteriori",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#estrazione-dei-campioni-posteriori",
    "title": "68  Introduzione a CmdStanR",
    "section": "\n68.5 Estrazione dei campioni posteriori",
    "text": "68.5 Estrazione dei campioni posteriori\n\n68.5.1 Estrazione dei campioni\nIl metodo $draws() può essere utilizzato per estrarre i campioni posteriori in formati supportati dal pacchetto posterior. Qui dimostriamo i formati draws_array e draws_df.\n\n# default is a 3-D draws_array object from the posterior package\n# iterations x chains x variables\ndraws_arr &lt;- fit$draws() # or format=\"array\"\nstr(draws_arr)\n\n 'draws_array' num [1:1000, 1:4, 1:3] -7.21 -8.34 -9.16 -7.22 -7.21 ...\n - attr(*, \"dimnames\")=List of 3\n  ..$ iteration: chr [1:1000] \"1\" \"2\" \"3\" \"4\" ...\n  ..$ chain    : chr [1:4] \"1\" \"2\" \"3\" \"4\"\n  ..$ variable : chr [1:3] \"lp__\" \"p\" \"p_gt_chance\"\n\n\nOppure, possiamo usare as_draws_df() per creare un data frame:\n\ndraws &lt;- as_draws_df(fit)\nhead(draws)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__    p p_gt_chance\n1 -7.2 0.63           1\n2 -8.3 0.41           0\n3 -9.2 0.34           0\n4 -7.2 0.66           1\n5 -7.2 0.63           1\n6 -7.2 0.64           1\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nLo stesso risultato si ottiene nel modo seguente:\n\ndraws_df &lt;- as_draws_df(draws_arr)\nhead(draws_df)\n\n# A draws_df: 6 iterations, 1 chains, and 3 variables\n  lp__    p p_gt_chance\n1 -7.2 0.63           1\n2 -8.3 0.41           0\n3 -9.2 0.34           0\n4 -7.2 0.66           1\n5 -7.2 0.63           1\n6 -7.2 0.64           1\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n\n\nUna volta creato un data frame, possiamo facilmente calcolare le statistiche descrittive. Per esempio:\n\ndraws_df$p |&gt;\n    mean()\n\n[1] 0.6364032\n\n\nIn questo modo possiamo calcolare la probabilità che, ad esempio, \\(p\\) sia compreso tra 0.5 e 0.75:\n\ndraws_df |&gt;\n    summarise(\n        p_between_0.5_and_0.75 = mean(p &gt; 0.5 & p &lt; 0.75)\n    )\n\n# A tibble: 1 × 1\n  p_between_0.5_and_0.75\n                   &lt;dbl&gt;\n1                  0.595\n\n\n\npartion_vector &lt;- c(\"italic(p)&lt;0.5\", \"{0.5&lt;italic(p)}&lt;0.75\", \"lower~80*'%'\", \"middle~80*'%'\")\n\ndraws_df |&gt;\n    mutate(\n        `italic(p)&lt;0.5` = p &lt; 0.5,\n        `{0.5&lt;italic(p)}&lt;0.75` = p &gt; 0.5 & p &lt; 0.75,\n        `lower~80*'%'` = p &lt; quantile(p, probs = 0.8),\n        `middle~80*'%'` = p &gt; quantile(p, probs = 0.1) & p &lt; quantile(p, probs = 0.9)\n    ) |&gt;\n    pivot_longer(cols = `italic(p)&lt;0.5`:`middle~80*'%'`) |&gt;\n    mutate(name = factor(name, levels = partion_vector)) |&gt;\n    ggplot(aes(x = p, fill = value)) +\n    geom_histogram(boundary = 0, binwidth = 0.01) +\n    scale_x_continuous(expression(proportion ~ water ~ (italic(p))), limits = 0:1) +\n    scale_y_continuous(NULL, breaks = NULL) +\n    scale_fill_viridis_d(end = 0.6, breaks = NULL) +\n    facet_wrap(~name, labeller = label_parsed)\n\nWarning: Dropping 'draws_df' class as required metadata was removed.\n\n\n\n\n\n\n\n\n\n68.5.2 Visualizzazione dei campioni\nVisualizzare le distribuzioni posteriori è semplice: basta passare l’oggetto restituito dal metodo $draws() direttamente alle funzioni di plotting del pacchetto bayesplot.\n\nmcmc_hist(fit$draws(\"p\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#diagnostica-del-campionatore",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#diagnostica-del-campionatore",
    "title": "68  Introduzione a CmdStanR",
    "section": "\n68.6 Diagnostica del campionatore",
    "text": "68.6 Diagnostica del campionatore\nIl metodo $sampler_diagnostics() estrae i valori dei parametri del campionatore (come treedepth__, divergent__, ecc.) in formati supportati dal pacchetto posterior.\n\nstr(fit$sampler_diagnostics(format = \"df\"))\n\ndraws_df [4,000 × 9] (S3: draws_df/draws/tbl_df/tbl/data.frame)\n $ treedepth__  : num [1:4000] 2 1 1 2 1 2 2 1 1 2 ...\n $ divergent__  : num [1:4000] 0 0 0 0 0 0 0 0 0 0 ...\n $ energy__     : num [1:4000] 7.21 8.57 9.3 9.06 7.23 ...\n $ accept_stat__: num [1:4000] 1 0.762 0.816 1 0.999 ...\n $ stepsize__   : num [1:4000] 0.937 0.937 0.937 0.937 0.937 ...\n $ n_leapfrog__ : num [1:4000] 3 3 1 3 3 3 3 1 1 3 ...\n $ .chain       : int [1:4000] 1 1 1 1 1 1 1 1 1 1 ...\n $ .iteration   : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n $ .draw        : int [1:4000] 1 2 3 4 5 6 7 8 9 10 ...\n\n\n\nfit$diagnostic_summary()\n\n$num_divergent\n[1] 0 0 0 0\n\n$num_max_treedepth\n[1] 0 0 0 0\n\n$ebfmi\n[1] 1.1950436 0.9774677 1.2009506 0.9659775\n\n\nQuesto processo consente di esaminare in dettaglio le prestazioni del campionatore e di verificare eventuali problemi o inefficienze durante l’esecuzione del modello.",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "chapters/mcmc/18_cmdstanr_intro.html#informazioni-sullambiente-di-sviluppo",
    "href": "chapters/mcmc/18_cmdstanr_intro.html#informazioni-sullambiente-di-sviluppo",
    "title": "68  Introduzione a CmdStanR",
    "section": "Informazioni sull’Ambiente di Sviluppo",
    "text": "Informazioni sull’Ambiente di Sviluppo\n\nsessionInfo()\n\nR version 4.4.2 (2024-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] C/UTF-8/C/C/C/C\n\ntime zone: Europe/Rome\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1          bayesplot_1.11.1    posterior_1.6.0    \n [4] cmdstanr_0.8.1.9000 lubridate_1.9.3     forcats_1.0.0      \n [7] stringr_1.5.1       dplyr_1.1.4         purrr_1.0.2        \n[10] readr_2.1.5         tidyr_1.3.1         tibble_3.2.1       \n[13] ggplot2_3.5.1       tidyverse_2.0.0    \n\nloaded via a namespace (and not attached):\n [1] tensorA_0.36.2.1     utf8_1.2.4           generics_0.1.3      \n [4] stringi_1.8.4        hms_1.1.3            digest_0.6.37       \n [7] magrittr_2.0.3       evaluate_1.0.1       grid_4.4.2          \n[10] timechange_0.3.0     fastmap_1.2.0        plyr_1.8.9          \n[13] rprojroot_2.0.4      jsonlite_1.8.9       processx_3.8.4      \n[16] backports_1.5.0      ps_1.8.1             fansi_1.0.6         \n[19] viridisLite_0.4.2    scales_1.3.0         abind_1.4-8         \n[22] cli_3.6.3            rlang_1.1.4          munsell_0.5.1       \n[25] withr_3.0.2          yaml_2.3.10          tools_4.4.2         \n[28] reshape2_1.4.4       tzdb_0.4.0           checkmate_2.3.2     \n[31] colorspace_2.1-1     vctrs_0.6.5          R6_2.5.1            \n[34] matrixStats_1.4.1    lifecycle_1.0.4      htmlwidgets_1.6.4   \n[37] pkgconfig_2.0.3      pillar_1.9.0         gtable_0.3.6        \n[40] Rcpp_1.0.13-1        data.table_1.16.2    glue_1.8.0          \n[43] xfun_0.49            tidyselect_1.2.1     knitr_1.49          \n[46] farver_2.1.2         htmltools_0.5.8.1    labeling_0.4.3      \n[49] rmarkdown_2.29       compiler_4.4.2       distributional_0.5.0",
    "crumbs": [
      "MCMC",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>Introduzione a CmdStanR</span>"
    ]
  },
  {
    "objectID": "99-references.html",
    "href": "99-references.html",
    "title": "Bibliografia",
    "section": "",
    "text": "Albert, J., & Hu, J. (2019). Probability and bayesian\nmodeling. CRC Press.\n\n\nAlexander, R. (2023). Telling stories with data: With applications\nin r. Chapman; Hall/CRC.\n\n\nAltmejd, A., Dreber, A., Forsell, E., Huber, J., Imai, T., Johannesson,\nM., Kirchler, M., Nave, G., & Camerer, C. (2019). Predicting the\nreplicability of social science lab experiments. PloS One,\n14(12), e0225826.\n\n\nAngrist, J. D., & Pischke, J.-S. (2010). The credibility revolution\nin empirical economics: How better research design is taking the con out\nof econometrics. Journal of Economic Perspectives,\n24(2), 3–30.\n\n\nAungle, P., & Langer, E. (2023). Physical healing as a function of\nperceived time. Scientific Reports, 13(1), 22432.\n\n\nBaker, M. (2016a). 1,500 scientists lift the lid on reproducibility.\nNature, 533(7604).\n\n\nBaker, M. (2016b). Reproducibility crisis. Nature,\n533(7604), 452–454.\n\n\nBarber, D. (2012). Bayesian reasoning and machine learning.\nCambridge University Press.\n\n\nBargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of social\nbehavior: Direct effects of trait construct and stereotype activation on\naction. Journal of Personality and Social Psychology,\n71(2), 230–244.\n\n\nBaribault, B., & Collins, A. G. (2023). Troubleshooting bayesian\ncognitive models. Psychological Methods.\n\n\nBem, D. J. (2011). Feeling the future: Experimental evidence for\nanomalous retroactive influences on cognition and affect. Journal of\nPersonality and Social Psychology, 100(3), 407–425.\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A.,\nWagenmakers, E.-J., Berk, R., Bollen, K. A., Brembs, B., Brown, L.,\nCamerer, C., et al. (2018). Redefine statistical significance.\nNature Human Behaviour, 2(1), 6–10.\n\n\nBetancourt, M. (2016). Diagnosing suboptimal cotangent disintegrations\nin hamiltonian monte carlo. arXiv Preprint arXiv:1604.00695.\n\n\nBishop, D. (2019). The psychology of experimental psychologists:\nOvercoming cognitive constraints to improve research.\n\n\nBland, J. M., & Altman, D. G. (2011). Comparisons within randomised\ngroups can be very misleading. Bmj, 342.\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with\nlatent variable models. Annual Review of Statistics and Its\nApplication, 1(1), 203–232.\n\n\nBoden, M. A. (2008). An evaluation of computational modeling in\ncognitive science.\n\n\nBorel, E. (1914). Introduction\ngéométrique. G. Villars, New York.\n\n\nBornstein, A. M., & Norman, K. A. (2017). Reinstated episodic\ncontext guides sampling-based decisions for reward. Nature\nNeuroscience, 20(7), 997–1003.\n\n\nBotvinick, M. M., Braver, T. S., Barch, D. M., Carter, C. S., &\nCohen, J. D. (2001). Conflict monitoring and cognitive control.\nPsychological Review, 108(3), 624–652.\n\n\nBox, G. E. (1976). Science and statistics. Journal of the American\nStatistical Association, 71(356), 791–799.\n\n\nBrowning, M., Behrens, T. E., Jocham, G., O’reilly, J. X., & Bishop,\nS. J. (2015). Anxious individuals have difficulty learning the causal\nstatistics of aversive environments. Nature Neuroscience,\n18(4), 590–596.\n\n\nBruton, S. V., Medlin, M., Brown, M., & Sacco, D. F. (2020).\nPersonal motivations and systemic incentives: Scientists on questionable\nresearch practices. Science and Engineering Ethics,\n26(3), 1531–1547.\n\n\nBuchanan, E. M., Crain, S. E., Cunningham, A. L., Johnson, H. R., Stash,\nH., Papadatou-Pastou, M., Isager, P. M., Carlsson, R., & Aczel, B.\n(2021). Getting started creating data dictionaries: How to create a\nshareable data set. Advances in Methods and Practices in\nPsychological Science, 4(1), 2515245920928007.\n\n\nBulbulia, J. A. (2023). A workflow for causal inference in\ncross-cultural psychology. Religion, Brain & Behavior,\n13(3), 291–306.\n\n\nBürkner, P.-C. (2024). The brms book: Applied bayesian regression\nmodelling using r and stan (early draft). https://paulbuerkner.com/software/brms-book\n\n\nButler, R. C. (2022). Popularity leads to bad habits: Alternatives to\n“the statistics” routine of significance,“alphabet\nsoup” and dynamite plots. In Annals of Applied Biology\n(No. 2; Vol. 180, pp. 182–195). Wiley Online Library.\n\n\nButton, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J.,\nRobinson, E. S., & Munafò, M. R. (2013). Power failure: Why small\nsample size undermines the reliability of neuroscience. Nature\nReviews Neuroscience, 14(5), 365–376.\n\n\nByrnes, J. E., & Dee, L. E. (2024). Causal inference with\nobservational data and unobserved confounding variables.\nbioRxiv, 2024–2002.\n\n\nCalin-Jageman, R. J., & Caldwell, T. L. (2014). Replication of the\nsuperstition and performance study by damisch, stoberock, and mussweiler\n(2010). Social Psychology.\n\n\nCamerer, C. F., Dreber, A., Holzmeister, F., Ho, T.-H., Huber, J.,\nJohannesson, M., Kirchler, M., Nave, G., Nosek, B. A., Pfeiffer, T., et\nal. (2018). Evaluating the replicability of social science experiments\nin nature and science between 2010 and 2015. Nature Human\nBehaviour, 2(9), 637–644.\n\n\nCarlin, J. B., & Moreno-Betancur, M. (2023). On the uses and abuses\nof regression models: A call for reform of statistical practice and\nteaching. arXiv Preprint arXiv:2309.06668.\n\n\nCaudek, C., Lorenzino, M., & Liperoti, R. (2017). Delta plots do not\nreveal response inhibition in lying. Consciousness and\nCognition, 55, 232–244.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi\n(III rist. 2023, Vol. 11, p. 320). Laterza.\n\n\nCaudek, C., Sica, C., Cerea, S., Colpizzi, I., & Stendardi, D.\n(2021). Susceptibility to eating disorders is associated with cognitive\ninflexibility in female university students. Journal of Behavioral\nand Cognitive Therapy, 31(4), 317–328.\n\n\nCaudek, C., Sica, C., Marchetti, I., Colpizzi, I., & Stendardi, D.\n(2020). Cognitive inflexibility specificity for individuals with high\nlevels of obsessive-compulsive symptoms. Journal of Behavioral and\nCognitive Therapy, 30(2), 103–113.\n\n\nChekroud, A. M., Hawrilenko, M., Loho, H., Bondar, J., Gueorguieva, R.,\nHasan, A., Kambeitz, J., Corlett, P. R., Koutsouleris, N., Krumholz, H.\nM., et al. (2024). Illusory generalizability of clinical prediction\nmodels. Science, 383(6679), 164–167.\n\n\nChivers, T. (2024). Everything is predictable: How bayesian\nstatistics explain our world. Simon; Schuster.\n\n\nCinelli, C., Forney, A., & Pearl, J. (2024). A crash course in good\nand bad controls. Sociological Methods & Research,\n53(3), 1071–1104.\n\n\nCipresso, P., Borghesi, F., & Chirico, A. (2023). Affects affect\naffects: A markov chain. Frontiers in Psychology, 14,\n1162655.\n\n\nClayton, A. (2021). Bernoulli’s fallacy: Statistical illogic and the\ncrisis of modern science. Columbia University Press.\n\n\nCollaboration, O. S. (2015). Estimating the reproducibility of\npsychological science. Science, 349(6251), aac4716.\n\n\nCronbach, L. J. (1957). The two disciplines of scientific psychology.\nAmerican Psychologist, 12(11), 671–684.\n\n\nDanielmeier, C., & Ullsperger, M. (2011). Post-error adjustments.\nFrontiers in Psychology, 2, 233.\n\n\nDebertin, J., Vélez, J. A. J., Corlin, L., Hidalgo, B., & Murray, E.\nJ. (2024). Synthesizing subject-matter expertise for variable selection\nin causal effect estimation: A case study. Epidemiology,\n10–1097.\n\n\nDoorn, J. van, Matzke, D., & Wagenmakers, E.-J. (2020). An in-class\ndemonstration of bayesian inference. Psychology Learning &\nTeaching, 19(1), 36–45.\n\n\nDowney, A. B. (2021). Think bayes. \" O’Reilly Media, Inc.\".\n\n\nDuane, S., Kennedy, A. D., Pendleton, B. J., & Roweth, D. (1987).\nHybrid monte carlo. Physics Letters B, 195(2),\n216–222.\n\n\nDuncan, K. D., & Shohamy, D. (2016). Memory states influence\nvalue-based decisions. Journal of Experimental Psychology:\nGeneral, 145(11), 1420.\n\n\nEckstein, M. K., & Collins, A. G. (2020). Computational evidence for\nhierarchically structured reinforcement learning in humans.\nProceedings of the National Academy of Sciences,\n117(47), 29381–29389.\n\n\nEckstein, M., Summerfield, C., Daw, N., & Miller, K. J. (n.d.).\nHybrid neural-cognitive models reveal how memory shapes human reward\nlearning.\n\n\nEronen, M. I., & Bringmann, L. F. (2021). The theory crisis in\npsychology: How to move forward. Perspectives on Psychological\nScience, 16(4), 779–788.\n\n\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., &\nBaribault, B. (2018). How to become a bayesian in eight easy steps: An\nannotated reading list. Psychonomic Bulletin & Review,\n25(1), 219–234.\n\n\nFerguson, C. J., & Heene, M. (2012). A vast graveyard of undead\ntheories: Publication bias and psychological science’s aversion to the\nnull. Perspectives on Psychological Science, 7(6),\n555–561.\n\n\nFincham, E., Gašević, D., Jovanović, J., & Pardo, A. (2018). From\nstudy tactics to learning strategies: An analytical method for\nextracting interpretable representations. IEEE Transactions on\nLearning Technologies, 12(1), 59–72.\n\n\nFinetti, B. de. (1970a). Teoria delle probabilità (pp. VIII,\n350–769). G. Einaudi.\n\n\nFinetti, B. de. (1970b). Teoria delle probabilità:\nSintesi introduttiva con appendice critica. Einaudi.\n\n\nFishburn, P. C. (1986). The axioms of subjective probability.\nStatistical Science, 1(3), 335–345.\n\n\nFitzgerald, J. (2024). US states that mandated COVID-19 vaccination see\nhigher, not lower, take-up of COVID-19 boosters and flu vaccines.\nProceedings of the National Academy of Sciences,\n121(41), e2403758121. https://doi.org/10.1073/pnas.2403758121\n\n\nFox, J. (2015). Applied regression analysis and generalized linear\nmodels. Sage publications.\n\n\nFrank, M. J., & Badre, D. (2012). Mechanisms of hierarchical\nreinforcement learning in corticostriatal circuits 1: Computational\nanalysis. Cerebral Cortex, 22(3), 509–526.\n\n\nFreiesleben, T., & Molnar, C. (2024). Supervised machine\nlearning for science: How to stop worrying and love your black box.\nhttps://ml-science-book.com/\n\n\nFunder, D. C., Levine, J. M., Mackie, D. M., Morf, C. C., Sansone, C.,\nVazire, S., & West, S. G. (2014). Improving the dependability of\nresearch in personality and social psychology: Recommendations for\nresearch and educational practice. Personality and Social Psychology\nReview, 18(1), 3–12.\n\n\nFunder, D. C., & Ozer, D. J. (2019). Evaluating effect size in\npsychological research: Sense and nonsense. Advances in Methods and\nPractices in Psychological Science, 2(2), 156–168.\n\n\nGansch, R., & Adee, A. (2020). System theoretic view on\nuncertainties. 2020 Design, Automation & Test in Europe\nConference & Exhibition (DATE), 1345–1350.\n\n\nGee, P., Neal, A., & Vancouver, J. B. (2018). A formal model of goal\nrevision in approach and avoidance contexts. Organizational Behavior\nand Human Decision Processes, 146, 51–61.\n\n\nGelman, A. (2006). Prior distributions for variance parameters in\nhierarchical models (comment on article by browne and draper).\nBayesian Analysis, 1(3), 515–534. https://doi.org/10.1214/06-BA117A\n\n\nGelman, A. (2016). Commentary on “crisis in science? Or crisis in\nstatistics! Mixed messages in statistics with impact on science.”\nJournal of Statistical Research, 48-50(1), 11–12.\n\n\nGelman, A. (2024). Before data analysis: Additional recommendations for\ndesigning experiments to learn about the world. Journal of Consumer\nPsychology, 34, 190–191.\n\n\nGelman, A., & Brown, N. J. (2024). How statistical challenges\nand misreadings of the literature combine to produce unreplicable\nscience: An example from psychology.\n\n\nGelman, A., & Carlin, J. (2014). Beyond power calculations:\nAssessing type s (sign) and type m (magnitude) errors. Perspectives\non Psychological Science, 9(6), 641–651.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995).\nBayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other\nstories. Cambridge University Press.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGelman, A., & Imbens, G. (2013). Why ask why? Forward causal\ninference and reverse causal questions. National Bureau of Economic\nResearch.\n\n\nGelman, A., & Loken, E. (2013). The garden of forking paths: Why\nmultiple comparisons can be a problem, even when there is no\n“fishing expedition” or “p-hacking” and the\nresearch hypothesis was posited ahead of time. Department of\nStatistics, Columbia University, 348(1-17), 3.\n\n\nGelman, A., & Loken, E. (2014). The statistical crisis in science.\nAmerican Scientist, 102(6), 460–465.\n\n\nGelman, A., & Shalizi, C. R. (2013). Philosophy and the practice of\nbayesian statistics. British Journal of Mathematical and Statistical\nPsychology, 66(1), 8–38.\n\n\nGelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B.,\nYao, Y., Kennedy, L., Gabry, J., Bürkner, P.-C., & Modrák, M.\n(2020). Bayesian workflow. arXiv Preprint arXiv:2011.01808.\n\n\nGelman, A., & Weakliem, D. (2009). Of beauty, sex and power: Too\nlittle attention has been paid to the statistical challenges in\nestimating small effects. American Scientist, 97(4),\n310–316.\n\n\nGeman, S., & Geman, D. (1984). Stochastic relaxation,\nGibbs distributions, and the Bayesian\nrestoration of images. IEEE Transactions on Pattern Analysis and\nMachine Intelligence, 6, 721–741.\n\n\nGibson, E., & Wu, H.-H. I. (2013). Processing chinese relative\nclauses in context. Language and Cognitive Processes,\n28(1-2), 125–155.\n\n\nGill, J. (2015). Bayesian methods: A social and behavioral sciences\napproach (3rd Edition). Chapman; Hall/CRC.\n\n\nGlass, G. V., McGaw, B., & Smith, M. L. (1981). Meta-analysis in\nsocial research. Sage Publications.\n\n\nGoligher, E. C., Heath, A., & Harhay, M. O. (2024). Bayesian\nstatistics for clinical research. The Lancet,\n404(10457), 1067–1076. https://doi.org/10.1016/S0140-6736(24)00055-9\n\n\nGopalakrishna, G., Ter Riet, G., Vink, G., Stoop, I., Wicherts, J. M.,\n& Bouter, L. M. (2022). Prevalence of questionable research\npractices, research misconduct and their potential explanatory factors:\nA survey among academic researchers in the netherlands. PloS\nOne, 17(2), e0263023.\n\n\nGori, B., Grippo, A., Focardi, M., & Lolli, F. (2024). The italian\nversion of edinburgh handedness inventory: Translation, transcultural\nadaptation, and validation in healthy subjects. Laterality,\n29(2), 151–168.\n\n\nGrice, J. W., Cohn, A., Ramsey, R. R., & Chaney, J. M. (2015). On\nmuddled reasoning and mediation modeling. Basic and Applied Social\nPsychology, 37(4), 214–225.\n\n\nGriffiths, T. L., Chater, N., & Tenenbaum, J. B. (2024).\nBayesian models of cognition: Reverse engineering the mind. MIT\nPress.\n\n\nGrimes, D. R., Bauch, C. T., & Ioannidis, J. P. (2018). Modelling\nscience trustworthiness under publish or perish pressure. Royal\nSociety Open Science, 5(1), 171511.\n\n\nGunawan, D., Hawkins, G. E., Kohn, R., Tran, M.-N., & Brown, S. D.\n(2022). Time-evolving psychological processes over repeated decisions.\nPsychological Review, 129(3), 438–456.\n\n\nHanada, M., & Matsuura, S. (2022). MCMC from scratch.\nSpringer.\n\n\nHardt, M., & Recht, B. (2022). Patterns, predictions, and\nactions: Foundations of machine learning. Princeton University\nPress.\n\n\nHardwicke, T. E., Thibault, R. T., Kosie, J. E., Wallach, J. D.,\nKidwell, M. C., & Ioannidis, J. P. (2022). Estimating the prevalence\nof transparency and reproducibility-related research practices in\npsychology (2014–2017). Perspectives on Psychological Science,\n17(1), 239–251.\n\n\nHaslbeck, J. M., & Ryan, O. (2022). Recovering within-person\ndynamics from psychological time series. Multivariate Behavioral\nResearch, 57(5), 735–766.\n\n\nHastings, W. K. (1970). Monte Carlo sampling\nmethods using Markov chains and their applications.\nBiometrika, 57(1), 97–109.\n\n\nHayes, S. C., Hofmann, S. G., Stanton, C. E., Carpenter, J. K., Sanford,\nB. T., Curtiss, J. E., & Ciarrochi, J. (2019). The role of the\nindividual in the coming era of process-based therapy. Behaviour\nResearch and Therapy, 117, 40–53.\n\n\nHealy, K. (2018). Data visualization: A practical introduction.\nPrinceton University Press.\n\n\nHempel, C. G. (1970). La formazione dei concetti e delle teorie\nnella scienza empirica. Feltrinelli.\n\n\nHirsch, C. R., Meeten, F., Krahé, C., & Reeder, C. (2016). Resolving\nambiguity in emotional disorders: The nature and role of interpretation\nbiases. Annual Review of Clinical Psychology, 12(1),\n281–305.\n\n\nHitchcock, P. F., Fried, E. I., & Frank, M. J. (2022). Computational\npsychiatry needs time and context. Annual Review of Psychology,\n73(1), 243–270.\n\n\nHoffman, M. D., Gelman, A., et al. (2014). The no-u-turn sampler:\nAdaptively setting path lengths in hamiltonian monte carlo. Journal\nof Machine Learning Research, 15(1), 1593–1623.\n\n\nHoffmann, T., Hofman, A., & Wagenmakers, E.-J. (2022). Bayesian\ntests of two proportions: A tutorial with r and JASP.\nMethodology, 18(4), 239–277.\n\n\nHoogeveen, S., Sarafoglou, A., & Wagenmakers, E.-J. (2020).\nLaypeople can predict which social-science studies will be replicated\nsuccessfully. Advances in Methods and Practices in Psychological\nScience, 3(3), 267–285.\n\n\nHowson, C., & Urbach, P. (2006). Scientific reasoning: The\nbayesian approach. Open Court Publishing.\n\n\nHuntington-Klein, N. (2021). The effect: An introduction to research\ndesign and causality. Chapman; Hall/CRC.\n\n\nIoannidis, J. P. (2005). Why most published research findings are false.\nPLoS Medicine, 2(8), e124.\n\n\nIoannidis, J. P. (2019). What have we (not) learnt from millions of\nscientific papers with p values? The American Statistician,\n73(sup1), 20–25.\n\n\nJaynes, E. T. (2003). Probability theory: The logic of science.\nCambridge University Press.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with\nR. CRC Press.\n\n\nJung, K., Shavitt, S., Viswanathan, M., & Hilbe, J. M. (2014).\nFemale hurricanes are deadlier than male hurricanes. Proceedings of\nthe National Academy of Sciences, 111(24), 8782–8787.\n\n\nKanazawa, S. (2007). Beautiful parents have more daughters: A further\nimplication of the generalized trivers–willard hypothesis (gTWH).\nJournal of Theoretical Biology, 244(1), 133–140.\n\n\nKaplan, D. (2023). Bayesian statistics for the social sciences.\nGuilford Publications.\n\n\nKarataş, M., & Cutright, K. M. (2023). Thinking about god increases\nacceptance of artificial intelligence in decision-making.\nProceedings of the National Academy of Sciences,\n120(33), e2218961120.\n\n\nKhaw, M. W., Glimcher, P. W., & Louie, K. (2017). Normalized value\ncoding explains dynamic adaptation in the human valuation process.\nProceedings of the National Academy of Sciences,\n114(48), 12696–12701.\n\n\nKnight, E., Neal, A., Palada, H., & Ballard, T. (2023). A tutorial\non bayesian modeling of change across time, individuals, and groups.\nComputational Brain & Behavior, 6(4), 697–718.\n\n\nKorbmacher, M., Azevedo, F., Pennington, C. R., Hartmann, H., Pownall,\nM., Schmidt, K., Elsherif, M., Breznau, N., Robertson, O., Kalandadze,\nT., et al. (2023). The replication crisis has led to positive\nstructural, procedural, and community changes. Communications\nPsychology, 1(1), 3.\n\n\nKruschke, J. (2014). Doing bayesian data analysis: A\ntutorial with R, JAGS, and Stan. Academic\nPress.\n\n\nKullback, S., & Leibler, R. A. (1951). On information and\nsufficiency. The Annals of Mathematical Statistics,\n22(1), 79–86.\n\n\nLabatut, B. (2021). Quando abbiamo smesso di capire il mondo.\nAdelphi Edizioni spa.\n\n\nLakens, D. (2015). On the challenges of drawing conclusions from\np-values just below 0.05. PeerJ, 3, e1142.\n\n\nLarson, C., Kaplan, D., Girolamo, T., Kover, S. T., & Eigsti, I.-M.\n(2023). A bayesian statistics tutorial for clinical research: Prior\ndistributions and meaningful results for small clinical samples.\nJournal of Clinical Psychology, 79(11), 2602–2624.\n\n\nLeemput, I. A. van de, Wichers, M., Cramer, A. O., Borsboom, D.,\nTuerlinckx, F., Kuppens, P., Van Nes, E. H., Viechtbauer, W., Giltay, E.\nJ., Aggen, S. H., et al. (2014). Critical slowing down as early warning\nfor the onset and termination of depression. Proceedings of the\nNational Academy of Sciences, 111(1), 87–92.\n\n\nLeppik, I., Dreifuss, F., Porter, R., Bowman, T., Santilli, N., Jacobs,\nM., Crosby, C., Cloyd, J., Stackman, J., Graves, N., et al. (1987). A\ncontrolled study of progabide in partial seizures: Methodology and\nresults. Neurology, 37(6), 963–963.\n\n\nLilienfeld, S. O., & Strother, A. N. (2020). Psychological\nmeasurement and the replication crisis: Four sacred cows. Canadian\nPsychology/Psychologie Canadienne, 61(4), 281–288.\n\n\nLim, L., Bannert, M., Graaf, J. van der, Singh, S., Fan, Y.,\nSurendrannair, S., Rakovic, M., Molenaar, I., Moore, J., & Gašević,\nD. (2023). Effects of real-time analytics-based personalized scaffolds\non students’ self-regulated learning. Computers in Human\nBehavior, 139, 107547.\n\n\nLindley, D. V. (2013). Understanding uncertainty. John Wiley\n& Sons.\n\n\nLoken, E., & Gelman, A. (2017). Measurement error and the\nreplication crisis. Science, 355(6325), 584–585.\n\n\nLoredo, T. J., & Wolpert, R. L. (2024). Bayesian inference: More\nthan bayes’s theorem. Frontiers in Astronomy and Space\nSciences, 11, 1326926.\n\n\nLundberg, I., Johnson, R., & Stewart, B. M. (2021). What is your\nestimand? Defining the target quantity connects statistical evidence to\ntheory. American Sociological Review, 86(3), 532–565.\n\n\nMarr, D. (2010). Vision: A computational investigation into the\nhuman representation and processing of visual information. MIT\npress.\n\n\nMartin, O. (2024). Bayesian analysis with python. Packt\nPublishing Ltd.\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian modeling\nand computation in python. CRC Press.\n\n\nMatcha, W., Gasevic, D., Jovanovic, J., Pardo, A., Lim, L.,\nMaldonado-Mahauad, J., Gentili, S., Pérez-Sanagustı́n, M., Tsai, Y.-S.,\net al. (2020). Analytics of learning strategies: Role of course design\nand delivery modality authors. Journal of Learning Analytics,\n7(2), 45–71.\n\n\nMatter, U. (2025). Data analysis with AI and\nR (1st Edition). Manning Publications.\n\n\nMaul, A., Irribarra, D. T., & Wilson, M. (2016). On the\nphilosophical foundations of psychological measurement.\nMeasurement, 79, 311–320.\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (2nd Edition). CRC Press.\n\n\nMcKinney, W. (2022). Python for data analysis. \" O’Reilly\nMedia, Inc.\".\n\n\nMeehl, P. E. (1967). Theory-testing in psychology and physics: A\nmethodological paradox. Philosophy of Science, 34(2),\n103–115.\n\n\nMeehl, P. E. (2012). Why summaries of research on psychological theories\nare often uninterpretable. In Improving inquiry in social\nscience (pp. 13–59). Routledge.\n\n\nMehr, S. A., Song, L. A., & Spelke, E. S. (2016). For 5-month-old\ninfants, melodies are social. Psychological Science,\n27(4), 486–501.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H.,\n& Teller, E. (1953). Equation of state calculations by fast\ncomputing machines. The Journal of Chemical Physics,\n21(6), 1087–1092.\n\n\nMildiner Moraga, S., Bos, F. M., Doornbos, B., Bruggeman, R., Krieke, L.\nvan der, Snippe, E., & Aarts, E. (2024). Evidence for mood\ninstability in patients with bipolar disorder: Applying multilevel\nhidden markov modeling to intensive longitudinal ecological momentary\nassessment data. Journal of Psychopathology and Clinical\nScience.\n\n\nMogg, K., Bradbury, K. E., & Bradley, B. P. (2006). Interpretation\nof ambiguous information in clinical depression. Behaviour Research\nand Therapy, 44(10), 1411–1419.\n\n\nMoore, D. A., Schroeder, J., Bailey, E. R., Gershon, R., Moore, J. E.,\n& Simmons, J. P. (2024). Does thinking about god increase acceptance\nof artificial intelligence in decision-making? Proceedings of the\nNational Academy of Sciences, 121(31), e2402315121.\n\n\nMunger, K. (2023). Temporal validity as meta-science. Research &\nPolitics, 10(3), 20531680231187271.\n\n\nMurray, E. J., & Carr, K. C. (2024). Measuring racial sentiment\nusing social media is harder than it seems. Epidemiology,\n35(1), 60–63.\n\n\nMuthukrishna, M., & Henrich, J. (2019). A problem in theory.\nNature Human Behaviour, 3(3), 221–229.\n\n\nMyers, C. E., Interian, A., & Moustafa, A. A. (2022). A practical\nintroduction to using the drift diffusion model of decision-making in\ncognitive psychology, neuroscience, and health sciences. Frontiers\nin Psychology, 13, 1039172.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions\nbetween scientific judgement and statistical model selection.\nComputational Brain & Behavior, 2(1), 28–34.\n\n\nNelson, L. D., Simmons, J., & Simonsohn, U. (2018). Psychology’s\nrenaissance. Annual Review of Psychology, 69(1),\n511–534.\n\n\nNeyman, J. (1923). Sur les applications de la théorie des\nprobabilités aux experiences agricoles: Essai des\nprincipes. Roczniki Nauk Rolniczych, 10(1), 1–51.\n\n\nNicenboim, B., Schad, D., & Vasishth, S. (2024). An introduction to\nbayesian data analysis for cognitive science. Chapman and\nHall/CRC.\n\n\nNobles, M. (2000). Shades of citizenship: Race and the census in\nmodern politics. Stanford University Press.\n\n\nNosek, B. A., Spies, J. R., & Motyl, M. (2012). Scientific utopia:\nII. Restructuring incentives and practices to promote truth over\npublishability. Perspectives on Psychological Science,\n7(6), 615–631.\n\n\nNotebaert, W., Houtman, F., Van Opstal, F., Gevers, W., Fias, W., &\nVerguts, T. (2009). Post-error slowing: An orienting account.\nCognition, 111(2), 275–279.\n\n\nNuzzo, R. (2014). Statistical errors. Nature,\n506(7487), 150–152.\n\n\nO’Hagan, A. (2019). Expert knowledge elicitation: Subjective but\nscientific. The American Statistician, 73(sup1),\n69–81.\n\n\nOberauer, K., & Lewandowsky, S. (2019). Addressing the theory crisis\nin psychology. Psychonomic Bulletin & Review, 26,\n1596–1618.\n\n\nOijen, M. van. (2024). Bayesian compendium (2nd ed.). Springer.\nhttps://doi.org/10.1007/978-3-031-66085-6\n\n\nPalminteri, S., Khamassi, M., Joffily, M., & Coricelli, G. (2015).\nContextual modulation of value signals in reward and punishment\nlearning. Nature Communications, 6(1), 8096.\n\n\nPapadatou-Pastou, M., Ntolka, E., Schmitz, J., Martin, M., Munafò, M.\nR., Ocklenburg, S., & Paracchini, S. (2020). Human handedness: A\nmeta-analysis. Psychological Bulletin, 146(6),\n481–524.\n\n\nPaxinou, E., Kalles, D., Panagiotakopoulos, C. T., & Verykios, V. S.\n(2021). Analyzing sequence data with markov chain models in scientific\nexperiments. SN Computer Science, 2(5), 385.\n\n\nPearl, J. (1995). Causal diagrams for empirical research.\nBiometrika, 82(4), 669–688.\n\n\nPearl, J. (2009). Causality. Cambridge University Press.\n\n\nPearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference\nin statistics: A primer. John Wiley & Sons.\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: The new\nscience of cause and effect. Basic books.\n\n\nPeeters, W., Saqr, M., & Viberg, O. (2020). Applying learning\nanalytics to map students’ self-regulated learning tactics in an\nacademic writing course. Proceedings of the 28th International\nConference on Computers in Education, 1, 245–254.\n\n\nPetersen, I. T. (2024). Principles of psychological assessment: With\napplied examples in r. CRC Press.\n\n\nPines, A., Tozzi, L., Bertrand, C., Keller, A. S., Zhang, X.,\nWhitfield-Gabrieli, S., Hastie, T., Larsen, B., Leikauf, J., &\nWilliams, L. M. (2024). Psychiatric symptoms, cognition, and symptom\nseverity in children. JAMA Psychiatry. https://doi.org/10.1001/jamapsychiatry.2024.2399\n\n\nPress, S. J. (2009). Subjective and objective bayesian statistics:\nPrinciples, models, and applications. John Wiley & Sons.\n\n\nPulcu, E., & Browning, M. (2019). The misestimation of uncertainty\nin affective disorders. Trends in Cognitive Sciences,\n23(10), 865–875.\n\n\nRafaeli, E., & Revelle, W. (2006). A premature consensus: Are\nhappiness and sadness truly opposite affects? Motivation and\nEmotion, 30, 1–12.\n\n\nRains, S. A., & Richards, A. S. (2024). US state vaccine mandates\ndid not influence COVID-19 vaccination rates but reduced uptake of\nCOVID-19 boosters and flu vaccines compared to bans on vaccine\nrestrictions. Proceedings of the National Academy of Sciences,\n121(8), e2313610121.\n\n\nRamsey, F. P. (1926). Truth and probability. In Readings in formal\nepistemology: sourcebook (pp. 21–45). Springer.\n\n\nRescorla, R. A., & Wagner, A. R. (1972). A theory of pavlovian\nconditioning: Variations in the effectiveness of reinforcement and\nnon-reinforcement. Classical Conditioning II, Current Research and\nTheory, 2, 64–69.\n\n\nRiederer, E. (2021). Causal design patterns for data analysts.\nhttps://emilyriederer.netlify.app/post/causal-design-patterns/\n\n\nRiha, A. E., Siccha, N., Oulasvirta, A., & Vehtari, A. (2024).\nSupporting bayesian modelling workflows with iterative filtering for\nmultiverse analysis. arXiv Preprint arXiv:2404.01688.\n\n\nRitchie, S. J., Wiseman, R., & French, C. C. (2012). Failing the\nfuture: Three unsuccessful attempts to replicate bem’s ‘retroactive\nfacilitation of recall’effect. PloS One, 7(3), e33423.\n\n\nRoger, E. (1987). Stan ulam, john von neumann, and the monte carlo\nmethod. Los Alamos Science, 15, 131–137.\n\n\nRosa, L., Rosa, E., Sarner, L., & Barrett, S. (1998). A close look\nat therapeutic touch. Jama, 279(13), 1005–1010.\n\n\nRoss, C. T., Winterhalder, B., & McElreath, R. (2021). Racial\ndisparities in police use of deadly force against unarmed individuals\npersist after appropriately benchmarking shooting data on violent crime\nrates. Social Psychological and Personality Science,\n12(3), 323–332.\n\n\nRowland, Z., & Wenzel, M. (2020). Mindfulness and affect-network\ndensity: Does mindfulness facilitate disengagement from affective\nexperiences in daily life? Mindfulness, 11, 1253–1266.\n\n\nRubin, D. B. (1974). Estimating causal effects of treatments in\nrandomized and nonrandomized studies. Journal of Educational\nPsychology, 66(5), 688–701.\n\n\nRussell, J. A. (1980). A circumplex model of affect. Journal of\nPersonality and Social Psychology, 39(6), 1161–1178.\n\n\nSaqr, M., & López-Pernas, S. (2023). The temporal dynamics of online\nproblem-based learning: Why and when sequence matters. International\nJournal of Computer-Supported Collaborative Learning,\n18(1), 11–37.\n\n\nScheel, A. M., Schijen, M. R., & Lakens, D. (2021). An excess of\npositive results: Comparing the standard psychology literature with\nregistered reports. Advances in Methods and Practices in\nPsychological Science, 4(2), 25152459211007467.\n\n\nSchennach, S. M. (2016). Recent advances in the measurement error\nliterature. Annual Review of Economics, 8(1), 341–377.\n\n\nScholz, U., Stadler, G., Berli, C., Lüscher, J., & Knoll, N. (2021).\nHow do people experience and respond to social control from their\npartner? Three daily diary studies. Frontiers in Psychology,\n11, 613546.\n\n\nSchoot, V. R. de, Veen, D., Smeets, L., & Winter, S. (2020). A\ntutorial on using the WAMBS checklist to avoid the misuse of bayesian\nstatistics (pp. 30–49). Routledge.\n\n\nSchulz, E., & Gershman, S. J. (2019). The algorithmic architecture\nof exploration in the human brain. Current Opinion in\nNeurobiology, 55, 7–14.\n\n\nSchumacher, L., Bürkner, P.-C., Voss, A., Köthe, U., & Radev, S. T.\n(2023). Neural superstatistics for bayesian estimation of dynamic\ncognitive models. Scientific Reports, 13(1), 13778.\n\n\nShiffrin, R. M., & Schneider, W. (1977). Controlled and automatic\nhuman information processing: II. Perceptual learning, automatic\nattending and a general theory. Psychological Review,\n84(2), 127–190.\n\n\nShrout, P. E., & Rodgers, J. L. (2018). Psychology, science, and\nknowledge construction: Broadening perspectives from the replication\ncrisis. Annual Review of Psychology, 69(1), 487–510.\n\n\nSimchon, A., Hadar, B., & Gilead, M. (2023). A computational text\nanalysis investigation of the relation between personal and linguistic\nagency. Communications Psychology, 1(1), 23.\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011).\nFalse-positive psychology: Undisclosed flexibility in data collection\nand analysis allows presenting anything as significant.\nPsychological Science, 22(11), 1359–1366.\n\n\nSkinner, B. F. (1965). Science and human behavior. Simon;\nSchuster.\n\n\nSmaldino, P. E., & McElreath, R. (2016). The natural selection of\nbad science. Royal Society Open Science, 3(9), 160384.\n\n\nSommet, N., Weissman, D. L., Cheutin, N., & Elliot, A. J. (2023).\nHow many participants do i need to test an interaction? Conducting an\nappropriate power analysis and achieving sufficient power to detect an\ninteraction. Advances in Methods and Practices in Psychological\nScience, 6(3), 25152459231178728.\n\n\nSorensen, T., & Vasishth, S. (2015). Bayesian linear mixed models\nusing stan: A tutorial for psychologists, linguists, and cognitive\nscientists. arXiv Preprint arXiv:1506.06201.\n\n\nSoto, F. A., Vogel, E. H., Uribe-Bahamonde, Y. E., & Perez, O. D.\n(2023). Why is the rescorla-wagner model so influential?\nNeurobiology of Learning and Memory, 204, 107794.\n\n\nSpake, R., Bowler, D. E., Callaghan, C. T., Blowes, S. A., Doncaster, C.\nP., Antao, L. H., Nakagawa, S., McElreath, R., & Chase, J. M.\n(2023). Understanding “it depends” in ecology: A guide to\nhypothesising, visualising and interpreting statistical interactions.\nBiological Reviews, 98(4), 983–1002.\n\n\nSpector, A. J. (1956). Expectations, fulfillment, and morale. The\nJournal of Abnormal and Social Psychology, 52(1), 51–56.\n\n\nSpeelman, C. P., Parker, L., Rapley, B. J., & McGann, M. (2024).\nMost psychological researchers assume their samples are ergodic:\nEvidence from a year of articles in three major journals. Collabra:\nPsychology, 10(1).\n\n\nSteegen, S., Tuerlinckx, F., Gelman, A., & Vanpaemel, W. (2016).\nIncreasing transparency through a multiverse analysis. Perspectives\non Psychological Science, 11(5), 702–712.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement.\nScience, 103(2684), 677–680.\n\n\nStigler, S. (1986). The history of statistics. Belknap Harvard.\n\n\nStone, J. V. (2022). Information theory: A tutorial introduction,\n2nd edition.\n\n\nSutton, R. S., & Barto, A. G. (2018). Reinforcement learning: An\nintroduction, second edi. The MIT Press.\n\n\nTackett, J. L., Brandes, C. M., King, K. M., & Markon, K. E. (2019).\nPsychology’s replication crisis and clinical psychological science.\nAnnual Review of Clinical Psychology, 15(1), 579–604.\n\n\nTomitaka, S., Kawasaki, Y., Ide, K., Akutagawa, M., Ono, Y., &\nFurukawa, T. A. (2019). Distribution of psychological distress is stable\nin recent decades and follows an exponential pattern in the US\npopulation. Scientific Reports, 9(1), 11982.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S.\n(2022). A person-centered approach to study students’ socio-emotional\ninteraction profiles and regulation of collaborative learning.\nFrontiers in Education, 7, 866612.\n\n\nTörmänen, T., Järvenoja, H., Saqr, M., Malmberg, J., & Järvelä, S.\n(2023). Affective states and regulation of learning during\nsocio-emotional interactions in secondary school collaborative groups.\nBritish Journal of Educational Psychology, 93, 48–70.\n\n\nVan Dongen, N., Bork, R. van, Finnemann, A., Haslbeck, J., Maas, H. L.\nvan der, Robinaugh, D. J., Ron, J. de, Sprenger, J., & Borsboom, D.\n(2024). Productive explanation: A framework for evaluating explanations\nin psychological science. Psychological Review.\n\n\nVehtari, A., Gelman, A., Simpson, D., Carpenter, B., & Bürkner,\nP.-C. (2021). Rank-normalization, folding, and localization: An improved\nr ̂ for assessing convergence of MCMC (with discussion). Bayesian\nAnalysis, 16(2), 667–718.\n\n\nWagenmakers, E.-J., Lee, M., Lodewyckx, T., & Iverson, G. J. (2008).\nBayesian versus frequentist inference. Bayesian Evaluation of\nInformative Hypotheses, 181–207.\n\n\nWagenmakers, E.-J., Marsman, M., Jamil, T., Ly, A., Verhagen, J., Love,\nJ., Selker, R., Gronau, Q. F., Šmı́ra, M., Epskamp, S., et al. (2018).\nBayesian inference for psychology. Part i: Theoretical advantages and\npractical ramifications. Psychonomic Bulletin & Review,\n25, 35–57.\n\n\nWard, A., & Mann, T. (2022). Control yourself: Broad implications of\nnarrowed attention. Perspectives on Psychological Science,\n17(6), 1692–1703.\n\n\nWare, J. J., & Munafò, M. R. (2015). Significance chasing in\nresearch practice: Causes, consequences and possible solutions.\nAddiction, 110(1), 4–8.\n\n\nWasserstein, R. L., & Lazar, N. A. (2016). The ASA’s\nstatement on p-values: Context, process, and purpose. The American\nStatistician, 70(2), 129–133.\n\n\nWatson, J. B. (1913). Psychology as the behaviorist views it.\nPsychological Review, 20(2), 158.\n\n\nWest, R. M. (2022). Best practice in statistics: The use of log\ntransformation. Annals of Clinical Biochemistry,\n59(3), 162–165.\n\n\nWestreich, D., & Greenland, S. (2013). The table 2 fallacy:\nPresenting and interpreting confounder and modifier coefficients.\nAmerican Journal of Epidemiology, 177(4), 292–298.\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for\ndata science. \" O’Reilly Media, Inc.\".\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: A primer on\nmaking informative and compelling figures. O’Reilly Media.\n\n\nWilkinson, G., & Rogers, C. (1973). Symbolic description of\nfactorial models for analysis of variance. Journal of the Royal\nStatistical Society Series C: Applied Statistics, 22(3),\n392–399.\n\n\nWilliams, W. C., Haque, E., Mai, B., & Venkatraman, V. (2023). Face\nmasks influence emotion judgments of facial expressions: A\ndrift–diffusion model. Scientific Reports, 13(1),\n8842.\n\n\nWilms, R., Mäthner, E., Winnen, L., & Lanwehr, R. (2021). Omitted\nvariable bias: A threat to estimating causal relationships. Methods\nin Psychology, 5, 100075.\n\n\nYang, Y., Youyou, W., & Uzzi, B. (2020). Estimating the deep\nreplicability of scientific findings using human and artificial\nintelligence. Proceedings of the National Academy of Sciences,\n117(20), 10762–10768.\n\n\nYaple, Z. A., & Yu, R. (2019). Fractionating adaptive learning: A\nmeta-analysis of the reversal learning paradigm. Neuroscience &\nBiobehavioral Reviews, 102, 85–94.\n\n\nYarkoni, T. (2022). The generalizability crisis. Behavioral and\nBrain Sciences, 45, e1.\n\n\nYouyou, W., Yang, Y., & Uzzi, B. (2023). A discipline-wide\ninvestigation of the replicability of psychology papers over the past\ntwo decades. Proceedings of the National Academy of Sciences,\n120(6), e2208863120.\n\n\nYu, B., & Barter, R. L. (2024). Veridical data science: The\npractice of responsible data analysis and decision making. MIT\nPress.\n\n\nZanesco, A. P. (2020). Quantifying streams of thought during cognitive\ntask performance using sequence analysis. Behavior Research\nMethods, 52(6), 2417–2437.\n\n\nZetsche, U., Buerkner, P.-C., & Renneberg, B. (2019). Future\nexpectations in clinical depression: Biased or realistic? Journal of\nAbnormal Psychology, 128(7), 678.\n\n\nZwet, E. van, Gelman, A., Greenland, S., Imbens, G., Schwab, S., &\nGoodman, S. N. (2023). A new look at p values for randomized clinical\ntrials. NEJM Evidence, 3(1), EVIDoa2300003.",
    "crumbs": [
      "Bibliografia"
    ]
  }
]